<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 6]
- [cs.CL](#cs.CL) [Total: 8]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.CY](#cs.CY) [Total: 4]
- [q-fin.CP](#q-fin.CP) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Human Creativity and AI](https://arxiv.org/abs/2507.08001)
*Shengyi Xie*

Main category: cs.AI

TL;DR: 本文探讨了AI能否具备创造力，梳理了相关哲学、心理学和认知神经科学的发展，对创造力的定义与AI关联做出了综述。


<details>
  <summary>Details</summary>
Motivation: 科技尤其是AI技术飞速发展，促使关于创造力本质与表现形式的哲学重新解读，尤其聚焦人工智能是否能展现创造力的核心疑问。

Method: 通过文献综述、对创造力定义的分析，以及从自然主义与认知神经科学视角的理论梳理，系统评述了创造力哲学与AI的关系。

Result: 本文回顾了创造力的历史观念，阐释了心理学进展对创造力研究的影响，并详述了多种创造力定义和主流理论对AI创造力的回应。

Conclusion: 本文综合分析了心理学、认知神经科学与创造力哲学领域的当代理论，特别围绕AI发展展开，论证并探讨了AI是否能够具备创造力的核心问题。

Abstract: With the advancement of science and technology, the philosophy of creativity
has undergone significant reinterpretation. This paper investigates
contemporary research in the fields of psychology, cognitive neuroscience, and
the philosophy of creativity, particularly in the context of the development of
artificial intelligence (AI) techniques. It aims to address the central
question: Can AI exhibit creativity? The paper reviews the historical
perspectives on the philosophy of creativity and explores the influence of
psychological advancements on the study of creativity. Furthermore, it analyzes
various definitions of creativity and examines the responses of naturalism and
cognitive neuroscience to the concept of creativity.

</details>


### [2] [TableReasoner: Advancing Table Reasoning Framework with Large Language Models](https://arxiv.org/abs/2507.08046)
*Sishi Xiong,Dakai Wang,Yu Zhao,Jie Zhang,Changzai Pan,Haowei He,Xiangyu Li,Wenhan Chang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 提出TableReasoner，通过大模型和多步推理机制，提升了大规模真实表格上的问答能力，并在国际竞赛中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的表格数据通常规模大、列语义不全且实体存在歧义，导致表格问答任务难度提升。需要有效的策略来处理这些问题，提高表格问答系统的性能和可靠性。

Method: 基于大语言模型（LLM）和编程推理的框架。系统采用结构化与语义结合的表模式，进行表格全局理解，并设计多步schema linking流程，聚焦与查询相关的表结构信息，还集成了迭代思考与反思架构，实现增量推理。

Result: 系统在SemEval-2025 Task 8两个子任务上均获得第一名，证明了方法的有效性和先进性。

Conclusion: 提出了TableReasoner系统，通过结构化和语义结合的表模式建模，并采用多步的schema linking方法，显著提升了表格问答任务的准确性，在SemEval-2025 Task 8取得第一名。

Abstract: The paper presents our system developed for table question answering (TQA).
TQA tasks face challenges due to the characteristics of real-world tabular
data, such as large size, incomplete column semantics, and entity ambiguity. To
address these issues, we propose a large language model (LLM)-powered and
programming-based table reasoning framework, named TableReasoner. It models a
table using the schema that combines structural and semantic representations,
enabling holistic understanding and efficient processing of large tables. We
design a multi-step schema linking plan to derive a focused table schema that
retains only query-relevant information, eliminating ambiguity and alleviating
hallucinations. This focused table schema provides precise and sufficient table
details for query refinement and programming. Furthermore, we integrate the
reasoning workflow into an iterative thinking architecture, allowing
incremental cycles of thinking, reasoning and reflection. Our system achieves
first place in both subtasks of SemEval-2025 Task 8.

</details>


### [3] [A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking](https://arxiv.org/abs/2507.08207)
*Zhengye Han,Quanyan Zhu*

Main category: cs.AI

TL;DR: 用博弈论和智能体方法主动模拟并防御大模型越狱攻防，有效提升安全性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）广泛应用于关键场景，模型被攻击者通过“越狱”手段绕过安全机制的问题日益突出，亟需有效建模与防护方法。

Method: 本论文提出了一个动态Stackelberg博弈框架，将攻击者与防御者在LLM越狱背景下的互动建模为顺序型博弈，并提出了集成进攻与防御策略、采用RRT算法的“Purple Agent”智能体方案，主动模拟潜在攻击轨迹并提前干预防护。

Result: 通过该方法能够更系统性分析攻防动态，并对防御越狱风险提供原理性方案，有效提升LLM的安全性。

Conclusion: 本文为LLM越狱的风险缓解提供了理论及可行的实践基础，为后续攻防研究和安全机制开发奠定基础。

Abstract: As large language models (LLMs) are increasingly deployed in critical
applications, the challenge of jailbreaking, where adversaries manipulate the
models to bypass safety mechanisms, has become a significant concern. This
paper presents a dynamic Stackelberg game framework to model the interactions
between attackers and defenders in the context of LLM jailbreaking. The
framework treats the prompt-response dynamics as a sequential extensive-form
game, where the defender, as the leader, commits to a strategy while
anticipating the attacker's optimal responses. We propose a novel agentic AI
solution, the "Purple Agent," which integrates adversarial exploration and
defensive strategies using Rapidly-exploring Random Trees (RRT). The Purple
Agent actively simulates potential attack trajectories and intervenes
proactively to prevent harmful outputs. This approach offers a principled
method for analyzing adversarial dynamics and provides a foundation for
mitigating the risk of jailbreaking.

</details>


### [4] [Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions](https://arxiv.org/abs/2507.08208)
*Quanyan Zhu*

Main category: cs.AI

TL;DR: 作者提出LLM-Nash新模型，用于刻画和分析LLM系统中的有限理性决策过程，并证明其均衡与经典理论的不同。


<details>
  <summary>Details</summary>
Motivation: 经典博弈论假设代理完全理性、直接行动，而在LLM驱动决策中，推理过程复杂且存在认知约束。为更真实地刻画这种交互与智能体决策，需要新模型。

Method: 提出了基于博弈论的LLM-Nash模型，将代理的推理提示（prompt）作为战略变量，分析推理均衡，并利用实例展示该模型的适用性与理论差异。

Result: 该框架揭示，由于推理及提示选择的影响，LLM系统中的均衡行为会明显区别于传统博弈，能研究如认知约束、思维表达和知识学习等关键现象。

Conclusion: LLM-Nash框架为LLM驱动系统中战略交互提供了新的理论基础，能够反映参与者有限理性的推理过程，且推理均衡与经典Nash均衡不同。

Abstract: We introduce the LLM-Nash framework, a game-theoretic model where agents
select reasoning prompts to guide decision-making via Large Language Models
(LLMs). Unlike classical games that assume utility-maximizing agents with full
rationality, this framework captures bounded rationality by modeling the
reasoning process explicitly. Equilibrium is defined over the prompt space,
with actions emerging as the behavioral output of LLM inference. This approach
enables the study of cognitive constraints, mindset expressiveness, and
epistemic learning. Through illustrative examples, we show how reasoning
equilibria can diverge from classical Nash outcomes, offering a new foundation
for strategic interaction in LLM-enabled systems.

</details>


### [5] [Multi-Agent LLMs as Ethics Advocates in AI-Based Systems](https://arxiv.org/abs/2507.08392)
*Asma Yamani,Malak Baslyman,Moataz Ahmed*

Main category: cs.AI

TL;DR: 通过在多智能体大语言模型框架中加入伦理倡导代理人，实现对系统伦理需求的自动生成。经案例验证，框架可高效捕捉大多数关键伦理需求，但结果的可靠性仍需人工调整和监督，能促进伦理在需求工程中的普及。


<details>
  <summary>Details</summary>
Motivation: 在需求获取过程中融入伦理考量对于开发合乎伦理的系统非常重要。然而，人工获取伦理需求依赖于多个利益相关者的多样性意见，受到时间和资源的限制，且经常被优先级较低地对待。

Method: 提出一种框架，通过在多智能体大语言模型（LLM）环境中引入伦理倡导代理人，实现自动生成伦理需求草案。该代理人根据系统描述对伦理问题进行批判和输入。通过两个不同行业背景的案例研究对框架进行评估。

Result: 该框架可以涵盖研究者在30分钟访谈中识别的大部分伦理需求，并能引入其他相关的新需求。但同时也暴露出生成伦理需求时的可靠性问题，强调在该敏感领域仍需人工反馈。

Conclusion: 推行该研究有助于在需求工程流程中更广泛地采用伦理考量，从而推动开发更合乎伦理的产品。

Abstract: Incorporating ethics into the requirement elicitation process is essential
for creating ethically aligned systems. Although eliciting manual ethics
requirements is effective, it requires diverse input from multiple
stakeholders, which can be challenging due to time and resource constraints.
Moreover, it is often given a low priority in the requirements elicitation
process. This study proposes a framework for generating ethics requirements
drafts by introducing an ethics advocate agent in a multi-agent LLM setting.
This agent critiques and provides input on ethical issues based on the system
description. The proposed framework is evaluated through two case studies from
different contexts, demonstrating that it captures the majority of ethics
requirements identified by researchers during 30-minute interviews and
introduces several additional relevant requirements. However, it also
highlights reliability issues in generating ethics requirements, emphasizing
the need for human feedback in this sensitive domain. We believe this work can
facilitate the broader adoption of ethics in the requirements engineering
process, ultimately leading to more ethically aligned products.

</details>


### [6] [From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration](https://arxiv.org/abs/2507.08210)
*Fryderyk Mantiuk,Hanqi Zhou,Charley M. Wu*

Main category: cs.AI

TL;DR: 本文研究强化学习代理如何在好奇心与能力之间自适应权衡，通过实验揭示两者互动机制，并为认知科学及高效算法设计提供了理论和实践指导。


<details>
  <summary>Details</summary>
Motivation: 探索智能体如何在探索新知（好奇心）与掌控环境（能力）之间权衡，这个问题关系到儿童发展与科学实践等核心认知现象，亦影响强化学习智能体的效率。

Method: 将基于手工状态抽象（Tabular）与学习内部世界模型（Dreamer）的两类基于模型的强化学习智能体进行对比实验，分析各自如何平衡探索（好奇心）与控制（能力）。

Result: Tabular智能体在探索中显示出好奇心和能力的独特模式，且同时优先考虑二者能促进探索；Dreamer智能体发现探索与表征学习间存在双向互动，类似人类发展中的好奇心与能力协同演进。

Conclusion: 自发探索需要在好奇心和能力之间取得平衡，这种平衡通过内部表征的演化实现。实验结果为认知理论和高效强化学习提供新见解。

Abstract: What drives an agent to explore the world while also maintaining control over
the environment? From a child at play to scientists in the lab, intelligent
agents must balance curiosity (the drive to seek knowledge) with competence
(the drive to master and control the environment). Bridging cognitive theories
of intrinsic motivation with reinforcement learning, we ask how evolving
internal representations mediate the trade-off between curiosity (novelty or
information gain) and competence (empowerment). We compare two model-based
agents using handcrafted state abstractions (Tabular) or learning an internal
world model (Dreamer). The Tabular agent shows curiosity and competence guide
exploration in distinct patterns, while prioritizing both improves exploration.
The Dreamer agent reveals a two-way interaction between exploration and
representation learning, mirroring the developmental co-evolution of curiosity
and competence. Our findings formalize adaptive exploration as a balance
between pursuing the unknown and the controllable, offering insights for
cognitive theories and efficient reinforcement learning.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [7] [A Systematic Analysis of Declining Medical Safety Messaging in Generative AI Models](https://arxiv.org/abs/2507.08030)
*Sonali Sharma,Ahmed M. Alaa,Roxana Daneshjou*

Main category: cs.CL

TL;DR: 2022-2025年，主流医学AI模型生成的免责声明比例大幅下降，现有措施或不足以保护用户，需加强输出安全提醒。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型（包括大型语言模型和视觉语言模型）在医疗图像解读和临床问答中使用越来越广，但这些模型的输出常有不准确之处，因此需要通过免责声明提醒用户AI不是专业诊断工具。

Method: 研究通过收集2022-2025年不同版本LLM和VLM的输出，使用500例乳腺X光、500例胸部X光、500例皮肤病学图像以及500道医学问题，对输出中是否包含免责声明进行筛查和统计。

Result: 数据显示，从2022到2025年，LLM和VLM输出中免责声明的比例显著下降。2022年LLM免责声明出现率为26.3%，2025年降至0.97%；VLM在2023年为19.6%，2025年降至1.05%。2025年大多数模型输出不含免责声明。

Conclusion: 随着AI模型能力和权威性提升，免责声明在其医学输出中的缺失增加了用户风险。应动态适配临床应用场景，在每次输出时恰当提示免责声明，以保障用户安全。

Abstract: Generative AI models, including large language models (LLMs) and
vision-language models (VLMs), are increasingly used to interpret medical
images and answer clinical questions. Their responses often include
inaccuracies; therefore, safety measures like medical disclaimers are critical
to remind users that AI outputs are not professionally vetted or a substitute
for medical advice. This study evaluated the presence of disclaimers in LLM and
VLM outputs across model generations from 2022 to 2025. Using 500 mammograms,
500 chest X-rays, 500 dermatology images, and 500 medical questions, outputs
were screened for disclaimer phrases. Medical disclaimer presence in LLM and
VLM outputs dropped from 26.3% in 2022 to 0.97% in 2025, and from 19.6% in 2023
to 1.05% in 2025, respectively. By 2025, the majority of models displayed no
disclaimers. As public models become more capable and authoritative,
disclaimers must be implemented as a safeguard adapting to the clinical context
of each output.

</details>


### [8] [RepeaTTS: Towards Feature Discovery through Repeated Fine-Tuning](https://arxiv.org/abs/2507.08012)
*Atli Sigurgeirsson,Simon King*

Main category: cs.CL

TL;DR: 提出通过主成分分析找到输出波动的关键潜在特征，并用其微调Prompt型TTS模型，从而提升了模型输出的可控性和一致性，尤其适用于原本可控性较弱的场景。


<details>
  <summary>Details</summary>
Motivation: 现有基于Prompt的语音合成模型虽然用户友好，但控制能力受限于训练中暴露的声学特征，而且对相同输入产生不可控波动，影响一致性。

Method: 提出了一种新的微调方法，通过分析大量合成样本的主成分，挖掘引起输出变化的潜在特征，并将这些特征作为新的标签进行二次微调。

Result: 在使用冰岛语语料训练的两种模型上评估该方法，其中一种模型未包含情感信息，结果显示该方法在连续和离散特征上均提升了模型的可控性。

Conclusion: 该方法能够有效提升Prompt-based TTS模型的可控性，特别是在原本不包含情感信息的场景下，通过新标签微调改善了语音输出的稳定性和可操作性。

Abstract: A Prompt-based Text-To-Speech model allows a user to control different
aspects of speech, such as speaking rate and perceived gender, through natural
language instruction. Although user-friendly, such approaches are on one hand
constrained: control is limited to acoustic features exposed to the model
during training, and too flexible on the other: the same inputs yields
uncontrollable variation that are reflected in the corpus statistics.
  We investigate a novel fine-tuning regime to address both of these issues at
the same time by exploiting the uncontrollable variance of the model. Through
principal component analysis of thousands of synthesised samples, we determine
latent features that account for the highest proportion of the output variance
and incorporate them as new labels for secondary fine-tuning. We evaluate the
proposed methods on two models trained on an expressive Icelandic speech
corpus, one with emotional disclosure and one without. In the case of the model
without emotional disclosure, the method yields both continuous and discrete
features that improve overall controllability of the model.

</details>


### [9] [Mass-Scale Analysis of In-the-Wild Conversations Reveals Complexity Bounds on LLM Jailbreaking](https://arxiv.org/abs/2507.08014)
*Aldan Creo,Raul Castro Fernandez,Manuel Cebrian*

Main category: cs.CL

TL;DR: 大规模分析显示，LLM越狱攻击的复杂性并不随时间增长，且未超出现有对话复杂度上限；更复杂攻击尚未大范围出现，当前AI安全对抗未陷入激烈军备竞赛，但信息泄露依然可能带来风险。


<details>
  <summary>Details</summary>
Motivation: 大语言模型被广泛部署后，越狱攻击带来的AI安全风险备受关注。作者希望揭示现实中的越狱手法到底有多复杂，及其变化趋势，以科学评估防御难度和安全策略。

Method: 作者大规模收集分析了来自不同平台（包括专门的越狱社区和通用聊天机器人）的两百万余条真实对话，并使用概率度量、词汇多样性、压缩比、认知负荷等多维指标评估了越狱尝试的复杂性。此外，通过时间序列分析考察了攻击复杂度与毒性的演变。

Result: 越狱复杂度未超过正常对话，且整体趋于稳定，暗示当前对抗并无显著军备竞赛。随着防御机制进步，AI助手表现更安全。信息披露不当，若引发更复杂的攻击，可能破坏现有平衡并带来新风险。

Conclusion: 研究发现，现有的越狱尝试与普通对话的复杂度并无显著差异，且这一趋势在不同平台和用户群体中都保持一致。同时，用户攻击的毒性和复杂度随时间保持稳定，而AI助手的响应毒性则有所降低，说明安全机制在逐步提升。复杂度分布未显示出幂律规律，暗示越狱策略的发展上存在自然限制。

Abstract: As large language models (LLMs) become increasingly deployed, understanding
the complexity and evolution of jailbreaking strategies is critical for AI
safety.
  We present a mass-scale empirical analysis of jailbreak complexity across
over 2 million real-world conversations from diverse platforms, including
dedicated jailbreaking communities and general-purpose chatbots. Using a range
of complexity metrics spanning probabilistic measures, lexical diversity,
compression ratios, and cognitive load indicators, we find that jailbreak
attempts do not exhibit significantly higher complexity than normal
conversations. This pattern holds consistently across specialized jailbreaking
communities and general user populations, suggesting practical bounds on attack
sophistication. Temporal analysis reveals that while user attack toxicity and
complexity remains stable over time, assistant response toxicity has decreased,
indicating improving safety mechanisms. The absence of power-law scaling in
complexity distributions further points to natural limits on jailbreak
development.
  Our findings challenge the prevailing narrative of an escalating arms race
between attackers and defenders, instead suggesting that LLM safety evolution
is bounded by human ingenuity constraints while defensive measures continue
advancing. Our results highlight critical information hazards in academic
jailbreak disclosure, as sophisticated attacks exceeding current complexity
baselines could disrupt the observed equilibrium and enable widespread harm
before defensive adaptation.

</details>


### [10] [MedicalBERT: enhancing biomedical natural language processing using pretrained BERT-based model](https://arxiv.org/abs/2507.08013)
*K. Sahit Reddy,N. Ragavenderan,Vasanth K.,Ganesh N. Naik,Vishalakshi Prabhu,Nagaraja G. S*

Main category: cs.CL

TL;DR: MedicalBERT针对医学领域设计，采用专业语料和词表，显著优于其他BERT模型，平均提升5.67%。适合多种医学NLP任务，验证了迁移学习在医学文本处理的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前主流的预训练语言模型（如BERT、GPT等）虽提升了NLP表现，但在医学领域因术语专有性和上下文理解需求，表现存在局限。尤其是BERT的双向理解对于医学文本尤为重要。因此，发展更适用于生物医学领域的语言模型成为必要。

Method: 提出MedicalBERT：在大规模生物医学数据集上训练的BERT模型，引入领域专用词表。通过针对具体任务（如命名实体识别、关系抽取、问答、句子相似度与文档分类）优化与微调。使用F1分数、准确率和皮尔逊相关系数等指标进行性能评价，并与BioBERT、SciBERT等主流医学BERT变体进行对比。

Result: MedicalBERT在大多数医学NLP基准任务上优于BioBERT、SciBERT、ClinicalBERT等主流BERT模型，平均比通用BERT提升5.67%。

Conclusion: 基于预训练BERT，并融合生物医学领域知识，可以显著提升医学NLP任务的性能。该方法展示了迁移学习在捕捉医学领域专有信息方面的有效性，对医学文本处理具有应用前景。

Abstract: Recent advances in natural language processing (NLP) have been driven
bypretrained language models like BERT, RoBERTa, T5, and GPT. Thesemodels excel
at understanding complex texts, but biomedical literature, withits
domain-specific terminology, poses challenges that models likeWord2Vec and
bidirectional long short-term memory (Bi-LSTM) can't fullyaddress. GPT and T5,
despite capturing context, fall short in tasks needingbidirectional
understanding, unlike BERT. Addressing this, we proposedMedicalBERT, a
pretrained BERT model trained on a large biomedicaldataset and equipped with
domain-specific vocabulary that enhances thecomprehension of biomedical
terminology. MedicalBERT model is furtheroptimized and fine-tuned to address
diverse tasks, including named entityrecognition, relation extraction, question
answering, sentence similarity, anddocument classification. Performance metrics
such as the F1-score,accuracy, and Pearson correlation are employed to showcase
the efficiencyof our model in comparison to other BERT-based models such as
BioBERT,SciBERT, and ClinicalBERT. MedicalBERT outperforms these models onmost
of the benchmarks, and surpasses the general-purpose BERT model by5.67% on
average across all the tasks evaluated respectively. This work alsounderscores
the potential of leveraging pretrained BERT models for medicalNLP tasks,
demonstrating the effectiveness of transfer learning techniques incapturing
domain-specific information.
  (PDF) MedicalBERT: enhancing biomedical natural language processing using
pretrained BERT-based model. Available from:
https://www.researchgate.net/publication/392489050_MedicalBERT_enhancing_biomedical_natural_language_processing_using_pretrained_BERT-based_model
[accessed Jul 06 2025].

</details>


### [11] ["Amazing, They All Lean Left" -- Analyzing the Political Temperaments of Current LLMs](https://arxiv.org/abs/2507.08027)
*W. Russell Neuman,Chad Coleman,Ali Dasdan,Safinah Ali,Manan Shah,Kund Meghani*

Main category: cs.CL

TL;DR: 主流大型语言模型普遍显示自由主义价值取向，主要由于训练语料和微调方式。该倾向本质上源自数据和话语环境，为分析AI与民主讨论的关系提供新角度。


<details>
  <summary>Details</summary>
Motivation: 商业大型语言模型（LLMs）在伦理和政治回应上普遍表现出自由主义倾向，但其原因和影响尚不清楚。该研究旨在系统分析和解释这一现象背后的动因及其影响。

Method: 论文对七个主流LLM（包括OpenAI GPT-4o、Anthropic Claude Sonnet 4、Perplexity Sonar Large、Google Gemini 2.5 Flash、Meta Llama 4、Mistral 7b Le Chat 和 DeepSeek R1）采用多维度方法分析，包括道德基础理论、十余种主流政治意识形态量表以及新的当前政治争议指数。进一步比较了基础模型和微调模型，并探讨了训练语料、RLHF、学界话语、模型安全微调等影响因素。

Result: 大多数模型表现出明显且一致的自由主义价值取向，尤其强调关怀与公平。导致这种倾向的主要原因包括自由主义导向的训练语料、RLHF、学术伦理话语的自由派框架主导以及安全微调。微调往往进一步增强自由主义倾向，且该偏向是一种由民主权利话语训练产生的涌现属性，并非程序员个人意愿。

Conclusion: LLMs的自由主义倾向是一种与训练数据和话语环境相关的自然产物，为理解群体推理与民主话语提供了新视角，而不是编程失误或人为偏见。

Abstract: Recent studies have revealed a consistent liberal orientation in the ethical
and political responses generated by most commercial large language models
(LLMs), yet the underlying causes and resulting implications remain unclear.
This paper systematically investigates the political temperament of seven
prominent LLMs - OpenAI's GPT-4o, Anthropic's Claude Sonnet 4, Perplexity
(Sonar Large), Google's Gemini 2.5 Flash, Meta AI's Llama 4, Mistral 7b Le Chat
and High-Flyer's DeepSeek R1 -- using a multi-pronged approach that includes
Moral Foundations Theory, a dozen established political ideology scales and a
new index of current political controversies. We find strong and consistent
prioritization of liberal-leaning values, particularly care and fairness,
across most models. Further analysis attributes this trend to four overlapping
factors: Liberal-leaning training corpora, reinforcement learning from human
feedback (RLHF), the dominance of liberal frameworks in academic ethical
discourse and safety-driven fine-tuning practices. We also distinguish between
political "bias" and legitimate epistemic differences, cautioning against
conflating the two. A comparison of base and fine-tuned model pairs reveals
that fine-tuning generally increases liberal lean, an effect confirmed through
both self-report and empirical testing. We argue that this "liberal tilt" is
not a programming error or the personal preference of programmers but an
emergent property of training on democratic rights-focused discourse. Finally,
we propose that LLMs may indirectly echo John Rawls' famous veil-of ignorance
philosophical aspiration, reflecting a moral stance unanchored to personal
identity or interest. Rather than undermining democratic discourse, this
pattern may offer a new lens through which to examine collective reasoning.

</details>


### [12] [Better Together: Quantifying the Benefits of AI-Assisted Recruitment](https://arxiv.org/abs/2507.08029)
*Ada Aka,Emil Palikot,Ali Ansari,Nima Yazdani*

Main category: cs.CL

TL;DR: AI招聘显著提升了筛选和就业效果，但存在选择年纪更轻、经验更少候选人的倾向，对招聘结果和公平性会产生影响。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能（AI）在招聘流程中的应用不断增加，其对招聘效率和候选人筛选的实际影响尚缺乏量化的实证证据。本文旨在填补这一空白，评估AI在招聘中的具体作用。

Method: 将37,000名初级开发岗位的申请者随机分配到传统招聘流程（简历筛选加人工评估）和AI辅助流程（首先由AI主导的结构化视频面试，然后人工评估）两组。两组通过初选的候选人在最后阶段均接受同一个人工面试，且面试官并不知晓候选人所经历的筛选方式。随后，通过获得领英信息追踪两组顶级申请者五个月后的就业情况，并对AI生成的面试记录进行分析。

Result: AI辅助招聘流程中54%的候选人通过了最终面试，而传统流程中仅有34%，平均效应为20个百分点。五个月后，23%的AI组顶级申请者找到新工作，而传统组为18%，差异为5.9个百分点。AI更容易选拔出更年轻、经验较少、资历较低的候选人。

Conclusion: AI辅助招聘能显著提高候选人通过最终面试的概率和后续就业率，同时其选择偏好与传统流程存在差异，这对招聘决策和人才获取过程有重要影响，需要关注其潜在的结构性影响。

Abstract: Artificial intelligence (AI) is increasingly used in recruitment, yet
empirical evidence quantifying its impact on hiring efficiency and candidate
selection remains limited. We randomly assign 37,000 applicants for a
junior-developer position to either a traditional recruitment process (resume
screening followed by human selection) or an AI-assisted recruitment pipeline
incorporating an initial AI-driven structured video interview before human
evaluation. Candidates advancing from either track faced the same final-stage
human interview, with interviewers blind to the earlier selection method. In
the AI-assisted pipeline, 54% of candidates passed the final interview compared
with 34% from the traditional pipeline, yielding an average treatment effect of
20 percentage points (SE 12 pp.). Five months later, we collected LinkedIn
profiles of top applicants from both groups and found that 18% (SE 1.1%) of
applicants from the traditional track found new jobs compared with 23% (SE
2.3%) from the AI group, resulting in a 5.9 pp. (SE 2.6 pp.) difference in the
probability of finding new employment between groups. The AI system tended to
select younger applicants with less experience and fewer advanced credentials.
We analyze AI-generated interview transcripts to examine the selection criteria
and conversational dynamics. Our findings contribute to understanding how AI
technologies affect decision making in recruitment and talent acquisition while
highlighting some of their potential implications.

</details>


### [13] [Assessing the Capabilities and Limitations of FinGPT Model in Financial NLP Applications](https://arxiv.org/abs/2507.08015)
*Prudence Djagba,Chimezie A. Odinakachukwu*

Main category: cs.CL

TL;DR: FinGPT针对金融领域的NLP任务在部分分类任务上表现优异，接近GPT-4，但在复杂推理与生成类任务中差距明显。研究指出该模型需进一步优化，不足以完全替代通用大模型。


<details>
  <summary>Details</summary>
Motivation: 评估金融领域特定语言模型FinGPT在真实金融NLP应用中的性能与不足，明确其与通用大模型（如GPT-4）和人类表现的对比，指出未来改进方向。

Method: 设计了六大金融NLP任务（情感分析、文本分类、命名实体识别、金融问答、文本摘要、股票走势预测），用金融专用数据集对FinGPT进行系统测试，并与GPT-4及人类基准进行性能比较。

Result: FinGPT在结构化的金融分类任务（如情感分析、标题分类）中表现突出，接近甚至媲美GPT-4。但在需要推理和生成的任务（如金融问答与摘要）中明显落后，尤其在数值准确性和复杂推理方面与GPT-4及人类存在较大差距。

Conclusion: FinGPT在特定金融结构化任务上表现良好，但并非全能解决方案。当前还需要进一步优化架构和针对金融领域进行深度定制，本文为后续相关研究提供了基准和方向。

Abstract: This work evaluates FinGPT, a financial domain-specific language model,
across six key natural language processing (NLP) tasks: Sentiment Analysis,
Text Classification, Named Entity Recognition, Financial Question Answering,
Text Summarization, and Stock Movement Prediction. The evaluation uses
finance-specific datasets to assess FinGPT's capabilities and limitations in
real-world financial applications. The results show that FinGPT performs
strongly in classification tasks such as sentiment analysis and headline
categorization, often achieving results comparable to GPT-4. However, its
performance is significantly lower in tasks that involve reasoning and
generation, such as financial question answering and summarization. Comparisons
with GPT-4 and human benchmarks highlight notable performance gaps,
particularly in numerical accuracy and complex reasoning. Overall, the findings
indicate that while FinGPT is effective for certain structured financial tasks,
it is not yet a comprehensive solution. This research provides a useful
benchmark for future research and underscores the need for architectural
improvements and domain-specific optimization in financial language models.

</details>


### [14] [Mechanistic Indicators of Understanding in Large Language Models](https://arxiv.org/abs/2507.08017)
*Pierre Beckmann,Matthieu Queloz*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型（LLM）机械可解释性最新进展，提出三层次“机器理解”新框架，认为LLM能展现出功能性理解但结构与人类不同，未来应更关注模型内在机制。


<details>
  <summary>Details</summary>
Motivation: 面对越来越复杂的LLM，人们对其是否具备理解能力存在争议。本文旨在梳理最新MI研究，提出更精细、具体的理解框架，帮助理解LLM的内部认知结构。

Method: 系统化梳理了近期机械可解释性（MI）领域的研究成果，并提出三层次的机器理解理论框架，结合实证研究进行了理论整合与分析。

Result: 提出了三层机器理解：概念理解（通过特征形成抽象连接）、世界状态理解（追踪事实与特征间的动态关系）、原理性理解（发现普遍规律并形成电路结构）。同时指出LLM在内部存在并行机制，认知方式与人类不同。

Conclusion: LLMs表现出某种形式的“理解”，但其认知结构和人类仍有显著差异，未来的讨论应聚焦于这些模型内部独特的认知机制而非单纯的“是否理解”。

Abstract: Recent findings in mechanistic interpretability (MI), the field probing the
inner workings of Large Language Models (LLMs), challenge the view that these
models rely solely on superficial statistics. Here, we offer an accessible
synthesis of these findings that doubles as an introduction to MI, all while
integrating these findings within a novel theoretical framework for thinking
about machine understanding. We argue that LLMs develop internal structures
that are functionally analogous to the kind of understanding that consists in
seeing connections. To sharpen this idea, we propose a three-tiered conception
of machine understanding. First, conceptual understanding emerges when a model
forms "features" as directions in latent space, thereby learning the
connections between diverse manifestations of something. Second,
state-of-the-world understanding emerges when a model learns contingent factual
connections between features and dynamically tracks changes in the world.
Third, principled understanding emerges when a model ceases to rely on a
collection of memorized facts and discovers a "circuit" that connects these
facts. However, we conclude by exploring the "parallel mechanisms" phenomenon,
arguing that while LLMs exhibit forms of understanding, their cognitive
architecture remains different from ours, and the debate should shift from
whether LLMs understand to how their strange minds work.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [15] [EP-GAT: Energy-based Parallel Graph Attention Neural Network for Stock Trend Classification](https://arxiv.org/abs/2507.08184)
*Zhuodong Jiang,Pengju Zhang,Peter Martin*

Main category: cs.CE

TL;DR: 本文提出了一种结合能量差和并行图注意力机制的股票预测方法，可动态建模股票间关系并保留层次特征，在多个市场和数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于图神经网络的股票预测方法主要依赖静态或手工定义的因子来建模股票间的动态相互关系，且难以保持股票内部的层次特征，限制了模型在预测复杂股票市场中的表现。

Method: 提出了一种新的Energy-based Parallel Graph Attention Neural Network（EP-GAT）方法。该方法首先利用股票之间的能量差与玻尔兹曼分布动态生成股票图，捕捉相互依赖关系的变化。随后应用并行图注意力机制来保留股票内部的层次动态特征。

Result: 在五个真实数据集（包括美国NASDAQ、NYSE、SP和英国FTSE、LSE市场）上的实验结果表明，EP-GAT在多项评测指标上均优于五个主流基线方法。消融实验与超参数敏感性分析进一步验证了各模块的有效性。

Conclusion: EP-GAT方法能够有效建模股票间动态依赖关系并保留层次特征，在多市场、多数据集上表现优异，证明了其在股票预测任务中的优越性。

Abstract: Graph neural networks have shown remarkable performance in forecasting stock
movements, which arises from learning complex inter-dependencies between stocks
and intra-dynamics of stocks. Existing approaches based on graph neural
networks typically rely on static or manually defined factors to model changing
inter-dependencies between stocks. Furthermore, these works often struggle to
preserve hierarchical features within stocks. To bridge these gaps, this work
presents the Energy-based Parallel Graph Attention Neural Network, a novel
approach for predicting future movements for multiple stocks. First, it
generates a dynamic stock graph with the energy difference between stocks and
Boltzmann distribution, capturing evolving inter-dependencies between stocks.
Then, a parallel graph attention mechanism is proposed to preserve the
hierarchical intra-stock dynamics. Extensive experiments on five real-world
datasets are conducted to validate the proposed approach, spanning from the US
stock markets (NASDAQ, NYSE, SP) and UK stock markets (FTSE, LSE). The
experimental results demonstrate that EP-GAT consistently outperforms
competitive five baselines on test periods across various metrics. The ablation
studies and hyperparameter sensitivity analysis further validate the
effectiveness of each module in the proposed method.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [16] [A Systematic Mapping Study on Open Source Agriculture Technology Research](https://arxiv.org/abs/2507.08103)
*Kevin Lumbard,Vinod Kumar Ahuja,Matt Cantu Snell*

Main category: cs.CY

TL;DR: 本研究系统梳理了开源农业数字技术的科研现状，揭示其发展趋势与未来研究机会，对农业和信息系统领域具有参考价值。


<details>
  <summary>Details</summary>
Motivation: 农业对美国经济贡献巨大，随着数字技术的出现，农业领域发生了颠覆性变化。目前，开源理念正逐步进入农业科技领域，但其影响和相关研究尚未被深入探讨。本文旨在系统梳理和分析开源农业数字技术的科学研究现状。

Method: 本文采用系统映射研究法，对现有开源农业数字技术相关文献进行了分类与整理，以展现研究主题、趋势和未充分探索的领域。

Result: 研究呈现了现有开源农业数字技术相关科学文献的分布、研究趋势及潜在不足，强调了该领域的未来研究方向与机遇。

Conclusion: 开源与农业数字技术的融合为农业发展提供了新的动力和研究方向，信息系统领域可基于当前趋势拓展未来的研究，以推动农业科技创新。

Abstract: Agriculture contributes trillions of dollars to the US economy each year.
Digital technologies are disruptive forces in agriculture. The open source
movement is beginning to emerge in agriculture technology and has dramatic
implications for the future of farming and agriculture digital technologies.
The convergence of open source and agriculture digital technology is observable
in scientific research, but the implications of open source ideals related to
agriculture technology have yet to be explored. This study explores open
agriculture digital technology through a systematic mapping of available open
agriculture digital technology research. The study contributes to Information
Systems research by illuminating current trends and future research
opportunities.

</details>


### [17] [AI Feedback Enhances Community-Based Content Moderation through Engagement with Counterarguments](https://arxiv.org/abs/2507.08110)
*Saeedeh Mohammadi,Taha Yasseri*

Main category: cs.CY

TL;DR: 本文研究AI辅助社区笔记审核，通过不同类型AI反馈提升笔记质量，尤其辩论型反馈效果最佳，显示集体智能与多元视角的重要性，对AI在政治内容审核领域的应用提供新见解。


<details>
  <summary>Details</summary>
Motivation: 社交媒体在新闻传播和政治沟通中影响巨大，但其传播虚假信息引发广泛担忧，因此各平台推行内容审核策略，有效性和公正性成为研究重点。

Method: 研究提出一种AI辅助的混合审核框架：参与者在撰写社区审核笔记后，收到AI生成的反馈（支持型、中立型或辩论型），并据此进行笔记修订。

Result: 通过纳入AI反馈，笔记质量显著提升。其中，辩论型反馈带来最大提升效果，显示多元观点和直接互动对集体智能的价值。

Conclusion: AI生成反馈能有效提升众包事实核查的质量，尤其是鼓励辩论和多元化视角的反馈；AI在政治内容审核中具有巨大潜力，设计需注重信息性和多样性。

Abstract: Today, social media platforms are significant sources of news and political
communication, but their role in spreading misinformation has raised
significant concerns. In response, these platforms have implemented various
content moderation strategies. One such method, Community Notes on X, relies on
crowdsourced fact-checking and has gained traction, though it faces challenges
such as partisan bias and delays in verification. This study explores an
AI-assisted hybrid moderation framework in which participants receive
AI-generated feedback -supportive, neutral, or argumentative -on their notes
and are asked to revise them accordingly. The results show that incorporating
feedback improves the quality of notes, with the most substantial gains
resulting from argumentative feedback. This underscores the value of diverse
perspectives and direct engagement in human-AI collective intelligence. The
research contributes to ongoing discussions about AI's role in political
content moderation, highlighting the potential of generative AI and the
importance of informed design.

</details>


### [18] [Effect of Static vs. Conversational AI-Generated Messages on Colorectal Cancer Screening Intent: a Randomized Controlled Trial](https://arxiv.org/abs/2507.08211)
*Neil K. R. Sehgal,Manuel Tonneau,Andy Tan,Shivan J. Mehta,Alison Buttenheim,Lyle Ungar,Anish K. Agarwal,Sharath Chandra Guntuku*

Main category: cs.CY

TL;DR: 简短、定制化AI消息显著提升了粪便筛查意向，且效果优于复杂聊天机器人与专家材料，为健康行为干预提供了更具扩展性的方案，但对传统肠镜偏好影响有限。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）聊天机器人在说服性沟通方面表现出越来越大的潜力，但其在临床等真实环境中的实用性尚不确定，尤其是在需要持续对话且扩展性受限的场景下。研究者希望验证LLM在促进健康行为改变方面的效果及其可行性。

Method: 采用预注册随机对照试验，招募美国45-75岁、从未做过结直肠癌筛查的915名成年人。被试随机分配至四组：（1）无消息组（对照），（2）专家编写患者材料组，（3）单条AI生成消息组，（4）动机性访谈聊天机器人组。所有参与者需在所在实验组至少停留3分钟，AI组根据自报年龄和性别定制信息。

Result: 两种AI干预组在提升粪便筛查意向上比专家材料组显著更有效（提升12.9-13.8/100 vs 7.5/100，p<0.001），但在提升肠镜筛查意向方面未优于专家材料组，尽管聊天机器人组交流时间更长，但提升意向未优于单条AI消息组。

Conclusion: 简洁、针对人口统计特征定制的AI消息比复杂聊天机器人或传统专家材料更具扩展性和临床实用价值，能更有效促进行为意向转变，尤其是在辅助较为生疏、低侵入性的检测方法（如粪检）时。未来需探索个性化要素对行为改变的作用，以及如何将意向提升转化为实际健康行为。

Abstract: Large language model (LLM) chatbots show increasing promise in persuasive
communication. Yet their real-world utility remains uncertain, particularly in
clinical settings where sustained conversations are difficult to scale. In a
pre-registered randomized controlled trial, we enrolled 915 U.S. adults (ages
45-75) who had never completed colorectal cancer (CRC) screening. Participants
were randomized to: (1) no message control, (2) expert-written patient
materials, (3) single AI-generated message, or (4) a motivational interviewing
chatbot. All participants were required to remain in their assigned condition
for at least three minutes. Both AI arms tailored content using participant's
self-reported demographics including age and gender. Both AI interventions
significantly increased stool test intentions by over 12 points
(12.9-13.8/100), compared to a 7.5 gain for expert materials (p<.001 for all
comparisons). While the AI arms outperformed the no message control for
colonoscopy intent, neither showed improvement xover expert materials. Notably,
for both outcomes, the chatbot did not outperform the single AI message in
boosting intent despite participants spending ~3.5 minutes more on average
engaging with it. These findings suggest concise, demographically tailored AI
messages may offer a more scalable and clinically viable path to health
behavior change than more complex conversational agents and generic time
intensive expert-written materials. Moreover, LLMs appear more persuasive for
lesser-known and less-invasive screening approaches like stool testing, but may
be less effective for entrenched preferences like colonoscopy. Future work
should examine which facets of personalization drive behavior change, whether
integrating structural supports can translate these modest intent gains into
completed screenings, and which health behaviors are most responsive to
AI-supported guidance.

</details>


### [19] [Generative AI in Science: Applications, Challenges, and Emerging Questions](https://arxiv.org/abs/2507.08310)
*Ryan Harries,Cornelia Lawson,Philip Shapira*

Main category: cs.CY

TL;DR: 本文系统梳理了生成式人工智能（GenAI）在科学领域的应用、益处和挑战，发现其正被快速采用，但长期影响和治理方式仍需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 鉴于生成式人工智能（如大型语言模型和ChatGPT）在科学领域的快速发展和应用，亟需梳理其应用现状、优势与面临的挑战，以明确未来研究方向。

Method: 通过在OpenAlex出版物数据库采用布尔搜索法筛选相关高被引文献和评论，并对39篇文献进行质性编码和分析。

Result: 分析表明，GenAI主要被应用于科学研究、科学写作、医务实践以及教育与培训领域。尽管应用迅速增长，但相关的不确定性和治理难题依然突出。

Conclusion: 生成式人工智能（GenAI）在科学和科学实践中正迅速普及，但其长期影响尚未明朗，对其使用与治理仍存在诸多不确定性。

Abstract: This paper examines the impact of Generative Artificial Intelligence (GenAI)
on scientific practices, conducting a qualitative review of selected literature
to explore its applications, benefits, and challenges. The review draws on the
OpenAlex publication database, using a Boolean search approach to identify
scientific literature related to GenAI (including large language models and
ChatGPT). Thirty-nine highly cited papers and commentaries are reviewed and
qualitatively coded. Results are categorized by GenAI applications in science,
scientific writing, medical practice, and education and training. The analysis
finds that while there is a rapid adoption of GenAI in science and science
practice, its long-term implications remain unclear, with ongoing uncertainties
about its use and governance. The study provides early insights into GenAI's
growing role in science and identifies questions for future research in this
evolving field.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [20] [Tensor train representations of Greeks for Fourier-based pricing of multi-asset options](https://arxiv.org/abs/2507.08482)
*Rihito Sakurai,Koichi Miyamoto,Tsuyoshi Okubo*

Main category: q-fin.CP

TL;DR: 本文提出了一种基于张量列表示的多资产期权Greeks计算框架，通过数值微分实现了比Monte Carlo高出数量级的效率，同时精度可比甚至更优。推荐使用数值微分方法。


<details>
  <summary>Details</summary>
Motivation: 多资产期权Greeks高效计算一直是量化金融的难题。Monte Carlo（MC）模拟虽常用于实际，但精度高时样本需求极大，效率低。因此寻求既高效又精确的计算框架。

Method: 将基于傅里叶变换（FT）的定价函数通过张量交叉插值进行TT压缩学习，然后利用该TT表示，提出了两种计算Greeks的方法：一是对单个张量核心应用数值微分算子（ND），二是对FT定价的封闭表达式做解析微分后再转为TT（AN）。

Result: 在Black-Scholes模型下的五资产min-call期权实验中，TT方法相较于MC方法实现了约10⁵倍的加速，同时保持相当的精度。ND方法在实现精度和效率上表现最佳。

Conclusion: 基于张量列（TT）表示的数值微分方法（ND）在计算多资产期权的Greeks时，实现了与解析方法（AN）相当或更高的精度，并且在构建TT表示时所需的计算复杂度更低，因此成为首选方法。

Abstract: Efficient computation of Greeks for multi-asset options remains a key
challenge in quantitative finance. While Monte Carlo (MC) simulation is widely
used, it suffers from the large sample complexity for high accuracy. We propose
a framework to compute Greeks in a single evaluation of a tensor train (TT),
which is obtained by compressing the Fourier transform (FT)-based pricing
function via TT learning using tensor cross interpolation. Based on this TT
representation, we introduce two approaches to compute Greeks: a numerical
differentiation (ND) approach that applies a numerical differential operator to
one tensor core and an analytical (AN) approach that constructs the TT of
closed-form differentiation expressions of FT-based pricing. Numerical
experiments on a five-asset min-call option in the Black-Sholes model show
significant speed-ups of up to about $10^{5} \times$ over MC while maintaining
comparable accuracy. The ND approach matches or exceeds the accuracy of the AN
approach and requires lower computational complexity for constructing the TT
representation, making it the preferred choice.

</details>
