<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 10]
- [cs.CL](#cs.CL) [Total: 11]
- [cs.CE](#cs.CE) [Total: 5]
- [cs.CY](#cs.CY) [Total: 7]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](https://arxiv.org/abs/2507.12484)
*Jarosław A. Chudziak,Adam Kostka*

Main category: cs.AI

TL;DR: 本文针对现有AI辅导系统的被动性，提出一种多智能体AI数学辅导平台，集成个性化反馈、课程生成和知识检索，实现模块化和工具化的学习体验，有效提升了数学学习的个性化与结构化水平。


<details>
  <summary>Details</summary>
Motivation: 当前AI辅导系统大多为被动响应式，只提供直接答案，缺乏促进深入反思或结合结构化教学工具的能力，特别是在数学领域尤为明显。研究动机在于提升AI辅导系统的自主性和教学效果，让AI不仅仅是答题工具。

Method: 研究提出并开发了一种新颖的多智能体AI辅导平台，结合自适应和个性化反馈、结构化课程生成及教科书知识检索，实现模块化、工具辅助的学习过程。系统由多种教育智能体与AI组件协作，支持定制练习和针对性复习。

Result: 平台支持学生有效学习新知识、识别并弥补弱项、备考复习及无限量个性化练习。实验结果显示该系统可提供更为结构化和有效的数学教学方案。

Conclusion: 通过多智能体和AI驱动组件结合，本研究提出的平台丰富了AI教育领域，为数学教学提供了更模块化、有效的解决方案。该方法有助于AI导师系统从被动答题走向主动、工具化和个性化辅导。

Abstract: The growing ubiquity of artificial intelligence (AI), in particular large
language models (LLMs), has profoundly altered the way in which learners gain
knowledge and interact with learning material, with many claiming that AI
positively influences their learning achievements. Despite this advancement,
current AI tutoring systems face limitations associated with their reactive
nature, often providing direct answers without encouraging deep reflection or
incorporating structured pedagogical tools and strategies. This limitation is
most apparent in the field of mathematics, in which AI tutoring systems remain
underdeveloped. This research addresses the question: How can AI tutoring
systems move beyond providing reactive assistance to enable structured,
individualized, and tool-assisted learning experiences? We introduce a novel
multi-agent AI tutoring platform that combines adaptive and personalized
feedback, structured course generation, and textbook knowledge retrieval to
enable modular, tool-assisted learning processes. This system allows students
to learn new topics while identifying and targeting their weaknesses, revise
for exams effectively, and practice on an unlimited number of personalized
exercises. This article contributes to the field of artificial intelligence in
education by introducing a novel platform that brings together pedagogical
agents and AI-driven components, augmenting the field with modular and
effective systems for teaching mathematics.

</details>


### [2] [MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](https://arxiv.org/abs/2507.12494)
*Dustin Holley,Jovin D'sa,Hossein Nourkhiz Mahjoub,Gibran Ali*

Main category: cs.AI

TL;DR: 本文提出了一种结合博弈论决策与动力学的统一模型，能更真实解释和模拟高速公路并道场景下的复杂人类驾驶行为，并已验证其在真实数据和大规模仿真中的有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 提高仿真环境对现实中驾驶员行为的还原能力，特别是在高速公路并道场景下，使仿真智能体更加接近人类驾驶行为，从而更好地支持自动驾驶技术的发展。

Method: 提出了一种结合改进收益函数和滞后动作的博弈论决策模型，并与底层动力学模型结合，形成统一的决策与动力学模型，对复杂并道互动进行建模和解释。

Result: 模型在真实世界数据集上验证了其对复杂交互的高度复现能力，并被集成至高精度仿真平台，计算效率也达到了大规模仿真需求。

Conclusion: 所提模型能在高速公路并道仿真中有效再现人类驾驶的复杂交互，且适用于支持自动驾驶研发的大规模仿真环境。

Abstract: Enhancing simulation environments to replicate real-world driver behavior,
i.e., more humanlike sim agents, is essential for developing autonomous vehicle
technology. In the context of highway merging, previous works have studied the
operational-level yielding dynamics of lag vehicles in response to a merging
car at highway on-ramps. Other works focusing on tactical decision modeling
generally consider limited action sets or utilize payoff functions with large
parameter sets and limited payoff bounds. In this work, we aim to improve the
simulation of the highway merge scenario by targeting a game theoretic model
for tactical decision-making with improved payoff functions and lag actions. We
couple this with an underlying dynamics model to have a unified decision and
dynamics model that can capture merging interactions and simulate more
realistic interactions in an explainable and interpretable fashion. The
proposed model demonstrated good reproducibility of complex interactions when
validated on a real-world dataset. The model was finally integrated into a high
fidelity simulation environment and confirmed to have adequate computation time
efficiency for use in large-scale simulations to support autonomous vehicle
development.

</details>


### [3] [A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs](https://arxiv.org/abs/2507.12599)
*Léo Saulières*

Main category: cs.AI

TL;DR: 本文提出了一个‘What-How’的分类法，对250多篇可解释性强化学习文献进行了综述，指出了该领域尚需关注的方向与需求。


<details>
  <summary>Details</summary>
Motivation: 近年来人工智能模型取得了巨大成功，但其内部机制变得越来越晦涩，尤其是深度神经网络的广泛应用，导致模型输出难以解释。为此，诞生了一系列可解释性人工智能（XAI）方法。本文聚焦于XAI的一个细分领域——可解释强化学习（XRL），目的是解释通过强化学习训练出来的智能体所做出的行为。

Method: 提出了一个基于“是什么”（What）和“如何做”（How）两个核心问题的直观分类法。基于该分类法，作者对250余篇相关文献进行了系统性综述，并探讨了与XRL密切相关但尚未引起足够重视的研究领域。

Result: 建立了一个基于‘What’和‘How’的分类标准，总结了可解释强化学习领域的研究进展，梳理了250多篇论文，发现并强调了与XRL紧密相关但发展不充分的领域，并总结了该领域未来的发展需求。

Conclusion: 通过提出的新分类法，对当前可解释强化学习领域的研究成果进行了梳理与评价，同时指出了该领域的若干需求和未来关注方向。

Abstract: The success of recent Artificial Intelligence (AI) models has been
accompanied by the opacity of their internal mechanisms, due notably to the use
of deep neural networks. In order to understand these internal mechanisms and
explain the output of these AI models, a set of methods have been proposed,
grouped under the domain of eXplainable AI (XAI). This paper focuses on a
sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims
to explain the actions of an agent that has learned by reinforcement learning.
We propose an intuitive taxonomy based on two questions "What" and "How". The
first question focuses on the target that the method explains, while the second
relates to the way the explanation is provided. We use this taxonomy to provide
a state-of-the-art review of over 250 papers. In addition, we present a set of
domains close to XRL, which we believe should get attention from the community.
Finally, we identify some needs for the field of XRL.

</details>


### [4] [Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models](https://arxiv.org/abs/2507.12666)
*Alex Zook,Josef Spjut,Jonathan Tremblay*

Main category: cs.AI

TL;DR: 本文提出通过强化学习和多模态大模型协作，实现以玩家行为为依据的自动化游戏设计迭代框架，并在实验中展示了此方法优化游戏机制的有效性和实用前景。


<details>
  <summary>Details</summary>
Motivation: 现有的基于代码或素材的自动生成系统，难以捕捉静态规则到玩家动态行为的转化，影响了游戏设计的自动化效率。

Method: 提出一个自动化游戏设计迭代框架，将强化学习（RL）代理作为自动游玩测试工具，与大型多模态模型（LMM）配对，由LMM根据RL代理的行为对游戏内容进行修改。每轮迭代中，RL代理生成数值游玩指标和/或视频帧摘要，由LMM分析与编辑游戏配置，引导行为朝目标靠近。

Result: 实验表明，LMM能基于RL生成的行为轨迹有效推理，并能迭代优化游戏机制，对实际AI辅助游戏设计工具的可行性和可扩展性起到积极作用。

Conclusion: 将RL代理与LMM结合，实现了行为驱动的自动化游戏机制优化，为AI辅助的游戏设计提供了高效可扩展的新方案。

Abstract: Game design hinges on understanding how static rules and content translate
into dynamic player behavior - something modern generative systems that inspect
only a game's code or assets struggle to capture. We present an automated
design iteration framework that closes this gap by pairing a reinforcement
learning (RL) agent, which playtests the game, with a large multimodal model
(LMM), which revises the game based on what the agent does. In each loop the RL
player completes several episodes, producing (i) numerical play metrics and/or
(ii) a compact image strip summarising recent video frames. The LMM designer
receives a gameplay goal and the current game configuration, analyses the play
traces, and edits the configuration to steer future behaviour toward the goal.
We demonstrate results that LMMs can reason over behavioral traces supplied by
RL agents to iteratively refine game mechanics, pointing toward practical,
scalable tools for AI-assisted game design.

</details>


### [5] [Benchmarking Deception Probes via Black-to-White Performance Boosts](https://arxiv.org/abs/2507.12691)
*Avi Parrack,Carlo Leonardo Attubato,Stefan Heimersheim*

Main category: cs.AI

TL;DR: 研究比较了AI助手欺骗检测中的白盒与黑盒监控，当前探针效果一般但显示出一定前景。


<details>
  <summary>Details</summary>
Motivation: AI助手有时会对用户查询做出欺骗性的回应，现有的“欺骗探针”能在多大程度上检测并区分模型内部的欺骗或诚实激活仍不明确，也不清楚这些探针能否抵抗具有规避意图的AI助手。

Method: 将白盒监控（可访问探针激活）与黑盒监控（不可访问激活）进行比较，通过“黑盒到白盒性能提升”来评测欺骗探针的有效性。

Result: 现有欺骗探针带来了微弱但令人鼓舞的黑盒到白盒性能提升。

Conclusion: 目前的欺骗探针在检测AI助手欺骗性行为上效果有限但有改进空间，白盒监控表现略优于黑盒监控。

Abstract: AI assistants will occasionally respond deceptively to user queries.
Recently, linear classifiers (called "deception probes") have been trained to
distinguish the internal activations of a language model during deceptive
versus honest responses. However, it's unclear how effective these probes are
at detecting deception in practice, nor whether such probes are resistant to
simple counter strategies from a deceptive assistant who wishes to evade
detection. In this paper, we compare white-box monitoring (where the monitor
has access to token-level probe activations) to black-box monitoring (without
such access). We benchmark deception probes by the extent to which the white
box monitor outperforms the black-box monitor, i.e. the black-to-white
performance boost. We find weak but encouraging black-to-white performance
boosts from existing deception probes.

</details>


### [6] [Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning](https://arxiv.org/abs/2507.12801)
*Sosui Moribe,Taketoshi Ushiama*

Main category: cs.AI

TL;DR: 本研究开发了一种AI学习伙伴，通过模拟同行水平和共性错误，探索提升英语写作同行学习效果的方法，以期解决现实同行学习中的受众匹配局限。


<details>
  <summary>Details</summary>
Motivation: 近年来，同行学习因能促进学习者自发思考而备受关注，但现实中人与人之间的同行学习存在水平匹配难等局限。该研究旨在开发可随时随地进行同行学习的AI学习伙伴。

Method: 假设和学习者处于相同水平的同伴会犯同样的错误，并以英语写作为例，验证该AI Agent的设计思路。

Result: 研究聚焦于AI学习伙伴在同行学习情境中的效果，特别是水平匹配及错误共性对学习效果的影响。

Conclusion: AI Agent有潜力克服人类同行学习中的限制，为学习者提供更有效的个性化学习支持，尤其是在同行水平匹配方面。

Abstract: In recent years, peer learning has gained attention as a method that promotes
spontaneous thinking among learners, and its effectiveness has been confirmed
by numerous studies. This study aims to develop an AI Agent as a learning
companion that enables peer learning anytime and anywhere. However, peer
learning between humans has various limitations, and it is not always
effective. Effective peer learning requires companions at the same proficiency
levels. In this study, we assume that a learner's peers with the same
proficiency level as the learner make the same mistakes as the learner does and
focus on English composition as a specific example to validate this approach.

</details>


### [7] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: 本文提出MCPEval开源评测框架，实现LLM智能体评测的自动化和标准化，可消除人工数据构建环节，在多个领域实验表现优秀，已对外开放。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体的评测方法受限于静态基准和高人工成本，缺乏可扩展、自动化的评测体系。

Method: 提出并实现了基于Model Context Protocol（MCP）的开放源代码评测框架MCPEval，支持端到端自动任务生成和多维度评测，并能无缝集成现有智能体工具。

Result: MCPEval在五个真实世界任务领域实验中展现出区分细粒度、领域相关性能的有效性。框架已开源，推动评测的标准化和可复现。

Conclusion: MCPEval框架能够有效自动化并标准化LLM智能体在不同领域的深度评测，为大规模、可复现、标准化的智能体评测提供了有力工具。

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [8] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 本文针对情感支持对话任务，提出结合提示工程与低秩适配或全参数微调的大语言模型方案，在NLPCC 2025比赛中取得第二名，显示该方法在情感支持任务中的强大潜力。


<details>
  <summary>Details</summary>
Motivation: 面对不断增长的心理健康支持需求，情感支持对话（ESC）旨在通过对话提供同理心和有效的情感协助。

Method: 该研究提出了一种结合提示工程和微调技术的大规模语言模型方案，探索了参数高效的低秩适配（LoRA）与全参数微调两种策略，以提升模型在情感支持任务中的表现。

Result: 所提出的最佳模型在NLPCC 2025 Task 8情感支持对话评测中获得第二名，证明了结合大语言模型与高效适配方法的有效性。

Conclusion: 本研究展示了大语言模型结合适配策略在情感支持对话任务中的潜力，并指出未来将进一步提升模型的情感理解和个性化回应能力，以构建更实用可靠的情感支持系统。

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [9] [Assessing adaptive world models in machines with novel games](https://arxiv.org/abs/2507.12821)
*Lance Ying,Katherine M. Collins,Prafull Sharma,Cedric Colas,Kaiya Ivy Zhao,Adrian Weller,Zenna Tavares,Phillip Isola,Samuel J. Gershman,Jacob D. Andreas,Thomas L. Griffiths,Francois Chollet,Kelsey R. Allen,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: 人类智能依靠高效的环境世界模型学习实现快速适应。本文借鉴认知科学经验，提出用持续创新的新颖游戏衡量AI系统世界模型归纳能力，为通用AI的评估和发展提供新框架和标准。


<details>
  <summary>Details</summary>
Motivation: 人类智能能够在新颖和不熟悉的情境中快速适应和高效解决问题，而这种能力与对环境内部表征（即“世界模型”）的高效构建和优化密切相关。然而，目前人工智能领域对世界模型的理解和评估过于狭窄，主要集中在基于大量数据语料学习的静态表示，而忽略了模型通过与新环境交互和探索高效学习这些表示的能力。

Method: 本文借鉴认知科学领域关于人类高效学习和适应的研究，提出了一种基于不断创新、结构多变的‘新颖游戏’套件作为基准的新评估框架，以此来挑战和评估AI系统的快速世界模型归纳能力。文章具体阐明了设计这些游戏的关键要求，并提出了相应的衡量指标。

Result: 提出并细化了一套用以评价人工智能系统中世界模型归纳和快速适应能力的全新评估框架，同时明确了构建新颖游戏及其度量标准的方法。

Conclusion: 该论文呼吁AI领域应重视并采用新的评估框架，通过持续新颖的游戏来系统性地评估和推动AI系统世界模型归纳、快速适应与泛化能力的提升，从而迈向类人通用智能。

Abstract: Human intelligence exhibits a remarkable capacity for rapid adaptation and
effective problem-solving in novel and unfamiliar contexts. We argue that this
profound adaptability is fundamentally linked to the efficient construction and
refinement of internal representations of the environment, commonly referred to
as world models, and we refer to this adaptation mechanism as world model
induction. However, current understanding and evaluation of world models in
artificial intelligence (AI) remains narrow, often focusing on static
representations learned from training on a massive corpora of data, instead of
the efficiency and efficacy of models in learning these representations through
interaction and exploration within a novel environment. In this Perspective, we
provide a view of world model induction drawing on decades of research in
cognitive science on how humans learn and adapt so efficiently; we then call
for a new evaluation framework for assessing adaptive world models in AI.
Concretely, we propose a new benchmarking paradigm based on suites of carefully
designed games with genuine, deep and continually refreshing novelty in the
underlying game structures -- we refer to this kind of games as novel games. We
detail key desiderata for constructing these games and propose appropriate
metrics to explicitly challenge and evaluate the agent's ability for rapid
world model induction. We hope that this new evaluation framework will inspire
future evaluation efforts on world models in AI and provide a crucial step
towards developing AI systems capable of the human-like rapid adaptation and
robust generalization -- a critical component of artificial general
intelligence.

</details>


### [10] [Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command](https://arxiv.org/abs/2507.12862)
*Hussein Abbass,Taylan Akay,Harrison Tolley*

Main category: cs.AI

TL;DR: 本文提出将伦理评价与模拟流程分离，借鉴多准则决策的熵权法，实现仿真中伦理指标的动态自动加权，提高了大规模仿真中的决策伦理评估效率。


<details>
  <summary>Details</summary>
Motivation: 在AI时代，人类指挥官需要利用现有计算能力模拟大量场景。每个场景中决策选项可能产生伦理后果，进而需要人工判断，但这既低效又难以实现大规模模拟，因此亟需减少人类判断在模拟过程中所占据的环节。

Method: 将“人类判断”移出模拟决策循环，由人类事先设计伦理度量空间，模拟环境自动在此空间内探索，最终只在关键选项上由人类决策。研究重点是仿真运行时如何动态加权各类伦理属性，即如何自动计算伦理指标的权重，借鉴多指标决策领域中有关“熵”方法的文献。

Result: 本文提出了一种在仿真测试与评估过程中自动确定伦理属性权重的方法，借鉴了多准则决策（MCDM）领域中基于“熵”的权重分配思路，实现了伦理属性在模拟环境下的动态加权。

Conclusion: 通过将人类判断移至仿真循环之外，并采用自动权重分配机制，可以在大规模情景模拟中高效且系统地对伦理敏感的决策选项进行评估，提升决策效率，减少人力负担。

Abstract: In the age of AI, human commanders need to use the computational powers
available in today's environment to simulate a very large number of scenarios.
Within each scenario, situations occur where different decision design options
could have ethical consequences. Making these decisions reliant on human
judgement is both counter-productive to the aim of exploring very large number
of scenarios in a timely manner and infeasible when considering the workload
needed to involve humans in each of these choices. In this paper, we move human
judgement outside the simulation decision cycle. Basically, the human will
design the ethical metric space, leaving it to the simulated environment to
explore the space. When the simulation completes its testing cycles, the
testing environment will come back to the human commander with a few options to
select from. The human commander will then exercise human-judgement to select
the most appropriate course of action, which will then get executed
accordingly. We assume that the problem of designing metrics that are
sufficiently granular to assess the ethical implications of decisions is
solved. Subsequently, the fundamental problem we look at in this paper is how
to weight ethical decisions during the running of these simulations; that is,
how to dynamically weight the ethical attributes when agents are faced with
decision options with ethical implications during generative simulations. The
multi-criteria decision making literature has started to look at nearby
problems, where the concept of entropy has been used to determine the weights
during aggregation. We draw from that literature different approaches to
automatically calculate the weights for ethical attributes during
simulation-based testing and evaluation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [11] [Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models](https://arxiv.org/abs/2507.12547)
*Lionel Wong,Katherine M. Collins,Lance Ying,Cedegao E. Zhang,Adrian Weller,Tobias Gersternberg,Timothy O'Donnell,Alexander K. Lew,Jacob D. Andreas,Joshua B. Tenenbaum,Tyler Brooke-Wilson*

Main category: cs.CL

TL;DR: 本文提出了一种结合语言模型和概率程序的模型合成架构（MSA），能够更好地模拟人类在新颖情境下的开放式推理，超越了仅依赖语言模型的方法。


<details>
  <summary>Details</summary>
Motivation: 人类在面对新颖情境时，能从丰富的背景知识中调取相关信息并加以推理，这一能力背后的认知机制尚不清楚。本文尝试解释人类如何高效整合广泛信息并进行连贯推理。

Method: 提出了“模型合成架构”（MSA），结合分布式和符号表示，通过语言模型实现全局相关性检索和模型合成，并利用概率程序生成定制的世界模型。设计了以“Model Olympics”为核心的推理数据集，通过测评人类类比推理能力，测试MSA性能。

Result: MSA在模拟人类判断方面优于仅依赖语言模型的基线，无论是在直接生成还是“思维链”生成任务上，均表现更好。

Conclusion: 模型合成架构可以有效地模仿人类在开放领域下，整合全局相关变量并进行局部连贯推理的能力，为理解和复制人类推理能力提供了新路径。

Abstract: When faced with novel situations, people are able to marshal relevant
considerations from a wide range of background knowledge and put these to use
in inferences and predictions. What permits us to draw in globally relevant
information and reason over it coherently? Here, we explore the hypothesis that
people use a combination of distributed and symbolic representations to
construct bespoke mental models tailored to novel situations. We propose a
computational implementation of this idea -- a ``Model Synthesis Architecture''
(MSA) -- using language models to implement global relevance-based retrieval
and model synthesis and probabilistic programs to implement bespoke, coherent
world models. We evaluate our MSA as a model of human judgments on a novel
reasoning dataset. The dataset -- built around a `Model Olympics` domain of
sports vignettes -- tests models' capacity for human-like, open-ended reasoning
by requiring (i) judgments about novel causal structures described in language;
(ii) drawing on large bodies of background knowledge; and (iii) doing both in
light of observations that introduce arbitrary novel variables. Our MSA
approach captures human judgments better than language model-only baselines,
under both direct and chain-of-thought generations from the LM that supports
model synthesis. These results suggest that MSAs can be implemented in a way
that mirrors people's ability to deliver locally coherent reasoning over
globally relevant variables, offering a path to understanding and replicating
human reasoning in open-ended domains.

</details>


### [12] [Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility](https://arxiv.org/abs/2507.12553)
*Michael A. Lepori,Jennifer Hu,Ishita Dasgupta,Roma Patel,Thomas Serre,Ellie Pavlick*

Main category: cs.CL

TL;DR: 本文通过机制可解释性技术，发现语言模型具备比此前认为更强的模态类别判别能力，并揭示了其演变、表征方式与人类模态分类行为的关系，对人机模态认知理解有重要启示。


<details>
  <summary>Details</summary>
Motivation: 近期有研究质疑语言模型（LMs）能够有效识别句子的模态类别（如可能、不可能、荒谬等）。本研究旨在探究现有LMs在模态判别方面的表现及其内部机制。

Method: 本文分析了各类语言模型中的激活模式，通过识别能区分模态类别的线性表征（即“模态差异向量”），并利用该表征与人类判别数据进行相关性分析，采用了机制可解释性技术，结合训练步骤、模型层数和参数量等因素进一步分析其演变过程。

Result: 研究发现，实际LMs对句子模态分类的能力优于此前报告。模态差异向量随着模型能力提升（训练进度、结构复杂度等）而以一致顺序出现。此外，这些向量投影值与人类受试者对可解释特征的评分呈良好相关。

Conclusion: 本研究揭示了语言模型在模态判别方面的潜力和内部机制，为理解和提升模型及人类的模态分类过程提供了新视角和工具。

Abstract: Language models (LMs) are used for a diverse range of tasks, from question
answering to writing fantastical stories. In order to reliably accomplish these
tasks, LMs must be able to discern the modal category of a sentence (i.e.,
whether it describes something that is possible, impossible, completely
nonsensical, etc.). However, recent studies have called into question the
ability of LMs to categorize sentences according to modality (Michaelov et al.,
2025; Kauf et al., 2023). In this work, we identify linear representations that
discriminate between modal categories within a variety of LMs, or modal
difference vectors. Analysis of modal difference vectors reveals that LMs have
access to more reliable modal categorization judgments than previously
reported. Furthermore, we find that modal difference vectors emerge in a
consistent order as models become more competent (i.e., through training steps,
layers, and parameter count). Notably, we find that modal difference vectors
identified within LM activations can be used to model fine-grained human
categorization behavior. This potentially provides a novel view into how human
participants distinguish between modal categories, which we explore by
correlating projections along modal difference vectors with human participants'
ratings of interpretable features. In summary, we derive new insights into LM
modal categorization using techniques from mechanistic interpretability, with
the potential to inform our understanding of modal categorization in humans.

</details>


### [13] [The first open machine translation system for the Chechen language](https://arxiv.org/abs/2507.12672)
*Abu-Viskhan A. Umishov,Vladislav A. Grigorian*

Main category: cs.CL

TL;DR: 首次实现了车臣语与俄语之间的开源机器翻译模型及数据集构建，取得了可用的翻译效果，并推动了低资源语言技术的发展。


<details>
  <summary>Details</summary>
Motivation: 车臣语是一种濒危语言，在现有的多语种翻译系统中鲜有支持。本研究旨在为车臣语与俄语之间的翻译建立第一个开源模型，并推动低资源语言的技术发展。

Method: 本研究收集并构建了用于车臣语和俄语互译的平行语料库，并基于NLLB-200大型多语种翻译系统，探索了通过微调将新语言纳入系统的技术路径。还发布了相应的多语种句子编码器并对其进行了车臣语适配。

Result: 俄语到车臣语的翻译模型BLEU分数为8.34，ChrF++分数为34.69；车臣语到俄语方向分别为20.89和44.55。相应语料和模型均已开源发布。

Conclusion: 本研究首次为车臣语与俄语之间的机器翻译提供了公开的技术基础和数据资源，为濒危语言的信息化保护和多语种自然语言处理研究提供了支持。

Abstract: We introduce the first open-source model for translation between the
vulnerable Chechen language and Russian, and the dataset collected to train and
evaluate it. We explore fine-tuning capabilities for including a new language
into a large language model system for multilingual translation NLLB-200. The
BLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for
translation from Russian to Chechen and reverse direction, respectively. The
release of the translation models is accompanied by the distribution of
parallel words, phrases and sentences corpora and multilingual sentence encoder
adapted to the Chechen language.

</details>


### [14] [Improving Drug Identification in Overdose Death Surveillance using Large Language Models](https://arxiv.org/abs/2507.12679)
*Arthur J. Funnell,Panayiotis Petousis,Fabrice Harel-Canada,Ruby Romero,Alex A. T. Bui,Adam Koncsol,Hritika Chaturvedi,Chelsea Shover,David Goodman-Meza*

Main category: cs.CL

TL;DR: 通过NLP方法，尤其是微调的临床BERT模型，可高度准确且高效地从验尸官文本报告中识别药物过量死亡，大大加速代码化和监测流程，比传统方法表现优异，有助于发现最新滥用趋势。


<details>
  <summary>Details</summary>
Motivation: 美国药物相关死亡率上升，主要由芬太尼驱动，亟需及时、准确的监测。然而，关键的药物过量死亡数据多隐藏在验尸官的自由文本报告中，导致通过ICD-10编码时出现延迟和信息丢失。现有人工处理方式效率低下，难以及时应对药物滥用趋势变化。NLP（自然语言处理）有望自动化并提升过量死亡监测效果，但目前应用有限。

Method: 收集了2020年美国多个地区的35,433份死亡记录用于模型训练与内部测试，外部验证采用了2023-2024年的3,335份全新记录。比较了多种NLP方法，包括传统的单标签和多标签分类器、微调的编码器（如BERT、BioClinicalBERT）和最新的解码器大语言模型（如Qwen 3和Llama 3）。主要通过macro F1分数评估模型性能，并计算了95%置信区间。

Result: 微调的BioClinicalBERT模型在内部测试集上表现接近完美，macro F1分数≥0.998。外部验证显示其鲁棒性（macro F1=0.966），显著优于传统机器学习、通用BERT模型以及各种解码器大语言模型。

Conclusion: 针对自由文本的死亡报告，NLP方法（尤其是临床领域微调模型BioClinicalBERT）可实现极高准确率和可扩展性，能显著提升药物过量死亡的监测效率，支持对新兴物质滥用趋势的近实时检测，超越手工ICD-10编码带来的滞后和信息损失。

Abstract: The rising rate of drug-related deaths in the United States, largely driven
by fentanyl, requires timely and accurate surveillance. However, critical
overdose data are often buried in free-text coroner reports, leading to delays
and information loss when coded into ICD (International Classification of
Disease)-10 classifications. Natural language processing (NLP) models may
automate and enhance overdose surveillance, but prior applications have been
limited. A dataset of 35,433 death records from multiple U.S. jurisdictions in
2020 was used for model training and internal testing. External validation was
conducted using a novel separate dataset of 3,335 records from 2023-2024.
Multiple NLP approaches were evaluated for classifying specific drug
involvement from unstructured death certificate text. These included
traditional single- and multi-label classifiers, as well as fine-tuned
encoder-only language models such as Bidirectional Encoder Representations from
Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large
language models such as Qwen 3 and Llama 3. Model performance was assessed
using macro-averaged F1 scores, and 95% confidence intervals were calculated to
quantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect
performance, with macro F1 scores >=0.998 on the internal test set. External
validation confirmed robustness (macro F1=0.966), outperforming conventional
machine learning, general-domain BERT models, and various decoder-only large
language models. NLP models, particularly fine-tuned clinical variants like
BioClinicalBERT, offer a highly accurate and scalable solution for overdose
death classification from free-text reports. These methods can significantly
accelerate surveillance workflows, overcoming the limitations of manual ICD-10
coding and supporting near real-time detection of emerging substance use
trends.

</details>


### [15] [AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.12695)
*S M Rafiuddin,Sadia Kamal,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen*

Main category: cs.CL

TL;DR: 本文提出了AdaptiSent多模态情感分析框架，通过自适应注意力机制融合文本和图像信息，显著提升了情感和方面识别准确率，成为MABSA领域的新标杆。


<details>
  <summary>Details</summary>
Motivation: 当前多模态面向方面情感分析（MABSA）在融合文本与图像信息上存在不足，难以充分捕捉文本与视觉之间的细粒度交互，限制了情感和方面分类的精度。因此，作者希望通过改进跨模态建模机制，提升情感分析和方面术语抽取表现。

Method: 作者提出了名为AdaptiSent的新框架，通过自适应跨模态注意力机制，动态权重融合文本与图像信息，实现基于上下文的注意力分配。该模型能够根据当前情境的相关性调整关注重点，更有效地整合两种模态的信息。

Result: 在多个标准Twitter数据集上的实验显示，AdaptiSent在精准率、召回率和F1分数上明显优于传统文本模型及其他多模态方法，尤其擅长发现文本和视觉间的复杂关系，实现更准确的情感和方面抽取。

Conclusion: AdaptiSent设定了多模态面向方面情感分析的新标准，特别擅长理解复杂的多模态信息，在多项指标上大幅超越了现有方法。

Abstract: We introduce AdaptiSent, a new framework for Multimodal Aspect-Based
Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms
to improve sentiment classification and aspect term extraction from both text
and images. Our model integrates dynamic modality weighting and
context-adaptive attention, enhancing the extraction of sentiment and
aspect-related information by focusing on how textual cues and visual context
interact. We tested our approach against several baselines, including
traditional text-based models and other multimodal methods. Results from
standard Twitter datasets show that AdaptiSent surpasses existing models in
precision, recall, and F1 score, and is particularly effective in identifying
nuanced inter-modal relationships that are crucial for accurate sentiment and
aspect term extraction. This effectiveness comes from the model's ability to
adjust its focus dynamically based on the context's relevance, improving the
depth and accuracy of sentiment analysis across various multimodal data sets.
AdaptiSent sets a new standard for MABSA, significantly outperforming current
methods, especially in understanding complex multimodal information.

</details>


### [16] [AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation](https://arxiv.org/abs/2507.12705)
*Potsawee Manakul,Woody Haosheng Gan,Michael J. Ryan,Ali Sartaz Khan,Warit Sirichotedumrong,Kunat Pipatanakul,William Held,Diyi Yang*

Main category: cs.CL

TL;DR: 本文提出利用大型音频模型AudioJudge统一进行语音多特征和人类偏好自动化评估，取得与人工高度一致的结果（Spearman相关达到0.91），但存在输出冗余和偏置等问题需改进。


<details>
  <summary>Details</summary>
Motivation: 当前的语音评估存在两个主要问题：一是需要针对不同音频特征设计专门的系统，过程复杂；二是自动化评估方法与人类主观偏好的一致性较差。

Method: 该论文提出利用大型音频模型（LAM）AudioJudge作为统一评判工具，系统性地在发音、语速、说话人识别、语音质量等音频特征检测以及自动化模拟人类偏好的任务中进行评估。通过不同的提示词工程（prompt engineering）策略，发现音频串联与上下文学习结合可以显著提升模型在音频特征检测和人类偏好模拟任务上的表现。同时，提出多方面集成AudioJudge，将语音评估分为词汇内容、语音质量和副语言特征三个评判子系统。

Result: 多方面集成AudioJudge在系统排名基准上，与人类偏好的Spearman相关系数最高达到0.91。鲁棒性分析显示，LAM在有噪声的条件下依然表现良好，但存在输出冗长及位置偏置问题，有待进一步优化。

Conclusion: AudioJudge能够作为统一评估框架，解决语音评估场景中的多特征检测与主观偏好一致性问题，并在多方面实现高与人类一致的自动评估，但仍需针对其冗余性和位置偏置加以改进。

Abstract: Current speech evaluation suffers from two critical limitations: the need and
difficulty of designing specialized systems targeting individual audio
characteristics, and poor correlation between automatic evaluation methods and
human preferences. This work presents a systematic study of Large Audio Model
(LAM) as a Judge, AudioJudge, investigating whether it can provide a unified
evaluation framework that addresses both challenges. We systematically explore
AudioJudge across audio characteristic detection tasks, including
pronunciation, speaking rate, speaker identification and speech quality, and
system-level human preference simulation for automated benchmarking. We
investigate different prompt engineering strategies, finding that audio
concatenation combined with in-context learning significantly improves
performance across both audio characteristic detection and human preference
simulation tasks. We further introduce a multi-aspect ensemble AudioJudge to
enable general-purpose multi-aspect audio evaluation. This method decomposes
speech assessment into specialized judges for lexical content, speech quality,
and paralinguistic features, achieving up to 0.91 Spearman correlation with
human preferences on our system ranking benchmark. Robustness analysis reveals
that while LAMs maintain strong performance under acoustic noise, they exhibit
significant verbosity and positional biases that require careful mitigation.

</details>


### [17] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
*Abraham Toluase Owodunni,Orevaoghene Ahia,Sachin Kumar*

Main category: cs.CL

TL;DR: 本文提出了FLEXITOKENS，一种可学习、灵活的分词机制，有效减少分词碎片化，并在多项任务上显著提升了下游性能。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型（LMs）在通过简单微调适应新数据分布时面临挑战，主要原因是其子词分词器的僵化，难以调整以适应新的语言、脚本或领域，会导致分词碎片化、效率低下。

Method: 提出了一种基于字节的语言模型，并引入可学习分词器模块，使模型能够自适应地进行分词。该方法通过预测字节序列中的边界，将输入编码为变长片段。不同于现有通过强制固定压缩率训练分词边界的方法，作者提出了FLEXITOKENS，一种简化的训练目标，提高了模型对新领域的适应性。

Result: 在多个多语言基准、形态多样任务和不同领域中评估，FLEXITOKENS有助于减少分词碎片化现象，并在下游任务表现上比子词及其它基于梯度的分词方法提升了最高10%的性能。

Conclusion: 可学习、自适应分词机制能显著提升语言模型在不同时域、语言和领域的泛化能力和实际表现，有效克服传统分词器的僵化问题。

Abstract: Language models (LMs) are challenging to adapt to new data distributions by
simple finetuning. This is due to the rigidity of their subword tokenizers,
which typically remain unchanged during adaptation. This inflexibility often
leads to inefficient tokenization, causing overfragmentation of
out-of-distribution domains, unseen languages, or scripts. In this work, we
develop byte-level LMs with learnable tokenizers to make tokenization adaptive.
Our models include a submodule that learns to predict boundaries between the
input byte sequence, encoding it into variable-length segments. Existing
tokenizer-free methods train this boundary predictor using an auxiliary loss
that enforces a fixed compression rate across the training corpus, introducing
a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective
that enables significantly greater flexibility during adaptation. Evaluating
across multiple multilingual benchmarks, morphologically diverse tasks, and
domains, we demonstrate that FLEXITOKENS consistently reduces token
over-fragmentation and achieves up to 10\% improvements on downstream task
performance compared to subword and other gradient-based tokenizers. Code and
data for our experiments will be released at
https://github.com/owos/flexitokens

</details>


### [18] [TransEvalnia: Reasoning-based Evaluation and Ranking of Translations](https://arxiv.org/abs/2507.12724)
*Richard Sproat,Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: TransEvalnia是一个基于prompt和LLM推理的机器翻译评价系统，在细粒度打分、与人工一致性和部分语言对实验上表现出色，且公开所有资源，推动了自动翻译评价的进步。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译评估系统在多维度、细粒度评分和与人类评价一致性等方面仍有一定局限。本研究旨在开发一种更精细、可解释，且与人工评价相关性高的自动化评价系统。

Method: 采用基于prompt的大型语言模型（如Claude-3.5-Sonnet和Qwen-2.5-72B-Instruct）进行推理式翻译质量评分，依据MQM的多个维度输出细粒度分数与最终评价。还提出处理评分顺序偏置的方法。

Result: TransEvalnia在英日等多个语对的实验中，评价表现与或优于最先进系统MT-Ranker，且自动评价分数与人工评分高度相关；发现评分顺序对评价有影响，并提出对应解决方案。系统相关资源均已开源。

Conclusion: TransEvalnia系统能够在机器翻译质量评价和排序方面与当前最先进的方法相媲美，甚至更佳，并且其结果与人工评价高度一致。系统和实验数据、代码均已公开。

Abstract: We present TransEvalnia, a prompting-based translation evaluation and ranking
system that uses reasoning in performing its evaluations and ranking. This
system presents fine-grained evaluations based on a subset of the
Multidimensional Quality Metrics (https://themqm.org/), returns an assessment
of which translation it deems the best, and provides numerical scores for the
various dimensions and for the overall translation. We show that TransEvalnia
performs as well as or better than the state-of-the-art MT-Ranker (Moosa et al.
2024) on our own English-Japanese data as well as several language pairs from
various WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and
Qwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations
returned are deemed highly acceptable to human raters, and that the scores
assigned to the translations by Sonnet, as well as other LLMs, correlate well
with scores assigned by the human raters. We also note the sensitivity of our
system -- as well as MT-Ranker -- to the order in which the translations are
presented, and we propose methods to address this position bias. All data,
including the system's evaluation and reasoning, human assessments, as well as
code is released.

</details>


### [19] [Strategy Adaptation in Large Language Model Werewolf Agents](https://arxiv.org/abs/2507.12732)
*Fuya Nakamori,Yin Jou Huang,Fei Cheng*

Main category: cs.CL

TL;DR: 本文提出通过对话上下文和玩家态度动态切换预定义策略，有效提升了人狼游戏AI对复杂场景的应对能力，并通过实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 以往人狼游戏AI通过提示工程实现策略，存在策略隐性定义、难以应对变化的问题。作者希望提升人狼AI针对不同对局情境的自适应能力。

Method: 提出一种基于上下文和他人态度动态切换预定义策略的方法，显式根据游戏上下文及其他玩家角色估计选择最优策略。

Result: 与采用隐式或固定策略的基线AI对比，验证了策略自适应AI效果更优。

Conclusion: 显式策略切换能提升人狼游戏AI对变化场景的适应力和整体表现。

Abstract: This study proposes a method to improve the performance of Werewolf agents by
switching between predefined strategies based on the attitudes of other players
and the context of conversations. While prior works of Werewolf agents using
prompt engineering have employed methods where effective strategies are
implicitly defined, they cannot adapt to changing situations. In this research,
we propose a method that explicitly selects an appropriate strategy based on
the game context and the estimated roles of other players. We compare the
strategy adaptation Werewolf agents with baseline agents using implicit or
fixed strategies and verify the effectiveness of our proposed method.

</details>


### [20] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2507.12759)
*Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang*

Main category: cs.CL

TL;DR: 作者提出ThinkLogit及其优化版，利用小模型推理指导，无需或极少额外训练显著提升大模型长链推理性能，节省算力且效果出色。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRM）在长链思维（CoT）下能进行复杂推理，但如何高效激发其内在的长推理能力尚不清楚。现有方法多数依赖额外训练，消耗大量算力。作者希望探索能否以更低成本（甚或无需训练）激发大模型的长推理能力。

Method: 提出ThinkLogit，一种推理时（decoding-time）方法，利用logits算术微调用目标大模型，由一个小得多的“引导者”模型指引；进一步提出ThinkLogit-DPO，通过对正确/错误推理样本进行偏好优化训练引导者模型；实验在数学数据集上用Qwen2.5-32B和R1-Distill-Qwen-1.5B进行验证。

Result: ThinkLogit和ThinkLogit-DPO在4个数学数据集的pass@1指标上分别提高26%和29%，用R1-Distill-Qwen-1.5B（21倍小的引导者）指导Qwen2.5-32B；ThinkLogit还能迁移通过强化学习获得的长推理技能，较基础模型提升13%。

Conclusion: 提出无需或极少训练即可激发大模型长链推理能力的方法，大幅提升性能且计算资源需求低。方法简单高效，适合大模型推理能力快速增强。

Abstract: Large reasoning models (LRMs) can do complex reasoning via long
chain-of-thought (CoT) involving cognitive strategies such as backtracking and
self-correction. Recent studies suggest that some models inherently possess
these long reasoning abilities, which may be unlocked via extra training. Our
work first investigates whether we can elicit such behavior without any
training. To this end, we propose a decoding-time approach, ThinkLogit, which
utilizes logits arithmetic (Liu et al., 2024) to tune a target large LM for
long reasoning using a substantially smaller model as guider. We then show that
we can further boost performance by training the guider model with preference
optimization over correct/incorrect reasoning pairs sampled from both the
target and guider model -- a setup we refer to as ThinkLogit-DPO. Our
experiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative
improvement in pass@1 by 26% and 29%, respectively, over four mathematical
datasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model
21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skills
acquired through reinforcement learning, improving pass@1 by 13% relative
compared to the Qwen2.5-32B base model. Our work presents a
computationally-efficient method to elicit long reasoning in large models with
minimal or no additional training.

</details>


### [21] [Synergy: End-to-end Concept Model](https://arxiv.org/abs/2507.12769)
*Keli Zheng,Zerong Xie*

Main category: cs.CL

TL;DR: Synergy提出了一种无需分词器、端到端学习的字节级语言模型，通过自学习分词获得比BBPE更少的token且性能不降，部分模块还表现出位置无关的建模能力，展示了无分词器NLP架构的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型通常依赖于固定的分词器进行文本处理，这可能限制模型对低层次语言抽象的捕捉能力，并影响其在不同任务中的泛化和灵活性。如何设计一种能够自主学习分词的端到端语言模型，是提升模型适应性和表现的一个重要方向。

Method: 提出了一种名为Synergy的语言模型，采用端到端的方法，通过学习到的路由机制桥接不同抽象层次。模型以字节为基础进行训练，实现了无分词器（tokenizer-free）的处理流程，并与传统的BBPE分词器和Llama3模型进行了对比实验。

Result: Synergy能自动学习有效的分词方式，其生成的概念token数量少于BBPE分词器，在模型规模和训练数据集相同的情况下性能持平甚至优于Llama3。此外，进一步实验表明，模型中较高抽象层的部分在移除位置编码后表现更好，显示了位置无关概念的自发涌现。

Conclusion: Synergy模型验证了去分词器化架构（tokenizer-free architecture）的可行性，为构建更健壮、更灵活的自然语言处理流程提供了新可能。

Abstract: In this paper, we present Synergy, a language model that bridges different
levels of abstraction in an end-to-end fashion through a learned routing
mechanism. Focusing on low-level linguistic abstraction, we trained our model
as a byte-level language model. Our model spontaneously learns to tokenize
bytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE)
tokenizers while keeping comparable performance. By comparing with Llama3, we
observed an advantage of Synergy under the same model scale and training
dataset size. Further studies show that the middle part (the higher abstraction
part) of our model performs better when positional encodings are removed,
suggesting the emergence of position-independent concepts. These findings
demonstrate the feasibility of tokenizer-free architectures, paving the way for
more robust and flexible pipelines.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [22] [Vector-level Feedforward Control of LPBF Melt Pool Area Using a Physics-Based Thermal Model](https://arxiv.org/abs/2507.12557)
*Nicholas Kirschbaum,Nathaniel Wood,Chang-Eun Kim,Thejaswi U. Tumkur,Chinedum Okwudire*

Main category: cs.CE

TL;DR: 本文提出了一种高效的数据驱动前馈控制方法，通过耦合热模型和熔池模型，实现了对LPBF过程中熔池面积的精准调节，大幅提升了零件的几何精度和致密度，具备良好的扩展性和实用性。


<details>
  <summary>Details</summary>
Motivation: 激光选区熔化（LPBF）技术能够制造复杂且高密度的金属零件，但容易出现内部缺陷和几何偏差，主要原因之一是熔池的变化性。如何有效控制熔池区域，提升制件质量，是该领域亟需解决的问题。

Method: 提出了一种新颖的矢量级前馈控制框架以调节LPBF中的熔池面积。该方法采用两个耦合的轻量级模型：有限差分热模型用于捕捉矢量级温度场，以及一个降阶解析熔池模型。这两个模型分别通过少量单道与二维实验进行校准，并在复杂三维几何体上进行了验证。

Result: 采用该前馈矢量级激光功率调度后，关键尺寸的几何不准确性降低了62%，整体孔隙率降低了16.5%，光电二极管检测信号的波动平均降低了6.8%。

Conclusion: 该方法通过有效预测和优化熔池行为，显著提升了零件质量，同时具有良好的计算效率和通用性，易于扩展到不同材料和设备。

Abstract: Laser powder bed fusion (LPBF) is an additive manufacturing technique that
has gained popularity thanks to its ability to produce geometrically complex,
fully dense metal parts. However, these parts are prone to internal defects and
geometric inaccuracies, stemming in part from variations in the melt pool. This
paper proposes a novel vector-level feedforward control framework for
regulating melt pool area in LPBF. By decoupling part-scale thermal behavior
from small-scale melt pool physics, the controller provides a scale-agnostic
prediction of melt pool area and efficient optimization over it. This is done
by operating on two coupled lightweight models: a finite-difference thermal
model that efficiently captures vector-level temperature fields and a
reduced-order, analytical melt pool model. Each model is calibrated separately
with minimal single-track and 2D experiments, and the framework is validated on
a complex 3D geometry in both Inconel 718 and 316L stainless steel. Results
showed that feedforward vector-level laser power scheduling reduced geometric
inaccuracy in key dimensions by 62%, overall porosity by 16.5%, and photodiode
variation by 6.8% on average. Overall, this modular, data-efficient approach
demonstrates that proactively compensating for known thermal effects can
significantly improve part quality while remaining computationally efficient
and readily extensible to other materials and machines.

</details>


### [23] [IDS-Net: A novel framework for few-shot photovoltaic power prediction with interpretable dynamic selection and feature information fusion](https://arxiv.org/abs/2507.12745)
*Hang Fan,Weican Liu,Zuhan Zhang,Ying Lu,Wencai Run,Dunnan Liu*

Main category: cs.CE

TL;DR: 本文提出了一种创新的迁移学习与特征融合方法IDS-Net，用于解决新建光伏电站数据稀缺下的电力预测难题，并通过实际数据验证了其优越效果和适应性。


<details>
  <summary>Details</summary>
Motivation: 由于新建光伏（PV）电站数据有限，导致电力预测具有很大挑战，而可再生能源的需求显著增长，因此需要提出高效的数据少量预测方法。

Method: 提出了一种基于特征信息融合的可解释动态选择网络（IDS-Net），结合迁移学习，包括（1）预训练和数据集相似性选择，特征选择与异常值校正；（2）IDS-Net多模型特征提取与加权，特征融合，并通过MLP预测；（3）端到端自适应迁移学习策略，最终完成对目标数据集的预测。

Result: 使用河北省两个光伏电力数据集进行实验，验证了该框架和迁移学习策略的有效性和泛化能力。

Conclusion: 提出的方法能实现对新建光伏电站的小样本高精度预测，有很好的迁移泛化能力。

Abstract: With the growing demand for renewable energy, countries are accelerating the
construction of photovoltaic (PV) power stations. However, accurately
forecasting power data for newly constructed PV stations is extremely
challenging due to limited data availability. To this end, we propose a novel
interpretable dynamic selection network (IDS-Net) based on feature information
fusion to achieve accurate few-shot prediction. This transfer learning
framework primarily consists of two parts. In the first stage, we pre-train on
the large dataset, utilizing Maximum Mean Discrepancy (MMD) to select the
source domain dataset most similar to the target domain data distribution.
Subsequently, the ReliefF algorithm is utilized for feature selection, reducing
the influence of feature redundancy. Then, the Hampel Identifier (HI) is used
for training dataset outlier correction. In the IDS-Net model, we first obtain
the initial extracted features from a pool of predictive models. Following
this, two separate weighting channels are utilized to determine the
interpretable weights for each sub-model and the adaptive selection outcomes,
respectively. Subsequently, the extracted feature results from each sub-model
are multiplied by their corresponding weights and then summed to obtain the
weighted extracted features. Then, we perform cross-embedding on the additional
features and fuse them with the extracted weighted features. This fused
information is then passed through the MLP (Multi-Layer Perceptron) layer to
obtain predictions. In the second stage, we design an end-to-end adaptive
transfer learning strategy to obtain the final prediction results on the target
dataset. We validate the transfer learning process using two PV power datasets
from Hebei province, China, to demonstrate the effectiveness and generalization
of our framework and transfer learning strategy.

</details>


### [24] [Quantum-Enhanced Reinforcement Learning with LSTM Forecasting Signals for Optimizing Fintech Trading Decisions](https://arxiv.org/abs/2507.12835)
*Yen-Ku Liu,Yun-Huei Pan,Pei-Fan Lu,Yun-Cheng Tsai,Samuel Yen-Chi Chen*

Main category: cs.CE

TL;DR: 该研究提出并测试了结合量子电路和LSTM信号的强化学习交易系统，结果显示，相较传统方法，量子模型在不稳定的金融环境中表现更好且更稳定。


<details>
  <summary>Details</summary>
Motivation: 由于金融交易环境高度波动、复杂且市场状态不断变化，传统强化学习方法在这一场景下表现有限，因此动力来源于探索量子强化学习是否能够带来突破性改进。

Method: 提出了一个结合量子电路的强化学习框架，并比较了经典A3C和量子A3C算法的效果，还考察了引入LSTM预测经济趋势信号对学习表现的影响。采用自定义的、兼容Gymnasium的交易环境进行实验，模拟离散交易行为并以投资组合反馈为奖励。

Result: 量子A3C算法，尤其是在结合LSTM预测信号的情况下，对比经典A3C表现出更优的交易策略和更强的稳定性。

Conclusion: 量子模型，特别是结合LSTM经济趋势预测信号时，在嘈杂金融环境下展现出优越的性能和稳定性，即便量子电路层次较浅。

Abstract: Financial trading environments are characterized by high volatility, numerous
macroeconomic signals, and dynamically shifting market regimes, where
traditional reinforcement learning methods often fail to deliver breakthrough
performance. In this study, we design a reinforcement learning framework
tailored for financial systems by integrating quantum circuits. We compare (1)
the performance of classical A3C versus quantum A3C algorithms, and (2) the
impact of incorporating LSTM-based predictions of the following week's economic
trends on learning outcomes. The experimental framework adopts a custom
Gymnasium-compatible trading environment, simulating discrete trading actions
and evaluating rewards based on portfolio feedback. Experimental results show
that quantum models - especially when combined with predictive signals -
demonstrate superior performance and stability under noisy financial
conditions, even with shallow quantum circuit depth.

</details>


### [25] [Agentar-DeepFinance-300K: A Large-Scale Financial Dataset via Systematic Chain-of-Thought Synthesis Optimization](https://arxiv.org/abs/2507.12901)
*Xiaoke Zhao,Zhaowen Zhou,Lin Chen,Lihong Wang,Zhiyi Huang,Kaiyuan Zheng,Yanjun Zheng,Xiyang Du,Longfei Liao,Jiawei Liu,Xiang Qi,Bo Zhang,Peng Zhang,Zhe Li,Wei Wang*

Main category: cs.CE

TL;DR: 本文通过系统化的CoT合成策略，构建了大型金融推理数据集Agentar-DeepFinance-300K，并显著提升了模型的金融推理能力。


<details>
  <summary>Details</summary>
Motivation: 金融领域需要强大的推理能力，但现有的大语言模型（LLMs）在金融推理方面的链式思考（CoT）采样较浅，缺乏构建系统性金融推理知识空间的方法。

Method: 提出了Agentar-DeepFinance-300K数据集，并设计了系统化的CoT合成优化流程：包括多视角知识提取（MKE）和自我纠正重写（SCR）以生成更深层次、更全面的金融推理路径。还通过CoT Cube系统分析影响CoT有效性的关键因素，如必要性、长度和合成器。

Result: 实验证明，在Agentar-DeepFinance-300K数据集上训练的模型，在多个金融基准任务上取得了显著提升。

Conclusion: 该工作提出了一个高质量的大规模金融推理数据集及其系统的链式思考合成方法，为进一步推动金融推理模型的研究提供了新工具。数据集已公开发布。

Abstract: Recent advancements in large language models (LLMs) have demonstrated
remarkable general reasoning capabilities, holding significant potential for
applications in the financial domain, a field that requires robust and reliable
reasoning. It has been demonstrated that distilling high-quality
chain-of-thought (CoT) rationales from advanced general reasoning models offers
a promising and efficient path to the financial reasoning model. However,
existing CoT synthesis methods suffer from shallow CoT sampling, leaving the
question of how to construct a well-designed knowledge space for finance
reasoning unexplored. In this paper, we present
\textbf{Agentar-DeepFinance-300K }, a large-scale financial reasoning dataset
characterized by its systematic CoT synthesis optimization. We first introduce
a comprehensive CoT synthesis pipeline featuring Multi-perspective Knowledge
Extraction (MKE) and Self-Corrective Rewriting (SCR) to generate exhaustive and
deep financial reasoning trajectories. Furthermore, a systematic investigation,
termed CoT Cube, is conducted to analyze critical factors that influence CoT
effectiveness, such as necessity, length and synthesizer, yielding valuable
insights for high-quality financial CoT construction. Experiments demonstrate
that models trained on our Agentar-DeepFinance-300K achieve significant
improvements on financial benchmarks. We publicly release
Agentar-DeepFinance-300K , hoping to advance the research in financial
reasoning models.

</details>


### [26] [To What Extent Can Public Equity Indices Statistically Hedge Real Purchasing Power Loss in Compounded Structural Emerging-Market Crises? An Explainable ML-Based Assessment](https://arxiv.org/abs/2507.13055)
*Artem Alkhamov,Boris Kriuk*

Main category: cs.CE

TL;DR: 新兴市场重大金融与货币危机时，股票市场无法有效保值，传统的通胀和贬值对冲观点值得重新审视。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于评估新兴市场重大宏观金融危机期间，本地股票指数在对抗实际购买力损失方面的有效性。当前市场普遍认为股票是抵御通胀和货币贬值的工具，但实际在危机期间是否成立尚不明朗。

Method: 本文采用非线性乘法实际收益计算（一致于费雪均衡理论），并结合分位数回归、尾部相关Copula分析和SHAP（Shapley加法解释法）来评估宏观变量的解释力。选取2018年土耳其、2020年尼日利亚和2021年巴基斯坦三次数据可得的危机事件作为样本。

Result: 尾部聚焦的建模显示，在宏观经济与货币双重危机并发时，本地股市的购买力保护功能系统性失效，恰好在最需要保护的时候。

Conclusion: 研究结果质疑了传统股票对抗通胀和贬值的假设，强调了股票保护的局限性，并呼吁在复合型宏观金融危机期间采用更具情境感知的投资策略。

Abstract: This study investigates the extent to which local public equity indices can
statistically hedge real purchasing power loss during compounded structural
macro-financial collapses in emerging markets. We employ a non-linear
multiplicative real return calculations consistent with Fisher-parity logics
for both domestic and foreign investors with a principled quantile regression,
tail dependence copula analysis, and Shapley Additive Explanations (SHAP) to
assess the explanatory power of macro variables. The analysis focuses on three
recent and data-accessible exemplary collapse episodes: Turkey (2018), Nigeria
(2020), and Pakistan (2021). Such cases, selected to align with post-2018
improvements in data standardization and crisis comparability, span varied
monetary regimes and crisis triggers. Our tail-focused modeling reveals a
systematic breakdown in public-equity-based purchasing power protection
precisely during simultaneous macroeconomic and monetary dislocations when such
protection is most needed. The findings call into question conventional
inflation and devaluation hedge presumptions in equity pricing theory,
emphasizing the limitations of equity-based protection and the need for
context-sensitive strategies during compounded macro-financial distress.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [27] [Rookie Mistakes: Measuring Software Quality in Student Projects to Guide Educational Enhancement](https://arxiv.org/abs/2507.12488)
*Marco De Luca,Sergio Di Martino,Sergio Di Meglio,Anna Rita Fasolino,Luigi Libero Lucio Starace,Porfirio Tramontana*

Main category: cs.CY

TL;DR: 本研究分析了172名大学生83个团队面向对象项目的质量，借助静态分析工具揭示了中级学生在复杂项目中常见的软件质量问题，为改进软件工程教学提供了依据。


<details>
  <summary>Details</summary>
Motivation: 当前计算机本科教育在编程和软件工程课程中，往往更强调软件项目的实现功能，忽视了软件质量的培养，且大多数相关研究仅关注初学者代码与小型项目，缺乏对中级学生及较复杂项目的软件质量研究。因此，教育者在有限教学时间内无法获得充分文献指导，难以合理权衡软件质量教学重点。

Method: 本文收集并分析了4届面向对象编程课程中172名大学生组成团队开发的83个面向对象项目，利用SonarQube和ArchUnit组成的静态分析流程检测代码异味和架构反模式，对项目软件质量进行系统评估。

Result: 分析结果发现，中级编程学生在开发复杂项目时仍反复出现一些典型的软件质量问题。研究揭示了他们在当前课程阶段面临的具体主要挑战。

Conclusion: 研究为高校教师提供了具体数据和见解，有助于优化软件工程课程设置，特别是如何更好地培养学生的软件质量意识和实践。

Abstract: When teaching Programming and Software Engineering in Bachelor's Degree
programs, the emphasis on creating functional software projects often
overshadows the focus on software quality, a trend that aligns with ACM
curricula recommendations. Software Engineering courses are typically
introduced later in the curriculum, and can generally allocate only limited
time to quality-related topics, leaving educators with the challenge of
deciding which quality aspects to prioritize. In this decision, the literature
offers limited guidance, as most existing studies focus on code written by
novice students and small code units, making it unclear whether those findings
extend to intermediate-level students with foundational object-oriented
programming skills working on more complex software projects. To address this
gap, we analyze 83 object-oriented team projects developed by 172 university
students across 4 different editions of the Object-Oriented Programming course.
We apply a static analysis pipeline used in prior research to assess software
quality, combining SonarQube and ArchUnit to detect code smells and
architectural anti-patterns. Our findings highlight recurring quality issues
and offer concrete evidence of the challenges students face at this stage,
providing valuable guidance for educators aiming to continuously improve
Software Engineering curricula and promote quality-oriented development
practices.

</details>


### [28] [Catching Dark Signals in Algorithms: Unveiling Audiovisual and Thematic Markers of Unsafe Content Recommended for Children and Teenagers](https://arxiv.org/abs/2507.12571)
*Haoning Xue,Brian Nishimine,Martin Hilbert,Drew Cingel,Samantha Vigil,Jane Shawcroft,Arti Thakur,Zubair Shafiq,Jingwen Zhang*

Main category: cs.CY

TL;DR: 该文通过对推荐给青少年的短视频内容分析，发现许多视频存在直接或间接的心理危害，提出了线上危害框架，强调需加强内容管理与平台监管以保护未成年用户。


<details>
  <summary>Details</summary>
Motivation: 随着短视频平台的流行以及年龄验证机制的低效，儿童和青少年面临算法推荐环境中潜在危害的担忧日益增加。

Method: 研究者对Instagram Reels、TikTok、YouTube Shorts三大平台上被推荐给儿童和青少年的4,492个短视频进行了多模态特征分析和主题内容建模，并作为算法审计实验的一部分。

Result: 分析显示，不安全（问题性或心理困扰）短视频通常具有更暗的视觉特征，且内容包含显性有害信息及隐性由普通内容引发焦虑的危害。研究还提出了“显性、隐性、非预期”三类线上危害框架。

Conclusion: 结果突显了保护儿童和青少年发展关键阶段的观众免受社交媒体上的显性与隐性危害的必要性，并呼吁对内容审核、年龄验证和平台监管做出改进。

Abstract: The prevalence of short form video platforms, combined with the
ineffectiveness of age verification mechanisms, raises concerns about the
potential harms facing children and teenagers in an algorithm-moderated online
environment. We conducted multimodal feature analysis and thematic topic
modeling of 4,492 short videos recommended to children and teenagers on
Instagram Reels, TikTok, and YouTube Shorts, collected as a part of an
algorithm auditing experiment. This feature-level and content-level analysis
revealed that unsafe (i.e., problematic, mentally distressing) short videos (a)
possess darker visual features and (b) contain explicitly harmful content and
implicit harm from anxiety-inducing ordinary content. We introduce a useful
framework of online harm (i.e., explicit, implicit, unintended), providing a
unique lens for understanding the dynamic, multifaceted online risks facing
children and teenagers. The findings highlight the importance of protecting
younger audiences in critical developmental stages from both explicit and
implicit risks on social media, calling for nuanced content moderation, age
verification, and platform regulation.

</details>


### [29] [ParaStudent: Generating and Evaluating Realistic Student Code by Teaching LLMs to Struggle](https://arxiv.org/abs/2507.12674)
*Mihran Miroyan,Rose Niousha,Joseph E. Gonzalez,Gireeja Ranade,Narges Norouzi*

Main category: cs.CY

TL;DR: 本研究通过微调大语言模型，使其能够更加真实地模拟学生代码的风格和学习轨迹，实验验证其在捕捉错误和风格多样性方面优于未经微调的模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在编程任务中表现优异，但是否能生成“类学生”的代码，即不完美、具有迭代性和风格多样性，是一个亟需探索的问题。作者希望通过模拟学生的学习和编程过程，加强教育领域LLM的实用性和真实度。

Method: 使用包含多个学期学生代码提交的时间戳数据，设计了低分辨率与高分辨率实验，对学生学习轨迹进行建模，并从语义、功能和风格多维度对生成代码进行评估。对LLM进行了微调，使其更贴近真实学生的代码流程和错误特征。

Result: 微调后的LLM在模拟学生代码输出时，与真实学生代码序列的对齐度明显提高，更好地捕捉了学习中的错误、改进和风格变化。多维评估证明这种方法效果显著。

Conclusion: 研究表明，通过针对学生提交数据进行微调的大语言模型（LLM），能够更加真实地模拟学生的代码风格，捕捉其错误模式、增量改进过程和风格多样性。模型能较好地重现学生在学习过程中的动态变化。

Abstract: Large Language Models (LLMs) have shown strong performance on programming
tasks, but can they generate student-like code like real students - imperfect,
iterative, and stylistically diverse? We present ParaStudent, a systematic
study of LLM-based "student-like" code generation in an introductory
programming course setting. Using a dataset of timestamped student submissions
across multiple semesters, we design low- and high-resolution experiments to
model student progress and evaluate code outputs along semantic, functional,
and stylistic dimensions. Our results show that fine-tuning significantly
improves alignment with real student trajectories and captures error patterns,
incremental improvements, and stylistic variations more faithfully. This study
shows that modeling realistic student code requires capturing learning dynamics
through context-aware generation, temporal modeling, and multi-dimensional
evaluation. Code for experiments and evaluation is available at
\href{https://github.com/mmiroyan/ParaStudent}{\texttt{github.com/mmiroyan/ParaStudent}}.

</details>


### [30] [The Case for Contextual Copyleft: Licensing Open Source Training Data and Generative AI](https://arxiv.org/abs/2507.12713)
*Grant Shanklin,Emmie Hine,Claudio Novelli,Tyler Schroder,Luciano Floridi*

Main category: cs.CY

TL;DR: 本文针对生成式AI时代开源代码面临的新版权挑战，提出CCAI许可协议，拉宽copyleft原则对AI模型的适用范围。经过法律、政策及风险收益多层次评估，认为CCAI需配套监管，可成为保障开源AI发展的有效工具。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI系统迅速发展，开源社区面临着传统copyleft（著作权左转）原则在AI模型训练数据中的适用性问题，需要新的解决方案以保护开源精神。

Method: 提出了一种新的许可协议Contextual Copyleft AI（CCAI），并利用三层次的评估框架，包括法律可行性、政策正当性分析及跨领域风险与收益综合评估。

Result: CCAI许可协议能够提升开发者控制权、促进开源AI发展、减少开源漂洗风险，但由于开源AI可能被滥用，需配合监管措施才能实现风险与利益的平衡。

Conclusion: 只要在有适当监管的环境下实施，CCAI许可协议能有效保留并适应FOSS原则于生成式AI领域，是应对AI时代开源挑战的可行路径。

Abstract: The proliferation of generative AI systems has created new challenges for the
Free and Open Source Software (FOSS) community, particularly regarding how
traditional copyleft principles should apply when open source code is used to
train AI models. This article introduces the Contextual Copyleft AI (CCAI)
license, a novel licensing mechanism that extends copyleft requirements from
training data to the resulting generative AI models. The CCAI license offers
significant advantages, including enhanced developer control, incentivization
of open source AI development, and mitigation of openwashing practices. This is
demonstrated through a structured three-part evaluation framework that examines
(1) legal feasibility under current copyright law, (2) policy justification
comparing traditional software and AI contexts, and (3) synthesis of
cross-contextual benefits and risks. However, the increased risk profile of
open source AI, particularly the potential for direct misuse, necessitates
complementary regulatory approaches to achieve an appropriate risk-benefit
balance. The paper concludes that when implemented within a robust regulatory
environment focused on responsible AI usage, the CCAI license provides a viable
mechanism for preserving and adapting core FOSS principles to the evolving
landscape of generative AI development.

</details>


### [31] [The Goldilocks zone of governing technology: Leveraging uncertainty for responsible quantum practices](https://arxiv.org/abs/2507.12957)
*Miriam Meckel,Philipp Hacker,Lea Steinacker,Aurelija Lukoseviciene,Surjo R. Soekadar,Jacob Slosser,Gina-Maria Poehlmann*

Main category: cs.CY

TL;DR: 本文提出，面对量子计算等高不确定性前沿技术，应改变治理思路，将不确定性视为积极力量。通过类比量子力学和认知科学，提出了概率性自适应治理新模式（QRS概念），主张欧盟用更灵活、责任化的方法监管创新科技。


<details>
  <summary>Details</summary>
Motivation: 新兴技术（如量子计算）的不确定性已成为治理中的关键难题，传统治理方法难以适应这种本质上的不确定性。该研究旨在寻找适应这种持续和根本性不确定性的治理新方式。

Method: 本文通过引入量子力学范式，将概率性和适应性治理理论应用于技术创新治理，提出了包含物理、技术和社会三层不确定性的分析框架，并以“量子风险模拟器（QRS）”作为概念示例，同时借鉴认知神经科学和预测处理理论，提出一种动态的不确定性治理模型。

Result: 研究提出了以概率推理为核心、能动态适应不确定性的治理新模式，强调三层不确定性的相互作用，并以QRS为想象性蓝图，展示了如何将该理论应用于实际治理过程中。

Conclusion: 这种以不确定性为生成动力的治理模式，为量子及前沿技术的监管提供了更灵活且有责任感的新路径，特别适用于欧盟，希望构建在放任和国家控制之间的“第三种方式”。

Abstract: Emerging technologies challenge conventional governance approaches,
especially when uncertainty is not a temporary obstacle but a foundational
feature as in quantum computing. This paper reframes uncertainty from a
governance liability to a generative force, using the paradigms of quantum
mechanics to propose adaptive, probabilistic frameworks for responsible
innovation. We identify three interdependent layers of uncertainty--physical,
technical, and societal--central to the evolution of quantum technologies. The
proposed Quantum Risk Simulator (QRS) serves as a conceptual example, an
imaginative blueprint rather than a prescriptive tool, meant to illustrate how
probabilistic reasoning could guide dynamic, uncertainty-based governance. By
foregrounding epistemic and ontological ambiguity, and drawing analogies from
cognitive neuroscience and predictive processing, we suggest a new model of
governance aligned with the probabilistic essence of quantum systems. This
model, we argue, is especially promising for the European Union as a third way
between laissez-faire innovation and state-led control, offering a flexible yet
responsible pathway for regulating quantum and other frontier technologies.

</details>


### [32] [Bridging Boundaries: How to Foster Effective Research Collaborations Across Affiliations in the Field of Trust and Safety](https://arxiv.org/abs/2507.13008)
*Amanda Menking,Mona Elswah,David J. Grüning,Lasse H. Hansen,Irene Huang,Julia Kamin,Catrine Normann*

Main category: cs.CY

TL;DR: 本文分析了数字空间信任与安全领域跨部门研究合作的挑战和重要性，提出了具体框架和策略，强调包容和透明的合作模式对于推动该领域发展至关重要。


<details>
  <summary>Details</summary>
Motivation: 由于数字空间的信任与安全议题日益复杂，需要学界、业界、政府和非政府部门之间开展合作，但现实中各方激励、周期与限制常常不一致，影响合作效果。

Method: 作者基于自身跨部门合作经验，总结不同部门间的差异并提出了一个结构化的、可操作的合作框架，包括建立信任、目标对齐和角色分配的策略。

Result: 定义了主要的部门类型，展示了部门间在研究优先级、运营压力和评估标准的不同，并给出了启动和管理有效合作的实用步骤和建议。强调了合作中“表述性”工作的价值，并主张合作模式需注重包容性、透明性和现实意义。

Conclusion: 跨部门合作对于数字空间中的信任与安全领域至关重要，能够推动更具伦理性、公平性与影响力的研究。

Abstract: As the field of Trust and Safety in digital spaces continues to grow, it has
become increasingly necessary - but also increasingly complex - to collaborate
on research across the academic, industry, governmental and non-governmental
sectors. This paper examines how cross-affiliation research partnerships can be
structured to overcome misaligned incentives, timelines and constraints while
delivering on the unique strengths of each stakeholder. Drawing on our own
experience of cross-sector collaboration, we define the main types of
affiliation and highlight the common differences in research priorities,
operational pressures and evaluation metrics across sectors. We then propose a
practical, step-by-step framework for initiating and managing effective
collaborations, including strategies for building trust, aligning goals, and
distributing roles. We emphasize the critical yet often invisible work of
articulation and argue that cross-sector partnerships are essential for
developing more ethical, equitable and impactful research in trust and safety.
Ultimately, we advocate collaborative models that prioritize inclusivity,
transparency and real-world relevance in order to meet the interdisciplinary
demands of this emerging field.

</details>


### [33] [Quantifying the Improvement of Accessibility achieved via Shared Mobility on Demand](https://arxiv.org/abs/2507.13100)
*Severin Diepolder,Andrea Araldo,Tarek Chouaki,Santa Maiti,Sebastian Hörl,Constantinos Antoniou*

Main category: cs.CY

TL;DR: 本论文提出结合共享出行与传统公共交通的可达性定量评估方法，通过空间统计技术，将实际SMS行程转化为等时线可达性指标，并在巴黎郊区实际仿真中验证，为交通系统优化和衡量SMS效益提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 共享出行服务（SMS）能够提升低密度地区的出行便利性，这些地区常规公共交通覆盖较差。传统评估多依赖等待或出行时间等基础指标，无法体现SMS提升用户可达性的核心作用，即扩大用户在有限时间内可到达的工作、学校、商业等机会。

Method: 提出首个基于Isochrone（等时线）的可达性量化计算方法，结合传统公共交通与SMS，SMS作为进出枢纽补充方式。方法采用空间-时间统计分析（Kriging地统计），以观测到的SMS行程生成图结构，再在该图上计算等时线可达性指标。

Result: 该方法在巴黎郊区Saclay区的需求响应交通集成公共交通MATSim仿真案例中应用，能够量化SMS与PT组合系统下的不同时域可达性。

Conclusion: 首次给出了SMS与传统PT融合集成系统可达性可量化测算方法，填补了基于等时线的可达性量化评价空白，对SMS提升交通公平性和出行机会具有指导意义。

Abstract: Shared Mobility Services (SMS), e.g., demand-responsive transport or
ride-sharing, can improve mobility in low-density areas, which are often poorly
served by conventional Public Transport (PT). Such improvement is generally
measured via basic performance indicators, such as waiting or travel time.
However, such basic indicators do not account for the most important
contribution that SMS can provide to territories, i.e., increasing the
potential, for users, to reach surrounding opportunities, such as jobs,
schools, businesses, etc. Such potential can be measured by isochrone-based
accessibility indicators, which count the number of opportunities reachable in
a limited time, and are thus easy for the public to understand. % The potential
impact of SMS on accessibility has been qualitatively discussed and
implications on equity have been empirically studied. However, to date, there
are no quantitative methods to compute isochrone-based indicators of the
accessibility achieved via SMS.
  This work fills this gap by proposing a first method to compute isochrone
accessibility of PT systems composed of conventional PT and SMS, acting as a
feeder for access and egress trips to/from PT hubs. This method is grounded on
spatial-temporal statistical analysis, performed via Kriging. It takes as input
observed trips of SMS and summarizes them in a graph. On such a graph,
isochrone accessibility indicators are computed. We apply the proposed method
to a MATSim simulation study concerning demand-responsive transport integrated
into PT, in the suburban area of Paris-Saclay.

</details>
