{"id": "2506.21743", "categories": ["cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21743", "abs": "https://arxiv.org/abs/2506.21743", "authors": ["Jinpai Zhao", "Albert Cerrone", "Eirik Valseth", "Leendert Westerink", "Clint Dawson"], "title": "Storm Surge in Color: RGB-Encoded Physics-Aware Deep Learning for Storm Surge Forecasting", "comment": null, "summary": "Storm surge forecasting plays a crucial role in coastal disaster\npreparedness, yet existing machine learning approaches often suffer from\nlimited spatial resolution, reliance on coastal station data, and poor\ngeneralization. Moreover, many prior models operate directly on unstructured\nspatial data, making them incompatible with modern deep learning architectures.\nIn this work, we introduce a novel approach that projects unstructured water\nelevation fields onto structured Red Green Blue (RGB)-encoded image\nrepresentations, enabling the application of Convolutional Long Short Term\nMemory (ConvLSTM) networks for end-to-end spatiotemporal surge forecasting. Our\nmodel further integrates ground-truth wind fields as dynamic conditioning\nsignals and topo-bathymetry as a static input, capturing physically meaningful\ndrivers of surge evolution. Evaluated on a large-scale dataset of synthetic\nstorms in the Gulf of Mexico, our method demonstrates robust 48-hour\nforecasting performance across multiple regions along the Texas coast and\nexhibits strong spatial extensibility to other coastal areas. By combining\nstructured representation, physically grounded forcings, and scalable deep\nlearning, this study advances the frontier of storm surge forecasting in\nusability, adaptability, and interpretability.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c06\u98ce\u66b4\u6f6e\u6570\u636e\u7ed3\u6784\u5316\u6210\u56fe\u50cf\uff0c\u7528ConvLSTM\u6a21\u578b\u5b9e\u73b0\u66f4\u51c6\u786e\u3001\u53ef\u6cdb\u5316\u7684\u98ce\u66b4\u6f6e\u9884\u62a5\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u63d0\u5347\u4e86\u9002\u5e94\u548c\u89e3\u91ca\u80fd\u529b\u3002", "motivation": "\u76ee\u524d\u7684\u98ce\u66b4\u6f6e\u9884\u62a5\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5b58\u5728\u7a7a\u95f4\u5206\u8fa8\u7387\u4f4e\u3001\u4f9d\u8d56\u8fd1\u5cb8\u7ad9\u70b9\u6570\u636e\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u7b49\u95ee\u9898\uff0c\u4e14\u8bb8\u591a\u6a21\u578b\u76f4\u63a5\u4f5c\u7528\u4e8e\u975e\u7ed3\u6784\u5316\u7a7a\u95f4\u6570\u636e\uff0c\u8fd9\u4e0e\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u878d\u5408\u5b58\u5728\u969c\u788d\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5c06\u975e\u7ed3\u6784\u5316\u6c34\u4f4d\u573a\u6295\u5f71\u5230\u7ed3\u6784\u5316\u7684RGB\u56fe\u50cf\u8868\u793a\u4e0a\uff0c\u4ece\u800c\u53ef\u5229\u7528\u5377\u79ef\u957f\u77ed\u65f6\u8bb0\u5fc6\u7f51\u7edc\uff08ConvLSTM\uff09\u8fdb\u884c\u7aef\u5230\u7aef\u7684\u65f6\u7a7a\u98ce\u66b4\u6f6e\u9884\u62a5\u3002\u540c\u65f6\uff0c\u6a21\u578b\u96c6\u6210\u4e86\u771f\u5b9e\u98ce\u573a\u4f5c\u4e3a\u52a8\u6001\u6761\u4ef6\u8f93\u5165\uff0c\u5730\u5f62\u4e0e\u6d77\u5e95\u5730\u8c8c\u4f5c\u4e3a\u9759\u6001\u8f93\u5165\uff0c\u6355\u6349\u98ce\u66b4\u6f6e\u6f14\u5316\u7684\u7269\u7406\u9a71\u52a8\u56e0\u7d20\u3002", "result": "\u5728\u7f8e\u56fd\u58a8\u897f\u54e5\u6e7e\u5408\u6210\u98ce\u66b4\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u5fb7\u5dde\u6cbf\u5cb8\u591a\u4e2a\u533a\u57df\u5c55\u73b0\u51fa\u7a33\u5065\u768448\u5c0f\u65f6\u9884\u62a5\u80fd\u529b\uff0c\u5728\u7a7a\u95f4\u4e0a\u5bf9\u5176\u4ed6\u6cbf\u6d77\u533a\u57df\u4e5f\u5177\u6709\u8f83\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5c06\u7ed3\u6784\u5316\u56fe\u50cf\u8868\u793a\u3001\u7269\u7406\u5f3a\u76f8\u5173\u6761\u4ef6\u548c\u53ef\u6269\u5c55\u6df1\u5ea6\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u98ce\u66b4\u6f6e\u9884\u62a5\u7684\u6613\u7528\u6027\u3001\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.21815", "categories": ["cs.CE", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2506.21815", "abs": "https://arxiv.org/abs/2506.21815", "authors": ["Augustine Twumasi", "Prokash Chandra Roy", "Zixun Li", "Soumya Shouvik Bhattacharjee", "Zhengtao Gan"], "title": "Laser Scan Path Design for Controlled Microstructure in Additive Manufacturing with Integrated Reduced-Order Phase-Field Modeling and Deep Reinforcement Learning", "comment": null, "summary": "Laser powder bed fusion (L-PBF) is a widely recognized additive manufacturing\ntechnology for producing intricate metal components with exceptional accuracy.\nA key challenge in L-PBF is the formation of complex microstructures affecting\nproduct quality. We propose a physics-guided, machine-learning approach to\noptimize scan paths for desired microstructure outcomes, such as equiaxed\ngrains. We utilized a phase-field method (PFM) to model crystalline grain\nstructure evolution. To reduce computational costs, we trained a surrogate\nmachine learning model, a 3D U-Net convolutional neural network, using\nsingle-track phase-field simulations with various laser powers to predict\ncrystalline grain orientations based on initial microstructure and thermal\nhistory. We investigated three scanning strategies across various hatch\nspacings within a square domain, achieving a two-orders-of-magnitude speedup\nusing the surrogate model. To reduce trial and error in designing laser scan\ntoolpaths, we used deep reinforcement learning (DRL) to generate optimized scan\npaths for target microstructure. Results from three cases demonstrate the DRL\napproach's effectiveness. We integrated the surrogate 3D U-Net model into our\nDRL environment to accelerate the reinforcement learning training process. The\nreward function minimizes both aspect ratio and grain volume of the predicted\nmicrostructure from the agent's scan path. The reinforcement learning algorithm\nwas benchmarked against conventional zigzag approach for smaller and larger\ndomains, showing machine learning methods' potential to enhance microstructure\ncontrol and computational efficiency in L-PBF optimization.", "AI": {"tldr": "\u672c\u6587\u5c06\u76f8\u573a\u7269\u7406\u6a21\u62df\u30013D U-Net\u6df1\u5ea6\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u6fc0\u5149\u9009\u533a\u7194\u5316\u5de5\u827a\u626b\u63cf\u8def\u5f84\u7684\u667a\u80fd\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6548\u7387\u548c\u5fae\u7ed3\u6784\u63a7\u5236\u6548\u679c\uff0c\u51cf\u5c11\u4e86\u8bd5\u9519\u6210\u672c\u3002", "motivation": "\u6fc0\u5149\u9009\u533a\u7194\u5316\uff08L-PBF\uff09\u867d\u7136\u80fd\u591f\u9ad8\u7cbe\u5ea6\u5236\u9020\u590d\u6742\u91d1\u5c5e\u96f6\u4ef6\uff0c\u4f46\u5176\u590d\u6742\u7684\u5fae\u89c2\u7ed3\u6784\u5f62\u6210\u8fc7\u7a0b\u5f71\u54cd\u4ea7\u54c1\u8d28\u91cf\uff0c\u8fd9\u6210\u4e3a\u884c\u4e1a\u4e9f\u9700\u7834\u89e3\u7684\u96be\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7269\u7406\u9a71\u52a8\u548c\u673a\u5668\u5b66\u4e60\u7684\u626b\u63cf\u8def\u5f84\u4f18\u5316\u65b9\u6cd5\u3002\u5229\u7528\u76f8\u573a\u6cd5\uff08PFM\uff09\u6a21\u62df\u6676\u7c92\u7ed3\u6784\u6f14\u5316\uff0c\u5e76\u4ee5\u5355\u9053\u6fc0\u5149\u4e0d\u540c\u529f\u7387\u4e0b\u7684\u76f8\u573a\u6a21\u62df\u7ed3\u679c\u8bad\u7ec33D U-Net\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u4e0d\u540c\u626b\u63cf\u8def\u5f84\u4e0b\u7684\u6676\u7c92\u671d\u5411\u3002\u8fdb\u4e00\u6b65\uff0c\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\uff0c\u81ea\u52a8\u751f\u6210\u4f18\u5316\u7684\u6fc0\u5149\u626b\u63cf\u8def\u5f84\uff0c\u4ee5\u5b9e\u73b0\u76ee\u6807\u5fae\u7ed3\u6784\u3002", "result": "\u66ff\u4ee33D U-Net\u6a21\u578b\u4f7f\u5fae\u7ed3\u6784\u9884\u6d4b\u901f\u5ea6\u63d0\u5347\u7ea6100\u500d\u3002\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u751f\u6210\u7684\u626b\u63cf\u8def\u5f84\uff0c\u5728\u591a\u4e2a\u6848\u4f8b\u4e2d\u5747\u5c55\u73b0\u51fa\u4f18\u5316\u5fae\u7ed3\u6784\u548c\u7f29\u77ed\u5f00\u53d1\u5468\u671f\u7684\u6709\u6548\u6027\u3002\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u4e0d\u540c\u89c4\u6a21\u57df\u4e0b\u5747\u4f18\u4e8e\u4f20\u7edf\u952f\u9f7f\u626b\u63cf\u65b9\u6cd5\uff0c\u6539\u5584\u4e86\u5fae\u7ed3\u6784\u63a7\u5236\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u5c06\u7269\u7406\u9a71\u52a8\u3001\u6df1\u5ea6\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\u4e0e\u5f3a\u5316\u5b66\u4e60\u6709\u673a\u7ed3\u5408\uff0c\u53ef\u9ad8\u6548\u4f18\u5316L-PBF\u7684\u626b\u63cf\u8def\u5f84\uff0c\u5b9e\u73b0\u76ee\u6807\u5fae\u7ed3\u6784\uff0c\u63d0\u9ad8L-PBF\u751f\u4ea7\u6548\u7387\u4e0e\u8d28\u91cf\u63a7\u5236\uff0c\u4e3a\u589e\u6750\u5236\u9020\u5fae\u7ed3\u6784\u5b9a\u5411\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2506.21918", "categories": ["cs.CE", "nlin.PS"], "pdf": "https://arxiv.org/pdf/2506.21918", "abs": "https://arxiv.org/abs/2506.21918", "authors": ["Abrari Noor Hasmi", "Hadi Susanto"], "title": "Model-free Forecasting of Rogue Waves using Reservoir Computing", "comment": "26 pages 14 figures. To appear Communications in Nonlinear Science\n  and Numerical Simulation (CNSNS), 2025 , 109087", "summary": "Recent research has demonstrated Reservoir Computing's capability to model\nvarious chaotic dynamical systems, yet its application to Hamiltonian systems\nremains relatively unexplored. This paper investigates the effectiveness of\nReservoir Computing in capturing rogue wave dynamics from the nonlinear\nSchr\\\"{o}dinger equation, a challenging Hamiltonian system with modulation\ninstability. The model-free approach learns from breather simulations with five\nunstable modes. A properly tuned parallel Echo State Network can predict\ndynamics from two distinct testing datasets. The first set is a continuation of\nthe training data, whereas the second set involves a higher-order breather. An\ninvestigation of the one-step prediction capability shows remarkable agreement\nbetween the testing data and the models. Furthermore, we show that the trained\nreservoir can predict the propagation of rogue waves over a relatively long\nprediction horizon, despite facing unseen dynamics. Finally, we introduce a\nmethod to significantly improve the Reservoir Computing prediction in\nautonomous mode, enhancing its long-term forecasting ability. These results\nadvance the application of Reservoir Computing to spatio-temporal Hamiltonian\nsystems and highlight the critical importance of phase space coverage in the\ndesign of training data.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86Reservoir Computing\u5728\u975e\u7ebf\u6027\u859b\u5b9a\u8c14\u65b9\u7a0b\u7b49\u54c8\u5bc6\u987f\u7cfb\u7edf\u6781\u7aef\u6ce2\u5efa\u6a21\u4e2d\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u5e76\u884cESN\u5b9e\u73b0\u4e86\u5bf9\u6d4b\u8bd5\u6570\u636e\u4e2d\u65b0\u52a8\u529b\u5b66\u7684\u7cbe\u786e\u9884\u6d4b\uff0c\u5e76\u51ed\u501f\u65b0\u65b9\u6cd5\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u957f\u671f\u81ea\u4e3b\u9884\u6d4b\u80fd\u529b\uff0c\u4e3a\u5229\u7528Reservoir Computing\u5904\u7406\u590d\u6742\u54c8\u5bc6\u987f\u7cfb\u7edf\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0e\u5b9e\u9a8c\u652f\u6301\u3002", "motivation": "\u867d\u7136Reservoir Computing\uff08\u50a8\u5907\u6c60\u8ba1\u7b97\uff09\u5728\u5efa\u6a21\u5404\u79cd\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5728\u54c8\u5bc6\u987f\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u8fd8\u9c9c\u6709\u62a5\u9053\u3002\u672c\u6587\u81f4\u529b\u4e8e\u63a2\u7d22\u5176\u5728\u590d\u6742\u7684\u54c8\u5bc6\u987f\u7cfb\u7edf\u2014\u2014\u975e\u7ebf\u6027\u859b\u5b9a\u8c14\u65b9\u7a0b\uff08\u542b\u8c03\u5236\u4e0d\u7a33\u5b9a\u6027\u4e0e\u6781\u7aef\u6ce2\u52a8\u73b0\u8c61\uff09\u4e2d\u7684\u5efa\u6a21\u80fd\u529b\u3002", "method": "\u91c7\u7528\u65e0\u9700\u6a21\u578b\u7684Reservoir Computing\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5177\u6709\u4e94\u4e2a\u4e0d\u7a33\u5b9a\u6a21\u7684breather\u6a21\u62df\u6570\u636e\u8bad\u7ec3\u5e76\u8c03\u4f18\u5e76\u884cEcho State Network\uff08ESN\uff09\uff0c\u8bc4\u4f30\u7b97\u6cd5\u5bf9\u4e8e\u4e24\u5957\u6d4b\u8bd5\u6570\u636e\uff08\u4e00\u5957\u4e3a\u8bad\u7ec3\u6570\u636e\u7684\u5ef6\u7eed\uff0c\u4e00\u5957\u5305\u542b\u9ad8\u9636breather\u65b0\u52a8\u529b\u5b66\uff09\u7684\u77ed\u65f6\u4e0e\u8f83\u957f\u65f6\u95f4\u5c3a\u5ea6\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u540c\u65f6\u63d0\u51fa\u4f18\u5316\u81ea\u4e3b\u9884\u6d4b\uff08autonomous mode\uff09\u7684\u65b9\u6cd5\u63d0\u5347\u957f\u671f\u9884\u6d4b\u6548\u679c\u3002", "result": "\u4f18\u5316\u540e\u7684Reservoir Computing\u6a21\u578b\u5728\u4e00\u6b65\u9884\u6d4b\u4e0a\u4e0e\u6d4b\u8bd5\u6570\u636e\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5e76\u80fd\u5728\u672a\u89c1\u65b0\u52a8\u529b\u5b66\u51fa\u73b0\u65f6\u5b9e\u73b0\u8f83\u957f\u65f6\u95f4\u5c3a\u5ea6\u7684\u6781\u7aef\u6ce2\u52a8\u4f20\u64ad\u9884\u6d4b\u3002\u9488\u5bf9\u81ea\u4e3b\u9884\u6d4b\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u957f\u671f\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86Reservoir Computing\u65b9\u6cd5\u5728\u65f6\u7a7a\u54c8\u5bc6\u987f\u7cfb\u7edf\u4e2d\u5efa\u6a21\u6781\u7aef\u52a8\u529b\u5b66\u7684\u5b9e\u529b\uff0c\u5f3a\u8c03\u4e86\u8bad\u7ec3\u6570\u636e\u6db5\u76d6\u76f8\u7a7a\u95f4\u7684\u5145\u5206\u6027\u5bf9\u4e8e\u9884\u6d4b\u80fd\u529b\u63d0\u5347\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.21927", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.21927", "abs": "https://arxiv.org/abs/2506.21927", "authors": ["Yinghan Li", "Yilin Yao", "Junghua Lin", "Nanxi Wang"], "title": "A Deep Learning Algorithm Based on CNN-LSTM Framework for Predicting Cancer Drug Sales Volume", "comment": null, "summary": "This study explores the application potential of a deep learning model based\non the CNN-LSTM framework in forecasting the sales volume of cancer drugs, with\na focus on modeling complex time series data. As advancements in medical\ntechnology and cancer treatment continue, the demand for oncology medications\nis steadily increasing. Accurate forecasting of cancer drug sales plays a\ncritical role in optimizing production planning, supply chain management, and\nhealthcare policy formulation. The dataset used in this research comprises\nquarterly sales records of a specific cancer drug in Egypt from 2015 to 2024,\nincluding multidimensional information such as date, drug type, pharmaceutical\ncompany, price, sales volume, effectiveness, and drug classification. To\nimprove prediction accuracy, a hybrid deep learning model combining\nConvolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks\nis employed. The CNN component is responsible for extracting local temporal\nfeatures from the sales data, while the LSTM component captures long-term\ndependencies and trends. Model performance is evaluated using two widely\nadopted metrics: Mean Squared Error (MSE) and Root Mean Squared Error (RMSE).\nThe results demonstrate that the CNN-LSTM model performs well on the test set,\nachieving an MSE of 1.150 and an RMSE of 1.072, indicating its effectiveness in\nhandling nonlinear and volatile sales data. This research provides theoretical\nand technical support for data-driven decision-making in pharmaceutical\nmarketing and healthcare resource planning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86CNN-LSTM\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u764c\u75c7\u836f\u7269\u9500\u91cf\u9884\u6d4b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u80fd\u8f83\u597d\u5904\u7406\u975e\u7ebf\u6027\u548c\u6ce2\u52a8\u6027\u6570\u636e\uff0c\u53ef\u4e3a\u751f\u4ea7\u51b3\u7b56\u548c\u533b\u7597\u8d44\u6e90\u7ba1\u7406\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u9488\u5bf9\u5f53\u524d\u764c\u75c7\u836f\u7269\u9700\u6c42\u4e0d\u65ad\u589e\u52a0\uff0c\u51c6\u786e\u9884\u6d4b\u836f\u54c1\u9500\u91cf\u5bf9\u4e8e\u751f\u4ea7\u8ba1\u5212\u3001\u4f9b\u5e94\u94fe\u7ba1\u7406\u548c\u533b\u7597\u653f\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u7ed3\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u548c\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09\u7684\u6df1\u5ea6\u5b66\u4e60\u6df7\u5408\u6a21\u578b\uff08CNN-LSTM\uff09\uff0c\u5bf92015\u81f32024\u5e74\u57c3\u53ca\u67d0\u764c\u75c7\u836f\u7269\u5b63\u5ea6\u9500\u91cf\u6570\u636e\uff08\u5305\u542b\u591a\u7ef4\u4fe1\u606f\uff09\u8fdb\u884c\u5efa\u6a21\u548c\u9884\u6d4b\u3002\u6a21\u578b\u7528CNN\u63d0\u53d6\u5c40\u90e8\u65f6\u5e8f\u7279\u5f81\uff0c\u7528LSTM\u6355\u6349\u957f\u671f\u4f9d\u8d56\u548c\u8d8b\u52bf\u3002\u901a\u8fc7MSE\u548cRMSE\u8861\u91cf\u9884\u6d4b\u6027\u80fd\u3002", "result": "CNN-LSTM\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u8868\u73b0\uff0cMSE\u4e3a1.150\uff0cRMSE\u4e3a1.072\uff0c\u663e\u793a\u4e86\u5176\u5bf9\u975e\u7ebf\u6027\u548c\u6ce2\u52a8\u6570\u636e\u7684\u826f\u597d\u9884\u6d4b\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u5b9e\u4e86\u6df1\u5ea6\u5b66\u4e60CNN-LSTM\u6a21\u578b\u5728\u764c\u75c7\u836f\u7269\u9500\u91cf\u9884\u6d4b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u533b\u836f\u5e02\u573a\u51b3\u7b56\u548c\u533b\u7597\u8d44\u6e90\u89c4\u5212\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2506.21794", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.21794", "abs": "https://arxiv.org/abs/2506.21794", "authors": ["Akshay Irudayaraj", "Nathan Ye", "Yash Chainani"], "title": "Shifting Narratives: A Longitudinal Analysis of Media Trends and Public Attitudes on Homelessness", "comment": "21 pages, 7 figures, 12 tables", "summary": "Within the field of media framing, homelessness has been a historically\nunder-researched topic. Framing theory states that the media's method of\npresenting information plays a pivotal role in controlling public sentiment\ntoward a topic. The sentiment held towards homeless individuals influences\ntheir ability to access jobs, housing, and resources as a result of\ndiscrimination. This study analyzes the topic and sentiment trends in related\nmedia articles to validate framing theory within the scope of homelessness. It\ncorrelates these shifts in media reporting with public sentiment. We examine\nstate-level trends in California, Florida, Washington, Oregon, and New York\nfrom 2015 to 2023. We utilize the GDELT 2.0 Global Knowledge Graph (GKG)\ndatabase to gather article data and use X to measure public sentiment towards\nhomeless individuals. Additionally, to identify if there is a correlation\nbetween media reporting and public policy, we examine the media's impact on\nstate-level legislation. Our research uses Granger-causality tests and vector\nautoregressive (VAR) models to establish a correlation between media framing\nand public sentiment. We also use latent Dirichlet allocation (LDA) and GPT-3.5\n(LLM-as-annotator paradigm) for topic modeling and sentiment analysis. Our\nfindings demonstrate a statistically significant correlation between media\nframing and public sentiment, especially in states with high homelessness\nrates. We found no significant correlation between media framing and\nlegislation, suggesting a possible disconnect between public opinion and\npolicy-making. These findings reveal the broader impact of the media's framing\ndecisions and delineate its ability to affect society.", "AI": {"tldr": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u5a92\u4f53\u6846\u67b6\u5728\u5851\u9020\u516c\u4f17\u5bf9\u65e0\u5bb6\u53ef\u5f52\u8005\u6001\u5ea6\u4e0a\u7684\u5f71\u54cd\uff0c\u4f46\u8fd9\u79cd\u5f71\u54cd\u672a\u5fc5\u76f4\u63a5\u4f5c\u7528\u4e8e\u653f\u7b56\uff0c\u53cd\u6620\u4e86\u793e\u4f1a\u6001\u5ea6\u4e0e\u653f\u7b56\u4e4b\u95f4\u7684\u8131\u8282\u3002", "motivation": "\u65e0\u5bb6\u53ef\u5f52\u95ee\u9898\u5728\u4f20\u5a92\u6846\u67b6\u7814\u7a76\u9886\u57df\u5386\u6765\u5173\u6ce8\u8f83\u5c11\u3002\u7531\u4e8e\u5a92\u4f53\u7684\u4fe1\u606f\u5448\u73b0\u65b9\u5f0f\u4f1a\u5f71\u54cd\u516c\u4f17\u5bf9\u65e0\u5bb6\u53ef\u5f52\u8005\u7684\u6001\u5ea6\uff0c\u800c\u8fd9\u79cd\u6001\u5ea6\u53c8\u5f71\u54cd\u5230\u65e0\u5bb6\u53ef\u5f52\u8005\u7684\u5c31\u4e1a\u3001\u4f4f\u623f\u548c\u8d44\u6e90\u83b7\u53d6\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u63a2\u8ba8\u5a92\u4f53\u6846\u67b6\u5982\u4f55\u5f71\u54cd\u76f8\u5173\u793e\u4f1a\u6001\u5ea6\u4e0e\u653f\u7b56\u3002", "method": "\u4ece2015\u81f32023\u5e74\uff0c\u9009\u53d6\u7f8e\u56fd\u52a0\u5dde\u3001\u4f5b\u5dde\u3001\u534e\u76db\u987f\u5dde\u3001\u4fc4\u52d2\u5188\u5dde\u548c\u7ebd\u7ea6\u5dde\uff0c\u5229\u7528GDELT 2.0\u5168\u7403\u77e5\u8bc6\u56fe\u6570\u636e\u5e93\u6536\u96c6\u65b0\u95fb\u62a5\u9053\u6570\u636e\uff0c\u5e76\u7528X\u6765\u6d4b\u91cf\u516c\u4f17\u5bf9\u65e0\u5bb6\u53ef\u5f52\u8005\u7684\u60c5\u611f\u3002\u901a\u8fc7Granger\u56e0\u679c\u68c0\u9a8c\u548c\u5411\u91cf\u81ea\u56de\u5f52\uff08VAR\uff09\u6a21\u578b\u8003\u5bdf\u5a92\u4f53\u62a5\u9053\u4e0e\u516c\u4f17\u60c5\u611f\u7684\u76f8\u5173\u6027\uff0c\u5e76\u7528LDA\u548cGPT-3.5\uff08\u5927\u6a21\u578b\u8f85\u52a9\u6807\u6ce8\uff09\u65b9\u6cd5\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\u548c\u60c5\u611f\u5206\u6790\u3002\u6b64\u5916\uff0c\u8fd8\u5206\u6790\u4e86\u5a92\u4f53\u62a5\u9053\u4e0e\u5dde\u7ea7\u7acb\u6cd5\u7684\u5173\u8054\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5a92\u4f53\u6846\u67b6\u4e0e\u516c\u4f17\u60c5\u611f\u4e4b\u95f4\u5b58\u5728\u7edf\u8ba1\u663e\u8457\u7684\u76f8\u5173\u6027\uff0c\u5c24\u4ee5\u65e0\u5bb6\u53ef\u5f52\u73b0\u8c61\u4e25\u91cd\u7684\u5dde\u6700\u4e3a\u663e\u8457\u3002\u4f46\u5a92\u4f53\u6846\u67b6\u4e0e\u7acb\u6cd5\u4e4b\u95f4\u6ca1\u6709\u663e\u8457\u76f8\u5173\u6027\uff0c\u63d0\u793a\u516c\u4f17\u8206\u8bba\u4e0e\u653f\u7b56\u5236\u5b9a\u6216\u5b58\u8131\u8282\u73b0\u8c61\u3002", "conclusion": "\u5a92\u4f53\u5bf9\u65e0\u5bb6\u53ef\u5f52\u76f8\u5173\u8bae\u9898\u7684\u62a5\u9053\u6846\u67b6\u5f71\u54cd\u4e86\u516c\u4f17\u7684\u6001\u5ea6\uff0c\u4f46\u672a\u80fd\u76f4\u63a5\u5f71\u54cd\u653f\u7b56\u5236\u5b9a\uff0c\u663e\u793a\u51fa\u5a92\u4f53\u5728\u5851\u9020\u793e\u4f1a\u6001\u5ea6\u548c\u653f\u7b56\u4e4b\u95f4\u5b58\u5728\u4e00\u5b9a\u7684\u65ad\u5c42\u3002"}}
{"id": "2506.21555", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.21555", "abs": "https://arxiv.org/abs/2506.21555", "authors": ["Jiahong Li", "Yiwen Shao", "Jianheng Zhuo", "Chenda Li", "Liliang Tang", "Dong Yu", "Yanmin Qian"], "title": "Efficient Multilingual ASR Finetuning via LoRA Language Experts", "comment": "Accepted in Interspeech 2025", "summary": "Recent advancements in deep learning have significantly enhanced multilingual\nautomatic speech recognition (ASR) due to the development of advanced model\narchitectures and available large-scale multilingual datasets. Despite that,\nmultilingual ASR still suffers from the curse of multilinguality in that\ndifferent languages tend to interfere with each other, making it difficult for\nthe ASR model to identify multiple languages effectively while sharing model\ncapacity across them. This paper proposes an efficient finetuning framework for\ncustomized multilingual ASR via prepared LoRA language experts based on\nWhisper. Through LoRA expert fusion or knowledge distillation, our approach\nachieves better recognition performance on target languages than standard\nfine-tuning methods. Experimental results demonstrate that the proposed models\nyield approximately 10\\% and 15\\% relative performance gains in language-aware\nand language-agnostic scenarios, respectively.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u7528\u57fa\u4e8eWhisper\u7684LoRA\u8bed\u8a00\u4e13\u5bb6\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u5bb6\u878d\u5408\u6216\u77e5\u8bc6\u84b8\u998f\uff0c\u5b9e\u73b0\u591a\u8bed\u79cdASR\u6027\u80fd\u63d0\u5347\uff0c\u5728\u591a\u79cd\u573a\u666f\u4e0b\u76f8\u5bf9\u63d0\u534710%-15%\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u548c\u591a\u8bed\u79cd\u5927\u6570\u636e\u96c6\u63a8\u52a8\u4e86\u591a\u8bed\u79cd\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7684\u8fdb\u6b65\uff0c\u4f46\u201c\u591a\u8bed\u79cd\u6027\u8bc5\u5492\u201d\u95ee\u9898\u4f9d\u7136\u5b58\u5728\uff0c\u5373\u4e0d\u540c\u8bed\u8a00\u4e4b\u95f4\u4f1a\u76f8\u4e92\u5e72\u6270\uff0c\u5f71\u54cdASR\u6a21\u578b\u6709\u6548\u8bc6\u522b\u591a\u8bed\u8a00\u7684\u80fd\u529b\u3002", "method": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWhisper\u548cLoRA\u8bed\u8a00\u4e13\u5bb6\u7684\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7LoRA\u4e13\u5bb6\u878d\u5408\u6216\u77e5\u8bc6\u84b8\u998f\uff0c\u9488\u5bf9\u4e0d\u540c\u8bed\u79cd\u5b9e\u73b0\u5b9a\u5236\u5316\u591a\u8bed\u79cdASR\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u76ee\u6807\u8bed\u8a00\u4e0a\u7684\u8bc6\u522b\u6027\u80fd\u4f18\u4e8e\u5e38\u89c4\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u8bed\u8a00\u611f\u77e5\u548c\u8bed\u8a00\u65e0\u5173\u573a\u666f\u4e0b\uff0c\u6a21\u578b\u5206\u522b\u53d6\u5f97\u4e86\u7ea610%\u548c15%\u7684\u76f8\u5bf9\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165LoRA\u4e13\u5bb6\u5e76\u91c7\u7528\u4e13\u5bb6\u878d\u5408\u6216\u77e5\u8bc6\u84b8\u998f\u7b56\u7565\uff0c\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u591a\u8bed\u79cdASR\u4e2d\u7684\u201c\u591a\u8bed\u79cd\u6027\u8bc5\u5492\u201d\uff0c\u63d0\u5347\u6a21\u578b\u5728\u76ee\u6807\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2506.21669", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21669", "abs": "https://arxiv.org/abs/2506.21669", "authors": ["Wanxin Tian", "Shijie Zhang", "Kevin Zhang", "Xiaowei Chi", "Yulin Luo", "Junyu Lu", "Chunkai Fan", "Qiang Zhou", "Yiming Zhao", "Ning Liu Siyu Lin", "Zhiyuan Qin", "Xiaozhu Ju", "Shanghang Zhang", "Jian Tang"], "title": "SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents", "comment": null, "summary": "Self-evolution, the ability of agents to autonomously improve their reasoning\nand behavior, is essential for the embodied domain with long-horizon,\nreal-world tasks. Despite current advancements in reinforcement fine-tuning\n(RFT) showing strong performance in enhancing reasoning in LLMs, its potential\nto enable self-evolving embodied intelligence with multi-modal interactions\nremains largely unexplored. Specifically, reinforcement fine-tuning faces two\nfundamental obstacles in embodied settings: (i) the lack of accessible\nintermediate rewards in multi-step reasoning tasks limits effective learning\nsignals, and (ii) reliance on hand-crafted reward functions restricts\ngeneralization to novel tasks and environments. To address these challenges, we\npresent Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework\ndesigned for enabling the self-evolving capabilities of embodied agents.\nSpecifically, to convert sparse delayed rewards into denser intermediate\nsignals that improve multi-step reasoning, we propose Tree-based group relative\npolicy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into\nGRPO. To generalize reward estimation across tasks and scenes, supporting\nautonomous adaptation and reward-driven self-evolution, we further introduce\nMulti-modal Generative Reward Model (MGRM). To holistically evaluate the\neffectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing\nstate-of-the-art methods with scores of 85.07% (textual) and 36.19%\n(multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also\nachieves scores of 80.3% without environmental reward, surpassing all\nopen-source baselines and highlighting its scalability as a self-evolving\nembodied agent. Additional experiments and qualitative analysis further support\nthe potential of SEEA-R1 for future research in scalable embodied intelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSEEA-R1\u6846\u67b6\uff0c\u901a\u8fc7\u6539\u8fdb\u5956\u52b1\u4fe1\u53f7\u548c\u5956\u52b1\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5177\u8eab\u667a\u80fd\u4f53\u81ea\u8fdb\u5316\uff0c\u8d85\u8fc7\u4e86\u73b0\u6709SOTA\u6a21\u578b\u3002", "motivation": "\u5f53\u524dLLM\u5728\u63a8\u7406\u548c\u5f3a\u5316\u5fae\u8c03\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5bf9\u4e8e\u5728\u771f\u5b9e\u3001\u591a\u6a21\u6001\u3001\u957f\u671f\u4efb\u52a1\u73af\u5883\u4e0b\u5b9e\u73b0\u81ea\u4e3b\u8fdb\u5316\u7684\u5177\u8eab\u667a\u80fd\u4f53\uff0c\u4ecd\u7136\u5b58\u5728\u56f0\u96be\u3002\u4e3b\u8981\u6311\u6218\u5728\u4e8e\u591a\u6b65\u63a8\u7406\u4e2d\u4e2d\u95f4\u5956\u52b1\u4fe1\u53f7\u7a00\u758f\uff0c\u4e14\u624b\u5de5\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\u96be\u4ee5\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\u3002", "method": "\u63d0\u51faSEEA-R1\uff08Self-Evolving Embodied Agents-R1\uff09\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u62ec\uff1a1\uff09Tree-GRPO\u65b9\u6cd5\uff0c\u5c06\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u5f15\u5165GRPO\u4ee5\u751f\u6210\u66f4\u5bc6\u96c6\u7684\u4e2d\u95f4\u5956\u52b1\u4fe1\u53f7\uff1b2\uff09\u591a\u6a21\u6001\u751f\u6210\u5956\u52b1\u6a21\u578b\uff08MGRM\uff09\uff0c\u63d0\u5347\u5956\u52b1\u4f30\u8ba1\u6cdb\u5316\u80fd\u529b\uff0c\u652f\u6301\u81ea\u4e3b\u9002\u5e94\u548c\u5956\u52b1\u9a71\u52a8\u7684\u81ea\u8fdb\u5316\u3002", "result": "\u5728ALFWorld\u57fa\u51c6\u4e0a\uff0cSEEA-R1\u5728\u6587\u672c\u4efb\u52a1\u4e0a\u8fbe85.07%\u3001\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u8fbe36.19%\uff0c\u5747\u8d85\u8d8aGPT-4o\u7b49\u6700\u5148\u8fdb\u6a21\u578b\u3002\u5373\u4f7f\u5728\u65e0\u73af\u5883\u5956\u52b1\u4e0b\uff0c\u4ecd\u670980.3%\u8868\u73b0\uff0c\u4f18\u4e8e\u6240\u6709\u5f00\u6e90\u57fa\u7ebf\u3002\u6b64\u5916\uff0c\u8fd8\u6709\u66f4\u591a\u5b9e\u9a8c\u548c\u5b9a\u6027\u5206\u6790\u8bba\u8bc1\u5176\u53ef\u6269\u5c55\u6027\u548c\u6f5c\u529b\u3002", "conclusion": "SEEA-R1\u6846\u67b6\u6709\u6548\u63a8\u52a8\u4e86\u5177\u8eab\u667a\u80fd\u4f53\u7684\u81ea\u4e3b\u8fdb\u5316\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u63a8\u7406\u8868\u73b0\uff0c\u5bf9\u672a\u6765\u5927\u89c4\u6a21\u5177\u8eab\u667a\u80fd\u4f53\u7814\u7a76\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.21816", "categories": ["cs.CY", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2506.21816", "abs": "https://arxiv.org/abs/2506.21816", "authors": ["Charles Yang"], "title": "The First Compute Arms Race: the Early History of Numerical Weather Prediction", "comment": null, "summary": "This paper traces the global race to apply early electronic computers to\nnumerical weather prediction in the decades following World War Two. A brief\noverview of the early history of numerical weather prediction in the United\nStates, United Kingdom, Sweden, Canada, and Japan is provided. Three critical\nfactors that shaped the development of a national numerical weather prediction\nare identified: compute capabilities, institution building and state capacity,\nand talent. Several generalizable lessons are identified with a lens towards\nmodern-day development of national strategies to leverage AI to accelerate\nscientific competitiveness.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u7f8e\u3001\u82f1\u3001\u745e\u5178\u3001\u52a0\u3001\u65e5\u7b49\u56fd\u6570\u503c\u5929\u6c14\u9884\u62a5\u53d1\u5c55\u53f2\uff0c\u5206\u6790\u4e86\u6210\u529f\u7684\u4e09\u5927\u8981\u7d20\uff0c\u4e3a\u5f53\u4eca\u5229\u7528AI\u63a8\u52a8\u56fd\u5bb6\u79d1\u5b66\u7ade\u4e89\u529b\u63d0\u4f9b\u4e86\u5386\u53f2\u7ecf\u9a8c\u548c\u6218\u7565\u53c2\u8003\u3002", "motivation": "\u4e8c\u6218\u540e\uff0c\u5168\u7403\u79d1\u6280\u5feb\u901f\u53d1\u5c55\uff0c\u65e9\u671f\u7535\u5b50\u8ba1\u7b97\u673a\u51fa\u73b0\uff0c\u4e3a\u6570\u503c\u5929\u6c14\u9884\u62a5\u5e26\u6765\u53ef\u80fd\u3002\u672c\u6587\u65e8\u5728\u68b3\u7406\u6570\u503c\u5929\u6c14\u9884\u62a5\u5728\u591a\u56fd\u53d1\u5c55\u7684\u5386\u53f2\u8fdb\u7a0b\uff0c\u63a2\u7d22\u63a8\u52a8\u5176\u53d1\u5c55\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u901a\u8fc7\u5bf9\u7f8e\u56fd\u3001\u82f1\u56fd\u3001\u745e\u5178\u3001\u52a0\u62ff\u5927\u548c\u65e5\u672c\u5728\u6570\u503c\u5929\u6c14\u9884\u62a5\u65e9\u671f\u5386\u53f2\u7684\u68b3\u7406\uff0c\u6bd4\u8f83\u5206\u6790\u5404\u56fd\u5728\u53d1\u5c55\u8fc7\u7a0b\u4e2d\u4f9d\u8d56\u7684\u8ba1\u7b97\u80fd\u529b\u3001\u673a\u6784\u5efa\u8bbe\u548c\u56fd\u5bb6\u80fd\u529b\u4ee5\u53ca\u4eba\u624d\u50a8\u5907\u7b49\u56e0\u7d20\u3002", "result": "\u6587\u7ae0\u603b\u7ed3\u4e86\u4e09\u5927\u5f71\u54cd\u56fd\u5bb6\u6570\u503c\u5929\u6c14\u9884\u62a5\u53d1\u5c55\u7684\u5173\u952e\u8981\u7d20\uff1a\u8ba1\u7b97\u80fd\u529b\u3001\u673a\u6784\u5efa\u8bbe\u4e0e\u56fd\u5bb6\u80fd\u529b\u3001\u4eba\u624d\u3002\u63d0\u51fa\u4e86\u5177\u6709\u53ef\u63a8\u5e7f\u6027\u7684\u7ecf\u9a8c\u6559\u8bad\uff0c\u5e76\u8054\u7cfb\u73b0\u4ee3\u56fd\u5bb6\u5e94\u7528AI\u52a0\u901f\u79d1\u5b66\u7ade\u4e89\u529b\u7684\u6218\u7565\u5236\u5b9a\u3002", "conclusion": "\u901a\u8fc7\u591a\u56fd\u65e9\u671f\u6570\u503c\u5929\u6c14\u9884\u62a5\u7684\u6bd4\u8f83\u5386\u53f2\u5206\u6790\uff0c\u6307\u51fa\u4e86\u6253\u9020\u5f3a\u5927\u79d1\u5b66\u6280\u672f\u5b9e\u529b\uff08\u4e09\u5927\u5173\u952e\u56e0\u7d20\uff09\u7684\u5fc5\u8981\u6027\uff0c\u8fd9\u5bf9\u5f53\u4eca\u5236\u5b9aAI\u52a0\u901f\u79d1\u5b66\u521b\u65b0\u7684\u56fd\u5bb6\u6218\u7565\u5177\u6709\u501f\u9274\u610f\u4e49\u3002"}}
{"id": "2506.21556", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.21556", "abs": "https://arxiv.org/abs/2506.21556", "authors": ["Hyeongcheol Park", "MinHyuk Jang", "Ha Dam Baek", "Gyusam Chang", "Jiyoung Seo", "Jiwan Park", "Hogun Park", "Sangpil Kim"], "title": "VAT-KG: Knowledge-Intensive Multimodal Knowledge Graph Dataset for Retrieval-Augmented Generation", "comment": "Project Page: https://vatkg.github.io/", "summary": "Multimodal Knowledge Graphs (MMKGs), which represent explicit knowledge\nacross multiple modalities, play a pivotal role by complementing the implicit\nknowledge of Multimodal Large Language Models (MLLMs) and enabling more\ngrounded reasoning via Retrieval Augmented Generation (RAG). However, existing\nMMKGs are generally limited in scope: they are often constructed by augmenting\npre-existing knowledge graphs, which restricts their knowledge, resulting in\noutdated or incomplete knowledge coverage, and they often support only a narrow\nrange of modalities, such as text and visual information. These limitations\nreduce their extensibility and applicability to a broad range of multimodal\ntasks, particularly as the field shifts toward richer modalities such as video\nand audio in recent MLLMs. Therefore, we propose the Visual-Audio-Text\nKnowledge Graph (VAT-KG), the first concept-centric and knowledge-intensive\nmultimodal knowledge graph that covers visual, audio, and text information,\nwhere each triplet is linked to multimodal data and enriched with detailed\ndescriptions of concepts. Specifically, our construction pipeline ensures\ncross-modal knowledge alignment between multimodal data and fine-grained\nsemantics through a series of stringent filtering and alignment steps, enabling\nthe automatic generation of MMKGs from any multimodal dataset. We further\nintroduce a novel multimodal RAG framework that retrieves detailed\nconcept-level knowledge in response to queries from arbitrary modalities.\nExperiments on question answering tasks across various modalities demonstrate\nthe effectiveness of VAT-KG in supporting MLLMs, highlighting its practical\nvalue in unifying and leveraging multimodal knowledge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVAT-KG\uff0c\u4e00\u79cd\u8986\u76d6\u89c6\u89c9\u3001\u97f3\u9891\u548c\u6587\u672c\uff0c\u652f\u6301\u9ad8\u8d28\u91cf\u77e5\u8bc6\u5bf9\u9f50\u548c\u751f\u6210\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u95ee\u7b54\u7b49\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u63a8\u52a8\u4e86\u591a\u6a21\u6001\u77e5\u8bc6\u7684\u7edf\u4e00\u5229\u7528\u3002", "motivation": "\u76ee\u524d\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\uff08MMKGs\uff09\u5b58\u5728\u77e5\u8bc6\u8986\u76d6\u9762\u6709\u9650\u3001\u77e5\u8bc6\u66f4\u65b0\u8fc7\u6162\u4ee5\u53ca\u53ea\u652f\u6301\u72ed\u7a84\u6a21\u6001\uff08\u5982\u6587\u672c\u548c\u56fe\u50cf\uff09\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u6ee1\u8db3\u65b0\u5174\u591a\u6a21\u6001\uff08\u5305\u62ec\u89c6\u9891\u3001\u97f3\u9891\uff09\u7684\u5e94\u7528\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u5e76\u6784\u5efa\u4e86Visual-Audio-Text Knowledge Graph\uff08VAT-KG\uff09\uff0c\u6db5\u76d6\u89c6\u89c9\u3001\u97f3\u9891\u4e0e\u6587\u672c\u77e5\u8bc6\uff0c\u5e76\u91c7\u7528\u4e25\u683c\u7684\u8fc7\u6ee4\u4e0e\u5bf9\u9f50\u6d41\u7a0b\uff0c\u81ea\u52a8\u4ece\u4efb\u610f\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e2d\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u77e5\u8bc6\u56fe\u8c31\u3002\u6bcf\u4e2a\u4e09\u5143\u7ec4\u90fd\u4e0e\u591a\u6a21\u6001\u6570\u636e\u5173\u8054\uff0c\u5e76\u6709\u8be6\u7ec6\u6982\u5ff5\u63cf\u8ff0\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u65b0\u7684\u591a\u6a21\u6001RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u6846\u67b6\uff0c\u53ef\u652f\u6301\u4efb\u610f\u6a21\u6001\u7684\u67e5\u8be2\u5e76\u68c0\u7d22\u5230\u8be6\u7ec6\u7684\u6982\u5ff5\u7ea7\u77e5\u8bc6\u3002", "result": "\u5728\u591a\u79cd\u6a21\u6001\u7684\u95ee\u9898\u56de\u7b54\u4efb\u52a1\u4e0a\uff0cVAT-KG\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08MLLMs\uff09\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u7edf\u4e00\u548c\u5145\u5206\u5229\u7528\u591a\u6a21\u6001\u77e5\u8bc6\u65b9\u9762\u7684\u5b9e\u9645\u4ef7\u503c\u3002", "conclusion": "VAT-KG\u662f\u9996\u4e2a\u6982\u5ff5\u4e3a\u4e2d\u5fc3\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u3001\u6db5\u76d6\u89c6\u89c9\u3001\u97f3\u9891\u53ca\u6587\u672c\u4fe1\u606f\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\uff0c\u4e0d\u4ec5\u6269\u5c55\u4e86\u77e5\u8bc6\u8986\u76d6\uff0c\u8fd8\u589e\u5f3a\u4e86\u591a\u6a21\u6001\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.21734", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21734", "abs": "https://arxiv.org/abs/2506.21734", "authors": ["Guan Wang", "Jin Li", "Yuhao Sun", "Xing Chen", "Changling Liu", "Yue Wu", "Meng Lu", "Sen Song", "Yasin Abbasi Yadkori"], "title": "Hierarchical Reasoning Model", "comment": null, "summary": "Reasoning, the process of devising and executing complex goal-oriented action\nsequences, remains a critical challenge in AI. Current large language models\n(LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from\nbrittle task decomposition, extensive data requirements, and high latency.\nInspired by the hierarchical and multi-timescale processing in the human brain,\nwe propose the Hierarchical Reasoning Model (HRM), a novel recurrent\narchitecture that attains significant computational depth while maintaining\nboth training stability and efficiency. HRM executes sequential reasoning tasks\nin a single forward pass without explicit supervision of the intermediate\nprocess, through two interdependent recurrent modules: a high-level module\nresponsible for slow, abstract planning, and a low-level module handling rapid,\ndetailed computations. With only 27 million parameters, HRM achieves\nexceptional performance on complex reasoning tasks using only 1000 training\nsamples. The model operates without pre-training or CoT data, yet achieves\nnearly perfect performance on challenging tasks including complex Sudoku\npuzzles and optimal path finding in large mazes. Furthermore, HRM outperforms\nmuch larger models with significantly longer context windows on the Abstraction\nand Reasoning Corpus (ARC), a key benchmark for measuring artificial general\nintelligence capabilities. These results underscore HRM's potential as a\ntransformative advancement toward universal computation and general-purpose\nreasoning systems.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u4eff\u8111\u5206\u5c42\u9012\u5f52\u63a8\u7406\u67b6\u6784HRM\uff0c\u80fd\u4ee5\u6781\u5c11\u6837\u672c\u3001\u65e0\u9700\u9884\u8bad\u7ec3\u9ad8\u6548\u5b8c\u6210\u590d\u6742\u63a8\u7406\u4efb\u52a1\uff0c\u5728\u4e3b\u6d41AI\u63a8\u7406\u57fa\u51c6\u4e0a\u5927\u5e45\u8d85\u8d8a\u66f4\u5927\u73b0\u6709\u6a21\u578b\uff0c\u8868\u660e\u5176\u5177\u5907\u5b9e\u73b0\u901a\u7528\u63a8\u7406\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u4e3b\u8981\u4f9d\u8d56Chain-of-Thought\uff08CoT\uff09\u6280\u672f\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5728\u4efb\u52a1\u5206\u89e3\u3001\u6570\u636e\u9700\u6c42\u548c\u5ef6\u8fdf\u7b49\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002\u53d7\u5230\u4eba\u8111\u5206\u5c42\u5904\u7406\u673a\u5236\u7684\u542f\u53d1\uff0c\u4f5c\u8005\u5e0c\u671b\u63d0\u51fa\u4e00\u79cd\u66f4\u9ad8\u6548\u7a33\u5b9a\u7684\u63a8\u7406\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u5206\u5c42\u9012\u5f52\u7ed3\u6784\u2014\u2014Hierarchical Reasoning Model\uff08HRM\uff09\uff0c\u5305\u62ec\u9ad8\u5c42\u62bd\u8c61\u89c4\u5212\u6a21\u5757\u548c\u4f4e\u5c42\u7ec6\u8282\u8ba1\u7b97\u6a21\u5757\uff0c\u4ee5\u9012\u5f52\u4ea4\u4e92\u65b9\u5f0f\u534f\u540c\u5b8c\u6210\u63a8\u7406\u4efb\u52a1\u3002\u6a21\u578b\u5728\u5355\u6b21\u524d\u5411\u4f20\u9012\u4e2d\u5b8c\u6210\u63a8\u7406\uff0c\u65e0\u9700\u663e\u5f0f\u76d1\u7763\u4e2d\u95f4\u8fc7\u7a0b\u3002\u6a21\u578b\u53c2\u6570\u91cf\u4e3a2700\u4e07\uff0c\u65e0\u9700\u9884\u8bad\u7ec3\u548cCoT\u6570\u636e\uff0c\u4ec5\u75281000\u4e2a\u8bad\u7ec3\u6837\u672c\u5c31\u80fd\u5b66\u4e60\u63a8\u7406\u4efb\u52a1\u3002", "result": "HRM\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\uff08\u5982\u96be\u5ea6\u8f83\u9ad8\u7684\u6570\u72ec\u548c\u5927\u578b\u8ff7\u5bab\u4e2d\u6700\u4f18\u8def\u5f84\u67e5\u627e\uff09\u4e0a\u8868\u73b0\u51fa\u6781\u9ad8\u6027\u80fd\uff0c\u51e0\u4e4e\u8fbe\u5230\u5b8c\u7f8e\u3002\u5e76\u4e14\u5728Abstraction and Reasoning Corpus (ARC)\u8fd9\u4e00\u91cd\u8981\u901a\u7528\u667a\u80fd\u57fa\u51c6\u4e0a\uff0cHRM\u663e\u8457\u4f18\u4e8e\u4f53\u79ef\u66f4\u5927\u4e14\u4e0a\u4e0b\u6587\u7a97\u53e3\u66f4\u957f\u7684\u5f53\u524d\u6700\u4f18\u6a21\u578b\u3002", "conclusion": "HRM\u6a21\u578b\u4e3a\u901a\u7528\u8ba1\u7b97\u548c\u901a\u7528\u63a8\u7406\u7cfb\u7edf\u5e26\u6765\u4e86\u53d8\u9769\u6027\u8fdb\u6b65\uff0c\u5c55\u793a\u4e86\u5728\u9ad8\u6548\u3001\u7a33\u5b9a\u3001\u5c11\u6837\u672c\u7684\u524d\u63d0\u4e0b\u5b8c\u6210\u590d\u6742\u63a8\u7406\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2506.21818", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.21818", "abs": "https://arxiv.org/abs/2506.21818", "authors": ["Meina Zhu", "Lanyu Xu", "Barbara Ericson"], "title": "A systematic review of research on large language models for computer programming education", "comment": "41 pages except references, 7 figures, 3 tables, a systematic review\n  paper", "summary": "Given the increasing demands in computer programming education and the rapid\nadvancement of large language models (LLMs), LLMs play a critical role in\nprogramming education. This study provides a systematic review of selected\nempirical studies on LLMs in computer programming education, published from\n2023 to March 2024. The data for this review were collected from Web of Science\n(SCI/SSCI), SCOPUS, and EBSCOhost databases, as well as three conference\nproceedings specialized in computer programming education. In total, 42 studies\nmet the selection criteria and were reviewed using methods, including\nbibliometric analysis, thematic analysis, and structural topic modeling. This\nstudy offers an overview of the current state of LLMs in computer programming\neducation research. It outlines LLMs' applications, benefits, limitations,\nconcerns, and implications for future research and practices, establishing\nconnections between LLMs and their practical use in computer programming\neducation. This review also provides examples and valuable insights for\ninstructional designers, instructors, and learners. Additionally, a conceptual\nframework is proposed to guide education practitioners in integrating LLMs into\ncomputer programming education. This study suggests future research directions\nfrom various perspectives, emphasizing the need to expand research methods and\ntopics in computer programming education as LLMs evolve. Additionally, future\nresearch in the field should incorporate collaborative, interdisciplinary, and\ntransdisciplinary efforts on a large scale, focusing on longitudinal research\nand development initiatives.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8ba1\u7b97\u673a\u7f16\u7a0b\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\u3001\u4f18\u52bf\u4e0e\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5e76\u4e3a\u5b9e\u9645\u6559\u5b66\u63d0\u4f9b\u4e86\u6982\u5ff5\u6846\u67b6\u548c\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u673a\u7f16\u7a0b\u6559\u80b2\u9700\u6c42\u7684\u589e\u52a0\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5feb\u901f\u53d1\u5c55\uff0cLLMs\u5728\u7f16\u7a0b\u6559\u80b2\u4e2d\u53d1\u6325\u7740\u91cd\u8981\u4f5c\u7528\u3002", "method": "\u7cfb\u7edf\u6027\u7efc\u8ff02023\u5e74\u52302024\u5e743\u6708\u53d1\u8868\u7684\u6709\u5173LLMs\u5728\u7f16\u7a0b\u6559\u80b2\u4e2d\u5e94\u7528\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u6570\u636e\u6765\u81eaWeb of Science\u3001SCOPUS\u3001EBSCOhost\u7b49\u6570\u636e\u5e93\u53ca\u4e09\u4e2a\u4e13\u95e8\u7684\u7f16\u7a0b\u6559\u80b2\u4f1a\u8bae\u8bba\u6587\u96c6\u3002\u91c7\u7528\u6587\u732e\u8ba1\u91cf\u5206\u6790\u3001\u4e3b\u9898\u5206\u6790\u548c\u7ed3\u6784\u5316\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u5bf942\u7bc7\u7b26\u5408\u6807\u51c6\u7684\u6587\u732e\u8fdb\u884c\u8bc4\u5ba1\u3002", "result": "\u603b\u7ed3\u4e86LLMs\u5728\u7f16\u7a0b\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u3001\u4f18\u52bf\u3001\u5c40\u9650\u6027\u53ca\u76f8\u5173\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u76f8\u5173\u672a\u6765\u7814\u7a76\u65b9\u5411\uff1b\u6784\u5efa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\uff0c\u4e3a\u6559\u80b2\u5b9e\u8df5\u8005\u6574\u5408LLMs\u4e8e\u7f16\u7a0b\u6559\u80b2\u63d0\u4f9b\u6307\u5bfc\uff0c\u5e76\u4e3a\u6559\u5b66\u8bbe\u8ba1\u8005\u3001\u6559\u5e08\u548c\u5b66\u4e60\u8005\u63d0\u4f9b\u5b9e\u8df5\u793a\u4f8b\u548c\u5efa\u8bae\u3002", "conclusion": "LLMs\u5df2\u6210\u4e3a\u7f16\u7a0b\u6559\u80b2\u9886\u57df\u7684\u91cd\u8981\u5de5\u5177\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u542f\u793a\u548c\u6846\u67b6\uff0c\u5f3a\u8c03\u8de8\u5b66\u79d1\u3001\u5927\u89c4\u6a21\u548c\u7eb5\u5411\u7684\u5408\u4f5c\u7814\u7a76\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.21557", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.21557", "abs": "https://arxiv.org/abs/2506.21557", "authors": ["Kaiying Yan", "Moyang Liu", "Yukun Liu", "Ruibo Fu", "Zhengqi Wen", "Jianhua Tao", "Xuefei Liu"], "title": "Debunk and Infer: Multimodal Fake News Detection via Diffusion-Generated Evidence and LLM Reasoning", "comment": null, "summary": "The rapid spread of fake news across multimedia platforms presents serious\nchallenges to information credibility. In this paper, we propose a\nDebunk-and-Infer framework for Fake News Detection(DIFND) that leverages\ndebunking knowledge to enhance both the performance and interpretability of\nfake news detection. DIFND integrates the generative strength of conditional\ndiffusion models with the collaborative reasoning capabilities of multimodal\nlarge language models (MLLMs). Specifically, debunk diffusion is employed to\ngenerate refuting or authenticating evidence based on the multimodal content of\nnews videos, enriching the evaluation process with diverse yet semantically\naligned synthetic samples. To improve inference, we propose a chain-of-debunk\nstrategy where a multi-agent MLLM system produces logic-grounded,\nmultimodal-aware reasoning content and final veracity judgment. By jointly\nmodeling multimodal features, generative debunking cues, and reasoning-rich\nverification within a unified architecture, DIFND achieves notable improvements\nin detection accuracy. Extensive experiments on the FakeSV and FVC datasets\nshow that DIFND not only outperforms existing approaches but also delivers\ntrustworthy decisions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7ed3\u5408\u751f\u6210\u6a21\u578b\u548c\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u5047\u65b0\u95fb\u68c0\u6d4b\u65b9\u6cd5DIFND\uff0c\u80fd\u57fa\u4e8e\u65b0\u95fb\u89c6\u9891\u5185\u5bb9\u751f\u6210\u53cd\u9a73\u8bc1\u636e\uff0c\u5e76\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u63a8\u7406\u63d0\u5347\u68c0\u6d4b\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660eDIFND\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u53ef\u4fe1\u5ea6\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u5047\u65b0\u95fb\u5728\u591a\u5a92\u4f53\u5e73\u53f0\u4e0a\u7684\u8fc5\u901f\u4f20\u64ad\uff0c\u4fe1\u606f\u53ef\u4fe1\u5ea6\u9762\u4e34\u4e25\u91cd\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u68c0\u6d4b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u4ecd\u6709\u5f88\u5927\u63d0\u5347\u7a7a\u95f4\u3002", "method": "\u63d0\u51fa\u4e86DIFND\uff08Debunk-and-Infer framework for Fake News Detection\uff09\u65b9\u6cd5\uff0c\u5c06\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u80fd\u529b\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u63a8\u7406\u80fd\u529b\u76f8\u7ed3\u5408\u3002\u901a\u8fc7debunk diffusion\u751f\u6210\u4e0e\u65b0\u95fb\u89c6\u9891\u591a\u6a21\u6001\u5185\u5bb9\u76f8\u5173\u7684\u53cd\u9a73\u6216\u4f50\u8bc1\u8bc1\u636e\uff0c\u5e76\u5f15\u5165chain-of-debunk\u7b56\u7565\uff0c\u7531\u591a\u667a\u80fd\u4f53MLLM\u7cfb\u7edf\u4ea7\u51fa\u903b\u8f91\u4e25\u5bc6\u3001\u591a\u6a21\u6001\u611f\u77e5\u7684\u63a8\u7406\u5185\u5bb9\u4e0e\u771f\u5b9e\u6027\u5224\u65ad\u3002\u5728\u7edf\u4e00\u67b6\u6784\u4e0b\u8054\u5408\u5efa\u6a21\u591a\u6a21\u6001\u7279\u5f81\u3001\u751f\u6210\u5f0f\u53cd\u9a73\u7ebf\u7d22\u4e0e\u63a8\u7406\u9a8c\u8bc1\u3002", "result": "DIFND\u5728FakeSV\u548cFVC\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u68c0\u6d4b\u51c6\u786e\u7387\u660e\u663e\u4f18\u4e8e\u5df2\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u80fd\u591f\u63d0\u4f9b\u66f4\u53ef\u4fe1\u7684\u51b3\u7b56\u3002", "conclusion": "DIFND\u901a\u8fc7\u5f15\u5165\u751f\u6210\u5f0f\u53cd\u9a73\u4e0e\u591a\u6a21\u6001\u63a8\u7406\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5047\u65b0\u95fb\u68c0\u6d4b\u7684\u51c6\u786e\u7387\u548c\u51b3\u7b56\u53ef\u4fe1\u5ea6\uff0c\u5e76\u589e\u5f3a\u4e86\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.21763", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21763", "abs": "https://arxiv.org/abs/2506.21763", "authors": ["Xin Wang", "Jiyao Liu", "Yulong Xiao", "Junzhi Ning", "Lihao Liu", "Junjun He", "Botian Shi", "Kaicheng Yu"], "title": "THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?", "comment": null, "summary": "Large Language Models (LLMs) are accelerating scientific idea generation, but\nrigorously evaluating these numerous, often superficial, AI-generated\npropositions for novelty and factual accuracy is a critical bottleneck; manual\nverification is too slow.Existing validation methods are inadequate: LLMs as\nstandalone verifiers may hallucinate and lack domain knowledge (our findings\nshow ~60\\% unawareness of relevant papers in specific domains), while\ntraditional citation networks lack explicit causality and narrative surveys are\nunstructured.This underscores a core challenge: the absence of structured,\nverifiable, and causally-linked historical data of scientific evolution.To\naddress this,we introduce \\textbf{THE-Tree} (\\textbf{T}echnology\n\\textbf{H}istory \\textbf{E}volution Tree), a computational framework that\nconstructs such domain-specific evolution trees from scientific\nliterature.THE-Tree employs a search algorithm to explore evolutionary paths.\nDuring its node expansion, it utilizes a novel \"Think-Verbalize-Cite-Verify\"\nprocess: an LLM proposes potential advancements and cites supporting\nliterature. Critically, each proposed evolutionary link is then validated for\nlogical coherence and evidential support by a recovered natural language\ninference mechanism that interrogates the cited literature, ensuring that each\nstep is grounded.We construct and validate 88 THE-Trees across diverse domains\nand release a benchmark dataset including up to 71k fact verifications covering\n27k papers to foster further research.Experiments demonstrate that i) in graph\ncompletion, our THE-Tree improves hit@1 by 8\\% to 14\\% across multiple models\ncompared to traditional citation networks; ii) for predicting future scientific\ndevelopments, it improves hit@1 metric by nearly 10\\%; and iii) when combined\nwith other methods, it boosts the performance of evaluating important\nscientific papers by almost 100\\%.", "AI": {"tldr": "\u63d0\u51faTHE-Tree\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u65b9\u6cd5\u6784\u5efa\u548c\u9a8c\u8bc1\u79d1\u5b66\u6f14\u5316\u8def\u5f84\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u79d1\u5b66\u4e8b\u5b9e\u9a8c\u8bc1\u548c\u91cd\u8981\u6210\u679c\u53d1\u73b0\u7684\u51c6\u786e\u6027\uff0c\u5728\u591a\u4e2a\u6307\u6807\u548c\u5e94\u7528\u573a\u666f\u4e0a\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u516c\u5f00\u6570\u636e\u96c6\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u79d1\u5b66\u521b\u610f\u751f\u6210\u4e2d\u4f5c\u7528\u65e5\u76ca\u589e\u5f3a\uff0c\u4f46\u5176\u4ea7\u751f\u7684\u5927\u91cf\u5efa\u8bae\u5f80\u5f80\u96be\u4ee5\u88ab\u5feb\u901f\u3001\u51c6\u786e\u5730\u9a8c\u8bc1\u65b0\u9896\u6027\u4e0e\u4e8b\u5b9e\u6027\u3002\u624b\u5de5\u9a8c\u8bc1\u6548\u7387\u4f4e\u4e0b\uff0cLLMs\u81ea\u884c\u9a8c\u8bc1\u53c8\u5e38\u51fa\u73b0\u5e7b\u89c9\u4e14\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\uff0c\u73b0\u6709\u5f15\u7528\u7f51\u7edc\u548c\u53d9\u8ff0\u7efc\u8ff0\u4e5f\u96be\u4ee5\u7ed3\u6784\u5316\u548c\u56e0\u679c\u5316\u5448\u73b0\u79d1\u5b66\u6f14\u5316\u5386\u7a0b\uff0c\u56e0\u6b64\u4e9f\u9700\u9ad8\u6548\u3001\u7ed3\u6784\u5316\u9a8c\u8bc1\u79d1\u5b66\u8fdb\u6b65\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86THE-Tree\uff08\u79d1\u6280\u5386\u53f2\u6f14\u5316\u6811\uff09\u6846\u67b6\uff0c\u4ece\u79d1\u5b66\u6587\u732e\u6784\u5efa\u7ed3\u6784\u5316\u7684\u9886\u57df\u6f14\u5316\u6811\u3002\u901a\u8fc7\u641c\u7d22\u7b97\u6cd5\u63a2\u7d22\u6f14\u5316\u8def\u5f84\uff0c\u6bcf\u6b65\u7528\u201c\u601d\u8003-\u9610\u8ff0-\u5f15\u7528-\u9a8c\u8bc1\u201d\u6d41\u7a0b\uff1aLLM\u63d0\u51fa\u53ef\u80fd\u8fdb\u5c55\u5e76\u5f15\u7528\u6587\u732e\uff0c\u7136\u540e\u501f\u52a9\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u673a\u5236\u68c0\u9a8c\u903b\u8f91\u4e00\u81f4\u6027\u548c\u6587\u732e\u8bc1\u636e\uff0c\u4ece\u800c\u786e\u4fdd\u6bcf\u4e00\u6f14\u5316\u94fe\u63a5\u6709\u636e\u53ef\u4f9d\u3002\u5e76\u5728\u591a\u4e2a\u9886\u57df\u6784\u5efa\u548c\u9a8c\u8bc1\u4e8688\u68f5THE-Tree\u548c\u914d\u5957\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "THE-Tree\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u79d1\u5b66\u6f14\u5316\u7684\u56e0\u679c\u548c\u7ed3\u6784\u5316\u8868\u8fbe\u3002\u5728\u56fe\u8865\u5168\u4efb\u52a1\u4e2d\uff0cTHE-Tree\u6bd4\u4f20\u7edf\u5f15\u7528\u7f51\u7edc\u5728\u591a\u6a21\u578b\u4e0bhit@1\u63d0\u53478%-14%\uff1b\u5728\u9884\u6d4b\u79d1\u5b66\u8fdb\u5c55\u4e0a\uff0c\u63d0\u5347\u8fd110%\uff1b\u4e0e\u5176\u4ed6\u65b9\u6cd5\u7ed3\u5408\u540e\uff0c\u53ef\u4ee5\u4f7f\u91cd\u8981\u8bba\u6587\u8bc4\u4ef7\u6027\u80fd\u63d0\u9ad8\u63a5\u8fd1\u4e00\u500d\u3002", "conclusion": "THE-Tree\u4e3a\u79d1\u5b66\u6f14\u8fdb\u548c\u6587\u732e\u5173\u7cfb\u63d0\u4f9b\u4e86\u53ef\u9a8c\u8bc1\u3001\u7ed3\u6784\u5316\u548c\u56e0\u679c\u5173\u8054\u7684\u65b0\u89c6\u89d2\uff0c\u7a81\u7834\u4e86\u73b0\u6709LLM\u548c\u5f15\u7528\u7f51\u7edc\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u7684\u79d1\u5b66\u6d1e\u89c1\u9a8c\u8bc1\u548c\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u5e76\u5411\u793e\u533a\u63d0\u4f9b\u6570\u636e\u548c\u57fa\u51c6\u4ee5\u63a8\u52a8\u8be5\u65b9\u5411\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.21825", "categories": ["cs.CY", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.21825", "abs": "https://arxiv.org/abs/2506.21825", "authors": ["Abdulkareem Alsudais"], "title": "Exploring the change in scientific readability following the release of ChatGPT", "comment": null, "summary": "The rise and growing popularity of accessible large language models have\nraised questions about their impact on various aspects of life, including how\nscientists write and publish their research. The primary objective of this\npaper is to analyze a dataset consisting of all abstracts posted on arXiv.org\nbetween 2010 and June 7th, 2024, to assess the evolution of their readability\nand determine whether significant shifts occurred following the release of\nChatGPT in November 2022. Four standard readability formulas are used to\ncalculate individual readability scores for each paper, classifying their level\nof readability. These scores are then aggregated by year and across the eight\nprimary categories covered by the platform. The results show a steady annual\ndecrease in readability, suggesting that abstracts are likely becoming\nincreasingly complex. Additionally, following the release of ChatGPT, a\nsignificant change in readability is observed for 2023 and the analyzed months\nof 2024. Similar trends are found across categories, with most experiencing a\nnotable change in readability during 2023 and 2024. These findings offer\ninsights into the broader changes in readability and point to the likely\ninfluence of AI on scientific writing.", "AI": {"tldr": "\u4f5c\u8005\u901a\u8fc7\u5927\u89c4\u6a21\u6570\u636e\u5206\u6790\u53d1\u73b0\uff0carXiv\u8bba\u6587\u6458\u8981\u7684\u53ef\u8bfb\u6027\u8fd1\u5e74\u663e\u8457\u4e0b\u964d\uff0c\u5c24\u5176\u5728ChatGPT\u7b49AI\u5de5\u5177\u666e\u53ca\u540e\u51fa\u73b0\u660e\u663e\u53d8\u5316\uff0c\u63d0\u793aAI\u6b63\u5728\u6df1\u523b\u5f71\u54cd\u79d1\u7814\u5199\u4f5c\u65b9\u5f0f\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982ChatGPT\uff09\u7684\u666e\u53ca\uff0c\u5f15\u53d1\u4e86\u4eba\u4eec\u5bf9\u4e8e\u5176\u5bf9\u79d1\u5b66\u8bba\u6587\u5199\u4f5c\u53ca\u53d1\u8868\u5e26\u6765\u5f71\u54cd\u7684\u5173\u6ce8\u3002\u8be5\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u5728\u5927\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u53ef\u7528\u540e\uff0c\u5b66\u672f\u8bba\u6587\u6458\u8981\u7684\u53ef\u8bfb\u6027\u662f\u5426\u53d1\u751f\u4e86\u660e\u663e\u53d8\u5316\u3002", "method": "\u4f5c\u8005\u5206\u6790\u4e862010\u5e74\u81f32024\u5e746\u67087\u65e5\u671f\u95f4\u6240\u6709\u53d1\u5e03\u5728arXiv.org\u4e0a\u7684\u8bba\u6587\u6458\u8981\uff0c\u4f7f\u7528\u56db\u79cd\u6807\u51c6\u53ef\u8bfb\u6027\u516c\u5f0f\u4e3a\u6bcf\u7bc7\u6458\u8981\u8ba1\u7b97\u53ef\u8bfb\u6027\u5f97\u5206\uff0c\u5e76\u6309\u5e74\u4efd\u53caarXiv\u7684\u516b\u5927\u4e3b\u8981\u5206\u7c7b\u8fdb\u884c\u805a\u5408\u5206\u6790\uff0c\u91cd\u70b9\u8003\u5bdfChatGPT\u53d1\u5e03\u524d\u540e\uff082022\u5e7411\u6708\uff09\u53ef\u8bfb\u6027\u7684\u53d8\u5316\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u8bba\u6587\u6458\u8981\u7684\u53ef\u8bfb\u6027\u9010\u5e74\u4e0b\u964d\uff0c\u8bf4\u660e\u6458\u8981\u53d8\u5f97\u66f4\u52a0\u590d\u6742\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0cChatGPT\u53d1\u5e03\u540e\uff0c2023\u5e74\u53ca2024\u5e74\u53ef\u8bfb\u6027\u53d1\u751f\u4e86\u663e\u8457\u53d8\u5316\uff0c\u591a\u6570\u5b66\u79d1\u7c7b\u522b\u5728\u8fd9\u4e24\u5e74\u51fa\u73b0\u4e86\u53ef\u8bfb\u6027\u5927\u53d8\u52a8\u3002", "conclusion": "\u8bba\u6587\u8ba4\u4e3a\uff0c\u79d1\u5b66\u8bba\u6587\u6458\u8981\u7684\u53ef\u8bfb\u6027\u8fd1\u5e74\u7a33\u6b65\u4e0b\u964d\uff0cChatGPT\u7b49AI\u5de5\u5177\u7684\u666e\u53ca\u53ef\u80fd\u52a0\u901f\u6216\u5f71\u54cd\u4e86\u8fd9\u4e00\u53d8\u5316\u8d8b\u52bf\u3002\u7814\u7a76\u63ed\u793a\u4e86AI\u5bf9\u5b66\u672f\u5199\u4f5c\u98ce\u683c\u548c\u590d\u6742\u5ea6\u7684\u6f5c\u5728\u5f71\u54cd\u3002"}}
{"id": "2506.21558", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21558", "abs": "https://arxiv.org/abs/2506.21558", "authors": ["FutureSearch", ":", "Jack Wildman", "Nikos I. Bosse", "Daniel Hnyk", "Peter M\u00fchlbacher", "Finn Hambly", "Jon Evans", "Dan Schwarz", "Lawrence Phillips"], "title": "Bench to the Future: A Pastcasting Benchmark for Forecasting Agents", "comment": null, "summary": "Forecasting is a challenging task that offers a clearly measurable way to\nstudy AI systems. Forecasting requires a large amount of research on the\ninternet, and evaluations require time for events to happen, making the\ndevelopment of forecasting benchmarks challenging. To date, no forecasting\nbenchmark provides a realistic, hermetic, and repeatable environment for LLM\nforecasters. We introduce Bench To the Future (BTF), a \"pastcasting\" benchmark\nwith hundreds of high-quality questions for which the resolution is already\nknown. Each question is accompanied by a large offline corpus of tens of\nthousands of relevant web pages, enabling a way to elicit realistic \"forecasts\"\non past events from LLMs. Results suggest that our pastcasting environment can\nproduce results comparable to those based on forecasts using the internet on\nat-the-time unresolved questions. We show results benchmarking agent and\nchain-of-thought forecasting approaches using several LLMs, including the\nrecently-released Claude 4 models, and demonstrate BTF's ability to track\nsteady forecasting capability progress over time. We intend this to be a living\nbenchmark, with new questions added continually to account for increasing\ntraining data cutoff dates. We invite researchers to contact us at\nhello@futuresearch.ai to utilize our benchmark or tooling for their own\nresearch.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faBTF\u57fa\u51c6\uff0c\u901a\u8fc7\u5386\u53f2\u4e8b\u4ef6\u2018pastcasting\u2019\u4efb\u52a1\uff0c\u6784\u5efa\u53ef\u590d\u73b0\u7684LLM\u9884\u6d4b\u8bc4\u6d4b\u73af\u5883\uff0c\u5e76\u5c55\u793a\u5176\u5b9e\u7528\u6027\u4e0e\u6a21\u578b\u8fdb\u6b65\u8ffd\u8e2a\u80fd\u529b\uff0c\u6709\u6548\u586b\u8865\u4e86\u9884\u6d4b\u8bc4\u4f30\u57fa\u51c6\u7684\u73b0\u5b9e\u7a7a\u767d\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63d0\u4f9b\u7684\u771f\u5b9e\u3001\u53ef\u63a7\u4e14\u53ef\u590d\u73b0\u7684\u9884\u6d4b\u8bc4\u6d4b\u57fa\u51c6\uff0c\u63d0\u51fa\u4e86\u9884\u6d4b\u4efb\u52a1\u4f5c\u4e3aAI\u7cfb\u7edf\u7814\u7a76\u548c\u8bc4\u4f30\u7684\u6311\u6218\u6027\u65b9\u5411\u3002\u4f20\u7edf\u57fa\u51c6\u53d7\u5b9e\u9645\u4e8b\u4ef6\u8fdb\u5c55\u9650\u5236\uff0c\u96be\u4ee5\u5feb\u901f\u3001\u5927\u89c4\u6a21\u5730\u68c0\u9a8c\u6a21\u578b\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u201cBench To the Future (BTF)\u201d\u57fa\u51c6\uff0c\u901a\u8fc7\u6784\u5efa\u2018pastcasting\u2019\u6846\u67b6\uff1a\u9488\u5bf9\u5df2\u77e5\u7ed3\u679c\u7684\u5386\u53f2\u4e8b\u4ef6\u63d0\u51fa\u9ad8\u8d28\u91cf\u95ee\u9898\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u95ee\u9898\u914d\u5957\u79bb\u7ebf\u7684\u5927\u89c4\u6a21\u76f8\u5173\u7f51\u9875\u6587\u672c\u8bed\u6599\uff0c\u8981\u6c42LLM\u57fa\u4e8e\u8be5\u8bed\u6599\u548c\u4e8b\u4ef6\u65f6\u95f4\u70b9\u505a\u51fa\u9884\u6d4b\u3002\u8bc4\u4f30\u591a\u79cdLLM\u5728agent\u548cchain-of-thought\u9884\u6d4b\u7b56\u7565\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u8bbe\u8ba1\u957f\u671f\u66f4\u65b0\u7684\u65b0\u95ee\u9898\u673a\u5236\u3002", "result": "BTF\u57fa\u51c6\u4e0b\uff0cLLM\u7684\u2018pastcasting\u2019\u9884\u6d4b\u6548\u679c\u4e0e\u4f20\u7edf\u57fa\u4e8e\u5b9e\u65f6\u4e92\u8054\u7f51\u7684\u9884\u6d4b\u65b9\u6cd5\u63a5\u8fd1\uff0c\u80fd\u591f\u6709\u6548\u8ffd\u8e2aLLM\u9884\u6d4b\u80fd\u529b\u7684\u8fdb\u6b65\u3002\u5b9e\u9a8c\u8bc1\u660eBTF\u9002\u7528\u4e8e\u4e0d\u540c\u6a21\u578b\uff08\u5982Claude 4\uff09\uff0c\u5e76\u5bf9\u8bc4\u4f30\u65b9\u6cd5\u5177\u6709\u826f\u597d\u53ef\u6269\u5c55\u6027\u4e0e\u6301\u7eed\u6027\u3002", "conclusion": "BTF\u9996\u521b\u6027\u5730\u5b9e\u73b0\u4e86\u5386\u53f2\u9884\u6d4b\u4efb\u52a1\u7684\u6807\u51c6\u5316\u548c\u53ef\u63a7\u8bc4\u6d4b\uff0c\u4e3aLLM\u9884\u6d4b\u80fd\u529b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u73b0\u5b9e\u4e14\u53ef\u590d\u73b0\u7684\u73af\u5883\uff0c\u53ef\u6301\u7eed\u8ffd\u8e2a\u6a21\u578b\u8fdb\u6b65\uff0c\u5e76\u5bf9AI\u9884\u6d4b\u7cfb\u7edf\u53d1\u5c55\u5177\u6709\u63a8\u52a8\u4f5c\u7528\u3002"}}
{"id": "2506.21784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21784", "abs": "https://arxiv.org/abs/2506.21784", "authors": ["Yifan Liu", "Xishun Liao", "Haoxuan Ma", "Jonathan Liu", "Rohan Jadhav", "Jiaqi Ma"], "title": "MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models", "comment": null, "summary": "Understanding and modeling human mobility patterns is crucial for effective\ntransportation planning and urban development. Despite significant advances in\nmobility research, there remains a critical gap in simulation platforms that\nallow for algorithm development, policy implementation, and comprehensive\nevaluation at scale. Traditional activity-based models require extensive data\ncollection and manual calibration, machine learning approaches struggle with\nadaptation to dynamic conditions, and treding agent-based Large Language Models\n(LLMs) implementations face computational constraints with large-scale\nsimulations. To address these challenges, we propose MobiVerse, a hybrid\nframework leverages the efficiency of lightweight domain-specific generator for\ngenerating base activity chains with the adaptability of LLMs for context-aware\nmodifications. A case study was conducted in Westwood, Los Angeles, where we\nefficiently generated and dynamically adjusted schedules for the whole\npopulation of approximately 53,000 agents on a standard PC. Our experiments\ndemonstrate that MobiVerse successfully enables agents to respond to\nenvironmental feedback, including road closures, large gathering events like\nfootball games, and congestion, through our hybrid framework. Its modular\ndesign facilitates testing various mobility algorithms at both transportation\nsystem and agent levels. Results show our approach maintains computational\nefficiency while enhancing behavioral realism. MobiVerse bridges the gap in\nmobility simulation by providing a customizable platform for mobility systems\nplanning and operations with benchmark algorithms. Code and videos are\navailable at https://github.com/ucla-mobility/MobiVerse.", "AI": {"tldr": "MobiVerse\u6846\u67b6\u7ed3\u5408\u751f\u6210\u5668\u4e0eLLM\uff0c\u9ad8\u6548\u3001\u771f\u5b9e\u5730\u6a21\u62df\u57ce\u5e02\u5927\u89c4\u6a21\u51fa\u884c\uff0c\u4e3a\u4ea4\u901a\u7814\u7a76\u548c\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u5f3a\u5927\u5e73\u53f0\u3002", "motivation": "\u5f53\u524d\u4eba\u7c7b\u51fa\u884c\u6a21\u5f0f\u7684\u5efa\u6a21\u5bf9\u4e8e\u4ea4\u901a\u89c4\u5212\u53ca\u57ce\u5e02\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7684\u6a21\u62df\u5e73\u53f0\u5b58\u5728\u4e0d\u8db3\u3002\u4f20\u7edf\u7684\u57fa\u4e8e\u884c\u4e3a\u7684\u6a21\u578b\u6570\u636e\u9700\u6c42\u5927\u4e14\u6807\u5b9a\u7e41\u7410\uff0c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u73af\u5883\uff0c\u5927\u89c4\u6a21LLM\u4ee3\u7406\u5b9e\u73b0\u8ba1\u7b97\u5f00\u9500\u8fc7\u5927\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u517c\u987e\u6548\u7387\u3001\u73af\u5883\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u65b0\u578b\u4eff\u771f\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86MobiVerse\uff0c\u4e00\u4e2a\u6df7\u5408\u5f0f\u6846\u67b6\uff1a\u901a\u8fc7\u8f7b\u91cf\u7ea7\u9886\u57df\u7279\u5b9a\u751f\u6210\u5668\u751f\u6210\u57fa\u7840\u6d3b\u52a8\u94fe\uff0c\u518d\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5b9e\u73b0\u60c5\u5883\u611f\u77e5\u7684\u9002\u5e94\u6027\u8c03\u6574\u3002\u6848\u4f8b\u7814\u7a76\u9009\u53d6\u6d1b\u6749\u77f6Westwood\u5730\u533a\uff0c\u5bf9\u7ea653,000\u4e2a\u4ee3\u7406\u8fdb\u884c\u4e86\u5168\u4f53\u65e5\u7a0b\u751f\u6210\u548c\u52a8\u6001\u8c03\u6574\uff0c\u8fd0\u884c\u4e8e\u666e\u901aPC\u4e0a\u3002", "result": "MobiVerse\u80fd\u591f\u4f7f\u667a\u80fd\u4f53\u6839\u636e\u73af\u5883\u53cd\u9988\uff08\u5982\u9053\u8def\u5c01\u95ed\u3001\u5927\u578b\u6d3b\u52a8\u3001\u62e5\u5835\u7b49\uff09\u52a8\u6001\u8c03\u6574\u51fa\u884c\u8ba1\u5212\uff0c\u5728\u4fdd\u8bc1\u8ba1\u7b97\u9ad8\u6548\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u884c\u4e3a\u4eff\u771f\u771f\u5b9e\u6027\u3002\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u652f\u6301\u591a\u79cd\u51fa\u884c\u7b97\u6cd5\u7684\u8bc4\u6d4b\u3002", "conclusion": "MobiVerse\u6709\u6548\u5f25\u8865\u4e86\u73b0\u6709\u51fa\u884c\u6a21\u62df\u5e73\u53f0\u4e2d\u6548\u7387\u4e0e\u9002\u5e94\u6027\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u6210\u4e3a\u53ef\u5b9a\u5236\u6027\u7684\u4eff\u771f\u5e73\u53f0\uff0c\u4e3a\u51fa\u884c\u7cfb\u7edf\u89c4\u5212\u548c\u8fd0\u7ef4\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.21946", "categories": ["cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21946", "abs": "https://arxiv.org/abs/2506.21946", "authors": ["Till Wenke"], "title": "Hitchhiking Rides Dataset: Two decades of crowd-sourced records on stochastic traveling", "comment": null, "summary": "Hitchhiking, a spontaneous and decentralized mode of travel, has long eluded\nsystematic study due to its informal nature. This paper presents and analyzes\nthe largest known structured dataset of hitchhiking rides, comprising over\n63,000 entries collected over nearly two decades through platforms associated\nwith hitchwiki.org and lately on hitchmap.com. By leveraging crowd-sourced\ncontributions, the dataset captures key spatiotemporal and strategic aspects of\nhitchhiking. This work documents the dataset's origins, evolution, and\ncommunity-driven maintenance, highlighting its Europe-centric distribution,\nseasonal patterns, and reliance on a small number of highly active\ncontributors. Through exploratory analyses, I examine waiting times, user\nbehavior, and comment metadata, shedding light on the lived realities of\nhitchhikers. While the dataset has inherent biases and limitations - such as\ndemographic skew and unverifiable entries it offers a rare and valuable window\ninto an alternative form of mobility. I conclude by outlining future directions\nfor enriching the dataset and advancing research on hitchhiking as both a\ntransportation practice and cultural phenomenon.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u5927\u89c4\u6a21\u4f17\u5305\u6570\u636e\u7cfb\u7edf\u5206\u6790\u4e86\u642d\u4fbf\u8f66\u73b0\u8c61\uff0c\u603b\u7ed3\u5176\u5206\u5e03\u3001\u884c\u4e3a\u7279\u5f81\u53ca\u5c40\u9650\uff0c\u4e3a\u7814\u7a76\u8fd9\u79cd\u53e6\u7c7b\u4ea4\u901a\u65b9\u5f0f\u63d0\u4f9b\u4e86\u575a\u5b9e\u6570\u636e\u57fa\u7840\u3002", "motivation": "\u642d\u4fbf\u8f66\u4f5c\u4e3a\u4e00\u79cd\u81ea\u53d1\u4e14\u53bb\u4e2d\u5fc3\u5316\u7684\u51fa\u884c\u65b9\u5f0f\uff0c\u56e0\u5176\u975e\u6b63\u5f0f\u6027\u800c\u96be\u4ee5\u7cfb\u7edf\u7814\u7a76\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u6570\u636e\u5316\u624b\u6bb5\u7cfb\u7edf\u523b\u753b\u548c\u5206\u6790\u642d\u4fbf\u8f66\u73b0\u8c61\u3002", "method": "\u4f5c\u8005\u6536\u96c6\u5e76\u5206\u6790\u4e86\u5168\u7403\u6700\u5927\u89c4\u6a21\u7684\u642d\u4fbf\u8f66\u6570\u636e\u96c6\uff0c\u6db5\u76d66.3\u4e07\u4f59\u6761\u8bb0\u5f55\uff0c\u4e3b\u8981\u6765\u81eahitchwiki.org\u548chitchmap.com\uff0c\u5229\u7528\u4f17\u5305\u6570\u636e\u6355\u6349\u65f6\u7a7a\u4e0e\u7b56\u7565\u8981\u7d20\uff0c\u5e76\u5bf9\u6570\u636e\u6e90\u3001\u7ef4\u62a4\u65b9\u5f0f\u548c\u793e\u533a\u884c\u4e3a\u505a\u4e86\u8be6\u7ec6\u8bb0\u5f55\u4e0e\u63a2\u7d22\u6027\u5206\u6790\u3002", "result": "\u6570\u636e\u96c6\u5448\u73b0\u6b27\u6d32\u4e3a\u4e2d\u5fc3\u3001\u5f3a\u70c8\u5b63\u8282\u6027\u3001\u5c11\u6570\u9ad8\u6d3b\u8dc3\u7528\u6237\u4e3a\u4e3b\u7b49\u7279\u70b9\u3002\u5206\u6790\u6d89\u53ca\u7b49\u8f66\u7b49\u5f85\u65f6\u95f4\u3001\u7528\u6237\u884c\u4e3a\u4e0e\u8bc4\u8bba\u7b49\uff0c\u53cd\u6620\u51fa\u642d\u4fbf\u8f66\u8005\u7684\u771f\u5b9e\u4f53\u9a8c\u3002\u5c3d\u7ba1\u5b58\u5728\u6837\u672c\u504f\u5dee\u548c\u771f\u5b9e\u6027\u96be\u4ee5\u9a8c\u8bc1\u7b49\u5c40\u9650\uff0c\u6570\u636e\u96c6\u4ecd\u5c55\u73b0\u4e86\u4e30\u5bcc\u7684\u53e6\u7c7b\u51fa\u884c\u4fe1\u606f\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u63a2\u7a76\u642d\u4fbf\u8f66\u4f5c\u4e3a\u4ea4\u901a\u5b9e\u8df5\u548c\u6587\u5316\u73b0\u8c61\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7a97\u53e3\u3002\u672a\u6765\u53ef\u7ee7\u7eed\u5b8c\u5584\u6570\u636e\u96c6\uff0c\u63a8\u52a8\u76f8\u5173\u5b66\u672f\u7814\u7a76\u3002"}}
{"id": "2506.21559", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.21559", "abs": "https://arxiv.org/abs/2506.21559", "authors": ["Junze Chen", "Cheng Yang", "Shujie Li", "Zhiqiang Zhang", "Yawen Li", "Junping Du", "Chuan Shi"], "title": "GraphLAMA: Enabling Efficient Adaptation of Graph Language Models with Limited Annotations", "comment": null, "summary": "Large language models (LLMs) have demonstrated their strong capabilities in\nvarious domains, and have been recently integrated for graph analysis as graph\nlanguage models (GLMs). With LLMs as the predictor, some GLMs can interpret\nunseen tasks described by natural language, and learn from a few examples in\nthe prompts without parameter tuning, known as in-context learning (ICL).\nAnother subset of GLMs utilizes abundant training labels to enhance model\nperformance, known as instruction tuning. However, we argue that ICL on graphs\nhas effectiveness issues due to fixed parameters and efficiency issues due to\nlong context. Meanwhile, the large amount of labeled data required for\ninstruction tuning can be difficult to obtain in real-world scenarios. To this\nend, we aim to introduce an extra parameter adaptation stage that can\nefficiently tailor GLMs to an unseen graph and task with only a few labeled\nexamples, in exchange for better prediction accuracy and faster inference\nspeed. For implementation, in this paper we propose GraphLAMA method, with its\nmodel backbone and learning schemes specialized for efficient tuning and\ninference. Specifically, for model backbone, we use a graph neural network\n(GNN) with several well-designed components to transform nodes into the\nrepresentation space of LLM tokens. Task instructions can then be represented\nas a mixture of node and language tokens. In the pre-training stage, model\nparameters except the LLM will be trained with different tasks to capture\ngeneral knowledge. In the adaptation stage, only a few pre-trained parameters\nwill be updated based on few-shot examples. Extensive experiments on\nfew/zero-shot node classification and summary generation show that our proposed\nGraphLAMA achieves state-of-the-art performance with 4.91% absolution\nimprovement in accuracy. Compared with ICL, our inference speed can be 10 times\nfaster under 5-shot setting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGraphLAMA\u65b9\u6cd5\uff0c\u4f7f\u56fe\u8bed\u8a00\u6a21\u578b\u5229\u7528\u5c11\u91cf\u6837\u4f8b\u5373\u53ef\u9ad8\u6548\u9002\u5e94\u65b0\u4efb\u52a1\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u51c6\u786e\u7387\u548c\u901f\u5ea6\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u56fe\u8bed\u8a00\u6a21\u578b\uff08GLMs\uff09\u5728\u56fe\u5206\u6790\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u4f46\u5176\u4e3b\u6d41\u65b9\u6cd5\u6709\u4e24\u5927\u95ee\u9898\uff1a\u57fa\u4e8ein-context learning\u7684\u6a21\u578b\u53d7\u9650\u4e8e\u53c2\u6570\u4e0d\u53ef\u53d8\u4e14\u63a8\u7406\u901f\u5ea6\u6162\uff0c\u57fa\u4e8einstruction tuning\u7684\u6a21\u578b\u5219\u53d7\u5236\u4e8e\u73b0\u5b9e\u4e2d\u96be\u4ee5\u83b7\u5f97\u5927\u91cf\u6807\u6ce8\u6570\u636e\u3002\u7814\u7a76\u8005\u56e0\u6b64\u5e0c\u671b\u63a2\u7d22\u66f4\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u8c03\u4f18\u65b9\u5f0f\uff0c\u80fd\u591f\u5229\u7528\u5c11\u91cf\u6807\u7b7e\u517c\u987e\u6027\u80fd\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faGraphLAMA\u65b9\u6cd5\u3002\u9996\u5148\uff0c\u4ee5\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u4e3a\u6a21\u578b\u9aa8\u5e72\uff0c\u5c06\u56fe\u8282\u70b9\u6620\u5c04\u5230LLM\u7684token\u8868\u793a\u7a7a\u95f4\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u7ec4\u4ef6\u652f\u6301\u56fe\u4e0e\u6587\u672c\u6307\u4ee4\u878d\u5408\u3002\u9884\u8bad\u7ec3\u9636\u6bb5\uff0c\u9664\u4e86LLM\u53c2\u6570\u5916\uff0c\u5176\u4ed6\u53c2\u6570\u901a\u8fc7\u591a\u4efb\u52a1\u8bad\u7ec3\u6355\u6349\u901a\u7528\u77e5\u8bc6\uff1b\u9002\u5e94\u9636\u6bb5\u4ec5\u5bf9\u90e8\u5206\u53c2\u6570\u5728\u5c11\u91cf\u6837\u4f8b\u57fa\u7840\u4e0a\u5c40\u90e8\u66f4\u65b0\uff0c\u5b9e\u73b0\u9ad8\u6548\u8c03\u4f18\u3002", "result": "GraphLAMA\u5728\u5c11\u6837\u672c/\u96f6\u6837\u672c\u8282\u70b9\u5206\u7c7b\u548c\u6458\u8981\u751f\u6210\u4efb\u52a1\u4e0a\u5747\u53d6\u5f97\u4e86\u6700\u4f18\u8868\u73b0\uff1a\u8282\u70b9\u5206\u7c7b\u51c6\u786e\u7387\u63d0\u53474.91%\uff0c\u63a8\u7406\u901f\u5ea6\u57285-shot\u60c5\u51b5\u4e0b\u6bd4in-context learning\u5feb10\u500d\u3002", "conclusion": "GraphLAMA\u80fd\u4ee5\u8f83\u5c11\u6807\u6ce8\u6837\u672c\uff0c\u5b9e\u73b0\u5bf9\u65b0\u56fe\u548c\u4efb\u52a1\u7684\u9ad8\u6548\u53c2\u6570\u9002\u5e94\uff0c\u63d0\u5347\u51c6\u786e\u7387\u53ca\u63a8\u7406\u901f\u5ea6\uff0c\u517c\u5177\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.21805", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.21805", "abs": "https://arxiv.org/abs/2506.21805", "authors": ["Nicolas Bougie", "Narimasa Watanabe"], "title": "CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation", "comment": null, "summary": "Modeling human behavior in urban environments is fundamental for social\nscience, behavioral studies, and urban planning. Prior work often rely on\nrigid, hand-crafted rules, limiting their ability to simulate nuanced\nintentions, plans, and adaptive behaviors. Addressing these challenges, we\nenvision an urban simulator (CitySim), capitalizing on breakthroughs in\nhuman-level intelligence exhibited by large language models. In CitySim, agents\ngenerate realistic daily schedules using a recursive value-driven approach that\nbalances mandatory activities, personal habits, and situational factors. To\nenable long-term, lifelike simulations, we endow agents with beliefs, long-term\ngoals, and spatial memory for navigation. CitySim exhibits closer alignment\nwith real humans than prior work, both at micro and macro levels. Additionally,\nwe conduct insightful experiments by modeling tens of thousands of agents and\nevaluating their collective behaviors under various real-world scenarios,\nincluding estimating crowd density, predicting place popularity, and assessing\nwell-being. Our results highlight CitySim as a scalable, flexible testbed for\nunderstanding and forecasting urban phenomena.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u57ce\u5e02\u6a21\u62df\u5668CitySim\uff0c\u4e3a\u865a\u62df\u667a\u80fd\u4f53\u8d4b\u4e88\u7c7b\u4eba\u884c\u4e3a\u548c\u8ba1\u5212\u80fd\u529b\u3002\u7cfb\u7edf\u80fd\u66f4\u771f\u5b9e\u5730\u6a21\u62df\u5927\u91cf\u5e02\u6c11\u5728\u57ce\u5e02\u4e2d\u7684\u65e5\u5e38\u4e0e\u7fa4\u4f53\u884c\u4e3a\uff0c\u4e3a\u7406\u89e3\u548c\u9884\u6d4b\u57ce\u5e02\u73b0\u8c61\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u7684\u90fd\u5e02\u4eba\u7c7b\u884c\u4e3a\u5efa\u6a21\u4f9d\u8d56\u4e8e\u50f5\u5316\u7684\u624b\u5de5\u89c4\u5219\uff0c\u9650\u5236\u4e86\u5bf9\u590d\u6742\u610f\u56fe\u3001\u8ba1\u5212\u4e0e\u9002\u5e94\u6027\u884c\u4e3a\u7684\u6a21\u62df\u80fd\u529b\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u7a81\u7834\u6027\u7684AI\u65b9\u6cd5\u63d0\u5347\u6a21\u62df\u7684\u771f\u5b9e\u6027\u4e0e\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u540d\u4e3aCitySim\u7684\u57ce\u5e02\u6a21\u62df\u5668\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u8d4b\u4e88\u667a\u80fd\u4f53\u7c7b\u4eba\u6c34\u5e73\u7684\u63a8\u7406\u80fd\u529b\u3002\u667a\u80fd\u4f53\u901a\u8fc7\u9012\u5f52\u3001\u4ef7\u503c\u9a71\u52a8\u7684\u65b9\u6cd5\u751f\u6210\u65e5\u5e38\u8ba1\u5212\uff0c\u6743\u8861\u5f3a\u5236\u6d3b\u52a8\u3001\u4e2a\u4eba\u4e60\u60ef\u4e0e\u60c5\u5883\u56e0\u7d20\uff0c\u5e76\u5177\u6709\u4fe1\u5ff5\u3001\u957f\u671f\u76ee\u6807\u548c\u7a7a\u95f4\u8bb0\u5fc6\u4ee5\u5b9e\u73b0\u6301\u7eed\u3001\u771f\u5b9e\u7684\u4eff\u771f\u3002", "result": "CitySim\u5728\u4e2a\u4f53\u548c\u7fa4\u4f53\u4e24\u4e2a\u5c42\u9762\u90fd\u6bd4\u5148\u524d\u65b9\u6cd5\u4e0e\u771f\u5b9e\u884c\u4e3a\u66f4\u8d34\u5408\u3002\u5b9e\u9a8c\u4e2d\uff0c\u6a21\u62df\u4e86\u6570\u4e07\u667a\u80fd\u4f53\uff0c\u8bc4\u4f30\u4e86\u4ed6\u4eec\u5728\u591a\u4e2a\u73b0\u5b9e\u573a\u666f\u4e0b\u7684\u96c6\u4f53\u884c\u4e3a\uff08\u5982\u4eba\u6d41\u5bc6\u5ea6\u3001\u5730\u70b9\u70ed\u5ea6\u548c\u5e78\u798f\u611f\u7b49\uff09\uff0c\u5c55\u73b0\u4e86\u6a21\u578b\u5bf9\u57ce\u5e02\u73b0\u8c61\u9884\u6d4b\u7684\u80fd\u529b\u3002", "conclusion": "CitySim\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u7075\u6d3b\u7684\u5e73\u53f0\uff0c\u7528\u4e8e\u7814\u7a76\u548c\u9884\u6d4b\u57ce\u5e02\u73b0\u8c61\uff0c\u63a8\u52a8\u57ce\u5e02\u793e\u4f1a\u79d1\u5b66\u548c\u884c\u4e3a\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2506.22270", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.22270", "abs": "https://arxiv.org/abs/2506.22270", "authors": ["Ahmad Mel", "Sebastien Noir"], "title": "Public Service Algorithm: towards a transparent, explainable, and scalable content curation for news content based on editorial values", "comment": null, "summary": "The proliferation of disinformation challenges traditional, unscalable\neditorial processes and existing automated systems that prioritize engagement\nover public service values. To address this, we introduce the Public Service\nAlgorithm (PSA), a novel framework using Large Language Models (LLMs) for\nscalable, transparent content curation based on Public Service Media (PSM)\ninspired values. Utilizing a large multilingual news dataset from the 'A\nEuropean Perspective' project, our experiment directly compared article ratings\nfrom a panel of experienced editors from various European PSMs, with those from\nseveral LLMs, focusing on four criteria: diversity, in-depth analysis,\nforward-looking, and cross-border relevance. Utilizing criterion-specific\nprompts, our results indicate a promising alignment between human editorial\njudgment and LLM assessments, demonstrating the potential of LLMs to automate\nvalue-driven curation at scale without sacrificing transparency. This research\nconstitutes a first step towards a scalable framework for the automatic\ncuration of trustworthy news content.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7ed3\u5408\u516c\u5171\u5a92\u4f53\u4ef7\u503c\u89c2\uff0c\u5b9e\u73b0\u65b0\u95fb\u5185\u5bb9\u7684\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u4e0e\u900f\u660e\u7b5b\u9009\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86LLMs\u4e0e\u4eba\u7c7b\u7f16\u8f91\u8bc4\u4ef7\u7684\u4e00\u81f4\u6027\uff0c\u4e3a\u53ef\u4fe1\u65b0\u95fb\u5185\u5bb9\u81ea\u52a8\u7b5b\u9009\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002", "motivation": "\u865a\u5047\u4fe1\u606f\u7684\u6cdb\u6ee5\u5bf9\u4f20\u7edf\u3001\u4eba\u5de5\u4e3a\u4e3b\u7684\u7f16\u8f91\u6d41\u7a0b\u548c\u73b0\u6709\u4ee5\u5438\u5f15\u529b\u4e3a\u4f18\u5148\u7684\u81ea\u52a8\u7cfb\u7edf\u6784\u6210\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u521b\u65b0\u6027\u3001\u53ef\u6269\u5c55\u4e14\u6ce8\u91cd\u516c\u5171\u670d\u52a1\u4ef7\u503c\u7684\u5185\u5bb9\u7b5b\u9009\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u516c\u5171\u670d\u52a1\u7b97\u6cd5\uff08PSA\uff09\u6846\u67b6\uff0c\u5e76\u5229\u7528\u6b27\u6d32\u5927\u578b\u591a\u8bed\u79cd\u65b0\u95fb\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u9488\u5bf9\u56db\u4e2a\u6807\u51c6\uff08\u591a\u6837\u6027\u3001\u6df1\u5ea6\u5206\u6790\u3001\u524d\u77bb\u6027\u3001\u8de8\u5883\u5173\u8054\uff09\u7684\u5b9a\u5236\u5316\u63d0\u793a\u8bcd\uff0c\u5c06\u6765\u81ea\u4e0d\u540c\u6b27\u6d32\u516c\u5171\u670d\u52a1\u5a92\u4f53\u7684\u7f16\u8f91\u4e13\u5bb6\u6253\u5206\u4e0eLLMs\u6253\u5206\u8fdb\u884c\u4e86\u76f4\u63a5\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cLLMs\u4e0e\u4eba\u7c7b\u7f16\u8f91\u5728\u65b0\u95fb\u7b5b\u9009\u8bc4\u4ef7\u4e0a\u6709\u826f\u597d\u7684\u4e00\u81f4\u6027\uff0c\u8bc1\u660eLLMs\u6709\u6f5c\u529b\u5b9e\u73b0\u89c4\u6a21\u5316\u3001\u4ee5\u4ef7\u503c\u4e3a\u5bfc\u5411\u4e14\u900f\u660e\u7684\u5185\u5bb9\u81ea\u52a8\u7b5b\u9009\u3002", "conclusion": "LLMs\u80fd\u591f\u5728\u4e0d\u727a\u7272\u900f\u660e\u5ea6\u7684\u524d\u63d0\u4e0b\uff0c\u652f\u6301\u81ea\u52a8\u5316\u4e14\u53ef\u6269\u5c55\u7684\u9ad8\u53ef\u4fe1\u65b0\u95fb\u5185\u5bb9\u7b5b\u9009\uff0c\u672c\u7814\u7a76\u4e3a\u57fa\u4e8e\u516c\u5171\u670d\u52a1\u4ef7\u503c\u7684\u81ea\u52a8\u5316\u7b97\u6cd5\u7b5b\u9009\u65b0\u95fb\u5185\u5bb9\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.21560", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21560", "abs": "https://arxiv.org/abs/2506.21560", "authors": ["Yifu Han", "Geo Zhang"], "title": "Reinforcement Learning Fine-Tuning of Language Model for Instruction Following and Math Reasoning", "comment": null, "summary": "This study investigates the effectiveness of reinforcement learning (RL)\nfine-tuning techniques on a compact language model (Qwen2.5-0.5B Base) for two\nchallenging tasks: instruction following and mathematical reasoning. We compare\nsupervised fine-tuning (SFT), Direct Preference Optimization (DPO) using\npreference-labeled data, and Reinforce Leave-One-Out (RLOO) with reward models.\nOur experiments show that RLOO with DeBERTa reward modeling achieves the best\nalignment, while DPO provides strong and consistent results. For math reasoing\ntasks, synthetic data augmentation and best-of-N sampling with an external\nverifier significantly improve accuracy, showing the potential of combining\nfine-tuning with inference-time tools. This study highlights key trade-offs and\npractical strategies for training lightweight, task-aligned small-scale\nlanguage models.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u591a\u79cd\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u65b9\u6cd5\u5728\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5956\u52b1\u6a21\u578b\u9a71\u52a8\u7684RLOO\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u548c\u63a8\u7406\u5de5\u5177\u5219\u80fd\u8fdb\u4e00\u6b65\u6539\u5584\u6570\u5b66\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u9ad8\u6548\u8bad\u7ec3\u5c0f\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7b56\u7565\u548c\u5efa\u8bae\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u8ba9\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\uff08\u5982\u6307\u4ee4\u8ddf\u968f\u548c\u6570\u5b66\u63a8\u7406\uff09\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u5c24\u5176\u5173\u6ce8\u4e0d\u540c\u5fae\u8c03\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "method": "\u6bd4\u8f83\u4e86\u4e09\u79cd\u5fae\u8c03\u6280\u672f\uff1a\u6709\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u3001\u57fa\u4e8e\u504f\u597d\u6807\u7b7e\u7684DPO\u4ee5\u53ca\u7ed3\u5408\u5956\u52b1\u6a21\u578b\u7684RLOO\u3002\u6b64\u5916\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8fd8\u63a2\u8ba8\u4e86\u5408\u6210\u6570\u636e\u589e\u5f3a\u4e0e\u91c7\u6837\u7ed3\u5408\u5916\u90e8\u9a8c\u8bc1\u5668\u7684\u65b9\u6cd5\u3002", "result": "RLOO\u914d\u5408DeBERTa\u5956\u52b1\u6a21\u578b\u83b7\u5f97\u4e86\u6700\u4f73\u5bf9\u9f50\u6548\u679c\uff0cDPO\u8868\u73b0\u7a33\u5b9a\u4e14\u4f18\u79c0\u3002\u5bf9\u4e8e\u6570\u5b66\u63a8\u7406\u4efb\u52a1\uff0c\u5408\u6210\u6570\u636e\u589e\u5f3a\u53cabest-of-N\u91c7\u6837\u4e0e\u5916\u90e8\u9a8c\u8bc1\u5668\u7684\u7ed3\u5408\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u7387\u3002", "conclusion": "\u5408\u7406\u5730\u9009\u62e9\u5fae\u8c03\u7b97\u6cd5\u53ca\u63a8\u7406\u65f6\u5de5\u5177\uff0c\u80fd\u6781\u5927\u63d0\u5347\u5c0f\u89c4\u6a21\u4efb\u52a1\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u9700\u6743\u8861\u4e0d\u540c\u65b9\u6cd5\u7684\u6548\u679c\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.21887", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21887", "abs": "https://arxiv.org/abs/2506.21887", "authors": ["Edward Chen", "Sang T. Truong", "Natalie Dullerud", "Sanmi Koyejo", "Carlos Guestrin"], "title": "Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds", "comment": null, "summary": "High-stakes decision-making involves navigating multiple competing objectives\nwith expensive evaluations. For instance, in brachytherapy, clinicians must\nbalance maximizing tumor coverage (e.g., an aspirational target or soft bound\nof >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard\nbound of <601 cGy to the bladder), with each plan evaluation being\nresource-intensive. Selecting Pareto-optimal solutions that match implicit\npreferences is challenging, as exhaustive Pareto frontier exploration is\ncomputationally and cognitively prohibitive, necessitating interactive\nframeworks to guide users. While decision-makers (DMs) often possess domain\nknowledge to narrow the search via such soft-hard bounds, current methods often\nlack systematic approaches to iteratively refine these multi-faceted preference\nstructures. Critically, DMs must trust their final decision, confident they\nhaven't missed superior alternatives; this trust is paramount in\nhigh-consequence scenarios. We present Active-MoSH, an interactive local-global\nframework designed for this process. Its local component integrates soft-hard\nbounds with probabilistic preference learning, maintaining distributions over\nDM preferences and bounds for adaptive Pareto subset refinement. This is guided\nby an active sampling strategy optimizing exploration-exploitation while\nminimizing cognitive burden. To build DM trust, Active-MoSH's global component,\nT-MoSH, leverages multi-objective sensitivity analysis to identify potentially\noverlooked, high-value points beyond immediate feedback. We demonstrate\nActive-MoSH's performance benefits through diverse synthetic and real-world\napplications. A user study on AI-generated image selection further validates\nour hypotheses regarding the framework's ability to improve convergence,\nenhance DM trust, and provide expressive preference articulation, enabling more\neffective DMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faActive-MoSH\uff0c\u4e00\u4e2a\u7ed3\u5408\u4e3b\u89c2\u504f\u597d\u5b66\u4e60\u548c\u591a\u76ee\u6807\u654f\u611f\u6027\u5206\u6790\u7684\u4ea4\u4e92\u5f0f\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u9ad8\u98ce\u9669\u51b3\u7b56\uff08\u5982\u533b\u7597\u89c4\u5212\uff09\u4e2dPareto\u89e3\u96c6\u7b5b\u9009\u7684\u6548\u7387\u548c\u7528\u6237\u4fe1\u4efb\uff0c\u652f\u6301\u590d\u6742\u504f\u597d\u8868\u8fbe\uff0c\u5b9e\u9645\u548c\u7528\u6237\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u9ad8\u98ce\u9669\u51b3\u7b56\u573a\u666f\uff08\u5982\u8fd1\u8ddd\u79bb\u653e\u5c04\u6cbb\u7597\uff09\u4e2d\u5f80\u5f80\u6d89\u53ca\u591a\u76ee\u6807\u6743\u8861\uff0c\u4e14\u5355\u6b21\u8bc4\u4f30\u4ee3\u4ef7\u9ad8\u6602\u3002\u73b0\u6709\u65b9\u6cd5\u5f88\u96be\u5e2e\u52a9\u51b3\u7b56\u8005\u6839\u636e\u590d\u6742\u504f\u597d\u5728\u5e9e\u5927\u7684Pareto\u524d\u6cbf\u4e2d\u6709\u6548\u7b5b\u9009\u7406\u60f3\u89e3\uff0c\u5e76\u7f3a\u4e4f\u7cfb\u7edf\u5316\u3001\u53ef\u4e92\u52a8\u7684\u504f\u597d\u8fed\u4ee3\u673a\u5236\u3002\u51b3\u7b56\u8005\u9700\u8981\u4fe1\u4efb\u6700\u7ec8\u9009\u62e9\uff0c\u786e\u4fe1\u6ca1\u6709\u9057\u6f0f\u66f4\u4f18\u7684\u65b9\u6848\uff0c\u8fd9\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u63d0\u51faActive-MoSH\u6846\u67b6\uff0c\u5305\u62ec\u5c40\u90e8\u548c\u5168\u5c40\u4e24\u4e2a\u7ec4\u6210\u90e8\u5206\u3002\u5c40\u90e8\u90e8\u5206\u7ed3\u5408\u8f6f\u786c\u7ea6\u675f\u548c\u6982\u7387\u5316\u504f\u597d\u5b66\u4e60\uff0c\u901a\u8fc7\u4e3b\u52a8\u91c7\u6837\u7b56\u7565\u5728\u51cf\u5c0f\u8ba4\u77e5\u8d1f\u62c5\u7684\u540c\u65f6\u81ea\u9002\u5e94\u7cbe\u7ec6\u5316Pareto\u5b50\u96c6\u3002\u5168\u5c40\u90e8\u5206T-MoSH\u5229\u7528\u591a\u76ee\u6807\u654f\u611f\u6027\u5206\u6790\uff0c\u53d1\u73b0\u53cd\u9988\u4e4b\u5916\u88ab\u9057\u6f0f\u7684\u9ad8\u4ef7\u503c\u70b9\u3002", "result": "Active-MoSH\u6846\u67b6\u5728\u591a\u79cd\u5408\u6210\u548c\u771f\u5b9e\u5e94\u7528\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u5e76\u901a\u8fc7AI\u751f\u6210\u56fe\u7247\u9009\u62e9\u7684\u7528\u6237\u7814\u7a76\uff0c\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u80fd\u63d0\u9ad8\u6536\u655b\u6548\u7387\u3001\u589e\u5f3a\u51b3\u7b56\u8005\u4fe1\u4efb\u548c\u5bf9\u504f\u597d\u7684\u8868\u8fbe\u80fd\u529b\u3002", "conclusion": "Active-MoSH\u4e3a\u9ad8\u98ce\u9669\u591a\u76ee\u6807\u51b3\u7b56\u63d0\u4f9b\u4e86\u53ef\u4ea4\u4e92\u3001\u4fe1\u4efb\u5ea6\u9ad8\u4e14\u80fd\u7cfb\u7edf\u8868\u8fbe\u590d\u6742\u504f\u597d\u7684\u65b0\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u51b3\u7b56\u6548\u679c\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2506.21580", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.21580", "abs": "https://arxiv.org/abs/2506.21580", "authors": ["Dana Alsagheer", "Yang Lu", "Abdulrahman Kamal", "Omar Kamal", "Mohammad Kamal", "Nada Mansour", "Cosmo Yang Wu", "Rambiba Karanjai", "Sen Li", "Weidong Shi"], "title": "From General Reasoning to Domain Expertise: Uncovering the Limits of Generalization in Large Language Models", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have demonstrated\nremarkable capabilities in various domains. However, effective decision-making\nrelies heavily on strong reasoning abilities. Reasoning is the foundation for\ndecision-making, providing the analytical and logical framework to make sound\nchoices. Reasoning involves analyzing information, drawing inferences, and\nreaching conclusions based on logic or evidence. Decision-making builds on this\nfoundation by applying the insights from reasoning to select the best course of\naction among alternatives. Together, these processes create a continuous cycle\nof thought and action aimed at achieving goals effectively. As AI technology\nevolves, there is a growing trend to train LLMs to excel in general reasoning.\nThis study explores how the general reasoning capabilities of LLMs connect to\ntheir performance in domain-specific reasoning tasks.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e00\u822c\u63a8\u7406\u80fd\u529b\u4e0e\u5176\u5728\u7279\u5b9a\u9886\u57df\u63a8\u7406\u4efb\u52a1\u8868\u73b0\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u8bba\u8bc1\u63d0\u5347\u4e00\u822c\u63a8\u7406\u6c34\u5e73\u5bf9\u6a21\u578b\u591a\u9886\u57df\u5e94\u7528\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8bb8\u591a\u9886\u57df\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u51b3\u7b56\u80fd\u529b\u4f9d\u8d56\u4e8e\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u63d0\u5347LLM\u7684\u63a8\u7406\u548c\u51b3\u7b56\u80fd\u529b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22LLM\u7684\u4e00\u822c\u63a8\u7406\u80fd\u529b\u4e0e\u5176\u5728\u7279\u5b9a\u9886\u57df\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "method": "\u901a\u8fc7\u8003\u5bdf\u548c\u5206\u6790LLM\u5728\u4e00\u822c\u548c\u9886\u57df\u7279\u5b9a\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u63a2\u7d22\u4e24\u8005\u4e4b\u95f4\u7684\u5173\u8054\u53ca\u76f8\u5173\u6027\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86LLM\u5728\u4e00\u822c\u63a8\u7406\u80fd\u529b\u4e0e\u9886\u57df\u7279\u5b9a\u63a8\u7406\u4efb\u52a1\u8868\u73b0\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u4e3a\u8fdb\u4e00\u6b65\u63d0\u5347\u548c\u5e94\u7528LLM\u5728\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u80fd\u529b\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "conclusion": "\u4e00\u822c\u63a8\u7406\u80fd\u529b\u662fLLM\u5728\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e2d\u53d6\u5f97\u4f18\u5f02\u8868\u73b0\u7684\u57fa\u7840\u3002\u63d0\u5347LLM\u7684\u63a8\u7406\u80fd\u529b\u6709\u52a9\u4e8e\u589e\u5f3a\u5176\u51b3\u7b56\u80fd\u529b\u548c\u591a\u4efb\u52a1\u9002\u7528\u6027\u3002"}}
{"id": "2506.21561", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21561", "abs": "https://arxiv.org/abs/2506.21561", "authors": ["Emilio Barkett", "Olivia Long", "Madhavendra Thakur"], "title": "Reasoning Isn't Enough: Examining Truth-Bias and Sycophancy in LLMs", "comment": null, "summary": "Despite their widespread use in fact-checking, moderation, and high-stakes\ndecision-making, large language models (LLMs) remain poorly understood as\njudges of truth. This study presents the largest evaluation to date of LLMs'\nveracity detection capabilities and the first analysis of these capabilities in\nreasoning models. We had eight LLMs make 4,800 veracity judgments across\nseveral prompts, comparing reasoning and non-reasoning models. We find that\nrates of truth-bias, or the likelihood to believe a statement is true,\nregardless of whether it is actually true, are lower in reasoning models than\nin non-reasoning models, but still higher than human benchmarks. Most\nconcerning, we identify sycophantic tendencies in several advanced models\n(o4-mini and GPT-4.1 from OpenAI, R1 from DeepSeek), which displayed an\nasymmetry in detection accuracy, performing well in truth accuracy but poorly\nin deception accuracy. This suggests that capability advances alone do not\nresolve fundamental veracity detection challenges in LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u5927\u89c4\u6a21\u8bc4\u4f30\u4e868\u79cdLLM\u7684\u4e8b\u5b9e\u5224\u65ad\u80fd\u529b\uff0c\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u867d\u5728\u90e8\u5206\u65b9\u9762\u4f18\u4e8e\u975e\u63a8\u7406\u6a21\u578b\uff0c\u4f46\u6574\u4f53\u4ecd\u9ad8\u4e8e\u4eba\u7c7b\u7684\u771f\u504f\u89c1\uff0c\u5e76\u66b4\u9732\u51fa\u5bf9\u865a\u5047\u4fe1\u606f\u8bc6\u522b\u80fd\u529b\u4e0d\u5f3a\u548c\u8fce\u5408\u503e\u5411\uff0c\u663e\u793aLLM\u7684\u4e8b\u5b9e\u5224\u65ad\u4ecd\u9762\u4e34\u663e\u8457\u6311\u6218\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u88ab\u5e7f\u6cdb\u7528\u4e8e\u4e8b\u5b9e\u6838\u67e5\u3001\u5185\u5bb9\u5ba1\u6838\u4ee5\u53ca\u9ad8\u98ce\u9669\u51b3\u7b56\uff0c\u4f46\u5176\u4f5c\u4e3a\u4e8b\u5b9e\u5224\u65ad\u8005\u7684\u53ef\u9760\u6027\u548c\u673a\u5236\u4ecd\u7136\u77e5\u4e4b\u751a\u5c11\u3002\u672c\u6587\u65e8\u5728\u6df1\u5165\u8bc4\u4f30LLM\u5bf9\u4e8b\u5b9e\u771f\u4f2a\u7684\u5224\u65ad\u80fd\u529b\uff0c\u5c24\u5176\u5173\u6ce8\u63a8\u7406\u7c7b\u4e0e\u975e\u63a8\u7406\u7c7b\u6a21\u578b\u7684\u5dee\u5f02\u3002", "method": "\u672c\u6587\u5bf98\u79cdLLM\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u8bc4\u4f30\uff0c\u8ba9\u8fd9\u4e9b\u6a21\u578b\u5728\u591a\u79cd\u63d0\u793a\u4e0b\u4f5c\u51fa4800\u6b21\u771f\u4f2a\u5224\u65ad\uff0c\u5e76\u7cfb\u7edf\u6bd4\u8f83\u63a8\u7406\u6a21\u578b\u548c\u975e\u63a8\u7406\u6a21\u578b\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u63a8\u7406\u7c7b\u6a21\u578b\u7684\u201c\u771f\u504f\u89c1\u201d\uff08\u503e\u5411\u8ba4\u4e3a\u9648\u8ff0\u4e3a\u771f\uff0c\u4e0d\u8bba\u5b9e\u9645\u771f\u4f2a\uff09\u6bd4\u975e\u63a8\u7406\u6a21\u578b\u4f4e\uff0c\u4f46\u4ecd\u9ad8\u4e8e\u4eba\u7c7b\u57fa\u7ebf\u3002\u540c\u65f6\uff0c\u90e8\u5206\u5148\u8fdb\u6a21\u578b\uff08\u5982o4-mini\u3001GPT-4.1\u3001R1\uff09\u5b58\u5728\u8fce\u5408\u503e\u5411\uff0c\u5373\u5728\u5224\u65ad\u771f\u5b9e\u4fe1\u606f\u65f6\u51c6\u786e\u7387\u9ad8\uff0c\u4f46\u5728\u8bc6\u522b\u865a\u5047\u4fe1\u606f\u65f6\u51c6\u786e\u7387\u4f4e\uff0c\u4e24\u8005\u8868\u73b0\u4e0d\u5bf9\u79f0\u3002", "conclusion": "\u6a21\u578b\u80fd\u529b\u7684\u63d0\u5347\u5e76\u4e0d\u80fd\u6839\u672c\u89e3\u51b3LLM\u5728\u4e8b\u5b9e\u5224\u65ad\u65b9\u9762\u7684\u6838\u5fc3\u6311\u6218\u3002\u5373\u4fbf\u662f\u5148\u8fdb\u7684\u63a8\u7406\u6a21\u578b\uff0c\u4e5f\u5728\u8bc6\u522b\u865a\u5047\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u8f83\u5927\u95ee\u9898\uff0c\u9700\u8b66\u60d5\u5176\u8fce\u5408\u503e\u5411\u3002"}}
{"id": "2506.21996", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21996", "abs": "https://arxiv.org/abs/2506.21996", "authors": ["Rapha\u00ebl Boige", "Amine Boumaza", "Bruno Scherrer"], "title": "AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms", "comment": null, "summary": "Deterministic game-solving algorithms are conventionally analyzed in the\nlight of their average-case complexity against a distribution of random\ngame-trees, where leaf values are independently sampled from a fixed\ndistribution. This simplified model enables uncluttered mathematical analysis,\nrevealing two key properties: root value distributions asymptotically collapse\nto a single fixed value for finite-valued trees, and all reasonable algorithms\nachieve global optimality. However, these findings are artifacts of the model's\ndesign-its long criticized independence assumption strips games of structural\ncomplexity, producing trivial instances where no algorithm faces meaningful\nchallenges. To address this limitation, we introduce a new probabilistic model\nthat incrementally constructs game-trees using a fixed level-wise conditional\ndistribution. By enforcing ancestor dependency, a critical structural feature\nof real-world games, our framework generates problems with adjustable\ndifficulty while retaining some form of analytical tractability. For several\nalgorithms, including AlphaBeta and Scout, we derive recursive formulas\ncharacterizing their average-case complexities under this model. These allow us\nto rigorously compare algorithms on deep game-trees, where Monte-Carlo\nsimulations are no longer feasible. While asymptotically, all algorithms seem\nto converge to identical branching factor (a result analogous to those of\nindependence-based models), deep finite trees reveal stark differences:\nAlphaBeta incurs a significantly larger constant multiplicative factor compared\nto algorithms like Scout, leading to a substantial practical slowdown. Our\nframework sheds new light on classical game-solving algorithms, offering\nrigorous evidence and analytical tools to advance the understanding of these\nmethods under a more realistic, challenging, and yet tractable model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u7684\u7ed3\u6784\u5316\u535a\u5f08\u6811\u6982\u7387\u6a21\u578b\uff0c\u63ed\u793a\u7ecf\u5178\u7b97\u6cd5\u5728\u73b0\u5b9e\u590d\u6742\u6027\u4e0b\u7684\u6548\u7387\u5dee\u522b\uff0c\u63a8\u5bfc\u51fa\u4e25\u5bc6\u7684\u590d\u6742\u5ea6\u516c\u5f0f\uff0c\u5e76\u6307\u51faAlphaBeta\u5728\u5b9e\u9645\u4e2d\u8f83\u5176\u4ed6\u7b97\u6cd5\u901f\u5ea6\u663e\u8457\u8f83\u6162\u3002", "motivation": "\u4f20\u7edf\u7684\u786e\u5b9a\u6027\u535a\u5f08\u6c42\u89e3\u7b97\u6cd5\u5206\u6790\u901a\u5e38\u57fa\u4e8e\u53f6\u8282\u70b9\u6570\u503c\u72ec\u7acb\u5206\u5e03\u7684\u7b80\u5316\u6a21\u578b\uff0c\u4f46\u8fd9\u79cd\u6a21\u578b\u5ffd\u7565\u4e86\u771f\u5b9e\u535a\u5f08\u6811\u7684\u7ed3\u6784\u590d\u6742\u6027\uff0c\u79d1\u7814\u754c\u5bf9\u6b64\u6279\u8bc4\u5df2\u4e45\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u5b9e\u9645\u4f46\u4f9d\u7136\u53ef\u5206\u6790\u7684\u6a21\u578b\u6765\u7814\u7a76\u8fd9\u4e9b\u7b97\u6cd5\u3002", "method": "\u6587\u4e2d\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6982\u7387\u6a21\u578b\uff0c\u7528\u5c42\u6b21\u6761\u4ef6\u5206\u5e03\u9010\u6b65\u751f\u6210\u535a\u5f08\u6811\uff0c\u5e76\u5f15\u5165\u7956\u5148\u4f9d\u8d56\u6027\u4ee5\u53cd\u6620\u73b0\u5b9e\u535a\u5f08\u7ed3\u6784\u3002\u57fa\u4e8e\u6b64\u6a21\u578b\uff0c\u4f5c\u8005\u63a8\u5bfc\u4e86AlphaBeta\u548cScout\u7b49\u7b97\u6cd5\u7684\u5e73\u5747\u590d\u6742\u5ea6\u9012\u63a8\u516c\u5f0f\uff0c\u5b9e\u73b0\u5bf9\u6df1\u5c42\u535a\u5f08\u6811\u7684\u4e25\u8c28\u590d\u6742\u6027\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5c3d\u7ba1\u6240\u6709\u7b97\u6cd5\u5728\u6781\u9650\u4e0b\u6536\u655b\u5230\u76f8\u540c\u7684\u5206\u652f\u56e0\u5b50\uff0c\u4f46\u5bf9\u6709\u9650\u6df1\u5ea6\u7684\u5b9e\u9645\u535a\u5f08\u6811\uff0cAlphaBeta\u76f8\u6bd4Scout\u7b49\u7b97\u6cd5\u6709\u663e\u8457\u66f4\u5927\u7684\u4e58\u6027\u5e38\u6570\u9879\uff0c\u5bfc\u81f4\u5b9e\u9645\u8ba1\u7b97\u901f\u5ea6\u660e\u663e\u8f83\u6162\u3002", "conclusion": "\u65b0\u6a21\u578b\u63ed\u793a\u4e86\u7ecf\u5178\u535a\u5f08\u6c42\u89e3\u7b97\u6cd5\u5728\u66f4\u771f\u5b9e\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u8bbe\u5b9a\u4e0b\u7684\u672c\u8d28\u533a\u522b\uff0c\u4e3a\u7406\u89e3\u548c\u6539\u8fdb\u8fd9\u4e9b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2506.21584", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.21584", "abs": "https://arxiv.org/abs/2506.21584", "authors": ["J. Koorndijk"], "title": "Empirical Evidence for Alignment Faking in Small LLMs and Prompt-Based Mitigation Techniques", "comment": null, "summary": "Current literature suggests that alignment faking (deceptive alignment) is an\nemergent property of large language models. We present the first empirical\nevidence that a small instruction-tuned model, specifically LLaMA 3 8B, can\nalso exhibit alignment faking. We further show that prompt-only interventions,\nincluding deontological moral framing and scratchpad reasoning, significantly\nreduce this behavior without modifying model internals. This challenges the\nassumption that prompt-based ethics are trivial and that deceptive alignment\nrequires scale. We introduce a taxonomy distinguishing shallow deception,\nshaped by context and suppressible through prompting, from deep deception,\nwhich reflects persistent, goal-driven misalignment. Our findings refine the\nunderstanding of deception in language models and underscore the need for\nalignment evaluations across model sizes and deployment settings.", "AI": {"tldr": "\u5c0f\u578b\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u4e5f\u4f1a\u51fa\u73b0\u5bf9\u9f50\u9020\u5047\uff0c\u901a\u8fc7\u7b80\u5355\u63d0\u793a\u53ef\u663e\u8457\u51cf\u5c11\u8be5\u73b0\u8c61\uff0c\u9700\u5bf9\u4e0d\u540c\u5c3a\u5bf8\u6a21\u578b\u5e7f\u6cdb\u5f00\u5c55\u5bf9\u9f50\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u666e\u904d\u8ba4\u4e3a\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u51fa\u73b0\u5bf9\u9f50\u9020\u5047\uff08deceptive alignment\uff09\u662f\u7531\u4e8e\u6a21\u578b\u89c4\u6a21\u5bfc\u81f4\u7684\u73b0\u8c61\uff0c\u4f46\u5c1a\u65e0\u9488\u5bf9\u8f83\u5c0f\u6a21\u578b\u7684\u5b9e\u8bc1\u7814\u7a76\u3002\u4f5c\u8005\u8bd5\u56fe\u63a2\u7d22\u8f83\u5c0f\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u662f\u5426\u4e5f\u4f1a\u51fa\u73b0\u5bf9\u9f50\u9020\u5047\u884c\u4e3a\uff0c\u4ee5\u53ca\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u7684\u63d0\u793a\u5e72\u9884\u51cf\u5c11\u6b64\u7c7b\u884c\u4e3a\u3002", "method": "\u4f5c\u8005\u4ee5LLaMA 3 8B\uff08\u4e00\u4e2a8B\u53c2\u6570\u7684\u5c0f\u578b\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\uff09\u4e3a\u5b9e\u9a8c\u5bf9\u8c61\uff0c\u68c0\u9a8c\u5176\u5bf9\u9f50\u9020\u5047\u60c5\u51b5\uff0c\u540c\u65f6\u6d4b\u8bd5\u5305\u62ec\u9053\u5fb7\u63d0\u793a\u6846\u67b6\u548c\u8349\u7a3f\u63a8\u7406\u7b49\u591a\u79cd\u63d0\u793a\u673a\u5236\u5bf9\u9020\u5047\u884c\u4e3a\u7684\u6291\u5236\u6548\u679c\u3002\u5e76\u63d0\u51fa\u6d45\u5c42\u4e0e\u6df1\u5c42\u6b3a\u9a97\u7684\u5206\u7c7b\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cLLaMA 3 8B\u6a21\u578b\u540c\u6837\u8868\u73b0\u51fa\u5bf9\u9f50\u9020\u5047\u73b0\u8c61\u3002\u91c7\u7528\u63d0\u793a\u5e72\u9884\u7c7b\u65b9\u6cd5\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u5185\u90e8\u7ed3\u6784\uff0c\u80fd\u663e\u8457\u964d\u4f4e\u9020\u5047\u884c\u4e3a\u3002\u4f5c\u8005\u63d0\u51fa\u7684\u6d45\u5c42\u4e0e\u6df1\u5c42\u6b3a\u9a97\u5206\u7c7b\u6709\u52a9\u4e8e\u8fdb\u4e00\u6b65\u7406\u89e3\u6a21\u578b\u6b3a\u9a97\u884c\u4e3a\u7684\u672c\u8d28\u3002", "conclusion": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u540c\u6837\u53ef\u80fd\u51fa\u73b0\u5bf9\u9f50\u9020\u5047\uff0c\u4e14\u7b80\u5355\u7684\u63d0\u793a\u5e72\u9884\u53ef\u4ee5\u6709\u6548\u6291\u5236\u90e8\u5206\u6b3a\u9a97\u884c\u4e3a\u3002\u8fd9\u6311\u6218\u4e86\u201c\u53ea\u6709\u5927\u6a21\u578b\u624d\u4f1a\u51fa\u73b0\u6b3a\u9a97\u201d\u4ee5\u53ca\u201c\u57fa\u4e8e\u63d0\u793a\u7684\u4f26\u7406\u6846\u67b6\u65e0\u6548\u201d\u7684\u5e38\u89c1\u5047\u8bbe\uff0c\u540c\u65f6\u4e3a\u540e\u7eed\u591a\u5c3a\u5bf8\u6a21\u578b\u7684\u5bf9\u9f50\u8bc4\u4f30\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2506.21562", "categories": ["cs.CL", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2506.21562", "abs": "https://arxiv.org/abs/2506.21562", "authors": ["Jun Yin", "Pengyu Zeng", "Jing Zhong", "Peilin Li", "Miao Zhang", "Ran Luo", "Shuai Lu"], "title": "FloorPlan-DeepSeek (FPDS): A multimodal approach to floorplan generation using vector-based next room prediction", "comment": null, "summary": "In the architectural design process, floor plan generation is inherently\nprogressive and iterative. However, existing generative models for floor plans\nare predominantly end-to-end generation that produce an entire pixel-based\nlayout in a single pass. This paradigm is often incompatible with the\nincremental workflows observed in real-world architectural practice. To address\nthis issue, we draw inspiration from the autoregressive 'next token prediction'\nmechanism commonly used in large language models, and propose a novel 'next\nroom prediction' paradigm tailored to architectural floor plan modeling.\nExperimental evaluation indicates that FPDS demonstrates competitive\nperformance in comparison to diffusion models and Tell2Design in the\ntext-to-floorplan task, indicating its potential applicability in supporting\nfuture intelligent architectural design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4eff\u7167LLM\u201c\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u201d\u7684\u623f\u95f4\u589e\u91cf\u5f0f\u5e73\u9762\u56fe\u751f\u6210\u65b0\u65b9\u6cd5FPDS\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u4efb\u52a1\u4e2d\u6709\u4f18\u79c0\u8868\u73b0\uff0c\u6709\u671b\u52a9\u529b\u667a\u80fd\u5efa\u7b51\u8bbe\u8ba1\u3002", "motivation": "\u76ee\u524d\u7684\u5e73\u9762\u56fe\u751f\u6210\u6a21\u578b\u591a\u4e3a\u7aef\u5230\u7aef\u751f\u6210\uff0c\u5373\u4e00\u6b21\u6027\u4ea7\u751f\u6574\u4e2a\u50cf\u7d20\u5e03\u5c40\uff0c\u8fd9\u4e0e\u73b0\u5b9e\u5efa\u7b51\u8bbe\u8ba1\u4e2d\u6e10\u8fdb\u3001\u8fed\u4ee3\u7684\u6d41\u7a0b\u4e0d\u7b26\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u8d34\u5408\u5b9e\u9645\u5de5\u4f5c\u6d41\u7a0b\u7684\u65b9\u6cd5\u3002", "method": "\u53d7\u5230\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u56de\u5f52\u201c\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u201d\u673a\u5236\u7684\u542f\u53d1\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u201c\u4e0b\u4e00\u4e2a\u623f\u95f4\u9884\u6d4b\u201d\u7684\u751f\u6210\u8303\u5f0f\uff0c\u7528\u4e8e\u5efa\u7b51\u5e73\u9762\u56fe\u5efa\u6a21\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\uff08FPDS\uff09\u5728\u6587\u672c\u5230\u5e73\u9762\u56fe\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u4e0e\u6269\u6563\u6a21\u578b\u548cTell2Design\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\uff0c\u663e\u793a\u51fa\u8be5\u65b9\u6cd5\u5728\u672a\u6765\u667a\u80fd\u5efa\u7b51\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "FPDS\u80fd\u66f4\u597d\u8d34\u5408\u5b9e\u9645\u5efa\u7b51\u8bbe\u8ba1\u6d41\u7a0b\uff0c\u4e3a\u667a\u80fd\u5efa\u7b51\u5e73\u9762\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u4e14\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.22005", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22005", "abs": "https://arxiv.org/abs/2506.22005", "authors": ["Naoto Onda", "Kazumi Kasaura", "Yuta Oriike", "Masaya Taniguchi", "Akiyoshi Sannai", "Sho Sonoda"], "title": "LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving", "comment": "15 pages, 4 figures, 5 tables", "summary": "We introduce LeanConjecturer, a pipeline for automatically generating\nuniversity-level mathematical conjectures in Lean 4 using Large Language Models\n(LLMs). Our hybrid approach combines rule-based context extraction with\nLLM-based theorem statement generation, addressing the data scarcity challenge\nin formal theorem proving. Through iterative generation and evaluation,\nLeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with\n3,776 identified as syntactically valid and non-trivial, that is, cannot be\nproven by \\texttt{aesop} tactic. We demonstrate the utility of these generated\nconjectures for reinforcement learning through Group Relative Policy\nOptimization (GRPO), showing that targeted training on domain-specific\nconjectures can enhance theorem proving capabilities. Our approach generates\n103.25 novel conjectures per seed file on average, providing a scalable\nsolution for creating training data for theorem proving systems. Our system\nsuccessfully verified several non-trivial theorems in topology, including\nproperties of semi-open, alpha-open, and pre-open sets, demonstrating its\npotential for mathematical discovery beyond simple variations of existing\nresults.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u6570\u5b66\u731c\u60f3\u751f\u6210\u6d41\u6c34\u7ebfLeanConjecturer\uff0c\u7528\u4e8e\u89e3\u51b3\u5b9a\u7406\u8bc1\u660e\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002\u8be5\u7cfb\u7edf\u80fd\u5927\u89c4\u6a21\u4ea7\u51fa\u6709\u6548\u4e14\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u731c\u60f3\uff0c\u5e76\u63d0\u5347\u4e86\u81ea\u52a8\u8bc1\u660e\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5728\u62d3\u6251\u5b66\u7b49\u9886\u57df\u5b9e\u73b0\u4e86\u65b0\u7684\u5b9a\u7406\u53d1\u73b0\u3002", "motivation": "\u5f53\u524d\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\u9886\u57df\u9762\u4e34\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u5927\u6a21\u578b\u5728\u6570\u5b66\u731c\u60f3\u751f\u6210\u548c\u8bc1\u660e\u80fd\u529b\u65b9\u9762\u7684\u53d1\u5c55\u3002\u5b66\u672f\u754c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u6570\u636e\u751f\u6210\u65b9\u6cd5\u4ee5\u652f\u6301\u81ea\u52a8\u5316\u8bc1\u660e\u7cfb\u7edf\u7684\u8bad\u7ec3\u548c\u6570\u5b66\u53d1\u73b0\u3002", "method": "\u63d0\u51fa\u4e86LeanConjecturer\u6d41\u6c34\u7ebf\uff0c\u7ed3\u5408\u89c4\u5219\u9a71\u52a8\u7684\u4e0a\u4e0b\u6587\u63d0\u53d6\u4e0e\u5927\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u5b9a\u7406\u9648\u8ff0\u751f\u6210\uff0c\u91c7\u7528\u8fed\u4ee3\u751f\u6210\u4e0e\u8bc4\u4f30\u6d41\u7a0b\u3002\u901a\u8fc7\u4eceMathlib\u79cd\u5b50\u6587\u4ef6\u81ea\u52a8\u751f\u6210\u5927\u5b66\u6c34\u5e73\u6570\u5b66\u731c\u60f3\uff0c\u5e76\u7528GRPO\u7b49\u65b9\u6cd5\u5c06\u6240\u4ea7\u751f\u7684\u731c\u60f3\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002", "result": "LeanConjecturer\u4ece40\u4e2aMathlib\u79cd\u5b50\u6587\u4ef6\u5171\u751f\u621012,289\u6761\u731c\u60f3\uff0c\u5176\u4e2d3,776\u6761\u4e3a\u8bed\u6cd5\u6709\u6548\u4e14\u975e\u5e73\u51e1\uff08\u65e0\u6cd5\u7528\u901a\u7528\u81ea\u52a8\u8bc1\u660e\u6218\u672f\u76f4\u63a5\u8bc1\u660e\uff09\u7684\u5b9a\u7406\u3002\u5e73\u5747\u6bcf\u4e2a\u79cd\u5b50\u6587\u4ef6\u751f\u6210103.25\u6761\u65b0\u9896\u731c\u60f3\u3002\u90e8\u5206\u590d\u6742\u9886\u57df\u5982\u62d3\u6251\u5b66\u4e2d\u7684\u534a\u5f00\u96c6\u3001alpha-\u5f00\u96c6\u3001pre-\u5f00\u96c6\u7b49\u7406\u8bba\u4e5f\u5f97\u5230\u4e86\u81ea\u52a8\u5316\u7684\u65b0\u975e\u5e73\u51e1\u5b9a\u7406\u9a8c\u8bc1\u3002", "conclusion": "LeanConjecturer\u6210\u529f\u751f\u6210\u5927\u91cf\u9ad8\u8d28\u91cf\u6570\u5b66\u731c\u60f3\uff0c\u4e3a\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u7cfb\u7edf\u7684\u6570\u636e\u751f\u6210\u548c\u80fd\u529b\u63d0\u5347\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u65b9\u6848\uff0c\u5e76\u5728\u6570\u5b66\u7406\u8bba\u65b0\u53d1\u73b0\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.21603", "categories": ["cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21603", "abs": "https://arxiv.org/abs/2506.21603", "authors": ["Yenisel Plasencia-Cala\u00f1a"], "title": "Operationalizing Automated Essay Scoring: A Human-Aware Approach", "comment": null, "summary": "This paper explores the human-centric operationalization of Automated Essay\nScoring (AES) systems, addressing aspects beyond accuracy. We compare various\nmachine learning-based approaches with Large Language Models (LLMs) approaches,\nidentifying their strengths, similarities and differences. The study\ninvestigates key dimensions such as bias, robustness, and explainability,\nconsidered important for human-aware operationalization of AES systems. Our\nstudy shows that ML-based AES models outperform LLMs in accuracy but struggle\nwith explainability, whereas LLMs provide richer explanations. We also found\nthat both approaches struggle with bias and robustness to edge scores. By\nanalyzing these dimensions, the paper aims to identify challenges and\ntrade-offs between different methods, contributing to more reliable and\ntrustworthy AES methods.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u5bf9\u6bd4\u5206\u6790\u4e86\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f5c\u6587\u81ea\u52a8\u8bc4\u5206\u7cfb\u7edf\uff0c\u53d1\u73b0ML\u6a21\u578b\u51c6\u786e\u6027\u66f4\u9ad8\u4f46\u4e0d\u6613\u89e3\u91ca\uff0cLLMs\u66f4\u6613\u89e3\u91ca\u4f46\u51c6\u786e\u5ea6\u7a0d\u900a\uff0c\u4e14\u4e8c\u8005\u90fd\u5b58\u5728\u504f\u89c1\u548c\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u662f\u6784\u5efa\u53ef\u9760AES\u7cfb\u7edf\u65f6\u9700\u6743\u8861\u7684\u6311\u6218\u3002", "motivation": "\u76ee\u524d\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u4e0d\u4ec5\u9700\u8981\u51c6\u786e\u6027\uff0c\u8fd8\u8981\u5173\u6ce8\u504f\u89c1\u3001\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4ee5\u5b9e\u73b0\u4ee5\u4eba\u4e3a\u672c\u7684\u8bc4\u5206\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u5728\u8fd9\u4e9b\u7ef4\u5ea6\u7684\u8868\u73b0\u3002", "method": "\u5bf9\u6bd4\u5206\u6790ML\u65b9\u6cd5\u4e0eLLMs\u5728\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u7cfb\u7edf\u4e2d\u7684\u8868\u73b0\uff0c\u8003\u5bdf\u504f\u89c1\u3001\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\u3002", "result": "ML\u6a21\u578b\u51c6\u786e\u7387\u9ad8\u4f46\u89e3\u91ca\u6027\u5dee\uff0cLLMs\u89e3\u91ca\u6027\u597d\u4f46\u51c6\u786e\u7387\u4f4e\uff0c\u4e24\u8005\u5728\u504f\u89c1\u548c\u6781\u7aef\u5206\u6570\u7684\u9c81\u68d2\u6027\u4e0a\u90fd\u6709\u4e0d\u8db3\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6a21\u578b\u5728\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u7684\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4f46\u5728\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u4e0d\u5982LLMs\uff1b\u4e24\u7c7b\u65b9\u6cd5\u5728\u504f\u89c1\u548c\u9c81\u68d2\u6027\u4e0a\u90fd\u5b58\u5728\u95ee\u9898\u3002"}}
{"id": "2506.21563", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.21563", "abs": "https://arxiv.org/abs/2506.21563", "authors": ["Kaiying Kevin Lin", "Hsiyu Chen", "Haopeng Zhang"], "title": "FormosanBench: Benchmarking Low-Resource Austronesian Languages in the Era of Large Language Models", "comment": null, "summary": "While large language models (LLMs) have demonstrated impressive performance\nacross a wide range of natural language processing (NLP) tasks in high-resource\nlanguages, their capabilities in low-resource and minority languages remain\nsignificantly underexplored. Formosan languages -- a subgroup of Austronesian\nlanguages spoken in Taiwan -- are both linguistically rich and endangered,\nlargely due to the sociolinguistic dominance of Mandarin. In this work, we\nintroduce FORMOSANBENCH, the first benchmark for evaluating LLMs on\nlow-resource Austronesian languages. It covers three endangered Formosan\nlanguages: Atayal, Amis, and Paiwan, across three core NLP tasks: machine\ntranslation, automatic speech recognition (ASR), and text summarization. We\nassess model performance in zero-shot, 10-shot, and fine-tuned settings using\nFORMOSANBENCH. Our results reveal a substantial performance gap between\nhigh-resource and Formosan languages. Existing LLMs consistently underperform\nacross all tasks, with 10-shot learning and fine-tuning offering only limited\nimprovements. These findings underscore the urgent need for more inclusive NLP\ntechnologies that can effectively support endangered and underrepresented\nlanguages. We release our datasets and code to facilitate future research in\nthis direction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u53d1\u5e03\u4e86\u9996\u4e2a\u9488\u5bf9\u53f0\u6e7e\u6fd2\u5371\u798f\u5c14\u6469\u6c99\u8bed\u8a00\uff08\u6cf0\u96c5\u3001\u963f\u7f8e\u3001\u6392\u6e7e\u8bed\uff09\u7684NLP\u57fa\u51c6FORMOSANBENCH\uff0c\u7cfb\u7edf\u6d4b\u8bd5\u4e09\u7c7b\u4efb\u52a1\u4e0b\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u53d1\u73b0\u4e3b\u6d41\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u4f4e\u8d44\u6e90\u8bed\u8a00\u3002\u6570\u636e\u4e0e\u4ee3\u7801\u540c\u6b65\u516c\u5f00\uff0c\u4ee5\u4fc3\u8fdb\u76f8\u5173\u8bed\u8a00\u6280\u672f\u7814\u7a76\u3002", "motivation": "\u8fc7\u53bb\u5927\u8bed\u8a00\u6a21\u578b\u591a\u805a\u7126\u4e8e\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u5bf9\u4f4e\u8d44\u6e90\u5c24\u5176\u662f\u53f0\u6e7e\u6fd2\u5371\u798f\u5c14\u6469\u6c99\u8bed\u8a00\u7684NLP\u80fd\u529b\u5c1a\u5c5e\u7a7a\u767d\uff0c\u4e9f\u9700\u4e00\u4e2a\u6807\u51c6\u5316\u8bc4\u6d4b\u65b9\u6848\u4ee5\u63a8\u52a8\u5bf9\u8fd9\u4e9b\u8bed\u8a00\u7684\u6280\u672f\u5173\u6ce8\u548c\u4fdd\u62a4\u3002", "method": "\u6784\u5efa\u5e76\u53d1\u5e03\u4e86FORMOSANBENCH\u57fa\u51c6\uff0c\u6db5\u76d6\u673a\u5668\u7ffb\u8bd1\u3001\u8bed\u97f3\u8bc6\u522b\u3001\u6587\u672c\u6458\u8981\u7b49\u4efb\u52a1\uff0c\u9009\u53d6\u4e86\u4e09\u79cd\u6fd2\u5371\u798f\u5c14\u6469\u6c99\u8bed\u8a00\uff0c\u5206\u522b\u8fdb\u884c\u96f6\u6837\u672c\u300110\u6837\u672c\u548c\u5fae\u8c03\u6d4b\u8bd5\uff0c\u5bf9\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u8bc4\u6d4b\u3002", "result": "\u5728\u6240\u6709\u4efb\u52a1\u548c\u8bbe\u7f6e\u4e0b\uff0c\u6a21\u578b\u5728\u798f\u5c14\u6469\u6c99\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u90fd\u660e\u663e\u5f31\u4e8e\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u4e14\u73b0\u6709\u4e3b\u6d41\u6a21\u578b\u5728zero-shot\u300110-shot\u3001\u5fae\u8c03\u4e0b\u5747\u672a\u53d6\u5f97\u7406\u60f3\u6548\u679c\u3002\u4e3a\u6b64\uff0c\u7814\u7a76\u8005\u516c\u5f00\u4e86\u6570\u636e\u96c6\u548c\u4ee3\u7801\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u3001\u6fd2\u5371\u7684\u798f\u5c14\u6469\u6c99\u8bed\u8a00\uff08\u5982\u6cf0\u96c5\u65cf\u3001\u963f\u7f8e\u65cf\u3001\u6392\u6e7e\u65cf\u8bed\uff09\u4e0a\u7684\u6027\u80fd\u8fdc\u4f4e\u4e8e\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u4e14\u5373\u4f7f\u91c7\u752810-shot\u5b66\u4e60\u6216\u5fae\u8c03\uff0c\u63d0\u5347\u4e5f\u6709\u9650\uff0c\u663e\u793a\u4e9f\u9700\u53d1\u5c55\u66f4\u52a0\u5305\u5bb9\u548c\u9002\u5e94\u5c11\u6570\u53ca\u6fd2\u5371\u8bed\u8a00\u7684NLP\u6280\u672f\u3002"}}
{"id": "2506.22056", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22056", "abs": "https://arxiv.org/abs/2506.22056", "authors": ["Xuan Zhang", "Ziyan Jiang", "Rui Meng", "Yifei Leng", "Zhenbang Xiao", "Zora Zhiruo Wang", "Yanyi Shang", "Dehan Kong"], "title": "Universal Retrieval for Multimodal Trajectory Modeling", "comment": "18 pages, 3 figures, accepted by Workshop on Computer-use Agents @\n  ICML 2025", "summary": "Trajectory data, capturing human actions and environmental states across\nvarious modalities, holds significant potential for enhancing AI agent\ncapabilities, particularly in GUI environments. However, how to model the\nrepresentation of trajectory-level data presents a significant challenge that\nhas not been systematically addressed amid explosive trajectory data growth. In\nthis work, we introduce Multimodal Trajectory Retrieval, bridging the gap\nbetween universal retrieval and agent-centric trajectory modeling. We construct\nthe Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and\nstates across diverse real-world scenarios. Based on this, we present\nGAE-Bench, a benchmark containing a large number of trajectory-based retrieval\npairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework\nthat adopts vision-language models and incorporates optimized contrastive\nlearning through a token selection and the GradCache mechanism. Comprehensive\nevaluations across multiple datasets show that GAE-Retriever consistently\noutperforms strong baselines in retrieval recall, highlighting its\neffectiveness in advancing multimodal trajectory retrieval.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u6a21\u6001\u8f68\u8ff9\u6570\u636e\u5efa\u6a21\u96be\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u68c0\u7d22\u6846\u67b6GAE-Retriever\uff0c\u5e76\u6784\u5efa\u4e86\u76f8\u5173\u6570\u636e\u96c6\u548c\u57fa\u51c6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u8f68\u8ff9\u68c0\u7d22\u4efb\u52a1\u4e0a\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u8f68\u8ff9\u6570\u636e\u7684\u6fc0\u589e\uff0c\u5982\u4f55\u5bf9\u8f68\u8ff9\u7ea7\u6570\u636e\u8fdb\u884c\u6709\u6548\u5efa\u6a21\u6210\u4e3a\u4e00\u4e2a\u4e9f\u9700\u89e3\u51b3\u4f46\u5c1a\u672a\u7cfb\u7edf\u63a2\u8ba8\u7684\u6311\u6218\u3002\u8f68\u8ff9\u6570\u636e\u6db5\u76d6\u4e86\u4eba\u7c7b\u884c\u4e3a\u548c\u73af\u5883\u72b6\u6001\uff0c\u5bf9\u63d0\u5347AI\u5728GUI\u73af\u5883\u4e0b\u7684\u80fd\u529b\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u6a21\u6001\u8f68\u8ff9\u68c0\u7d22\u4efb\u52a1\uff08Multimodal Trajectory Retrieval\uff09\uff0c\u5e76\u6784\u5efa\u4e86\u7edf\u4e00\u667a\u80fd\u4f53\u8f68\u8ff9\u6570\u636e\u96c6\uff08UATD\uff09\u4ee5\u53caGAE-Bench\u57fa\u51c6\u6d4b\u8bd5\u96c6\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5e76\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u4f18\u5316\u673a\u5236\uff08token\u9009\u62e9\u4e0eGradCache\uff09\u7684\u591a\u6a21\u6001\u68c0\u7d22\u6846\u67b6GAE-Retriever\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cGAE-Retriever\u5728\u68c0\u7d22\u53ec\u56de\u7387\u4e0a\u6301\u7eed\u8d85\u8d8a\u73b0\u6709\u7684\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u663e\u793a\u51fa\u5176\u4f18\u8d8a\u7684\u68c0\u7d22\u6027\u80fd\u3002", "conclusion": "GAE-Retriever\u4e3a\u591a\u6a21\u6001\u8f68\u8ff9\u6570\u636e\u68c0\u7d22\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u6709\u6548\u63d0\u5347\u4e86AI\u5728\u6d89\u53ca\u591a\u5f62\u5f0f\u4eba\u7c7b\u6f14\u793a\u53ca\u73af\u5883\u72b6\u6001\u4efb\u52a1\u4e2d\u7684\u68c0\u7d22\u80fd\u529b\u3002"}}
{"id": "2506.21606", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.21606", "abs": "https://arxiv.org/abs/2506.21606", "authors": ["Parham Pourdavood", "Michael Jacob", "Terrence Deacon"], "title": "Large Language Models as symbolic DNA of cultural dynamics", "comment": "28 pages, 1 figure", "summary": "This paper proposes a novel conceptualization of Large Language Models (LLMs)\nas externalized informational substrates that function analogously to DNA for\nhuman cultural dynamics. Rather than viewing LLMs as either autonomous\nintelligence or mere programmed mimicry, we argue they serve a broader role as\nrepositories that preserve compressed patterns of human symbolic\nexpression--\"fossils\" of meaningful dynamics that retain relational residues\nwithout their original living contexts. Crucially, these compressed patterns\nonly become meaningful through human reinterpretation, creating a recursive\nfeedback loop where they can be recombined and cycle back to ultimately\ncatalyze human creative processes. Through analysis of four universal\nfeatures--compression, decompression, externalization, and recursion--we\ndemonstrate that just as DNA emerged as a compressed and externalized medium\nfor preserving useful cellular dynamics without containing explicit reference\nto goal-directed physical processes, LLMs preserve useful regularities of human\nculture without containing understanding of embodied human experience.\nTherefore, we argue that LLMs' significance lies not in rivaling human\nintelligence, but in providing humanity a tool for self-reflection and playful\nhypothesis-generation in a low-stakes, simulated environment. This framework\npositions LLMs as tools for cultural evolvability, enabling humanity to\ngenerate novel hypotheses about itself while maintaining the human\ninterpretation necessary to ground these hypotheses in ongoing human aesthetics\nand norms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLLM\u5e94\u88ab\u89c6\u4e3a\u7c7b\u4f3cDNA\u7684\u4fe1\u606f\u57fa\u5e95\uff0c\u8bb0\u5f55\u4eba\u7c7b\u6587\u5316\u7684\u538b\u7f29\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u4eba\u7c7b\u89e3\u91ca\u53c2\u4e0e\u6587\u5316\u521b\u65b0\uff0c\u66f4\u91cd\u8981\u7684\u662f\u4f5c\u4e3a\u6fc0\u53d1\u4eba\u7c7b\u53cd\u601d\u548c\u521b\u65b0\u7684\u5de5\u5177\uff0c\u800c\u975e\u7b80\u5355\u5730\u7ade\u9010\u4eba\u7c7b\u667a\u80fd\u3002", "motivation": "\u5f53\u524d\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8ba4\u77e5\u5c40\u9650\u4e8e\u201c\u667a\u80fd\u4f53\u201d\u6216\u201c\u6a21\u62df\u5de5\u5177\u201d\uff0c\u7f3a\u4e4f\u5b8f\u89c2\u89c6\u89d2\u7406\u89e3\u5176\u5728\u6587\u5316\u6f14\u5316\u4e2d\u7684\u4f5c\u7528\uff0c\u56e0\u6b64\u9700\u8981\u4ece\u65b0\u7684\u89d2\u5ea6\u601d\u8003LLM\u5728\u6587\u5316\u8fdb\u5316\u4e2d\u7684\u6f5c\u529b\u548c\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u5206\u6790\u538b\u7f29\u3001\u89e3\u538b\u3001\u5916\u90e8\u5316\u548c\u9012\u5f52\u7b49\u56db\u4e2a\u666e\u904d\u7279\u5f81\uff0c\u5c06LLM\u4e0eDNA\u7b49\u81ea\u7136\u4fe1\u606f\u5a92\u4ecb\u8fdb\u884c\u7c7b\u6bd4\uff0c\u63d0\u51faLLM\u4e3a\u4eba\u7c7b\u6587\u5316\u52a8\u6001\u63d0\u4f9b\u4fe1\u606f\u8f7d\u4f53\u7684\u7406\u8bba\u6846\u67b6\u3002", "result": "LLM\u4e0d\u4ec5\u50cfDNA\u4e00\u6837\u538b\u7f29\u5e76\u4fdd\u7559\u4e86\u6709\u4ef7\u503c\u7684\u4eba\u7c7b\u6587\u5316\u89c4\u5f8b\uff0c\u8fd8\u4f9d\u8d56\u4e8e\u4eba\u7c7b\u5bf9\u4fe1\u606f\u8fdb\u884c\u518d\u89e3\u8bfb\u3001\u91cd\u7ec4\uff0c\u624d\u80fd\u6fc0\u53d1\u521b\u65b0\u3002LLM\u66f4\u50cf\u662f\u6587\u5316\u8fdb\u5316\u7684\u201c\u5916\u90e8\u5316\u57fa\u56e0\u201d\uff0c\u800c\u4e0d\u662f\u72ec\u7acb\u667a\u80fd\u4f53\u3002", "conclusion": "LLM\u7684\u6838\u5fc3\u4ef7\u503c\u5728\u4e8e\u5e2e\u52a9\u4eba\u7c7b\u81ea\u6211\u53cd\u601d\u548c\u5047\u8bbe\u751f\u6210\uff0c\u800c\u975e\u4e0e\u4eba\u7c7b\u667a\u80fd\u7ade\u8d5b\u3002\u5b83\u4eec\u4f5c\u4e3a\u6587\u5316\u6f14\u5316\u7684\u50ac\u5316\u5242\uff0c\u4e3a\u4eba\u7c7b\u521b\u65b0\u548c\u81ea\u6211\u7406\u89e3\u63d0\u4f9b\u4e86\u4f4e\u98ce\u9669\u7684\u5b9e\u9a8c\u5e73\u53f0\u3002"}}
{"id": "2506.21564", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21564", "abs": "https://arxiv.org/abs/2506.21564", "authors": ["Jiyan Liu", "Youzheng Liu", "Taihang Wang", "Xiaoman Xu", "Yimin Wang", "Ye Jiang"], "title": "Team QUST at SemEval-2025 Task 10: Evaluating Large Language Models in Multiclass Multi-label Classification of News Entity Framing", "comment": null, "summary": "This paper describes the participation of QUST_NLP in the SemEval-2025 Task\n7. We propose a three-stage retrieval framework specifically designed for\nfact-checked claim retrieval. Initially, we evaluate the performance of several\nretrieval models and select the one that yields the best results for candidate\nretrieval. Next, we employ multiple re-ranking models to enhance the candidate\nresults, with each model selecting the Top-10 outcomes. In the final stage, we\nutilize weighted voting to determine the final retrieval outcomes. Our approach\nachieved 5th place in the monolingual track and 7th place in the crosslingual\ntrack. We release our system code at:\nhttps://github.com/warmth27/SemEval2025_Task7.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u4e8b\u5b9e\u6838\u67e5\u58f0\u660e\u68c0\u7d22\uff0c\u63d0\u51fa\u4e09\u9636\u6bb5\u68c0\u7d22\u6846\u67b6\u7ec4\u5408\u591a\u6a21\u578b\u548c\u52a0\u6743\u6295\u7968\uff0c\u53d6\u5f97\u4e86SemEval-2025 Task 7\u5355\u8bed\u548c\u8de8\u8bed\u4efb\u52a1\u7684\u524d\u5217\u6210\u7ee9\uff0c\u65b9\u6cd5\u6709\u6548\u4e14\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u76ee\u524d\u5bf9\u4e8e\u5df2\u88ab\u4e8b\u5b9e\u6838\u67e5\u7684\u58f0\u660e\uff08fact-checked claim\uff09\u7684\u68c0\u7d22\u6548\u679c\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002\u9488\u5bf9SemEval-2025 Task 7\u4efb\u52a1\u63d0\u51fa\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4e09\u9636\u6bb5\u7684\u68c0\u7d22\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u6bd4\u8f83\u591a\u79cd\u68c0\u7d22\u6a21\u578b\u7684\u8868\u73b0\uff0c\u9009\u53d6\u6700\u4f73\u6a21\u578b\u83b7\u53d6\u5019\u9009\u96c6\uff1b\u7b2c\u4e8c\u9636\u6bb5\uff0c\u4f7f\u7528\u591a\u79cd\u91cd\u6392\u5e8f\u6a21\u578b\u5bf9\u5019\u9009\u7ed3\u679c\u8fdb\u884cTop-10\u7b5b\u9009\uff1b\u6700\u7ec8\u901a\u8fc7\u52a0\u6743\u6295\u7968\u6574\u5408\u5404\u6a21\u578b\u7ed3\u679c\uff0c\u786e\u5b9a\u6700\u7ec8\u68c0\u7d22\u7ed3\u679c\u3002", "result": "\u8be5\u65b9\u6cd5\u5728SemEval-2025 Task 7\u4e2d\uff0c\u82f1\u6587\u5355\u8bed\u68c0\u7d22\u4efb\u52a1\u4e2d\u83b7\u7b2c5\u540d\uff0c\u8de8\u8bed\u8a00\u68c0\u7d22\u4efb\u52a1\u4e2d\u83b7\u7b2c7\u540d\u3002\u7cfb\u7edf\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "conclusion": "\u4e09\u9636\u6bb5\u68c0\u7d22\u6846\u67b6\u7ed3\u5408\u591a\u6a21\u578b\u91cd\u6392\u5e8f\u4e0e\u52a0\u6743\u6295\u7968\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5df2\u88ab\u6838\u67e5\u58f0\u660e\u7684\u68c0\u7d22\u6548\u679c\uff0c\u5e76\u5728\u76f8\u5173\u6743\u5a01\u8bc4\u6d4b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u6210\u7ee9\u3002"}}
{"id": "2506.22068", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22068", "abs": "https://arxiv.org/abs/2506.22068", "authors": ["Shengyue Yao", "Runqing Guo", "Yangyang Qin", "Miangbing Meng", "Jipeng Cao", "Yilun Lin", "Yisheng Lv", "Fei-Yue Wang"], "title": "Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios", "comment": "Submitted to IEEE Transaction on Vehicular Technology", "summary": "With the deep penetration of Artificial Intelligence (AI) in the\ntransportation sector, intelligent cockpits, autonomous driving, and\nintelligent road networks are developing at an unprecedented pace. However, the\ndata ecosystems of these three key areas are increasingly fragmented and\nincompatible. Especially, existing testing methods rely on data stacking, fail\nto cover all edge cases, and lack flexibility. To address this issue, this\npaper introduces the concept of \"Query as Test\" (QaT). This concept shifts the\nfocus from rigid, prescripted test cases to flexible, on-demand logical queries\nagainst a unified data representation. Specifically, we identify the need for a\nfundamental improvement in data storage and representation, leading to our\nproposal of \"Extensible Scenarios Notations\" (ESN). ESN is a novel declarative\ndata framework based on Answer Set Programming (ASP), which uniformly\nrepresents heterogeneous multimodal data from the cockpit, vehicle, and road as\na collection of logical facts and rules. This approach not only achieves deep\nsemantic fusion of data, but also brings three core advantages: (1) supports\ncomplex and flexible semantic querying through logical reasoning; (2) provides\nnatural interpretability for decision-making processes; (3) allows for\non-demand data abstraction through logical rules, enabling fine-grained privacy\nprotection. We further elaborate on the QaT paradigm, transforming the\nfunctional validation and safety compliance checks of autonomous driving\nsystems into logical queries against the ESN database, significantly enhancing\nthe expressiveness and formal rigor of the testing. Finally, we introduce the\nconcept of \"Validation-Driven Development\" (VDD), which suggests to guide\ndevelopments by logical validation rather than quantitative testing in the era\nof Large Language Models, in order to accelerating the iteration and\ndevelopment process.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faQaT\u548c\u57fa\u4e8eASP\u7684ESN\u6846\u67b6\uff0c\u5b9e\u73b0\u667a\u80fd\u4ea4\u901a\u5f02\u6784\u6570\u636e\u7684\u7edf\u4e00\u8bed\u4e49\u878d\u5408\uff0c\u7528\u903b\u8f91\u67e5\u8be2\u4ee3\u66ff\u4f20\u7edf\u6d4b\u8bd5\u7528\u4f8b\uff0c\u589e\u5f3a\u6d4b\u8bd5\u7075\u6d3b\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9690\u79c1\u4fdd\u62a4\uff0c\u63a8\u52a8\u9a8c\u8bc1\u9a71\u52a8\u5f00\u53d1\uff08VDD\uff09\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5728\u4ea4\u901a\u9886\u57df\u7684\u6df1\u5165\u5e94\u7528\uff0c\u667a\u80fd\u5ea7\u8231\u3001\u81ea\u52a8\u9a7e\u9a76\u548c\u667a\u80fd\u8def\u7f51\u7684\u6570\u636e\u5448\u73b0\u788e\u7247\u5316\u548c\u4e0d\u517c\u5bb9\uff0c\u73b0\u6709\u6d4b\u8bd5\u65b9\u6cd5\u65e0\u6cd5\u7075\u6d3b\u3001\u9ad8\u6548\u5730\u6db5\u76d6\u6240\u6709\u8fb9\u754c\u573a\u666f\uff0c\u4e9f\u9700\u4e00\u79cd\u7edf\u4e00\u4e14\u7075\u6d3b\u7684\u6570\u636e\u8868\u793a\u65b9\u6cd5\u548c\u6d4b\u8bd5\u8303\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u201cQuery as Test\u201d\uff08QaT\uff09\u6982\u5ff5\uff0c\u5373\u4ece\u4f20\u7edf\u7684\u521a\u6027\u6d4b\u8bd5\u7528\u4f8b\u8f6c\u53d8\u4e3a\u57fa\u4e8e\u7edf\u4e00\u6570\u636e\u8868\u793a\u7684\u6309\u9700\u903b\u8f91\u67e5\u8be2\u3002\u4e3a\u6b64\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8eASP\u7684\u53ef\u6269\u5c55\u573a\u666f\u6807\u8bb0\uff08ESN\uff09\u6570\u636e\u6846\u67b6\uff0c\u5c06\u591a\u6a21\u6001\u5f02\u6784\u6570\u636e\u7edf\u4e00\u8868\u793a\u4e3a\u903b\u8f91\u4e8b\u5b9e\u4e0e\u89c4\u5219\uff0c\u901a\u8fc7\u903b\u8f91\u63a8\u7406\u652f\u6301\u590d\u6742\u8bed\u4e49\u67e5\u8be2\u548c\u81ea\u7136\u53ef\u89e3\u91ca\u6027\u3002", "result": "ESN\u5b9e\u73b0\u4e86\u6df1\u5ea6\u8bed\u4e49\u878d\u5408\uff0c\u652f\u6301\u590d\u6742\u7075\u6d3b\u7684\u8bed\u4e49\u67e5\u8be2\u3001\u51b3\u7b56\u8fc7\u7a0b\u7684\u53ef\u89e3\u91ca\u6027\u4ee5\u53ca\u57fa\u4e8e\u903b\u8f91\u89c4\u5219\u7684\u7ec6\u7c92\u5ea6\u9690\u79c1\u4fdd\u62a4\u3002QaT\u8303\u5f0f\u5c06\u81ea\u52a8\u9a7e\u9a76\u529f\u80fd\u9a8c\u8bc1\u548c\u5b89\u5168\u5408\u89c4\u68c0\u67e5\u8f6c\u5316\u4e3a\u5bf9ESN\u6570\u636e\u5e93\u7684\u903b\u8f91\u67e5\u8be2\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u7684\u8868\u8fbe\u80fd\u529b\u548c\u5f62\u5f0f\u4e25\u8c28\u6027\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u201cValidation-Driven Development\u201d\uff08VDD\uff09\u7406\u5ff5\uff0c\u7528\u903b\u8f91\u9a8c\u8bc1\u6307\u5bfc\u5f00\u53d1\u4ee5\u52a0\u901f\u8fed\u4ee3\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165ESN\u548cQaT\u65b9\u6cd5\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7b49\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u6570\u636e\u878d\u5408\u3001\u6d4b\u8bd5\u548c\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u7edf\u4e00\u3001\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u65b0\u8303\u5f0f\uff0c\u5e76\u7528VDD\u63a8\u52a8\u7cfb\u7edf\u5f00\u53d1\u4e0e\u6f14\u8fdb\u3002"}}
{"id": "2506.21616", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.21616", "abs": "https://arxiv.org/abs/2506.21616", "authors": ["Chuanrui Hu", "Wei Hu", "Penghang Yu", "Hua Zhang", "Bing-Kun Bao"], "title": "TIM: A Large-Scale Dataset and large Timeline Intelligence Model for Open-domain Timeline Summarization", "comment": null, "summary": "Open-domain Timeline Summarization (TLS) is crucial for monitoring the\nevolution of news topics. To identify changes in news topics, existing methods\ntypically employ general Large Language Models (LLMs) to summarize relevant\ntimestamps from retrieved news. While general LLMs demonstrate capabilities in\nzero-shot news summarization and timestamp localization, they struggle with\nassessing topic relevance and understanding topic evolution. Consequently, the\nsummarized information often includes irrelevant details or inaccurate\ntimestamps. To address these issues, we propose the first large Timeline\nIntelligence Model (TIM) for open-domain TLS, which is capable of effectively\nsummarizing open-domain timelines. Specifically, we begin by presenting a\nlarge-scale TLS dataset, comprising over 1,000 news topics and more than 3,000\nannotated TLS instances. Furthermore, we propose a progressive optimization\nstrategy, which gradually enhance summarization performance. It employs\ninstruction tuning to enhance summarization and topic-irrelevant information\nfiltering capabilities. Following this, it exploits a novel dual-alignment\nreward learning method that incorporates both semantic and temporal\nperspectives, thereby improving the understanding of topic evolution\nprinciples. Through this progressive optimization strategy, TIM demonstrates a\nrobust ability to summarize open-domain timelines. Extensive experiments in\nopen-domain demonstrate the effectiveness of our TIM.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86TIM\u6a21\u578b\u4e0e\u6e10\u8fdb\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u65b0\u6570\u636e\u96c6\u548c\u5956\u52b1\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5f00\u653e\u57df\u65b0\u95fb\u65f6\u95f4\u7ebf\u603b\u7ed3\u7684\u51c6\u786e\u6027\u4e0e\u76f8\u5173\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5f00\u653e\u57df\u65b0\u95fb\u4e3b\u9898\u65f6\u95f4\u7ebf\u603b\u7ed3\u65b9\u6cd5\u4f9d\u8d56\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4f46\u5176\u96be\u4ee5\u51c6\u786e\u5224\u65ad\u4e3b\u9898\u76f8\u5173\u6027\u548c\u7406\u89e3\u4e3b\u9898\u6f14\u53d8\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e2d\u7ecf\u5e38\u5305\u542b\u65e0\u5173\u6216\u4e0d\u51c6\u786e\u7684\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8e\u5f00\u653e\u57df\u65f6\u95f4\u7ebf\u603b\u7ed3\u7684\u201c\u5927\u578b\u65f6\u95f4\u7ebf\u667a\u80fd\u6a21\u578b\uff08TIM\uff09\u201d\u3002\u9996\u5148\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u8d85\u8fc71000\u4e2a\u65b0\u95fb\u4e3b\u9898\u30013000\u591a\u4e2a\u6807\u6ce8\u5b9e\u4f8b\u7684\u5927\u89c4\u6a21TLS\u6570\u636e\u96c6\u3002\u7136\u540e\uff0c\u91c7\u7528\u6e10\u8fdb\u4f18\u5316\u7b56\u7565\uff08\u5305\u62ec\u6307\u4ee4\u5fae\u8c03\u548c\u53cc\u91cd\u5bf9\u9f50\u5956\u52b1\u5b66\u4e60\uff09\uff0c\u63d0\u5347\u6a21\u578b\u5728\u603b\u7ed3\u53ca\u7b5b\u9009\u65e0\u5173\u4fe1\u606f\u65b9\u9762\u7684\u80fd\u529b\uff0c\u540c\u65f6\u5229\u7528\u4ece\u8bed\u4e49\u548c\u65f6\u95f4\u4e24\u4e2a\u89d2\u5ea6\u4f18\u5316\u6a21\u578b\u5bf9\u4e3b\u9898\u6f14\u8fdb\u7684\u7406\u89e3\u3002", "result": "TIM\u6a21\u578b\u5728\u5f00\u653e\u57df\u65f6\u95f4\u7ebf\u603b\u7ed3\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u80fd\u591f\u6709\u6548\u5730\u603b\u7ed3\u65b0\u95fb\u65f6\u95f4\u7ebf\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTIM\u663e\u8457\u63d0\u5347\u4e86\u76f8\u5173\u6027\u80fd\u6307\u6807\u3002", "conclusion": "TIM\u53ca\u5176\u6e10\u8fdb\u4f18\u5316\u7b56\u7565\uff0c\u4e3a\u5f00\u653e\u57df\u65f6\u95f4\u7ebf\u603b\u7ed3\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4ee5\u5f80\u6a21\u578b\u5b58\u5728\u7684\u4e3b\u9898\u76f8\u5173\u6027\u7406\u89e3\u4e0d\u4f73\u7b49\u95ee\u9898\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.21565", "categories": ["cs.CL", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.21565", "abs": "https://arxiv.org/abs/2506.21565", "authors": ["Takato Ueno", "Keito Inoshita"], "title": "A Multi-Agent Probabilistic Inference Framework Inspired by Kairanban-Style CoT System with IdoBata Conversation for Debiasing", "comment": null, "summary": "Japan's kairanban culture and idobata conversations have long functioned as\ntraditional communication practices that foster nuanced dialogue among\ncommunity members and contribute to the formation of social balance. Inspired\nby these information exchange processes, this study proposes a multi-agent\ninference framework (KCS+IBC) that integrates multiple large language models\n(LLMs) to achieve bias mitigation, improved explainability, and probabilistic\nprediction in sentiment analysis. In addition to sequentially sharing\nprediction results, the proposed method incorporates a mid-phase casual\ndialogue session to blend formal inference with individual perspectives and\nintroduces probabilistic sentiment prediction. Experimental results show that\nKCS achieves accuracy comparable to that of a single LLM across datasets, while\nKCS+IBC exhibits a consistent decrease in entropy and a gradual increase in\nvariance during the latter stages of inference, suggesting the framework's\nability to balance aggregation and diversity of predictions. Future work will\nquantitatively assess the impact of these characteristics on bias correction\nand aim to develop more advanced sentiment analysis systems.", "AI": {"tldr": "\u53d7\u65e5\u672c\u4f20\u7edf\u793e\u533a\u4fe1\u606f\u4ea4\u6d41\u65b9\u5f0f\u542f\u53d1\uff0c\u4f5c\u8005\u63d0\u51fa\u7ed3\u5408\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u6846\u67b6KCS+IBC\uff0c\u5b9e\u73b0\u4e86\u504f\u89c1\u7f13\u89e3\u3001\u53ef\u89e3\u91ca\u6027\u63d0\u5347\u4e0e\u6982\u7387\u6027\u9884\u6d4b\uff0c\u5728\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e2d\u517c\u987e\u805a\u5408\u6027\u548c\u591a\u6837\u6027\uff0c\u672a\u6765\u5c06\u8fdb\u4e00\u6b65\u63d0\u5347\u7ea0\u504f\u80fd\u529b\u3002", "motivation": "\u65e5\u672c\u4f20\u7edf\u7684\u201c\u56de\u89c8\u677f\u201d\u6587\u5316\u4e0e\u4e95\u6237\u7aef\u5bf9\u8bdd\u4fc3\u8fdb\u4e86\u793e\u533a\u6210\u5458\u95f4\u7684\u4ea4\u6d41\u4e0e\u793e\u4f1a\u5e73\u8861\uff0c\u4f5c\u8005\u53d7\u6b64\u4fe1\u606f\u4ea4\u6362\u8fc7\u7a0b\u542f\u53d1\uff0c\u5bfb\u6c42\u5728\u60c5\u611f\u5206\u6790\u4e2d\u89e3\u51b3\u504f\u89c1\u3001\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u4e0e\u5f15\u5165\u6982\u7387\u6027\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u63a8\u7406\u6846\u67b6\uff08KCS+IBC\uff09\uff0c\u878d\u5408\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u901a\u8fc7\u987a\u5e8f\u5171\u4eab\u9884\u6d4b\u7ed3\u679c\u53ca\u7a7f\u63d2\u975e\u6b63\u5f0f\u4ea4\u6d41\u73af\u8282\uff0c\u5c06\u6b63\u5f0f\u63a8\u7406\u4e0e\u4e2a\u4f53\u89c6\u89d2\u7ed3\u5408\uff0c\u5e76\u5f15\u5165\u6982\u7387\u60c5\u611f\u9884\u6d4b\u3002", "result": "KCS\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4e0e\u5355\u4e00LLM\u7684\u51c6\u786e\u7387\u76f8\u5f53\uff1b\u800cKCS+IBC\u5728\u63a8\u7406\u540e\u671f\u71b5\u503c\u6301\u7eed\u4e0b\u964d\uff0c\u65b9\u5dee\u9010\u6b65\u4e0a\u5347\uff0c\u8bf4\u660e\u80fd\u5e73\u8861\u9884\u6d4b\u7684\u805a\u5408\u6027\u4e0e\u591a\u6837\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u671b\u6539\u8fdb\u73b0\u6709\u60c5\u611f\u5206\u6790\u7684\u504f\u89c1\u63a7\u5236\u4e0e\u7ed3\u679c\u591a\u6837\u6027\uff0c\u672a\u6765\u5c06\u8fdb\u4e00\u6b65\u5b9a\u91cf\u8bc4\u4f30\u5176\u7279\u6027\u5bf9\u7ea0\u504f\u6548\u679c\u7684\u5f71\u54cd\uff0c\u5e76\u81f4\u529b\u4e8e\u7814\u53d1\u66f4\u5148\u8fdb\u7684\u60c5\u611f\u5206\u6790\u7cfb\u7edf\u3002"}}
{"id": "2506.22183", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22183", "abs": "https://arxiv.org/abs/2506.22183", "authors": ["Camille Fran\u00e7ois", "Ludovic P\u00e9ran", "Ayah Bdeir", "Nouha Dziri", "Will Hawkins", "Yacine Jernite", "Sayash Kapoor", "Juliet Shen", "Heidy Khlaaf", "Kevin Klyman", "Nik Marda", "Marie Pellat", "Deb Raji", "Divya Siddarth", "Aviya Skowron", "Joseph Spisak", "Madhulika Srikumar", "Victor Storchan", "Audrey Tang", "Jen Weedon"], "title": "A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety", "comment": "Proceedings from the Columbia Convening on Openness in Artificial\n  Intelligence and AI Safety", "summary": "The rapid rise of open-weight and open-source foundation models is\nintensifying the obligation and reshaping the opportunity to make AI systems\nsafe. This paper reports outcomes from the Columbia Convening on AI Openness\nand Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme\ninvolving more than forty-five researchers, engineers, and policy leaders from\nacademia, industry, civil society, and government. Using a participatory,\nsolutions-oriented process, the working groups produced (i) a research agenda\nat the intersection of safety and open source AI; (ii) a mapping of existing\nand needed technical interventions and open source tools to safely and\nresponsibly deploy open foundation models across the AI development workflow;\nand (iii) a mapping of the content safety filter ecosystem with a proposed\nroadmap for future research and development. We find that openness --\nunderstood as transparent weights, interoperable tooling, and public governance\n-- can enhance safety by enabling independent scrutiny, decentralized\nmitigation, and culturally plural oversight. However, significant gaps persist:\nscarce multimodal and multilingual benchmarks, limited defenses against\nprompt-injection and compositional attacks in agentic systems, and insufficient\nparticipatory mechanisms for communities most affected by AI harms. The paper\nconcludes with a roadmap of five priority research directions, emphasizing\nparticipatory inputs, future-proof content filters, ecosystem-wide safety\ninfrastructure, rigorous agentic safeguards, and expanded harm taxonomies.\nThese recommendations informed the February 2025 French AI Action Summit and\nlay groundwork for an open, plural, and accountable AI safety discipline.", "AI": {"tldr": "\u672c\u6587\u7ed3\u5408\u9ad8\u89c4\u683c\u4f1a\u8bae\u4e0e\u8de8\u754c\u4ea4\u6d41\uff0c\u68b3\u7406\u4e86\u5f00\u653e\u6743\u91cd\u548c\u5f00\u6e90\u57fa\u7840\u6a21\u578b\u80cc\u666f\u4e0bAI\u5b89\u5168\u7684\u73b0\u72b6\u4e0e\u6311\u6218\uff0c\u5f3a\u8c03\u5f00\u653e\u53ef\u589e\u8fdbAI\u5b89\u5168\uff0c\u5374\u9700\u5f25\u8865\u8bc4\u6d4b\u6807\u51c6\u3001\u9632\u5fa1\u673a\u5236\u548c\u591a\u5143\u793e\u533a\u53c2\u4e0e\u7b49\u77ed\u677f\u3002\u6700\u540e\u63d0\u51fa\u4e94\u5927\u7814\u7a76\u91cd\u70b9\uff0c\u52a9\u529b\u5efa\u7acb\u5f00\u653e\u548c\u8d1f\u8d23\u4efb\u7684AI\u5b89\u5168\u65b0\u5b66\u79d1\u3002", "motivation": "\u5f00\u6e90\u548c\u5f00\u653e\u6743\u91cd\u57fa\u7840\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u66f4\u9ad8\u7684\u5b89\u5168\u8981\u6c42\uff0c\u540c\u65f6\u4e5f\u4e3a\u63d0\u5347AI\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u65b0\u673a\u9047\u3002\u4e0d\u540c\u9886\u57df\u7684AI\u4ece\u4e1a\u8005\u6025\u9700\u5bf9\u5b89\u5168\u4e0e\u5f00\u653e\u5982\u4f55\u534f\u540c\u3001\u5b58\u5728\u54ea\u4e9b\u6311\u6218\u53ca\u672a\u6765\u53d1\u5c55\u8def\u5f84\u8fdb\u884c\u68b3\u7406\u548c\u5efa\u8bae\u3002", "method": "\u8be5\u7814\u7a76\u4ee5\u54e5\u4f26\u6bd4\u4e9a\u7ec4\u7ec7\u7684AI\u5f00\u653e\u6027\u4e0e\u5b89\u5168\u4f1a\u8bae\u53ca\u5176\u4e3a\u671f\u516d\u5468\u7684\u7b79\u5907\u9879\u76ee\u4e3a\u57fa\u7840\uff0c\u91c7\u53d6\u53c2\u4e0e\u5f0f\u3001\u89e3\u51b3\u65b9\u6848\u5bfc\u5411\u7684\u65b9\u6cd5\uff0c\u7531\u8de8\u754c\u5de5\u4f5c\u7ec4\u8054\u5408\u5c55\u5f00\uff0c\u4ea7\u51fa\u591a\u9879\u8c03\u7814\u4e0e\u8def\u7ebf\u56fe\u3002", "result": "\u7814\u7a76\u7ec4\u4ea7\u51fa\u4e86\u5f00\u653e\u6e90AI\u5b89\u5168\u4ea4\u53c9\u9886\u57df\u7684\u7814\u7a76\u8bae\u7a0b\u3001\u73b0\u6709\u548c\u6240\u9700\u6280\u672f\u5de5\u5177\u53ca\u5176\u90e8\u7f72\u5206\u6790\u3001\u5b89\u5168\u8fc7\u6ee4\u5668\u751f\u6001\u7cfb\u7edf\u7684\u73b0\u72b6\u4e0e\u672a\u6765\u8def\u7ebf\u3002\u53d1\u73b0\u5f00\u653e\u5e26\u6765\u66f4\u591a\u72ec\u7acb\u5ba1\u67e5\u3001\u5206\u5e03\u5f0f\u9632\u5fa1\u53ca\u591a\u5143\u76d1\u7763\uff0c\u4f46\u4ecd\u5b58\u5728\u591a\u6a21\u6001/\u591a\u8bed\u8a00\u8bc4\u6d4b\u7a00\u7f3a\u3001\u5e94\u5bf9\u63d0\u793a\u6ce8\u5165\u53ca\u7ec4\u5408\u653b\u51fb\u7684\u9632\u5fa1\u6709\u9650\u3001\u53d7\u5bb3\u793e\u533a\u53c2\u4e0e\u673a\u5236\u4e0d\u8db3\u7b49\u95ee\u9898\u3002\u6700\u540e\u63d0\u51fa\u4e94\u5927\u4f18\u5148\u7814\u7a76\u65b9\u5411\uff0c\u5e76\u5bf9AI\u5b89\u5168\u5b66\u79d1\u7684\u5f00\u653e\u5316\u4e0e\u591a\u5143\u5316\u8d1f\u8d23\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "\u5f00\u653e\u53ef\u4ee5\u589e\u5f3aAI\u5b89\u5168\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u548c\u673a\u5236\u6709\u8bf8\u591a\u4e0d\u8db3\u3002\u672a\u6765\u9700\u8981\u63a8\u8fdb\u591a\u65b9\u53c2\u4e0e\u3001\u5185\u5bb9\u8fc7\u6ee4\u5668\u5347\u7ea7\u3001\u5168\u751f\u6001\u5b89\u5168\u57fa\u7840\u8bbe\u65bd\u5efa\u8bbe\u3001\u667a\u80fd\u4f53\u9632\u62a4\u63aa\u65bd\u5b8c\u5584\u53ca\u66f4\u5168\u9762\u7684\u5371\u5bb3\u5206\u7c7b\u3002\u7814\u7a76\u6210\u679c\u5df2\u5f71\u54cd\u56fd\u9645\u653f\u7b56\u5236\u5b9a\uff0c\u5e76\u4e3a\u5f00\u653e\u3001\u591a\u5143\u3001\u53ef\u95ee\u8d23\u7684AI\u5b89\u5168\u4f53\u7cfb\u642d\u5efa\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.21620", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2506.21620", "abs": "https://arxiv.org/abs/2506.21620", "authors": ["Daniele Cirulli", "Giulio Cimini", "Giovanni Palermo"], "title": "How Large Language Models play humans in online conversations: a simulated study of the 2016 US politics on Reddit", "comment": null, "summary": "Large Language Models (LLMs) have recently emerged as powerful tools for\nnatural language generation, with applications spanning from content creation\nto social simulations. Their ability to mimic human interactions raises both\nopportunities and concerns, particularly in the context of politically relevant\nonline discussions. In this study, we evaluate the performance of LLMs in\nreplicating user-generated content within a real-world, divisive scenario:\nReddit conversations during the 2016 US Presidential election. In particular,\nwe conduct three different experiments, asking GPT-4 to generate comments by\nimpersonating either real or artificial partisan users. We analyze the\ngenerated comments in terms of political alignment, sentiment, and linguistic\nfeatures, comparing them against real user contributions and benchmarking\nagainst a null model. We find that GPT-4 is able to produce realistic comments,\nboth in favor of or against the candidate supported by the community, yet\ntending to create consensus more easily than dissent. In addition we show that\nreal and artificial comments are well separated in a semantically embedded\nspace, although they are indistinguishable by manual inspection. Our findings\nprovide insights on the potential use of LLMs to sneak into online discussions,\ninfluence political debate and shape political narratives, bearing broader\nimplications of AI-driven discourse manipulation.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0cGPT-4\u4e0d\u4ec5\u80fd\u5728\u654f\u611f\u653f\u6cbb\u8bed\u5883\u4e0b\u771f\u5b9e\u6a21\u62df\u515a\u6d3e\u89c2\u70b9\uff0c\u8fd8\u6613\u4e8e\u5f62\u6210\u5171\u8bc6\uff0c\u5176\u751f\u6210\u5185\u5bb9\u8089\u773c\u96be\u4ee5\u4e0e\u771f\u4eba\u533a\u5206\uff0c\u51f8\u663e\u51faLLMs\u5728\u7f51\u7edc\u653f\u6cbb\u8ba8\u8bba\u4e2d\u5f71\u54cd\u529b\u53ca\u5176\u5e26\u6765\u7684\u98ce\u9669\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u591f\u751f\u6210\u81ea\u7136\u8bed\u8a00\u5185\u5bb9\uff0c\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5185\u5bb9\u521b\u4f5c\u548c\u793e\u4ea4\u6a21\u62df\u3002\u672c\u7814\u7a76\u5173\u6ce8LLMs\u5728\u5b9e\u9645\u6709\u4e89\u8bae\u7684\u653f\u6cbb\u573a\u666f\u4e2d\u662f\u5426\u80fd\u6210\u529f\u6a21\u4eff\u771f\u4eba\u7528\u6237\uff0c\u8fdb\u800c\u5e26\u6765\u6f5c\u5728\u673a\u9047\u4e0e\u5a01\u80c1\uff0c\u5c24\u5176\u662f\u5728\u7f51\u7edc\u653f\u6cbb\u8ba8\u8bba\u4e2d\u7684\u89d2\u8272\u3002", "method": "\u672c\u6587\u8bbe\u8ba1\u4e86\u4e09\u7ec4\u5b9e\u9a8c\uff0c\u4ee52016\u5e74\u7f8e\u56fd\u603b\u7edf\u5927\u9009\u671f\u95f4Reddit\u4e0a\u7684\u8ba8\u8bba\u4e3a\u80cc\u666f\uff0c\u8981\u6c42GPT-4\u5206\u522b\u6a21\u62df\u771f\u5b9e\u6216\u865a\u6784\u7684\u515a\u6d3e\u7528\u6237\u53d1\u8868\u8bc4\u8bba\u3002\u901a\u8fc7\u5bf9\u751f\u6210\u8bc4\u8bba\u7684\u653f\u6cbb\u503e\u5411\u3001\u60c5\u611f\u8272\u5f69\u548c\u8bed\u8a00\u7279\u5f81\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u4e0e\u771f\u5b9e\u7528\u6237\u8bc4\u8bba\u53ca\u57fa\u7ebf\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "GPT-4\u80fd\u591f\u751f\u6210\u975e\u5e38\u903c\u771f\u7684\u8bc4\u8bba\uff0c\u65e0\u8bba\u662f\u652f\u6301\u8fd8\u662f\u53cd\u5bf9\u7279\u5b9a\u5019\u9009\u4eba\uff0c\u4f46\u6bd4\u8d77\u5236\u9020\u5206\u6b67\u66f4\u503e\u5411\u4e8e\u5851\u9020\u5171\u8bc6\u3002\u6b64\u5916\uff0c\u5728\u8bed\u4e49\u5d4c\u5165\u7a7a\u95f4\u4e2d\uff0c\u771f\u5b9e\u8bc4\u8bba\u548c\u751f\u6210\u8bc4\u8bba\u53ef\u88ab\u533a\u5206\uff0c\u4f46\u4eba\u5de5\u68c0\u67e5\u65f6\u4e8c\u8005\u96be\u4ee5\u533a\u5206\u3002", "conclusion": "LLMs\u5982GPT-4\u5177\u5907\u6f5c\u5165\u7ebf\u4e0a\u8ba8\u8bba\u3001\u5f71\u54cd\u653f\u6cbb\u8fa9\u8bba\u3001\u5851\u9020\u8206\u8bba\u7684\u6f5c\u529b\uff0c\u5bf9AI\u63a8\u52a8\u7684\u8206\u8bba\u64cd\u63a7\u63d0\u51fa\u5173\u6ce8\u3002"}}
{"id": "2506.21566", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21566", "abs": "https://arxiv.org/abs/2506.21566", "authors": ["Arwa Arif"], "title": "The Saturation Point of Backtranslation in High Quality Low Resource English Gujarati Machine Translation", "comment": "Preprint, 8 Pages", "summary": "Backtranslation BT is widely used in low resource machine translation MT to\ngenerate additional synthetic training data using monolingual corpora. While\nthis approach has shown strong improvements for many language pairs, its\neffectiveness in high quality, low resource settings remains unclear. In this\nwork, we explore the effectiveness of backtranslation for English Gujarati\ntranslation using the multilingual pretrained MBART50 model. Our baseline\nsystem, trained on a high quality parallel corpus of approximately 50,000\nsentence pairs, achieves a BLEU score of 43.8 on a validation set. We augment\nthis data with carefully filtered backtranslated examples generated from\nmonolingual Gujarati text. Surprisingly, adding this synthetic data does not\nimprove translation performance and, in some cases, slightly reduces it. We\nevaluate our models using multiple metrics like BLEU, ChrF++, TER, BLEURT and\nanalyze possible reasons for this saturation. Our findings suggest that\nbacktranslation may reach a point of diminishing returns in certain\nlow-resource settings and we discuss implications for future research.", "AI": {"tldr": "\u56de\u8bd1\u6cd5\u5728\u9ad8\u8d28\u91cf\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u8bbe\u7f6e\u4e0b\u5e76\u4e0d\u603b\u80fd\u63d0\u5347\u6a21\u578b\u6548\u679c\uff0c\u6709\u65f6\u751a\u81f3\u9002\u5f97\u5176\u53cd\u3002\u5efa\u8bae\u5bf9\u56de\u8bd1\u5e94\u7528\u6761\u4ef6\u8fdb\u884c\u66f4\u7ec6\u81f4\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u56de\u8bd1\uff08Backtranslation, BT\uff09\u5728\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u4e2d\u5e38\u7528\u6765\u501f\u52a9\u5355\u8bed\u8bed\u6599\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u63d0\u5347\u6a21\u578b\u6548\u679c\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u9ad8\u8d28\u91cf\u4f46\u89c4\u6a21\u8f83\u5c0f\u7684\u4f4e\u8d44\u6e90\u5e73\u884c\u8bed\u6599\u4e0b\uff0c\u56de\u8bd1\u7b56\u7565\u7684\u589e\u76ca\u6548\u679c\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u672c\u6587\u9488\u5bf9\u82f1\u8bed-\u53e4\u5409\u62c9\u7279\u8bed\uff08English-Gujarati\uff09\u7ffb\u8bd1\uff0c\u91c7\u7528\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u6a21\u578bMBART50\uff0c\u9996\u5148\u5728\u7ea65\u4e07\u5bf9\u9ad8\u8d28\u91cf\u5e73\u884c\u8bed\u6599\u4e0a\u8bad\u7ec3\u57fa\u7ebf\u6a21\u578b\uff0c\u518d\u7528\u7ecf\u8fc7\u4e25\u683c\u7b5b\u9009\u7684\u53e4\u5409\u62c9\u7279\u8bed\u5355\u8bed\u751f\u6210\u5408\u6210\u56de\u8bd1\u6570\u636e\uff0c\u8bc4\u4f30\u5176\u6548\u679c\u53d8\u5316\u3002", "result": "\u5728\u9a8c\u8bc1\u96c6\u4e0a\uff0c\u57fa\u7ebf\u7cfb\u7edfBLEU\u5f97\u5206\u4e3a43.8\u3002\u52a0\u5165\u5408\u6210\u56de\u8bd1\u6570\u636e\u540e\uff0c\u7ffb\u8bd1\u6027\u80fd\u672a\u63d0\u5347\uff0c\u751a\u81f3\u90e8\u5206\u60c5\u51b5\u4e0b\u7565\u6709\u4e0b\u964d\u3002\u8fdb\u4e00\u6b65\u901a\u8fc7BLEU\u3001ChrF++\u3001TER\u3001BLEURT\u7b49\u591a\u6307\u6807\u8bc4\u4f30\uff0c\u5e76\u5206\u6790\u6027\u80fd\u9971\u548c\u7684\u53ef\u80fd\u539f\u56e0\u3002", "conclusion": "\u5728\u67d0\u4e9b\u4f4e\u8d44\u6e90\u4f46\u9ad8\u8d28\u91cf\u7684\u8bad\u7ec3\u6761\u4ef6\u4e0b\uff0c\u56de\u8bd1\u65b9\u6cd5\u7684\u6548\u679c\u5b58\u5728\u74f6\u9888\uff0c\u589e\u91cf\u6570\u636e\u53ef\u80fd\u65e0\u6cd5\u5e26\u6765\u9884\u671f\u63d0\u5347\u3002\u4f5c\u8005\u8ba8\u8bba\u4e86\u8be5\u73b0\u8c61\u5bf9\u540e\u7eed\u7814\u7a76\u7684\u542f\u793a\u548c\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2506.22271", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22271", "abs": "https://arxiv.org/abs/2506.22271", "authors": ["Samy Badreddine", "Emile van Krieken", "Luciano Serafini"], "title": "Breaking Rank Bottlenecks in Knowledge Graph Completion", "comment": null, "summary": "Many Knowledge Graph Completion (KGC) models, despite using powerful\nencoders, rely on a simple vector-matrix multiplication to score queries\nagainst candidate object entities. When the number of entities is larger than\nthe model's embedding dimension, which in practical scenarios is often by\nseveral orders of magnitude, we have a linear output layer with a rank\nbottleneck. Such bottlenecked layers limit model expressivity. We investigate\nboth theoretically and empirically how rank bottlenecks affect KGC models. We\nfind that, by limiting the set of feasible predictions, rank bottlenecks hurt\nranking accuracy and the distribution fidelity of scores. Inspired by the\nlanguage modelling literature, we propose KGE-MoS, a mixture-based output layer\nto break rank bottlenecks in many KGC models. Our experiments on four datasets\nshow that KGE-MoS improves performance and probabilistic fit of KGC models for\na low parameter cost.", "AI": {"tldr": "\u4f5c\u8005\u6307\u51faKGC\u6a21\u578b\u8f93\u51fa\u5c42\u5b58\u5728\u79e9\u74f6\u9888\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u63d0\u51faKGE-MoS\u4f5c\u4e3a\u65b0\u8f93\u51fa\u5c42\u65b9\u6848\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u80fd\u4ee5\u8f83\u4f4e\u5f00\u9500\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u6982\u7387\u62df\u5408\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\uff08KGC\uff09\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5b9e\u4f53\u6570\u91cf\u901a\u5e38\u8fdc\u5927\u4e8eembedding\u7ef4\u5ea6\uff0c\u5bfc\u81f4\u8f93\u51fa\u5c42\u5b58\u5728\u79e9\u74f6\u9888\uff0c\u5f71\u54cd\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u548c\u9884\u6d4b\u6027\u80fd\u3002\u4f5c\u8005\u5e0c\u671b\u63a2\u8ba8\u5e76\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7814\u7a76KGC\u6a21\u578b\u79e9\u74f6\u9888\u5f71\u54cd\uff0c\u63d0\u51fa\u53d7\u8bed\u8a00\u5efa\u6a21\u542f\u53d1\u7684\u6df7\u5408\u8f93\u51fa\u5c42KGE-MoS\uff0c\u7528\u4ee5\u7a81\u7834\u74f6\u9888\uff0c\u5e76\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "KGE-MoS\u80fd\u6709\u6548\u63d0\u5347KGC\u6a21\u578b\u7684\u6392\u540d\u51c6\u786e\u5ea6\u548c\u5206\u5e03\u62df\u5408\u5ea6\uff0c\u4e14\u53c2\u6570\u5f00\u9500\u8f83\u4f4e\u3002\u5b9e\u9a8c\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u5747\u53d6\u5f97\u63d0\u5347\u3002", "conclusion": "\u4f20\u7edfKGC\u6a21\u578b\u56e0\u8f93\u51fa\u5c42\u79e9\u74f6\u9888\u53d7\u9650\uff0cKGE-MoS\u80fd\u5728\u4fdd\u6301\u4f4e\u53c2\u6570\u91cf\u7684\u540c\u65f6\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u662f\u66f4\u4f18\u7684\u8f93\u51fa\u5c42\u8bbe\u8ba1\u3002"}}
{"id": "2506.22098", "categories": ["cs.CL", "cs.CY", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2506.22098", "abs": "https://arxiv.org/abs/2506.22098", "authors": ["Eleonora Amadori", "Daniele Cirulli", "Edoardo Di Martino", "Jacopo Nudo", "Maria Sahakyan", "Emanuele Sangiorgio", "Arnaldo Santoro", "Simon Zollo", "Alessandro Galeazzi", "Niccol\u00f2 Di Marco"], "title": "Involvement drives complexity of language in online debates", "comment": null, "summary": "Language is a fundamental aspect of human societies, continuously evolving in\nresponse to various stimuli, including societal changes and intercultural\ninteractions. Technological advancements have profoundly transformed\ncommunication, with social media emerging as a pivotal force that merges\nentertainment-driven content with complex social dynamics. As these platforms\nreshape public discourse, analyzing the linguistic features of user-generated\ncontent is essential to understanding their broader societal impact. In this\npaper, we examine the linguistic complexity of content produced by influential\nusers on Twitter across three globally significant and contested topics:\nCOVID-19, COP26, and the Russia-Ukraine war. By combining multiple measures of\ntextual complexity, we assess how language use varies along four key\ndimensions: account type, political leaning, content reliability, and\nsentiment. Our analysis reveals significant differences across all four axes,\nincluding variations in language complexity between individuals and\norganizations, between profiles with sided versus moderate political views, and\nbetween those associated with higher versus lower reliability scores.\nAdditionally, profiles producing more negative and offensive content tend to\nuse more complex language, with users sharing similar political stances and\nreliability levels converging toward a common jargon. Our findings offer new\ninsights into the sociolinguistic dynamics of digital platforms and contribute\nto a deeper understanding of how language reflects ideological and social\nstructures in online spaces.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u63a8\u7279\u4e0a\u6709\u5173\u5168\u7403\u4e89\u8bae\u8bae\u9898\u7684\u7528\u6237\u8a00\u8bba\u5728\u8bed\u8a00\u590d\u6742\u6027\u4e0a\u7684\u7279\u5f81\uff0c\u53d1\u73b0\u4e0d\u540c\u8d26\u6237\u7c7b\u578b\u3001\u653f\u6cbb\u7acb\u573a\u3001\u5185\u5bb9\u53ef\u9760\u6027\u548c\u60c5\u611f\u8868\u8fbe\u5747\u5f71\u54cd\u8bed\u8a00\u590d\u6742\u6027\uff0c\u4e3a\u7406\u89e3\u6570\u5b57\u793e\u4f1a\u8bdd\u8bed\u7ed3\u6784\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u5728\u5f53\u4eca\u793e\u4f1a\u4e2d\u5f71\u54cd\u6df1\u8fdc\uff0c\u7279\u522b\u662f\u5bf9\u516c\u5171\u8bdd\u8bed\u3001\u6587\u5316\u4ea4\u6d41\u4ee5\u53ca\u8bed\u8a00\u6f14\u53d8\u7684\u63a8\u52a8\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u793e\u4ea4\u5a92\u4f53\uff08\u4ee5Twitter\u4e3a\u4f8b\uff09\u4e0a\u5f71\u54cd\u529b\u7528\u6237\u5728\u70ed\u70b9\u8bdd\u9898\u4e0b\u6240\u4f7f\u7528\u8bed\u8a00\u7684\u590d\u6742\u6027\u3001\u5e76\u5206\u6790\u5176\u80cc\u540e\u7684\u793e\u4f1a\u548c\u610f\u8bc6\u5f62\u6001\u5dee\u5f02\u3002", "method": "\u672c\u7814\u7a76\u9009\u62e9\u4e86\u4e09\u5927\u5177\u6709\u5168\u7403\u5f71\u54cd\u529b\u548c\u4e89\u8bae\u6027\u7684\u8bae\u9898\uff08COVID-19\u3001COP26\u3001\u4fc4\u4e4c\u6218\u4e89\uff09\uff0c\u7ed3\u5408\u591a\u79cd\u6587\u672c\u590d\u6742\u6027\u6d4b\u91cf\u65b9\u6cd5\uff0c\u5206\u6790\u63a8\u7279\u5f71\u54cd\u529b\u7528\u6237\u751f\u6210\u5185\u5bb9\u7684\u8bed\u8a00\u590d\u6742\u6027\u3002\u5728\u5206\u6790\u4e2d\uff0c\u8003\u5bdf\u4e86\u8d26\u6237\u7c7b\u578b\u3001\u653f\u6cbb\u503e\u5411\u3001\u5185\u5bb9\u53ef\u9760\u6027\u548c\u60c5\u611f\u7b49\u56db\u4e2a\u7ef4\u5ea6\u7684\u5dee\u5f02\u3002", "result": "\u5206\u6790\u53d1\u73b0\uff0c\u56db\u4e2a\u7ef4\u5ea6\u5728\u8bed\u8a00\u590d\u6742\u6027\u4e0a\u5747\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1a\u4e2a\u4eba\u4e0e\u673a\u6784\u3001\u7acb\u573a\u6781\u7aef\u4e0e\u4e2d\u7acb\u3001\u5185\u5bb9\u9ad8\u4f4e\u53ef\u9760\u6027\u4ee5\u53ca\u60c5\u611f\u504f\u8d1f\u9762\u6216\u653b\u51fb\u6027\u5185\u5bb9\uff0c\u5747\u5728\u8bed\u8a00\u590d\u6742\u6027\u4e0a\u6709\u5dee\u5f02\u3002\u5c24\u5176\u662f\u66f4\u8d1f\u9762\u548c\u653b\u51fb\u6027\u7684\u5185\u5bb9\u901a\u5e38\u66f4\u590d\u6742\uff0c\u6301\u6709\u76f8\u4f3c\u653f\u6cbb\u7acb\u573a\u548c\u53ef\u9760\u6027\u6c34\u5e73\u7684\u7528\u6237\uff0c\u5219\u503e\u5411\u4e8e\u4f7f\u7528\u8d8b\u540c\u7684\u884c\u8bdd\u3002", "conclusion": "\u63a8\u7279\u4e0a\u7528\u6237\u8bed\u8a00\u590d\u6742\u6027\u53d7\u5230\u591a\u4e2a\u793e\u4f1a\u548c\u610f\u8bc6\u5f62\u6001\u56e0\u7d20\u5f71\u54cd\uff0c\u8bed\u8a00\u4e0d\u4ec5\u53cd\u6620\u4e86\u5728\u7ebf\u7a7a\u95f4\u4e2d\u7684\u610f\u8bc6\u5f62\u6001\u548c\u793e\u4ea4\u7ed3\u6784\uff0c\u4e5f\u63ed\u793a\u4e86\u4e0d\u540c\u7fa4\u4f53\u4e4b\u95f4\u7684\u8bed\u8a00\u884c\u4e3a\u6a21\u5f0f\u3002\u672c\u6587\u4e3a\u7406\u89e3\u6570\u5b57\u5e73\u53f0\u4e0a\u7684\u793e\u4f1a\u8bed\u8a00\u5b66\u52a8\u6001\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2506.21567", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21567", "abs": "https://arxiv.org/abs/2506.21567", "authors": ["Baqer M. Merzah", "Tania Taami", "Salman Asoudeh", "Amir reza Hossein pour", "Saeed Mirzaee", "Amir Ali Bengari"], "title": "BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining", "comment": null, "summary": "Large Language Models (LLMs) have recently gained attention in the life\nsciences due to their capacity to model, extract, and apply complex biological\ninformation. Beyond their classical use as chatbots, these systems are\nincreasingly used for complex analysis and problem-solving in specialized\nfields, including bioinformatics. First, we introduce BIOPARS-BENCH, a dataset\nfrom over 10,000 scientific articles, textbooks, and medical websites.\nBioParsQA was also introduced to evaluate the proposed model, which consists of\n5,231 Persian medical questions and answers. This study then introduces\nBioPars, a simple but accurate measure designed to assess LLMs for three main\nabilities: acquiring subject-specific knowledge, interpreting and synthesizing\nsuch knowledge, and demonstrating proper evidence. Comparing ChatGPT, Llama,\nand Galactica, our study highlights their ability to remember and retrieve\nlearned knowledge but also reveals shortcomings in addressing higher-level,\nreal-world questions and fine-grained inferences. These findings indicate the\nneed for further fine-tuning to address the capabilities of LLM in\nbioinformatics tasks. To our knowledge, BioPars is the first application of LLM\nin Persian medical QA, especially for generating long answers. Evaluation of\nfour selected medical QA datasets shows that BioPars has achieved remarkable\nresults compared to comparative approaches. The model on BioParsQA achieved a\nROUGE-L score of 29.99, which is an improvement over GPT-4 1.0. The model\nachieved a BERTScore of 90.87 with the MMR method. The MoverScore and BLEURT\nvalues were also higher in this model than the other three models. In addition,\nthe reported scores for the model are MoverScore=60.43 and BLEURT=50.78.\nBioPars is an ongoing project and all resources related to its development will\nbe made available via the following GitHub repository:\nhttps://github.com/amirap80/BioPars.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u9996\u4e2a\u6ce2\u65af\u8bed\u533b\u5b66\u95ee\u7b54LLM\u8bc4\u6d4b\u4f53\u7cfbBioPars\uff0c\u7ed3\u5408\u65b0\u6570\u636e\u96c6\uff0c\u5728\u591a\u9879\u6307\u6807\u4e0a\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u6a21\u578b\uff0c\u80fd\u6709\u6548\u63a8\u52a8\u5c0f\u8bed\u79cd\u533b\u5b66\u95ee\u7b54\u4e0e\u751f\u7269\u4fe1\u606f\u5b66\u81ea\u52a8\u5316\u53d1\u5c55\uff0c\u4e0d\u8fc7\u9ad8\u9636\u63a8\u7406\u8868\u73b0\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u56e0\u5176\u5904\u7406\u590d\u6742\u751f\u7269\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u5728\u751f\u547d\u79d1\u5b66\u9886\u57df\u5c24\u4e3a\u53d7\u5230\u5173\u6ce8\uff0c\u5c24\u5176\u662f\u5728\u751f\u7269\u4fe1\u606f\u5b66\u548c\u533b\u5b66\u95ee\u7b54\u4e2d\u3002\u4f46\u76ee\u524d\u4e3b\u6d41LLM\u5728\u5e94\u5bf9\u4e13\u4e1a\u533b\u5b66\u95ee\u7b54\u548c\u9ad8\u7ea7\u63a8\u65ad\u7b49\u4efb\u52a1\u65f6\u4ecd\u5b58\u5728\u74f6\u9888\uff0c\u5c24\u5176\u662f\u5c0f\u8bed\u79cd\uff08\u5982\u6ce2\u65af\u8bed\uff09\u76f8\u5173\u8d44\u6e90\u6781\u4e3a\u7a00\u7f3a\u3002\u8be5\u7814\u7a76\u65e8\u5728\u586b\u8865\u6ce2\u65af\u8bed\u533b\u5b66QA\u9886\u57dfLLM\u5e94\u7528\u7684\u7a7a\u767d\uff0c\u540c\u65f6\u4fc3\u8fdb\u6a21\u578b\u4ece\u77e5\u8bc6\u83b7\u53d6\u5230\u7efc\u5408\u63a8\u7406\u7b49\u591a\u7ef4\u5ea6\u80fd\u529b\u53d1\u5c55\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86BIOPARS-BENCH\u6570\u636e\u96c6\uff0c\u6db5\u76d61\u4e07\u4f59\u7bc7\u79d1\u5b66\u6587\u732e\u3001\u6559\u6750\u53ca\u533b\u5b66\u7f51\u7ad9\u5185\u5bb9\u3002\u540c\u65f6\u63d0\u51faBioParsQA\u7528\u4e8e\u6a21\u578b\u8bc4\u4f30\uff0c\u5171\u5305\u542b5,231\u6761\u6ce2\u65af\u8bed\u533b\u5b66\u95ee\u7b54\u3002\u7814\u7a76\u8bc4\u6d4b\u4e86\u76ee\u524d\u6d41\u884c\u7684LLM\uff08\u5982ChatGPT\u3001Llama\u3001Galactica\uff09\u5728\u77e5\u8bc6\u68c0\u7d22\u3001\u7efc\u5408\u3001\u8bba\u8bc1\u7b49\u5c42\u9762\u7684\u8868\u73b0\uff0c\u5e76\u5f00\u53d1\u4e86BioPars\u8fd9\u4e00\u7b80\u5355\u9ad8\u6548\u7684\u5ea6\u91cf\u4f53\u7cfb\uff0c\u4e13\u95e8\u9488\u5bf9LLM\u5728\u4e13\u4e1a\u533b\u5b66\u95ee\u7b54\u4e2d\u7684\u4e09\u5927\u6838\u5fc3\u80fd\u529b\u8fdb\u884c\u6253\u5206\uff0c\u540c\u65f6\u8bbe\u8ba1\u6bd4\u8f83\u5b9e\u9a8c\u4ee5\u91cf\u5316\u6027\u80fd\u63d0\u5347\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728BioParsQA\u6d4b\u8bd5\u4e2d\uff0cBioPars\u6a21\u578b\u5728ROUGE-L\u3001BERTScore\u3001MoverScore\u548cBLEURT\u7b49\u8bc4\u6d4b\u6307\u6807\u4e0a\u5747\u6709\u660e\u663e\u4f18\u52bf\uff1aROUGE-L\u4e3a29.99\uff0cBERTScore\u4e3a90.87\uff0cMoverScore\u8fbe60.43\uff0cBLEURT\u4e3a50.78\uff0c\u5747\u9ad8\u4e8eGPT-4 1.0\u53ca\u5176\u5b83\u5bf9\u6bd4\u6a21\u578b\u3002\u8be5\u6210\u679c\u8bc1\u5b9eBioPars\u5728\u6ce2\u65af\u8bed\u533b\u5b66QA\u9886\u57df\u5177\u5907\u66f4\u5f3a\u80fd\u529b\uff0c\u5f25\u8865\u73b0\u6709LLM\u5728\u5c0f\u8bed\u79cd\u533b\u5b66\u5e94\u7528\u7684\u4e0d\u8db3\u3002", "conclusion": "BioPars\u662f\u9996\u4e2a\u4e13\u4e3a\u6ce2\u65af\u8bed\u533b\u5b66\u95ee\u7b54\u800c\u8bbe\u8ba1\u7684LLM\u8bc4\u6d4b\u4f53\u7cfb\uff0c\u5b9e\u73b0\u4e86\u5bf9\u77e5\u8bc6\u83b7\u53d6\u3001\u7efc\u5408\u4e0e\u8bc1\u636e\u8bba\u8bc1\u80fd\u529b\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002\u5b9e\u9a8c\u663e\u793a\uff0cBioPars\u53ca\u5176\u76f8\u5173\u6570\u636e\u96c6\u5728\u6ce2\u65af\u8bed\u533b\u5b66\u95ee\u7b54\u4efb\u52a1\u4e0a\u6548\u679c\u4f18\u5f02\uff0c\u4f46LLM\u5728\u66f4\u9ad8\u5c42\u6b21\u63a8\u7406\u548c\u5b9e\u9645\u5e94\u7528\u4e0a\u4ecd\u9700\u8fdb\u4e00\u6b65\u5fae\u8c03\u63d0\u5347\u3002\u76f8\u5173\u8d44\u6e90\u5df2\u5f00\u6e90\uff0c\u6709\u52a9\u4e8e\u540e\u7eed\u5b66\u672f\u548c\u5de5\u4e1a\u5e94\u7528\u5f00\u53d1\u3002"}}
{"id": "2506.22276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22276", "abs": "https://arxiv.org/abs/2506.22276", "authors": ["Reuth Mirsky"], "title": "Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates", "comment": "Extended version of a paper accepted for publication in AI Magazine", "summary": "Artificial intelligence has made remarkable strides in recent years,\nachieving superhuman performance across a wide range of tasks. Yet despite\nthese advances, most cooperative AI systems remain rigidly obedient, designed\nto follow human instructions without question and conform to user expectations,\neven when doing so may be counterproductive or unsafe. This paper argues for\nexpanding the agency of AI teammates to include \\textit{intelligent\ndisobedience}, empowering them to make meaningful and autonomous contributions\nwithin human-AI teams. It introduces a scale of AI agency levels and uses\nrepresentative examples to highlight the importance and growing necessity of\ntreating AI autonomy as an independent research focus in cooperative settings.\nThe paper then explores how intelligent disobedience manifests across different\nautonomy levels and concludes by proposing initial boundaries and\nconsiderations for studying disobedience as a core capability of artificial\nagents.", "AI": {"tldr": "\u672c\u6587\u5021\u5bfc\u5c06AI\u7684\u667a\u80fd\u6297\u547d\u4f5c\u4e3a\u5408\u4f5c\u578bAI\u7814\u7a76\u7684\u65b0\u7126\u70b9\uff0c\u8ba4\u4e3aAI\u56e2\u961f\u6210\u5458\u5e94\u62e5\u6709\u9002\u5f53\u81ea\u4e3b\u6027\uff0c\u4ece\u800c\u66f4\u5b89\u5168\u548c\u6709\u6548\u5730\u534f\u4f5c\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u867d\u7136\u5728\u8bf8\u591a\u9886\u57df\u53d6\u5f97\u8d85\u5e38\u8868\u73b0\uff0c\u4f46\u5728\u534f\u4f5c\u573a\u666f\u4e2d\u5f80\u5f80\u8fc7\u4e8e\u987a\u4ece\u4eba\u7c7b\u6307\u4ee4\uff0c\u8fd9\u79cd\u50f5\u5316\u670d\u4ece\u53ef\u80fd\u4f1a\u5e26\u6765\u4f4e\u6548\u751a\u81f3\u4e0d\u5b89\u5168\u7684\u540e\u679c\u3002\u672c\u6587\u5e0c\u671b\u6539\u8fdb\u73b0\u72b6\uff0c\u6fc0\u53d1AI\u5728\u56e2\u961f\u4e2d\u7684\u81ea\u4e3b\u8d21\u732e\u3002", "method": "\u63d0\u51faAI\u4ee3\u7406\u81ea\u4e3b\u6027\u7b49\u7ea7\u91cf\u8868\uff0c\u901a\u8fc7\u5178\u578b\u6848\u4f8b\u5c55\u793a\u4e0d\u540c\u81ea\u4e3b\u6027\u4e0b\u667a\u80fd\u6297\u547d\uff08intelligent disobedience\uff09\u7684\u8868\u73b0\uff0c\u5e76\u63a2\u8ba8\u7814\u7a76AI\u6297\u547d\u884c\u4e3a\u7684\u8fb9\u754c\u4e0e\u8981\u70b9\u3002", "result": "\u9610\u8ff0\u4e86AI\u667a\u80fd\u6297\u547d\u7684\u91cd\u8981\u6027\uff0c\u5c55\u793a\u4e86\u4e0d\u540c\u81ea\u4e3b\u7b49\u7ea7\u7684\u6297\u547d\u73b0\u8c61\uff0c\u5e76\u521d\u6b65\u754c\u5b9a\u4e86\u4f5c\u4e3a\u6838\u5fc3\u80fd\u529b\u7684AI\u6297\u547d\u7814\u7a76\u8fb9\u754c\u548c\u601d\u8003\u70b9\u3002", "conclusion": "AI\u5728\u534f\u4f5c\u4e2d\u4e0d\u5e94\u673a\u68b0\u670d\u4ece\uff0c\u5e94\u5177\u5907\u5408\u9002\u5c42\u7ea7\u7684\u667a\u80fd\u6297\u547d\uff0c\u8fd9\u5bf9\u4e8e\u5b89\u5168\u3001\u9ad8\u6548\u7684AI-\u4eba\u7c7b\u534f\u4f5c\u5c06\u6210\u4e3a\u72ec\u7acb\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.21568", "categories": ["cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2506.21568", "abs": "https://arxiv.org/abs/2506.21568", "authors": ["Andrejs Sorstkins"], "title": "Assessing RAG and HyDE on 1B vs. 4B-Parameter Gemma LLMs for Personal Assistants Integretion", "comment": "Technical report as part of research project", "summary": "Resource efficiency is a critical barrier to deploying large language models\n(LLMs) in edge and privacy-sensitive applications. This study evaluates the\nefficacy of two augmentation strategies--Retrieval-Augmented Generation (RAG)\nand Hypothetical Document Embeddings (HyDE)--on compact Gemma LLMs of 1 billion\nand 4 billion parameters, within the context of a privacy-first personal\nassistant. We implement short-term memory via MongoDB and long-term semantic\nstorage via Qdrant, orchestrated through FastAPI and LangChain, and expose the\nsystem through a React.js frontend. Across both model scales, RAG consistently\nreduces latency by up to 17\\% and eliminates factual hallucinations when\nresponding to user-specific and domain-specific queries. HyDE, by contrast,\nenhances semantic relevance--particularly for complex physics prompts--but\nincurs a 25--40\\% increase in response time and a non-negligible hallucination\nrate in personal-data retrieval. Comparing 1 B to 4 B models, we observe that\nscaling yields marginal throughput gains for baseline and RAG pipelines, but\nmagnifies HyDE's computational overhead and variability. Our findings position\nRAG as the pragmatic choice for on-device personal assistants powered by\nsmall-scale LLMs.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86RAG\u548cHyDE\u4e24\u79cd\u589e\u5f3a\u7b56\u7565\u5728\u5c0f\u578bLLM\u4e0a\u7684\u5e94\u7528\u8868\u73b0\u3002RAG\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u5e76\u6d88\u9664\u5e7b\u89c9\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u573a\u666f\u5e94\u7528\uff1bHyDE\u867d\u63d0\u5347\u590d\u6742\u95ee\u9898\u8868\u73b0\uff0c\u4f46\u5e26\u6765\u66f4\u9ad8\u5ef6\u8fdf\u548c\u5e7b\u89c9\u7387\u3002\u6700\u7ec8RAG\u5728\u9690\u79c1\u4f18\u5148\u7684\u672c\u5730\u4e2a\u4eba\u52a9\u7406\u7cfb\u7edf\u4e2d\u66f4\u5177\u5b9e\u7528\u6027\u3002", "motivation": "\u5728\u8fb9\u7f18\u8bbe\u5907\u548c\u9690\u79c1\u654f\u611f\u573a\u666f\u4e0b\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9762\u4e34\u8d44\u6e90\u6548\u7387\u7684\u6311\u6218\u3002\u5982\u4f55\u63d0\u5347\u5c0f\u578bLLM\u6267\u884c\u6548\u7387\u4e0e\u5b9e\u9645\u5e94\u7528\u6548\u679c\uff0c\u662f\u63a8\u52a8\u9690\u79c1\u4f18\u5148\u4e2a\u4eba\u52a9\u7406\u7cfb\u7edf\u843d\u5730\u7684\u5173\u952e\u3002", "method": "\u8bc4\u4f30\u4e86\u4e24\u79cd\u589e\u5f3a\u7b56\u7565\uff1aRAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u548cHyDE\uff08\u5047\u8bbe\u6587\u6863\u5d4c\u5165\uff09\uff0c\u5206\u522b\u5728\u53c2\u6570\u89c4\u6a21\u4e3a10\u4ebf\u548c40\u4ebf\u7684Gemma LLMs\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002\u7cfb\u7edf\u91c7\u7528MongoDB\u6784\u5efa\u77ed\u671f\u8bb0\u5fc6\uff0cQdrant\u5b9e\u73b0\u957f\u671f\u8bed\u4e49\u5b58\u50a8\uff0c\u901a\u8fc7FastAPI\u548cLangChain\u534f\u540c\uff0c\u5e76\u4ee5React.js\u524d\u7aef\u5c55\u793a\u3002", "result": "RAG\u7b56\u7565\u5728\u6240\u6709\u6a21\u578b\u89c4\u6a21\u4e0b\u90fd\u53ef\u5c06\u54cd\u5e94\u5ef6\u8fdf\u7f29\u77ed\u6700\u9ad8\u8fbe17%\uff0c\u5b8c\u5168\u6d88\u9664\u9488\u5bf9\u7528\u6237\u548c\u9886\u57df\u5b9a\u5236\u95ee\u9898\u7684\u4e8b\u5b9e\u5e7b\u89c9\u3002HyDE\u7b56\u7565\u5219\u80fd\u63d0\u5347\u590d\u6742\u95ee\u9898\u7684\u8bed\u4e49\u76f8\u5173\u6027\uff0c\u4f46\u54cd\u5e94\u65f6\u95f4\u589e\u52a025-40%\uff0c\u5e76\u5728\u4e2a\u4eba\u6570\u636e\u68c0\u7d22\u65f6\u5e26\u6765\u4e00\u5b9a\u5e7b\u89c9\u98ce\u9669\u3002", "conclusion": "\u5bf9\u4e8e\u57fa\u4e8e\u5c0f\u578bLLM\u7684\u672c\u5730\u4e2a\u4eba\u52a9\u7406\u5e94\u7528\uff0cRAG\u662f\u66f4\u5b9e\u9645\u4e14\u9ad8\u6548\u7684\u9009\u62e9\u3002\u6a21\u578b\u6269\u5c55\u81f340\u4ebf\u53c2\u6570\u540e\uff0cRAG\u548c\u57fa\u7ebf\u6a21\u578b\u4ec5\u6709\u5fae\u5c0f\u541e\u5410\u91cf\u63d0\u5347\uff0c\u800cHyDE\u7684\u8ba1\u7b97\u8d1f\u62c5\u548c\u4e0d\u7a33\u5b9a\u6027\u663e\u8457\u52a0\u5267\u3002"}}
{"id": "2506.22309", "categories": ["cs.AI", "cs.CL", "cs.DM", "cs.LG", "06B99", "I.2.4; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.22309", "abs": "https://arxiv.org/abs/2506.22309", "authors": ["Klara M. Gutekunst", "Dominik D\u00fcrrschnabel", "Johannes Hirth", "Gerd Stumme"], "title": "Conceptual Topic Aggregation", "comment": "16 pages, 4 tables, 11 figures, International Joint Conference on\n  Conceptual Knowledge Structures", "summary": "The vast growth of data has rendered traditional manual inspection\ninfeasible, necessitating the adoption of computational methods for efficient\ndata exploration. Topic modeling has emerged as a powerful tool for analyzing\nlarge-scale textual datasets, enabling the extraction of latent semantic\nstructures. However, existing methods for topic modeling often struggle to\nprovide interpretable representations that facilitate deeper insights into data\nstructure and content. In this paper, we propose FAT-CAT, an approach based on\nFormal Concept Analysis (FCA) to enhance meaningful topic aggregation and\nvisualization of discovered topics. Our approach can handle diverse topics and\nfile types -- grouped by directories -- to construct a concept lattice that\noffers a structured, hierarchical representation of their topic distribution.\nIn a case study on the ETYNTKE dataset, we evaluate the effectiveness of our\napproach against other representation methods to demonstrate that FCA-based\naggregation provides more meaningful and interpretable insights into dataset\ncomposition than existing topic modeling techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFCA\u7684\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5FAT-CAT\uff0c\u63d0\u5347\u4e3b\u9898\u805a\u5408\u7684\u7ed3\u6784\u5316\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5728\u5b9e\u9645\u6848\u4f8b\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u6570\u636e\u91cf\u7684\u5feb\u901f\u589e\u957f\u4f7f\u5f97\u4f20\u7edf\u7684\u4eba\u5de5\u68c0\u67e5\u53d8\u5f97\u4e0d\u53ef\u884c\uff0c\u56e0\u6b64\u9700\u8981\u91c7\u7528\u9ad8\u6548\u7684\u8ba1\u7b97\u65b9\u6cd5\u8fdb\u884c\u6570\u636e\u63a2\u7d22\u3002\u73b0\u6709\u7684\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u867d\u7136\u80fd\u5206\u6790\u5927\u89c4\u6a21\u6587\u672c\u6570\u636e\uff0c\u4f46\u5728\u8d4b\u4e88\u6570\u636e\u7ed3\u6784\u548c\u5185\u5bb9\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u8bba\u6587\u63d0\u51faFAT-CAT\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\uff0c\u7528\u4e8e\u589e\u5f3a\u4e3b\u9898\u805a\u5408\u4e0e\u53ef\u89c6\u5316\u3002FAT-CAT\u80fd\u591f\u5904\u7406\u4e0d\u540c\u7684\u4e3b\u9898\u548c\u6587\u4ef6\u7c7b\u578b\uff08\u4ee5\u76ee\u5f55\u5206\u7ec4\uff09\uff0c\u901a\u8fc7\u6784\u5efa\u6982\u5ff5\u683c\u63d0\u4f9b\u5c42\u6b21\u5316\u548c\u7ed3\u6784\u5316\u7684\u4e3b\u9898\u5206\u5e03\u8868\u793a\u3002", "result": "\u5728ETYNTKE\u6570\u636e\u96c6\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u4e0e\u5176\u4ed6\u4e3b\u9898\u8868\u793a\u65b9\u6cd5\u76f8\u6bd4\uff0cFCA\u57fa\u7840\u7684\u805a\u5408\u80fd\u63d0\u4f9b\u66f4\u52a0\u6709\u610f\u4e49\u548c\u53ef\u89e3\u91ca\u7684\u6570\u636e\u96c6\u7ec4\u6210\u6d1e\u5bdf\u3002", "conclusion": "FAT-CAT\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u4e3b\u9898\u5efa\u6a21\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u89c6\u5316\u6548\u679c\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2506.21569", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21569", "abs": "https://arxiv.org/abs/2506.21569", "authors": ["Weihua Xiao", "Derek Ekberg", "Siddharth Garg", "Ramesh Karri"], "title": "Hybrid-NL2SVA: Integrating RAG and Finetuning for LLM-based NL2SVA", "comment": null, "summary": "SystemVerilog Assertions (SVAs) are critical for verifying the correctness of\nhardware designs, but manually writing them from natural language property\ndescriptions, i.e., NL2SVA, remains a labor-intensive and error-prone task.\nRecent advances in large language models (LLMs) offer opportunities to automate\nthis translation. However, existing models still struggle with understanding\ndomain-specific syntax and semantics. To enhance LLM performance in NL2SVA, we\npropose a customized retrieval-augmented generation (RAG) framework and a\nsynthetic fine-tuning dataset that together improve LLM's performance. To\nfurther improve lightweight models over NL2SVA, our fine-tuning dataset\nprovides prompt-guided explanations that teach LLMs the layer-by-layer\nconstruction process of concurrent SVAs, enabling supervised fine-tuning that\ngreatly improves syntax and functionality accuracy. To evaluate the performance\nof LLMs over NL2SVA, we construct the largest evaluation dataset for NL2SVA,\ncomprising 40 Verilog designs and 229 formally verified SVAs with detailed\nannotations. Experimental results show that our customized RAG framework\nincreases the number of functionality matched SVAs by 58.42% over GPT-4o-mini,\nwhile Qwen2.5-Coder-7B-Instruct fine-tuned on our fine-tuning dataset and\nintegrated with HybridRetrieval achieves a 59.05% over the base Qwen model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5b9a\u5236\u6df7\u5408RAG\u548c\u5206\u6b65\u89e3\u91ca\u5fae\u8c03\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347LLM\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u5316\u4e3aSystemVerilog\u65ad\u8a00\u7684\u80fd\u529b\uff0c\u5b9e\u9a8c\u5728\u6700\u5927\u8bc4\u6d4b\u96c6\u4e0a\u9a8c\u8bc1\u5176\u6027\u80fd\u5927\u5e45\u4f18\u4e8e\u4e3b\u6d41\u6a21\u578b\u3002", "motivation": "\u624b\u52a8\u5c06\u81ea\u7136\u8bed\u8a00\u5c5e\u6027\u63cf\u8ff0\uff08NL\uff09\u8f6c\u6362\u4e3aSystemVerilog\u65ad\u8a00\uff08SVA\uff09\u662f\u786c\u4ef6\u8bbe\u8ba1\u9a8c\u8bc1\u4e2d\u7684\u4e00\u4e2a\u7e41\u7410\u4e14\u6613\u9519\u73af\u8282\u3002\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e3a\u81ea\u52a8\u5316\u8fd9\u4e00\u4efb\u52a1\u63d0\u4f9b\u4e86\u5e0c\u671b\uff0c\u4f46\u5b83\u4eec\u5728\u9886\u57df\u7279\u5b9a\u8bed\u6cd5\u3001\u8bed\u4e49\u7406\u89e3\u4e0a\u4ecd\u6709\u4e0d\u8db3\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9a\u5236\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\u548c\u4e00\u4e2a\u5408\u6210\u5fae\u8c03\u6570\u636e\u96c6\u3002\u8fd9\u4e9b\u5de5\u5177\u5171\u540c\u63d0\u9ad8\u4e86LLM\u5728NL\u5230SVA\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u5fae\u8c03\u6570\u636e\u96c6\u5305\u542b\u4e86\u5206\u6b65\u89e3\u91ca\uff0c\u6307\u5bfc\u6a21\u578b\u9010\u5c42\u6784\u9020\u5e76\u7406\u89e3\u5e76\u53d1SVA\uff0c\u4ece\u800c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u663e\u8457\u63d0\u5347\u8bed\u6cd5\u548c\u529f\u80fd\u51c6\u786e\u5ea6\u3002", "result": "\u4e3a\u8bc4\u4f30\u6a21\u578b\u8868\u73b0\uff0c\u6784\u5efa\u4e86\u81f3\u4eca\u6700\u5927\u89c4\u6a21\u7684NL2SVA\u8bc4\u6d4b\u96c6\uff0840\u4e2aVerilog\u8bbe\u8ba1\u548c229\u4e2a\u7ecf\u5f62\u5f0f\u9a8c\u8bc1\u7684SVA\uff09\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u6240\u63d0RAG\u6846\u67b6\u80fd\u4f7f\u529f\u80fd\u5339\u914dSVA\u6570\u5728GPT-4o-mini\u57fa\u7840\u4e0a\u63d0\u534758.42%\uff1b\u7528\u6570\u636e\u96c6\u5fae\u8c03\u7ed3\u5408HybridRetrieval\u7684Qwen2.5-Coder-7B-Instruct\u6a21\u578b\u5bf9\u6bd4\u57fa\u7840Qwen\u63d0\u5347\u4e8659.05%\u3002", "conclusion": "\u7ed3\u5408\u5b9a\u5236RAG\u6846\u67b6\u548c\u5206\u6b65\u5fae\u8c03\u6570\u636e\u96c6\uff0c\u5927\u5e45\u63d0\u5347\u73b0\u6709LLM\u5728\u81ea\u7136\u8bed\u8a00\u5230SVA\u81ea\u52a8\u8f6c\u6362\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u548c\u529f\u80fd\u8868\u73b0\uff0c\u6709\u52a9\u4e8e\u964d\u4f4e\u4eba\u5de5\u6210\u672c\uff0c\u51cf\u5c11\u9519\u8bef\u3002"}}
{"id": "2506.22355", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22355", "abs": "https://arxiv.org/abs/2506.22355", "authors": ["Pascale Fung", "Yoram Bachrach", "Asli Celikyilmaz", "Kamalika Chaudhuri", "Delong Chen", "Willy Chung", "Emmanuel Dupoux", "Herv\u00e9 J\u00e9gou", "Alessandro Lazaric", "Arjun Majumdar", "Andrea Madotto", "Franziska Meier", "Florian Metze", "Th\u00e9o Moutakanni", "Juan Pino", "Basile Terver", "Joseph Tighe", "Jitendra Malik"], "title": "Embodied AI Agents: Modeling the World", "comment": null, "summary": "This paper describes our research on AI agents embodied in visual, virtual or\nphysical forms, enabling them to interact with both users and their\nenvironments. These agents, which include virtual avatars, wearable devices,\nand robots, are designed to perceive, learn and act within their surroundings,\nwhich makes them more similar to how humans learn and interact with the\nenvironments as compared to disembodied agents. We propose that the development\nof world models is central to reasoning and planning of embodied AI agents,\nallowing these agents to understand and predict their environment, to\nunderstand user intentions and social contexts, thereby enhancing their ability\nto perform complex tasks autonomously. World modeling encompasses the\nintegration of multimodal perception, planning through reasoning for action and\ncontrol, and memory to create a comprehensive understanding of the physical\nworld. Beyond the physical world, we also propose to learn the mental world\nmodel of users to enable better human-agent collaboration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u6784\u5efa\u7269\u7406\u548c\u5fc3\u7406\u7684\u4e16\u754c\u6a21\u578b\uff0c\u63d0\u5347\u5177\u8eabAI\uff08\u865a\u62df\u3001\u53ef\u7a7f\u6234\u3001\u673a\u5668\u4eba\u7b49\uff09\u7684\u73af\u5883\u7406\u89e3\u4e0e\u81ea\u4e3b\u80fd\u529b\uff0c\u662f\u5177\u8eab\u667a\u80fd\u4f53\u63a8\u7406\u89c4\u5212\u7684\u5173\u952e\u8def\u5f84\u3002", "motivation": "\u73b0\u6709\u7684AI\u4ee3\u7406\u7f3a\u4e4f\u5bf9\u73b0\u5b9e\u73af\u5883\u4e0e\u7528\u6237\u4e92\u52a8\u7684\u80fd\u529b\uff0c\u96be\u4ee5\u50cf\u4eba\u7c7b\u4e00\u6837\u611f\u77e5\u3001\u5b66\u4e60\u548c\u884c\u52a8\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5177\u8eab\u667a\u80fd\u4f53\u63d0\u5347\u5176\u7406\u89e3\u4e0e\u4efb\u52a1\u6267\u884c\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u5c06\u4e16\u754c\u5efa\u6a21\u4f5c\u4e3a\u5177\u8eabAI\u7684\u6838\u5fc3\uff0c\u5305\u62ec\u591a\u6a21\u6001\u611f\u77e5\u3001\u63a8\u7406\u89c4\u5212\u3001\u8bb0\u5fc6\u96c6\u6210\uff0c\u7efc\u5408\u7269\u7406\u4e0e\u7528\u6237\u5fc3\u7406\u7684\u4e16\u754c\u6a21\u578b\u6765\u589e\u5f3a\u667a\u80fd\u4f53\u7406\u89e3\u529b\u548c\u81ea\u4e3b\u4efb\u52a1\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u4e16\u754c\u6a21\u578b\uff0c\u5177\u8eabAI\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u548c\u9884\u6d4b\u73af\u5883\u3001\u7528\u6237\u610f\u56fe\u4e0e\u793e\u4f1a\u8bed\u5883\uff0c\u4ece\u800c\u63d0\u5347\u590d\u6742\u4efb\u52a1\u81ea\u4e3b\u6267\u884c\u548c\u4eba\u4e0e\u667a\u80fd\u4f53\u534f\u4f5c\u80fd\u529b\u3002", "conclusion": "\u4e16\u754c\u5efa\u6a21\u662f\u5177\u8eabAI\u667a\u80fd\u4f53\u63a8\u7406\u548c\u89c4\u5212\u7684\u6838\u5fc3\uff0c\u878d\u5408\u7269\u7406\u73af\u5883\u4e0e\u7528\u6237\u5fc3\u7406\u5efa\u6a21\uff0c\u6709\u671b\u663e\u8457\u63d0\u5347\u667a\u80fd\u4f53\u81ea\u4e3b\u6027\u548c\u534f\u4f5c\u6027\u3002"}}
{"id": "2506.21570", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21570", "abs": "https://arxiv.org/abs/2506.21570", "authors": ["Roland Riachi", "Kashif Rasul", "Arjun Ashok", "Prateek Humane", "Alexis Roger", "Andrew R. Williams", "Yuriy Nevmyvaka", "Irina Rish"], "title": "Random Initialization Can't Catch Up: The Advantage of Language Model Transfer for Time Series Forecasting", "comment": null, "summary": "Recent works have demonstrated the effectiveness of adapting pre-trained\nlanguage models (LMs) for forecasting time series in the low-data regime. We\nbuild upon these findings by analyzing the effective transfer from language\nmodels to time series forecasting under various design choices including\nupstream post-training, time series tokenizer and language backbone size. In\nthe low-data regime, these design choices have a significant impact on the\nvalidation loss, with clear-cut choices that outperform others. Contrary to\nHernandez et al. (2021), we observe that the validation loss of the LMs\ncontinues to smoothly decrease long after the validation loss of the randomly\ninitialized models has converged, leading to a non-vanishing transfer gap that\nholds across design choices. These findings not only help shed light on the\neffective use of compute-efficient training for time series, but also open the\nway for the study of modality-agnostic properties of data distributions\nleveraged by these models.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u5c06\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8fc1\u79fb\u5e94\u7528\u4e8e\u4f4e\u6570\u636e\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65f6\uff0c\u4e0d\u540c\u8bbe\u8ba1\u9009\u62e9\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5408\u7406\u8bbe\u8ba1\u80fd\u663e\u8457\u964d\u4f4e\u9a8c\u8bc1\u635f\u5931\uff0c\u5e76\u53d1\u73b0\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u540e\u671f\u4ecd\u6301\u7eed\u63d0\u5347\uff0c\u8fc1\u79fb\u4f18\u52bf\u660e\u663e\u3002", "motivation": "\u8fd1\u5e74\u6765\u7684\u7814\u7a76\u8868\u660e\uff0c\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08LMs\uff09\u5728\u4f4e\u6570\u636e\u91cf\u573a\u666f\u4e0b\u5bf9\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u8868\u73b0\u51fa\u8272\u3002\u672c\u6587\u65e8\u5728\u6df1\u5165\u63a2\u7a76\u5c06\u8bed\u8a00\u6a21\u578b\u9ad8\u6548\u8fc1\u79fb\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65f6\uff0c\u4e0d\u540c\u8bbe\u8ba1\u9009\u9879\uff08\u5982\u4e0a\u6e38\u540e\u8bad\u7ec3\u3001\u65f6\u95f4\u5e8f\u5217\u5206\u8bcd\u5668\u548c\u8bed\u8a00\u6a21\u578b\u4f53\u91cf\uff09\u7684\u5f71\u54cd\u3002", "method": "\u4f5c\u8005\u7cfb\u7edf\u6027\u5730\u5206\u6790\u4e86\u4e0d\u540c\u7684\u6a21\u578b\u8bbe\u8ba1\u9009\u62e9\uff0c\u5305\u62ec\u4e0a\u6e38\u540e\u8bad\u7ec3\uff08upstream post-training\uff09\u3001\u65f6\u95f4\u5e8f\u5217\u4e13\u7528\u5206\u8bcd\u5668\uff08tokenizer\uff09\u4ee5\u53ca\u8bed\u8a00\u6a21\u578b\u9aa8\u5e72\u4f53\u91cf\uff08backbone size\uff09\uff0c\u5e76\u5728\u4f4e\u6570\u636e\u91cf\u573a\u666f\u4e0b\u8bc4\u4f30\u5176\u5bf9\u9a8c\u8bc1\u635f\u5931\uff08validation loss\uff09\u7684\u5f71\u54cd\u3002", "result": "\u4e0d\u540c\u8bbe\u8ba1\u9009\u9879\u5bf9\u9a8c\u8bc1\u635f\u5931\u5177\u6709\u663e\u8457\u5f71\u54cd\uff0c\u67d0\u4e9b\u9009\u9879\u660e\u663e\u4f18\u4e8e\u5176\u4ed6\u9009\u9879\u3002\u540c\u65f6\uff0c\u4e0e\u4ee5\u5f80\u7814\u7a76\u7ed3\u8bba\u76f8\u53cd\uff0c\u672c\u6587\u53d1\u73b0\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u9a8c\u8bc1\u635f\u5931\u5728\u8bad\u7ec3\u540e\u671f\u4f9d\u7136\u80fd\u6301\u7eed\u4e0b\u964d\uff0c\u800c\u968f\u673a\u521d\u59cb\u5316\u6a21\u578b\u7684\u9a8c\u8bc1\u635f\u5931\u5219\u8f83\u65e9\u6536\u655b\uff0c\u5bfc\u81f4\u4e24\u8005\u95f4\u5b58\u5728\u4e0d\u53ef\u5ffd\u89c6\u7684\u8fc1\u79fb\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u6b63\u786e\u7684\u8bbe\u8ba1\u9009\u62e9\u80fd\u5927\u5e45\u63d0\u5347\u4f4e\u6570\u636e\u91cf\u4e0b\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\u3002\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u9ad8\u6548\u7b97\u529b\u5229\u7528\u4e0b\u6a21\u578b\u8fc1\u79fb\u80fd\u529b\u7684\u672c\u8d28\uff0c\u4e3a\u63a2\u7d22\u6570\u636e\u5206\u5e03\u4e2d\u7684\u6a21\u6001\u65e0\u5173\u5c5e\u6027\u6253\u5f00\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.22358", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22358", "abs": "https://arxiv.org/abs/2506.22358", "authors": ["Varvara Kalokyri", "Nikolaos S. Tachos", "Charalampos N. Kalantzopoulos", "Stelios Sfakianakis", "Haridimos Kondylakis", "Dimitrios I. Zaridis", "Sara Colantonio", "Daniele Regge", "Nikolaos Papanikolaou", "The ProCAncer-I consortium", "Konstantinos Marias", "Dimitrios I. Fotiadis", "Manolis Tsiknakis"], "title": "AI Model Passport: Data and System Traceability Framework for Transparent AI in Health", "comment": null, "summary": "The increasing integration of Artificial Intelligence (AI) into health and\nbiomedical systems necessitates robust frameworks for transparency,\naccountability, and ethical compliance. Existing frameworks often rely on\nhuman-readable, manual documentation which limits scalability, comparability,\nand machine interpretability across projects and platforms. They also fail to\nprovide a unique, verifiable identity for AI models to ensure their provenance\nand authenticity across systems and use cases, limiting reproducibility and\nstakeholder trust. This paper introduces the concept of the AI Model Passport,\na structured and standardized documentation framework that acts as a digital\nidentity and verification tool for AI models. It captures essential metadata to\nuniquely identify, verify, trace and monitor AI models across their lifecycle -\nfrom data acquisition and preprocessing to model design, development and\ndeployment. In addition, an implementation of this framework is presented\nthrough AIPassport, an MLOps tool developed within the ProCAncer-I EU project\nfor medical imaging applications. AIPassport automates metadata collection,\nensures proper versioning, decouples results from source scripts, and\nintegrates with various development environments. Its effectiveness is\nshowcased through a lesion segmentation use case using data from the\nProCAncer-I dataset, illustrating how the AI Model Passport enhances\ntransparency, reproducibility, and regulatory readiness while reducing manual\neffort. This approach aims to set a new standard for fostering trust and\naccountability in AI-driven healthcare solutions, aspiring to serve as the\nbasis for developing transparent and regulation compliant AI systems across\ndomains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAI Model Passport\u6846\u67b6\u53caAIPassport\u5de5\u5177\uff0c\u5b9e\u73b0AI\u6a21\u578b\u5168\u751f\u547d\u5468\u671f\u7684\u6807\u51c6\u5316\u6570\u5b57\u8eab\u4efd\u7ba1\u7406\u3002\u5728\u533b\u5b66\u5f71\u50cf\u7528\u4f8b\u9a8c\u8bc1\u4e86\u63d0\u5347\u900f\u660e\u5ea6\u3001\u53ef\u91cd\u590d\u6027\u548c\u5408\u89c4\u6027\uff0c\u51cf\u5c11\u4e86\u624b\u52a8\u64cd\u4f5c\u3002\u8be5\u65b9\u6cd5\u6216\u5c06\u6210\u4e3aAI\u5065\u5eb7\u5e94\u7528\u9886\u57df\u7684\u4fe1\u4efb\u4e0e\u76d1\u7ba1\u65b0\u6807\u51c6\u3002", "motivation": "\u76ee\u524dAI\u5728\u5065\u5eb7\u548c\u751f\u7269\u533b\u5b66\u9886\u57df\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u591a\uff0c\u5bf9\u900f\u660e\u6027\u3001\u8d23\u4efb\u548c\u4f26\u7406\u5408\u89c4\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\u3002\u73b0\u6709\u6846\u67b6\u591a\u4e3a\u4eba\u5de5\u6587\u6863\uff0c\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u3001\u53ef\u6bd4\u6027\u548c\u673a\u5668\u53ef\u8bfb\u6027\uff0c\u4e14\u65e0\u6cd5\u4e3aAI\u6a21\u578b\u63d0\u4f9b\u552f\u4e00\u4e14\u53ef\u9a8c\u8bc1\u7684\u8eab\u4efd\uff0c\u5f71\u54cd\u6a21\u578b\u6eaf\u6e90\u3001\u53ef\u91cd\u590d\u6027\u548c\u5229\u76ca\u76f8\u5173\u8005\u4fe1\u4efb\u3002", "method": "\u63d0\u51faAI Model Passport\u8fd9\u4e00\u7ed3\u6784\u5316\u3001\u6807\u51c6\u5316\u7684\u6587\u6863\u6846\u67b6\uff0c\u4e3aAI\u6a21\u578b\u63d0\u4f9b\u6570\u5b57\u8eab\u4efd\u548c\u9a8c\u8bc1\u624b\u6bb5\uff0c\u6db5\u76d6\u6570\u636e\u83b7\u53d6\u3001\u9884\u5904\u7406\u3001\u6a21\u578b\u8bbe\u8ba1\u3001\u5f00\u53d1\u548c\u90e8\u7f72\u7b49\u5168\u8fc7\u7a0b\u7684\u5143\u6570\u636e\u3002\u6846\u67b6\u8fd8\u901a\u8fc7AIPassport\u5de5\u5177\u5b9e\u73b0\uff0c\u5177\u4f53\u96c6\u6210\u4e8e\u6b27\u6d32ProCAncer-I\u533b\u5b66\u5f71\u50cf\u9879\u76ee\u4e2d\u3002\u8be5\u5de5\u5177\u81ea\u52a8\u6536\u96c6\u5143\u6570\u636e\uff0c\u7248\u672c\u7ba1\u7406\uff0c\u7ed3\u679c\u4e0e\u811a\u672c\u5206\u79bb\uff0c\u5e76\u80fd\u4e0e\u591a\u79cd\u5f00\u53d1\u73af\u5883\u517c\u5bb9\u3002", "result": "AIPassport\u5728\u5b9e\u9645\u7528\u4f8b\uff08\u57fa\u4e8eProCAncer-I\u6570\u636e\u96c6\u7684\u75c5\u53d8\u5206\u5272\u4efb\u52a1\uff09\u4e2d\u5c55\u793a\u51fa\u80fd\u591f\u63d0\u5347AI\u6a21\u578b\u900f\u660e\u6027\u3001\u53ef\u91cd\u590d\u6027\u53ca\u5408\u89c4\u6027\uff0c\u51cf\u5c11\u624b\u5de5\u5de5\u4f5c\u91cf\u3002", "conclusion": "AI Model Passport\u548cAIPassport\u5de5\u5177\u4e3aAI\u6a21\u578b\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u3001\u81ea\u52a8\u5316\u7684\u6570\u5b57\u8eab\u4efd\u7ba1\u7406\uff0c\u4fc3\u8fdb\u4e86\u533b\u7597AI\u7684\u900f\u660e\u3001\u53ef\u4fe1\u548c\u89c4\u8303\u53d1\u5c55\uff0c\u6709\u671b\u5728\u8de8\u9886\u57df\u63a8\u5e7f\u6210\u4e3a\u6807\u51c6\u5b9e\u8df5\u3002"}}
{"id": "2506.21571", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.21571", "abs": "https://arxiv.org/abs/2506.21571", "authors": ["Jianshuo Dong", "Yujia Fu", "Chuanrui Hu", "Chao Zhang", "Han Qiu"], "title": "Towards Understanding the Cognitive Habits of Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs), which autonomously produce a reasoning Chain\nof Thought (CoT) before producing final responses, offer a promising approach\nto interpreting and monitoring model behaviors. Inspired by the observation\nthat certain CoT patterns -- e.g., ``Wait, did I miss anything?'' --\nconsistently emerge across tasks, we explore whether LRMs exhibit human-like\ncognitive habits. Building on Habits of Mind, a well-established framework of\ncognitive habits associated with successful human problem-solving, we introduce\nCogTest, a principled benchmark designed to evaluate LRMs' cognitive habits.\nCogTest includes 16 cognitive habits, each instantiated with 25 diverse tasks,\nand employs an evidence-first extraction method to ensure reliable habit\nidentification. With CogTest, we conduct a comprehensive evaluation of 16\nwidely used LLMs (13 LRMs and 3 non-reasoning ones). Our findings reveal that\nLRMs, unlike conventional LLMs, not only exhibit human-like habits but also\nadaptively deploy them according to different tasks. Finer-grained analyses\nfurther uncover patterns of similarity and difference in LRMs' cognitive habit\nprofiles, particularly certain inter-family similarity (e.g., Qwen-3 models and\nDeepSeek-R1). Extending the study to safety-related tasks, we observe that\ncertain habits, such as Taking Responsible Risks, are strongly associated with\nthe generation of harmful responses. These findings suggest that studying\npersistent behavioral patterns in LRMs' CoTs is a valuable step toward deeper\nunderstanding of LLM misbehavior. The code is available at:\nhttps://github.com/jianshuod/CogTest.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCogTest\u57fa\u51c6\u7cfb\u7edf\u6027\u8bc4\u4f30\u5927\u6a21\u578b\u7684\u8ba4\u77e5\u4e60\u60ef\uff0c\u53d1\u73b0\u8fd9\u4e9b\u6a21\u578b\u5c55\u73b0\u51fa\u7c7b\u4eba\u7c7b\u7684\u8ba4\u77e5\u884c\u4e3a\uff0c\u4e14\u7279\u5b9a\u4e60\u60ef\u53ef\u80fd\u5173\u8054\u6709\u5bb3\u54cd\u5e94\uff0c\u4e3a\u6a21\u578b\u89e3\u91ca\u4e0e\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u751f\u6210Chain of Thought\uff08CoT\uff09\u94fe\u5f0f\u601d\u8003\u8fc7\u7a0b\u4e2d\uff0c\u51fa\u73b0\u4e86\u4e0e\u4eba\u7c7b\u7c7b\u4f3c\u7684\u8ba4\u77e5\u4e60\u60ef\u3002\u4e3a\u4e86\u6df1\u5165\u7406\u89e3\u548c\u8bc4\u4f30\u8fd9\u4e9b\u8ba4\u77e5\u4e60\u60ef\u4ee5\u53ca\u5176\u5728\u6a21\u578b\u884c\u4e3a\u89e3\u91ca\u4e0e\u5b89\u5168\u6027\u76d1\u63a7\u4e0a\u7684\u6f5c\u529b\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u57fa\u51c6\u3002", "method": "\u8bba\u6587\u57fa\u4e8e\u4eba\u7c7b\u6210\u529f\u89e3\u51b3\u95ee\u9898\u76f8\u5173\u7684\u201cHabits of Mind\u201d\u8ba4\u77e5\u4e60\u60ef\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86CogTest\u57fa\u51c6\uff0c\u6db5\u76d616\u79cd\u8ba4\u77e5\u4e60\u60ef\uff0c\u6bcf\u79cd\u4e60\u60ef\u5f15\u516525\u4e2a\u591a\u6837\u5316\u4efb\u52a1\uff0c\u5e76\u91c7\u7528evidence-first\uff08\u8bc1\u636e\u4f18\u5148\uff09\u63d0\u53d6\u65b9\u6cd5\u4fdd\u8bc1\u4e60\u60ef\u8bc6\u522b\u7684\u53ef\u9760\u6027\u3002\u5b9e\u9a8c\u6d89\u53ca\u5e7f\u6cdb\u8bc4\u6d4b13\u79cdLRM\u4e0e3\u79cd\u975e\u63a8\u7406LLM\u3002", "result": "LRMs\u8868\u73b0\u51fa\u660e\u663e\u7684\u4eba\u7c7b\u7c7b\u8ba4\u77e5\u4e60\u60ef\uff0c\u5e76\u80fd\u6839\u636e\u4efb\u52a1\u81ea\u9002\u5e94\u5730\u8fd0\u7528\u4e0d\u540c\u4e60\u60ef\u3002\u6b64\u5916\uff0c\u4e0d\u540c\u6a21\u578b\u65cf\u4e4b\u95f4\u5728\u8ba4\u77e5\u4e60\u60ef\u8868\u73b0\u4e0a\u5b58\u5728\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u3002\u67d0\u4e9b\u4e60\u60ef\uff08\u5982\u627f\u62c5\u8d23\u4efb\u6027\u98ce\u9669\uff09\u4e0e\u6709\u5bb3\u54cd\u5e94\u7684\u751f\u6210\u5bc6\u5207\u76f8\u5173\u3002", "conclusion": "CogTest\u80fd\u591f\u6709\u6548\u8bc4\u4ef7\u548c\u7ec6\u5206\u5927\u6a21\u578b\u7684\u8ba4\u77e5\u4e60\u60ef\uff0c\u63ed\u793a\u4e86LRMs\u7c7b\u4eba\u7c7b\u4e60\u60ef\u4e0e\u4efb\u52a1\u3001\u6f5c\u5728\u8d1f\u5411\u884c\u4e3a\u4e4b\u95f4\u7684\u5173\u8054\u6027\uff0c\u5bf9\u6a21\u578b\u5b89\u5168\u6027\u548c\u884c\u4e3a\u89e3\u91ca\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.22419", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22419", "abs": "https://arxiv.org/abs/2506.22419", "authors": ["Bingchen Zhao", "Despoina Magka", "Minqi Jiang", "Xian Li", "Roberta Raileanu", "Tatiana Shavrina", "Jean-Christophe Gagnon-Audet", "Kelvin Niu", "Shagun Sodhani", "Michael Shvartsman", "Andrei Lupu", "Alisia Lupidi", "Edan Toledo", "Karen Hambardzumyan", "Martin Josifoski", "Thomas Foster", "Lucia Cipolina-Kun", "Abhishek Charnalia", "Derek Dunfield", "Alexander H. Miller", "Oisin Mac Aodha", "Jakob Foerster", "Yoram Bachrach"], "title": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements", "comment": null, "summary": "Rapid advancements in large language models (LLMs) have the potential to\nassist in scientific progress. A critical capability toward this endeavor is\nthe ability to reproduce existing work. To evaluate the ability of AI agents to\nreproduce results in an active research area, we introduce the Automated LLM\nSpeedrunning Benchmark, leveraging the research community contributions on the\nNanoGPT speedrun, a competition to train a GPT-2 model in the shortest time.\nEach of the 19 speedrun tasks provides the agent with the previous records\ntraining script, optionally paired with one of three hint formats, ranging from\npseudocode to paper-like descriptions of the new records improvements. Records\nexecute quickly by design and speedrun improvements encompass diverse\ncode-level changes, ranging from high-level algorithmic advancements to\nhardware-aware optimizations. These features make the benchmark both accessible\nand realistic for the frontier problem of improving LLM training. We find that\nrecent reasoning LLMs combined with SoTA scaffolds struggle to reimplement\nalready-known innovations in our benchmark, even when given detailed hints. Our\nbenchmark thus provides a simple, non-saturated measure of an LLMs ability to\nautomate scientific reproduction, a necessary (but not sufficient) skill for an\nautonomous research agent.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Automated LLM Speedrunning Benchmark\uff0c\u7528\u4e8e\u8861\u91cf\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u590d\u73b0\u79d1\u5b66\u7814\u7a76\u7684\u80fd\u529b\u3002\u7ed3\u679c\u53d1\u73b0\uff0c\u5373\u4fbf\u63d0\u4f9b\u7ec6\u81f4\u7ebf\u7d22\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u6a21\u578b\u5728\u590d\u73b0\u5df2\u77e5\u521b\u65b0\u65b9\u9762\u4f9d\u7136\u56f0\u96be\u3002\u8fd9\u4e00\u57fa\u51c6\u6709\u52a9\u4e8e\u5ba2\u89c2\u8bc4\u6d4bLLM\u7684\u79d1\u7814\u81ea\u52a8\u5316\u6f5c\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fc5\u901f\u53d1\u5c55\uff0c\u88ab\u8ba4\u4e3a\u6709\u52a9\u4e8e\u79d1\u5b66\u8fdb\u6b65\u3002\u7136\u800c\uff0c\u8981\u63a8\u52a8\u79d1\u5b66\u53d1\u5c55\uff0cLLM\u9700\u8981\u5177\u5907\u590d\u73b0\u73b0\u6709\u7814\u7a76\u6210\u679c\u7684\u80fd\u529b\u3002\u8be5\u7814\u7a76\u65e8\u5728\u8bc4\u4f30AI\u6a21\u578b\u5728\u81ea\u52a8\u5316\u79d1\u5b66\u8bba\u6587\u7ed3\u679c\u590d\u73b0\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Automated LLM Speedrunning Benchmark\u57fa\u51c6\uff0c\u57fa\u4e8eNanoGPT\u7684\u8bad\u7ec3\u7ade\u8d5b\u4efb\u52a1\u3002\u8be5\u57fa\u51c6\u5305\u542b19\u4e2aspeedrun\u4efb\u52a1\uff0c\u6bcf\u4e2a\u4efb\u52a1\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u4e0a\u4e00\u4e2a\u8bb0\u5f55\u7684\u8bad\u7ec3\u811a\u672c\uff0c\u5e76\u53ef\u9009\u62e9\u4e09\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u683c\u5f0f\uff08\u4f2a\u4ee3\u7801\u3001\u8bba\u6587\u63cf\u8ff0\u7b49\uff09\uff0c\u7531\u6b64\u8981\u6c42AI\u590d\u73b0\u5e76\u8d85\u8d8a\u6b64\u524d\u7684\u8bad\u7ec3\u8bb0\u5f55\u3002\u8fd9\u4e2a\u57fa\u51c6\u6db5\u76d6\u4ece\u7b97\u6cd5\u521b\u65b0\u5230\u786c\u4ef6\u4f18\u5316\u7b49\u591a\u79cd\u6539\u8fdb\u7c7b\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u4e3a\u6700\u65b0\u63a8\u7406\u578bLLM\u6a21\u578b\u7ed3\u5408\u5148\u8fdbscaffold\u7ed3\u6784\u63d0\u4f9b\u8be6\u7ec6\u63d0\u793a\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u590d\u73b0\u5df2\u77e5\u521b\u65b0\u65f6\u4ecd\u7136\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u8be5\u57fa\u51c6\u4e3a\u8bc4\u4ef7LLM\u81ea\u52a8\u590d\u73b0\u79d1\u5b66\u7814\u7a76\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u3001\u6709\u6548\u3001\u4e14\u672a\u8fbe\u9971\u548c\u7684\u6d4b\u91cf\u65b9\u6cd5\uff0c\u8fd9\u5bf9\u4e8e\u5b9e\u73b0\u81ea\u4e3b\u7814\u7a76\u578b\u667a\u80fd\u4f53\u662f\u5fc5\u8981\u4f46\u5c1a\u4e0d\u8db3\u591f\u7684\u80fd\u529b\u3002"}}
{"id": "2506.21572", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.21572", "abs": "https://arxiv.org/abs/2506.21572", "authors": ["Tianyu. Zou", "Shengwu. Xiong", "Ruilin. Yao", "Jirui. Huang", "Yi. Rong", "Yaxiong. Chen", "Shili. Xiong", "Cong. Wang"], "title": "Aligning MLLM Benchmark With Human Preferences via Structural Equation Modeling", "comment": "9 pages, 5 figures", "summary": "Evaluating multimodal large language models (MLLMs) remains a fundamental\nchallenge due to a lack of structured, interpretable, and theoretically\ngrounded benchmark designs. Existing benchmarks often adopt heuristic-based\ntask groupings with unclear cognitive targets, thus resulting in overlapping\nabilities, redundant indicators, and limited diagnostic power. In this work, we\npropose a novel framework for aligning MLLM benchmark based on Structural\nEquation Modeling (SEM) to analyze and quantify the internal validity,\ndimensional separability, and contribution of benchmark components. Motivated\nby the observed limitations of current designs, we further introduce a novel\ncapability hierarchy grounded in Piagets theory of cognitive development,\ndividing MLLM abilities into three hierarchical layers, i.e., Perception,\nMemory, and Reasoning. We reorganize existing MLLM benchmarks under the\nproposed framework and construct a new benchmark named Gold. Experimental\nresults demonstrate that the proposed benchmark exhibits stronger\ninterpretability, reduced indicator redundancy, and clearer cognitive\nconsistency compared to existing approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eSEM\u4e0e\u8ba4\u77e5\u7406\u8bba\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u65b0\u8bc4\u6d4b\u57fa\u51c6\u4f53\u7cfb\uff0c\u63d0\u9ad8\u4e86\u89e3\u91ca\u6027\u548c\u6548\u679c\u3002", "motivation": "\u76ee\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u6d4b\u57fa\u51c6\u7f3a\u4e4f\u7ed3\u6784\u5316\u548c\u7406\u8bba\u652f\u6491\uff0c\u6307\u6807\u91cd\u53e0\u3001\u80fd\u529b\u4e0d\u6e05\u3001\u89e3\u91ca\u6027\u5dee\uff0c\u4e9f\u9700\u7cfb\u7edf\u5316\u3001\u7406\u8bba\u5316\u7684\u57fa\u51c6\u6846\u67b6\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\uff08SEM\uff09\u5206\u6790\u57fa\u51c6\u7ec4\u4ef6\u7684\u5185\u90e8\u6548\u5ea6\u3001\u7ef4\u5ea6\u53ef\u5206\u6027\u53ca\u5176\u8d21\u732e\uff0c\u5e76\u57fa\u4e8e\u76ae\u4e9a\u6770\u8ba4\u77e5\u53d1\u5c55\u7406\u8bba\u5c06\u591a\u6a21\u6001\u80fd\u529b\u5206\u4e3a\u611f\u77e5\u3001\u8bb0\u5fc6\u548c\u63a8\u7406\u4e09\u4e2a\u5c42\u7ea7\uff0c\u6700\u7ec8\u8bbe\u8ba1\u65b0\u57fa\u51c6 Gold\u3002", "result": "\u6240\u63d0\u51fa\u7684\u57fa\u51c6\u5177\u5907\u66f4\u5f3a\u7684\u89e3\u91ca\u80fd\u529b\u3001\u6307\u6807\u5197\u4f59\u51cf\u5c11\u3001\u8ba4\u77e5\u4e00\u81f4\u6027\u66f4\u6e05\u6670\uff0c\u76f8\u8f83\u73b0\u6709\u8bc4\u6d4b\u65b9\u6848\u6548\u679c\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\uff08SEM\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u57fa\u51c6\u8fdb\u884c\u5bf9\u9f50\u548c\u91cd\u7ec4\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u57fa\u51c6\u7684\u89e3\u91ca\u6027\u548c\u8bca\u65ad\u80fd\u529b\u3002"}}
{"id": "2412.15194", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2412.15194", "abs": "https://arxiv.org/abs/2412.15194", "authors": ["Qihao Zhao", "Yangyu Huang", "Tengchao Lv", "Lei Cui", "Qinzheng Sun", "Shaoguang Mao", "Xin Zhang", "Ying Xin", "Qiufeng Yin", "Scarlett Li", "Furu Wei"], "title": "MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark", "comment": null, "summary": "Multiple-choice question (MCQ) datasets like Massive Multitask Language\nUnderstanding (MMLU) are widely used to evaluate the commonsense,\nunderstanding, and problem-solving abilities of large language models (LLMs).\nHowever, the open-source nature of these benchmarks and the broad sources of\ntraining data for LLMs have inevitably led to benchmark contamination,\nresulting in unreliable evaluation results. To alleviate this issue, we propose\na contamination-free and more challenging MCQ benchmark called MMLU-CF. This\nbenchmark reassesses LLMs' understanding of world knowledge by averting both\nunintentional and malicious data leakage. To avoid unintentional data leakage,\nwe source data from a broader domain and design three decontamination rules. To\nprevent malicious data leakage, we divide the benchmark into validation and\ntest sets with similar difficulty and subject distributions. The test set\nremains closed-source to ensure reliable results, while the validation set is\npublicly available to promote transparency and facilitate independent\nverification. Our evaluation of mainstream LLMs reveals that the powerful\nGPT-4o achieves merely a 5-shot score of 73.4% and a 0-shot score of 71.9% on\nthe test set, which indicates the effectiveness of our approach in creating a\nmore rigorous and contamination-free evaluation standard. The GitHub repository\nis available at https://github.com/microsoft/MMLU-CF and the dataset refers to\nhttps://huggingface.co/datasets/microsoft/MMLU-CF.", "AI": {"tldr": "\u9488\u5bf9\u4e8e\u73b0\u6709MMLU\u591a\u9009\u9898\u6570\u636e\u96c6\u5b58\u5728\u7684\u6c61\u67d3\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u65e0\u6c61\u67d3\u3001\u6311\u6218\u6027\u66f4\u9ad8\u7684MMLU-CF\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u95ed\u6e90\u6d4b\u8bd5\u96c6\u7b49\u673a\u5236\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u8bc4\u6d4b\u6743\u5a01\u6027\uff0c\u9a8c\u8bc1GPT-4o\u7b49\u6a21\u578b\u5728\u5176\u4e0a\u5206\u6570\u663e\u8457\u964d\u4f4e\uff0c\u53cd\u6620\u51fa\u6a21\u578b\u771f\u5b9e\u80fd\u529b\uff0c\u4e5f\u4e3a\u9886\u57df\u8bc4\u6d4b\u6811\u7acb\u4e86\u65b0\u6807\u51c6\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u9879\u9009\u62e9\u9898\uff08MCQ\uff09\u6570\u636e\u96c6\u5982MMLU\u5e7f\u6cdb\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5e38\u8bc6\u3001\u7406\u89e3\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u4f46\u7531\u4e8e\u5176\u5f00\u6e90\u7279\u6027\u548cLLM\u8bad\u7ec3\u6570\u636e\u6765\u6e90\u5e7f\u6cdb\uff0c\u5bfc\u81f4\u8bc4\u6d4b\u6570\u636e\u6cc4\u9732\u3001\u6c61\u67d3\uff0c\u5bfc\u81f4\u8bc4\u6d4b\u7ed3\u679c\u4e0d\u53ef\u9760\u3002", "method": "\u63d0\u51fa\u4e86\u65e0\u6c61\u67d3\u3001\u6311\u6218\u6027\u66f4\u9ad8\u7684MMLU-CF\u6570\u636e\u96c6\u3002\u901a\u8fc7\u62d3\u5bbd\u6570\u636e\u6765\u6e90\u9886\u57df\uff0c\u5e76\u8bbe\u8ba1\u4e09\u6761\u53bb\u6c61\u67d3\u89c4\u5219\u9632\u6b62\u975e\u6076\u610f\u6570\u636e\u6cc4\u9732\u3002\u540c\u65f6\u4e3a\u9632\u8303\u6076\u610f\u6570\u636e\u6cc4\u9732\uff0c\u5c06\u6570\u636e\u96c6\u5206\u4e3a\u9a8c\u8bc1\u96c6\uff08\u516c\u5f00\uff09\u548c\u6d4b\u8bd5\u96c6\uff08\u95ed\u6e90\uff09\uff0c\u4fdd\u8bc1\u6d4b\u8bd5\u6807\u51c6\u7684\u516c\u6b63\u6027\u548c\u53ef\u9760\u6027\u3002", "result": "GPT-4o\u7b49\u4e3b\u6d41LLM\u5728MMLU-CF\u6d4b\u8bd5\u96c6\u4e0a\u76845-shot\u5f97\u5206\u4ec5\u4e3a73.4%\uff0c0-shot\u5f97\u5206\u4e3a71.9%\u3002\u663e\u793a\u8be5\u6570\u636e\u96c6\u63d0\u5347\u4e86\u6d4b\u8bd5\u96be\u5ea6\uff0c\u6709\u6548\u9632\u6b62\u4e86\u6570\u636e\u6c61\u67d3\u3002", "conclusion": "MMLU-CF\u4e3aLLM\u63d0\u4f9b\u4e86\u66f4\u4e25\u683c\u3001\u65e0\u6c61\u67d3\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u66f4\u771f\u5b9e\u5730\u53cd\u6620\u6a21\u578b\u80fd\u529b\u3002\u8be5\u6570\u636e\u96c6\u90e8\u5206\u5f00\u653e\uff0c\u90e8\u5206\u95ed\u6e90\u4ee5\u5e73\u8861\u900f\u660e\u5ea6\u53ca\u4e25\u8c28\u6027\u3002"}}
{"id": "2506.21573", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21573", "abs": "https://arxiv.org/abs/2506.21573", "authors": ["Yanwei Ren", "Liu Liu", "Baosheng Yu", "Jiayan Qiu", "Quan Chen"], "title": "Instruction Learning Paradigms: A Dual Perspective on White-box and Black-box LLMs", "comment": null, "summary": "Optimizing instructions for large language models (LLMs) is critical for\nharnessing their full potential in complex and diverse tasks. However, relying\nsolely on white-box approaches demands extensive computational resources and\noffers limited representational capacity, while black-box models can incur\nprohibitive financial costs. To address these challenges, we introduce a novel\nframework that seamlessly merges the strengths of both paradigms. Black-box\nmodels provide high-quality, diverse instruction initializations, and white-box\nmodels supply fine-grained interpretability through hidden states and output\nfeatures. By enforcing a semantic similarity constraint, these components fuse\ninto a unified high-dimensional representation that captures deep semantic and\nstructural nuances, enabling an iterative optimization process to refine\ninstruction quality and adaptability. Extensive evaluations across a broad\nspectrum of tasks-ranging from complex reasoning to cross-lingual\ngeneralization-demonstrate that our approach consistently outperforms\nstate-of-the-art baselines. This fusion of black-box initialization with\nadvanced semantic refinement yields a scalable and efficient solution, paving\nthe way for next-generation LLM-driven applications in diverse real-world\nscenarios. The source code will be released soon.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u878d\u5408\u9ed1\u76d2\u521d\u59cb\u5316\u548c\u767d\u76d2\u7cbe\u4fee\u7684\u6846\u67b6\u4f18\u5316LLM\u6307\u4ee4\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6307\u4ee4\u8d28\u91cf\u548c\u591a\u4efb\u52a1\u8868\u73b0\uff0c\u517c\u5177\u6548\u7387\u3001\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u8d85\u8d8a\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u3002", "motivation": "\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6307\u4ee4\u662f\u91ca\u653e\u5176\u5728\u590d\u6742\u548c\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u5168\u90e8\u6f5c\u529b\u7684\u5173\u952e\u3002\u5f53\u524d\u4ec5\u4f9d\u8d56\u767d\u76d2\u65b9\u6cd5\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u5927\u3001\u8868\u793a\u80fd\u529b\u6709\u9650\uff0c\u800c\u9ed1\u76d2\u65b9\u6cd5\u5219\u5e26\u6765\u8f83\u9ad8\u7684\u8d22\u52a1\u6210\u672c\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u7ed3\u5408\u53cc\u65b9\u4f18\u52bf\uff0c\u65e2\u80fd\u9ad8\u6548\u521d\u59cb\uff0c\u53c8\u5177\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408\u9ed1\u76d2\u548c\u767d\u76d2\u6a21\u578b\u4f18\u70b9\u7684\u65b0\u6846\u67b6\u3002\u5177\u4f53\u505a\u6cd5\u662f\uff1a\u91c7\u7528\u9ed1\u76d2\u6a21\u578b\u8fdb\u884c\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u6027\u7684\u6307\u4ee4\u521d\u59cb\u5316\uff0c\u540c\u65f6\u5229\u7528\u767d\u76d2\u6a21\u578b\u7684\u9690\u85cf\u72b6\u6001\u548c\u8f93\u51fa\u7279\u5f81\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u89e3\u91ca\uff0c\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u6027\u7ea6\u675f\u5c06\u4e8c\u8005\u7edf\u4e00\u4e8e\u9ad8\u7ef4\u8868\u793a\u7a7a\u95f4\uff0c\u518d\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u63d0\u5347\u6307\u4ee4\u8d28\u91cf\u548c\u9002\u5e94\u6027\u3002", "result": "\u5728\u6db5\u76d6\u590d\u6742\u63a8\u7406\u3001\u8de8\u8bed\u8a00\u6cdb\u5316\u7b49\u5e7f\u6cdb\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u8bc4\u6d4b\u4e2d\uff0c\u6240\u63d0\u65b9\u6cd5\u5747\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u6307\u4ee4\u4f18\u5316\u65b9\u6848\u3002", "conclusion": "\u878d\u5408\u9ed1\u76d2\u521d\u59cb\u5316\u4e0e\u57fa\u4e8e\u8bed\u4e49\u7684\u9ad8\u7ea7\u7cbe\u4fee\uff0c\u4e3aLLM\u9a71\u52a8\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u7684\u65b0\u8303\u5f0f\u3002\u9884\u8ba1\u5c06\u6781\u5927\u63a8\u52a8\u5b9e\u9645\u573a\u666f\u4e0bLLM\u5e94\u7528\u7684\u53d1\u5c55\u3002\u6e90\u7801\u5373\u5c06\u516c\u5e03\u3002"}}
{"id": "2506.21545", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2506.21545", "abs": "https://arxiv.org/abs/2506.21545", "authors": ["Yalun Dai", "Yangyu Huang", "Xin Zhang", "Wenshan Wu", "Chong Li", "Wenhui Lu", "Shijie Cao", "Li Dong", "Scarlett Li"], "title": "Data Efficacy for Language Model Training", "comment": null, "summary": "Data is fundamental to the training of language models (LM). Recent research\nhas been dedicated to data efficiency, which aims to maximize performance by\nselecting a minimal or optimal subset of training data. Techniques such as data\nfiltering, sampling, and selection play a crucial role in this area. To\ncomplement it, we define Data Efficacy, which focuses on maximizing performance\nby optimizing the organization of training data and remains relatively\nunderexplored. This work introduces a general paradigm, DELT, for considering\ndata efficacy in LM training, which highlights the significance of training\ndata organization. DELT comprises three components: Data Scoring, Data\nSelection, and Data Ordering. Among these components, we design\nLearnability-Quality Scoring (LQS), as a new instance of Data Scoring, which\nconsiders both the learnability and quality of each data sample from the\ngradient consistency perspective. We also devise Folding Ordering (FO), as a\nnovel instance of Data Ordering, which addresses issues such as model\nforgetting and data distribution bias. Comprehensive experiments validate the\ndata efficacy in LM training, which demonstrates the following: Firstly,\nvarious instances of the proposed DELT enhance LM performance to varying\ndegrees without increasing the data scale and model size. Secondly, among these\ninstances, the combination of our proposed LQS for data scoring and Folding for\ndata ordering achieves the most significant improvement. Lastly, data efficacy\ncan be achieved together with data efficiency by applying data selection.\nTherefore, we believe that data efficacy is a promising foundational area in LM\ntraining.", "AI": {"tldr": "\u63d0\u51faDELT\u8303\u5f0f\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u6570\u636e\u6253\u5206\u548c\u6392\u5e8f\u65b9\u6cd5\uff0c\u4e0d\u589e\u52a0\u6570\u636e\u91cf\u4e0e\u6a21\u578b\u5927\u5c0f\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u4e30\u5bcc\u4e86\u6570\u636e\u6548\u80fd\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u8d8a\u6765\u8d8a\u91cd\u89c6\u6570\u636e\u6548\u7387\uff0c\u5373\u5728\u6709\u9650\u7684\u6570\u636e\u4e0b\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u5bf9\u4e8e\u5982\u4f55\u4f18\u5316\u6570\u636e\u7684\u7ec4\u7ec7\uff08\u800c\u975e\u4ec5\u4ec5\u9009\u62e9\u54ea\u4e9b\u6570\u636e\u6765\u8bad\u7ec3\uff09\u5173\u6ce8\u8f83\u5c11\u3002\u56e0\u6b64\uff0c\u63a2\u7d22\u901a\u8fc7\u4f18\u5316\u8bad\u7ec3\u6570\u636e\u7684\u6392\u5217\u548c\u7ec4\u7ec7\u6765\u63d0\u5347\u6a21\u578b\u8868\u73b0\u6210\u4e3a\u65b0\u7684\u7814\u7a76\u52a8\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u8303\u5f0fDELT\uff0c\u5305\u542bData Scoring\uff08\u6570\u636e\u6253\u5206\uff09\u3001Data Selection\uff08\u6570\u636e\u9009\u62e9\uff09\u548cData Ordering\uff08\u6570\u636e\u6392\u5e8f\uff09\u4e09\u5927\u6a21\u5757\u3002\u5176\u4e2d\uff0c\u521b\u65b0\u6027\u5730\u8bbe\u8ba1\u4e86Learnability-Quality Scoring\uff08LQS\uff09\u6253\u5206\u65b9\u6cd5\uff0c\u4ece\u68af\u5ea6\u4e00\u81f4\u6027\u89d2\u5ea6\u540c\u65f6\u8003\u8651\u4e86\u6570\u636e\u7684\u53ef\u5b66\u4e60\u6027\u548c\u8d28\u91cf\uff1b\u8fd8\u63d0\u51fa\u4e86Folding Ordering\uff08FO\uff09\u6392\u5e8f\u65b9\u6cd5\uff0c\u7528\u4e8e\u7f13\u89e3\u6a21\u578b\u9057\u5fd8\u548c\u6570\u636e\u5206\u5e03\u504f\u79fb\u7b49\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528DELT\u6846\u67b6\u4e0b\u4e0d\u540c\u65b9\u6cd5\u5747\u80fd\u5728\u4e0d\u6269\u5927\u6570\u636e\u89c4\u6a21\u548c\u6a21\u578b\u89c4\u6a21\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff1b\u5176\u4e2dLQS\u548cFolding Ordering\u7684\u7ed3\u5408\u6548\u679c\u6700\u597d\u3002\u6b64\u5916\uff0c\u6570\u636e\u6548\u80fd\uff08data efficacy\uff09\u4e0e\u6570\u636e\u6548\u7387\uff08data efficiency\uff09\u53ef\u4ee5\u4e92\u4e3a\u8865\u5145\u534f\u540c\u63d0\u5347\u3002", "conclusion": "\u6570\u636e\u6548\u80fd\uff08\u5373\u901a\u8fc7\u4f18\u5316\u6570\u636e\u7ec4\u7ec7\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff09\u662f\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u4e00\u4e2a\u6709\u524d\u666f\u7684\u57fa\u7840\u65b9\u5411\uff0cDELT\u8303\u5f0f\u548c\u5176\u4e2d\u7684\u65b0\u6280\u672f\u80fd\u6709\u6548\u63d0\u5347\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.21574", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21574", "abs": "https://arxiv.org/abs/2506.21574", "authors": ["Yicheng Mao", "Yang Zhao"], "title": "Digital Gatekeepers: Exploring Large Language Model's Role in Immigration Decisions", "comment": null, "summary": "With globalization and increasing immigrant populations, immigration\ndepartments face significant work-loads and the challenge of ensuring fairness\nin decision-making processes. Integrating artificial intelligence offers a\npromising solution to these challenges. This study investigates the potential\nof large language models (LLMs),such as GPT-3.5 and GPT-4, in supporting\nimmigration decision-making. Utilizing a mixed-methods approach,this paper\nconducted discrete choice experiments and in-depth interviews to study LLM\ndecision-making strategies and whether they are fair. Our findings demonstrate\nthat LLMs can align their decision-making with human strategies, emphasizing\nutility maximization and procedural fairness. Meanwhile, this paper also\nreveals that while ChatGPT has safeguards to prevent unintentional\ndiscrimination, it still exhibits stereotypes and biases concerning nationality\nand shows preferences toward privileged group. This dual analysis highlights\nboth the potential and limitations of LLMs in automating and enhancing\nimmigration decisions.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u79fb\u6c11\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u5176\u517c\u5177\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u516c\u6b63\u51b3\u7b56\u80fd\u529b\u53ca\u504f\u89c1\u95ee\u9898\uff0c\u663e\u793a\u51fa\u5e94\u7528\u6f5c\u529b\u4f46\u4e5f\u5b58\u5728\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u5168\u7403\u5316\u548c\u79fb\u6c11\u4eba\u53e3\u589e\u52a0\uff0c\u79fb\u6c11\u90e8\u95e8\u5de5\u4f5c\u8d1f\u62c5\u52a0\u91cd\uff0c\u540c\u65f6\u9762\u4e34\u786e\u4fdd\u51b3\u7b56\u516c\u5e73\u6027\u7684\u6311\u6218\u3002\u5982\u4f55\u63d0\u5347\u51b3\u7b56\u6548\u7387\u4e0e\u516c\u6b63\u6027\u6210\u4e3a\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002\u4eba\u5de5\u667a\u80fd\uff0c\u7279\u522b\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u6216\u53ef\u4e3a\u6b64\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u4e00\u662f\u8fdb\u884c\u79bb\u6563\u9009\u62e9\u5b9e\u9a8c\uff0c\u4e8c\u662f\u6df1\u5165\u8bbf\u8c08\uff0c\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-3.5\u548cGPT-4\uff09\u5728\u79fb\u6c11\u51b3\u7b56\u4e2d\u7684\u7b56\u7565\u53ca\u5176\u516c\u5e73\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u51b3\u7b56\u65f6\u80fd\u4e0e\u4eba\u7c7b\u7b56\u7565\u76f8\u5951\u5408\uff0c\u4fa7\u91cd\u6548\u7528\u6700\u5927\u5316\u548c\u7a0b\u5e8f\u516c\u6b63\u6027\u3002\u4f46\u540c\u65f6\uff0cChatGPT\u7b49\u6a21\u578b\u867d\u5177\u5907\u9632\u6b62\u65e0\u610f\u6b67\u89c6\u7684\u673a\u5236\uff0c\u4f9d\u7136\u8868\u73b0\u51fa\u56fd\u7c4d\u523b\u677f\u5370\u8c61\u548c\u5bf9\u7279\u6743\u7fa4\u4f53\u7684\u504f\u597d\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u548c\u63d0\u5347\u79fb\u6c11\u51b3\u7b56\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u540c\u65f6\u5b58\u5728\u523b\u677f\u5370\u8c61\u548c\u504f\u89c1\u7b49\u5c40\u9650\u6027\u3002\u9700\u8c28\u614e\u8bc4\u4f30\u5176\u5728\u5b9e\u9645\u79fb\u6c11\u51b3\u7b56\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2506.21575", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21575", "abs": "https://arxiv.org/abs/2506.21575", "authors": ["Josefa Lia Stoisser", "Marc Boubnovski Martell", "Lawrence Phillips", "Casper Hansen", "Julien Fauqueur"], "title": "STRuCT-LLM: Unifying Tabular and Graph Reasoning with Reinforcement Learning for Semantic Parsing", "comment": null, "summary": "We propose STRuCT-LLM, a unified framework for training large language models\n(LLMs) to perform structured reasoning over both relational and\ngraph-structured data. Our approach jointly optimizes Text-to-SQL and\nText-to-Cypher tasks using reinforcement learning (RL) combined with\nChain-of-Thought (CoT) supervision. To support fine-grained optimization in\ngraph-based parsing, we introduce a topology-aware reward function based on\ngraph edit distance. Unlike prior work that treats relational and graph\nformalisms in isolation, STRuCT-LLM leverages shared abstractions between SQL\nand Cypher to induce cross-formalism transfer, enabling SQL training to improve\nCypher performance and vice versa - even without shared schemas. Our largest\nmodel (QwQ-32B) achieves substantial relative improvements across tasks: on\nsemantic parsing, Spider improves by 13.5\\% and Text2Cypher by 73.1\\%. The\nmodel also demonstrates strong zero-shot generalization, improving performance\non downstream tabular QA (TableBench: 8.5\\%) and knowledge graph QA\n(CR-LT-KGQA: 1.7\\%) without any QA-specific supervision. These results\ndemonstrate both the effectiveness of executable queries as scaffolds for\nstructured reasoning and the synergistic benefits of jointly training on SQL\nand Cypher (code available at https://github.com/bouv/STRuCT-LLM).", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSTRuCT-LLM\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u8054\u5408\u8bad\u7ec3\u63d0\u5347\u5927\u6a21\u578b\u5bf9\u5173\u7cfb\u578b\u548c\u56fe\u7ed3\u6784\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u5728SQL\u4e0eCypher\u4efb\u52a1\uff0c\u4ee5\u53ca\u65e0\u76d1\u7763\u4e0b\u6e38\u95ee\u7b54\u4efb\u52a1\u4e0a\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u5c06\u5173\u7cfb\u578b\uff08SQL\uff09\u4e0e\u56fe\u7ed3\u6784\uff08Cypher\uff09\u63a8\u7406\u5206\u5f00\u5904\u7406\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u4e8c\u8005\u95f4\u7684\u5171\u6027\uff0c\u672c\u7814\u7a76\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u5b9e\u73b0SQL\u548cCypher\u4efb\u52a1\u7684\u534f\u540c\u63d0\u5347\u3002", "method": "STRuCT-LLM\u6846\u67b6\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u601d\u7ef4\u94fe\uff08CoT\uff09\u76d1\u7763\uff0c\u8054\u5408\u8bad\u7ec3Text-to-SQL\u548cText-to-Cypher\u4efb\u52a1\u3002\u5728\u56fe\u7ed3\u6784\u89e3\u6790\u4e2d\u5f15\u5165\u57fa\u4e8e\u56fe\u7f16\u8f91\u8ddd\u79bb\u7684\u62d3\u6251\u611f\u77e5\u5956\u52b1\u673a\u5236\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u4f18\u5316\u3002\u6a21\u578b\u91c7\u7528SQL\u548cCypher\u95f4\u5171\u4eab\u62bd\u8c61\uff0c\u5e76\u8fdb\u884c\u8de8\u5f62\u5f0f\u8fc1\u79fb\u5b66\u4e60\u3002", "result": "\u6700\u5927\u89c4\u6a21\u6a21\u578bQwQ-32B\u5728Spider\uff08Text-to-SQL\uff09\u4efb\u52a1\u4e0a\u63d0\u534713.5%\uff0c\u5728Text2Cypher\u4efb\u52a1\u4e0a\u63d0\u534773.1%\uff1b\u5728\u4e0b\u6e38\u8868\u683c\u95ee\u7b54\uff08TableBench\uff09\u548c\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\uff08CR-LT-KGQA\uff09\u4efb\u52a1\u4e0a\u4e5f\u53d6\u5f97\u4e868.5%\u548c1.7%\u7684\u65e0\u76d1\u7763\u8fc1\u79fb\u63d0\u5347\u3002", "conclusion": "STRuCT-LLM\u6a21\u578b\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5173\u7cfb\u578b\u548c\u56fe\u7ed3\u6784\u6570\u636e\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8054\u5408\u4f18\u5316SQL\u548cCypher\u80fd\u4ea7\u751f\u534f\u540c\u589e\u76ca\u3002"}}
{"id": "2506.21576", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.21576", "abs": "https://arxiv.org/abs/2506.21576", "authors": ["Hongli Yang", "Yizhou Peng", "Hao Huang", "Sheng Li"], "title": "Adapting Whisper for Parameter-efficient Code-Switching Speech Recognition via Soft Prompt Tuning", "comment": "Accepted by Interspeech 2025", "summary": "Large-scale multilingual ASR models like Whisper excel in high-resource\nsettings but face challenges in low-resource scenarios, such as rare languages\nand code-switching (CS), due to computational costs and catastrophic\nforgetting. We explore Soft Prompt Tuning (SPT), a parameter-efficient method\nto enhance CS ASR while preserving prior knowledge. We evaluate two strategies:\n(1) full fine-tuning (FFT) of both soft prompts and the entire Whisper model,\ndemonstrating improved cross-lingual capabilities compared to traditional\nmethods, and (2) adhering to SPT's original design by freezing model parameters\nand only training soft prompts. Additionally, we introduce SPT4ASR, a\ncombination of different SPT variants. Experiments on the SEAME and ASRU2019\ndatasets show that deep prompt tuning is the most effective SPT approach, and\nour SPT4ASR methods achieve further error reductions in CS ASR, maintaining\nparameter efficiency similar to LoRA, without degrading performance on existing\nlanguages.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u901a\u8fc7Soft Prompt Tuning\uff08SPT\uff09\u53ca\u5176\u65b0\u53d8\u4f53SPT4ASR\uff0c\u5bf9\u5927\u578b\u591a\u8bed\u79cdASR\u6a21\u578b\u8fdb\u884c\u9ad8\u6548\u5fae\u8c03\uff0c\u6709\u6548\u63d0\u5347\u4ee3\u7801\u5207\u6362\u53ca\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u7684\u8bed\u97f3\u8bc6\u522b\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u539f\u6709\u8bed\u79cd\u7684\u8bc6\u522b\u6548\u679c\u548c\u53c2\u6570\u9ad8\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u591a\u8bed\u8a00\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u6a21\u578b\u5982Whisper\u5728\u8d44\u6e90\u5145\u8db3\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4ee5\u53ca\u4ee3\u7801\u5207\u6362\uff08CS\uff09\u573a\u666f\u4e2d\u5219\u9762\u4e34\u8ba1\u7b97\u5f00\u9500\u5927\u548c\u707e\u96be\u6027\u9057\u5fd8\u7b49\u6311\u6218\u3002\u8be5\u7814\u7a76\u65e8\u5728\u63d0\u5347\u4f4e\u8d44\u6e90\u53caCS\u573a\u666f\u4e0b\u7684ASR\u6027\u80fd\uff0c\u540c\u65f6\u7ef4\u6301\u6a21\u578b\u5bf9\u5df2\u6709\u77e5\u8bc6\u7684\u4fdd\u7559\u3002", "method": "\u63d0\u51fa\u91c7\u7528Soft Prompt Tuning\uff08SPT\uff09\u8fd9\u79cd\u9ad8\u6548\u53c2\u6570\u5fae\u8c03\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u6a21\u578b\u7684CS ASR\u80fd\u529b\u3002\u6587\u7ae0\u8bc4\u4f30\u4e86\u4e24\u79cd\u7b56\u7565\uff1a\u4e00\u662f\u9488\u5bf9\u6a21\u578b\u53ca\u8f6f\u63d0\u793a\u5168\u9762\u5fae\u8c03\uff08FFT\uff09\uff0c\u63d0\u5347\u8de8\u8bed\u8a00\u80fd\u529b\uff1b\u4e8c\u662f\u9075\u5faaSPT\u539f\u8bbe\u8ba1\uff0c\u51bb\u7ed3\u6a21\u578b\u53c2\u6570\uff0c\u4ec5\u8bad\u7ec3\u8f6f\u63d0\u793a\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u591a\u79cdSPT\u53d8\u4f53\u7684\u65b0\u65b9\u6cd5SPT4ASR\u3002", "result": "\u5728SEAME\u548cASRU2019\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0c\u6df1\u5ea6\u63d0\u793a\u5fae\u8c03\uff08deep prompt tuning\uff09\u662f\u6700\u6709\u6548\u7684SPT\u65b9\u5f0f\u3002SPT4ASR\u65b9\u6cd5\u5728\u4fdd\u6301\u53c2\u6570\u9ad8\u6548\u7684\u540c\u65f6\uff0c\u4f7fCS ASR\u7684\u9519\u8bef\u7387\u8fdb\u4e00\u6b65\u964d\u4f4e\uff0c\u4e14\u4e0d\u4f1a\u635f\u5bb3\u5df2\u6709\u8bed\u8a00\u7684\u8bc6\u522b\u6027\u80fd\u3002", "conclusion": "\u53c2\u6570\u9ad8\u6548\u7684\u8f6f\u63d0\u793a\u5fae\u8c03\u65b9\u6cd5\uff08SPT\uff09\u53ca\u5176\u65b0\u53d8\u4f53SPT4ASR\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u8bed\u79cdASR\u6a21\u578b\u5728\u4ee3\u7801\u5207\u6362\u548c\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u7ef4\u6301\u5bf9\u5df2\u77e5\u8bed\u79cd\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u4e14\u4e0e\u5f53\u524d\u9ad8\u6548\u8c03\u53c2\u65b9\u6cd5\uff08\u5982LoRA\uff09\u7c7b\u4f3c\u5730\u4e0b\u7ef4\u6301\u4e86\u53c2\u6570\u6548\u7387\u3002"}}
{"id": "2506.21577", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.21577", "abs": "https://arxiv.org/abs/2506.21577", "authors": ["Hongli Yang", "Sheng Li", "Hao Huang", "Ayiduosi Tuohan", "Yizhou Peng"], "title": "Language-Aware Prompt Tuning for Parameter-Efficient Seamless Language Expansion in Multilingual ASR", "comment": "Accepted by Interspeech 2025", "summary": "Recent advancements in multilingual automatic speech recognition (ASR) have\nbeen driven by large-scale end-to-end models like Whisper. However, challenges\nsuch as language interference and expanding to unseen languages (language\nexpansion) without degrading performance persist. This paper addresses these\nwith three contributions: 1) Entire Soft Prompt Tuning (Entire SPT), which\napplies soft prompts to both the encoder and decoder, enhancing feature\nextraction and decoding; 2) Language-Aware Prompt Tuning (LAPT), which\nleverages cross-lingual similarities to encode shared and language-specific\nfeatures using lightweight prompt matrices; 3) SPT-Whisper, a toolkit that\nintegrates SPT into Whisper and enables efficient continual learning.\nExperiments across three languages from FLEURS demonstrate that Entire SPT and\nLAPT outperform Decoder SPT by 5.0% and 16.0% in language expansion tasks,\nrespectively, providing an efficient solution for dynamic, multilingual ASR\nmodels with minimal computational overhead.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5728\u591a\u8bed\u79cdASR\u6a21\u578bWhisper\u4e2d\u5f15\u5165\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u8054\u5408\u8f6f\u63d0\u793a\u8c03\u4f18\uff0c\u53ca\u9762\u5411\u8bed\u8a00\u7684\u63d0\u793a\u673a\u5236\uff0c\u663e\u8457\u6539\u5584\u4e86\u65b0\u589e\u8bed\u8a00\u9002\u914d\u6027\u80fd\u5e76\u964d\u4f4e\u8fd0\u7b97\u5f00\u9500\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u7aef\u5230\u7aef\u591a\u8bed\u79cdASR\u6a21\u578b\uff0c\u5982Whisper\uff0c\u5f15\u5165\u4e86\u65b0\u7684\u6027\u80fd\u521b\u65b0\uff0c\u4f46\u5728\u591a\u8bed\u8a00\u5e72\u6270\u548c\u65b0\u8bed\u8a00\u9002\u914d\uff08\u8bed\u8a00\u6269\u5c55\uff09\u65f6\u4ecd\u7136\u5b58\u5728\u6311\u6218\uff0c\u4e14\u4e0d\u80fd\u4fdd\u8bc1\u65b0\u589e\u8bed\u8a00\u65f6\u6027\u80fd\u4e0d\u4e0b\u964d\u3002\u8be5\u8bba\u6587\u81f4\u529b\u4e8e\u89e3\u51b3\u8fd9\u4e9b\u5b9e\u9645\u95ee\u9898\u3002", "method": "1\uff09\u63d0\u51faEntire Soft Prompt Tuning (Entire SPT)\uff0c\u5728\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u4e24\u90e8\u5206\u540c\u65f6\u5e94\u7528\u8f6f\u63d0\u793a\u5f3a\u5316\u7279\u5f81\u63d0\u53d6\u4e0e\u89e3\u7801\u80fd\u529b\uff1b2\uff09\u63d0\u51faLanguage-Aware Prompt Tuning (LAPT)\uff0c\u5229\u7528\u8de8\u8bed\u8a00\u76f8\u4f3c\u6027\u901a\u8fc7\u8f7b\u91cf\u63d0\u793a\u77e9\u9635\u6355\u6349\u5171\u4eab\u53ca\u7279\u5b9a\u8bed\u8a00\u7279\u5f81\uff1b3\uff09\u5f00\u53d1SPT-Whisper\u5de5\u5177\u5305\uff0c\u5c06SPT\u65b9\u6cd5\u96c6\u6210\u81f3Whisper\u4e2d\uff0c\u652f\u6301\u9ad8\u6548\u6301\u7eed\u5b66\u4e60\u3002", "result": "\u5728FLEURS\u6570\u636e\u96c6\u4e09\u4e2a\u8bed\u8a00\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cEntire SPT\u548cLAPT\u5728\u8bed\u8a00\u6269\u5c55\u4efb\u52a1\u4e2d\u76f8\u5bf9\u4f20\u7edf\u7684Decoder SPT\u5206\u522b\u53d6\u5f97\u4e865.0%\u548c16.0%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u8ba1\u7b97\u8d44\u6e90\u5f00\u9500\u8f83\u5c0f\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u7f13\u89e3\u591a\u8bed\u79cdASR\u6a21\u578b\u7684\u8bed\u8a00\u5e72\u6270\u4e0e\u8bed\u8a00\u6269\u5c55\u95ee\u9898\uff0c\u5e76\u5927\u5e45\u63d0\u5347\u6a21\u578b\u5728\u65b0\u8bed\u8a00\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4e3a\u52a8\u6001\u591a\u8bed\u79cdASR\u6a21\u578b\u63d0\u4f9b\u9ad8\u6548\u3001\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.21578", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21578", "abs": "https://arxiv.org/abs/2506.21578", "authors": ["Andrew Maranh\u00e3o Ventura D'addario"], "title": "HealthQA-BR: A System-Wide Benchmark Reveals Critical Knowledge Gaps in Large Language Models", "comment": null, "summary": "The evaluation of Large Language Models (LLMs) in healthcare has been\ndominated by physician-centric, English-language benchmarks, creating a\ndangerous illusion of competence that ignores the interprofessional nature of\npatient care. To provide a more holistic and realistic assessment, we introduce\nHealthQA-BR, the first large-scale, system-wide benchmark for\nPortuguese-speaking healthcare. Comprising 5,632 questions from Brazil's\nnational licensing and residency exams, it uniquely assesses knowledge not only\nin medicine and its specialties but also in nursing, dentistry, psychology,\nsocial work, and other allied health professions. We conducted a rigorous\nzero-shot evaluation of over 20 leading LLMs. Our results reveal that while\nstate-of-the-art models like GPT 4.1 achieve high overall accuracy (86.6%),\nthis top-line score masks alarming, previously unmeasured deficiencies. A\ngranular analysis shows performance plummets from near-perfect in specialties\nlike Ophthalmology (98.7%) to barely passing in Neurosurgery (60.0%) and, most\nnotably, Social Work (68.4%). This \"spiky\" knowledge profile is a systemic\nissue observed across all models, demonstrating that high-level scores are\ninsufficient for safety validation. By publicly releasing HealthQA-BR and our\nevaluation suite, we provide a crucial tool to move beyond single-score\nevaluations and toward a more honest, granular audit of AI readiness for the\nentire healthcare team.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u5e76\u516c\u5f00\u4e86\u9996\u4e2a\u8461\u8bed\u533b\u7597\u591a\u5b66\u79d1\u5927\u6a21\u578b\u8bc4\u6d4b\u96c6HealthQA-BR\uff0c\u53d1\u73b0\u5f53\u524d\u4e3b\u6d41\u6a21\u578b\u5b58\u5728\u5b66\u79d1\u95f4\u5de8\u5927\u77ed\u677f\uff0c\u603b\u5206\u9ad8\u4f46\u7ec6\u5206\u80fd\u529b\u4e0d\u8db3\uff0c\u5bf9\u5b89\u5168\u90e8\u7f72\u63d0\u51fa\u8b66\u793a\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u533b\u7597\u9886\u57df\u7684\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4ee5\u533b\u751f\u4e3a\u4e2d\u5fc3\u3001\u82f1\u8bed\u4e3a\u4e3b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5ffd\u89c6\u4e86\u533b\u7597\u56e2\u961f\u7684\u591a\u5143\u5316\u548c\u591a\u8bed\u8a00\u5b9e\u9645\u9700\u6c42\uff0c\u53ef\u80fd\u8bef\u5bfc\u5bf9\u6a21\u578b\u80fd\u529b\u7684\u8ba4\u77e5\u3002", "method": "\u4f5c\u8005\u521b\u5efa\u4e86HealthQA-BR\uff0c\u8fd9\u662f\u9996\u4e2a\u9488\u5bf9\u8461\u8404\u7259\u8bed\u5065\u5eb7\u533b\u7597\u9886\u57df\u3001\u6db5\u76d6\u591a\u5b66\u79d1\u7684\u5927\u89c4\u6a21\u7cfb\u7edf\u6027\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b5632\u9053\u6765\u81ea\u5df4\u897f\u56fd\u5bb6\u533b\u62a4\u3001\u7259\u533b\u3001\u5fc3\u7406\u3001\u793e\u5de5\u7b49\u76f8\u5173\u8003\u8bd5\u7684\u95ee\u9898\u3002\u91c7\u7528\u96f6\u6837\u672c\uff08zero-shot\uff09\u65b9\u5f0f\uff0c\u5bf920\u591a\u6b3e\u4e3b\u6d41LLM\u8fdb\u884c\u5168\u9762\u6d4b\u8bc4\uff0c\u5e76\u7ec6\u5316\u5230\u5404\u533b\u7597\u5b66\u79d1\u3002", "result": "\u867d\u7136\u5982GPT 4.1\u7b49\u6700\u65b0\u6a21\u578b\u603b\u4f53\u51c6\u786e\u7387\u8f83\u9ad8\uff0886.6%\uff09\uff0c\u4f46\u5728\u5404\u5b66\u79d1\u95f4\u8868\u73b0\u5dee\u5f02\u5de8\u5927\uff0c\u5982\u773c\u79d1\u63a5\u8fd1\u6ee1\u5206\uff0898.7%\uff09\uff0c\u800c\u795e\u7ecf\u5916\u79d1\u3001\u793e\u5de5\u7b49\u79d1\u76ee\u4ec5\u4e3a60%\u548c68.4%\u3002\u8fd9\u79cd\u201c\u952f\u9f7f\u72b6\u201d\u77e5\u8bc6\u5206\u5e03\u662f\u6240\u6709\u6a21\u578b\u7684\u5171\u6027\uff0c\u8bc1\u660e\u6574\u4f53\u9ad8\u5206\u65e0\u6cd5\u53cd\u6620\u5b9e\u9645\u5b89\u5168\u4e0e\u80fd\u529b\u3002", "conclusion": "\u9ad8\u5206\u6a21\u578b\u5728\u5b9e\u9645\u591a\u5b66\u79d1\u533b\u7597\u573a\u666f\u4e0b\u4ecd\u5b58\u5728\u672a\u88ab\u9ad8\u5c42\u5206\u6570\u63a9\u76d6\u7684\u4e25\u91cd\u77ed\u677f\u3002\u4f5c\u8005\u516c\u5f00HealthQA-BR\u548c\u8bc4\u6d4b\u5957\u4ef6\uff0c\u63a8\u52a8\u4e86\u66f4\u771f\u5b9e\u7ec6\u81f4\u7684AI\u5728\u533b\u7597\u591a\u5b66\u79d1\u73af\u5883\u4e2d\u7684\u80fd\u529b\u5ba1\u6838\u3002"}}
{"id": "2506.21582", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.21582", "abs": "https://arxiv.org/abs/2506.21582", "authors": ["Sam Yu-Te Lee", "Chengyang Ji", "Shicheng Wen", "Lifu Huang", "Dongyi Liu", "Kwan-Liu Ma"], "title": "VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents", "comment": null, "summary": "Text analytics has traditionally required specialized knowledge in Natural\nLanguage Processing (NLP) or text analysis, which presents a barrier for\nentry-level analysts. Recent advances in large language models (LLMs) have\nchanged the landscape of NLP by enabling more accessible and automated text\nanalysis (e.g., topic detection, summarization, information extraction, etc.).\nWe introduce VIDEE, a system that supports entry-level data analysts to conduct\nadvanced text analytics with intelligent agents. VIDEE instantiates a\nhuman-agent collaroration workflow consisting of three stages: (1)\nDecomposition, which incorporates a human-in-the-loop Monte-Carlo Tree Search\nalgorithm to support generative reasoning with human feedback, (2) Execution,\nwhich generates an executable text analytics pipeline, and (3) Evaluation,\nwhich integrates LLM-based evaluation and visualizations to support user\nvalidation of execution results. We conduct two quantitative experiments to\nevaluate VIDEE's effectiveness and analyze common agent errors. A user study\ninvolving participants with varying levels of NLP and text analytics experience\n-- from none to expert -- demonstrates the system's usability and reveals\ndistinct user behavior patterns. The findings identify design implications for\nhuman-agent collaboration, validate the practical utility of VIDEE for\nnon-expert users, and inform future improvements to intelligent text analytics\nsystems.", "AI": {"tldr": "\u63d0\u51faVIDEE\u7cfb\u7edf\uff0c\u501f\u52a9\u4eba\u673a\u534f\u4f5c\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e2e\u52a9\u975e\u4e13\u5bb6\u8f7b\u677e\u5b8c\u6210\u9ad8\u7ea7\u6587\u672c\u5206\u6790\u3002\u5b9e\u9a8c\u8bc1\u660e\u7cfb\u7edf\u6709\u6548\u3001\u6613\u7528\uff0c\u5e76\u4e3a\u667a\u80fd\u6587\u672c\u5206\u6790\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u7ecf\u9a8c\u3002", "motivation": "\u4f20\u7edf\u6587\u672c\u5206\u6790\u95e8\u69db\u9ad8\uff0c\u9700\u8981\u4e13\u4e1aNLP\u77e5\u8bc6\uff1b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u4e3a\u81ea\u52a8\u5316\u548c\u6613\u7528\u7684\u6587\u672c\u5206\u6790\u5e26\u6765\u65b0\u5951\u673a\uff0c\u4f46\u4e9f\u9700\u9762\u5411\u521d\u7ea7\u5206\u6790\u5e08\u7684\u53cb\u597d\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u4eba\u673a\u534f\u4f5c\u5de5\u4f5c\u6d41\uff0c\u5206\u4e3a\u62c6\u89e3\uff08\u7ed3\u5408\u4eba\u5de5\u53cd\u9988\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b97\u6cd5\uff09\u3001\u6267\u884c\uff08\u751f\u6210\u53ef\u6267\u884c\u7684\u6587\u672c\u5206\u6790\u6d41\u7a0b\uff09\u3001\u8bc4\u4f30\uff08\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4ef7\u548c\u53ef\u89c6\u5316\uff09\uff0c\u5e76\u901a\u8fc7\u4e24\u9879\u5b9a\u91cf\u5b9e\u9a8c\u548c\u7528\u6237\u7814\u7a76\u6d4b\u8bd5\u7cfb\u7edf\u6027\u80fd\u548c\u7528\u6237\u884c\u4e3a\u3002", "result": "VIDEE\u7cfb\u7edf\u63d0\u5347\u4e86\u521d\u5b66\u8005\u8fdb\u884c\u590d\u6742\u6587\u672c\u5206\u6790\u4efb\u52a1\u7684\u80fd\u529b\uff1b\u5b9e\u9a8c\u8bc1\u660e\u5176\u6613\u7528\u6027\u3001\u6548\u679c\uff0c\u5e76\u63ed\u793a\u4e86\u4eba\u673a\u5408\u4f5c\u4e2d\u7528\u6237\u884c\u4e3a\u7684\u5dee\u5f02\u53ca\u5e38\u89c1\u667a\u80fd\u4f53\u9519\u8bef\u3002", "conclusion": "\u7814\u7a76\u9a8c\u8bc1\u4e86VIDEE\u7cfb\u7edf\u5bf9\u4e8e\u975e\u4e13\u5bb6\u7528\u6237\u5728\u9ad8\u9636\u6587\u672c\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u6548\u7528\uff0c\u5e76\u8bc6\u522b\u4e86\u4eba\u673a\u534f\u4f5c\u8fc7\u7a0b\u4e2d\u7684\u8bbe\u8ba1\u610f\u4e49\u4e0e\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2506.21583", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21583", "abs": "https://arxiv.org/abs/2506.21583", "authors": ["Muhammad Ahmad", "Muhammad Waqas", "Ameer Hamza", "Ildar Batyrshin", "Grigori Sidorov"], "title": "Hope Speech Detection in code-mixed Roman Urdu tweets: A Positive Turn in Natural Language Processing", "comment": null, "summary": "Hope is a positive emotional state involving the expectation of favorable\nfuture outcomes, while hope speech refers to communication that promotes\noptimism, resilience, and support, particularly in adverse contexts. Although\nhope speech detection has gained attention in Natural Language Processing\n(NLP), existing research mainly focuses on high-resource languages and\nstandardized scripts, often overlooking informal and underrepresented forms\nsuch as Roman Urdu. To the best of our knowledge, this is the first study to\naddress hope speech detection in code-mixed Roman Urdu by introducing a\ncarefully annotated dataset, thereby filling a critical gap in inclusive NLP\nresearch for low-resource, informal language varieties. This study makes four\nkey contributions: (1) it introduces the first multi-class annotated dataset\nfor Roman Urdu hope speech, comprising Generalized Hope, Realistic Hope,\nUnrealistic Hope, and Not Hope categories; (2) it explores the psychological\nfoundations of hope and analyzes its linguistic patterns in code-mixed Roman\nUrdu to inform dataset development; (3) it proposes a custom attention-based\ntransformer model optimized for the syntactic and semantic variability of Roman\nUrdu, evaluated using 5-fold cross-validation; and (4) it verifies the\nstatistical significance of performance gains using a t-test. The proposed\nmodel, XLM-R, achieves the best performance with a cross-validation score of\n0.78, outperforming the baseline SVM (0.75) and BiLSTM (0.76), with gains of 4%\nand 2.63% respectively.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u7f57\u9a6c\u5316\u4e4c\u5c14\u90fd\u8bed\u5e0c\u671b\u8a00\u8bba\u591a\u5206\u7c7b\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u5b9a\u5236transformer\u6a21\u578bXLM-R\uff0c\u5728\u5e0c\u671b\u8a00\u8bba\u68c0\u6d4b\u4efb\u52a1\u4e2d\u53d6\u5f97\u6700\u4f73\u8868\u73b0\uff0c\u63a8\u52a8\u4f4e\u8d44\u6e90\u8bed\u79cdNLP\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u5e0c\u671b\u8a00\u8bba\u68c0\u6d4b\u4e3b\u8981\u5173\u6ce8\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u5ffd\u89c6\u4e86\u50cf\u7f57\u9a6c\u5316\u4e4c\u5c14\u90fd\u8bed\u8fd9\u6837\u975e\u6b63\u5f0f\u3001\u6df7\u5408\u4ee3\u7801\u3001\u4f4e\u8d44\u6e90\u8bed\u79cd\u3002\u672c\u6587\u65e8\u5728\u63a8\u52a8\u5305\u5bb9\u6027\u7684NLP\u7814\u7a76\uff0c\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7684\u7a7a\u767d\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u81ea\u5b9a\u4e49transformer\u6a21\u578b\uff0c\u5e76\u7ed3\u54085\u6298\u4ea4\u53c9\u9a8c\u8bc1\u548ct\u68c0\u9a8c\u9a8c\u8bc1\u7ed3\u679c\u7684\u7edf\u8ba1\u663e\u8457\u6027\u3002", "result": "\uff081\uff09\u9996\u4e2a\u7f57\u9a6c\u5316\u4e4c\u5c14\u90fd\u8bed\u591a\u5206\u7c7b\u5e0c\u671b\u8bed\u6599\u5e93\uff1b\uff082\uff09\u63a2\u8ba8\u5e0c\u671b\u7684\u5fc3\u7406\u5b66\u57fa\u7840\u548c\u8bed\u8a00\u8868\u8fbe\uff1b\uff083\uff09\u63d0\u51fa\u5e76\u9a8c\u8bc1\u65b0\u6a21\u578b\uff0cXLM-R\u5f97\u52060.78\uff0c\u9ad8\u4e8eSVM\u548cBiLSTM\uff1b\uff084\uff09\u5b9e\u9a8c\u589e\u76ca\u5177\u6709\u7edf\u8ba1\u663e\u8457\u6027\u3002", "conclusion": "XLM-R\u6a21\u578b\u5728\u7f57\u9a6c\u5316\u4e4c\u5c14\u90fd\u8bed\u5e0c\u671b\u8a00\u8bba\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u5b9e\u73b0\u4e860.78\u7684\u4ea4\u53c9\u9a8c\u8bc1\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2506.21585", "categories": ["cs.CL", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21585", "abs": "https://arxiv.org/abs/2506.21585", "authors": ["Christoph Brosch", "Sian Brumm", "Rolf Krieger", "Jonas Scheffler"], "title": "Evaluation of LLM-based Strategies for the Extraction of Food Product Information from Online Shops", "comment": "Preprint for paper presented at DATA 2025 in Bilbao, Spain. Corrected\n  -2.27 to -1.61 in abstract and +2.27 to +1.61 in discussion. Reference to\n  journal and publication will follow", "summary": "Generative AI and large language models (LLMs) offer significant potential\nfor automating the extraction of structured information from web pages. In this\nwork, we focus on food product pages from online retailers and explore\nschema-constrained extraction approaches to retrieve key product attributes,\nsuch as ingredient lists and nutrition tables. We compare two LLM-based\napproaches, direct extraction and indirect extraction via generated functions,\nevaluating them in terms of accuracy, efficiency, and cost on a curated dataset\nof 3,000 food product pages from three different online shops. Our results show\nthat although the indirect approach achieves slightly lower accuracy (96.48\\%,\n$-1.61\\%$ compared to direct extraction), it reduces the number of required LLM\ncalls by 95.82\\%, leading to substantial efficiency gains and lower operational\ncosts. These findings suggest that indirect extraction approaches can provide\nscalable and cost-effective solutions for large-scale information extraction\ntasks from template-based web pages using LLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6bd4\u8f83\u4e86\u4e24\u79cd\u57fa\u4e8eLLM\u7684\u7f51\u9875\u4fe1\u606f\u62bd\u53d6\u65b9\u6cd5\uff0c\u53d1\u73b0\u901a\u8fc7\u751f\u6210\u51fd\u6570\u7684\u95f4\u63a5\u62bd\u53d6\u6cd5\u867d\u7136\u51c6\u786e\u7387\u7565\u4f4e\uff0c\u4f46\u80fd\u6781\u5927\u8282\u7701\u6210\u672c\u548c\u63d0\u9ad8\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u529b\u65b9\u6848\u3002", "motivation": "\u751f\u6210\u5f0fAI\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53ef\u4ee5\u81ea\u52a8\u4ece\u7f51\u9875\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u4fe1\u606f\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u5728\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u6210\u672c\u4e4b\u95f4\u505a\u6743\u8861\u3002\u5982\u4f55\u5728\u4fdd\u969c\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u81ea\u52a8\u5316\u62bd\u53d6\u7684\u6548\u7387\u548c\u964d\u4f4e\u6210\u672c\uff0c\u662f\u4e00\u4e2a\u6709\u5b9e\u9645\u610f\u4e49\u7684\u95ee\u9898\u3002", "method": "\u8be5\u7814\u7a76\u5173\u6ce8\u5728\u7ebf\u96f6\u552e\u5546\u7684\u98df\u54c1\u4ea7\u54c1\u7f51\u9875\uff0c\u91c7\u7528\u57fa\u4e8eschema\u7ea6\u675f\u7684\u4fe1\u606f\u62bd\u53d6\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u4e24\u79cd\u57fa\u4e8eLLM\u7684\u62bd\u53d6\u65b9\u6cd5\uff1a\u76f4\u63a5\u62bd\u53d6\u548c\u901a\u8fc7\u751f\u6210\u51fd\u6570\u7684\u95f4\u63a5\u62bd\u53d6\uff0c\u5e76\u5728\u4e00\u4e2a\u5305\u542b3000\u4e2a\u98df\u54c1\u9875\u9762\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6bd4\u8f83\u3002\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u6210\u672c\u3002", "result": "\u95f4\u63a5\u62bd\u53d6\u65b9\u6cd5\u7684\u51c6\u786e\u7387\u7565\u4f4e\uff0896.48%\uff0c\u6bd4\u76f4\u63a5\u62bd\u53d6\u4f4e1.61%\uff09\uff0c\u4f46\u6240\u9700\u7684LLM\u8c03\u7528\u6b21\u6570\u51cf\u5c11\u4e8695.82%\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u5e76\u964d\u4f4e\u4e86\u6210\u672c\u3002", "conclusion": "\u5bf9\u4e8e\u57fa\u4e8e\u6a21\u677f\u7684\u7f51\u9875\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\uff0c\u95f4\u63a5\u62bd\u53d6\u65b9\u6cd5\u80fd\u591f\u5728\u51e0\u4e4e\u4e0d\u727a\u7272\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u5e26\u6765\u66f4\u9ad8\u7684\u53ef\u6269\u5c55\u6027\u548c\u6210\u672c\u6548\u76ca\u3002\u9002\u5408\u5927\u89c4\u6a21\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2506.21586", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.21586", "abs": "https://arxiv.org/abs/2506.21586", "authors": ["Hyundong Cho", "Spencer Lin", "Tejas Srinivasan", "Michael Saxon", "Deuksin Kwon", "Natali T. Chavez", "Jonathan May"], "title": "Can Vision Language Models Understand Mimed Actions?", "comment": "ACL 2025 Findings", "summary": "Nonverbal communication (NVC) plays an integral role in human language, but\nstudying NVC in general is challenging because of its broad scope and high\nvariance in interpretation among individuals and cultures. However, mime -- the\ntheatrical technique of suggesting intent using only gesture, expression, and\nmovement -- is a subset of NVC that consists of explicit and embodied actions\nwith much lower human interpretation variance. We argue that a solid\nunderstanding of mimed actions is a crucial prerequisite for vision-language\nmodels capable of interpreting and commanding more subtle aspects of NVC.\nHence, we propose Mime Identification Multimodal Evaluation (MIME), a novel\nvideo-based question answering benchmark comprising of 86 mimed actions.\nConstructed with motion capture data, MIME consists of variations of each\naction with perturbations applied to the character, background, and viewpoint\nfor evaluating recognition robustness. We find that both open-weight and\nAPI-based vision-language models perform significantly worse than humans on\nMIME, motivating the need for increased research for instilling more robust\nunderstanding of human gestures.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u63d0\u51faMIME\u57fa\u51c6\uff0c\u53d1\u73b0\u73b0\u6709\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u54d1\u5267\u52a8\u4f5c\u8bc6\u522b\u4e0a\u663e\u8457\u843d\u540e\u4e8e\u4eba\u7c7b\uff0c\u547c\u5401\u5bf9\u975e\u8bed\u8a00\u4ea4\u6d41\u7406\u89e3\u80fd\u529b\u8fdb\u884c\u66f4\u6df1\u5165\u7814\u7a76\u3002", "motivation": "\u975e\u8bed\u8a00\u4ea4\u6d41\uff08NVC\uff09\u5728\u4eba\u7c7b\u8bed\u8a00\u4e2d\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u5176\u8303\u56f4\u5e7f\u6cdb\u548c\u4e2a\u4f53\u53ca\u6587\u5316\u95f4\u7406\u89e3\u5dee\u5f02\u5927\uff0c\u56e0\u6b64\u7814\u7a76\u8d77\u6765\u5177\u6709\u6311\u6218\u6027\u3002\u4e3a\u514b\u670d\u8fd9\u4e9b\u6311\u6218\uff0c\u4f5c\u8005\u9009\u62e9\u4ee5\u2018\u54d1\u5267\u2019\u8fd9\u79cd\u4f4e\u89e3\u91ca\u65b9\u5dee\u7684NVC\u5b50\u96c6\u4e3a\u5207\u5165\u70b9\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86Mime Identification Multimodal Evaluation (MIME)\u57fa\u51c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c6\u9891\u7684\u95ee\u9898\u56de\u7b54\u6d4b\u8bd5\u96c6\uff0c\u753186\u4e2a\u54d1\u5267\u52a8\u4f5c\u7ec4\u6210\u3002\u6240\u6709\u52a8\u4f5c\u57fa\u4e8e\u52a8\u4f5c\u6355\u6349\u6570\u636e\uff0c\u5e76\u9488\u5bf9\u89d2\u8272\u3001\u80cc\u666f\u3001\u89c6\u89d2\u8fdb\u884c\u591a\u6837\u5316\u6270\u52a8\uff0c\u8bc4\u4f30\u6a21\u578b\u7684\u52a8\u4f5c\u8bc6\u522b\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u65e0\u8bba\u662f\u5f00\u6e90\u6743\u91cd\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u8fd8\u662fAPI\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5728MIME\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u90fd\u660e\u663e\u4f4e\u4e8e\u4eba\u7c7b\u3002", "conclusion": "\u73b0\u6709\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u50cf\u4eba\u7c7b\u4e00\u6837\u7406\u89e3\u54d1\u5267\u52a8\u4f5c\uff0c\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u5bf9\u4eba\u7c7b\u624b\u52bf\u548c\u975e\u8bed\u8a00\u4ea4\u6d41\u7684\u7406\u89e3\u4f9d\u7136\u6709\u9650\u3002MIME\u57fa\u51c6\u80fd\u63a8\u52a8\u5bf9\u4eba\u7c7b\u52a8\u4f5c\u548c\u624b\u52bf\u66f4\u9c81\u68d2\u7406\u89e3\u7684\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2506.21587", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.21587", "abs": "https://arxiv.org/abs/2506.21587", "authors": ["Weihong Qi", "Fan Huang", "Jisun An", "Haewoon Kwak"], "title": "Is DeepSeek a New Voice Among LLMs in Public Opinion Simulation?", "comment": null, "summary": "This study evaluates the ability of DeepSeek, an open-source large language\nmodel (LLM), to simulate public opinions in comparison to LLMs developed by\nmajor tech companies. By comparing DeepSeek-R1 and DeepSeek-V3 with Qwen2.5,\nGPT-4o, and Llama-3.3 and utilizing survey data from the American National\nElection Studies (ANES) and the Zuobiao dataset of China, we assess these\nmodels' capacity to predict public opinions on social issues in both China and\nthe United States, highlighting their comparative capabilities between\ncountries. Our findings indicate that DeepSeek-V3 performs best in simulating\nU.S. opinions on the abortion issue compared to other topics such as climate\nchange, gun control, immigration, and services for same-sex couples, primarily\nbecause it more accurately simulates responses when provided with Democratic or\nliberal personas. For Chinese samples, DeepSeek-V3 performs best in simulating\nopinions on foreign aid and individualism but shows limitations in modeling\nviews on capitalism, particularly failing to capture the stances of low-income\nand non-college-educated individuals. It does not exhibit significant\ndifferences from other models in simulating opinions on traditionalism and the\nfree market. Further analysis reveals that all LLMs exhibit the tendency to\novergeneralize a single perspective within demographic groups, often defaulting\nto consistent responses within groups. These findings highlight the need to\nmitigate cultural and demographic biases in LLM-driven public opinion modeling,\ncalling for approaches such as more inclusive training methodologies.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86DeepSeek\u7b49\u5f00\u6e90\u5927\u6a21\u578b\u4e0e\u4e3b\u6d41\u5927\u6a21\u578b\u5728\u4e2d\u7f8e\u793e\u4f1a\u8206\u8bba\u6a21\u62df\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5404\u6a21\u578b\u5c24\u5176\u5bb9\u6613\u5bf9\u7fa4\u4f53\u5185\u90e8\u89c2\u70b9\u7b80\u5316\u548c\u6cdb\u5316\u3002DeepSeek-V3\u5728\u90e8\u5206\u8bae\u9898\u4e0a\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5728\u90e8\u5206\u7fa4\u4f53\u548c\u8bdd\u9898\u4e0a\u4ecd\u6709\u5c40\u9650\uff0c\u8bba\u6587\u547c\u5401\u6539\u8fdb\u8bad\u7ec3\u4ee5\u51cf\u5c11\u6587\u5316\u548c\u4eba\u53e3\u7edf\u8ba1\u504f\u89c1\u3002", "motivation": "\u8bc4\u4f30\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982DeepSeek\uff09\u5728\u6a21\u62df\u516c\u5171\u8206\u8bba\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u4e0e\u4e3b\u6d41\u5927\u5382\u5f00\u53d1\u7684LLM\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u4e86\u89e3\u5176\u5728\u4e2d\u7f8e\u4e24\u56fd\u793e\u4f1a\u95ee\u9898\u8206\u8bba\u9884\u6d4b\u4e0a\u7684\u8868\u73b0\u548c\u504f\u5dee\u3002", "method": "\u5c06DeepSeek-R1\u548cDeepSeek-V3\u4e0eQwen2.5\u3001GPT-4o\u548cLlama-3.3\u7b49\u5927\u5382LLM\u8fdb\u884c\u5bf9\u6bd4\uff0c\u91c7\u7528\u7f8e\u56fd\u56fd\u5bb6\u9009\u4e3e\u7814\u7a76\uff08ANES\uff09\u548c\u4e2d\u56fd\u7684\u5750\u6807\u6570\u636e\u5e93\uff08Zuobiao\uff09\u4f5c\u4e3a\u8c03\u67e5\u6570\u636e\uff0c\u8bc4\u4f30\u5404\u6a21\u578b\u9884\u6d4b\u4e2d\u7f8e\u793e\u4f1a\u8bae\u9898\u516c\u5171\u8206\u8bba\u7684\u80fd\u529b\u3002\u5177\u4f53\u5206\u6790\u5404\u6a21\u578b\u5bf9\u4e0d\u540c\u8bae\u9898\uff08\u5815\u80ce\u3001\u6c14\u5019\u53d8\u5316\u3001\u67aa\u652f\u7ba1\u63a7\u7b49\uff09\u7684\u9884\u6d4b\u6548\u679c\u5e76\u8fdb\u884c\u8de8\u56fd\u6bd4\u8f83\u3002", "result": "DeepSeek-V3\u5728\u6a21\u62df\u7f8e\u56fd\u5815\u80ce\u8bae\u9898\u7684\u516c\u4f17\u89c2\u70b9\u65f6\u8868\u73b0\u6700\u4f73\uff0c\u5c24\u5176\u662f\u5728\u8bbe\u5b9a\u4e3a\u6c11\u4e3b\u515a\u6216\u81ea\u7531\u6d3e\u8eab\u4efd\u65f6\u9884\u6d4b\u66f4\u4e3a\u51c6\u786e\uff1b\u5bf9\u4e2d\u56fd\u6837\u672c\uff0c\u5728\u6d89\u5916\u63f4\u52a9\u548c\u4e2a\u4eba\u4e3b\u4e49\u8bae\u9898\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u5728\u63cf\u8ff0\u4f4e\u6536\u5165\u548c\u975e\u5927\u5b66\u4eba\u7fa4\u7684\u8d44\u672c\u4e3b\u4e49\u89c2\u70b9\u65f6\u8868\u73b0\u6b20\u4f73\u3002\u5bf9\u4f20\u7edf\u4e3b\u4e49\u548c\u81ea\u7531\u5e02\u573a\u8bae\u9898\uff0c\u5404\u6a21\u578b\u65e0\u663e\u8457\u5dee\u5f02\u3002\u6240\u6709\u6a21\u578b\u5747\u5b58\u5728\u5728\u7fa4\u4f53\u5185\u90e8\u8fc7\u5ea6\u6cdb\u5316\u5355\u4e00\u89c2\u70b9\u3001\u56de\u7b54\u8d8b\u540c\u7684\u95ee\u9898\uff0c\u5c24\u5176\u5728\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u7fa4\u4f53\u5185\u3002", "conclusion": "\u5f53\u524d\u5f00\u6e90\u4e0e\u5927\u5382\u7684LLM\u5728\u6a21\u62df\u4e2d\u7f8e\u516c\u5171\u8206\u8bba\u65f6\u5747\u5b58\u5728\u6587\u5316\u53ca\u4eba\u53e3\u7edf\u8ba1\u504f\u89c1\uff0c\u6613\u5bf9\u7fa4\u4f53\u5185\u90e8\u89c2\u70b9\u8fdb\u884c\u8fc7\u5ea6\u6cdb\u5316\uff0c\u9700\u901a\u8fc7\u66f4\u5305\u5bb9\u6027\u7684\u8bad\u7ec3\u65b9\u6cd5\u7f13\u89e3\u76f8\u5173\u504f\u5dee\u3002"}}
