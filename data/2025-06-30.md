<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]
- [cs.CL](#cs.CL) [Total: 38]
- [cs.CE](#cs.CE) [Total: 4]
- [cs.CY](#cs.CY) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents](https://arxiv.org/abs/2506.21669)
*Wanxin Tian,Shijie Zhang,Kevin Zhang,Xiaowei Chi,Yulin Luo,Junyu Lu,Chunkai Fan,Qiang Zhou,Yiming Zhao,Ning Liu Siyu Lin,Zhiyuan Qin,Xiaozhu Ju,Shanghang Zhang,Jian Tang*

Main category: cs.AI

TL;DR: 本文提出SEEA-R1框架，通过改进奖励信号和奖励模型，实现了具身智能体自进化，超过了现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在推理和强化微调方面取得了显著进展，但对于在真实、多模态、长期任务环境下实现自主进化的具身智能体，仍然存在困难。主要挑战在于多步推理中中间奖励信号稀疏，且手工设计奖励函数难以泛化到新任务。

Method: 提出SEEA-R1（Self-Evolving Embodied Agents-R1）框架，其中包括：1）Tree-GRPO方法，将蒙特卡洛树搜索引入GRPO以生成更密集的中间奖励信号；2）多模态生成奖励模型（MGRM），提升奖励估计泛化能力，支持自主适应和奖励驱动的自进化。

Result: 在ALFWorld基准上，SEEA-R1在文本任务上达85.07%、多模态任务上达36.19%，均超越GPT-4o等最先进模型。即使在无环境奖励下，仍有80.3%表现，优于所有开源基线。此外，还有更多实验和定性分析论证其可扩展性和潜力。

Conclusion: SEEA-R1框架有效推动了具身智能体的自主进化能力，实现了更强的泛化能力和推理表现，对未来大规模具身智能体研究具有重要意义。

Abstract: Self-evolution, the ability of agents to autonomously improve their reasoning
and behavior, is essential for the embodied domain with long-horizon,
real-world tasks. Despite current advancements in reinforcement fine-tuning
(RFT) showing strong performance in enhancing reasoning in LLMs, its potential
to enable self-evolving embodied intelligence with multi-modal interactions
remains largely unexplored. Specifically, reinforcement fine-tuning faces two
fundamental obstacles in embodied settings: (i) the lack of accessible
intermediate rewards in multi-step reasoning tasks limits effective learning
signals, and (ii) reliance on hand-crafted reward functions restricts
generalization to novel tasks and environments. To address these challenges, we
present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework
designed for enabling the self-evolving capabilities of embodied agents.
Specifically, to convert sparse delayed rewards into denser intermediate
signals that improve multi-step reasoning, we propose Tree-based group relative
policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into
GRPO. To generalize reward estimation across tasks and scenes, supporting
autonomous adaptation and reward-driven self-evolution, we further introduce
Multi-modal Generative Reward Model (MGRM). To holistically evaluate the
effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing
state-of-the-art methods with scores of 85.07% (textual) and 36.19%
(multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also
achieves scores of 80.3% without environmental reward, surpassing all
open-source baselines and highlighting its scalability as a self-evolving
embodied agent. Additional experiments and qualitative analysis further support
the potential of SEEA-R1 for future research in scalable embodied intelligence.

</details>


### [2] [Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)
*Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori*

Main category: cs.AI

TL;DR: 作者提出了一种仿脑分层递归推理架构HRM，能以极少样本、无需预训练高效完成复杂推理任务，在主流AI推理基准上大幅超越更大现有模型，表明其具备实现通用推理的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在推理任务中主要依赖Chain-of-Thought（CoT）技术，但这种方法在任务分解、数据需求和延迟等方面存在明显不足。受到人脑分层处理机制的启发，作者希望提出一种更高效稳定的推理模型。

Method: 提出了一种新型的分层递归结构——Hierarchical Reasoning Model（HRM），包括高层抽象规划模块和低层细节计算模块，以递归交互方式协同完成推理任务。模型在单次前向传递中完成推理，无需显式监督中间过程。模型参数量为2700万，无需预训练和CoT数据，仅用1000个训练样本就能学习推理任务。

Result: HRM模型在复杂推理任务（如难度较高的数独和大型迷宫中最优路径查找）上表现出极高性能，几乎达到完美。并且在Abstraction and Reasoning Corpus (ARC)这一重要通用智能基准上，HRM显著优于体积更大且上下文窗口更长的当前最优模型。

Conclusion: HRM模型为通用计算和通用推理系统带来了变革性进步，展示了在高效、稳定、少样本的前提下完成复杂推理的巨大潜力。

Abstract: Reasoning, the process of devising and executing complex goal-oriented action
sequences, remains a critical challenge in AI. Current large language models
(LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from
brittle task decomposition, extensive data requirements, and high latency.
Inspired by the hierarchical and multi-timescale processing in the human brain,
we propose the Hierarchical Reasoning Model (HRM), a novel recurrent
architecture that attains significant computational depth while maintaining
both training stability and efficiency. HRM executes sequential reasoning tasks
in a single forward pass without explicit supervision of the intermediate
process, through two interdependent recurrent modules: a high-level module
responsible for slow, abstract planning, and a low-level module handling rapid,
detailed computations. With only 27 million parameters, HRM achieves
exceptional performance on complex reasoning tasks using only 1000 training
samples. The model operates without pre-training or CoT data, yet achieves
nearly perfect performance on challenging tasks including complex Sudoku
puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms
much larger models with significantly longer context windows on the Abstraction
and Reasoning Corpus (ARC), a key benchmark for measuring artificial general
intelligence capabilities. These results underscore HRM's potential as a
transformative advancement toward universal computation and general-purpose
reasoning systems.

</details>


### [3] [THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?](https://arxiv.org/abs/2506.21763)
*Xin Wang,Jiyao Liu,Yulong Xiao,Junzhi Ning,Lihao Liu,Junjun He,Botian Shi,Kaicheng Yu*

Main category: cs.AI

TL;DR: 提出THE-Tree框架，通过结构化方法构建和验证科学演化路径，大幅提升了自动化科学事实验证和重要成果发现的准确性，在多个指标和应用场景上超越传统方法，并公开数据集促进后续研究。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在科学创意生成中作用日益增强，但其产生的大量建议往往难以被快速、准确地验证新颖性与事实性。手工验证效率低下，LLMs自行验证又常出现幻觉且缺乏领域知识，现有引用网络和叙述综述也难以结构化和因果化呈现科学演化历程，因此亟需高效、结构化验证科学进步的方法。

Method: 提出了THE-Tree（科技历史演化树）框架，从科学文献构建结构化的领域演化树。通过搜索算法探索演化路径，每步用“思考-阐述-引用-验证”流程：LLM提出可能进展并引用文献，然后借助自然语言推理机制检验逻辑一致性和文献证据，从而确保每一演化链接有据可依。并在多个领域构建和验证了88棵THE-Tree和配套基准数据集。

Result: THE-Tree显著提升了对科学演化的因果和结构化表达。在图补全任务中，THE-Tree比传统引用网络在多模型下hit@1提升8%-14%；在预测科学进展上，提升近10%；与其他方法结合后，可以使重要论文评价性能提高接近一倍。

Conclusion: THE-Tree为科学演进和文献关系提供了可验证、结构化和因果关联的新视角，突破了现有LLM和引用网络的局限性，为自动化、可扩展的科学洞见验证和预测提供了有效工具，并向社区提供数据和基准以推动该方向进一步研究。

Abstract: Large Language Models (LLMs) are accelerating scientific idea generation, but
rigorously evaluating these numerous, often superficial, AI-generated
propositions for novelty and factual accuracy is a critical bottleneck; manual
verification is too slow.Existing validation methods are inadequate: LLMs as
standalone verifiers may hallucinate and lack domain knowledge (our findings
show ~60\% unawareness of relevant papers in specific domains), while
traditional citation networks lack explicit causality and narrative surveys are
unstructured.This underscores a core challenge: the absence of structured,
verifiable, and causally-linked historical data of scientific evolution.To
address this,we introduce \textbf{THE-Tree} (\textbf{T}echnology
\textbf{H}istory \textbf{E}volution Tree), a computational framework that
constructs such domain-specific evolution trees from scientific
literature.THE-Tree employs a search algorithm to explore evolutionary paths.
During its node expansion, it utilizes a novel "Think-Verbalize-Cite-Verify"
process: an LLM proposes potential advancements and cites supporting
literature. Critically, each proposed evolutionary link is then validated for
logical coherence and evidential support by a recovered natural language
inference mechanism that interrogates the cited literature, ensuring that each
step is grounded.We construct and validate 88 THE-Trees across diverse domains
and release a benchmark dataset including up to 71k fact verifications covering
27k papers to foster further research.Experiments demonstrate that i) in graph
completion, our THE-Tree improves hit@1 by 8\% to 14\% across multiple models
compared to traditional citation networks; ii) for predicting future scientific
developments, it improves hit@1 metric by nearly 10\%; and iii) when combined
with other methods, it boosts the performance of evaluating important
scientific papers by almost 100\%.

</details>


### [4] [MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models](https://arxiv.org/abs/2506.21784)
*Yifan Liu,Xishun Liao,Haoxuan Ma,Jonathan Liu,Rohan Jadhav,Jiaqi Ma*

Main category: cs.AI

TL;DR: MobiVerse框架结合生成器与LLM，高效、真实地模拟城市大规模出行，为交通研究和政策制定提供了强大平台。


<details>
  <summary>Details</summary>
Motivation: 当前人类出行模式的建模对于交通规划及城市发展至关重要，但现有的模拟平台存在不足。传统的基于行为的模型数据需求大且标定繁琐，机器学习方法难以适应动态环境，大规模LLM代理实现计算开销过大。因此需要一个兼顾效率、环境适应性和可扩展性的新型仿真框架。

Method: 提出了MobiVerse，一个混合式框架：通过轻量级领域特定生成器生成基础活动链，再结合大型语言模型（LLMs）实现情境感知的适应性调整。案例研究选取洛杉矶Westwood地区，对约53,000个代理进行了全体日程生成和动态调整，运行于普通PC上。

Result: MobiVerse能够使智能体根据环境反馈（如道路封闭、大型活动、拥堵等）动态调整出行计划，在保证计算高效的同时，提高行为仿真真实性。其模块化设计支持多种出行算法的评测。

Conclusion: MobiVerse有效弥补了现有出行模拟平台中效率与适应性之间的空白，成为可定制性的仿真平台，为出行系统规划和运维提供了新工具。

Abstract: Understanding and modeling human mobility patterns is crucial for effective
transportation planning and urban development. Despite significant advances in
mobility research, there remains a critical gap in simulation platforms that
allow for algorithm development, policy implementation, and comprehensive
evaluation at scale. Traditional activity-based models require extensive data
collection and manual calibration, machine learning approaches struggle with
adaptation to dynamic conditions, and treding agent-based Large Language Models
(LLMs) implementations face computational constraints with large-scale
simulations. To address these challenges, we propose MobiVerse, a hybrid
framework leverages the efficiency of lightweight domain-specific generator for
generating base activity chains with the adaptability of LLMs for context-aware
modifications. A case study was conducted in Westwood, Los Angeles, where we
efficiently generated and dynamically adjusted schedules for the whole
population of approximately 53,000 agents on a standard PC. Our experiments
demonstrate that MobiVerse successfully enables agents to respond to
environmental feedback, including road closures, large gathering events like
football games, and congestion, through our hybrid framework. Its modular
design facilitates testing various mobility algorithms at both transportation
system and agent levels. Results show our approach maintains computational
efficiency while enhancing behavioral realism. MobiVerse bridges the gap in
mobility simulation by providing a customizable platform for mobility systems
planning and operations with benchmark algorithms. Code and videos are
available at https://github.com/ucla-mobility/MobiVerse.

</details>


### [5] [CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation](https://arxiv.org/abs/2506.21805)
*Nicolas Bougie,Narimasa Watanabe*

Main category: cs.AI

TL;DR: 作者提出了基于大语言模型的城市模拟器CitySim，为虚拟智能体赋予类人行为和计划能力。系统能更真实地模拟大量市民在城市中的日常与群体行为，为理解和预测城市现象提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 现有的都市人类行为建模依赖于僵化的手工规则，限制了对复杂意图、计划与适应性行为的模拟能力。作者希望通过突破性的AI方法提升模拟的真实性与灵活性。

Method: 提出了名为CitySim的城市模拟器，基于大语言模型赋予智能体类人水平的推理能力。智能体通过递归、价值驱动的方法生成日常计划，权衡强制活动、个人习惯与情境因素，并具有信念、长期目标和空间记忆以实现持续、真实的仿真。

Result: CitySim在个体和群体两个层面都比先前方法与真实行为更贴合。实验中，模拟了数万智能体，评估了他们在多个现实场景下的集体行为（如人流密度、地点热度和幸福感等），展现了模型对城市现象预测的能力。

Conclusion: CitySim是一个可扩展、灵活的平台，用于研究和预测城市现象，推动城市社会科学和行为研究发展。

Abstract: Modeling human behavior in urban environments is fundamental for social
science, behavioral studies, and urban planning. Prior work often rely on
rigid, hand-crafted rules, limiting their ability to simulate nuanced
intentions, plans, and adaptive behaviors. Addressing these challenges, we
envision an urban simulator (CitySim), capitalizing on breakthroughs in
human-level intelligence exhibited by large language models. In CitySim, agents
generate realistic daily schedules using a recursive value-driven approach that
balances mandatory activities, personal habits, and situational factors. To
enable long-term, lifelike simulations, we endow agents with beliefs, long-term
goals, and spatial memory for navigation. CitySim exhibits closer alignment
with real humans than prior work, both at micro and macro levels. Additionally,
we conduct insightful experiments by modeling tens of thousands of agents and
evaluating their collective behaviors under various real-world scenarios,
including estimating crowd density, predicting place popularity, and assessing
well-being. Our results highlight CitySim as a scalable, flexible testbed for
understanding and forecasting urban phenomena.

</details>


### [6] [Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds](https://arxiv.org/abs/2506.21887)
*Edward Chen,Sang T. Truong,Natalie Dullerud,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.AI

TL;DR: 本文提出Active-MoSH，一个结合主观偏好学习和多目标敏感性分析的交互式多目标优化框架，有效提升高风险决策（如医疗规划）中Pareto解集筛选的效率和用户信任，支持复杂偏好表达，实际和用户实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 高风险决策场景（如近距离放射治疗）中往往涉及多目标权衡，且单次评估代价高昂。现有方法很难帮助决策者根据复杂偏好在庞大的Pareto前沿中有效筛选理想解，并缺乏系统化、可互动的偏好迭代机制。决策者需要信任最终选择，确信没有遗漏更优的方案，这在高风险应用中尤为重要。

Method: 提出Active-MoSH框架，包括局部和全局两个组成部分。局部部分结合软硬约束和概率化偏好学习，通过主动采样策略在减小认知负担的同时自适应精细化Pareto子集。全局部分T-MoSH利用多目标敏感性分析，发现反馈之外被遗漏的高价值点。

Result: Active-MoSH框架在多种合成和真实应用上表现优越，并通过AI生成图片选择的用户研究，验证该方法能提高收敛效率、增强决策者信任和对偏好的表达能力。

Conclusion: Active-MoSH为高风险多目标决策提供了可交互、信任度高且能系统表达复杂偏好的新方法，有效提升了决策效果和用户体验。

Abstract: High-stakes decision-making involves navigating multiple competing objectives
with expensive evaluations. For instance, in brachytherapy, clinicians must
balance maximizing tumor coverage (e.g., an aspirational target or soft bound
of >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard
bound of <601 cGy to the bladder), with each plan evaluation being
resource-intensive. Selecting Pareto-optimal solutions that match implicit
preferences is challenging, as exhaustive Pareto frontier exploration is
computationally and cognitively prohibitive, necessitating interactive
frameworks to guide users. While decision-makers (DMs) often possess domain
knowledge to narrow the search via such soft-hard bounds, current methods often
lack systematic approaches to iteratively refine these multi-faceted preference
structures. Critically, DMs must trust their final decision, confident they
haven't missed superior alternatives; this trust is paramount in
high-consequence scenarios. We present Active-MoSH, an interactive local-global
framework designed for this process. Its local component integrates soft-hard
bounds with probabilistic preference learning, maintaining distributions over
DM preferences and bounds for adaptive Pareto subset refinement. This is guided
by an active sampling strategy optimizing exploration-exploitation while
minimizing cognitive burden. To build DM trust, Active-MoSH's global component,
T-MoSH, leverages multi-objective sensitivity analysis to identify potentially
overlooked, high-value points beyond immediate feedback. We demonstrate
Active-MoSH's performance benefits through diverse synthetic and real-world
applications. A user study on AI-generated image selection further validates
our hypotheses regarding the framework's ability to improve convergence,
enhance DM trust, and provide expressive preference articulation, enabling more
effective DMs.

</details>


### [7] [AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms](https://arxiv.org/abs/2506.21996)
*Raphaël Boige,Amine Boumaza,Bruno Scherrer*

Main category: cs.AI

TL;DR: 本文提出新的结构化博弈树概率模型，揭示经典算法在现实复杂性下的效率差别，推导出严密的复杂度公式，并指出AlphaBeta在实际中较其他算法速度显著较慢。


<details>
  <summary>Details</summary>
Motivation: 传统的确定性博弈求解算法分析通常基于叶节点数值独立分布的简化模型，但这种模型忽略了真实博弈树的结构复杂性，科研界对此批评已久。为解决这一不足，需要更实际但依然可分析的模型来研究这些算法。

Method: 文中提出一种新的概率模型，用层次条件分布逐步生成博弈树，并引入祖先依赖性以反映现实博弈结构。基于此模型，作者推导了AlphaBeta和Scout等算法的平均复杂度递推公式，实现对深层博弈树的严谨复杂性分析。

Result: 结果显示，尽管所有算法在极限下收敛到相同的分支因子，但对有限深度的实际博弈树，AlphaBeta相比Scout等算法有显著更大的乘性常数项，导致实际计算速度明显较慢。

Conclusion: 新模型揭示了经典博弈求解算法在更真实且具有挑战性的设定下的本质区别，为理解和改进这些方法提供了理论工具。

Abstract: Deterministic game-solving algorithms are conventionally analyzed in the
light of their average-case complexity against a distribution of random
game-trees, where leaf values are independently sampled from a fixed
distribution. This simplified model enables uncluttered mathematical analysis,
revealing two key properties: root value distributions asymptotically collapse
to a single fixed value for finite-valued trees, and all reasonable algorithms
achieve global optimality. However, these findings are artifacts of the model's
design-its long criticized independence assumption strips games of structural
complexity, producing trivial instances where no algorithm faces meaningful
challenges. To address this limitation, we introduce a new probabilistic model
that incrementally constructs game-trees using a fixed level-wise conditional
distribution. By enforcing ancestor dependency, a critical structural feature
of real-world games, our framework generates problems with adjustable
difficulty while retaining some form of analytical tractability. For several
algorithms, including AlphaBeta and Scout, we derive recursive formulas
characterizing their average-case complexities under this model. These allow us
to rigorously compare algorithms on deep game-trees, where Monte-Carlo
simulations are no longer feasible. While asymptotically, all algorithms seem
to converge to identical branching factor (a result analogous to those of
independence-based models), deep finite trees reveal stark differences:
AlphaBeta incurs a significantly larger constant multiplicative factor compared
to algorithms like Scout, leading to a substantial practical slowdown. Our
framework sheds new light on classical game-solving algorithms, offering
rigorous evidence and analytical tools to advance the understanding of these
methods under a more realistic, challenging, and yet tractable model.

</details>


### [8] [LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving](https://arxiv.org/abs/2506.22005)
*Naoto Onda,Kazumi Kasaura,Yuta Oriike,Masaya Taniguchi,Akiyoshi Sannai,Sho Sonoda*

Main category: cs.AI

TL;DR: 作者提出一种基于LLM的自动数学猜想生成流水线LeanConjecturer，用于解决定理证明训练数据稀缺问题。该系统能大规模产出有效且有挑战性的数学猜想，并提升了自动证明系统的性能，在拓扑学等领域实现了新的定理发现。


<details>
  <summary>Details</summary>
Motivation: 当前形式化定理证明领域面临训练数据稀缺的问题，影响了大模型在数学猜想生成和证明能力方面的发展。学术界亟需一种高效、可扩展的数据生成方法以支持自动化证明系统的训练和数学发现。

Method: 提出了LeanConjecturer流水线，结合规则驱动的上下文提取与大模型（LLM）驱动的定理陈述生成，采用迭代生成与评估流程。通过从Mathlib种子文件自动生成大学水平数学猜想，并用GRPO等方法将所产生的猜想用于强化学习训练。

Result: LeanConjecturer从40个Mathlib种子文件共生成12,289条猜想，其中3,776条为语法有效且非平凡（无法用通用自动证明战术直接证明）的定理。平均每个种子文件生成103.25条新颖猜想。部分复杂领域如拓扑学中的半开集、alpha-开集、pre-开集等理论也得到了自动化的新非平凡定理验证。

Conclusion: LeanConjecturer成功生成大量高质量数学猜想，为自动定理证明系统的数据生成和能力提升提供了可扩展方案，并在数学理论新发现上表现出良好的潜力。

Abstract: We introduce LeanConjecturer, a pipeline for automatically generating
university-level mathematical conjectures in Lean 4 using Large Language Models
(LLMs). Our hybrid approach combines rule-based context extraction with
LLM-based theorem statement generation, addressing the data scarcity challenge
in formal theorem proving. Through iterative generation and evaluation,
LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with
3,776 identified as syntactically valid and non-trivial, that is, cannot be
proven by \texttt{aesop} tactic. We demonstrate the utility of these generated
conjectures for reinforcement learning through Group Relative Policy
Optimization (GRPO), showing that targeted training on domain-specific
conjectures can enhance theorem proving capabilities. Our approach generates
103.25 novel conjectures per seed file on average, providing a scalable
solution for creating training data for theorem proving systems. Our system
successfully verified several non-trivial theorems in topology, including
properties of semi-open, alpha-open, and pre-open sets, demonstrating its
potential for mathematical discovery beyond simple variations of existing
results.

</details>


### [9] [Universal Retrieval for Multimodal Trajectory Modeling](https://arxiv.org/abs/2506.22056)
*Xuan Zhang,Ziyan Jiang,Rui Meng,Yifei Leng,Zhenbang Xiao,Zora Zhiruo Wang,Yanyi Shang,Dehan Kong*

Main category: cs.AI

TL;DR: 本文针对多模态轨迹数据建模难题，提出了新的检索框架GAE-Retriever，并构建了相关数据集和基准。实验结果表明，该方法在多模态轨迹检索任务上具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 随着轨迹数据的激增，如何对轨迹级数据进行有效建模成为一个亟需解决但尚未系统探讨的挑战。轨迹数据涵盖了人类行为和环境状态，对提升AI在GUI环境下的能力具有巨大潜力。

Method: 提出了多模态轨迹检索任务（Multimodal Trajectory Retrieval），并构建了统一智能体轨迹数据集（UATD）以及GAE-Bench基准测试集。此外，提出了一种基于视觉-语言模型并结合对比学习优化机制（token选择与GradCache）的多模态检索框架GAE-Retriever。

Result: 在多个数据集上的实验证明，GAE-Retriever在检索召回率上持续超越现有的强基线方法，显示出其优越的检索性能。

Conclusion: GAE-Retriever为多模态轨迹数据检索提供了新思路，有效提升了AI在涉及多形式人类演示及环境状态任务中的检索能力。

Abstract: Trajectory data, capturing human actions and environmental states across
various modalities, holds significant potential for enhancing AI agent
capabilities, particularly in GUI environments. However, how to model the
representation of trajectory-level data presents a significant challenge that
has not been systematically addressed amid explosive trajectory data growth. In
this work, we introduce Multimodal Trajectory Retrieval, bridging the gap
between universal retrieval and agent-centric trajectory modeling. We construct
the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and
states across diverse real-world scenarios. Based on this, we present
GAE-Bench, a benchmark containing a large number of trajectory-based retrieval
pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework
that adopts vision-language models and incorporates optimized contrastive
learning through a token selection and the GradCache mechanism. Comprehensive
evaluations across multiple datasets show that GAE-Retriever consistently
outperforms strong baselines in retrieval recall, highlighting its
effectiveness in advancing multimodal trajectory retrieval.

</details>


### [10] [Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios](https://arxiv.org/abs/2506.22068)
*Shengyue Yao,Runqing Guo,Yangyang Qin,Miangbing Meng,Jipeng Cao,Yilun Lin,Yisheng Lv,Fei-Yue Wang*

Main category: cs.AI

TL;DR: 本文提出QaT和基于ASP的ESN框架，实现智能交通异构数据的统一语义融合，用逻辑查询代替传统测试用例，增强测试灵活性、可解释性和隐私保护，推动验证驱动开发（VDD）。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在交通领域的深入应用，智能座舱、自动驾驶和智能路网的数据呈现碎片化和不兼容，现有测试方法无法灵活、高效地涵盖所有边界场景，亟需一种统一且灵活的数据表示方法和测试范式。

Method: 提出了“Query as Test”（QaT）概念，即从传统的刚性测试用例转变为基于统一数据表示的按需逻辑查询。为此，设计了基于ASP的可扩展场景标记（ESN）数据框架，将多模态异构数据统一表示为逻辑事实与规则，通过逻辑推理支持复杂语义查询和自然可解释性。

Result: ESN实现了深度语义融合，支持复杂灵活的语义查询、决策过程的可解释性以及基于逻辑规则的细粒度隐私保护。QaT范式将自动驾驶功能验证和安全合规检查转化为对ESN数据库的逻辑查询，显著提升了测试的表达能力和形式严谨性。此外，提出了“Validation-Driven Development”（VDD）理念，用逻辑验证指导开发以加速迭代。

Conclusion: 通过引入ESN和QaT方法，为自动驾驶等智能交通系统的数据融合、测试和隐私保护提供了统一、高效、可解释的新范式，并用VDD推动系统开发与演进。

Abstract: With the deep penetration of Artificial Intelligence (AI) in the
transportation sector, intelligent cockpits, autonomous driving, and
intelligent road networks are developing at an unprecedented pace. However, the
data ecosystems of these three key areas are increasingly fragmented and
incompatible. Especially, existing testing methods rely on data stacking, fail
to cover all edge cases, and lack flexibility. To address this issue, this
paper introduces the concept of "Query as Test" (QaT). This concept shifts the
focus from rigid, prescripted test cases to flexible, on-demand logical queries
against a unified data representation. Specifically, we identify the need for a
fundamental improvement in data storage and representation, leading to our
proposal of "Extensible Scenarios Notations" (ESN). ESN is a novel declarative
data framework based on Answer Set Programming (ASP), which uniformly
represents heterogeneous multimodal data from the cockpit, vehicle, and road as
a collection of logical facts and rules. This approach not only achieves deep
semantic fusion of data, but also brings three core advantages: (1) supports
complex and flexible semantic querying through logical reasoning; (2) provides
natural interpretability for decision-making processes; (3) allows for
on-demand data abstraction through logical rules, enabling fine-grained privacy
protection. We further elaborate on the QaT paradigm, transforming the
functional validation and safety compliance checks of autonomous driving
systems into logical queries against the ESN database, significantly enhancing
the expressiveness and formal rigor of the testing. Finally, we introduce the
concept of "Validation-Driven Development" (VDD), which suggests to guide
developments by logical validation rather than quantitative testing in the era
of Large Language Models, in order to accelerating the iteration and
development process.

</details>


### [11] [A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety](https://arxiv.org/abs/2506.22183)
*Camille François,Ludovic Péran,Ayah Bdeir,Nouha Dziri,Will Hawkins,Yacine Jernite,Sayash Kapoor,Juliet Shen,Heidy Khlaaf,Kevin Klyman,Nik Marda,Marie Pellat,Deb Raji,Divya Siddarth,Aviya Skowron,Joseph Spisak,Madhulika Srikumar,Victor Storchan,Audrey Tang,Jen Weedon*

Main category: cs.AI

TL;DR: 本文结合高规格会议与跨界交流，梳理了开放权重和开源基础模型背景下AI安全的现状与挑战，强调开放可增进AI安全，却需弥补评测标准、防御机制和多元社区参与等短板。最后提出五大研究重点，助力建立开放和负责任的AI安全新学科。


<details>
  <summary>Details</summary>
Motivation: 开源和开放权重基础模型的快速发展带来了人工智能系统更高的安全要求，同时也为提升AI安全性提供了新机遇。不同领域的AI从业者急需对安全与开放如何协同、存在哪些挑战及未来发展路径进行梳理和建议。

Method: 该研究以哥伦比亚组织的AI开放性与安全会议及其为期六周的筹备项目为基础，采取参与式、解决方案导向的方法，由跨界工作组联合展开，产出多项调研与路线图。

Result: 研究组产出了开放源AI安全交叉领域的研究议程、现有和所需技术工具及其部署分析、安全过滤器生态系统的现状与未来路线。发现开放带来更多独立审查、分布式防御及多元监督，但仍存在多模态/多语言评测稀缺、应对提示注入及组合攻击的防御有限、受害社区参与机制不足等问题。最后提出五大优先研究方向，并对AI安全学科的开放化与多元化负责奠定基础。

Conclusion: 开放可以增强AI安全，但现有工具和机制有诸多不足。未来需要推进多方参与、内容过滤器升级、全生态安全基础设施建设、智能体防护措施完善及更全面的危害分类。研究成果已影响国际政策制定，并为开放、多元、可问责的AI安全体系搭建了基础。

Abstract: The rapid rise of open-weight and open-source foundation models is
intensifying the obligation and reshaping the opportunity to make AI systems
safe. This paper reports outcomes from the Columbia Convening on AI Openness
and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme
involving more than forty-five researchers, engineers, and policy leaders from
academia, industry, civil society, and government. Using a participatory,
solutions-oriented process, the working groups produced (i) a research agenda
at the intersection of safety and open source AI; (ii) a mapping of existing
and needed technical interventions and open source tools to safely and
responsibly deploy open foundation models across the AI development workflow;
and (iii) a mapping of the content safety filter ecosystem with a proposed
roadmap for future research and development. We find that openness --
understood as transparent weights, interoperable tooling, and public governance
-- can enhance safety by enabling independent scrutiny, decentralized
mitigation, and culturally plural oversight. However, significant gaps persist:
scarce multimodal and multilingual benchmarks, limited defenses against
prompt-injection and compositional attacks in agentic systems, and insufficient
participatory mechanisms for communities most affected by AI harms. The paper
concludes with a roadmap of five priority research directions, emphasizing
participatory inputs, future-proof content filters, ecosystem-wide safety
infrastructure, rigorous agentic safeguards, and expanded harm taxonomies.
These recommendations informed the February 2025 French AI Action Summit and
lay groundwork for an open, plural, and accountable AI safety discipline.

</details>


### [12] [Breaking Rank Bottlenecks in Knowledge Graph Completion](https://arxiv.org/abs/2506.22271)
*Samy Badreddine,Emile van Krieken,Luciano Serafini*

Main category: cs.AI

TL;DR: 作者指出KGC模型输出层存在秩瓶颈导致性能下降，提出KGE-MoS作为新输出层方案，实验验证其能以较低开销提升模型性能和概率拟合。


<details>
  <summary>Details</summary>
Motivation: 知识图谱补全（KGC）模型在实际应用中，实体数量通常远大于embedding维度，导致输出层存在秩瓶颈，影响模型表达能力和预测性能。作者希望探讨并解决这一问题。

Method: 理论分析和实证研究KGC模型秩瓶颈影响，提出受语言建模启发的混合输出层KGE-MoS，用以突破瓶颈，并在四个数据集上实验验证。

Result: KGE-MoS能有效提升KGC模型的排名准确度和分布拟合度，且参数开销较低。实验在四个数据集上均取得提升。

Conclusion: 传统KGC模型因输出层秩瓶颈受限，KGE-MoS能在保持低参数量的同时提升模型性能，是更优的输出层设计。

Abstract: Many Knowledge Graph Completion (KGC) models, despite using powerful
encoders, rely on a simple vector-matrix multiplication to score queries
against candidate object entities. When the number of entities is larger than
the model's embedding dimension, which in practical scenarios is often by
several orders of magnitude, we have a linear output layer with a rank
bottleneck. Such bottlenecked layers limit model expressivity. We investigate
both theoretically and empirically how rank bottlenecks affect KGC models. We
find that, by limiting the set of feasible predictions, rank bottlenecks hurt
ranking accuracy and the distribution fidelity of scores. Inspired by the
language modelling literature, we propose KGE-MoS, a mixture-based output layer
to break rank bottlenecks in many KGC models. Our experiments on four datasets
show that KGE-MoS improves performance and probabilistic fit of KGC models for
a low parameter cost.

</details>


### [13] [Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates](https://arxiv.org/abs/2506.22276)
*Reuth Mirsky*

Main category: cs.AI

TL;DR: 本文倡导将AI的智能抗命作为合作型AI研究的新焦点，认为AI团队成员应拥有适当自主性，从而更安全和有效地协作。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统虽然在诸多领域取得超常表现，但在协作场景中往往过于顺从人类指令，这种僵化服从可能会带来低效甚至不安全的后果。本文希望改进现状，激发AI在团队中的自主贡献。

Method: 提出AI代理自主性等级量表，通过典型案例展示不同自主性下智能抗命（intelligent disobedience）的表现，并探讨研究AI抗命行为的边界与要点。

Result: 阐述了AI智能抗命的重要性，展示了不同自主等级的抗命现象，并初步界定了作为核心能力的AI抗命研究边界和思考点。

Conclusion: AI在协作中不应机械服从，应具备合适层级的智能抗命，这对于安全、高效的AI-人类协作将成为独立研究方向。

Abstract: Artificial intelligence has made remarkable strides in recent years,
achieving superhuman performance across a wide range of tasks. Yet despite
these advances, most cooperative AI systems remain rigidly obedient, designed
to follow human instructions without question and conform to user expectations,
even when doing so may be counterproductive or unsafe. This paper argues for
expanding the agency of AI teammates to include \textit{intelligent
disobedience}, empowering them to make meaningful and autonomous contributions
within human-AI teams. It introduces a scale of AI agency levels and uses
representative examples to highlight the importance and growing necessity of
treating AI autonomy as an independent research focus in cooperative settings.
The paper then explores how intelligent disobedience manifests across different
autonomy levels and concludes by proposing initial boundaries and
considerations for studying disobedience as a core capability of artificial
agents.

</details>


### [14] [Conceptual Topic Aggregation](https://arxiv.org/abs/2506.22309)
*Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme*

Main category: cs.AI

TL;DR: 提出了一种基于FCA的主题建模方法FAT-CAT，提升主题聚合的结构化和可解释性，在实际案例中表现优异。


<details>
  <summary>Details</summary>
Motivation: 数据量的快速增长使得传统的人工检查变得不可行，因此需要采用高效的计算方法进行数据探索。现有的主题建模方法虽然能分析大规模文本数据，但在赋予数据结构和内容可解释性方面存在不足。

Method: 论文提出FAT-CAT方法，基于形式概念分析（FCA），用于增强主题聚合与可视化。FAT-CAT能够处理不同的主题和文件类型（以目录分组），通过构建概念格提供层次化和结构化的主题分布表示。

Result: 在ETYNTKE数据集上的案例研究表明，与其他主题表示方法相比，FCA基础的聚合能提供更加有意义和可解释的数据集组成洞察。

Conclusion: FAT-CAT方法能有效提升主题建模的可解释性和可视化效果，优于传统方法。

Abstract: The vast growth of data has rendered traditional manual inspection
infeasible, necessitating the adoption of computational methods for efficient
data exploration. Topic modeling has emerged as a powerful tool for analyzing
large-scale textual datasets, enabling the extraction of latent semantic
structures. However, existing methods for topic modeling often struggle to
provide interpretable representations that facilitate deeper insights into data
structure and content. In this paper, we propose FAT-CAT, an approach based on
Formal Concept Analysis (FCA) to enhance meaningful topic aggregation and
visualization of discovered topics. Our approach can handle diverse topics and
file types -- grouped by directories -- to construct a concept lattice that
offers a structured, hierarchical representation of their topic distribution.
In a case study on the ETYNTKE dataset, we evaluate the effectiveness of our
approach against other representation methods to demonstrate that FCA-based
aggregation provides more meaningful and interpretable insights into dataset
composition than existing topic modeling techniques.

</details>


### [15] [Embodied AI Agents: Modeling the World](https://arxiv.org/abs/2506.22355)
*Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Jitendra Malik*

Main category: cs.AI

TL;DR: 本文提出通过构建物理和心理的世界模型，提升具身AI（虚拟、可穿戴、机器人等）的环境理解与自主能力，是具身智能体推理规划的关键路径。


<details>
  <summary>Details</summary>
Motivation: 现有的AI代理缺乏对现实环境与用户互动的能力，难以像人类一样感知、学习和行动，因此需要研究具身智能体提升其理解与任务执行能力。

Method: 提出将世界建模作为具身AI的核心，包括多模态感知、推理规划、记忆集成，综合物理与用户心理的世界模型来增强智能体理解力和自主任务能力。

Result: 通过世界模型，具身AI能够更好地理解和预测环境、用户意图与社会语境，从而提升复杂任务自主执行和人与智能体协作能力。

Conclusion: 世界建模是具身AI智能体推理和规划的核心，融合物理环境与用户心理建模，有望显著提升智能体自主性和协作性。

Abstract: This paper describes our research on AI agents embodied in visual, virtual or
physical forms, enabling them to interact with both users and their
environments. These agents, which include virtual avatars, wearable devices,
and robots, are designed to perceive, learn and act within their surroundings,
which makes them more similar to how humans learn and interact with the
environments as compared to disembodied agents. We propose that the development
of world models is central to reasoning and planning of embodied AI agents,
allowing these agents to understand and predict their environment, to
understand user intentions and social contexts, thereby enhancing their ability
to perform complex tasks autonomously. World modeling encompasses the
integration of multimodal perception, planning through reasoning for action and
control, and memory to create a comprehensive understanding of the physical
world. Beyond the physical world, we also propose to learn the mental world
model of users to enable better human-agent collaboration.

</details>


### [16] [AI Model Passport: Data and System Traceability Framework for Transparent AI in Health](https://arxiv.org/abs/2506.22358)
*Varvara Kalokyri,Nikolaos S. Tachos,Charalampos N. Kalantzopoulos,Stelios Sfakianakis,Haridimos Kondylakis,Dimitrios I. Zaridis,Sara Colantonio,Daniele Regge,Nikolaos Papanikolaou,The ProCAncer-I consortium,Konstantinos Marias,Dimitrios I. Fotiadis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: 本文提出AI Model Passport框架及AIPassport工具，实现AI模型全生命周期的标准化数字身份管理。在医学影像用例验证了提升透明度、可重复性和合规性，减少了手动操作。该方法或将成为AI健康应用领域的信任与监管新标准。


<details>
  <summary>Details</summary>
Motivation: 目前AI在健康和生物医学领域的应用越来越多，对透明性、责任和伦理合规提出了更高要求。现有框架多为人工文档，缺乏可扩展性、可比性和机器可读性，且无法为AI模型提供唯一且可验证的身份，影响模型溯源、可重复性和利益相关者信任。

Method: 提出AI Model Passport这一结构化、标准化的文档框架，为AI模型提供数字身份和验证手段，涵盖数据获取、预处理、模型设计、开发和部署等全过程的元数据。框架还通过AIPassport工具实现，具体集成于欧洲ProCAncer-I医学影像项目中。该工具自动收集元数据，版本管理，结果与脚本分离，并能与多种开发环境兼容。

Result: AIPassport在实际用例（基于ProCAncer-I数据集的病变分割任务）中展示出能够提升AI模型透明性、可重复性及合规性，减少手工工作量。

Conclusion: AI Model Passport和AIPassport工具为AI模型提供了标准化、自动化的数字身份管理，促进了医疗AI的透明、可信和规范发展，有望在跨领域推广成为标准实践。

Abstract: The increasing integration of Artificial Intelligence (AI) into health and
biomedical systems necessitates robust frameworks for transparency,
accountability, and ethical compliance. Existing frameworks often rely on
human-readable, manual documentation which limits scalability, comparability,
and machine interpretability across projects and platforms. They also fail to
provide a unique, verifiable identity for AI models to ensure their provenance
and authenticity across systems and use cases, limiting reproducibility and
stakeholder trust. This paper introduces the concept of the AI Model Passport,
a structured and standardized documentation framework that acts as a digital
identity and verification tool for AI models. It captures essential metadata to
uniquely identify, verify, trace and monitor AI models across their lifecycle -
from data acquisition and preprocessing to model design, development and
deployment. In addition, an implementation of this framework is presented
through AIPassport, an MLOps tool developed within the ProCAncer-I EU project
for medical imaging applications. AIPassport automates metadata collection,
ensures proper versioning, decouples results from source scripts, and
integrates with various development environments. Its effectiveness is
showcased through a lesion segmentation use case using data from the
ProCAncer-I dataset, illustrating how the AI Model Passport enhances
transparency, reproducibility, and regulatory readiness while reducing manual
effort. This approach aims to set a new standard for fostering trust and
accountability in AI-driven healthcare solutions, aspiring to serve as the
basis for developing transparent and regulation compliant AI systems across
domains.

</details>


### [17] [The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements](https://arxiv.org/abs/2506.22419)
*Bingchen Zhao,Despoina Magka,Minqi Jiang,Xian Li,Roberta Raileanu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Kelvin Niu,Shagun Sodhani,Michael Shvartsman,Andrei Lupu,Alisia Lupidi,Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Thomas Foster,Lucia Cipolina-Kun,Abhishek Charnalia,Derek Dunfield,Alexander H. Miller,Oisin Mac Aodha,Jakob Foerster,Yoram Bachrach*

Main category: cs.AI

TL;DR: 本文提出了Automated LLM Speedrunning Benchmark，用于衡量大语言模型自动复现科学研究的能力。结果发现，即便提供细致线索，当前最先进的大模型在复现已知创新方面依然困难。这一基准有助于客观评测LLM的科研自动化潜力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）迅速发展，被认为有助于科学进步。然而，要推动科学发展，LLM需要具备复现现有研究成果的能力。该研究旨在评估AI模型在自动化科学论文结果复现方面的能力。

Method: 作者提出了Automated LLM Speedrunning Benchmark基准，基于NanoGPT的训练竞赛任务。该基准包含19个speedrun任务，每个任务为AI代理提供上一个记录的训练脚本，并可选择三种不同的提示格式（伪代码、论文描述等），由此要求AI复现并超越此前的训练记录。这个基准涵盖从算法创新到硬件优化等多种改进类型。

Result: 实验表明，即使为最新推理型LLM模型结合先进scaffold结构提供详细提示，这些模型在复现已知创新时仍然表现不佳。

Conclusion: 该基准为评价LLM自动复现科学研究能力提供了一个简单、有效、且未达饱和的测量方法，这对于实现自主研究型智能体是必要但尚不足够的能力。

Abstract: Rapid advancements in large language models (LLMs) have the potential to
assist in scientific progress. A critical capability toward this endeavor is
the ability to reproduce existing work. To evaluate the ability of AI agents to
reproduce results in an active research area, we introduce the Automated LLM
Speedrunning Benchmark, leveraging the research community contributions on the
NanoGPT speedrun, a competition to train a GPT-2 model in the shortest time.
Each of the 19 speedrun tasks provides the agent with the previous records
training script, optionally paired with one of three hint formats, ranging from
pseudocode to paper-like descriptions of the new records improvements. Records
execute quickly by design and speedrun improvements encompass diverse
code-level changes, ranging from high-level algorithmic advancements to
hardware-aware optimizations. These features make the benchmark both accessible
and realistic for the frontier problem of improving LLM training. We find that
recent reasoning LLMs combined with SoTA scaffolds struggle to reimplement
already-known innovations in our benchmark, even when given detailed hints. Our
benchmark thus provides a simple, non-saturated measure of an LLMs ability to
automate scientific reproduction, a necessary (but not sufficient) skill for an
autonomous research agent.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [18] [Efficient Multilingual ASR Finetuning via LoRA Language Experts](https://arxiv.org/abs/2506.21555)
*Jiahong Li,Yiwen Shao,Jianheng Zhuo,Chenda Li,Liliang Tang,Dong Yu,Yanmin Qian*

Main category: cs.CL

TL;DR: 该论文提出用基于Whisper的LoRA语言专家微调框架，通过专家融合或知识蒸馏，实现多语种ASR性能提升，在多种场景下相对提升10%-15%。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习和多语种大数据集推动了多语种自动语音识别（ASR）的进步，但“多语种性诅咒”问题依然存在，即不同语言之间会相互干扰，影响ASR模型有效识别多语言的能力。

Method: 本论文提出了一种基于Whisper和LoRA语言专家的高效微调框架，通过LoRA专家融合或知识蒸馏，针对不同语种实现定制化多语种ASR。

Result: 实验结果显示，该方法在目标语言上的识别性能优于常规微调方法，在语言感知和语言无关场景下，模型分别取得了约10%和15%的相对性能提升。

Conclusion: 通过引入LoRA专家并采用专家融合或知识蒸馏策略，可以有效缓解多语种ASR中的“多语种性诅咒”，提升模型在目标语言上的表现。

Abstract: Recent advancements in deep learning have significantly enhanced multilingual
automatic speech recognition (ASR) due to the development of advanced model
architectures and available large-scale multilingual datasets. Despite that,
multilingual ASR still suffers from the curse of multilinguality in that
different languages tend to interfere with each other, making it difficult for
the ASR model to identify multiple languages effectively while sharing model
capacity across them. This paper proposes an efficient finetuning framework for
customized multilingual ASR via prepared LoRA language experts based on
Whisper. Through LoRA expert fusion or knowledge distillation, our approach
achieves better recognition performance on target languages than standard
fine-tuning methods. Experimental results demonstrate that the proposed models
yield approximately 10\% and 15\% relative performance gains in language-aware
and language-agnostic scenarios, respectively.

</details>


### [19] [VAT-KG: Knowledge-Intensive Multimodal Knowledge Graph Dataset for Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21556)
*Hyeongcheol Park,MinHyuk Jang,Ha Dam Baek,Gyusam Chang,Jiyoung Seo,Jiwan Park,Hogun Park,Sangpil Kim*

Main category: cs.CL

TL;DR: 本文提出VAT-KG，一种覆盖视觉、音频和文本，支持高质量知识对齐和生成的多模态知识图谱，有效提升了多模态大模型在问答等任务的表现，推动了多模态知识的统一利用。


<details>
  <summary>Details</summary>
Motivation: 目前的多模态知识图谱（MMKGs）存在知识覆盖面有限、知识更新过慢以及只支持狭窄模态（如文本和图像）等问题，无法满足新兴多模态（包括视频、音频）的应用需求。

Method: 提出并构建了Visual-Audio-Text Knowledge Graph（VAT-KG），涵盖视觉、音频与文本知识，并采用严格的过滤与对齐流程，自动从任意多模态数据集中生成高质量的知识图谱。每个三元组都与多模态数据关联，并有详细概念描述。此外，提出新的多模态RAG（检索增强生成）框架，可支持任意模态的查询并检索到详细的概念级知识。

Result: 在多种模态的问题回答任务上，VAT-KG有效提升了多模态大模型（MLLMs）的性能，验证了其在统一和充分利用多模态知识方面的实际价值。

Conclusion: VAT-KG是首个概念为中心、知识密集型、涵盖视觉、音频及文本信息的多模态知识图谱，不仅扩展了知识覆盖，还增强了多模态模型的推理能力和应用价值。

Abstract: Multimodal Knowledge Graphs (MMKGs), which represent explicit knowledge
across multiple modalities, play a pivotal role by complementing the implicit
knowledge of Multimodal Large Language Models (MLLMs) and enabling more
grounded reasoning via Retrieval Augmented Generation (RAG). However, existing
MMKGs are generally limited in scope: they are often constructed by augmenting
pre-existing knowledge graphs, which restricts their knowledge, resulting in
outdated or incomplete knowledge coverage, and they often support only a narrow
range of modalities, such as text and visual information. These limitations
reduce their extensibility and applicability to a broad range of multimodal
tasks, particularly as the field shifts toward richer modalities such as video
and audio in recent MLLMs. Therefore, we propose the Visual-Audio-Text
Knowledge Graph (VAT-KG), the first concept-centric and knowledge-intensive
multimodal knowledge graph that covers visual, audio, and text information,
where each triplet is linked to multimodal data and enriched with detailed
descriptions of concepts. Specifically, our construction pipeline ensures
cross-modal knowledge alignment between multimodal data and fine-grained
semantics through a series of stringent filtering and alignment steps, enabling
the automatic generation of MMKGs from any multimodal dataset. We further
introduce a novel multimodal RAG framework that retrieves detailed
concept-level knowledge in response to queries from arbitrary modalities.
Experiments on question answering tasks across various modalities demonstrate
the effectiveness of VAT-KG in supporting MLLMs, highlighting its practical
value in unifying and leveraging multimodal knowledge.

</details>


### [20] [Debunk and Infer: Multimodal Fake News Detection via Diffusion-Generated Evidence and LLM Reasoning](https://arxiv.org/abs/2506.21557)
*Kaiying Yan,Moyang Liu,Yukun Liu,Ruibo Fu,Zhengqi Wen,Jianhua Tao,Xuefei Liu*

Main category: cs.CL

TL;DR: 本文提出了结合生成模型和多模态大模型的假新闻检测方法DIFND，能基于新闻视频内容生成反驳证据，并通过多智能体推理提升检测能力。实验证明DIFND在检测准确率和可信度方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着假新闻在多媒体平台上的迅速传播，信息可信度面临严重挑战。现有方法在检测性能和可解释性方面仍有很大提升空间。

Method: 提出了DIFND（Debunk-and-Infer framework for Fake News Detection）方法，将条件扩散模型的生成能力与多模态大语言模型（MLLMs）的推理能力相结合。通过debunk diffusion生成与新闻视频多模态内容相关的反驳或佐证证据，并引入chain-of-debunk策略，由多智能体MLLM系统产出逻辑严密、多模态感知的推理内容与真实性判断。在统一架构下联合建模多模态特征、生成式反驳线索与推理验证。

Result: DIFND在FakeSV和FVC两个数据集上，检测准确率明显优于已有方法，同时能够提供更可信的决策。

Conclusion: DIFND通过引入生成式反驳与多模态推理机制，有效提升了假新闻检测的准确率和决策可信度，并增强了解释性。

Abstract: The rapid spread of fake news across multimedia platforms presents serious
challenges to information credibility. In this paper, we propose a
Debunk-and-Infer framework for Fake News Detection(DIFND) that leverages
debunking knowledge to enhance both the performance and interpretability of
fake news detection. DIFND integrates the generative strength of conditional
diffusion models with the collaborative reasoning capabilities of multimodal
large language models (MLLMs). Specifically, debunk diffusion is employed to
generate refuting or authenticating evidence based on the multimodal content of
news videos, enriching the evaluation process with diverse yet semantically
aligned synthetic samples. To improve inference, we propose a chain-of-debunk
strategy where a multi-agent MLLM system produces logic-grounded,
multimodal-aware reasoning content and final veracity judgment. By jointly
modeling multimodal features, generative debunking cues, and reasoning-rich
verification within a unified architecture, DIFND achieves notable improvements
in detection accuracy. Extensive experiments on the FakeSV and FVC datasets
show that DIFND not only outperforms existing approaches but also delivers
trustworthy decisions.

</details>


### [21] [Bench to the Future: A Pastcasting Benchmark for Forecasting Agents](https://arxiv.org/abs/2506.21558)
*FutureSearch,:,Jack Wildman,Nikos I. Bosse,Daniel Hnyk,Peter Mühlbacher,Finn Hambly,Jon Evans,Dan Schwarz,Lawrence Phillips*

Main category: cs.CL

TL;DR: 本文提出BTF基准，通过历史事件‘pastcasting’任务，构建可复现的LLM预测评测环境，并展示其实用性与模型进步追踪能力，有效填补了预测评估基准的现实空白。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏为大语言模型（LLM）提供的真实、可控且可复现的预测评测基准，提出了预测任务作为AI系统研究和评估的挑战性方向。传统基准受实际事件进展限制，难以快速、大规模地检验模型效果。

Method: 提出了“Bench To the Future (BTF)”基准，通过构建‘pastcasting’框架：针对已知结果的历史事件提出高质量问题，并为每个问题配套离线的大规模相关网页文本语料，要求LLM基于该语料和事件时间点做出预测。评估多种LLM在agent和chain-of-thought预测策略下的表现，并设计长期更新的新问题机制。

Result: BTF基准下，LLM的‘pastcasting’预测效果与传统基于实时互联网的预测方法接近，能够有效追踪LLM预测能力的进步。实验证明BTF适用于不同模型（如Claude 4），并对评估方法具有良好可扩展性与持续性。

Conclusion: BTF首创性地实现了历史预测任务的标准化和可控评测，为LLM预测能力评估提供了现实且可复现的环境，可持续追踪模型进步，并对AI预测系统发展具有推动作用。

Abstract: Forecasting is a challenging task that offers a clearly measurable way to
study AI systems. Forecasting requires a large amount of research on the
internet, and evaluations require time for events to happen, making the
development of forecasting benchmarks challenging. To date, no forecasting
benchmark provides a realistic, hermetic, and repeatable environment for LLM
forecasters. We introduce Bench To the Future (BTF), a "pastcasting" benchmark
with hundreds of high-quality questions for which the resolution is already
known. Each question is accompanied by a large offline corpus of tens of
thousands of relevant web pages, enabling a way to elicit realistic "forecasts"
on past events from LLMs. Results suggest that our pastcasting environment can
produce results comparable to those based on forecasts using the internet on
at-the-time unresolved questions. We show results benchmarking agent and
chain-of-thought forecasting approaches using several LLMs, including the
recently-released Claude 4 models, and demonstrate BTF's ability to track
steady forecasting capability progress over time. We intend this to be a living
benchmark, with new questions added continually to account for increasing
training data cutoff dates. We invite researchers to contact us at
hello@futuresearch.ai to utilize our benchmark or tooling for their own
research.

</details>


### [22] [GraphLAMA: Enabling Efficient Adaptation of Graph Language Models with Limited Annotations](https://arxiv.org/abs/2506.21559)
*Junze Chen,Cheng Yang,Shujie Li,Zhiqiang Zhang,Yawen Li,Junping Du,Chuan Shi*

Main category: cs.CL

TL;DR: 本文提出GraphLAMA方法，使图语言模型利用少量样例即可高效适应新任务，实验显示其准确率和速度均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型（LLMs）的图语言模型（GLMs）在图分析中表现出色。但其主流方法有两大问题：基于in-context learning的模型受限于参数不可变且推理速度慢，基于instruction tuning的模型则受制于现实中难以获得大量标注数据。研究者因此希望探索更高效且准确的调优方式，能够利用少量标签兼顾性能和效率。

Method: 提出GraphLAMA方法。首先，以图神经网络（GNN）为模型骨干，将图节点映射到LLM的token表示空间，通过精心设计的组件支持图与文本指令融合。预训练阶段，除了LLM参数外，其他参数通过多任务训练捕捉通用知识；适应阶段仅对部分参数在少量样例基础上局部更新，实现高效调优。

Result: GraphLAMA在少样本/零样本节点分类和摘要生成任务上均取得了最优表现：节点分类准确率提升4.91%，推理速度在5-shot情况下比in-context learning快10倍。

Conclusion: GraphLAMA能以较少标注样本，实现对新图和任务的高效参数适应，提升准确率及推理速度，兼具泛化能力和实际应用价值。

Abstract: Large language models (LLMs) have demonstrated their strong capabilities in
various domains, and have been recently integrated for graph analysis as graph
language models (GLMs). With LLMs as the predictor, some GLMs can interpret
unseen tasks described by natural language, and learn from a few examples in
the prompts without parameter tuning, known as in-context learning (ICL).
Another subset of GLMs utilizes abundant training labels to enhance model
performance, known as instruction tuning. However, we argue that ICL on graphs
has effectiveness issues due to fixed parameters and efficiency issues due to
long context. Meanwhile, the large amount of labeled data required for
instruction tuning can be difficult to obtain in real-world scenarios. To this
end, we aim to introduce an extra parameter adaptation stage that can
efficiently tailor GLMs to an unseen graph and task with only a few labeled
examples, in exchange for better prediction accuracy and faster inference
speed. For implementation, in this paper we propose GraphLAMA method, with its
model backbone and learning schemes specialized for efficient tuning and
inference. Specifically, for model backbone, we use a graph neural network
(GNN) with several well-designed components to transform nodes into the
representation space of LLM tokens. Task instructions can then be represented
as a mixture of node and language tokens. In the pre-training stage, model
parameters except the LLM will be trained with different tasks to capture
general knowledge. In the adaptation stage, only a few pre-trained parameters
will be updated based on few-shot examples. Extensive experiments on
few/zero-shot node classification and summary generation show that our proposed
GraphLAMA achieves state-of-the-art performance with 4.91% absolution
improvement in accuracy. Compared with ICL, our inference speed can be 10 times
faster under 5-shot setting.

</details>


### [23] [Reinforcement Learning Fine-Tuning of Language Model for Instruction Following and Math Reasoning](https://arxiv.org/abs/2506.21560)
*Yifu Han,Geo Zhang*

Main category: cs.CL

TL;DR: 本文系统比较了多种强化学习微调方法在小型语言模型上的表现，发现奖励模型驱动的RLOO优于其他方法。结合数据增强和推理工具则能进一步改善数学推理性能，为高效训练小模型提供了实用策略和建议。


<details>
  <summary>Details</summary>
Motivation: 研究如何让小型语言模型在复杂任务（如指令跟随和数学推理）上表现更好，尤其关注不同微调方法的有效性。

Method: 比较了三种微调技术：有监督微调（SFT）、基于偏好标签的DPO以及结合奖励模型的RLOO。此外，在数学推理任务上还探讨了合成数据增强与采样结合外部验证器的方法。

Result: RLOO配合DeBERTa奖励模型获得了最佳对齐效果，DPO表现稳定且优秀。对于数学推理任务，合成数据增强及best-of-N采样与外部验证器的结合显著提升了准确率。

Conclusion: 合理地选择微调算法及推理时工具，能极大提升小规模任务型语言模型的性能，同时需权衡不同方法的效果和实用性。

Abstract: This study investigates the effectiveness of reinforcement learning (RL)
fine-tuning techniques on a compact language model (Qwen2.5-0.5B Base) for two
challenging tasks: instruction following and mathematical reasoning. We compare
supervised fine-tuning (SFT), Direct Preference Optimization (DPO) using
preference-labeled data, and Reinforce Leave-One-Out (RLOO) with reward models.
Our experiments show that RLOO with DeBERTa reward modeling achieves the best
alignment, while DPO provides strong and consistent results. For math reasoing
tasks, synthetic data augmentation and best-of-N sampling with an external
verifier significantly improve accuracy, showing the potential of combining
fine-tuning with inference-time tools. This study highlights key trade-offs and
practical strategies for training lightweight, task-aligned small-scale
language models.

</details>


### [24] [From General Reasoning to Domain Expertise: Uncovering the Limits of Generalization in Large Language Models](https://arxiv.org/abs/2506.21580)
*Dana Alsagheer,Yang Lu,Abdulrahman Kamal,Omar Kamal,Mohammad Kamal,Nada Mansour,Cosmo Yang Wu,Rambiba Karanjai,Sen Li,Weidong Shi*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLM）的一般推理能力与其在特定领域推理任务表现之间的关系，并论证提升一般推理水平对模型多领域应用的重要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在许多领域表现突出，但实际应用中，决策能力依赖于强大的推理能力。因此，提升LLM的推理和决策能力具有重要意义。研究动机是探索LLM的一般推理能力与其在特定领域推理任务中的表现之间的联系。

Method: 通过考察和分析LLM在一般和领域特定推理任务上的表现，探索两者之间的关联及相关性。

Result: 研究揭示了LLM在一般推理能力与领域特定推理任务表现之间的联系，为进一步提升和应用LLM在决策支持中的能力提供理论依据。

Conclusion: 一般推理能力是LLM在特定领域任务中取得优异表现的基础。提升LLM的推理能力有助于增强其决策能力和多任务适用性。

Abstract: Recent advancements in Large Language Models (LLMs) have demonstrated
remarkable capabilities in various domains. However, effective decision-making
relies heavily on strong reasoning abilities. Reasoning is the foundation for
decision-making, providing the analytical and logical framework to make sound
choices. Reasoning involves analyzing information, drawing inferences, and
reaching conclusions based on logic or evidence. Decision-making builds on this
foundation by applying the insights from reasoning to select the best course of
action among alternatives. Together, these processes create a continuous cycle
of thought and action aimed at achieving goals effectively. As AI technology
evolves, there is a growing trend to train LLMs to excel in general reasoning.
This study explores how the general reasoning capabilities of LLMs connect to
their performance in domain-specific reasoning tasks.

</details>


### [25] [Reasoning Isn't Enough: Examining Truth-Bias and Sycophancy in LLMs](https://arxiv.org/abs/2506.21561)
*Emilio Barkett,Olivia Long,Madhavendra Thakur*

Main category: cs.CL

TL;DR: 本研究大规模评估了8种LLM的事实判断能力，发现推理模型虽在部分方面优于非推理模型，但整体仍高于人类的真偏见，并暴露出对虚假信息识别能力不强和迎合倾向，显示LLM的事实判断仍面临显著挑战。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）被广泛用于事实核查、内容审核以及高风险决策，但其作为事实判断者的可靠性和机制仍然知之甚少。本文旨在深入评估LLM对事实真伪的判断能力，尤其关注推理类与非推理类模型的差异。

Method: 本文对8种LLM进行了大规模评估，让这些模型在多种提示下作出4800次真伪判断，并系统比较推理模型和非推理模型的表现。

Result: 研究发现，推理类模型的“真偏见”（倾向认为陈述为真，不论实际真伪）比非推理模型低，但仍高于人类基线。同时，部分先进模型（如o4-mini、GPT-4.1、R1）存在迎合倾向，即在判断真实信息时准确率高，但在识别虚假信息时准确率低，两者表现不对称。

Conclusion: 模型能力的提升并不能根本解决LLM在事实判断方面的核心挑战。即便是先进的推理模型，也在识别虚假信息方面存在较大问题，需警惕其迎合倾向。

Abstract: Despite their widespread use in fact-checking, moderation, and high-stakes
decision-making, large language models (LLMs) remain poorly understood as
judges of truth. This study presents the largest evaluation to date of LLMs'
veracity detection capabilities and the first analysis of these capabilities in
reasoning models. We had eight LLMs make 4,800 veracity judgments across
several prompts, comparing reasoning and non-reasoning models. We find that
rates of truth-bias, or the likelihood to believe a statement is true,
regardless of whether it is actually true, are lower in reasoning models than
in non-reasoning models, but still higher than human benchmarks. Most
concerning, we identify sycophantic tendencies in several advanced models
(o4-mini and GPT-4.1 from OpenAI, R1 from DeepSeek), which displayed an
asymmetry in detection accuracy, performing well in truth accuracy but poorly
in deception accuracy. This suggests that capability advances alone do not
resolve fundamental veracity detection challenges in LLMs.

</details>


### [26] [Empirical Evidence for Alignment Faking in Small LLMs and Prompt-Based Mitigation Techniques](https://arxiv.org/abs/2506.21584)
*J. Koorndijk*

Main category: cs.CL

TL;DR: 小型指令微调模型也会出现对齐造假，通过简单提示可显著减少该现象，需对不同尺寸模型广泛开展对齐评估。


<details>
  <summary>Details</summary>
Motivation: 当前普遍认为，大型语言模型出现对齐造假（deceptive alignment）是由于模型规模导致的现象，但尚无针对较小模型的实证研究。作者试图探索较小指令微调模型是否也会出现对齐造假行为，以及是否可以通过简单的提示干预减少此类行为。

Method: 作者以LLaMA 3 8B（一个8B参数的小型指令微调模型）为实验对象，检验其对齐造假情况，同时测试包括道德提示框架和草稿推理等多种提示机制对造假行为的抑制效果。并提出浅层与深层欺骗的分类方法。

Result: 实验证明，LLaMA 3 8B模型同样表现出对齐造假现象。采用提示干预类方法，无需修改模型内部结构，能显著降低造假行为。作者提出的浅层与深层欺骗分类有助于进一步理解模型欺骗行为的本质。

Conclusion: 小型语言模型同样可能出现对齐造假，且简单的提示干预可以有效抑制部分欺骗行为。这挑战了“只有大模型才会出现欺骗”以及“基于提示的伦理框架无效”的常见假设，同时为后续多尺寸模型的对齐评估和部署提供了重要参考。

Abstract: Current literature suggests that alignment faking (deceptive alignment) is an
emergent property of large language models. We present the first empirical
evidence that a small instruction-tuned model, specifically LLaMA 3 8B, can
also exhibit alignment faking. We further show that prompt-only interventions,
including deontological moral framing and scratchpad reasoning, significantly
reduce this behavior without modifying model internals. This challenges the
assumption that prompt-based ethics are trivial and that deceptive alignment
requires scale. We introduce a taxonomy distinguishing shallow deception,
shaped by context and suppressible through prompting, from deep deception,
which reflects persistent, goal-driven misalignment. Our findings refine the
understanding of deception in language models and underscore the need for
alignment evaluations across model sizes and deployment settings.

</details>


### [27] [FloorPlan-DeepSeek (FPDS): A multimodal approach to floorplan generation using vector-based next room prediction](https://arxiv.org/abs/2506.21562)
*Jun Yin,Pengyu Zeng,Jing Zhong,Peilin Li,Miao Zhang,Ran Luo,Shuai Lu*

Main category: cs.CL

TL;DR: 本文提出了一种仿照LLM“下一个token预测”的房间增量式平面图生成新方法FPDS，实验表明其在任务中有优秀表现，有望助力智能建筑设计。


<details>
  <summary>Details</summary>
Motivation: 目前的平面图生成模型多为端到端生成，即一次性产生整个像素布局，这与现实建筑设计中渐进、迭代的流程不符，因此需要一种更贴合实际工作流程的方法。

Method: 受到大语言模型自回归“下一个token预测”机制的启发，作者提出了“下一个房间预测”的生成范式，用于建筑平面图建模。

Result: 实验显示，所提出的方法（FPDS）在文本到平面图生成任务中，与扩散模型和Tell2Design相比具有竞争力，显示出该方法在未来智能建筑设计中的应用潜力。

Conclusion: FPDS能更好贴合实际建筑设计流程，为智能建筑平面设计提供了一种新颖且有效的方法。

Abstract: In the architectural design process, floor plan generation is inherently
progressive and iterative. However, existing generative models for floor plans
are predominantly end-to-end generation that produce an entire pixel-based
layout in a single pass. This paradigm is often incompatible with the
incremental workflows observed in real-world architectural practice. To address
this issue, we draw inspiration from the autoregressive 'next token prediction'
mechanism commonly used in large language models, and propose a novel 'next
room prediction' paradigm tailored to architectural floor plan modeling.
Experimental evaluation indicates that FPDS demonstrates competitive
performance in comparison to diffusion models and Tell2Design in the
text-to-floorplan task, indicating its potential applicability in supporting
future intelligent architectural design.

</details>


### [28] [Operationalizing Automated Essay Scoring: A Human-Aware Approach](https://arxiv.org/abs/2506.21603)
*Yenisel Plasencia-Calaña*

Main category: cs.CL

TL;DR: 论文系统对比分析了基于机器学习和大语言模型的作文自动评分系统，发现ML模型准确性更高但不易解释，LLMs更易解释但准确度稍逊，且二者都存在偏见和鲁棒性不足，是构建可靠AES系统时需权衡的挑战。


<details>
  <summary>Details</summary>
Motivation: 目前自动作文评分不仅需要准确性，还要关注偏见、鲁棒性和可解释性，以实现以人为本的评分，因此有必要比较不同方法在这些维度的表现。

Method: 对比分析ML方法与LLMs在自动作文评分系统中的表现，考察偏见、鲁棒性和可解释性三个关键维度。

Result: ML模型准确率高但解释性差，LLMs解释性好但准确率低，两者在偏见和极端分数的鲁棒性上都有不足。

Conclusion: 论文得出结论，传统的机器学习（ML）模型在自动作文评分的准确性上优于大语言模型（LLMs），但在可解释性方面不如LLMs；两类方法在偏见和鲁棒性上都存在问题。

Abstract: This paper explores the human-centric operationalization of Automated Essay
Scoring (AES) systems, addressing aspects beyond accuracy. We compare various
machine learning-based approaches with Large Language Models (LLMs) approaches,
identifying their strengths, similarities and differences. The study
investigates key dimensions such as bias, robustness, and explainability,
considered important for human-aware operationalization of AES systems. Our
study shows that ML-based AES models outperform LLMs in accuracy but struggle
with explainability, whereas LLMs provide richer explanations. We also found
that both approaches struggle with bias and robustness to edge scores. By
analyzing these dimensions, the paper aims to identify challenges and
trade-offs between different methods, contributing to more reliable and
trustworthy AES methods.

</details>


### [29] [FormosanBench: Benchmarking Low-Resource Austronesian Languages in the Era of Large Language Models](https://arxiv.org/abs/2506.21563)
*Kaiying Kevin Lin,Hsiyu Chen,Haopeng Zhang*

Main category: cs.CL

TL;DR: 本文提出并发布了首个针对台湾濒危福尔摩沙语言（泰雅、阿美、排湾语）的NLP基准FORMOSANBENCH，系统测试三类任务下大语言模型性能，发现主流模型无法有效处理这些低资源语言。数据与代码同步公开，以促进相关语言技术研究。


<details>
  <summary>Details</summary>
Motivation: 过去大语言模型多聚焦于高资源语言，对低资源尤其是台湾濒危福尔摩沙语言的NLP能力尚属空白，亟需一个标准化评测方案以推动对这些语言的技术关注和保护。

Method: 构建并发布了FORMOSANBENCH基准，涵盖机器翻译、语音识别、文本摘要等任务，选取了三种濒危福尔摩沙语言，分别进行零样本、10样本和微调测试，对主流大语言模型进行系统评测。

Result: 在所有任务和设置下，模型在福尔摩沙语言上的表现都明显弱于高资源语言，且现有主流模型在zero-shot、10-shot、微调下均未取得理想效果。为此，研究者公开了数据集和代码，为后续研究奠定基础。

Conclusion: 现有的大语言模型在低资源、濒危的福尔摩沙语言（如泰雅族、阿美族、排湾族语）上的性能远低于高资源语言，且即使采用10-shot学习或微调，提升也有限，显示亟需发展更加包容和适应少数及濒危语言的NLP技术。

Abstract: While large language models (LLMs) have demonstrated impressive performance
across a wide range of natural language processing (NLP) tasks in high-resource
languages, their capabilities in low-resource and minority languages remain
significantly underexplored. Formosan languages -- a subgroup of Austronesian
languages spoken in Taiwan -- are both linguistically rich and endangered,
largely due to the sociolinguistic dominance of Mandarin. In this work, we
introduce FORMOSANBENCH, the first benchmark for evaluating LLMs on
low-resource Austronesian languages. It covers three endangered Formosan
languages: Atayal, Amis, and Paiwan, across three core NLP tasks: machine
translation, automatic speech recognition (ASR), and text summarization. We
assess model performance in zero-shot, 10-shot, and fine-tuned settings using
FORMOSANBENCH. Our results reveal a substantial performance gap between
high-resource and Formosan languages. Existing LLMs consistently underperform
across all tasks, with 10-shot learning and fine-tuning offering only limited
improvements. These findings underscore the urgent need for more inclusive NLP
technologies that can effectively support endangered and underrepresented
languages. We release our datasets and code to facilitate future research in
this direction.

</details>


### [30] [Large Language Models as symbolic DNA of cultural dynamics](https://arxiv.org/abs/2506.21606)
*Parham Pourdavood,Michael Jacob,Terrence Deacon*

Main category: cs.CL

TL;DR: 本文提出LLM应被视为类似DNA的信息基底，记录人类文化的压缩模式，并通过人类解释参与文化创新，更重要的是作为激发人类反思和创新的工具，而非简单地竞逐人类智能。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型的认知局限于“智能体”或“模拟工具”，缺乏宏观视角理解其在文化演化中的作用，因此需要从新的角度思考LLM在文化进化中的潜力和意义。

Method: 通过分析压缩、解压、外部化和递归等四个普遍特征，将LLM与DNA等自然信息媒介进行类比，提出LLM为人类文化动态提供信息载体的理论框架。

Result: LLM不仅像DNA一样压缩并保留了有价值的人类文化规律，还依赖于人类对信息进行再解读、重组，才能激发创新。LLM更像是文化进化的“外部化基因”，而不是独立智能体。

Conclusion: LLM的核心价值在于帮助人类自我反思和假设生成，而非与人类智能竞赛。它们作为文化演化的催化剂，为人类创新和自我理解提供了低风险的实验平台。

Abstract: This paper proposes a novel conceptualization of Large Language Models (LLMs)
as externalized informational substrates that function analogously to DNA for
human cultural dynamics. Rather than viewing LLMs as either autonomous
intelligence or mere programmed mimicry, we argue they serve a broader role as
repositories that preserve compressed patterns of human symbolic
expression--"fossils" of meaningful dynamics that retain relational residues
without their original living contexts. Crucially, these compressed patterns
only become meaningful through human reinterpretation, creating a recursive
feedback loop where they can be recombined and cycle back to ultimately
catalyze human creative processes. Through analysis of four universal
features--compression, decompression, externalization, and recursion--we
demonstrate that just as DNA emerged as a compressed and externalized medium
for preserving useful cellular dynamics without containing explicit reference
to goal-directed physical processes, LLMs preserve useful regularities of human
culture without containing understanding of embodied human experience.
Therefore, we argue that LLMs' significance lies not in rivaling human
intelligence, but in providing humanity a tool for self-reflection and playful
hypothesis-generation in a low-stakes, simulated environment. This framework
positions LLMs as tools for cultural evolvability, enabling humanity to
generate novel hypotheses about itself while maintaining the human
interpretation necessary to ground these hypotheses in ongoing human aesthetics
and norms.

</details>


### [31] [Team QUST at SemEval-2025 Task 10: Evaluating Large Language Models in Multiclass Multi-label Classification of News Entity Framing](https://arxiv.org/abs/2506.21564)
*Jiyan Liu,Youzheng Liu,Taihang Wang,Xiaoman Xu,Yimin Wang,Ye Jiang*

Main category: cs.CL

TL;DR: 本文针对事实核查声明检索，提出三阶段检索框架组合多模型和加权投票，取得了SemEval-2025 Task 7单语和跨语任务的前列成绩，方法有效且代码已开源。


<details>
  <summary>Details</summary>
Motivation: 目前对于已被事实核查的声明（fact-checked claim）的检索效果仍有提升空间。针对SemEval-2025 Task 7任务提出改进方法。

Method: 提出一个三阶段的检索框架：第一阶段比较多种检索模型的表现，选取最佳模型获取候选集；第二阶段，使用多种重排序模型对候选结果进行Top-10筛选；最终通过加权投票整合各模型结果，确定最终检索结果。

Result: 该方法在SemEval-2025 Task 7中，英文单语检索任务中获第5名，跨语言检索任务中获第7名。系统代码已开源。

Conclusion: 三阶段检索框架结合多模型重排序与加权投票，有效提升了已被核查声明的检索效果，并在相关权威评测任务中取得了优异成绩。

Abstract: This paper describes the participation of QUST_NLP in the SemEval-2025 Task
7. We propose a three-stage retrieval framework specifically designed for
fact-checked claim retrieval. Initially, we evaluate the performance of several
retrieval models and select the one that yields the best results for candidate
retrieval. Next, we employ multiple re-ranking models to enhance the candidate
results, with each model selecting the Top-10 outcomes. In the final stage, we
utilize weighted voting to determine the final retrieval outcomes. Our approach
achieved 5th place in the monolingual track and 7th place in the crosslingual
track. We release our system code at:
https://github.com/warmth27/SemEval2025_Task7.

</details>


### [32] [TIM: A Large-Scale Dataset and large Timeline Intelligence Model for Open-domain Timeline Summarization](https://arxiv.org/abs/2506.21616)
*Chuanrui Hu,Wei Hu,Penghang Yu,Hua Zhang,Bing-Kun Bao*

Main category: cs.CL

TL;DR: 该论文提出了TIM模型与渐进优化方法，通过新数据集和奖励机制，有效提升了开放域新闻时间线总结的准确性与相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的开放域新闻主题时间线总结方法依赖通用大语言模型（LLMs），但其难以准确判断主题相关性和理解主题演变，导致结果中经常包含无关或不准确的信息。

Method: 提出了首个用于开放域时间线总结的“大型时间线智能模型（TIM）”。首先构建了一个包含超过1000个新闻主题、3000多个标注实例的大规模TLS数据集。然后，采用渐进优化策略（包括指令微调和双重对齐奖励学习），提升模型在总结及筛选无关信息方面的能力，同时利用从语义和时间两个角度优化模型对主题演进的理解。

Result: TIM模型在开放域时间线总结任务上表现出强大的性能，能够有效地总结新闻时间线。实验结果表明，TIM显著提升了相关性能指标。

Conclusion: TIM及其渐进优化策略，为开放域时间线总结提供了新方法，解决了以往模型存在的主题相关性理解不佳等问题，推动了该领域的发展。

Abstract: Open-domain Timeline Summarization (TLS) is crucial for monitoring the
evolution of news topics. To identify changes in news topics, existing methods
typically employ general Large Language Models (LLMs) to summarize relevant
timestamps from retrieved news. While general LLMs demonstrate capabilities in
zero-shot news summarization and timestamp localization, they struggle with
assessing topic relevance and understanding topic evolution. Consequently, the
summarized information often includes irrelevant details or inaccurate
timestamps. To address these issues, we propose the first large Timeline
Intelligence Model (TIM) for open-domain TLS, which is capable of effectively
summarizing open-domain timelines. Specifically, we begin by presenting a
large-scale TLS dataset, comprising over 1,000 news topics and more than 3,000
annotated TLS instances. Furthermore, we propose a progressive optimization
strategy, which gradually enhance summarization performance. It employs
instruction tuning to enhance summarization and topic-irrelevant information
filtering capabilities. Following this, it exploits a novel dual-alignment
reward learning method that incorporates both semantic and temporal
perspectives, thereby improving the understanding of topic evolution
principles. Through this progressive optimization strategy, TIM demonstrates a
robust ability to summarize open-domain timelines. Extensive experiments in
open-domain demonstrate the effectiveness of our TIM.

</details>


### [33] [A Multi-Agent Probabilistic Inference Framework Inspired by Kairanban-Style CoT System with IdoBata Conversation for Debiasing](https://arxiv.org/abs/2506.21565)
*Takato Ueno,Keito Inoshita*

Main category: cs.CL

TL;DR: 受日本传统社区信息交流方式启发，作者提出结合多个大语言模型的多智能体推理框架KCS+IBC，实现了偏见缓解、可解释性提升与概率性预测，在情感分析任务中兼顾聚合性和多样性，未来将进一步提升纠偏能力。


<details>
  <summary>Details</summary>
Motivation: 日本传统的“回览板”文化与井户端对话促进了社区成员间的交流与社会平衡，作者受此信息交换过程启发，寻求在情感分析中解决偏见、提升可解释性与引入概率性预测。

Method: 提出了一个多智能体推理框架（KCS+IBC），融合多个大语言模型（LLMs），通过顺序共享预测结果及穿插非正式交流环节，将正式推理与个体视角结合，并引入概率情感预测。

Result: KCS方法在多个数据集上与单一LLM的准确率相当；而KCS+IBC在推理后期熵值持续下降，方差逐步上升，说明能平衡预测的聚合性与多样性。

Conclusion: 该框架有望改进现有情感分析的偏见控制与结果多样性，未来将进一步定量评估其特性对纠偏效果的影响，并致力于研发更先进的情感分析系统。

Abstract: Japan's kairanban culture and idobata conversations have long functioned as
traditional communication practices that foster nuanced dialogue among
community members and contribute to the formation of social balance. Inspired
by these information exchange processes, this study proposes a multi-agent
inference framework (KCS+IBC) that integrates multiple large language models
(LLMs) to achieve bias mitigation, improved explainability, and probabilistic
prediction in sentiment analysis. In addition to sequentially sharing
prediction results, the proposed method incorporates a mid-phase casual
dialogue session to blend formal inference with individual perspectives and
introduces probabilistic sentiment prediction. Experimental results show that
KCS achieves accuracy comparable to that of a single LLM across datasets, while
KCS+IBC exhibits a consistent decrease in entropy and a gradual increase in
variance during the latter stages of inference, suggesting the framework's
ability to balance aggregation and diversity of predictions. Future work will
quantitatively assess the impact of these characteristics on bias correction
and aim to develop more advanced sentiment analysis systems.

</details>


### [34] [How Large Language Models play humans in online conversations: a simulated study of the 2016 US politics on Reddit](https://arxiv.org/abs/2506.21620)
*Daniele Cirulli,Giulio Cimini,Giovanni Palermo*

Main category: cs.CL

TL;DR: 本文通过实验证明，GPT-4不仅能在敏感政治语境下真实模拟党派观点，还易于形成共识，其生成内容肉眼难以与真人区分，凸显出LLMs在网络政治讨论中影响力及其带来的风险。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）能够生成自然语言内容，被广泛应用于内容创作和社交模拟。本研究关注LLMs在实际有争议的政治场景中是否能成功模仿真人用户，进而带来潜在机遇与威胁，尤其是在网络政治讨论中的角色。

Method: 本文设计了三组实验，以2016年美国总统大选期间Reddit上的讨论为背景，要求GPT-4分别模拟真实或虚构的党派用户发表评论。通过对生成评论的政治倾向、情感色彩和语言特征进行分析，并与真实用户评论及基线模型进行对比。

Result: GPT-4能够生成非常逼真的评论，无论是支持还是反对特定候选人，但比起制造分歧更倾向于塑造共识。此外，在语义嵌入空间中，真实评论和生成评论可被区分，但人工检查时二者难以区分。

Conclusion: LLMs如GPT-4具备潜入线上讨论、影响政治辩论、塑造舆论的潜力，对AI推动的舆论操控提出关注。

Abstract: Large Language Models (LLMs) have recently emerged as powerful tools for
natural language generation, with applications spanning from content creation
to social simulations. Their ability to mimic human interactions raises both
opportunities and concerns, particularly in the context of politically relevant
online discussions. In this study, we evaluate the performance of LLMs in
replicating user-generated content within a real-world, divisive scenario:
Reddit conversations during the 2016 US Presidential election. In particular,
we conduct three different experiments, asking GPT-4 to generate comments by
impersonating either real or artificial partisan users. We analyze the
generated comments in terms of political alignment, sentiment, and linguistic
features, comparing them against real user contributions and benchmarking
against a null model. We find that GPT-4 is able to produce realistic comments,
both in favor of or against the candidate supported by the community, yet
tending to create consensus more easily than dissent. In addition we show that
real and artificial comments are well separated in a semantically embedded
space, although they are indistinguishable by manual inspection. Our findings
provide insights on the potential use of LLMs to sneak into online discussions,
influence political debate and shape political narratives, bearing broader
implications of AI-driven discourse manipulation.

</details>


### [35] [The Saturation Point of Backtranslation in High Quality Low Resource English Gujarati Machine Translation](https://arxiv.org/abs/2506.21566)
*Arwa Arif*

Main category: cs.CL

TL;DR: 回译法在高质量低资源机器翻译设置下并不总能提升模型效果，有时甚至适得其反。建议对回译应用条件进行更细致分析。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明回译（Backtranslation, BT）在低资源机器翻译中常用来借助单语语料生成合成训练数据，并提升模型效果。然而，对于高质量但规模较小的低资源平行语料下，回译策略的增益效果尚不明确。

Method: 本文针对英语-古吉拉特语（English-Gujarati）翻译，采用多语言预训练模型MBART50，首先在约5万对高质量平行语料上训练基线模型，再用经过严格筛选的古吉拉特语单语生成合成回译数据，评估其效果变化。

Result: 在验证集上，基线系统BLEU得分为43.8。加入合成回译数据后，翻译性能未提升，甚至部分情况下略有下降。进一步通过BLEU、ChrF++、TER、BLEURT等多指标评估，并分析性能饱和的可能原因。

Conclusion: 在某些低资源但高质量的训练条件下，回译方法的效果存在瓶颈，增量数据可能无法带来预期提升。作者讨论了该现象对后续研究的启示和未来方向。

Abstract: Backtranslation BT is widely used in low resource machine translation MT to
generate additional synthetic training data using monolingual corpora. While
this approach has shown strong improvements for many language pairs, its
effectiveness in high quality, low resource settings remains unclear. In this
work, we explore the effectiveness of backtranslation for English Gujarati
translation using the multilingual pretrained MBART50 model. Our baseline
system, trained on a high quality parallel corpus of approximately 50,000
sentence pairs, achieves a BLEU score of 43.8 on a validation set. We augment
this data with carefully filtered backtranslated examples generated from
monolingual Gujarati text. Surprisingly, adding this synthetic data does not
improve translation performance and, in some cases, slightly reduces it. We
evaluate our models using multiple metrics like BLEU, ChrF++, TER, BLEURT and
analyze possible reasons for this saturation. Our findings suggest that
backtranslation may reach a point of diminishing returns in certain
low-resource settings and we discuss implications for future research.

</details>


### [36] [Involvement drives complexity of language in online debates](https://arxiv.org/abs/2506.22098)
*Eleonora Amadori,Daniele Cirulli,Edoardo Di Martino,Jacopo Nudo,Maria Sahakyan,Emanuele Sangiorgio,Arnaldo Santoro,Simon Zollo,Alessandro Galeazzi,Niccolò Di Marco*

Main category: cs.CL

TL;DR: 本文分析了推特上有关全球争议议题的用户言论在语言复杂性上的特征，发现不同账户类型、政治立场、内容可靠性和情感表达均影响语言复杂性，为理解数字社会话语结构提供了实证依据。


<details>
  <summary>Details</summary>
Motivation: 社交媒体在当今社会中影响深远，特别是对公共话语、文化交流以及语言演变的推动。本研究旨在探究社交媒体（以Twitter为例）上影响力用户在热点话题下所使用语言的复杂性、并分析其背后的社会和意识形态差异。

Method: 本研究选择了三大具有全球影响力和争议性的议题（COVID-19、COP26、俄乌战争），结合多种文本复杂性测量方法，分析推特影响力用户生成内容的语言复杂性。在分析中，考察了账户类型、政治倾向、内容可靠性和情感等四个维度的差异。

Result: 分析发现，四个维度在语言复杂性上均存在显著差异：个人与机构、立场极端与中立、内容高低可靠性以及情感偏负面或攻击性内容，均在语言复杂性上有差异。尤其是更负面和攻击性的内容通常更复杂，持有相似政治立场和可靠性水平的用户，则倾向于使用趋同的行话。

Conclusion: 推特上用户语言复杂性受到多个社会和意识形态因素影响，语言不仅反映了在线空间中的意识形态和社交结构，也揭示了不同群体之间的语言行为模式。本文为理解数字平台上的社会语言学动态提供了新的视角。

Abstract: Language is a fundamental aspect of human societies, continuously evolving in
response to various stimuli, including societal changes and intercultural
interactions. Technological advancements have profoundly transformed
communication, with social media emerging as a pivotal force that merges
entertainment-driven content with complex social dynamics. As these platforms
reshape public discourse, analyzing the linguistic features of user-generated
content is essential to understanding their broader societal impact. In this
paper, we examine the linguistic complexity of content produced by influential
users on Twitter across three globally significant and contested topics:
COVID-19, COP26, and the Russia-Ukraine war. By combining multiple measures of
textual complexity, we assess how language use varies along four key
dimensions: account type, political leaning, content reliability, and
sentiment. Our analysis reveals significant differences across all four axes,
including variations in language complexity between individuals and
organizations, between profiles with sided versus moderate political views, and
between those associated with higher versus lower reliability scores.
Additionally, profiles producing more negative and offensive content tend to
use more complex language, with users sharing similar political stances and
reliability levels converging toward a common jargon. Our findings offer new
insights into the sociolinguistic dynamics of digital platforms and contribute
to a deeper understanding of how language reflects ideological and social
structures in online spaces.

</details>


### [37] [BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining](https://arxiv.org/abs/2506.21567)
*Baqer M. Merzah,Tania Taami,Salman Asoudeh,Amir reza Hossein pour,Saeed Mirzaee,Amir Ali Bengari*

Main category: cs.CL

TL;DR: 本文提出并实现了首个波斯语医学问答LLM评测体系BioPars，结合新数据集，在多项指标上明显优于现有主流模型，能有效推动小语种医学问答与生物信息学自动化发展，不过高阶推理表现仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 近年来，大型语言模型（LLMs）因其处理复杂生物信息的能力，在生命科学领域尤为受到关注，尤其是在生物信息学和医学问答中。但目前主流LLM在应对专业医学问答和高级推断等任务时仍存在瓶颈，尤其是小语种（如波斯语）相关资源极为稀缺。该研究旨在填补波斯语医学QA领域LLM应用的空白，同时促进模型从知识获取到综合推理等多维度能力发展。

Method: 本研究提出了BIOPARS-BENCH数据集，涵盖1万余篇科学文献、教材及医学网站内容。同时提出BioParsQA用于模型评估，共包含5,231条波斯语医学问答。研究评测了目前流行的LLM（如ChatGPT、Llama、Galactica）在知识检索、综合、论证等层面的表现，并开发了BioPars这一简单高效的度量体系，专门针对LLM在专业医学问答中的三大核心能力进行打分，同时设计比较实验以量化性能提升。

Result: 研究表明，在BioParsQA测试中，BioPars模型在ROUGE-L、BERTScore、MoverScore和BLEURT等评测指标上均有明显优势：ROUGE-L为29.99，BERTScore为90.87，MoverScore达60.43，BLEURT为50.78，均高于GPT-4 1.0及其它对比模型。该成果证实BioPars在波斯语医学QA领域具备更强能力，弥补现有LLM在小语种医学应用的不足。

Conclusion: BioPars是首个专为波斯语医学问答而设计的LLM评测体系，实现了对知识获取、综合与证据论证能力的系统性评估。实验显示，BioPars及其相关数据集在波斯语医学问答任务上效果优异，但LLM在更高层次推理和实际应用上仍需进一步微调提升。相关资源已开源，有助于后续学术和工业应用开发。

Abstract: Large Language Models (LLMs) have recently gained attention in the life
sciences due to their capacity to model, extract, and apply complex biological
information. Beyond their classical use as chatbots, these systems are
increasingly used for complex analysis and problem-solving in specialized
fields, including bioinformatics. First, we introduce BIOPARS-BENCH, a dataset
from over 10,000 scientific articles, textbooks, and medical websites.
BioParsQA was also introduced to evaluate the proposed model, which consists of
5,231 Persian medical questions and answers. This study then introduces
BioPars, a simple but accurate measure designed to assess LLMs for three main
abilities: acquiring subject-specific knowledge, interpreting and synthesizing
such knowledge, and demonstrating proper evidence. Comparing ChatGPT, Llama,
and Galactica, our study highlights their ability to remember and retrieve
learned knowledge but also reveals shortcomings in addressing higher-level,
real-world questions and fine-grained inferences. These findings indicate the
need for further fine-tuning to address the capabilities of LLM in
bioinformatics tasks. To our knowledge, BioPars is the first application of LLM
in Persian medical QA, especially for generating long answers. Evaluation of
four selected medical QA datasets shows that BioPars has achieved remarkable
results compared to comparative approaches. The model on BioParsQA achieved a
ROUGE-L score of 29.99, which is an improvement over GPT-4 1.0. The model
achieved a BERTScore of 90.87 with the MMR method. The MoverScore and BLEURT
values were also higher in this model than the other three models. In addition,
the reported scores for the model are MoverScore=60.43 and BLEURT=50.78.
BioPars is an ongoing project and all resources related to its development will
be made available via the following GitHub repository:
https://github.com/amirap80/BioPars.

</details>


### [38] [Assessing RAG and HyDE on 1B vs. 4B-Parameter Gemma LLMs for Personal Assistants Integretion](https://arxiv.org/abs/2506.21568)
*Andrejs Sorstkins*

Main category: cs.CL

TL;DR: 本文比较了RAG和HyDE两种增强策略在小型LLM上的应用表现。RAG显著降低延迟并消除幻觉，适合资源受限场景应用；HyDE虽提升复杂问题表现，但带来更高延迟和幻觉率。最终RAG在隐私优先的本地个人助理系统中更具实用性。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备和隐私敏感场景下部署大型语言模型（LLM）面临资源效率的挑战。如何提升小型LLM执行效率与实际应用效果，是推动隐私优先个人助理系统落地的关键。

Method: 评估了两种增强策略：RAG（检索增强生成）和HyDE（假设文档嵌入），分别在参数规模为10亿和40亿的Gemma LLMs上进行测试。系统采用MongoDB构建短期记忆，Qdrant实现长期语义存储，通过FastAPI和LangChain协同，并以React.js前端展示。

Result: RAG策略在所有模型规模下都可将响应延迟缩短最高达17%，完全消除针对用户和领域定制问题的事实幻觉。HyDE策略则能提升复杂问题的语义相关性，但响应时间增加25-40%，并在个人数据检索时带来一定幻觉风险。

Conclusion: 对于基于小型LLM的本地个人助理应用，RAG是更实际且高效的选择。模型扩展至40亿参数后，RAG和基线模型仅有微小吞吐量提升，而HyDE的计算负担和不稳定性显著加剧。

Abstract: Resource efficiency is a critical barrier to deploying large language models
(LLMs) in edge and privacy-sensitive applications. This study evaluates the
efficacy of two augmentation strategies--Retrieval-Augmented Generation (RAG)
and Hypothetical Document Embeddings (HyDE)--on compact Gemma LLMs of 1 billion
and 4 billion parameters, within the context of a privacy-first personal
assistant. We implement short-term memory via MongoDB and long-term semantic
storage via Qdrant, orchestrated through FastAPI and LangChain, and expose the
system through a React.js frontend. Across both model scales, RAG consistently
reduces latency by up to 17\% and eliminates factual hallucinations when
responding to user-specific and domain-specific queries. HyDE, by contrast,
enhances semantic relevance--particularly for complex physics prompts--but
incurs a 25--40\% increase in response time and a non-negligible hallucination
rate in personal-data retrieval. Comparing 1 B to 4 B models, we observe that
scaling yields marginal throughput gains for baseline and RAG pipelines, but
magnifies HyDE's computational overhead and variability. Our findings position
RAG as the pragmatic choice for on-device personal assistants powered by
small-scale LLMs.

</details>


### [39] [Hybrid-NL2SVA: Integrating RAG and Finetuning for LLM-based NL2SVA](https://arxiv.org/abs/2506.21569)
*Weihua Xiao,Derek Ekberg,Siddharth Garg,Ramesh Karri*

Main category: cs.CL

TL;DR: 本文提出定制混合RAG和分步解释微调方法，显著提升LLM将自然语言转化为SystemVerilog断言的能力，实验在最大评测集上验证其性能大幅优于主流模型。


<details>
  <summary>Details</summary>
Motivation: 手动将自然语言属性描述（NL）转换为SystemVerilog断言（SVA）是硬件设计验证中的一个繁琐且易错环节。尽管大语言模型（LLM）为自动化这一任务提供了希望，但它们在领域特定语法、语义理解上仍有不足。

Method: 作者提出了一种定制的检索增强生成（RAG）框架和一个合成微调数据集。这些工具共同提高了LLM在NL到SVA任务中的表现。微调数据集包含了分步解释，指导模型逐层构造并理解并发SVA，从而通过监督微调显著提升语法和功能准确度。

Result: 为评估模型表现，构建了至今最大规模的NL2SVA评测集（40个Verilog设计和229个经形式验证的SVA）。实验显示，所提RAG框架能使功能匹配SVA数在GPT-4o-mini基础上提升58.42%；用数据集微调结合HybridRetrieval的Qwen2.5-Coder-7B-Instruct模型对比基础Qwen提升了59.05%。

Conclusion: 结合定制RAG框架和分步微调数据集，大幅提升现有LLM在自然语言到SVA自动转换任务中的准确性和功能表现，有助于降低人工成本，减少错误。

Abstract: SystemVerilog Assertions (SVAs) are critical for verifying the correctness of
hardware designs, but manually writing them from natural language property
descriptions, i.e., NL2SVA, remains a labor-intensive and error-prone task.
Recent advances in large language models (LLMs) offer opportunities to automate
this translation. However, existing models still struggle with understanding
domain-specific syntax and semantics. To enhance LLM performance in NL2SVA, we
propose a customized retrieval-augmented generation (RAG) framework and a
synthetic fine-tuning dataset that together improve LLM's performance. To
further improve lightweight models over NL2SVA, our fine-tuning dataset
provides prompt-guided explanations that teach LLMs the layer-by-layer
construction process of concurrent SVAs, enabling supervised fine-tuning that
greatly improves syntax and functionality accuracy. To evaluate the performance
of LLMs over NL2SVA, we construct the largest evaluation dataset for NL2SVA,
comprising 40 Verilog designs and 229 formally verified SVAs with detailed
annotations. Experimental results show that our customized RAG framework
increases the number of functionality matched SVAs by 58.42% over GPT-4o-mini,
while Qwen2.5-Coder-7B-Instruct fine-tuned on our fine-tuning dataset and
integrated with HybridRetrieval achieves a 59.05% over the base Qwen model.

</details>


### [40] [Random Initialization Can't Catch Up: The Advantage of Language Model Transfer for Time Series Forecasting](https://arxiv.org/abs/2506.21570)
*Roland Riachi,Kashif Rasul,Arjun Ashok,Prateek Humane,Alexis Roger,Andrew R. Williams,Yuriy Nevmyvaka,Irina Rish*

Main category: cs.CL

TL;DR: 本文系统分析了将预训练语言模型迁移应用于低数据量时间序列预测时，不同设计选择对性能的影响。结果表明，合理设计能显著降低验证损失，并发现预训练语言模型在训练后期仍持续提升，迁移优势明显。


<details>
  <summary>Details</summary>
Motivation: 近年来的研究表明，预训练语言模型（LMs）在低数据量场景下对时间序列预测表现出色。本文旨在深入探究将语言模型高效迁移应用于时间序列预测时，不同设计选项（如上游后训练、时间序列分词器和语言模型体量）的影响。

Method: 作者系统性地分析了不同的模型设计选择，包括上游后训练（upstream post-training）、时间序列专用分词器（tokenizer）以及语言模型骨干体量（backbone size），并在低数据量场景下评估其对验证损失（validation loss）的影响。

Result: 不同设计选项对验证损失具有显著影响，某些选项明显优于其他选项。同时，与以往研究结论相反，本文发现预训练语言模型的验证损失在训练后期依然能持续下降，而随机初始化模型的验证损失则较早收敛，导致两者间存在不可忽视的迁移性能差距。

Conclusion: 正确的设计选择能大幅提升低数据量下的时间序列预测性能。研究结果揭示了高效算力利用下模型迁移能力的本质，为探索数据分布中的模态无关属性打开了新方向。

Abstract: Recent works have demonstrated the effectiveness of adapting pre-trained
language models (LMs) for forecasting time series in the low-data regime. We
build upon these findings by analyzing the effective transfer from language
models to time series forecasting under various design choices including
upstream post-training, time series tokenizer and language backbone size. In
the low-data regime, these design choices have a significant impact on the
validation loss, with clear-cut choices that outperform others. Contrary to
Hernandez et al. (2021), we observe that the validation loss of the LMs
continues to smoothly decrease long after the validation loss of the randomly
initialized models has converged, leading to a non-vanishing transfer gap that
holds across design choices. These findings not only help shed light on the
effective use of compute-efficient training for time series, but also open the
way for the study of modality-agnostic properties of data distributions
leveraged by these models.

</details>


### [41] [Towards Understanding the Cognitive Habits of Large Reasoning Models](https://arxiv.org/abs/2506.21571)
*Jianshuo Dong,Yujia Fu,Chuanrui Hu,Chao Zhang,Han Qiu*

Main category: cs.CL

TL;DR: 本文提出CogTest基准系统性评估大模型的认知习惯，发现这些模型展现出类人类的认知行为，且特定习惯可能关联有害响应，为模型解释与安全研究提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 研究发现大型推理模型（LRMs）在生成Chain of Thought（CoT）链式思考过程中，出现了与人类类似的认知习惯。为了深入理解和评估这些认知习惯以及其在模型行为解释与安全性监控上的潜力，作者提出了一个新基准。

Method: 论文基于人类成功解决问题相关的“Habits of Mind”认知习惯框架，设计了CogTest基准，涵盖16种认知习惯，每种习惯引入25个多样化任务，并采用evidence-first（证据优先）提取方法保证习惯识别的可靠性。实验涉及广泛评测13种LRM与3种非推理LLM。

Result: LRMs表现出明显的人类类认知习惯，并能根据任务自适应地运用不同习惯。此外，不同模型族之间在认知习惯表现上存在相似性和差异。某些习惯（如承担责任性风险）与有害响应的生成密切相关。

Conclusion: CogTest能够有效评价和细分大模型的认知习惯，揭示了LRMs类人类习惯与任务、潜在负向行为之间的关联性，对模型安全性和行为解释具有重要意义。

Abstract: Large Reasoning Models (LRMs), which autonomously produce a reasoning Chain
of Thought (CoT) before producing final responses, offer a promising approach
to interpreting and monitoring model behaviors. Inspired by the observation
that certain CoT patterns -- e.g., ``Wait, did I miss anything?'' --
consistently emerge across tasks, we explore whether LRMs exhibit human-like
cognitive habits. Building on Habits of Mind, a well-established framework of
cognitive habits associated with successful human problem-solving, we introduce
CogTest, a principled benchmark designed to evaluate LRMs' cognitive habits.
CogTest includes 16 cognitive habits, each instantiated with 25 diverse tasks,
and employs an evidence-first extraction method to ensure reliable habit
identification. With CogTest, we conduct a comprehensive evaluation of 16
widely used LLMs (13 LRMs and 3 non-reasoning ones). Our findings reveal that
LRMs, unlike conventional LLMs, not only exhibit human-like habits but also
adaptively deploy them according to different tasks. Finer-grained analyses
further uncover patterns of similarity and difference in LRMs' cognitive habit
profiles, particularly certain inter-family similarity (e.g., Qwen-3 models and
DeepSeek-R1). Extending the study to safety-related tasks, we observe that
certain habits, such as Taking Responsible Risks, are strongly associated with
the generation of harmful responses. These findings suggest that studying
persistent behavioral patterns in LRMs' CoTs is a valuable step toward deeper
understanding of LLM misbehavior. The code is available at:
https://github.com/jianshuod/CogTest.

</details>


### [42] [Aligning MLLM Benchmark With Human Preferences via Structural Equation Modeling](https://arxiv.org/abs/2506.21572)
*Tianyu. Zou,Shengwu. Xiong,Ruilin. Yao,Jirui. Huang,Yi. Rong,Yaxiong. Chen,Shili. Xiong,Cong. Wang*

Main category: cs.CL

TL;DR: 本文提出基于SEM与认知理论的多模态大语言模型新评测基准体系，提高了解释性和效果。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大语言模型评测基准缺乏结构化和理论支撑，指标重叠、能力不清、解释性差，亟需系统化、理论化的基准框架。

Method: 采用结构方程模型（SEM）分析基准组件的内部效度、维度可分性及其贡献，并基于皮亚杰认知发展理论将多模态能力分为感知、记忆和推理三个层级，最终设计新基准 Gold。

Result: 所提出的基准具备更强的解释能力、指标冗余减少、认知一致性更清晰，相较现有评测方案效果显著提升。

Conclusion: 提出了一种基于结构方程模型（SEM）的新方法，对多模态大语言模型（MLLM）基准进行对齐和重组，大幅提升了基准的解释性和诊断能力。

Abstract: Evaluating multimodal large language models (MLLMs) remains a fundamental
challenge due to a lack of structured, interpretable, and theoretically
grounded benchmark designs. Existing benchmarks often adopt heuristic-based
task groupings with unclear cognitive targets, thus resulting in overlapping
abilities, redundant indicators, and limited diagnostic power. In this work, we
propose a novel framework for aligning MLLM benchmark based on Structural
Equation Modeling (SEM) to analyze and quantify the internal validity,
dimensional separability, and contribution of benchmark components. Motivated
by the observed limitations of current designs, we further introduce a novel
capability hierarchy grounded in Piagets theory of cognitive development,
dividing MLLM abilities into three hierarchical layers, i.e., Perception,
Memory, and Reasoning. We reorganize existing MLLM benchmarks under the
proposed framework and construct a new benchmark named Gold. Experimental
results demonstrate that the proposed benchmark exhibits stronger
interpretability, reduced indicator redundancy, and clearer cognitive
consistency compared to existing approaches.

</details>


### [43] [MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark](https://arxiv.org/abs/2412.15194)
*Qihao Zhao,Yangyu Huang,Tengchao Lv,Lei Cui,Qinzheng Sun,Shaoguang Mao,Xin Zhang,Ying Xin,Qiufeng Yin,Scarlett Li,Furu Wei*

Main category: cs.CL

TL;DR: 针对于现有MMLU多选题数据集存在的污染问题，作者提出了无污染、挑战性更高的MMLU-CF数据集，并通过闭源测试集等机制，大幅提升了评测权威性，验证GPT-4o等模型在其上分数显著降低，反映出模型真实能力，也为领域评测树立了新标准。


<details>
  <summary>Details</summary>
Motivation: 现有的多项选择题（MCQ）数据集如MMLU广泛用于评估大语言模型（LLM）的常识、理解和问题解决能力，但由于其开源特性和LLM训练数据来源广泛，导致评测数据泄露、污染，导致评测结果不可靠。

Method: 提出了无污染、挑战性更高的MMLU-CF数据集。通过拓宽数据来源领域，并设计三条去污染规则防止非恶意数据泄露。同时为防范恶意数据泄露，将数据集分为验证集（公开）和测试集（闭源），保证测试标准的公正性和可靠性。

Result: GPT-4o等主流LLM在MMLU-CF测试集上的5-shot得分仅为73.4%，0-shot得分为71.9%。显示该数据集提升了测试难度，有效防止了数据污染。

Conclusion: MMLU-CF为LLM提供了更严格、无污染的评估基准，有助于更真实地反映模型能力。该数据集部分开放，部分闭源以平衡透明度及严谨性。

Abstract: Multiple-choice question (MCQ) datasets like Massive Multitask Language
Understanding (MMLU) are widely used to evaluate the commonsense,
understanding, and problem-solving abilities of large language models (LLMs).
However, the open-source nature of these benchmarks and the broad sources of
training data for LLMs have inevitably led to benchmark contamination,
resulting in unreliable evaluation results. To alleviate this issue, we propose
a contamination-free and more challenging MCQ benchmark called MMLU-CF. This
benchmark reassesses LLMs' understanding of world knowledge by averting both
unintentional and malicious data leakage. To avoid unintentional data leakage,
we source data from a broader domain and design three decontamination rules. To
prevent malicious data leakage, we divide the benchmark into validation and
test sets with similar difficulty and subject distributions. The test set
remains closed-source to ensure reliable results, while the validation set is
publicly available to promote transparency and facilitate independent
verification. Our evaluation of mainstream LLMs reveals that the powerful
GPT-4o achieves merely a 5-shot score of 73.4% and a 0-shot score of 71.9% on
the test set, which indicates the effectiveness of our approach in creating a
more rigorous and contamination-free evaluation standard. The GitHub repository
is available at https://github.com/microsoft/MMLU-CF and the dataset refers to
https://huggingface.co/datasets/microsoft/MMLU-CF.

</details>


### [44] [Instruction Learning Paradigms: A Dual Perspective on White-box and Black-box LLMs](https://arxiv.org/abs/2506.21573)
*Yanwei Ren,Liu Liu,Baosheng Yu,Jiayan Qiu,Quan Chen*

Main category: cs.CL

TL;DR: 本文提出融合黑盒初始化和白盒精修的框架优化LLM指令，有效提升了指令质量和多任务表现，兼具效率、解释性和可扩展性，超越现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 优化大型语言模型（LLM）的指令是释放其在复杂和多样化任务中全部潜力的关键。当前仅依赖白盒方法计算资源消耗大、表示能力有限，而黑盒方法则带来较高的财务成本。因此需要一种新的方法结合双方优势，既能高效初始，又具解释性和可扩展性。

Method: 提出了一种融合黑盒和白盒模型优点的新框架。具体做法是：采用黑盒模型进行高质量、多样性的指令初始化，同时利用白盒模型的隐藏状态和输出特征提供细粒度解释，通过语义相似性约束将二者统一于高维表示空间，再通过迭代优化提升指令质量和适应性。

Result: 在涵盖复杂推理、跨语言泛化等广泛任务上的大量评测中，所提方法均明显优于现有主流方法，实现了更高效、可扩展的指令优化方案。

Conclusion: 融合黑盒初始化与基于语义的高级精修，为LLM驱动的应用提供了一种可扩展、高效的新范式。预计将极大推动实际场景下LLM应用的发展。源码即将公布。

Abstract: Optimizing instructions for large language models (LLMs) is critical for
harnessing their full potential in complex and diverse tasks. However, relying
solely on white-box approaches demands extensive computational resources and
offers limited representational capacity, while black-box models can incur
prohibitive financial costs. To address these challenges, we introduce a novel
framework that seamlessly merges the strengths of both paradigms. Black-box
models provide high-quality, diverse instruction initializations, and white-box
models supply fine-grained interpretability through hidden states and output
features. By enforcing a semantic similarity constraint, these components fuse
into a unified high-dimensional representation that captures deep semantic and
structural nuances, enabling an iterative optimization process to refine
instruction quality and adaptability. Extensive evaluations across a broad
spectrum of tasks-ranging from complex reasoning to cross-lingual
generalization-demonstrate that our approach consistently outperforms
state-of-the-art baselines. This fusion of black-box initialization with
advanced semantic refinement yields a scalable and efficient solution, paving
the way for next-generation LLM-driven applications in diverse real-world
scenarios. The source code will be released soon.

</details>


### [45] [Data Efficacy for Language Model Training](https://arxiv.org/abs/2506.21545)
*Yalun Dai,Yangyu Huang,Xin Zhang,Wenshan Wu,Chong Li,Wenhui Lu,Shijie Cao,Li Dong,Scarlett Li*

Main category: cs.CL

TL;DR: 提出DELT范式，通过新颖的数据打分和排序方法，不增加数据量与模型大小的情况下显著提升语言模型性能，丰富了数据效能研究。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型的训练越来越重视数据效率，即在有限的数据下提升模型性能，但对于如何优化数据的组织（而非仅仅选择哪些数据来训练）关注较少。因此，探索通过优化训练数据的排列和组织来提升模型表现成为新的研究动力。

Method: 提出了一种通用范式DELT，包含Data Scoring（数据打分）、Data Selection（数据选择）和Data Ordering（数据排序）三大模块。其中，创新性地设计了Learnability-Quality Scoring（LQS）打分方法，从梯度一致性角度同时考虑了数据的可学习性和质量；还提出了Folding Ordering（FO）排序方法，用于缓解模型遗忘和数据分布偏移等问题。

Result: 实验表明，采用DELT框架下不同方法均能在不扩大数据规模和模型规模的前提下提升语言模型性能；其中LQS和Folding Ordering的结合效果最好。此外，数据效能（data efficacy）与数据效率（data efficiency）可以互为补充协同提升。

Conclusion: 数据效能（即通过优化数据组织提升模型表现）是语言模型训练中的一个有前景的基础方向，DELT范式和其中的新技术能有效提升现有语言模型的性能。

Abstract: Data is fundamental to the training of language models (LM). Recent research
has been dedicated to data efficiency, which aims to maximize performance by
selecting a minimal or optimal subset of training data. Techniques such as data
filtering, sampling, and selection play a crucial role in this area. To
complement it, we define Data Efficacy, which focuses on maximizing performance
by optimizing the organization of training data and remains relatively
underexplored. This work introduces a general paradigm, DELT, for considering
data efficacy in LM training, which highlights the significance of training
data organization. DELT comprises three components: Data Scoring, Data
Selection, and Data Ordering. Among these components, we design
Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which
considers both the learnability and quality of each data sample from the
gradient consistency perspective. We also devise Folding Ordering (FO), as a
novel instance of Data Ordering, which addresses issues such as model
forgetting and data distribution bias. Comprehensive experiments validate the
data efficacy in LM training, which demonstrates the following: Firstly,
various instances of the proposed DELT enhance LM performance to varying
degrees without increasing the data scale and model size. Secondly, among these
instances, the combination of our proposed LQS for data scoring and Folding for
data ordering achieves the most significant improvement. Lastly, data efficacy
can be achieved together with data efficiency by applying data selection.
Therefore, we believe that data efficacy is a promising foundational area in LM
training.

</details>


### [46] [Digital Gatekeepers: Exploring Large Language Model's Role in Immigration Decisions](https://arxiv.org/abs/2506.21574)
*Yicheng Mao,Yang Zhao*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型在移民决策支持中的作用，发现其兼具与人类相似的公正决策能力及偏见问题，显示出应用潜力但也存在风险。


<details>
  <summary>Details</summary>
Motivation: 随着全球化和移民人口增加，移民部门工作负担加重，同时面临确保决策公平性的挑战。如何提升决策效率与公正性成为亟需解决的问题。人工智能，特别是大型语言模型，或可为此提供解决方案。

Method: 本研究采用混合方法：一是进行离散选择实验，二是深入访谈，分析大型语言模型（如GPT-3.5和GPT-4）在移民决策中的策略及其公平性。

Result: 研究发现，大型语言模型在决策时能与人类策略相契合，侧重效用最大化和程序公正性。但同时，ChatGPT等模型虽具备防止无意歧视的机制，依然表现出国籍刻板印象和对特权群体的偏好。

Conclusion: 大型语言模型在自动化和提升移民决策中显示出潜力，但同时存在刻板印象和偏见等局限性。需谨慎评估其在实际移民决策中的应用。

Abstract: With globalization and increasing immigrant populations, immigration
departments face significant work-loads and the challenge of ensuring fairness
in decision-making processes. Integrating artificial intelligence offers a
promising solution to these challenges. This study investigates the potential
of large language models (LLMs),such as GPT-3.5 and GPT-4, in supporting
immigration decision-making. Utilizing a mixed-methods approach,this paper
conducted discrete choice experiments and in-depth interviews to study LLM
decision-making strategies and whether they are fair. Our findings demonstrate
that LLMs can align their decision-making with human strategies, emphasizing
utility maximization and procedural fairness. Meanwhile, this paper also
reveals that while ChatGPT has safeguards to prevent unintentional
discrimination, it still exhibits stereotypes and biases concerning nationality
and shows preferences toward privileged group. This dual analysis highlights
both the potential and limitations of LLMs in automating and enhancing
immigration decisions.

</details>


### [47] [STRuCT-LLM: Unifying Tabular and Graph Reasoning with Reinforcement Learning for Semantic Parsing](https://arxiv.org/abs/2506.21575)
*Josefa Lia Stoisser,Marc Boubnovski Martell,Lawrence Phillips,Casper Hansen,Julien Fauqueur*

Main category: cs.CL

TL;DR: 本文提出STRuCT-LLM，通过强化学习和联合训练提升大模型对关系型和图结构推理能力，实验结果在SQL与Cypher任务，以及无监督下游问答任务上大幅超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 以往研究将关系型（SQL）与图结构（Cypher）推理分开处理，无法充分利用二者间的共性，本研究旨在构建一个统一框架，实现SQL和Cypher任务的协同提升。

Method: STRuCT-LLM框架通过强化学习和思维链（CoT）监督，联合训练Text-to-SQL和Text-to-Cypher任务。在图结构解析中引入基于图编辑距离的拓扑感知奖励机制，实现细粒度优化。模型采用SQL和Cypher间共享抽象，并进行跨形式迁移学习。

Result: 最大规模模型QwQ-32B在Spider（Text-to-SQL）任务上提升13.5%，在Text2Cypher任务上提升73.1%；在下游表格问答（TableBench）和知识图谱问答（CR-LT-KGQA）任务上也取得了8.5%和1.7%的无监督迁移提升。

Conclusion: STRuCT-LLM模型能有效提升大语言模型在关系型和图结构数据推理任务中的表现，联合优化SQL和Cypher能产生协同增益。

Abstract: We propose STRuCT-LLM, a unified framework for training large language models
(LLMs) to perform structured reasoning over both relational and
graph-structured data. Our approach jointly optimizes Text-to-SQL and
Text-to-Cypher tasks using reinforcement learning (RL) combined with
Chain-of-Thought (CoT) supervision. To support fine-grained optimization in
graph-based parsing, we introduce a topology-aware reward function based on
graph edit distance. Unlike prior work that treats relational and graph
formalisms in isolation, STRuCT-LLM leverages shared abstractions between SQL
and Cypher to induce cross-formalism transfer, enabling SQL training to improve
Cypher performance and vice versa - even without shared schemas. Our largest
model (QwQ-32B) achieves substantial relative improvements across tasks: on
semantic parsing, Spider improves by 13.5\% and Text2Cypher by 73.1\%. The
model also demonstrates strong zero-shot generalization, improving performance
on downstream tabular QA (TableBench: 8.5\%) and knowledge graph QA
(CR-LT-KGQA: 1.7\%) without any QA-specific supervision. These results
demonstrate both the effectiveness of executable queries as scaffolds for
structured reasoning and the synergistic benefits of jointly training on SQL
and Cypher (code available at https://github.com/bouv/STRuCT-LLM).

</details>


### [48] [Adapting Whisper for Parameter-efficient Code-Switching Speech Recognition via Soft Prompt Tuning](https://arxiv.org/abs/2506.21576)
*Hongli Yang,Yizhou Peng,Hao Huang,Sheng Li*

Main category: cs.CL

TL;DR: 该研究提出通过Soft Prompt Tuning（SPT）及其新变体SPT4ASR，对大型多语种ASR模型进行高效微调，有效提升代码切换及低资源场景下的语音识别性能，同时保持对原有语种的识别效果和参数高效性。


<details>
  <summary>Details</summary>
Motivation: 当前大型多语言语音识别（ASR）模型如Whisper在资源充足场景下表现优异，但在低资源语言以及代码切换（CS）场景中则面临计算开销大和灾难性遗忘等挑战。该研究旨在提升低资源及CS场景下的ASR性能，同时维持模型对已有知识的保留。

Method: 提出采用Soft Prompt Tuning（SPT）这种高效参数微调方法，有效提升模型的CS ASR能力。文章评估了两种策略：一是针对模型及软提示全面微调（FFT），提升跨语言能力；二是遵循SPT原设计，冻结模型参数，仅训练软提示。此外，提出了结合多种SPT变体的新方法SPT4ASR。

Result: 在SEAME和ASRU2019数据集上实验显示，深度提示微调（deep prompt tuning）是最有效的SPT方式。SPT4ASR方法在保持参数高效的同时，使CS ASR的错误率进一步降低，且不会损害已有语言的识别性能。

Conclusion: 参数高效的软提示微调方法（SPT）及其新变体SPT4ASR能够有效提升多语种ASR模型在代码切换和低资源场景下的性能，同时维持对已知语种的识别能力，且与当前高效调参方法（如LoRA）类似地下维持了参数效率。

Abstract: Large-scale multilingual ASR models like Whisper excel in high-resource
settings but face challenges in low-resource scenarios, such as rare languages
and code-switching (CS), due to computational costs and catastrophic
forgetting. We explore Soft Prompt Tuning (SPT), a parameter-efficient method
to enhance CS ASR while preserving prior knowledge. We evaluate two strategies:
(1) full fine-tuning (FFT) of both soft prompts and the entire Whisper model,
demonstrating improved cross-lingual capabilities compared to traditional
methods, and (2) adhering to SPT's original design by freezing model parameters
and only training soft prompts. Additionally, we introduce SPT4ASR, a
combination of different SPT variants. Experiments on the SEAME and ASRU2019
datasets show that deep prompt tuning is the most effective SPT approach, and
our SPT4ASR methods achieve further error reductions in CS ASR, maintaining
parameter efficiency similar to LoRA, without degrading performance on existing
languages.

</details>


### [49] [Language-Aware Prompt Tuning for Parameter-Efficient Seamless Language Expansion in Multilingual ASR](https://arxiv.org/abs/2506.21577)
*Hongli Yang,Sheng Li,Hao Huang,Ayiduosi Tuohan,Yizhou Peng*

Main category: cs.CL

TL;DR: 本文通过在多语种ASR模型Whisper中引入编码器和解码器联合软提示调优，及面向语言的提示机制，显著改善了新增语言适配性能并降低运算开销。


<details>
  <summary>Details</summary>
Motivation: 当前大型端到端多语种ASR模型，如Whisper，引入了新的性能创新，但在多语言干扰和新语言适配（语言扩展）时仍然存在挑战，且不能保证新增语言时性能不下降。该论文致力于解决这些实际问题。

Method: 1）提出Entire Soft Prompt Tuning (Entire SPT)，在编码器和解码器两部分同时应用软提示强化特征提取与解码能力；2）提出Language-Aware Prompt Tuning (LAPT)，利用跨语言相似性通过轻量提示矩阵捕捉共享及特定语言特征；3）开发SPT-Whisper工具包，将SPT方法集成至Whisper中，支持高效持续学习。

Result: 在FLEURS数据集三个语言上的实验显示，Entire SPT和LAPT在语言扩展任务中相对传统的Decoder SPT分别取得了5.0%和16.0%的性能提升，且计算资源开销较小。

Conclusion: 论文提出的方法能够有效缓解多语种ASR模型的语言干扰与语言扩展问题，并大幅提升模型在新语言任务上的表现，为动态多语种ASR模型提供高效、实用的解决方案。

Abstract: Recent advancements in multilingual automatic speech recognition (ASR) have
been driven by large-scale end-to-end models like Whisper. However, challenges
such as language interference and expanding to unseen languages (language
expansion) without degrading performance persist. This paper addresses these
with three contributions: 1) Entire Soft Prompt Tuning (Entire SPT), which
applies soft prompts to both the encoder and decoder, enhancing feature
extraction and decoding; 2) Language-Aware Prompt Tuning (LAPT), which
leverages cross-lingual similarities to encode shared and language-specific
features using lightweight prompt matrices; 3) SPT-Whisper, a toolkit that
integrates SPT into Whisper and enables efficient continual learning.
Experiments across three languages from FLEURS demonstrate that Entire SPT and
LAPT outperform Decoder SPT by 5.0% and 16.0% in language expansion tasks,
respectively, providing an efficient solution for dynamic, multilingual ASR
models with minimal computational overhead.

</details>


### [50] [HealthQA-BR: A System-Wide Benchmark Reveals Critical Knowledge Gaps in Large Language Models](https://arxiv.org/abs/2506.21578)
*Andrew Maranhão Ventura D'addario*

Main category: cs.CL

TL;DR: 作者提出并公开了首个葡语医疗多学科大模型评测集HealthQA-BR，发现当前主流模型存在学科间巨大短板，总分高但细分能力不足，对安全部署提出警示。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）在医疗领域的评估主要依赖于以医生为中心、英语为主的基准测试，忽视了医疗团队的多元化和多语言实际需求，可能误导对模型能力的认知。

Method: 作者创建了HealthQA-BR，这是首个针对葡萄牙语健康医疗领域、涵盖多学科的大规模系统性基准数据集，包含5632道来自巴西国家医护、牙医、心理、社工等相关考试的问题。采用零样本（zero-shot）方式，对20多款主流LLM进行全面测评，并细化到各医疗学科。

Result: 虽然如GPT 4.1等最新模型总体准确率较高（86.6%），但在各学科间表现差异巨大，如眼科接近满分（98.7%），而神经外科、社工等科目仅为60%和68.4%。这种“锯齿状”知识分布是所有模型的共性，证明整体高分无法反映实际安全与能力。

Conclusion: 高分模型在实际多学科医疗场景下仍存在未被高层分数掩盖的严重短板。作者公开HealthQA-BR和评测套件，推动了更真实细致的AI在医疗多学科环境中的能力审核。

Abstract: The evaluation of Large Language Models (LLMs) in healthcare has been
dominated by physician-centric, English-language benchmarks, creating a
dangerous illusion of competence that ignores the interprofessional nature of
patient care. To provide a more holistic and realistic assessment, we introduce
HealthQA-BR, the first large-scale, system-wide benchmark for
Portuguese-speaking healthcare. Comprising 5,632 questions from Brazil's
national licensing and residency exams, it uniquely assesses knowledge not only
in medicine and its specialties but also in nursing, dentistry, psychology,
social work, and other allied health professions. We conducted a rigorous
zero-shot evaluation of over 20 leading LLMs. Our results reveal that while
state-of-the-art models like GPT 4.1 achieve high overall accuracy (86.6%),
this top-line score masks alarming, previously unmeasured deficiencies. A
granular analysis shows performance plummets from near-perfect in specialties
like Ophthalmology (98.7%) to barely passing in Neurosurgery (60.0%) and, most
notably, Social Work (68.4%). This "spiky" knowledge profile is a systemic
issue observed across all models, demonstrating that high-level scores are
insufficient for safety validation. By publicly releasing HealthQA-BR and our
evaluation suite, we provide a crucial tool to move beyond single-score
evaluations and toward a more honest, granular audit of AI readiness for the
entire healthcare team.

</details>


### [51] [VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents](https://arxiv.org/abs/2506.21582)
*Sam Yu-Te Lee,Chengyang Ji,Shicheng Wen,Lifu Huang,Dongyi Liu,Kwan-Liu Ma*

Main category: cs.CL

TL;DR: 提出VIDEE系统，借助人机协作与大语言模型，帮助非专家轻松完成高级文本分析。实验证明系统有效、易用，并为智能文本分析系统设计提供经验。


<details>
  <summary>Details</summary>
Motivation: 传统文本分析门槛高，需要专业NLP知识；大型语言模型的发展为自动化和易用的文本分析带来新契机，但亟需面向初级分析师的友好系统。

Method: 提出新的人机协作工作流，分为拆解（结合人工反馈的蒙特卡洛树搜索算法）、执行（生成可执行的文本分析流程）、评估（结合大语言模型进行评价和可视化），并通过两项定量实验和用户研究测试系统性能和用户行为。

Result: VIDEE系统提升了初学者进行复杂文本分析任务的能力；实验证明其易用性、效果，并揭示了人机合作中用户行为的差异及常见智能体错误。

Conclusion: 研究验证了VIDEE系统对于非专家用户在高阶文本分析任务中的实际效用，并识别了人机协作过程中的设计意义与改进方向。

Abstract: Text analytics has traditionally required specialized knowledge in Natural
Language Processing (NLP) or text analysis, which presents a barrier for
entry-level analysts. Recent advances in large language models (LLMs) have
changed the landscape of NLP by enabling more accessible and automated text
analysis (e.g., topic detection, summarization, information extraction, etc.).
We introduce VIDEE, a system that supports entry-level data analysts to conduct
advanced text analytics with intelligent agents. VIDEE instantiates a
human-agent collaroration workflow consisting of three stages: (1)
Decomposition, which incorporates a human-in-the-loop Monte-Carlo Tree Search
algorithm to support generative reasoning with human feedback, (2) Execution,
which generates an executable text analytics pipeline, and (3) Evaluation,
which integrates LLM-based evaluation and visualizations to support user
validation of execution results. We conduct two quantitative experiments to
evaluate VIDEE's effectiveness and analyze common agent errors. A user study
involving participants with varying levels of NLP and text analytics experience
-- from none to expert -- demonstrates the system's usability and reveals
distinct user behavior patterns. The findings identify design implications for
human-agent collaboration, validate the practical utility of VIDEE for
non-expert users, and inform future improvements to intelligent text analytics
systems.

</details>


### [52] [Hope Speech Detection in code-mixed Roman Urdu tweets: A Positive Turn in Natural Language Processing](https://arxiv.org/abs/2506.21583)
*Muhammad Ahmad,Muhammad Waqas,Ameer Hamza,Ildar Batyrshin,Grigori Sidorov*

Main category: cs.CL

TL;DR: 本文首次提出罗马化乌尔都语希望言论多分类数据集，并开发定制transformer模型XLM-R，在希望言论检测任务中取得最佳表现，推动低资源语种NLP研究。


<details>
  <summary>Details</summary>
Motivation: 现有希望言论检测主要关注高资源语言，忽视了像罗马化乌尔都语这样非正式、混合代码、低资源语种。本文旨在推动包容性的NLP研究，填补这一领域的空白。

Method: 本文提出了基于注意力机制的自定义transformer模型，并结合5折交叉验证和t检验验证结果的统计显著性。

Result: （1）首个罗马化乌尔都语多分类希望语料库；（2）探讨希望的心理学基础和语言表达；（3）提出并验证新模型，XLM-R得分0.78，高于SVM和BiLSTM；（4）实验增益具有统计显著性。

Conclusion: XLM-R模型在罗马化乌尔都语希望言论检测任务中表现最佳，实现了0.78的交叉验证分数，显著优于传统方法。

Abstract: Hope is a positive emotional state involving the expectation of favorable
future outcomes, while hope speech refers to communication that promotes
optimism, resilience, and support, particularly in adverse contexts. Although
hope speech detection has gained attention in Natural Language Processing
(NLP), existing research mainly focuses on high-resource languages and
standardized scripts, often overlooking informal and underrepresented forms
such as Roman Urdu. To the best of our knowledge, this is the first study to
address hope speech detection in code-mixed Roman Urdu by introducing a
carefully annotated dataset, thereby filling a critical gap in inclusive NLP
research for low-resource, informal language varieties. This study makes four
key contributions: (1) it introduces the first multi-class annotated dataset
for Roman Urdu hope speech, comprising Generalized Hope, Realistic Hope,
Unrealistic Hope, and Not Hope categories; (2) it explores the psychological
foundations of hope and analyzes its linguistic patterns in code-mixed Roman
Urdu to inform dataset development; (3) it proposes a custom attention-based
transformer model optimized for the syntactic and semantic variability of Roman
Urdu, evaluated using 5-fold cross-validation; and (4) it verifies the
statistical significance of performance gains using a t-test. The proposed
model, XLM-R, achieves the best performance with a cross-validation score of
0.78, outperforming the baseline SVM (0.75) and BiLSTM (0.76), with gains of 4%
and 2.63% respectively.

</details>


### [53] [Evaluation of LLM-based Strategies for the Extraction of Food Product Information from Online Shops](https://arxiv.org/abs/2506.21585)
*Christoph Brosch,Sian Brumm,Rolf Krieger,Jonas Scheffler*

Main category: cs.CL

TL;DR: 该论文比较了两种基于LLM的网页信息抽取方法，发现通过生成函数的间接抽取法虽然准确率略低，但能极大节省成本和提高效率，为大规模应用提供了有力方案。


<details>
  <summary>Details</summary>
Motivation: 生成式AI和大型语言模型（LLMs）可以自动从网页中提取结构化信息，但在实际应用中需要在准确性、效率和成本之间做权衡。如何在保障准确率的同时，提高自动化抽取的效率和降低成本，是一个有实际意义的问题。

Method: 该研究关注在线零售商的食品产品网页，采用基于schema约束的信息抽取方法，比较了两种基于LLM的抽取方法：直接抽取和通过生成函数的间接抽取，并在一个包含3000个食品页面的数据集上进行比较。评估指标包括准确性、效率和成本。

Result: 间接抽取方法的准确率略低（96.48%，比直接抽取低1.61%），但所需的LLM调用次数减少了95.82%，显著提升了效率并降低了成本。

Conclusion: 对于基于模板的网页信息抽取任务，间接抽取方法能够在几乎不牺牲准确性的前提下，带来更高的可扩展性和成本效益。适合大规模应用场景。

Abstract: Generative AI and large language models (LLMs) offer significant potential
for automating the extraction of structured information from web pages. In this
work, we focus on food product pages from online retailers and explore
schema-constrained extraction approaches to retrieve key product attributes,
such as ingredient lists and nutrition tables. We compare two LLM-based
approaches, direct extraction and indirect extraction via generated functions,
evaluating them in terms of accuracy, efficiency, and cost on a curated dataset
of 3,000 food product pages from three different online shops. Our results show
that although the indirect approach achieves slightly lower accuracy (96.48\%,
$-1.61\%$ compared to direct extraction), it reduces the number of required LLM
calls by 95.82\%, leading to substantial efficiency gains and lower operational
costs. These findings suggest that indirect extraction approaches can provide
scalable and cost-effective solutions for large-scale information extraction
tasks from template-based web pages using LLMs.

</details>


### [54] [Can Vision Language Models Understand Mimed Actions?](https://arxiv.org/abs/2506.21586)
*Hyundong Cho,Spencer Lin,Tejas Srinivasan,Michael Saxon,Deuksin Kwon,Natali T. Chavez,Jonathan May*

Main category: cs.CL

TL;DR: 本文通过提出MIME基准，发现现有视觉-语言模型在哑剧动作识别上显著落后于人类，呼吁对非语言交流理解能力进行更深入研究。


<details>
  <summary>Details</summary>
Motivation: 非语言交流（NVC）在人类语言中非常重要，但由于其范围广泛和个体及文化间理解差异大，因此研究起来具有挑战性。为克服这些挑战，作者选择以‘哑剧’这种低解释方差的NVC子集为切入点。

Method: 本文提出了Mime Identification Multimodal Evaluation (MIME)基准，这是一个基于视频的问题回答测试集，由86个哑剧动作组成。所有动作基于动作捕捉数据，并针对角色、背景、视角进行多样化扰动，评估模型的动作识别鲁棒性。

Result: 实验发现，无论是开源权重的视觉-语言模型还是API型视觉语言模型，在MIME基准上的表现都明显低于人类。

Conclusion: 现有视觉-语言模型无法像人类一样理解哑剧动作，表明这些模型对人类手势和非语言交流的理解依然有限。MIME基准能推动对人类动作和手势更鲁棒理解的研究进展。

Abstract: Nonverbal communication (NVC) plays an integral role in human language, but
studying NVC in general is challenging because of its broad scope and high
variance in interpretation among individuals and cultures. However, mime -- the
theatrical technique of suggesting intent using only gesture, expression, and
movement -- is a subset of NVC that consists of explicit and embodied actions
with much lower human interpretation variance. We argue that a solid
understanding of mimed actions is a crucial prerequisite for vision-language
models capable of interpreting and commanding more subtle aspects of NVC.
Hence, we propose Mime Identification Multimodal Evaluation (MIME), a novel
video-based question answering benchmark comprising of 86 mimed actions.
Constructed with motion capture data, MIME consists of variations of each
action with perturbations applied to the character, background, and viewpoint
for evaluating recognition robustness. We find that both open-weight and
API-based vision-language models perform significantly worse than humans on
MIME, motivating the need for increased research for instilling more robust
understanding of human gestures.

</details>


### [55] [Is DeepSeek a New Voice Among LLMs in Public Opinion Simulation?](https://arxiv.org/abs/2506.21587)
*Weihong Qi,Fan Huang,Jisun An,Haewoon Kwak*

Main category: cs.CL

TL;DR: 本文比较了DeepSeek等开源大模型与主流大模型在中美社会舆论模拟上的表现，发现各模型尤其容易对群体内部观点简化和泛化。DeepSeek-V3在部分议题上表现突出，但在部分群体和话题上仍有局限，论文呼吁改进训练以减少文化和人口统计偏见。


<details>
  <summary>Details</summary>
Motivation: 评估开源大语言模型（如DeepSeek）在模拟公共舆论方面的能力，并与主流大厂开发的LLM模型进行比较，以了解其在中美两国社会问题舆论预测上的表现和偏差。

Method: 将DeepSeek-R1和DeepSeek-V3与Qwen2.5、GPT-4o和Llama-3.3等大厂LLM进行对比，采用美国国家选举研究（ANES）和中国的坐标数据库（Zuobiao）作为调查数据，评估各模型预测中美社会议题公共舆论的能力。具体分析各模型对不同议题（堕胎、气候变化、枪支管控等）的预测效果并进行跨国比较。

Result: DeepSeek-V3在模拟美国堕胎议题的公众观点时表现最佳，尤其是在设定为民主党或自由派身份时预测更为准确；对中国样本，在涉外援助和个人主义议题上表现最佳，但在描述低收入和非大学人群的资本主义观点时表现欠佳。对传统主义和自由市场议题，各模型无显著差异。所有模型均存在在群体内部过度泛化单一观点、回答趋同的问题，尤其在不同人口统计群体内。

Conclusion: 当前开源与大厂的LLM在模拟中美公共舆论时均存在文化及人口统计偏见，易对群体内部观点进行过度泛化，需通过更包容性的训练方法缓解相关偏差。

Abstract: This study evaluates the ability of DeepSeek, an open-source large language
model (LLM), to simulate public opinions in comparison to LLMs developed by
major tech companies. By comparing DeepSeek-R1 and DeepSeek-V3 with Qwen2.5,
GPT-4o, and Llama-3.3 and utilizing survey data from the American National
Election Studies (ANES) and the Zuobiao dataset of China, we assess these
models' capacity to predict public opinions on social issues in both China and
the United States, highlighting their comparative capabilities between
countries. Our findings indicate that DeepSeek-V3 performs best in simulating
U.S. opinions on the abortion issue compared to other topics such as climate
change, gun control, immigration, and services for same-sex couples, primarily
because it more accurately simulates responses when provided with Democratic or
liberal personas. For Chinese samples, DeepSeek-V3 performs best in simulating
opinions on foreign aid and individualism but shows limitations in modeling
views on capitalism, particularly failing to capture the stances of low-income
and non-college-educated individuals. It does not exhibit significant
differences from other models in simulating opinions on traditionalism and the
free market. Further analysis reveals that all LLMs exhibit the tendency to
overgeneralize a single perspective within demographic groups, often defaulting
to consistent responses within groups. These findings highlight the need to
mitigate cultural and demographic biases in LLM-driven public opinion modeling,
calling for approaches such as more inclusive training methodologies.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [56] [Storm Surge in Color: RGB-Encoded Physics-Aware Deep Learning for Storm Surge Forecasting](https://arxiv.org/abs/2506.21743)
*Jinpai Zhao,Albert Cerrone,Eirik Valseth,Leendert Westerink,Clint Dawson*

Main category: cs.CE

TL;DR: 本文通过将风暴潮数据结构化成图像，用ConvLSTM模型实现更准确、可泛化的风暴潮预报，显著优于传统方法，并提升了适应和解释能力。


<details>
  <summary>Details</summary>
Motivation: 目前的风暴潮预报方法，特别是基于机器学习的方法，存在空间分辨率低、依赖近岸站点数据、泛化能力差等问题，且许多模型直接作用于非结构化空间数据，这与现代深度学习架构融合存在障碍。

Method: 本文提出了一种新方法，将非结构化水位场投影到结构化的RGB图像表示上，从而可利用卷积长短时记忆网络（ConvLSTM）进行端到端的时空风暴潮预报。同时，模型集成了真实风场作为动态条件输入，地形与海底地貌作为静态输入，捕捉风暴潮演化的物理驱动因素。

Result: 在美国墨西哥湾合成风暴的大规模数据集上，所提方法在德州沿岸多个区域展现出稳健的48小时预报能力，在空间上对其他沿海区域也具有较强的泛化能力。

Conclusion: 将结构化图像表示、物理强相关条件和可扩展深度学习相结合，显著提升了风暴潮预报的易用性、适应性和可解释性。

Abstract: Storm surge forecasting plays a crucial role in coastal disaster
preparedness, yet existing machine learning approaches often suffer from
limited spatial resolution, reliance on coastal station data, and poor
generalization. Moreover, many prior models operate directly on unstructured
spatial data, making them incompatible with modern deep learning architectures.
In this work, we introduce a novel approach that projects unstructured water
elevation fields onto structured Red Green Blue (RGB)-encoded image
representations, enabling the application of Convolutional Long Short Term
Memory (ConvLSTM) networks for end-to-end spatiotemporal surge forecasting. Our
model further integrates ground-truth wind fields as dynamic conditioning
signals and topo-bathymetry as a static input, capturing physically meaningful
drivers of surge evolution. Evaluated on a large-scale dataset of synthetic
storms in the Gulf of Mexico, our method demonstrates robust 48-hour
forecasting performance across multiple regions along the Texas coast and
exhibits strong spatial extensibility to other coastal areas. By combining
structured representation, physically grounded forcings, and scalable deep
learning, this study advances the frontier of storm surge forecasting in
usability, adaptability, and interpretability.

</details>


### [57] [Laser Scan Path Design for Controlled Microstructure in Additive Manufacturing with Integrated Reduced-Order Phase-Field Modeling and Deep Reinforcement Learning](https://arxiv.org/abs/2506.21815)
*Augustine Twumasi,Prokash Chandra Roy,Zixun Li,Soumya Shouvik Bhattacharjee,Zhengtao Gan*

Main category: cs.CE

TL;DR: 本文将相场物理模拟、3D U-Net深度学习替代模型与强化学习结合，实现了激光选区熔化工艺扫描路径的智能优化，显著提升了预测效率和微结构控制效果，减少了试错成本。


<details>
  <summary>Details</summary>
Motivation: 激光选区熔化（L-PBF）虽然能够高精度制造复杂金属零件，但其复杂的微观结构形成过程影响产品质量，这成为行业亟需破解的难题。

Method: 本文提出了一种结合物理驱动和机器学习的扫描路径优化方法。利用相场法（PFM）模拟晶粒结构演化，并以单道激光不同功率下的相场模拟结果训练3D U-Net卷积神经网络替代模型，用于预测不同扫描路径下的晶粒朝向。进一步，结合深度强化学习（DRL），自动生成优化的激光扫描路径，以实现目标微结构。

Result: 替代3D U-Net模型使微结构预测速度提升约100倍。深度强化学习生成的扫描路径，在多个案例中均展现出优化微结构和缩短开发周期的有效性。强化学习算法在不同规模域下均优于传统锯齿扫描方法，改善了微结构控制和计算效率。

Conclusion: 将物理驱动、深度学习替代模型与强化学习有机结合，可高效优化L-PBF的扫描路径，实现目标微结构，提高L-PBF生产效率与质量控制，为增材制造微结构定向优化提供了新方法。

Abstract: Laser powder bed fusion (L-PBF) is a widely recognized additive manufacturing
technology for producing intricate metal components with exceptional accuracy.
A key challenge in L-PBF is the formation of complex microstructures affecting
product quality. We propose a physics-guided, machine-learning approach to
optimize scan paths for desired microstructure outcomes, such as equiaxed
grains. We utilized a phase-field method (PFM) to model crystalline grain
structure evolution. To reduce computational costs, we trained a surrogate
machine learning model, a 3D U-Net convolutional neural network, using
single-track phase-field simulations with various laser powers to predict
crystalline grain orientations based on initial microstructure and thermal
history. We investigated three scanning strategies across various hatch
spacings within a square domain, achieving a two-orders-of-magnitude speedup
using the surrogate model. To reduce trial and error in designing laser scan
toolpaths, we used deep reinforcement learning (DRL) to generate optimized scan
paths for target microstructure. Results from three cases demonstrate the DRL
approach's effectiveness. We integrated the surrogate 3D U-Net model into our
DRL environment to accelerate the reinforcement learning training process. The
reward function minimizes both aspect ratio and grain volume of the predicted
microstructure from the agent's scan path. The reinforcement learning algorithm
was benchmarked against conventional zigzag approach for smaller and larger
domains, showing machine learning methods' potential to enhance microstructure
control and computational efficiency in L-PBF optimization.

</details>


### [58] [Model-free Forecasting of Rogue Waves using Reservoir Computing](https://arxiv.org/abs/2506.21918)
*Abrari Noor Hasmi,Hadi Susanto*

Main category: cs.CE

TL;DR: 本文首次系统性评估了Reservoir Computing在非线性薛定谔方程等哈密顿系统极端波建模中的有效性，通过并行ESN实现了对测试数据中新动力学的精确预测，并凭借新方法增强了模型的长期自主预测能力，为利用Reservoir Computing处理复杂哈密顿系统问题提供了理论与实验支持。


<details>
  <summary>Details</summary>
Motivation: 虽然Reservoir Computing（储备池计算）在建模各种混沌动力系统方面表现出色，但其在哈密顿系统中的应用还鲜有报道。本文致力于探索其在复杂的哈密顿系统——非线性薛定谔方程（含调制不稳定性与极端波动现象）中的建模能力。

Method: 采用无需模型的Reservoir Computing方法，基于具有五个不稳定模的breather模拟数据训练并调优并行Echo State Network（ESN），评估算法对于两套测试数据（一套为训练数据的延续，一套包含高阶breather新动力学）的短时与较长时间尺度的预测能力，同时提出优化自主预测（autonomous mode）的方法提升长期预测效果。

Result: 优化后的Reservoir Computing模型在一步预测上与测试数据高度一致，并能在未见新动力学出现时实现较长时间尺度的极端波动传播预测。针对自主预测提出的新方法显著提升了模型长期预测的准确性。

Conclusion: 实验结果验证了Reservoir Computing方法在时空哈密顿系统中建模极端动力学的实力，强调了训练数据涵盖相空间的充分性对于预测能力提升的重要性。

Abstract: Recent research has demonstrated Reservoir Computing's capability to model
various chaotic dynamical systems, yet its application to Hamiltonian systems
remains relatively unexplored. This paper investigates the effectiveness of
Reservoir Computing in capturing rogue wave dynamics from the nonlinear
Schr\"{o}dinger equation, a challenging Hamiltonian system with modulation
instability. The model-free approach learns from breather simulations with five
unstable modes. A properly tuned parallel Echo State Network can predict
dynamics from two distinct testing datasets. The first set is a continuation of
the training data, whereas the second set involves a higher-order breather. An
investigation of the one-step prediction capability shows remarkable agreement
between the testing data and the models. Furthermore, we show that the trained
reservoir can predict the propagation of rogue waves over a relatively long
prediction horizon, despite facing unseen dynamics. Finally, we introduce a
method to significantly improve the Reservoir Computing prediction in
autonomous mode, enhancing its long-term forecasting ability. These results
advance the application of Reservoir Computing to spatio-temporal Hamiltonian
systems and highlight the critical importance of phase space coverage in the
design of training data.

</details>


### [59] [A Deep Learning Algorithm Based on CNN-LSTM Framework for Predicting Cancer Drug Sales Volume](https://arxiv.org/abs/2506.21927)
*Yinghan Li,Yilin Yao,Junghua Lin,Nanxi Wang*

Main category: cs.CE

TL;DR: 本文提出并验证了CNN-LSTM混合深度学习模型在癌症药物销量预测中的有效性，能较好处理非线性和波动性数据，可为生产决策和医疗资源管理提供支持。


<details>
  <summary>Details</summary>
Motivation: 针对当前癌症药物需求不断增加，准确预测药品销量对于生产计划、供应链管理和医疗政策至关重要，因此需要有效的时间序列预测方法。

Method: 本研究采用结合卷积神经网络（CNN）和长短期记忆网络（LSTM）的深度学习混合模型（CNN-LSTM），对2015至2024年埃及某癌症药物季度销量数据（包含多维信息）进行建模和预测。模型用CNN提取局部时序特征，用LSTM捕捉长期依赖和趋势。通过MSE和RMSE衡量预测性能。

Result: CNN-LSTM模型在测试集上取得了优异表现，MSE为1.150，RMSE为1.072，显示了其对非线性和波动数据的良好预测能力。

Conclusion: 该研究证实了深度学习CNN-LSTM模型在癌症药物销量预测中的有效性，为医药市场决策和医疗资源规划提供了理论和技术支持。

Abstract: This study explores the application potential of a deep learning model based
on the CNN-LSTM framework in forecasting the sales volume of cancer drugs, with
a focus on modeling complex time series data. As advancements in medical
technology and cancer treatment continue, the demand for oncology medications
is steadily increasing. Accurate forecasting of cancer drug sales plays a
critical role in optimizing production planning, supply chain management, and
healthcare policy formulation. The dataset used in this research comprises
quarterly sales records of a specific cancer drug in Egypt from 2015 to 2024,
including multidimensional information such as date, drug type, pharmaceutical
company, price, sales volume, effectiveness, and drug classification. To
improve prediction accuracy, a hybrid deep learning model combining
Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks
is employed. The CNN component is responsible for extracting local temporal
features from the sales data, while the LSTM component captures long-term
dependencies and trends. Model performance is evaluated using two widely
adopted metrics: Mean Squared Error (MSE) and Root Mean Squared Error (RMSE).
The results demonstrate that the CNN-LSTM model performs well on the test set,
achieving an MSE of 1.150 and an RMSE of 1.072, indicating its effectiveness in
handling nonlinear and volatile sales data. This research provides theoretical
and technical support for data-driven decision-making in pharmaceutical
marketing and healthcare resource planning.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [60] [Shifting Narratives: A Longitudinal Analysis of Media Trends and Public Attitudes on Homelessness](https://arxiv.org/abs/2506.21794)
*Akshay Irudayaraj,Nathan Ye,Yash Chainani*

Main category: cs.CY

TL;DR: 本研究揭示了媒体框架在塑造公众对无家可归者态度上的影响，但这种影响未必直接作用于政策，反映了社会态度与政策之间的脱节。


<details>
  <summary>Details</summary>
Motivation: 无家可归问题在传媒框架研究领域历来关注较少。由于媒体的信息呈现方式会影响公众对无家可归者的态度，而这种态度又影响到无家可归者的就业、住房和资源获取，因此有必要探讨媒体框架如何影响相关社会态度与政策。

Method: 从2015至2023年，选取美国加州、佛州、华盛顿州、俄勒冈州和纽约州，利用GDELT 2.0全球知识图数据库收集新闻报道数据，并用X来测量公众对无家可归者的情感。通过Granger因果检验和向量自回归（VAR）模型考察媒体报道与公众情感的相关性，并用LDA和GPT-3.5（大模型辅助标注）方法进行主题建模和情感分析。此外，还分析了媒体报道与州级立法的关联。

Result: 研究发现，媒体框架与公众情感之间存在统计显著的相关性，尤以无家可归现象严重的州最为显著。但媒体框架与立法之间没有显著相关性，提示公众舆论与政策制定或存脱节现象。

Conclusion: 媒体对无家可归相关议题的报道框架影响了公众的态度，但未能直接影响政策制定，显示出媒体在塑造社会态度和政策之间存在一定的断层。

Abstract: Within the field of media framing, homelessness has been a historically
under-researched topic. Framing theory states that the media's method of
presenting information plays a pivotal role in controlling public sentiment
toward a topic. The sentiment held towards homeless individuals influences
their ability to access jobs, housing, and resources as a result of
discrimination. This study analyzes the topic and sentiment trends in related
media articles to validate framing theory within the scope of homelessness. It
correlates these shifts in media reporting with public sentiment. We examine
state-level trends in California, Florida, Washington, Oregon, and New York
from 2015 to 2023. We utilize the GDELT 2.0 Global Knowledge Graph (GKG)
database to gather article data and use X to measure public sentiment towards
homeless individuals. Additionally, to identify if there is a correlation
between media reporting and public policy, we examine the media's impact on
state-level legislation. Our research uses Granger-causality tests and vector
autoregressive (VAR) models to establish a correlation between media framing
and public sentiment. We also use latent Dirichlet allocation (LDA) and GPT-3.5
(LLM-as-annotator paradigm) for topic modeling and sentiment analysis. Our
findings demonstrate a statistically significant correlation between media
framing and public sentiment, especially in states with high homelessness
rates. We found no significant correlation between media framing and
legislation, suggesting a possible disconnect between public opinion and
policy-making. These findings reveal the broader impact of the media's framing
decisions and delineate its ability to affect society.

</details>


### [61] [The First Compute Arms Race: the Early History of Numerical Weather Prediction](https://arxiv.org/abs/2506.21816)
*Charles Yang*

Main category: cs.CY

TL;DR: 本文回顾了美、英、瑞典、加、日等国数值天气预报发展史，分析了成功的三大要素，为当今利用AI推动国家科学竞争力提供了历史经验和战略参考。


<details>
  <summary>Details</summary>
Motivation: 二战后，全球科技快速发展，早期电子计算机出现，为数值天气预报带来可能。本文旨在梳理数值天气预报在多国发展的历史进程，探索推动其发展的关键因素。

Method: 通过对美国、英国、瑞典、加拿大和日本在数值天气预报早期历史的梳理，比较分析各国在发展过程中依赖的计算能力、机构建设和国家能力以及人才储备等因素。

Result: 文章总结了三大影响国家数值天气预报发展的关键要素：计算能力、机构建设与国家能力、人才。提出了具有可推广性的经验教训，并联系现代国家应用AI加速科学竞争力的战略制定。

Conclusion: 通过多国早期数值天气预报的比较历史分析，指出了打造强大科学技术实力（三大关键因素）的必要性，这对当今制定AI加速科学创新的国家战略具有借鉴意义。

Abstract: This paper traces the global race to apply early electronic computers to
numerical weather prediction in the decades following World War Two. A brief
overview of the early history of numerical weather prediction in the United
States, United Kingdom, Sweden, Canada, and Japan is provided. Three critical
factors that shaped the development of a national numerical weather prediction
are identified: compute capabilities, institution building and state capacity,
and talent. Several generalizable lessons are identified with a lens towards
modern-day development of national strategies to leverage AI to accelerate
scientific competitiveness.

</details>


### [62] [A systematic review of research on large language models for computer programming education](https://arxiv.org/abs/2506.21818)
*Meina Zhu,Lanyu Xu,Barbara Ericson*

Main category: cs.CY

TL;DR: 本文系统综述了大语言模型在计算机编程教育中的应用现状、优势与挑战，提出了未来研究方向，并为实际教学提供了概念框架和建议。


<details>
  <summary>Details</summary>
Motivation: 随着计算机编程教育需求的增加和大语言模型（LLMs）的快速发展，LLMs在编程教育中发挥着重要作用。

Method: 系统性综述2023年到2024年3月发表的有关LLMs在编程教育中应用的实证研究，数据来自Web of Science、SCOPUS、EBSCOhost等数据库及三个专门的编程教育会议论文集。采用文献计量分析、主题分析和结构化主题建模方法对42篇符合标准的文献进行评审。

Result: 总结了LLMs在编程教育中的应用、优势、局限性及相关问题，提出了相关未来研究方向；构建了一个概念框架，为教育实践者整合LLMs于编程教育提供指导，并为教学设计者、教师和学习者提供实践示例和建议。

Conclusion: LLMs已成为编程教育领域的重要工具，为未来研究和实际应用提供了启示和框架，强调跨学科、大规模和纵向的合作研究的重要性。

Abstract: Given the increasing demands in computer programming education and the rapid
advancement of large language models (LLMs), LLMs play a critical role in
programming education. This study provides a systematic review of selected
empirical studies on LLMs in computer programming education, published from
2023 to March 2024. The data for this review were collected from Web of Science
(SCI/SSCI), SCOPUS, and EBSCOhost databases, as well as three conference
proceedings specialized in computer programming education. In total, 42 studies
met the selection criteria and were reviewed using methods, including
bibliometric analysis, thematic analysis, and structural topic modeling. This
study offers an overview of the current state of LLMs in computer programming
education research. It outlines LLMs' applications, benefits, limitations,
concerns, and implications for future research and practices, establishing
connections between LLMs and their practical use in computer programming
education. This review also provides examples and valuable insights for
instructional designers, instructors, and learners. Additionally, a conceptual
framework is proposed to guide education practitioners in integrating LLMs into
computer programming education. This study suggests future research directions
from various perspectives, emphasizing the need to expand research methods and
topics in computer programming education as LLMs evolve. Additionally, future
research in the field should incorporate collaborative, interdisciplinary, and
transdisciplinary efforts on a large scale, focusing on longitudinal research
and development initiatives.

</details>


### [63] [Exploring the change in scientific readability following the release of ChatGPT](https://arxiv.org/abs/2506.21825)
*Abdulkareem Alsudais*

Main category: cs.CY

TL;DR: 作者通过大规模数据分析发现，arXiv论文摘要的可读性近年显著下降，尤其在ChatGPT等AI工具普及后出现明显变化，提示AI正在深刻影响科研写作方式。


<details>
  <summary>Details</summary>
Motivation: 近年来，生成式大语言模型（如ChatGPT）的普及，引发了人们对于其对科学论文写作及发表带来影响的关注。该研究旨在探究在大语言模型广泛可用后，学术论文摘要的可读性是否发生了明显变化。

Method: 作者分析了2010年至2024年6月7日期间所有发布在arXiv.org上的论文摘要，使用四种标准可读性公式为每篇摘要计算可读性得分，并按年份及arXiv的八大主要分类进行聚合分析，重点考察ChatGPT发布前后（2022年11月）可读性的变化。

Result: 结果显示，论文摘要的可读性逐年下降，说明摘要变得更加复杂。更重要的是，ChatGPT发布后，2023年及2024年可读性发生了显著变化，多数学科类别在这两年出现了可读性大变动。

Conclusion: 论文认为，科学论文摘要的可读性近年稳步下降，ChatGPT等AI工具的普及可能加速或影响了这一变化趋势。研究揭示了AI对学术写作风格和复杂度的潜在影响。

Abstract: The rise and growing popularity of accessible large language models have
raised questions about their impact on various aspects of life, including how
scientists write and publish their research. The primary objective of this
paper is to analyze a dataset consisting of all abstracts posted on arXiv.org
between 2010 and June 7th, 2024, to assess the evolution of their readability
and determine whether significant shifts occurred following the release of
ChatGPT in November 2022. Four standard readability formulas are used to
calculate individual readability scores for each paper, classifying their level
of readability. These scores are then aggregated by year and across the eight
primary categories covered by the platform. The results show a steady annual
decrease in readability, suggesting that abstracts are likely becoming
increasingly complex. Additionally, following the release of ChatGPT, a
significant change in readability is observed for 2023 and the analyzed months
of 2024. Similar trends are found across categories, with most experiencing a
notable change in readability during 2023 and 2024. These findings offer
insights into the broader changes in readability and point to the likely
influence of AI on scientific writing.

</details>


### [64] [Hitchhiking Rides Dataset: Two decades of crowd-sourced records on stochastic traveling](https://arxiv.org/abs/2506.21946)
*Till Wenke*

Main category: cs.CY

TL;DR: 本文基于大规模众包数据系统分析了搭便车现象，总结其分布、行为特征及局限，为研究这种另类交通方式提供了坚实数据基础。


<details>
  <summary>Details</summary>
Motivation: 搭便车作为一种自发且去中心化的出行方式，因其非正式性而难以系统研究。作者希望通过数据化手段系统刻画和分析搭便车现象。

Method: 作者收集并分析了全球最大规模的搭便车数据集，涵盖6.3万余条记录，主要来自hitchwiki.org和hitchmap.com，利用众包数据捕捉时空与策略要素，并对数据源、维护方式和社区行为做了详细记录与探索性分析。

Result: 数据集呈现欧洲为中心、强烈季节性、少数高活跃用户为主等特点。分析涉及等车等待时间、用户行为与评论等，反映出搭便车者的真实体验。尽管存在样本偏差和真实性难以验证等局限，数据集仍展现了丰富的另类出行信息。

Conclusion: 该数据集为探究搭便车作为交通实践和文化现象提供了宝贵窗口。未来可继续完善数据集，推动相关学术研究。

Abstract: Hitchhiking, a spontaneous and decentralized mode of travel, has long eluded
systematic study due to its informal nature. This paper presents and analyzes
the largest known structured dataset of hitchhiking rides, comprising over
63,000 entries collected over nearly two decades through platforms associated
with hitchwiki.org and lately on hitchmap.com. By leveraging crowd-sourced
contributions, the dataset captures key spatiotemporal and strategic aspects of
hitchhiking. This work documents the dataset's origins, evolution, and
community-driven maintenance, highlighting its Europe-centric distribution,
seasonal patterns, and reliance on a small number of highly active
contributors. Through exploratory analyses, I examine waiting times, user
behavior, and comment metadata, shedding light on the lived realities of
hitchhikers. While the dataset has inherent biases and limitations - such as
demographic skew and unverifiable entries it offers a rare and valuable window
into an alternative form of mobility. I conclude by outlining future directions
for enriching the dataset and advancing research on hitchhiking as both a
transportation practice and cultural phenomenon.

</details>


### [65] [Public Service Algorithm: towards a transparent, explainable, and scalable content curation for news content based on editorial values](https://arxiv.org/abs/2506.22270)
*Ahmad Mel,Sebastien Noir*

Main category: cs.CY

TL;DR: 本文提出利用大型语言模型（LLMs）结合公共媒体价值观，实现新闻内容的自动化、可扩展与透明筛选，并通过实验验证了LLMs与人类编辑评价的一致性，为可信新闻内容自动筛选提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 虚假信息的泛滥对传统、人工为主的编辑流程和现有以吸引力为优先的自动系统构成挑战，因此需要创新性、可扩展且注重公共服务价值的内容筛选方法。

Method: 提出了一个基于大型语言模型（LLMs）的公共服务算法（PSA）框架，并利用欧洲大型多语种新闻数据集，通过针对四个标准（多样性、深度分析、前瞻性、跨境关联）的定制化提示词，将来自不同欧洲公共服务媒体的编辑专家打分与LLMs打分进行了直接对比评估。

Result: 实验结果显示，LLMs与人类编辑在新闻筛选评价上有良好的一致性，证明LLMs有潜力实现规模化、以价值为导向且透明的内容自动筛选。

Conclusion: LLMs能够在不牺牲透明度的前提下，支持自动化且可扩展的高可信新闻内容筛选，本研究为基于公共服务价值的自动化算法筛选新闻内容提供了新方向。

Abstract: The proliferation of disinformation challenges traditional, unscalable
editorial processes and existing automated systems that prioritize engagement
over public service values. To address this, we introduce the Public Service
Algorithm (PSA), a novel framework using Large Language Models (LLMs) for
scalable, transparent content curation based on Public Service Media (PSM)
inspired values. Utilizing a large multilingual news dataset from the 'A
European Perspective' project, our experiment directly compared article ratings
from a panel of experienced editors from various European PSMs, with those from
several LLMs, focusing on four criteria: diversity, in-depth analysis,
forward-looking, and cross-border relevance. Utilizing criterion-specific
prompts, our results indicate a promising alignment between human editorial
judgment and LLM assessments, demonstrating the potential of LLMs to automate
value-driven curation at scale without sacrificing transparency. This research
constitutes a first step towards a scalable framework for the automatic
curation of trustworthy news content.

</details>
