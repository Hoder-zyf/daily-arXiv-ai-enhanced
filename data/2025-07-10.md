<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 8]
- [cs.CL](#cs.CL) [Total: 30]
- [cs.CE](#cs.CE) [Total: 2]
- [cs.CY](#cs.CY) [Total: 13]
- [q-fin.TR](#q-fin.TR) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Digital Wargames to Enhance Military Medical Evacuation Decision-Making](https://arxiv.org/abs/2507.06373)
*Jeremy Fischer,Ram Krishnamoorthy,Vishal Kumar,Mahdi Al-Husseini*

Main category: cs.AI

TL;DR: 该论文介绍了美国陆军开发的医疗后送兵棋模拟系统MEWI，其通过仿真与实训显著提升了医学后送教育和决策水平，帮助学员提高实战医疗后送能力，是医疗教育高仿真训练领域的重要进展。


<details>
  <summary>Details</summary>
Motivation: 美国陆军医疗后送任务对于战场伤员的快速救治至关重要，但目前缺乏一个能在课堂环境中模拟和评估医疗后送网络及决策表现的平台。该研究旨在填补这一空白，为医疗后送教学和训练提供高保真、高互动性的工具。

Method: 本研究开发了一款三维多人模拟系统——医疗后送兵棋计划（MEWI），利用Unity引擎准确建模了伤员集合点、救护调换点、医疗救治设施和转运平台，并设置了两种典型作战场景（太平洋岛屿两栖进攻与欧亚大陆复杂交通网络）。通过在美国陆军医疗后送学术课程中应用MEWI系统，收集参与者绩效数据与问卷调查反馈，同时结合外部观察员笔记，分析关键决策节点和教学效果。

Result: 结果显示，MEWI的参与者在医疗后送知识吸收、合作决策方面均有显著提升。该系统显著提高了医疗后送教学的高保真度和实战相关性，也为联合部队的医疗后送教育和运作提供了宝贵改进建议。

Conclusion: MEWI为医学教育领域提供了先进的高保真训练工具，显著提升了学生的医疗后送决策能力和教育成效，有助于优化美军及联合部队的医疗后送作业模式及教学流程。该研究为未来类似高仿真医疗教学工具的开发和应用提供了实践案例与理论依据。

Abstract: Medical evacuation is one of the United States Army's most storied and
critical mission sets, responsible for efficiently and expediently evacuating
the battlefield ill and injured. Medical evacuation planning involves designing
a robust network of medical platforms and facilities capable of moving and
treating large numbers of casualties. Until now, there has not been a medium to
simulate these networks in a classroom setting and evaluate both offline
planning and online decision-making performance. This work describes the
Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer
simulation developed in Unity that replicates battlefield constraints and
uncertainties. MEWI accurately models patient interactions at casualty
collection points, ambulance exchange points, medical treatment facilities, and
evacuation platforms. Two operational scenarios are introduced: an amphibious
island assault in the Pacific and a Eurasian conflict across a sprawling road
and river network. These scenarios pit students against the clock to save as
many casualties as possible while adhering to doctrinal lessons learned during
didactic training. We visualize performance data collected from two iterations
of the MEWI Pacific scenario executed in the United States Army's Medical
Evacuation Doctrine Course. We consider post-wargame Likert survey data from
student participants and external observer notes to identify key planning
decision points, document medical evacuation lessons learned, and quantify
general utility. Results indicate that MEWI participation substantially
improves uptake of medical evacuation lessons learned and co-operative
decision-making. MEWI is a substantial step forward in the field of
high-fidelity training tools for medical education, and our study findings
offer critical insights into improving medical evacuation education and
operations across the joint force.

</details>


### [2] [Representing Prompting Patterns with PDL: Compliance Agent Case Study](https://arxiv.org/abs/2507.06396)
*Mandana Vaziri,Louis Mandel,Yuji Watanabe,Hirokuni Kitahara,Martin Hirzel,Anca Sailer*

Main category: cs.AI

TL;DR: 本文提出并验证了PDL，一种面向LLM提示工程的新语言，实现了提示组合与优化，显著提升了复杂智能体开发的效率与性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）的提示工程依然复杂，现有框架要么用严格的API隐藏细节，要么提供难以自定义的模式，使得开发高级智能体程序十分困难。

Method: 提出了一种新的提示表示方式：Prompt Declaration Language（PDL）。PDL将提示显性化，支持人工和自动调优，并可同时整合规则代码和外部工具，实现高级组合抽象。

Result: 在真实合规代理的案例研究中，使用PDL调优后的代理相比于固定模式的代理，性能提升最高可达4倍。

Conclusion: PDL能显著简化提示工程，提升开发效率，并可通过声明式表达优化LLM代理程序。

Abstract: Prompt engineering for LLMs remains complex, with existing frameworks either
hiding complexity behind restrictive APIs or providing inflexible canned
patterns that resist customization -- making sophisticated agentic programming
challenging. We present the Prompt Declaration Language (PDL), a novel approach
to prompt representation that tackles this fundamental complexity by bringing
prompts to the forefront, enabling manual and automatic prompt tuning while
capturing the composition of LLM calls together with rule-based code and
external tools. By abstracting away the plumbing for such compositions, PDL
aims at improving programmer productivity while providing a declarative
representation that is amenable to optimization. This paper demonstrates PDL's
utility through a real-world case study of a compliance agent. Tuning the
prompting pattern of this agent yielded up to 4x performance improvement
compared to using a canned agent and prompt pattern.

</details>


### [3] [Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI](https://arxiv.org/abs/2507.06398)
*David Orban*

Main category: cs.AI

TL;DR: 本文提出、建模并模拟验证了AI能力潜在“跳跃性”增长（超级指数）的理论工具，为未来验证和预测AI/AGI演进提供了方法论基础。


<details>
  <summary>Details</summary>
Motivation: 现有AI发展的增长模式是否呈现加速（超级指数）趋势尚无定论，论文旨在提供可验证假设的理论工具和方法，为理解未来AI甚至AGI的潜在演化轨迹提供研究基础。

Method: 提出理论框架，通过蒙特卡洛模拟验证检测方法的有效性。强调未来需结合长期纵向数据进行实证检验。

Result: 建立了可检测超级指数增长的数学工具，并通过模拟初步验证其可行性。揭示了“想法-行动”时间缩短与AI自我迭代对增长模式的推动作用，强调若假设成立将对研究、政策与AGI发展产生重要意义。

Conclusion: 本研究为AI能力发展的超级指数增长提供了数学基础，并强调了此动态对AGI出现的深远影响，为今后的研究与政策提供了新视角。

Abstract: This paper investigates the Jolting Technologies Hypothesis, which posits
superexponential growth (increasing acceleration, or a positive third
derivative) in the development of AI capabilities. We develop a theoretical
framework and validate detection methodologies through Monte Carlo simulations,
while acknowledging that empirical validation awaits suitable longitudinal
data. Our analysis focuses on creating robust tools for future empirical
studies and exploring the potential implications should the hypothesis prove
valid. The study examines how factors such as shrinking idea-to-action
intervals and compounding iterative AI improvements drive this jolting pattern.
By formalizing jolt dynamics and validating detection methods through
simulation, this work provides the mathematical foundation necessary for
understanding potential AI trajectories and their consequences for AGI
emergence, offering insights for research and policy.

</details>


### [4] [Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)](https://arxiv.org/abs/2507.06798)
*Uri Andrews,Luca San Mauro*

Main category: cs.AI

TL;DR: 本论文解决了辨证系统领域的一个开放性问题：严格证明了q-辨证系统的能力大于p-辨证系统，后者又大于d-辨证系统，从而揭示了在自动化信念修正中，反例与矛盾机制的互补与重要性。


<details>
  <summary>Details</summary>
Motivation: 该论文关注于解决一个长期存在的开放性问题：不同类型的辨证系统在知识修正与更新中的理论能力比较，特别是q-辨证系统与p-辨证系统之间的关系。辨证系统最初是为了模拟数学家或研究团体在追求真理过程中如何修正和完善信念提出的。

Method: 论文通过理论证明的方法，分析和描述了三类辨证系统（d-辨证、p-辨证和q-辨证系统）的结构与操作机制，重点证明了q-辨证系统在能力上严格超越p-辨证系统。

Result: 作者首次证明了q-辨证系统在推理和信念修正的能力上严格强于p-辨证系统，而后者又已知强于最基础的d-辨证系统。这一结论揭示了反例（counterexample）与矛盾（contradiction）在自动信念修正过程中的互补作用。

Conclusion: q-辨证系统在动态信念管理和自动推理方面具备更强的表达与修正能力，能够更全面地模拟数学家和学术共同体的推理过程。

Abstract: Dialectical systems are a mathematical formalism for modeling an agent
updating a knowledge base seeking consistency. Introduced in the 1970s by
Roberto Magari, they were originally conceived to capture how a working
mathematician or a research community refines beliefs in the pursuit of truth.
Dialectical systems also serve as natural models for the belief change of an
automated agent, offering a unifying, computable framework for dynamic belief
management.
  The literature distinguishes three main models of dialectical systems:
(d-)dialectical systems based on revising beliefs when they are seen to be
inconsistent, p-dialectical systems based on revising beliefs based on finding
a counterexample, and q-dialectical systems which can do both. We answer an
open problem in the literature by proving that q-dialectical systems are
strictly more powerful than p-dialectical systems, which are themselves known
to be strictly stronger than (d-)dialectical systems. This result highlights
the complementary roles of counterexample and contradiction in automated belief
revision, and thus also in the reasoning processes of mathematicians and
research communities.

</details>


### [5] [SCC-recursiveness in infinite argumentation (extended version)](https://arxiv.org/abs/2507.06852)
*Uri Andrews,Luca San Mauro*

Main category: cs.AI

TL;DR: 本文针对现有SCC递归语义难以推广至无限AF的问题，提出两种扩展方法并系统评价，发现新方法在一定条件下具有方向性，为构建能处理无限或演化领域的推理系统提供了新的理论基础。


<details>
  <summary>Details</summary>
Motivation: 传统的SCC递归语义在有限辩论框架（AFs）中非常有效，但Baumann和Spanring指出将其直接应用到无限AFs时会遇到基础性问题，无法可靠推广。因此，有必要探索适用于无限辩论框架的新方法。

Method: 提出并系统性地评估了两种将SCC递归性扩展到无限AF的方案，采用Baroni和Giacomin的语义评判标准对新方案进行分析与比较，重点考察了方向性（directionality）等属性。

Result: 发现在无限AF中，现有的方向性等性质通常无法保持，但在特定的有限性（如finitary frameworks）下，部分新提方案能够满足方向性。

Conclusion: 本文提出的扩展方法丰富了无限AF的理论基础，为未来处理无界或动态领域的推理系统奠定了理论基础。

Abstract: Argumentation frameworks (AFs) are a foundational tool in artificial
intelligence for modeling structured reasoning and conflict. SCC-recursiveness
is a well-known design principle in which the evaluation of arguments is
decomposed according to the strongly connected components (SCCs) of the attack
graph, proceeding recursively from "higher" to "lower" components. While
SCC-recursive semantics such as \cft and \stgt have proven effective for finite
AFs, Baumann and Spanring showed the failure of SCC-recursive semantics to
generalize reliably to infinite AFs due to issues with well-foundedness.
  We propose two approaches to extending SCC-recursiveness to the infinite
setting. We systematically evaluate these semantics using Baroni and Giacomin's
established criteria, showing in particular that directionality fails in
general. We then examine these semantics' behavior in finitary frameworks,
where we find some of our semantics satisfy directionality. These results
advance the theory of infinite argumentation and lay the groundwork for
reasoning systems capable of handling unbounded or evolving domains.

</details>


### [6] [Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report](https://arxiv.org/abs/2507.06968)
*Li Du,Hanyu Zhao,Yiming Ju,Tengfei Pan*

Main category: cs.AI

TL;DR: 本文提出了系统化的指令数据集扩展方法，有效提升了大模型在复杂及冷门任务上的表现，并构建了高质量数据集InfinityInstruct-Subject，为指令数据发展指明了方向。


<details>
  <summary>Details</summary>
Motivation: 当前指令微调作为提升大模型能力的关键方式，然而现有指令数据集无论在涵盖领域（coverage）还是指令复杂性（depth）上都存在不足，导致模型在处理复杂任务和罕见领域任务时表现有限。

Method: 作者提出了一个系统化的指令数据构建框架，包括分层标注体系、信息化种子选择算法、演化式数据合成流程，以及基于模型薄弱点的有针对性数据生成，并以闭环迭代的方式持续提升数据集的覆盖度和深度。

Result: 基于上述框架，作者构建了InfinityInstruct-Subject数据集，包含约150万条高质量指令。实验表明，该数据集能够有效提升基础模型的指令遵循与复杂任务能力，并在覆盖度和深度上超越同类合成数据集。

Conclusion: 本工作为高效、持续演化的指令数据集建设提供了理论和实践基础，实现了从数量扩张向质量提升的跃迁。

Abstract: Instruction tuning has become a foundation for unlocking the capabilities of
large-scale pretrained models and improving their performance on complex tasks.
Thus, the construction of high-quality instruction datasets is crucial for
enhancing model performance and generalizability. Although current instruction
datasets have reached tens of millions of samples, models finetuned on them may
still struggle with complex instruction following and tasks in rare domains.
This is primarily due to limited expansion in both ``coverage'' (coverage of
task types and knowledge areas) and ``depth'' (instruction complexity) of the
instruction set. To address this issue, we propose a systematic instruction
data construction framework, which integrates a hierarchical labeling system,
an informative seed selection algorithm, an evolutionary data synthesis
process, and a model deficiency diagnosis with targeted data generation. These
components form an iterative closed-loop to continuously enhance the coverage
and depth of instruction data. Based on this framework, we construct
InfinityInstruct-Subject, a high-quality dataset containing ~1.5 million
instructions. Experiments on multiple foundation models and benchmark tasks
demonstrate its effectiveness in improving instruction-following capabilities.
Further analyses suggest that InfinityInstruct-Subject shows enlarged coverage
and depth compared to comparable synthesized instruction datasets. Our work
lays a theoretical and practical foundation for the efficient, continuous
evolution of instruction datasets, moving from data quantity expansion to
qualitative improvement.

</details>


### [7] [The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation](https://arxiv.org/abs/2507.06993)
*Jieren Deng,Aleksandar Cvetkovic,Pak Kiu Chung,Dragomir Yankov,Chiqun Zhang*

Main category: cs.AI

TL;DR: 针对传统旅游系统在智能规划、末端导航和动态调整方面的不足，本文提出三智能体系统显著提升了复杂查询理解、导航精度和应对行程意外的能力，增强了用户体验。


<details>
  <summary>Details</summary>
Motivation: 传统的旅游规划系统存在静态和割裂的问题，难以应对环境变化和行程干扰，影响用户体验。现有系统在智能规划、末端导航、动态调整方面存在空白。

Method: 提出三个协作智能体：旅行规划智能体（借助网格化空间基础与地图分析处理多模态查询）、目的地助手智能体（精细化引导用户完成最后一段路线）、本地发现智能体（利用图像嵌入与RAG技术应对突发变动）。

Result: 系统在查询解释、导航精度及应对行程中断能力上都有显著提升。

Conclusion: 所提系统显著改善了旅行中智能规划、末端导航和动态调整的能力，能够实际应用于城市探索和应急响应等场景。

Abstract: Traditional travel-planning systems are often static and fragmented, leaving
them ill-equipped to handle real-world complexities such as evolving
environmental conditions and unexpected itinerary disruptions. In this paper,
we identify three gaps between existing service providers causing frustrating
user experience: intelligent trip planning, precision "last-100-meter"
navigation, and dynamic itinerary adaptation. We propose three cooperative
agents: a Travel Planning Agent that employs grid-based spatial grounding and
map analysis to help resolve complex multi-modal user queries; a Destination
Assistant Agent that provides fine-grained guidance for the final navigation
leg of each journey; and a Local Discovery Agent that leverages image
embeddings and Retrieval-Augmented Generation (RAG) to detect and respond to
trip plan disruptions. With evaluations and experiments, our system
demonstrates substantial improvements in query interpretation, navigation
accuracy, and disruption resilience, underscoring its promise for applications
from urban exploration to emergency response.

</details>


### [8] [First Return, Entropy-Eliciting Explore](https://arxiv.org/abs/2507.07017)
*Tianyu Zheng,Tianshun Xing,Qingshui Gu,Taoran Liang,Xingwei Qu,Xin Zhou,Yizhi Li,Zhoufutu Wen,Chenghua Lin,Wenhao Huang,Qian Liu,Ge Zhang,Zejun Ma*

Main category: cs.AI

TL;DR: 本文提出了一种新的结构化探索框架 FR3E，通过识别高不确定性的推理决策点并进行有针对性的rollout，解决了RLVR训练过程中的不稳定问题，在数学推理任务上显著提升了LLM的表现，训练更稳定、输出更优质。


<details>
  <summary>Details</summary>
Motivation: 现有的可验证奖励强化学习（RLVR）虽然能提升大型语言模型（LLM）的推理能力，但在探索阶段存在不稳定的问题。作者希望通过改进探索策略，促进更稳定和有效的训练过程。

Method: 提出FR3E框架（First Return, Entropy-Eliciting Explore），该方法在推理轨迹中识别高不确定性的决策点，并对这些点进行有针对性的rollout，生成有语义基础的中间反馈，无需依赖密集监督。

Result: 在数学推理基准测试（AIME24）上，FR3E带来更稳定的训练，生成更长且更连贯的回答，提高了完全正确推理轨迹的比例。

Conclusion: FR3E通过结构化的探索，有效增强了LLM的推理表现，表明稳健有针对性的探索策略对提升模型能力有重要作用。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning
abilities of Large Language Models (LLMs) but it struggles with unstable
exploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a
structured exploration framework that identifies high-uncertainty decision
points in reasoning trajectories and performs targeted rollouts to construct
semantically grounded intermediate feedback. Our method provides targeted
guidance without relying on dense supervision. Empirical results on
mathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable
training, produces longer and more coherent responses, and increases the
proportion of fully correct trajectories. These results highlight the
framework's effectiveness in improving LLM reasoning through more robust and
structured exploration.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [9] [Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities](https://arxiv.org/abs/2507.06261)
*Gheorghe Comanici,Eric Bieber,Mike Schaekermann,Ice Pasupat,Noveen Sachdeva,Inderjit Dhillon,Marcel Blistein,Ori Ram,Dan Zhang,Evan Rosen,Luke Marris,Sam Petulla,Colin Gaffney,Asaf Aharoni,Nathan Lintz,Tiago Cardal Pais,Henrik Jacobsson,Idan Szpektor,Nan-Jiang Jiang,Krishna Haridasan,Ahmed Omran,Nikunj Saunshi,Dara Bahri,Gaurav Mishra,Eric Chu,Toby Boyd,Brad Hekman,Aaron Parisi,Chaoyi Zhang,Kornraphop Kawintiranon,Tania Bedrax-Weiss,Oliver Wang,Ya Xu,Ollie Purkiss,Uri Mendlovic,Ilaï Deutel,Nam Nguyen,Adam Langley,Flip Korn,Lucia Rossazza,Alexandre Ramé,Sagar Waghmare,Helen Miller,Vaishakh Keshava,Ying Jian,Xiaofan Zhang,Raluca Ada Popa,Kedar Dhamdhere,Blaž Bratanič,Kyuyeun Kim,Terry Koo,Ferran Alet,Yi-ting Chen,Arsha Nagrani,Hannah Muckenhirn,Zhiyuan Zhang,Corbin Quick,Filip Pavetić,Duc Dung Nguyen,Joao Carreira,Michael Elabd,Haroon Qureshi,Fabian Mentzer,Yao-Yuan Yang,Danielle Eisenbud,Anmol Gulati,Ellie Talius,Eric Ni,Sahra Ghalebikesabi,Edouard Yvinec,Alaa Saade,Thatcher Ulrich,Lorenzo Blanco,Dan A. Calian,Muhuan Huang,Aäron van den Oord,Naman Goyal,Terry Chen,Praynaa Rawlani,Christian Schallhart,Swachhand Lokhande,Xianghong Luo,Jyn Shan,Ceslee Montgomery,Victoria Krakovna,Federico Piccinini,Omer Barak,Jingyu Cui,Yiling Jia,Mikhail Dektiarev,Alexey Kolganov,Shiyu Huang,Zhe Chen,Xingyu Wang,Jessica Austin,Peter de Boursac,Evgeny Sluzhaev,Frank Ding,Huijian Li,Surya Bhupatiraju,Mohit Agarwal,Sławek Kwasiborski,Paramjit Sandhu,Patrick Siegler,Ahmet Iscen,Eyal Ben-David,Shiraz Butt,Miltos Allamanis,Seth Benjamin,Robert Busa-Fekete,Felix Hernandez-Campos,Sasha Goldshtein,Matt Dibb,Weiyang Zhang,Annie Marsden,Carey Radebaugh,Stephen Roller,Abhishek Nayyar,Jacob Austin,Tayfun Terzi,Bhargav Kanagal Shamanna,Pete Shaw,Aayush Singh,Florian Luisier,Artur Mendonça,Vaibhav Aggarwal,Larisa Markeeva,Claudio Fantacci,Sergey Brin,HyunJeong Choe,Guanyu Wang,Hartwig Adam,Avigail Dabush,Tatsuya Kiyono,Eyal Marcus,Jeremy Cole,Theophane Weber,Hongrae Lee,Ronny Huang,Alex Muzio,Leandro Kieliger,Maigo Le,Courtney Biles,Long Le,Archit Sharma,Chengrun Yang,Avery Lamp,Dave Dopson,Nate Hurley,Katrina,Xu,Zhihao Shan,Shuang Song,Jiewen Tan,Alexandre Senges,George Zhang,Chong You,Yennie Jun,David Raposo,Susanna Ricco,Xuan Yang,Weijie Chen,Prakhar Gupta,Arthur Szlam,Kevin Villela,Chun-Sung Ferng,Daniel Kasenberg,Chen Liang,Rui Zhu,Arunachalam Narayanaswamy,Florence Perot,Paul Pucciarelli,Anna Shekhawat,Alexey Stern,Rishikesh Ingale,Stefani Karp,Sanaz Bahargam,Adrian Goedeckemeyer,Jie Han,Sicheng Li,Andrea Tacchetti,Dian Yu,Abhishek Chakladar,Zhiying Zhang,Mona El Mahdy,Xu Gao,Dale Johnson,Samrat Phatale,AJ Piergiovanni,Hyeontaek Lim,Clement Farabet,Carl Lebsack,Theo Guidroz,John Blitzer,Nico Duduta,David Madras,Steve Li,Daniel von Dincklage,Xin Li,Mahdis Mahdieh,George Tucker,Ganesh Jawahar,Owen Xiao,Danny Tarlow,Robert Geirhos,Noam Velan,Daniel Vlasic,Kalesha Bullard,SK Park,Nishesh Gupta,Kellie Webster,Ayal Hitron,Jieming Mao,Julian Eisenschlos,Laurel Prince,Nina D'Souza,Kelvin Zheng,Sara Nasso,Gabriela Botea,Carl Doersch,Caglar Unlu,Chris Alberti,Alexey Svyatkovskiy,Ankita Goel,Krzysztof Choromanski,Pan-Pan Jiang,Richard Nguyen,Four Flynn,Daria Ćurko,Peter Chen,Nicholas Roth,Kieran Milan,Caleb Habtegebriel,Shashi Narayan,Michael Moffitt,Jake Marcus,Thomas Anthony,Brendan McMahan,Gowoon Cheon,Ruibo Liu,Megan Barnes,Lukasz Lew,Rebeca Santamaria-Fernandez,Mayank Upadhyay,Arjun Akula,Arnar Mar Hrafnkelsson,Alvaro Caceres,Andrew Bunner,Michal Sokolik,Subha Puttagunta,Lawrence Moore,Berivan Isik,Weilun Chen,Jay Hartford,Lawrence Chan,Pradeep Shenoy,Dan Holtmann-Rice,Jane Park,Fabio Viola,Alex Salcianu,Sujeevan Rajayogam,Ian Stewart-Binks,Zelin Wu,Richard Everett,Xi Xiong,Pierre-Antoine Manzagol,Gary Leung,Carl Saroufim,Bo Pang,Dawid Wegner,George Papamakarios,Jennimaria Palomaki,Helena Pankov,Guangda Lai,Guilherme Tubone,Shubin Zhao,Theofilos Strinopoulos,Seth Neel,Mingqiu Wang,Joe Kelley,Li Li,Pingmei Xu,Anitha Vijayakumar,Andrea D'olimpio,Omer Levy,Massimo Nicosia,Grigory Rozhdestvenskiy,Ni Lao,Sirui Xie,Yash Katariya,Jon Simon,Sanjiv Kumar,Florian Hartmann,Michael Kilgore,Jinhyuk Lee,Aroma Mahendru,Roman Ring,Tom Hennigan,Fiona Lang,Colin Cherry,David Steiner,Dawsen Hwang,Ray Smith,Pidong Wang,Jeremy Chen,Ming-Hsuan Yang,Sam Kwei,Philippe Schlattner,Donnie Kim,Ganesh Poomal Girirajan,Nikola Momchev,Ayushi Agarwal,Xingyi Zhou,Ilkin Safarli,Zachary Garrett,AJ Pierigiovanni,Sarthak Jauhari,Alif Raditya Rochman,Shikhar Vashishth,Quan Yuan,Christof Angermueller,Jon Blanton,Xinying Song,Nitesh Bharadwaj Gundavarapu,Thi Avrahami,Maxine Deines,Subhrajit Roy,Manish Gupta,Christopher Semturs,Shobha Vasudevan,Aditya Srikanth Veerubhotla,Shriya Sharma,Josh Jacob,Zhen Yang,Andreas Terzis,Dan Karliner,Auriel Wright,Tania Rojas-Esponda,Ashley Brown,Abhijit Guha Roy,Pawan Dogra,Andrei Kapishnikov,Peter Young,Wendy Kan,Vinodh Kumar Rajendran,Maria Ivanova,Salil Deshmukh,Chia-Hua Ho,Mike Kwong,Stav Ginzburg,Annie Louis,KP Sawhney,Slav Petrov,Jing Xie,Yunfei Bai,Georgi Stoyanov,Alex Fabrikant,Rajesh Jayaram,Yuqi Li,Joe Heyward,Justin Gilmer,Yaqing Wang,Radu Soricut,Luyang Liu,Qingnan Duan,Jamie Hayes,Maura O'Brien,Gaurav Singh Tomar,Sivan Eiger,Bahar Fatemi,Jeffrey Hui,Catarina Barros,Adaeze Chukwuka,Alena Butryna,Saksham Thakur,Austin Huang,Zhufeng Pan,Haotian Tang,Serkan Cabi,Tulsee Doshi,Michiel Bakker,Sumit Bagri,Ruy Ley-Wild,Adam Lelkes,Jennie Lees,Patrick Kane,David Greene,Shimu Wu,Jörg Bornschein,Gabriela Surita,Sarah Hodkinson,Fangtao Li,Chris Hidey,Sébastien Pereira,Sean Ammirati,Phillip Lippe,Adam Kraft,Pu Han,Sebastian Gerlach,Zifeng Wang,Liviu Panait,Feng Han,Brian Farris,Yingying Bi,Hannah DeBalsi,Miaosen Wang,Gladys Tyen,James Cohan,Susan Zhang,Jarred Barber,Da-Woon Chung,Jaeyoun Kim,Markus Kunesch,Steven Pecht,Nami Akazawa,Abe Friesen,James Lyon,Ali Eslami,Junru Wu,Jie Tan,Yue Song,Ravi Kumar,Chris Welty,Ilia Akolzin,Gena Gibson,Sean Augenstein,Arjun Pillai,Nancy Yuen,Du Phan,Xin Wang,Iain Barr,Heiga Zen,Nan Hua,Casper Liu,Jilei,Wang,Tanuj Bhatia,Hao Xu,Oded Elyada,Pushmeet Kohli,Mirek Olšák,Ke Chen,Azalia Mirhoseini,Noam Shazeer,Shoshana Jakobovits,Maggie Tran,Nolan Ramsden,Tarun Bharti,Fred Alcober,Yunjie Li,Shilpa Shetty,Jing Chen,Dmitry Kalashnikov,Megha Nawhal,Sercan Arik,Hanwen Chen,Michiel Blokzijl,Shubham Gupta,James Rubin,Rigel Swavely,Sophie Bridgers,Ian Gemp,Chen Su,Arun Suggala,Juliette Pluto,Mary Cassin,Alain Vaucher,Kaiyang Ji,Jiahao Cai,Andrew Audibert,Animesh Sinha,David Tian,Efrat Farkash,Amy Hua,Jilin Chen,Duc-Hieu Tran,Edward Loper,Nicole Brichtova,Lara McConnaughey,Ballie Sandhu,Robert Leland,Doug DeCarlo,Andrew Over,James Huang,Xing Wu,Connie Fan,Eric Li,Yun Lei,Deepak Sharma,Cosmin Paduraru,Luo Yu,Matko Bošnjak,Phuong Dao,Min Choi,Sneha Kudugunta,Jakub Adamek,Carlos Guía,Ali Khodaei,Jie Feng,Wenjun Zeng,David Welling,Sandeep Tata,Christina Butterfield,Andrey Vlasov,Seliem El-Sayed,Swaroop Mishra,Tara Sainath,Shentao Yang,RJ Skerry-Ryan,Jeremy Shar,Robert Berry,Arunkumar Rajendran,Arun Kandoor,Andrea Burns,Deepali Jain,Tom Stone,Wonpyo Park,Shibo Wang,Albin Cassirer,Guohui Wang,Hayato Kobayashi,Sergey Rogulenko,Vineetha Govindaraj,Mikołaj Rybiński,Nadav Olmert,Colin Evans,Po-Sen Huang,Kelvin Xu,Premal Shah,Terry Thurk,Caitlin Sikora,Mu Cai,Jin Xie,Elahe Dabir,Saloni Shah,Norbert Kalb,Carrie Zhang,Shruthi Prabhakara,Amit Sabne,Artiom Myaskovsky,Vikas Raunak,Blanca Huergo,Behnam Neyshabur,Jon Clark,Ye Zhang,Shankar Krishnan,Eden Cohen,Dinesh Tewari,James Lottes,Yumeya Yamamori,Hui,Li,Mohamed Elhawaty,Ada Maksutaj Oflazer,Adrià Recasens,Sheryl Luo,Duy Nguyen,Taylor Bos,Kalyan Andra,Ana Salazar,Ed Chi,Jeongwoo Ko,Matt Ginsberg,Anders Andreassen,Anian Ruoss,Todor Davchev,Elnaz Davoodi,Chenxi Liu,Min Kim,Santiago Ontanon,Chi Ming To,Dawei Jia,Rosemary Ke,Jing Wang,Anna Korsun,Moran Ambar,Ilya Kornakov,Irene Giannoumis,Toni Creswell,Denny Zhou,Yi Su,Ishaan Watts,Aleksandr Zaks,Evgenii Eltyshev,Ziqiang Feng,Sidharth Mudgal,Alex Kaskasoli,Juliette Love,Kingshuk Dasgupta,Sam Shleifer,Richard Green,Sungyong Seo,Chansoo Lee,Dale Webster,Prakash Shroff,Ganna Raboshchuk,Isabel Leal,James Manyika,Sofia Erell,Daniel Murphy,Zhisheng Xiao,Anton Bulyenov,Julian Walker,Mark Collier,Matej Kastelic,Nelson George,Sushant Prakash,Sailesh Sidhwani,Alexey Frolov,Steven Hansen,Petko Georgiev,Tiberiu Sosea,Chris Apps,Aishwarya Kamath,David Reid,Emma Cooney,Charlotte Magister,Oriana Riva,Alec Go,Pu-Chin Chen,Sebastian Krause,Nir Levine,Marco Fornoni,Ilya Figotin,Nick Roy,Parsa Mahmoudieh,Vladimir Magay,Mukundan Madhavan,Jin Miao,Jianmo Ni,Yasuhisa Fujii,Ian Chou,George Scrivener,Zak Tsai,Siobhan Mcloughlin,Jeremy Selier,Sandra Lefdal,Jeffrey Zhao,Abhijit Karmarkar,Kushal Chauhan,Shivanker Goel,Zhaoyi Zhang,Vihan Jain,Parisa Haghani,Mostafa Dehghani,Jacob Scott,Erin Farnese,Anastasija Ilić,Steven Baker,Julia Pawar,Li Zhong,Josh Camp,Yoel Zeldes,Shravya Shetty,Anand Iyer,Vít Listík,Jiaxian Guo,Luming Tang,Mark Geller,Simon Bucher,Yifan Ding,Hongzhi Shi,Carrie Muir,Dominik Grewe,Ramy Eskander,Octavio Ponce,Boqing Gong,Derek Gasaway,Samira Khan,Umang Gupta,Angelos Filos,Weicheng Kuo,Klemen Kloboves,Jennifer Beattie,Christian Wright,Leon Li,Alicia Jin,Sandeep Mariserla,Miteyan Patel,Jens Heitkaemper,Dilip Krishnan,Vivek Sharma,David Bieber,Christian Frank,John Lambert,Paul Caron,Martin Polacek,Mai Giménez,Himadri Choudhury,Xing Yu,Sasan Tavakkol,Arun Ahuja,Franz Och,Rodolphe Jenatton,Wojtek Skut,Bryan Richter,David Gaddy,Andy Ly,Misha Bilenko,Megh Umekar,Ethan Liang,Martin Sevenich,Mandar Joshi,Hassan Mansoor,Rebecca Lin,Sumit Sanghai,Abhimanyu Singh,Xiaowei Li,Sudheendra Vijayanarasimhan,Zaheer Abbas,Yonatan Bitton,Hansa Srinivasan,Manish Reddy Vuyyuru,Alexander Frömmgen,Yanhua Sun,Ralph Leith,Alfonso Castaño,DJ Strouse,Le Yan,Austin Kyker,Satish Kambala,Mary Jasarevic,Thibault Sellam,Chao Jia,Alexander Pritzel,Raghavender R,Huizhong Chen,Natalie Clay,Sudeep Gandhe,Sean Kirmani,Sayna Ebrahimi,Hannah Kirkwood,Jonathan Mallinson,Chao Wang,Adnan Ozturel,Kuo Lin,Shyam Upadhyay,Vincent Cohen-Addad,Sean Purser-haskell,Yichong Xu,Ebrahim Songhori,Babi Seal,Alberto Magni,Almog Gueta,Tingting Zou,Guru Guruganesh,Thais Kagohara,Hung Nguyen,Khalid Salama,Alejandro Cruzado Ruiz,Justin Frye,Zhenkai Zhu,Matthias Lochbrunner,Simon Osindero,Wentao Yuan,Lisa Lee,Aman Prasad,Lam Nguyen Thiet,Daniele Calandriello,Victor Stone,Qixuan Feng,Han Ke,Maria Voitovich,Geta Sampemane,Lewis Chiang,Ling Wu,Alexander Bykovsky,Matt Young,Luke Vilnis,Ishita Dasgupta,Aditya Chawla,Qin Cao,Bowen Liang,Daniel Toyama,Szabolcs Payrits,Anca Stefanoiu,Dimitrios Vytiniotis,Ankesh Anand,Tianxiao Shen,Blagoj Mitrevski,Michael Tschannen,Sreenivas Gollapudi,Aishwarya P S,José Leal,Zhe Shen,Han Fu,Wei Wang,Arvind Kannan,Doron Kukliansky,Sergey Yaroshenko,Svetlana Grant,Umesh Telang,David Wood,Alexandra Chronopoulou,Alexandru Ţifrea,Tao Zhou,Tony,Nguy\~ên,Muge Ersoy,Anima Singh,Meiyan Xie,Emanuel Taropa,Woohyun Han,Eirikur Agustsson,Andrei Sozanschi,Hui Peng,Alex Chen,Yoel Drori,Efren Robles,Yang Gao,Xerxes Dotiwalla,Ying Chen,Anudhyan Boral,Alexei Bendebury,John Nham,Chris Tar,Luis Castro,Jiepu Jiang,Canoee Liu,Felix Halim,Jinoo Baek,Andy Wan,Jeremiah Liu,Yuan Cao,Shengyang Dai,Trilok Acharya,Ruoxi Sun,Fuzhao Xue,Saket Joshi,Morgane Lustman,Yongqin Xian,Rishabh Joshi,Deep Karkhanis,Nora Kassner,Jamie Hall,Xiangzhuo Ding,Gan Song,Gang Li,Chen Zhu,Yana Kulizhskaya,Bin Ni,Alexey Vlaskin,Solomon Demmessie,Lucio Dery,Salah Zaiem,Yanping Huang,Cindy Fan,Felix Gimeno,Ananth Balashankar,Koji Kojima,Hagai Taitelbaum,Maya Meng,Dero Gharibian,Sahil Singla,Wei Chen,Ambrose Slone,Guanjie Chen,Sujee Rajayogam,Max Schumacher,Suyog Kotecha,Rory Blevins,Qifei Wang,Mor Hazan Taege,Alex Morris,Xin Liu,Fayaz Jamil,Richard Zhang,Pratik Joshi,Ben Ingram,Tyler Liechty,Ahmed Eleryan,Scott Baird,Alex Grills,Gagan Bansal,Shan Han,Kiran Yalasangi,Shawn Xu,Majd Al Merey,Isabel Gao,Felix Weissenberger,Igor Karpov,Robert Riachi,Ankit Anand,Gautam Prasad,Kay Lamerigts,Reid Hayes,Jamie Rogers,Mandy Guo,Ashish Shenoy,Qiong,Hu,Kyle He,Yuchen Liu,Polina Zablotskaia,Sagar Gubbi,Yifan Chang,Jay Pavagadhi,Kristian Kjems,Archita Vadali,Diego Machado,Yeqing Li,Renshen Wang,Dipankar Ghosh,Aahil Mehta,Dana Alon,George Polovets,Alessio Tonioni,Nate Kushman,Joel D'sa,Lin Zhuo,Allen Wu,Rohin Shah,John Youssef,Jiayu Ye,Justin Snyder,Karel Lenc,Senaka Buthpitiya,Matthew Tung,Jichuan Chang,Tao Chen,David Saxton,Jenny Lee,Lydia Lihui Zhang,James Qin,Prabakar Radhakrishnan,Maxwell Chen,Piotr Ambroszczyk,Metin Toksoz-Exley,Yan Zhong,Nitzan Katz,Brendan O'Donoghue,Tamara von Glehn,Adi Gerzi Rosenthal,Aga Świetlik,Xiaokai Zhao,Nick Fernando,Jinliang Wei,Jieru Mei,Sergei Vassilvitskii,Diego Cedillo,Pranjal Awasthi,Hui Zheng,Koray Kavukcuoglu,Itay Laish,Joseph Pagadora,Marc Brockschmidt,Christopher A. Choquette-Choo,Arunkumar Byravan,Yifeng Lu,Xu Chen,Mia Chen,Kenton Lee,Rama Pasumarthi,Sijal Bhatnagar,Aditya Shah,Qiyin Wu,Zhuoyuan Chen,Zack Nado,Bartek Perz,Zixuan Jiang,David Kao,Ganesh Mallya,Nino Vieillard,Lantao Mei,Sertan Girgin,Mandy Jordan,Yeongil Ko,Alekh Agarwal,Yaxin Liu,Yasemin Altun,Raoul de Liedekerke,Anastasios Kementsietsidis,Daiyi Peng,Dangyi Liu,Utku Evci,Peter Humphreys,Austin Tarango,Xiang Deng,Yoad Lewenberg,Kevin Aydin,Chengda Wu,Bhavishya Mittal,Tsendsuren Munkhdalai,Kleopatra Chatziprimou,Rodrigo Benenson,Uri First,Xiao Ma,Jinning Li,Armand Joulin,Hamish Tomlinson,Tingnan Zhang,Milad Nasr,Zhi Hong,Michaël Sander,Lisa Anne Hendricks,Anuj Sharma,Andrew Bolt,Eszter Vértes,Jiri Simsa,Tomer Levinboim,Olcan Sercinoglu,Divyansh Shukla,Austin Wu,Craig Swanson,Danny Vainstein,Fan Bu,Bo Wang,Ryan Julian,Charles Yoon,Sergei Lebedev,Antonious Girgis,Bernd Bandemer,David Du,Todd Wang,Xi Chen,Ying Xiao,Peggy Lu,Natalie Ha,Vlad Ionescu,Simon Rowe,Josip Matak,Federico Lebron,Andreas Steiner,Lalit Jain,Manaal Faruqui,Nicolas Lacasse,Georgie Evans,Neesha Subramaniam,Dean Reich,Giulia Vezzani,Aditya Pandey,Joe Stanton,Tianhao Zhou,Liam McCafferty,Henry Griffiths,Verena Rieser,Soheil Hassas Yeganeh,Eleftheria Briakou,Lu Huang,Zichuan Wei,Liangchen Luo,Erik Jue,Gabby Wang,Victor Cotruta,Myriam Khan,Jongbin Park,Qiuchen Guo,Peiran Li,Rong Rong,Diego Antognini,Anastasia Petrushkina,Chetan Tekur,Eli Collins,Parul Bhatia,Chester Kwak,Wenhu Chen,Arvind Neelakantan,Immanuel Odisho,Sheng Peng,Vincent Nallatamby,Vaibhav Tulsyan,Fabian Pedregosa,Peng Xu,Raymond Lin,Yulong Wang,Emma Wang,Sholto Douglas,Reut Tsarfaty,Elena Gribovskaya,Renga Aravamudhan,Manu Agarwal,Mara Finkelstein,Qiao Zhang,Elizabeth Cole,Phil Crone,Sarmishta Velury,Anil Das,Chris Sauer,Luyao Xu,Danfeng Qin,Chenjie Gu,Dror Marcus,CJ Zheng,Wouter Van Gansbeke,Sobhan Miryoosefi,Haitian Sun,YaGuang Li,Charlie Chen,Jae Yoo,Pavel Dubov,Alex Tomala,Adams Yu,Paweł Wesołowski,Alok Gunjan,Eddie Cao,Jiaming Luo,Nikhil Sethi,Arkadiusz Socala,Laura Graesser,Tomas Kocisky,Arturo BC,Minmin Chen,Edward Lee,Sophie Wang,Weize Kong,Qiantong Xu,Nilesh Tripuraneni,Yiming Li,Xinxin Yu,Allen Porter,Paul Voigtlaender,Biao Zhang,Arpi Vezer,Sarah York,Qing Wei,Geoffrey Cideron,Mark Kurzeja,Seungyeon Kim,Benny Li,Angéline Pouget,Hyo Lee,Kaspar Daugaard,Yang Li,Dave Uthus,Aditya Siddhant,Paul Cavallaro,Sriram Ganapathy,Maulik Shah,Rolf Jagerman,Jeff Stanway,Piermaria Mendolicchio,Li Xiao,Kayi Lee,Tara Thompson,Shubham Milind Phal,Jason Chase,Sun Jae Lee,Adrian N Reyes,Disha Shrivastava,Zhen Qin,Roykrong Sukkerd,Seth Odoom,Lior Madmoni,John Aslanides,Jonathan Herzig,Elena Pochernina,Sheng Zhang,Parker Barnes,Daisuke Ikeda,Qiujia Li,Shuo-yiin Chang,Shakir Mohamed,Jim Sproch,Richard Powell,Bidisha Samanta,Domagoj Ćevid,Anton Kovsharov,Shrestha Basu Mallick,Srinivas Tadepalli,Anne Zheng,Kareem Ayoub,Andreas Noever,Christian Reisswig,Zhuo Xu,Junhyuk Oh,Martin Matysiak,Tim Blyth,Shereen Ashraf,Julien Amelot,Boone Severson,Michele Bevilacqua,Motoki Sano,Ethan Dyer,Ofir Roval,Anu Sinha,Yin Zhong,Sagi Perel,Tea Sabolić,Johannes Mauerer,Willi Gierke,Mauro Verzetti,Rodrigo Cabrera,Alvin Abdagic,Steven Hemingray,Austin Stone,Jong Lee,Farooq Ahmad,Karthik Raman,Lior Shani,Jonathan Lai,Orhan Firat,Nathan Waters,Eric Ge,Mo Shomrat,Himanshu Gupta,Rajeev Aggarwal,Tom Hudson,Bill Jia,Simon Baumgartner,Palak Jain,Joe Kovac,Junehyuk Jung,Ante Žužul,Will Truong,Morteza Zadimoghaddam,Songyou Peng,Marco Liang,Rachel Sterneck,Balaji Lakshminarayanan,Machel Reid,Oliver Woodman,Tong Zhou,Jianling Wang,Vincent Coriou,Arjun Narayanan,Jay Hoover,Yenai Ma,Apoorv Jindal,Clayton Sanford,Doug Reid,Swaroop Ramaswamy,Alex Kurakin,Roland Zimmermann,Yana Lunts,Dragos Dena,Zalán Borsos,Vered Cohen,Shujian Zhang,Will Grathwohl,Robert Dadashi,Morgan Redshaw,Joshua Kessinger,Julian Odell,Silvano Bonacina,Zihang Dai,Grace Chen,Ayush Dubey,Pablo Sprechmann,Mantas Pajarskas,Wenxuan Zhou,Niharika Ahuja,Tara Thomas,Martin Nikoltchev,Matija Kecman,Bharath Mankalale,Andrey Ryabtsev,Jennifer She,Christian Walder,Jiaming Shen,Lu Li,Carolina Parada,Sheena Panthaplackel,Okwan Kwon,Matt Lawlor,Utsav Prabhu,Yannick Schroecker,Marc'aurelio Ranzato,Pete Blois,Iurii Kemaev,Ting Yu,Dmitry,Lepikhin,Hao Xiong,Sahand Sharifzadeh,Oleaser Johnson,Jeremiah Willcock,Rui Yao,Greg Farquhar,Sujoy Basu,Hidetoshi Shimokawa,Nina Anderson,Haiguang Li,Khiem Pham,Yizhong Liang,Sebastian Borgeaud,Alexandre Moufarek,Hideto Kazawa,Blair Kutzman,Marcin Sieniek,Sara Smoot,Ruth Wang,Natalie Axelsson,Nova Fallen,Prasha Sundaram,Yuexiang Zhai,Varun Godbole,Petros Maniatis,Alek Wang,Ilia Shumailov,Santhosh Thangaraj,Remi Crocker,Nikita Gupta,Gang Wu,Phil Chen,Gellért Weisz,Celine Smith,Mojtaba Seyedhosseini,Boya Fang,Xiyang Luo,Roey Yogev,Zeynep Cankara,Andrew Hard,Helen Ran,Rahul Sukthankar,George Necula,Gaël Liu,Honglong Cai,Praseem Banzal,Daniel Keysers,Sanjay Ghemawat,Connie Tao,Emma Dunleavy,Aditi Chaudhary,Wei Li,Maciej Mikuła,Chen-Yu Lee,Tiziana Refice,Krishna Somandepalli,Alexandre Fréchette,Dan Bahir,John Karro,Keith Rush,Sarah Perrin,Bill Rosgen,Xiaomeng Yang,Clara Huiyi Hu,Mahmoud Alnahlawi,Justin Mao-Jones,Roopal Garg,Hoang Nguyen,Bat-Orgil Batsaikhan,Iñaki Iturrate,Anselm Levskaya,Avi Singh,Ashyana Kachra,Tony Lu,Denis Petek,Zheng Xu,Mark Graham,Lukas Zilka,Yael Karov,Marija Kostelac,Fangyu Liu,Yaohui Guo,Weiyue Wang,Bernd Bohnet,Emily Pitler,Tony Bruguier,Keisuke Kinoshita,Chrysovalantis Anastasiou,Nilpa Jha,Ting Liu,Jerome Connor,Phil Wallis,Philip Pham,Eric Bailey,Shixin Li,Heng-Tze Cheng,Sally Ma,Haiqiong Li,Akanksha Maurya,Kate Olszewska,Manfred Warmuth,Christy Koh,Dominik Paulus,Siddhartha Reddy Jonnalagadda,Enrique Piqueras,Ali Elqursh,Geoff Brown,Hadar Shemtov,Loren Maggiore,Fei Xia,Ryan Foley,Beka Westberg,George van den Driessche,Livio Baldini Soares,Arjun Kar,Michael Quinn,Siqi Zuo,Jialin Wu,Kyle Kastner,Anna Bortsova,Aijun Bai,Ales Mikhalap,Luowei Zhou,Jennifer Brennan,Vinay Ramasesh,Honglei Zhuang,John Maggs,Johan Schalkwyk,Yuntao Xu,Hui Huang,Andrew Howard,Sasha Brown,Linting Xue,Gloria Shen,Brian Albert,Neha Jha,Daniel Zheng,Varvara Krayvanova,Spurthi Amba Hombaiah,Olivier Lacombe,Gautam Vasudevan,Dan Graur,Tian Xie,Meet Gandhi,Bangju Wang,Dustin Zelle,Harman Singh,Dahun Kim,Sébastien Cevey,Victor Ungureanu,Natasha Noy,Fei Liu,Annie Xie,Fangxiaoyu Feng,Katerina Tsihlas,Daniel Formoso,Neera Vats,Quentin Wellens,Yinan Wang,Niket Kumar Bhumihar,Samrat Ghosh,Matt Hoffman,Tom Lieber,Oran Lang,Kush Bhatia,Tom Paine,Aroonalok Pyne,Ronny Votel,Madeleine Clare Elish,Benoit Schillings,Alex Panagopoulos,Haichuan Yang,Adam Raveret,Zohar Yahav,Shuang Liu,Warren Chen,Dalia El Badawy,Nishant Agrawal,Mohammed Badawi,Mahdi Mirzazadeh,Carla Bromberg,Fan Ye,Chang Liu,Tatiana Sholokhova,George-Cristian Muraru,Gargi Balasubramaniam,Jonathan Malmaud,Alen Carin,Danilo Martins,Irina Jurenka,Pankil Botadra,Dave Lacey,Richa Singh,Mariano Schain,Dan Zheng,Isabelle Guyon,Victor Lavrenko,Seungji Lee,Xiang Zhou,Demis Hassabis,Jeshwanth Challagundla,Derek Cheng,Nikhil Mehta,Matthew Mauger,Michela Paganini,Pushkar Mishra,Kate Lee,Zhang Li,Lexi Baugher,Ondrej Skopek,Max Chang,Amir Zait,Gaurav Menghani,Lizzetth Bellot,Guangxing Han,Jean-Michel Sarr,Sharat Chikkerur,Himanshu Sahni,Rohan Anil,Arun Narayanan,Chandu Thekkath,Daniele Pighin,Hana Strejček,Marko Velic,Fred Bertsch,Manuel Tragut,Keran Rong,Alicia Parrish,Kai Bailey,Jiho Park,Isabela Albuquerque,Abhishek Bapna,Rajesh Venkataraman,Alec Kosik,Johannes Griesser,Zhiwei Deng,Alek Andreev,Qingyun Dou,Kevin Hui,Fanny Wei,Xiaobin Yu,Lei Shu,Avia Aharon,David Barker,Badih Ghazi,Sebastian Flennerhag,Chris Breaux,Yuchuan Liu,Matthew Bilotti,Josh Woodward,Uri Alon,Stephanie Winkler,Tzu-Kuo Huang,Kostas Andriopoulos,João Gabriel Oliveira,Penporn Koanantakool,Berkin Akin,Michael Wunder,Cicero Nogueira dos Santos,Mohammad Hossein Bateni,Lin Yang,Dan Horgan,Beer Changpinyo,Keyvan Amiri,Min Ma,Dayeong Lee,Lihao Liang,Anirudh Baddepudi,Tejasi Latkar,Raia Hadsell,Jun Xu,Hairong Mu,Michael Han,Aedan Pope,Snchit Grover,Frank Kim,Ankit Bhagatwala,Guan Sun,Yamini Bansal,Amir Globerson,Alireza Nazari,Samira Daruki,Hagen Soltau,Jane Labanowski,Laurent El Shafey,Matt Harvey,Yanif Ahmad,Elan Rosenfeld,William Kong,Etienne Pot,Yi-Xuan Tan,Aurora Wei,Victoria Langston,Marcel Prasetya,Petar Veličković,Richard Killam,Robin Strudel,Darren Ni,Zhenhai Zhu,Aaron Archer,Kavya Kopparapu,Lynn Nguyen,Emilio Parisotto,Hussain Masoom,Sravanti Addepalli,Jordan Grimstad,Hexiang Hu,Joss Moore,Avinatan Hassidim,Le Hou,Mukund Raghavachari,Jared Lichtarge,Adam R. Brown,Hilal Dib,Natalia Ponomareva,Justin Fu,Yujing Zhang,Altaf Rahman,Joana Iljazi,Edouard Leurent,Gabriel Dulac-Arnold,Cosmo Du,Chulayuth Asawaroengchai,Larry Jin,Ela Gruzewska,Ziwei Ji,Benigno Uria,Daniel De Freitas,Paul Barham,Lauren Beltrone,Víctor Campos,Jun Yan,Neel Kovelamudi,Arthur Nguyen,Elinor Davies,Zhichun Wu,Zoltan Egyed,Kristina Toutanova,Nithya Attaluri,Hongliang Fei,Peter Stys,Siddhartha Brahma,Martin Izzard,Siva Velusamy,Scott Lundberg,Vincent Zhuang,Kevin Sequeira,Adam Santoro,Ehsan Amid,Ophir Aharoni,Shuai Ye,Mukund Sundararajan,Lijun Yu,Yu-Cheng Ling,Stephen Spencer,Hugo Song,Josip Djolonga,Christo Kirov,Sonal Gupta,Alessandro Bissacco,Clemens Meyer,Mukul Bhutani,Andrew Dai,Weiyi Wang,Siqi Liu,Ashwin Sreevatsa,Qijun Tan,Maria Wang,Lucy Kim,Yicheng Wang,Alex Irpan,Yang Xiao,Stanislav Fort,Yifan He,Alex Gurney,Bryan Gale,Yue Ma,Monica Roy,Viorica Patraucean,Taylan Bilal,Golnaz Ghiasi,Anahita Hosseini,Melvin Johnson,Zhuowan Li,Yi Tay,Benjamin Beyret,Katie Millican,Josef Broder,Mayank Lunayach,Danny Swisher,Eugen Vušak,David Parkinson,MH Tessler,Adi Mayrav Gilady,Richard Song,Allan Dafoe,Yves Raimond,Masa Yamaguchi,Itay Karo,Elizabeth Nielsen,Kevin Kilgour,Mike Dusenberry,Rajiv Mathews,Jiho Choi,Siyuan Qiao,Harsh Mehta,Sahitya Potluri,Chris Knutsen,Jialu Liu,Tat Tan,Kuntal Sengupta,Keerthana Gopalakrishnan,Abodunrinwa Toki,Mencher Chiang,Mike Burrows,Grace Vesom,Zafarali Ahmed,Ilia Labzovsky,Siddharth Vashishtha,Preeti Singh,Ankur Sharma,Ada Ma,Jinyu Xie,Pranav Talluri,Hannah Forbes-Pollard,Aarush Selvan,Joel Wee,Loic Matthey,Tom Funkhouser,Parthasarathy Gopavarapu,Lev Proleev,Cheng Li,Matt Thomas,Kashyap Kolipaka,Zhipeng Jia,Ashwin Kakarla,Srinivas Sunkara,Joan Puigcerver,Suraj Satishkumar Sheth,Emily Graves,Chen Wang,Sadh MNM Khan,Kai Kang,Shyamal Buch,Fred Zhang,Omkar Savant,David Soergel,Kevin Lee,Linda Friso,Xuanyi Dong,Rahul Arya,Shreyas Chandrakaladharan,Connor Schenck,Greg Billock,Tejas Iyer,Anton Bakalov,Leslie Baker,Alex Ruiz,Angad Chandorkar,Trieu Trinh,Matt Miecnikowski,Yanqi Zhou,Yangsibo Huang,Jiazhong Nie,Ali Shah,Ashish Thapliyal,Sam Haves,Lun Wang,Uri Shaham,Patrick Morris-Suzuki,Soroush Radpour,Leonard Berrada,Thomas Strohmann,Chaochao Yan,Jingwei Shen,Sonam Goenka,Tris Warkentin,Petar Dević,Dan Belov,Albert Webson,Madhavi Yenugula,Puranjay Datta,Jerry Chang,Nimesh Ghelani,Aviral Kumar,Vincent Perot,Jessica Lo,Yang Song,Herman Schmit,Jianmin Chen,Vasilisa Bashlovkina,Xiaoyue Pan,Diana Mincu,Paul Roit,Isabel Edkins,Andy Davis,Yujia Li,Ben Horn,Xinjian Li,Pradeep Kumar S,Eric Doi,Wanzheng Zhu,Sri Gayatri Sundara Padmanabhan,Siddharth Verma,Jasmine Liu,Heng Chen,Mihajlo Velimirović,Malcolm Reynolds,Priyanka Agrawal,Nick Sukhanov,Abhinit Modi,Siddharth Goyal,John Palowitch,Nima Khajehnouri,Wing Lowe,David Klinghoffer,Sharon Silver,Vinh Tran,Candice Schumann,Francesco Piccinno,Xi Liu,Mario Lučić,Xiaochen Yang,Sandeep Kumar,Ajay Kannan,Ragha Kotikalapudi,Mudit Bansal,Fabian Fuchs,Javad Hosseini,Abdelrahman Abdelhamed,Dawn Bloxwich,Tianhe Yu,Ruoxin Sang,Gregory Thornton,Karan Gill,Yuchi Liu,Virat Shejwalkar,Jason Lin,Zhipeng Yan,Kehang Han,Thomas Buschmann,Michael Pliskin,Zhi Xing,Susheel Tatineni,Junlin Zhang,Sissie Hsiao,Gavin Buttimore,Marcus Wu,Zefei Li,Geza Kovacs,Legg Yeung,Tao Huang,Aaron Cohen,Bethanie Brownfield,Averi Nowak,Mikel Rodriguez,Tianze Shi,Hado van Hasselt,Kevin Cen,Deepanway Ghoshal,Kushal Majmundar,Weiren Yu,Warren,Chen,Danila Sinopalnikov,Hao Zhang,Vlado Galić,Di Lu,Zeyu Zheng,Maggie Song,Gary Wang,Gui Citovsky,Swapnil Gawde,Isaac Galatzer-Levy,David Silver,Ivana Balazevic,Dipanjan Das,Kingshuk Majumder,Yale Cong,Praneet Dutta,Dustin Tran,Hui Wan,Junwei Yuan,Daniel Eppens,Alanna Walton,Been Kim,Harry Ragan,James Cobon-Kerr,Lu Liu,Weijun Wang,Bryce Petrini,Jack Rae,Rakesh Shivanna,Yan Xiong,Chace Lee,Pauline Coquinot,Yiming Gu,Lisa Patel,Blake Hechtman,Aviel Boag,Orion Jankowski,Alex Wertheim,Alex Lee,Paul Covington,Hila Noga,Sam Sobell,Shanthal Vasanth,William Bono,Chirag Nagpal,Wei Fan,Xavier Garcia,Kedar Soparkar,Aybuke Turker,Nathan Howard,Sachit Menon,Yuankai Chen,Vikas Verma,Vladimir Pchelin,Harish Rajamani,Valentin Dalibard,Ana Ramalho,Yang Guo,Kartikeya Badola,Seojin Bang,Nathalie Rauschmayr,Julia Proskurnia,Sudeep Dasari,Xinyun Chen,Mikhail Sushkov,Anja Hauth,Pauline Sho,Abhinav Singh,Bilva Chandra,Allie Culp,Max Dylla,Olivier Bachem,James Besley,Heri Zhao,Timothy Lillicrap,Wei Wei,Wael Al Jishi,Ning Niu,Alban Rrustemi,Raphaël Lopez Kaufman,Ryan Poplin,Jewel Zhao,Minh Truong,Shikhar Bharadwaj,Ester Hlavnova,Eli Stickgold,Cordelia Schmid,Georgi Stephanov,Zhaoqi Leng,Frederick Liu,Léonard Hussenot,Shenil Dodhia,Juliana Vicente Franco,Lesley Katzen,Abhanshu Sharma,Sarah Cogan,Zuguang Yang,Aniket Ray,Sergi Caelles,Shen Yan,Ravin Kumar,Daniel Gillick,Renee Wong,Joshua Ainslie,Jonathan Hoech,Séb Arnold,Dan Abolafia,Anca Dragan,Ben Hora,Grace Hu,Alexey Guseynov,Yang Lu,Chas Leichner,Jinmeng Rao,Abhimanyu Goyal,Nagabhushan Baddi,Daniel Hernandez Diaz,Tim McConnell,Max Bain,Jake Abernethy,Qiqi Yan,Rylan Schaeffer,Paul Vicol,Will Thompson,Montse Gonzalez Arenas,Mathias Bellaiche,Pablo Barrio,Stefan Zinke,Riccardo Patana,Pulkit Mehta,JK Kearns,Avraham Ruderman,Scott Pollom,David D'Ambrosio,Cath Hope,Yang Yu,Andrea Gesmundo,Kuang-Huei Lee,Aviv Rosenberg,Yiqian Zhou,Yaoyiran Li,Drew Garmon,Yonghui Wu,Safeen Huda,Gil Fidel,Martin Baeuml,Jian Li,Phoebe Kirk,Rhys May,Tao Tu,Sara Mc Carthy,Toshiyuki Fukuzawa,Miranda Aperghis,Chih-Kuan Yeh,Toshihiro Yoshino,Bo Li,Austin Myers,Kaisheng Yao,Ben Limonchik,Changwan Ryu,Rohun Saxena,Alex Goldin,Ruizhe Zhao,Rocky Rhodes,Tao Zhu,Divya Tyam,Heidi Howard,Nathan Byrd,Hongxu Ma,Yan Wu,Ryan Mullins,Qingze Wang,Aida Amini,Sebastien Baur,Yiran Mao,Subhashini Venugopalan,Will Song,Wen Ding,Paul Collins,Sashank Reddi,Megan Shum,Andrei Rusu,Luisa Zintgraf,Kelvin Chan,Sheela Goenka,Mathieu Blondel,Michael Collins,Renke Pan,Marissa Giustina,Nikolai Chinaev,Christian Schuler,Ce Zheng,Jonas Valfridsson,Alyssa Loo,Alex Yakubovich,Jamie Smith,Tao Jiang,Rich Munoz,Gabriel Barcik,Rishabh Bansal,Mingyao Yang,Yilun Du,Pablo Duque,Mary Phuong,Alexandra Belias,Kunal Lad,Zeyu Liu,Tal Schuster,Karthik Duddu,Jieru Hu,Paige Kunkle,Matthew Watson,Jackson Tolins,Josh Smith,Denis Teplyashin,Garrett Bingham,Marvin Ritter,Marco Andreetto,Divya Pitta,Mohak Patel,Shashank Viswanadha,Trevor Strohman,Catalin Ionescu,Jincheng Luo,Yogesh Kalley,Jeremy Wiesner,Dan Deutsch,Derek Lockhart,Peter Choy,Rumen Dangovski,Chawin Sitawarin,Cat Graves,Tanya Lando,Joost van Amersfoort,Ndidi Elue,Zhouyuan Huo,Pooya Moradi,Jean Tarbouriech,Henryk Michalewski,Wenting Ye,Eunyoung Kim,Alex Druinsky,Florent Altché,Xinyi Chen,Artur Dwornik,Da-Cheng Juan,Rivka Moroshko,Horia Toma,Jarrod Kahn,Hai Qian,Maximilian Sieb,Irene Cai,Roman Goldenberg,Praneeth Netrapalli,Sindhu Raghuram,Yuan Gong,Lijie Fan,Evan Palmer,Yossi Matias,Valentin Gabeur,Shreya Pathak,Tom Ouyang,Don Metzler,Geoff Bacon,Srinivasan Venkatachary,Sridhar Thiagarajan,Alex Cullum,Eran Ofek,Vytenis Sakenas,Mohamed Hammad,Cesar Magalhaes,Mayank Daswani,Oscar Chang,Ashok Popat,Ruichao Li,Komal Jalan,Yanhan Hou,Josh Lipschultz,Antoine He,Wenhao Jia,Pier Giuseppe Sessa,Prateek Kolhar,William Wong,Sumeet Singh,Lukas Haas,Jay Whang,Hanna Klimczak-Plucińska,Georges Rotival,Grace Chung,Yiqing Hua,Anfal Siddiqui,Nicolas Serrano,Dongkai Chen,Billy Porter,Libin Bai,Keshav Shivam,Sho Arora,Partha Talukdar,Tom Cobley,Sangnie Bhardwaj,Evgeny Gladchenko,Simon Green,Kelvin Guu,Felix Fischer,Xiao Wu,Eric Wang,Achintya Singhal,Tatiana Matejovicova,James Martens,Hongji Li,Roma Patel,Elizabeth Kemp,Jiaqi Pan,Lily Wang,Blake JianHang Chen,Jean-Baptiste Alayrac,Navneet Potti,Erika Gemzer,Eugene Ie,Kay McKinney,Takaaki Saeki,Edward Chou,Pascal Lamblin,SQ Mah,Zach Fisher,Martin Chadwick,Jon Stritar,Obaid Sarvana,Andrew Hogue,Artem Shtefan,Hadi Hashemi,Yang Xu,Jindong Gu,Sharad Vikram,Chung-Ching Chang,Sabela Ramos,Logan Kilpatrick,Weijuan Xi,Jenny Brennan,Yinghao Sun,Abhishek Jindal,Ionel Gog,Dawn Chen,Felix Wu,Jason Lee,Sudhindra Kopalle,Srinadh Bhojanapalli,Oriol Vinyals,Natan Potikha,Burcu Karagol Ayan,Yuan Yuan,Michael Riley,Piotr Stanczyk,Sergey Kishchenko,Bing Wang,Dan Garrette,Antoine Yang,Vlad Feinberg,CJ Carey,Javad Azizi,Viral Shah,Erica Moreira,Chongyang Shi,Josh Feldman,Elizabeth Salesky,Thomas Lampe,Aneesh Pappu,Duhyeon Kim,Jonas Adler,Avi Caciularu,Brian Walker,Yunhan Xu,Yochai Blau,Dylan Scandinaro,Terry Huang,Sam El-Husseini,Abhishek Sinha,Lijie Ren,Taylor Tobin,Patrik Sundberg,Tim Sohn,Vikas Yadav,Mimi Ly,Emily Xue,Jing Xiong,Afzal Shama Soudagar,Sneha Mondal,Nikhil Khadke,Qingchun Ren,Ben Vargas,Stan Bileschi,Sarah Chakera,Cindy Wang,Boyu Wang,Yoni Halpern,Joe Jiang,Vikas Sindhwani,Petre Petrov,Pranavaraj Ponnuramu,Sanket Vaibhav Mehta,Yu Watanabe,Betty Chan,Matheus Wisniewski,Trang Pham,Jingwei Zhang,Conglong Li,Dario de Cesare,Art Khurshudov,Alex Vasiloff,Melissa Tan,Zoe Ashwood,Bobak Shahriari,Maryam Majzoubi,Garrett Tanzer,Olga Kozlova,Robin Alazard,James Lee-Thorp,Nguyet Minh Phu,Isaac Tian,Junwhan Ahn,Andy Crawford,Lauren Lax,Yuan,Shangguan,Iftekhar Naim,David Ross,Oleksandr Ferludin,Tongfei Guo,Andrea Banino,Hubert Soyer,Xiaoen Ju,Dominika Rogozińska,Ishaan Malhi,Marcella Valentine,Daniel Balle,Apoorv Kulshreshtha,Maciej Kula,Yiwen Song,Sophia Austin,John Schultz,Roy Hirsch,Arthur Douillard,Apoorv Reddy,Michael Fink,Summer Yue,Khyatti Gupta,Adam Zhang,Norman Rink,Daniel McDuff,Lei Meng,András György,Yasaman Razeghi,Ricky Liang,Kazuki Osawa,Aviel Atias,Matan Eyal,Tyrone Hill,Nikolai Grigorev,Zhengdong Wang,Nitish Kulkarni,Rachel Soh,Ivan Lobov,Zachary Charles,Sid Lall,Kazuma Hashimoto,Ido Kessler,Victor Gomes,Zelda Mariet,Danny Driess,Alessandro Agostini,Canfer Akbulut,Jingcao Hu,Marissa Ikonomidis,Emily Caveness,Kartik Audhkhasi,Saurabh Agrawal,Ioana Bica,Evan Senter,Jayaram Mudigonda,Kelly Chen,Jingchen Ye,Xuanhui Wang,James Svensson,Philipp Fränken,Josh Newlan,Li Lao,Eva Schnider,Sami Alabed,Joseph Kready,Jesse Emond,Afief Halumi,Tim Zaman,Chengxi Ye,Naina Raisinghani,Vilobh Meshram,Bo Chang,Ankit Singh Rawat,Axel Stjerngren,Sergey Levi,Rui Wang,Xiangzhu Long,Mitchelle Rasquinha,Steven Hand,Aditi Mavalankar,Lauren Agubuzu,Sudeshna Roy,Junquan Chen,Jarek Wilkiewicz,Hao Zhou,Michal Jastrzebski,Qiong Hu,Agustin Dal Lago,Ramya Sree Boppana,Wei-Jen Ko,Jennifer Prendki,Yao Su,Zhi Li,Eliza Rutherford,Girish Ramchandra Rao,Ramona Comanescu,Adrià Puigdomènech,Qihang Chen,Dessie Petrova,Christine Chan,Vedrana Milutinovic,Felipe Tiengo Ferreira,Chin-Yi Cheng,Ming Zhang,Tapomay Dey,Sherry Yang,Ramesh Sampath,Quoc Le,Howard Zhou,Chu-Cheng Lin,Hoi Lam,Christine Kaeser-Chen,Kai Hui,Dean Hirsch,Tom Eccles,Basil Mustafa,Shruti Rijhwani,Morgane Rivière,Yuanzhong Xu,Junjie Wang,Xinyang Geng,Xiance Si,Arjun Khare,Cheolmin Kim,Vahab Mirrokni,Kamyu Lee,Khuslen Baatarsukh,Nathaniel Braun,Lisa Wang,Pallavi LV,Richard Tanburn,Yuvein,Zhu,Fangda Li,Setareh Ariafar,Dan Goldberg,Ken Burke,Daniil Mirylenka,Meiqi Guo,Olaf Ronneberger,Hadas Natalie Vogel,Liqun Cheng,Nishita Shetty,Johnson Jia,Thomas Jimma,Corey Fry,Ted Xiao,Martin Sundermeyer,Ryan Burnell,Yannis Assael,Mario Pinto,JD Chen,Rohit Sathyanarayana,Donghyun Cho,Jing Lu,Rishabh Agarwal,Sugato Basu,Lucas Gonzalez,Dhruv Shah,Meng Wei,Dre Mahaarachchi,Rohan Agrawal,Tero Rissa,Yani Donchev,Ramiro Leal-Cavazos,Adrian Hutter,Markus Mircea,Alon Jacovi,Faruk Ahmed,Jiageng Zhang,Shuguang Hu,Bo-Juen Chen,Jonni Kanerva,Guillaume Desjardins,Andrew Lee,Nikos Parotsidis,Asier Mujika,Tobias Weyand,Jasper Snoek,Jo Chick,Kai Chen,Paul Chang,Ethan Mahintorabi,Zi Wang,Tolly Powell,Orgad Keller,Abhirut Gupta,Claire Sha,Kanav Garg,Nicolas Heess,Ágoston Weisz,Cassidy Hardin,Bartek Wydrowski,Ben Coleman,Karina Zainullina,Pankaj Joshi,Alessandro Epasto,Terry Spitz,Binbin Xiong,Kai Zhao,Arseniy Klimovskiy,Ivy Zheng,Johan Ferret,Itay Yona,Waleed Khawaja,Jean-Baptiste Lespiau,Maxim Krikun,Siamak Shakeri,Timothee Cour,Bonnie Li,Igor Krivokon,Dan Suh,Alex Hofer,Jad Al Abdallah,Nikita Putikhin,Oscar Akerlund,Silvio Lattanzi,Anurag Kumar,Shane Settle,Himanshu Srivastava,Folawiyo Campbell-Ajala,Edouard Rosseel,Mihai Dorin Istin,Nishanth Dikkala,Anand Rao,Nick Young,Kate Lin,Dhruva Bhaswar,Yiming Wang,Jaume Sanchez Elias,Kritika Muralidharan,James Keeling,Dayou Du,Siddharth Gopal,Gregory Dibb,Charles Blundell,Manolis Delakis,Jacky Liang,Marco Tulio Ribeiro,Georgi Karadzhov,Guillermo Garrido,Ankur Bapna,Jiawei Cao,Adam Sadovsky,Pouya Tafti,Arthur Guez,Coline Devin,Yixian Di,Jinwei Xing,Chuqiao,Xu,Hanzhao Lin,Chun-Te Chu,Sameera Ponda,Wesley Helmholz,Fan Yang,Yue Gao,Sara Javanmardi,Wael Farhan,Alex Ramirez,Ricardo Figueira,Khe Chai Sim,Yuval Bahat,Ashwin Vaswani,Liangzhe Yuan,Gufeng Zhang,Leland Rechis,Hanjun Dai,Tayo Oguntebi,Alexandra Cordell,Eugénie Rives,Kaan Tekelioglu,Naveen Kumar,Bing Zhang,Aurick Zhou,Nikolay Savinov,Andrew Leach,Alex Tudor,Sanjay Ganapathy,Yanyan Zheng,Mirko Rossini,Vera Axelrod,Arnaud Autef,Yukun Zhu,Zheng Zheng,Mingda Zhang,Baochen Sun,Jie Ren,Nenad Tomasev,Nithish Kannan,Amer Sinha,Charles Chen,Louis O'Bryan,Alex Pak,Aditya Kusupati,Weel Yang,Deepak Ramachandran,Patrick Griffin,Seokhwan Kim,Philipp Neubeck,Craig Schiff,Tammo Spalink,Mingyang Ling,Arun Nair,Ga-Young Joung,Linda Deng,Avishkar Bhoopchand,Lora Aroyo,Tom Duerig,Jordan Griffith,Gabe Barth-Maron,Jake Ades,Alex Haig,Ankur Taly,Yunting Song,Paul Michel,Dave Orr,Dean Weesner,Corentin Tallec,Carrie Grimes Bostock,Paul Niemczyk,Andy Twigg,Mudit Verma,Rohith Vallu,Henry Wang,Marco Gelmi,Kiranbir Sodhia,Aleksandr Chuklin,Omer Goldman,Jasmine George,Liang Bai,Kelvin Zhang,Petar Sirkovic,Efrat Nehoran,Golan Pundak,Jiaqi Mu,Alice Chen,Alex Greve,Paulo Zacchello,David Amos,Heming Ge,Eric Noland,Colton Bishop,Jeffrey Dudek,Youhei Namiki,Elena Buchatskaya,Jing Li,Dorsa Sadigh,Masha Samsikova,Dan Malkin,Damien Vincent,Robert David,Rob Willoughby,Phoenix Meadowlark,Shawn Gao,Yan Li,Raj Apte,Amit Jhindal,Stein Xudong Lin,Alex Polozov,Zhicheng Wang,Tomas Mery,Anirudh GP,Varun Yerram,Sage Stevens,Tianqi Liu,Noah Fiedel,Charles Sutton,Matthew Johnson,Xiaodan Song,Kate Baumli,Nir Shabat,Muqthar Mohammad,Hao Liu,Marco Selvi,Yichao Zhou,Mehdi Hafezi Manshadi,Chu-ling Ko,Anthony Chen,Michael Bendersky,Jorge Gonzalez Mendez,Nisarg Kothari,Amir Zandieh,Yiling Huang,Daniel Andor,Ellie Pavlick,Idan Brusilovsky,Jitendra Harlalka,Sally Goldman,Andrew Lampinen,Guowang Li,Asahi Ushio,Somit Gupta,Lei Zhang,Chuyuan Kelly Fu,Madhavi Sewak,Timo Denk,Jed Borovik,Brendan Jou,Avital Zipori,Prateek Jain,Junwen Bai,Thang Luong,Jonathan Tompson,Alice Li,Li Liu,George Powell,Jiajun Shen,Alex Feng,Grishma Chole,Da Yu,Yinlam Chow,Tongxin Yin,Eric Malmi,Kefan Xiao,Yash Pande,Shachi Paul,Niccolò Dal Santo,Adil Dostmohamed,Sergio Guadarrama,Aaron Phillips,Thanumalayan Sankaranarayana Pillai,Gal Yona,Amin Ghafouri,Preethi Lahoti,Benjamin Lee,Dhruv Madeka,Eren Sezener,Simon Tokumine,Adrian Collister,Nicola De Cao,Richard Shin,Uday Kalra,Parker Beak,Emily Nottage,Ryo Nakashima,Ivan Jurin,Vikash Sehwag,Meenu Gaba,Junhao Zeng,Kevin R. McKee,Fernando Pereira,Tamar Yakar,Amayika Panda,Arka Dhar,Peilin Zhong,Daniel Sohn,Mark Brand,Lars Lowe Sjoesund,Viral Carpenter,Sharon Lin,Shantanu Thakoor,Marcus Wainwright,Ashwin Chaugule,Pranesh Srinivasan,Muye Zhu,Bernett Orlando,Jack Weber,Ayzaan Wahid,Gilles Baechler,Apurv Suman,Jovana Mitrović,Gabe Taubman,Honglin Yu,Helen King,Josh Dillon,Cathy Yip,Dhriti Varma,Tomas Izo,Levent Bolelli,Borja De Balle Pigem,Julia Di Trapani,Fotis Iliopoulos,Adam Paszke,Nishant Ranka,Joe Zou,Francesco Pongetti,Jed McGiffin,Alex Siegman,Rich Galt,Ross Hemsley,Goran Žužić,Victor Carbune,Tao Li,Myle Ott,Félix de Chaumont Quitry,David Vilar Torres,Yuri Chervonyi,Tomy Tsai,Prem Eruvbetine,Samuel Yang,Matthew Denton,Jake Walker,Slavica Andačić,Idan Heimlich Shtacher,Vittal Premachandran,Harshal Tushar Lehri,Cip Baetu,Damion Yates,Lampros Lamprou,Mariko Iinuma,Ioana Mihailescu,Ben Albrecht,Shachi Dave,Susie Sargsyan,Bryan Perozzi,Lucas Manning,Chiyuan Zhang,Denis Vnukov,Igor Mordatch,Raia Hadsell Wolfgang Macherey,Ryan Kappedal,Jim Stephan,Aditya Tripathi,Klaus Macherey,Jun Qian,Abhishek Bhowmick,Shekoofeh Azizi,Rémi Leblond,Shiva Mohan Reddy Garlapati,Timothy Knight,Matthew Wiethoff,Wei-Chih Hung,Anelia Angelova,Georgios Evangelopoulos,Pawel Janus,Dimitris Paparas,Matthew Rahtz,Ken Caluwaerts,Vivek Sampathkumar,Daniel Jarrett,Shadi Noghabi,Antoine Miech,Chak Yeung,Geoff Clark,Henry Prior,Fei Zheng,Jean Pouget-Abadie,Indro Bhattacharya,Kalpesh Krishna,Will Bishop,Zhe Yuan,Yunxiao Deng,Ashutosh Sathe,Kacper Krasowiak,Ciprian Chelba,Cho-Jui Hsieh,Kiran Vodrahalli,Buhuang Liu,Thomas Köppe,Amr Khalifa,Lubo Litchev,Pichi Charoenpanit,Reed Roberts,Sachin Yadav,Yasumasa Onoe,Desi Ivanov,Megha Mohabey,Vighnesh Birodkar,Nemanja Rakićević,Pierre Sermanet,Vaibhav Mehta,Krishan Subudhi,Travis Choma,Will Ng,Luheng He,Kathie Wang,Tasos Kementsietsidis,Shane Gu,Mansi Gupta,Andrew Nystrom,Mehran Kazemi,Timothy Chung,Nacho Cano,Nikhil Dhawan,Yufei Wang,Jiawei Xia,Trevor Yacovone,Eric Jia,Mingqing Chen,Simeon Ivanov,Ashrith Sheshan,Sid Dalmia,Paweł Stradomski,Pengcheng Yin,Salem Haykal,Congchao Wang,Dennis Duan,Neslihan Bulut,Greg Kochanski,Liam MacDermed,Namrata Godbole,Shitao Weng,Jingjing Chen,Rachana Fellinger,Ramin Mehran,Daniel Suo,Hisham Husain,Tong He,Kaushal Patel,Joshua Howland,Randall Parker,Kelvin Nguyen,Sharath Maddineni,Chris Rawles,Mina Khan,Shlomi Cohen-Ganor,Amol Mandhane,Xinyi Wu,Chenkai Kuang,Iulia Comşa,Ramya Ganeshan,Hanie Sedghi,Adam Bloniarz,Nuo Wang Pierse,Anton Briukhov,Petr Mitrichev,Anita Gergely,Serena Zhan,Allan Zhou,Nikita Saxena,Eva Lu,Josef Dean,Ashish Gupta,Nicolas Perez-Nieves,Renjie Wu,Cory McLean,Wei Liang,Disha Jindal,Anton Tsitsulin,Wenhao Yu,Kaiz Alarakyia,Tom Schaul,Piyush Patil,Peter Sung,Elijah Peake,Hongkun Yu,Feryal Behbahani,JD Co-Reyes,Alan Ansell,Sean Sun,Clara Barbu,Jonathan Lee,Seb Noury,James Allingham,Bilal Piot,Mohit Sharma,Christopher Yew,Ivan Korotkov,Bibo Xu,Demetra Brady,Goran Petrovic,Shibl Mourad,Claire Cui,Aditya Gupta,Parker Schuh,Saarthak Khanna,Anna Goldie,Abhinav Arora,Vadim Zubov,Amy Stuart,Mark Epstein,Yun Zhu,Jianqiao Liu,Yury Stuken,Ziyue Wang,Karolis Misiunas,Dee Guo,Ashleah Gill,Ale Hartman,Zaid Nabulsi,Aurko Roy,Aleksandra Faust,Jason Riesa,Ben Withbroe,Mengchao Wang,Marco Tagliasacchi,Andreea Marzoca,James Noraky,Serge Toropov,Malika Mehrotra,Bahram Raad,Sanja Deur,Steve Xu,Marianne Monteiro,Zhongru Wu,Yi Luan,Sam Ritter,Nick Li,Håvard Garnes,Yanzhang He,Martin Zlocha,Jifan Zhu,Matteo Hessel,Will Wu,Spandana Raj Babbula,Chizu Kawamoto,Yuanzhen Li,Mehadi Hassen,Yan Wang,Brian Wieder,James Freedman,Yin Zhang,Xinyi Bai,Tianli Yu,David Reitter,XiangHai Sheng,Mateo Wirth,Aditya Kini,Dima Damen,Mingcen Gao,Rachel Hornung,Michael Voznesensky,Brian Roark,Adhi Kuncoro,Yuxiang Zhou,Rushin Shah,Anthony Brohan,Kuangyuan Chen,James Wendt,David Rim,Paul Kishan Rubenstein,Jonathan Halcrow,Michelle Liu,Ty Geri,Yunhsuan Sung,Jane Shapiro,Shaan Bijwadia,Chris Duvarney,Christina Sorokin,Paul Natsev,Reeve Ingle,Pramod Gupta,Young Maeng,Ndaba Ndebele,Kexin Zhu,Valentin Anklin,Katherine Lee,Yuan Liu,Yaroslav Akulov,Shaleen Gupta,Guolong Su,Flavien Prost,Tianlin Liu,Vitaly Kovalev,Pol Moreno,Martin Scholz,Sam Redmond,Zongwei Zhou,Alex Castro-Ros,André Susano Pinto,Dia Kharrat,Michal Yarom,Rachel Saputro,Jannis Bulian,Ben Caine,Ji Liu,Abbas Abdolmaleki,Shariq Iqbal,Tautvydas Misiunas,Mikhail Sirotenko,Shefali Garg,Guy Bensky,Huan Gui,Xuezhi Wang,Raphael Koster,Mike Bernico,Da Huang,Romal Thoppilan,Trevor Cohn,Ben Golan,Wenlei Zhou,Andrew Rosenberg,Markus Freitag,Tynan Gangwani,Vincent Tsang,Anand Shukla,Xiaoqi Ren,Minh Giang,Chi Zou,Andre Elisseeff,Charline Le Lan,Dheeru Dua,Shuba Lall,Pranav Shyam,Frankie Garcia,Sarah Nguyen,Michael Guzman,AJ Maschinot,Marcello Maggioni,Ming-Wei Chang,Karol Gregor,Lotte Weerts,Kumaran Venkatesan,Bogdan Damoc,Leon Liu,Jan Wassenberg,Lewis Ho,Becca Roelofs,Majid Hadian,François-Xavier Aubet,Yu Liang,Sami Lachgar,Danny Karmon,Yong Cheng,Amelio Vázquez-Reina,Angie Chen,Zhuyun Dai,Andy Brock,Shubham Agrawal,Chenxi Pang,Peter Garst,Mariella Sanchez-Vargas,Ivor Rendulic,Aditya Ayyar,Andrija Ražnatović,Olivia Ma,Roopali Vij,Neha Sharma,Ashwin Balakrishna,Bingyuan Liu,Ian Mackinnon,Sorin Baltateanu,Petra Poklukar,Gabriel Ibagon,Colin Ji,Hongyang Jiao,Isaac Noble,Wojciech Stokowiec,Zhihao Li,Jeff Dean,David Lindner,Mark Omernick,Kristen Chiafullo,Mason Dimarco,Vitor Rodrigues,Vittorio Selo,Garrett Honke,Xintian,Wu,Wei He,Adam Hillier,Anhad Mohananey,Vihari Piratla,Chang Ye,Chase Malik,Sebastian Riedel,Samuel Albanie,Zi Yang,Kenny Vassigh,Maria Bauza,Sheng Li,Yiqing Tao,Nevan Wichers,Andrii Maksai,Abe Ittycheriah,Ross Mcilroy,Bryan Seybold,Noah Goodman,Romina Datta,Steven M. Hernandez,Tian Shi,Yony Kochinski,Anna Bulanova,Ken Franko,Mikita Sazanovich,Nicholas FitzGerald,Praneeth Kacham,Shubha Srinivas Raghvendra,Vincent Hellendoorn,Alexander Grushetsky,Julian Salazar,Angeliki Lazaridou,Jason Chang,Jan-Thorsten Peter,Sushant Kafle,Yann Dauphin,Abhishek Rao,Filippo Graziano,Izhak Shafran,Yuguo Liao,Tianli Ding,Geng Yan,Grace Chu,Zhao Fu,Vincent Roulet,Gabriel Rasskin,Duncan Williams,Shahar Drath,Alex Mossin,Raphael Hoffmann,Jordi Orbay,Francesco Bertolini,Hila Sheftel,Justin Chiu,Siyang Xue,Yuheng Kuang,Ferjad Naeem,Swaroop Nath,Nana Nti,Phil Culliton,Kashyap Krishnakumar,Michael Isard,Pei Sun,Ayan Chakrabarti,Nathan Clement,Regev Cohen,Arissa Wongpanich,GS Oh,Ashwin Murthy,Hao Zheng,Jessica Hamrick,Oskar Bunyan,Suhas Ganesh,Nitish Gupta,Roy Frostig,John Wieting,Yury Malkov,Pierre Marcenac,Zhixin,Lai,Xiaodan Tang,Mohammad Saleh,Fedir Zubach,Chinmay Kulkarni,Huanjie Zhou,Vicky Zayats,Nan Ding,Anshuman Tripathi,Arijit Pramanik,Patrik Zochbauer,Harish Ganapathy,Vedant Misra,Zach Behrman,Hugo Vallet,Mingyang Zhang,Mukund Sridhar,Ye Jin,Mohammad Babaeizadeh,Siim Põder,Megha Goel,Divya Jain,Tajwar Nasir,Shubham Mittal,Tim Dozat,Diego Ardila,Aliaksei Severyn,Fabio Pardo,Sammy Jerome,Siyang Qin,Louis Rouillard,Amir Yazdanbakhsh,Zizhao Zhang,Shivani Agrawal,Kaushik Shivakumar,Caden Lu,Praveen Kallakuri,Rachita Chhaparia,Kanishka Rao,Charles Kwong,Asya Fadeeva,Shitij Nigam,Yan Virin,Yuan Zhang,Balaji Venkatraman,Beliz Gunel,Marc Wilson,Huiyu Wang,Abhinav Gupta,Xiaowei Xu,Adrien Ali Taïga,Kareem Mohamed,Doug Fritz,Daniel Rodriguez,Zoubin Ghahramani,Harry Askham,Lior Belenki,James Zhao,Rahul Gupta,Krzysztof Jastrzębski,Takahiro Kosakai,Kaan Katircioglu,Jon Schneider,Rina Panigrahy,Konstantinos Bousmalis,Peter Grabowski,Prajit Ramachandran,Chaitra Hegde,Mihaela Rosca,Angelo Scorza Scarpati,Kyriakos Axiotis,Ying Xu,Zach Gleicher,Assaf Hurwitz Michaely,Mandar Sharma,Sanil Jain,Christoph Hirnschall,Tal Marian,Xuhui Jia,Kevin Mather,Kilol Gupta,Linhai Qiu,Nigamaa Nayakanti,Lucian Ionita,Steven Zheng,Lucia Loher,Kurt Shuster,Igor Petrovski,Roshan Sharma,Rahma Chaabouni,Angel Yeh,James An,Arushi Gupta,Steven Schwarcz,Seher Ellis,Sam Conway-Rahman,Javier Snaider,Alex Zhai,James Atwood,Daniel Golovin,Liqian Peng,Te I,Vivian Xia,Salvatore Scellato,Mahan Malihi,Arthur Bražinskas,Vlad-Doru Ion,Younghoon Jun,James Swirhun,Soroosh Mariooryad,Jiao Sun,Steve Chien,Rey Coaguila,Ariel Brand,Yi Gao,Tom Kwiatkowski,Roee Aharoni,Cheng-Chun Lee,Mislav Žanić,Yichi Zhang,Dan Ethier,Vitaly Nikolaev,Pranav Nair,Yoav Ben Shalom,Hen Fitoussi,Jai Gupta,Hongbin Liu,Dee Cattle,Tolga Bolukbasi,Ben Murdoch,Fantine Huot,Yin Li,Chris Hahn*

Main category: cs.CL

TL;DR: Gemini 2.X系列新模型同时兼顾高性能与高性价比，不仅推理、编码能力强，且支持多模态及长视频处理，能广泛赋能复杂智能代理场景。


<details>
  <summary>Details</summary>
Motivation: 当前用户和企业对能够处理复杂推理、多模态内容以及低延迟、低成本的AI模型需求不断增长，同时需要更强智能代理能力以应对复杂任务。

Method: 通过开发多种模型版本（包括Gemini 2.5 Pro、2.5 Flash、2.0 Flash及Flash-Lite），分别优化在前沿推理、编码、多模态理解、处理长视频内容等多方面能力，并兼顾计算与响应速度。

Result: Gemini 2.5 Pro在前沿编码与推理基准测试中达到了SOTA水平，具备先进的多模态理解及最大发电三小时视频内容的处理能力；2.5 Flash在保证优秀推理效果下大幅降低计算和延迟成本；2.0 Flash及Flash-Lite提供高效能、低延迟与低成本应用选择。

Conclusion: Gemini 2.X系列模型在性能和成本之间实现了全面平衡，为用户提供多种强大且具高性价比的智能解决方案，能满足不同场景下的高级推理、多模态处理与复杂任务代理需求。

Abstract: In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and
Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite
models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA
performance on frontier coding and reasoning benchmarks. In addition to its
incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that
excels at multimodal understanding and it is now able to process up to 3 hours
of video content. Its unique combination of long context, multimodal and
reasoning capabilities can be combined to unlock new agentic workflows. Gemini
2.5 Flash provides excellent reasoning abilities at a fraction of the compute
and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high
performance at low latency and cost. Taken together, the Gemini 2.X model
generation spans the full Pareto frontier of model capability vs cost, allowing
users to explore the boundaries of what is possible with complex agentic
problem solving.

</details>


### [10] [Humans overrely on overconfident language models, across languages](https://arxiv.org/abs/2507.06306)
*Neil Rathi,Dan Jurafsky,Kaitlyn Zhou*

Main category: cs.CL

TL;DR: 本文分析了大语言模型在五种语言下表达不确定性的方式及其对用户的影响，发现无论语言如何，用户均存在过度依赖模型生成内容的风险，而具体依赖行为又受不同语言文化影响，强调了多语言背景下模型校准与安全评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）在全球范围内部署，确保其在多种语言下能够准确表达不确定性与局限性变得非常重要。此前研究发现，LLM在英语环境下存在过度自信问题，导致用户过度依赖模型生成内容。考虑到表示不确定性的语言标记在不同语言中有显著差异，本文旨在探讨多语言下LLM的语言校准风险、过度自信与过度依赖等安全隐患。

Method: 本文对五种语言下LLM生成的表征主观确信度的语言标记进行分析，比较它们表现出的自信与不确定性。再通过人类用户行为测量，不同语言环境下用户对模型生成内容的依赖程度，分析用户对自信和不确定表达的依赖变化。

Result: 研究发现，所有语言下用户对LLM生成内容的过度依赖风险均较高。模型在不同语言间对不确定性标记的使用具有一定敏感性，如日语中生成的不确定表达最多，而德语和中文中生成的确定表达最多。用户层面，不同语言背景下对表达不确定性内容的依赖存在差异：与英语相比，日语用户对不确定表达的依赖显著更高。整体来看，LLM在多语言环境下广泛存在过度自信和依赖风险。

Conclusion: LLM在多语言环境下存在较高的过度自信及依赖风险，且模型与用户的行为模式受语言文化影响，提示当前校准策略与安全评估需充分考虑多语言、多文化特性，以提升模型的全球安全性与实用性。

Abstract: As large language models (LLMs) are deployed globally, it is crucial that
their responses are calibrated across languages to accurately convey
uncertainty and limitations. Previous work has shown that LLMs are
linguistically overconfident in English, leading users to overrely on confident
generations. However, the usage and interpretation of epistemic markers (e.g.,
'It's definitely,' 'I think') can differ sharply across languages. Here, we
study the risks of multilingual linguistic (mis)calibration, overconfidence,
and overreliance across five languages to evaluate the safety of LLMs in a
global context.
  We find that overreliance risks are high across all languages. We first
analyze the distribution of LLM-generated epistemic markers, and observe that
while LLMs are cross-linguistically overconfident, they are also sensitive to
documented linguistic variation. For example, models generate the most markers
of uncertainty in Japanese and the most markers of certainty in German and
Mandarin. We then measure human reliance rates across languages, finding that
while users strongly rely on confident LLM generations in all languages,
reliance behaviors differ cross-linguistically: for example, users rely
significantly more on expressions of uncertainty in Japanese than in English.
Taken together, these results indicate high risk of reliance on overconfident
model generations across languages. Our findings highlight the challenges of
multilingual linguistic calibration and stress the importance of culturally and
linguistically contextualized model safety evaluations.

</details>


### [11] [Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams](https://arxiv.org/abs/2507.06803)
*Matthew Anderson Hendricks,Alice Cicirello*

Main category: cs.CL

TL;DR: 融合NLP和LLMs自动生成SysML建模图，辅助工程动力系统的自动化建模与代码生成，提升设计效率，方法通用且性能优于仅用LLMs的方案。


<details>
  <summary>Details</summary>
Motivation: 工程动力系统的设计和部署过程通常耗时且依赖大量专业知识，而自动化和智能化手段在此领域应用仍存在局限。该论文旨在探索如何高效利用领域知识和专家经验，通过自动化方式生成动力系统的计算模型。

Method: 提出了一种五步法策略，结合自然语言处理（NLP）和大语言模型（LLMs），以系统建模语言（SysML）图为核心，自动提取文档中的组件依赖、属性和操作信息。具体包括关键名词提取、关系抽取、短语及属性归纳、模型图自动生成等环节，并以SysML图为中介，通过代码生成获得最终的动力系统计算模型。

Result: 通过多个案例分析表明，自动化生成SysML图及后续模型的流程是可行的，并在以单摆为例的端到端流程中，从文本到模型的过程展现了比仅靠LLMs更优的性能。

Conclusion: 本文提出的方法能够有效加速工程动力系统的设计与部署流程，不依赖某一特定领域或计算工具，适用性和通用性较强，并实现了从文本到模型的自动高效转换。

Abstract: This paper contributes to speeding up the design and deployment of
engineering dynamical systems by proposing a strategy for exploiting domain and
expert knowledge for the automated generation of dynamical system computational
model starting from a corpus of document relevant to the dynamical system of
interest and an input document describing the specific system. This strategy is
implemented in five steps and, crucially, it uses system modeling language
diagrams (SysML) to extract accurate information about the dependencies,
attributes, and operations of components. Natural Language Processing (NLP)
strategies and Large Language Models (LLMs) are employed in specific tasks to
improve intermediate outputs of the SySML diagrams automated generation, such
as: list of key nouns; list of extracted relationships; list of key phrases and
key relationships; block attribute values; block relationships; and BDD diagram
generation. The applicability of automated SysML diagram generation is
illustrated with different case studies. The computational models of complex
dynamical systems from SysML diagrams are then obtained via code generation and
computational model generation steps. In the code generation step, NLP
strategies are used for summarization, while LLMs are used for validation only.
The proposed approach is not limited to a specific system, domain, or
computational software. The applicability of the proposed approach is shown via
an end-to-end example from text to model of a simple pendulum, showing improved
performance compared to results yielded by LLMs only.

</details>


### [12] [ETT: Expanding the Long Context Understanding Capability of LLMs at Test-Time](https://arxiv.org/abs/2507.06313)
*Kiarash Zahirnia,Zahra Golpayegani,Walid Ahmad,Yang Liu*

Main category: cs.CL

TL;DR: 本文提出ETT方法，在测试时通过高效微调显著扩展LLM的上下文长度，不仅降低计算资源消耗，还提升最大30%的准确率，且精细微调特定层次效果更佳。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在处理长序列时计算和内存开销随序列长度呈二次增长，限制了其在长文本任务中的应用。本文旨在降低这些模型在长序列处理中的资源消耗。

Method: 提出了一种称为ETT（Extend at Test-Time）的方法，通过将输入上下文切分为重叠的子序列，在测试时高效微调模型参数。该方法内存需求恒定，计算开销线性增长。并对比分析不同Transformer模块在测试时微调的效果。

Result: 将GPT-Large和Phi-2的上下文长度从1k扩展到32k代币，模型准确率提高高达30%。发现仅微调Feed Forward网络（FFN）第二层比全量微调更有效，进一步提升准确率。

Conclusion: ETT方法显著扩展了Transformer LLMs在测试时的上下文长度，且资源消耗更低。按需微调特定模块可在提升性能的同时降低计算量。

Abstract: Transformer-based Language Models' computation and memory overhead increase
quadratically as a function of sequence length. The quadratic cost poses
challenges when employing LLMs for processing long sequences. In this work, we
introduce \ourmodelacronym~(Extend at Test-Time), method for extending the
context length of short context Transformer-based LLMs, with constant memory
requirement and linear computation overhead. ETT enable the extension of the
context length at test-time by efficient fine-tuning the model's parameters on
the input context, chunked into overlapping small subsequences. We evaluate ETT
on LongBench by extending the context length of GPT-Large and Phi-2 up to 32
times, increasing from 1k to 32k tokens. This results in up to a 30 percent
improvement in the model's accuracy. We also study how context can be stored in
LLM's weights effectively and efficiently. Through a detailed ablation study,
we examine which Transformer modules are most beneficial to fine-tune at
test-time. Interestingly, we find that fine-tuning the second layer of the FFNs
is more effective than full fine-tuning, leading to a further improvement in
the models' accuracy.

</details>


### [13] [Could the Road to Grounded, Neuro-symbolic AI be Paved with Words-as-Classifiers?](https://arxiv.org/abs/2507.06335)
*Casey Kennington,David Schlangen*

Main category: cs.CL

TL;DR: 本文通过回顾与实验，论证words-as-classifier模型可以统合形式、分布式及具身语义理论，并提出基于此模型的统一语义框架设想。


<details>
  <summary>Details</summary>
Motivation: 现有的计算语义学理论——形式语义、分布式语义和具身语义（基于感知/视觉的语义）各有优缺点，目前学界探索通过结合视觉信息、引入符号方法来整合这些理论。作者希望推动三者的统一。

Method: 文献回顾words-as-classifier模型，并以最近认知科学成果为动机，做了一个小型实验，最后提出基于words-as-classifier的统一语义模型设想。

Result: words-as-classifier模型已被用于对话系统，被实证验证，实现了形式、分布式和具身语义方法的部分整合。作者还描述了这一模型如何作为三种理论统一框架。

Conclusion: words-as-classifier模型有潜力作为统一形式、分布式和具身语义学的载体，对语义建模具有综合性价值。

Abstract: Formal, Distributional, and Grounded theories of computational semantics each
have their uses and their drawbacks. There has been a shift to ground models of
language by adding visual knowledge, and there has been a call to enrich models
of language with symbolic methods to gain the benefits from formal,
distributional, and grounded theories. In this paper, we attempt to make the
case that one potential path forward in unifying all three semantic fields is
paved with the words-as-classifier model, a model of word-level grounded
semantics that has been incorporated into formalisms and distributional
language models in the literature, and it has been well-tested within
interactive dialogue settings. We review that literature, motivate the
words-as-classifiers model with an appeal to recent work in cognitive science,
and describe a small experiment. Finally, we sketch a model of semantics
unified through words-as-classifiers.

</details>


### [14] [Evaluating Morphological Alignment of Tokenizers in 70 Languages](https://arxiv.org/abs/2507.06378)
*Catherine Arnett,Marisa Hudspeth,Brendan O'Connor*

Main category: cs.CL

TL;DR: 作者扩展了MorphScore，支持70种语言，以评估分词与形态结构的对齐，但发现形态学对齐程度与下游任务表现相关性很低，说明仅凭形态对齐无法全面评价分词器质量。


<details>
  <summary>Details</summary>
Motivation: 词语分词是语言建模的重要环节，但如何有效评估分词器的质量尚不明确。现有评估方法之一是看分词边界是否与词的形态学边界对齐，这在语言学上有意义。

Method: 扩展了MorphScore评估工具，将覆盖的语言数量从22种扩展到70种，并增强了灵活性及弥补了部分原有版本的不足。之后，作者基于五个预训练语言模型、七个任务，统计了分词与形态学对齐分数和下游任务性能的相关性。

Result: 分词边界与形态学边界的对齐度对模型在下游任务上的表现影响很小，解释不了大部分性能方差。

Conclusion: 形态学对齐作为分词器质量的单一衡量标准不足以反映模型性能表现。分词评估需要考虑更多维度。

Abstract: While tokenization is a key step in language modeling, with effects on model
training and performance, it remains unclear how to effectively evaluate
tokenizer quality. One proposed dimension of tokenizer quality is the extent to
which tokenizers preserve linguistically meaningful subwords, aligning token
boundaries with morphological boundaries within a word. We expand MorphScore
(Arnett & Bergen, 2025), which previously covered 22 languages, to support a
total of 70 languages. The updated MorphScore offers more flexibility in
evaluation and addresses some of the limitations of the original version. We
then correlate our alignment scores with downstream task performance for five
pre-trained languages models on seven tasks, with at least one task in each of
the languages in our sample. We find that morphological alignment does not
explain very much variance in model performance, suggesting that morphological
alignment alone does not measure dimensions of tokenization quality relevant to
model performance.

</details>


### [15] [Hypermagmas and Colored Operads: Heads, Phases, and Theta Roles](https://arxiv.org/abs/2507.06393)
*Matilde Marcolli,Riny Huijbregts,Richard K. Larson*

Main category: cs.CL

TL;DR: 本论文运用高级代数（hyper-magma，colored operad等）统一形式化句法结构及其限制（如阶段结构、投射原则、句法移动等），展示了句法理论可借助范畴论工具严密刻画。


<details>
  <summary>Details</summary>
Motivation: 希望为句法学中的复杂结构与限制（如阶段、投射、移动规则等）提供统一、严格的代数与范畴学形式工具，从而更好地解释句法对象的生成和限制方式。

Method: 通过将句法对象扩展为hyper-magma结构，运用colored operad（彩色幺半范畴）的芽生成系统(bud generating system)，对头、补足语、标识语、及修饰语位置等句法结构进行形式化，并将句法生成过程中的约束表达为有色operad生成器的过滤和变换规则。采用范畴论和代数结构分析方法。

Result: 证明了句法对象及其相关关系（如c-command与m-command、theta角色分配等）可以在ma/gma和hyper-magma的结构下用彩色operad formalism表达，句法生成的过程和各种句法规则（如移动、阶段不可穿透等）均能整合为有色operad的生成与过滤过程。

Conclusion: 该论文得出结论，句法结构中的运动规则、投射原则以及相关的限制条件，都可以统一地用有色operad生成器来描述，而语类、修饰语位置等核心句法结构也可通过有色operad系统来形式化。阶段结构与theta角色的兼容性也可归结为有色operad间的换位(transduction)问题。

Abstract: We show that head functions on syntactic objects extend the magma structure
to a hypermagma, with the c-command relation compatible with the magma
operation and the m-command relation with the hypermagma. We then show that the
structure of head and complement and specifier, additional modifier positions,
and the structure of phases in the Extended Projection can be formulated as a
bud generating system of a colored operad, in a form similar to the structure
of theta roles. We also show that, due to the special form of the colored
operad generators, the filtering of freely generated syntactic objects by these
coloring rules can be equivalently formulated as a filtering in the course of
structure formation via a colored Merge, which can in turn be related to the
hypermagma structure. The rules on movement by Internal Merge with respect to
phases, the Extended Projection Principle, Empty Category Principle, and Phase
Impenetrability Condition are all subsumed into the form of the colored operad
generators. Movement compatibilities between the phase structure and the theta
roles assignments can then be formulated in terms of the respective colored
operads and a transduction of colored operads.

</details>


### [16] [PERK: Long-Context Reasoning as Parameter-Efficient Test-Time Learning](https://arxiv.org/abs/2507.06415)
*Zeming Chen,Angelika Romanou,Gail Weiss,Antoine Bosselut*

Main category: cs.CL

TL;DR: 本文提出PERK方法，通过在测试时对低秩适配器进行更新，实现高效且高性能的长上下文推理。实验显示PERK显著优于传统方法，兼具强大推理能力和推理阶段的内存高效性。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理需要在大量嘈杂的输入信息中准确识别有用内容，但目前的元学习方法内存消耗极大，难以在长上下文场景应用。作者希望解决长上下文推理中的内存与效率问题。

Method: 提出了一种称为PERK（Parameter Efficient Reasoning over Knowledge）的方法，通过在测试时对轻量级模型适配器进行梯度更新，将长输入上下文编码到参数中。采用两个嵌套的优化循环：内循环快速编写上下文到低秩适配器（LoRA），作为高效的记忆模块；外循环则学习如何利用更新后的适配器准确回忆和推理相关信息。

Result: 在多个长上下文推理任务上，PERK显著优于传统基于提示的长上下文方法。具体来说，较小模型（GPT-2）平均绝对性能提升高达90%，最大模型（Qwen-2.5-0.5B）提升至27%。PERK对推理复杂度、长度外推以及关键信息位置更具鲁棒性，并且在推理阶段比传统方法更高效。

Conclusion: PERK能够高效处理长上下文推理任务，相较于传统方法在性能与推理效率上都有显著提升。尽管训练时内存消耗较高，但在实际应用（推理）中展现了较好的可扩展性和效果。

Abstract: Long-context reasoning requires accurately identifying relevant information
in extensive, noisy input contexts. Previous research shows that using
test-time learning to encode context directly into model parameters can
effectively enable reasoning over noisy information. However, meta-learning
methods for enabling test-time learning are prohibitively memory-intensive,
preventing their application to long context settings. In this work, we propose
PERK (Parameter Efficient Reasoning over Knowledge), a scalable approach for
learning to encode long input contexts using gradient updates to a lightweight
model adapter at test time. Specifically, PERK employs two nested optimization
loops in a meta-training phase. The inner loop rapidly encodes contexts into a
low-rank adapter (LoRA) that serves as a parameter-efficient memory module for
the base model. Concurrently, the outer loop learns to use the updated adapter
to accurately recall and reason over relevant information from the encoded long
context. Our evaluations on several long-context reasoning tasks show that PERK
significantly outperforms the standard prompt-based long-context baseline,
achieving average absolute performance gains of up to 90% for smaller models
(GPT-2) and up to 27% for our largest evaluated model, Qwen-2.5-0.5B. In
general, PERK is more robust to reasoning complexity, length extrapolation, and
the locations of relevant information in contexts. Finally, we show that while
PERK is memory-intensive during training, it scales more efficiently at
inference time than prompt-based long-context inference.

</details>


### [17] [Reward Models Can Improve Themselves: Reward-Guided Adversarial Failure Mode Discovery for Robust Reward Modeling](https://arxiv.org/abs/2507.06419)
*Pankayaraj Pathmanathan,Furong Huang*

Main category: cs.CL

TL;DR: 本文提出了REFORM框架，利用奖励模型自身生成并修复对抗性失败样本，有效提升了奖励建模在实际场景下的鲁棒性与对齐质量，无需依赖偏好分布先验。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励模型在对齐大型语言模型时，由于人类偏好的复杂性和数据集覆盖有限，经常在分布转移或对抗扰动下表现不佳。现有方法通常依赖对这些失败模式的先验知识，实际使用中缺乏通用性。

Method: 提出了一种与偏好分布无关、可行的方法，利用奖励引导的可控解码发现奖励模型的失败模式。在此基础上，作者提出了REFORM框架，通过奖励模型自身指导生成错误评分的回答，生成对抗样本用于扩充训练数据，从而修复奖励模型的误行为。

Result: 在Anthropic HH和PKU Beavertails两个主流偏好数据集上评估，REFORM显著提升了奖励模型的鲁棒性，并且不会损失奖励质量。在直接评估和下游策略训练中均保持了性能，还通过去除虚假相关性提升了对齐质量。

Conclusion: REFORM框架能在无需偏好分布先验的情况下，有效发现并修复奖励模型的失效模式，实质性提升对齐和鲁棒性，对实际奖励建模有较高价值。

Abstract: Reward modeling (RM), which captures human preferences to align large
language models (LLMs), is increasingly employed in tasks such as model
finetuning, response filtering, and ranking. However, due to the inherent
complexity of human preferences and the limited coverage of available datasets,
reward models often fail under distributional shifts or adversarial
perturbations. Existing approaches for identifying such failure modes typically
rely on prior knowledge about preference distributions or failure attributes,
limiting their practicality in real-world settings where such information is
unavailable. In this work, we propose a tractable, preference-distribution
agnostic method for discovering reward model failure modes via reward guided
controlled decoding. Building on this, we introduce REFORM, a self-improving
reward modeling framework that enhances robustness by using the reward model
itself to guide the generation of falsely scored responses. These adversarial
examples are then used to augment the training data and patch the reward
model's misaligned behavior. We evaluate REFORM on two widely used preference
datasets Anthropic Helpful Harmless (HH) and PKU Beavertails and demonstrate
that it significantly improves robustness without sacrificing reward quality.
Notably, REFORM preserves performance both in direct evaluation and in
downstream policy training, and further improves alignment quality by removing
spurious correlations.

</details>


### [18] [Exploring Task Performance with Interpretable Models via Sparse Auto-Encoders](https://arxiv.org/abs/2507.06427)
*Shun Wang,Tyler Loakman,Youbo Lei,Yi Liu,Bohao Yang,Yuting Zhao,Dong Yang,Chenghua Lin*

Main category: cs.CL

TL;DR: 本研究用稀疏自编码器解构大语言模型，改进了模型理解、提示重写和下游任务表现，提高了可信度和实用性。


<details>
  <summary>Details</summary>
Motivation: 传统认为大语言模型（LLMs）是黑箱算法，难以理解其内部机制，这降低了其可信度，也阻碍了提升模型下游任务性能的方法开发。

Method: 采用基于稀疏自编码器的字典学习方法，将LLM中的多义神经元分解出单一语义特征（monosemantic features）。

Result: 该方法不仅揭示了模型内部的误解，还能自动重写提示（prompts）并加入注释，从而提升了LLM对输入的理解。同时，在数学推理和隐喻检测等下游任务中，模型性能显著提升。

Conclusion: 通过模型解构，能更好地理解与提升LLM的表现和可解释性，为下游任务带来性能上的提升。

Abstract: Large Language Models (LLMs) are traditionally viewed as black-box
algorithms, therefore reducing trustworthiness and obscuring potential
approaches to increasing performance on downstream tasks. In this work, we
apply an effective LLM decomposition method using a dictionary-learning
approach with sparse autoencoders. This helps extract monosemantic features
from polysemantic LLM neurons. Remarkably, our work identifies model-internal
misunderstanding, allowing the automatic reformulation of the prompts with
additional annotations to improve the interpretation by LLMs. Moreover, this
approach demonstrates a significant performance improvement in downstream
tasks, such as mathematical reasoning and metaphor detection.

</details>


### [19] [Temporal Analysis of Climate Policy Discourse: Insights from Dynamic Embedded Topic Modeling](https://arxiv.org/abs/2507.06435)
*Rafiu Adekoya Badekale,Adewale Akinfaderin*

Main category: cs.CL

TL;DR: 本文基于DETM模型，自动分析了1995-2023年联合国气候政策文本的主题变化，实现了政策演化趋势的高效追踪，为全球治理与应对复杂危机提供了数据支持和方法创新。


<details>
  <summary>Details</summary>
Motivation: 理解政策语言随时间的演变，对评估全球应对复杂挑战（如气候变化）至关重要。传统人工编码方法效率低、难以捕捉复杂话语联系，亟需引入更高效的机器学习方法。

Method: 收集1995-2023年联合国气候变化框架公约（UNFCCC）政策决策文本，采用DETM模型进行主题演化建模，包括数据预处理、模型训练及词分布时序可视化。

Result: 模型揭示了政策话语重心从早期的温室气体和国际公约，逐步转向近期的实施、技术合作、能力建设、金融支持和全球协定等领域。

Conclusion: DETM（动态嵌入主题模型）能够有效、可扩展地分析全球政策话语的演变，为政策制定和主题追踪提供了新工具，后续可推广到其他政策领域。

Abstract: Understanding how policy language evolves over time is critical for assessing
global responses to complex challenges such as climate change. Temporal
analysis helps stakeholders, including policymakers and researchers, to
evaluate past priorities, identify emerging themes, design governance
strategies, and develop mitigation measures. Traditional approaches, such as
manual thematic coding, are time-consuming and limited in capturing the
complex, interconnected nature of global policy discourse. With the increasing
relevance of unsupervised machine learning, these limitations can be addressed,
particularly under high-volume, complex, and high-dimensional data conditions.
In this work, we explore a novel approach that applies the dynamic embedded
topic model (DETM) to analyze the evolution of global climate policy discourse.
A probabilistic model designed to capture the temporal dynamics of topics over
time. We collected a corpus of United Nations Framework Convention on Climate
Change (UNFCCC) policy decisions from 1995 to 2023, excluding 2020 due to the
postponement of COP26 as a result of the COVID-19 pandemic. The model reveals
shifts from early emphases on greenhouse gases and international conventions to
recent focuses on implementation, technical collaboration, capacity building,
finance, and global agreements. Section 3 presents the modeling pipeline,
including preprocessing, model training, and visualization of temporal word
distributions. Our results show that DETM is a scalable and effective tool for
analyzing the evolution of global policy discourse. Section 4 discusses the
implications of these findings and we concluded with future directions and
refinements to extend this approach to other policy domains.

</details>


### [20] [Perception-Aware Policy Optimization for Multimodal Reasoning](https://arxiv.org/abs/2507.06448)
*Zhenhailong Wang,Xuehang Guo,Sofia Stoica,Haiyang Xu,Hongru Wang,Hyeonjeong Ha,Xiusi Chen,Yangyi Chen,Ming Yan,Fei Huang,Heng Ji*

Main category: cs.CL

TL;DR: 该工作提出PAPO方法，显著提升了大语言模型在多模态推理中的感知和推理能力，且无需新增外部数据或奖励，尤其在视觉任务中表现突出，同时还缓解了损失攻破问题，是RLVR的一大进步。


<details>
  <summary>Details</summary>
Motivation: 现有的基于可验证奖励的强化学习（RLVR）方法虽然在文本领域大幅提升了大语言模型（LLM）的多步推理能力，但在多模态推理时表现不佳，主要原因是视觉感知能力不足，导致感知输入的错误频发。作者希望提升模型在多模态推理中的感知和推理能力。

Method: 提出了一种感知感知策略优化方法（PAPO），这是对GRPO的扩展。PAPO在目标中加入了隐式感知损失（KL散度项），实现感知与推理的同步学习，且仅依赖模型内部的监督信号，无需新增数据、外部奖励或专有模型。论文还提出了Double Entropy Loss来缓解新发现的损失被攻破（loss hacking）问题。

Result: PAPO在多样化多模态基准上实现了4.4%的性能提升，在强依赖视觉的任务上提升接近8.0%。感知错误减少了30.5%，显著增强了模型的感知能力。还专门分析并解决了损失攻破问题。

Conclusion: PAPO有效将感知能力纳入RLVR目标中，为多模态推理提供了更具视觉依赖性的强化学习新方法，并解决了感知方面的短板。为未来基于视觉的推理型RL框架奠定基础。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a
highly effective strategy for endowing Large Language Models (LLMs) with robust
multi-step reasoning abilities. However, its design and optimizations remain
tailored to purely textual domains, resulting in suboptimal performance when
applied to multimodal reasoning tasks. In particular, we observe that a major
source of error in current multimodal reasoning lies in the perception of
visual inputs. To address this bottleneck, we propose Perception-Aware Policy
Optimization (PAPO), a simple yet effective extension of GRPO that encourages
the model to learn to perceive while learning to reason, entirely from internal
supervision signals. Notably, PAPO does not rely on additional data curation,
external reward models, or proprietary models. Specifically, we introduce the
Implicit Perception Loss in the form of a KL divergence term to the GRPO
objective, which, despite its simplicity, yields significant overall
improvements (4.4%) on diverse multimodal benchmarks. The improvements are more
pronounced, approaching 8.0%, on tasks with high vision dependency. We also
observe a substantial reduction (30.5%) in perception errors, indicating
improved perceptual capabilities with PAPO. We conduct comprehensive analysis
of PAPO and identify a unique loss hacking issue, which we rigorously analyze
and mitigate through a Double Entropy Loss. Overall, our work introduces a
deeper integration of perception-aware supervision into RLVR learning
objectives and lays the groundwork for a new RL framework that encourages
visually grounded reasoning. Project page: https://mikewangwzhl.github.io/PAPO.

</details>


### [21] [A Semantic Parsing Framework for End-to-End Time Normalization](https://arxiv.org/abs/2507.06450)
*Xin Su,Sungduk Yu,Phillip Howard,Steven Bethard*

Main category: cs.CL

TL;DR: 本文提出将时间归一化视为基于SCATE框架的代码生成任务，并通过LLM自动合成数据用于训练小型可部署模型，结果显示方法大幅提升了性能和可解释性，实现了超越传统和父模型的表现。


<details>
  <summary>Details</summary>
Motivation: 传统的时间归一化系统（如ISO-TimeML）表达能力有限，难以处理复杂的时间表达（如组合型、事件相关、多区间时间表达），这限制了下游应用的发展。

Method: 提出将时间归一化任务转化为基于SCATE框架的代码生成任务，同时实现了可执行的SCATE Python库，利用大型语言模型（LLM）自动生成大量带有代码级校验的标注数据，并用此数据训练小型本地模型。

Result: 实验表明，使用数据增强后训练的小型本地模型在时间归一化任务中表现优异，甚至超越了用于生成数据的LLM本身，且具备实际应用价值。

Conclusion: 新的代码生成方法及数据增强流程显著提升了时间归一化的准确性和可解释性，突破了传统方法的表达和性能瓶颈。

Abstract: Time normalization is the task of converting natural language temporal
expressions into machine-readable representations. It underpins many downstream
applications in information retrieval, question answering, and clinical
decision-making. Traditional systems based on the ISO-TimeML schema limit
expressivity and struggle with complex constructs such as compositional,
event-relative, and multi-span time expressions. In this work, we introduce a
novel formulation of time normalization as a code generation task grounded in
the SCATE framework, which defines temporal semantics through symbolic and
compositional operators. We implement a fully executable SCATE Python library
and demonstrate that large language models (LLMs) can generate executable SCATE
code. Leveraging this capability, we develop an automatic data augmentation
pipeline using LLMs to synthesize large-scale annotated data with code-level
validation. Our experiments show that small, locally deployable models trained
on this augmented data can achieve strong performance, outperforming even their
LLM parents and enabling practical, accurate, and interpretable time
normalization.

</details>


### [22] [A Systematic Analysis of Hybrid Linear Attention](https://arxiv.org/abs/2507.06457)
*Dustin Wang,Rui-Jie Zhu,Steven Abreu,Yong Shan,Taylor Kergan,Yuqi Pan,Yuhong Chou,Zheng Li,Ge Zhang,Wenhao Huang,Jason Eshraghian*

Main category: cs.CL

TL;DR: 本文系统评测了多种线性注意力模型在混合结构中的表现，并提出了混合比例和架构的推荐。结果显示，混合中全注意力层的比例对回忆性能影响较大，选择性门控和分层机制至关重要。建议3:1到6:1的线性-全注意力比例，并已开源全部实验模型。


<details>
  <summary>Details</summary>
Motivation: Transformers在处理长序列时面临平方级别的复杂度和内存瓶颈，因此线性注意力机制应运而生。但线性注意力模型在回忆性能方面存在不足，促使研究者提出线性-全注意力混合结构。然而，混合架构中线性注意力模块的具体选择尚未被系统研究。

Method: 系统性地评估了多代线性注意力模型（从向量递归到高级门控机制），既作为单独模型也作为混合型模型。训练了并开源了72个模型，涵盖六种线性注意力变体、五种混合比例，在340M和1.3B参数规模、20B和100B训练Token下进行测试，在标准语言建模与回忆任务上基准测试。

Result: 发现表现较好的单独线性模型未必能在混合模型中维持优势。随着全注意力层占比增加，回忆性能显著提升，尤其在3:1以下混合比例时。而语言建模能力在不同混合比例下相对稳定。强调了选择性门控、分层递归和可控遗忘机制在混合架构中的重要性。

Conclusion: 建议采用HGRN-2或GatedDeltaNet等架构，并将线性与全注意力混合比例设置在3:1到6:1之间，以在效率和回忆能力之间取得Transformer级别的平衡。所有模型均已开源。

Abstract: Transformers face quadratic complexity and memory issues with long sequences,
prompting the adoption of linear attention mechanisms using fixed-size hidden
states. However, linear models often suffer from limited recall performance,
leading to hybrid architectures that combine linear and full attention layers.
Despite extensive hybrid architecture research, the choice of linear attention
component has not been deeply explored. We systematically evaluate various
linear attention models across generations - vector recurrences to advanced
gating mechanisms - both standalone and hybridized. To enable this
comprehensive analysis, we trained and open-sourced 72 models: 36 at 340M
parameters (20B tokens) and 36 at 1.3B parameters (100B tokens), covering six
linear attention variants across five hybridization ratios. Benchmarking on
standard language modeling and recall tasks reveals that superior standalone
linear models do not necessarily excel in hybrids. While language modeling
remains stable across linear-to-full attention ratios, recall significantly
improves with increased full attention layers, particularly below a 3:1 ratio.
Our study highlights selective gating, hierarchical recurrence, and controlled
forgetting as critical for effective hybrid models. We recommend architectures
such as HGRN-2 or GatedDeltaNet with a linear-to-full ratio between 3:1 and 6:1
to achieve Transformer-level recall efficiently. Our models are open-sourced at
https://huggingface.co/collections/m-a-p/hybrid-linear-attention-research-686c488a63d609d2f20e2b1e.

</details>


### [23] [On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks](https://arxiv.org/abs/2507.06489)
*Stephen Obadinma,Xiaodan Zhu*

Main category: cs.CL

TL;DR: 本文系统分析了大语言模型表达信心时在对抗性攻击下的脆弱性，并提出新的攻击框架。实验表明，当前方法很难防御这种攻击，凸显了设计更健壮信心表达机制的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在关键领域的应用，对其生成稳定可靠信心表述的需求日益增加，以保障人机交互的透明度、信任与安全。

Method: 提出了针对LLM口头自信度的新型干扰与绕过对抗攻击框架，测试了不同的提示方式、模型规模及应用领域。

Result: 对抗性攻击极易影响模型的口头自信评分，引发频繁的答案变动，而目前广泛使用的信心表达方式与防御技术无法有效抵御此类攻击。

Conclusion: 现有大语言模型（LLM）用于表达自信度的机制在面对对抗性攻击时非常脆弱，现有防御手段无效甚至适得其反。

Abstract: Robust verbal confidence generated by large language models (LLMs) is crucial
for the deployment of LLMs to ensure transparency, trust, and safety in
human-AI interactions across many high-stakes applications. In this paper, we
present the first comprehensive study on the robustness of verbal confidence
under adversarial attacks. We introduce a novel framework for attacking verbal
confidence scores through both perturbation and jailbreak-based methods, and
show that these attacks can significantly jeopardize verbal confidence
estimates and lead to frequent answer changes. We examine a variety of
prompting strategies, model sizes, and application domains, revealing that
current confidence elicitation methods are vulnerable and that commonly used
defence techniques are largely ineffective or counterproductive. Our findings
underscore the urgent need to design more robust mechanisms for confidence
expression in LLMs, as even subtle semantic-preserving modifications can lead
to misleading confidence in responses.

</details>


### [24] [Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings](https://arxiv.org/abs/2507.06506)
*Russell Taylor,Benjamin Herbert,Michael Sana*

Main category: cs.CL

TL;DR: 本文提出新颖方法结合大型语言模型和专业技术，实现英法文字游戏高质量翻译，在国际竞赛中获佳绩，有效提升了幽默与创造力的跨语际传递能力。


<details>
  <summary>Details</summary>
Motivation: 传统翻译（包括人工和机器）难以保留字谜、双关等文字游戏的幽默和创造力。本研究旨在突破字面翻译限制，探索如何更好地将源语言的语言巧思和文化幽默传达给目标语受众。

Method: 方法包括三阶段：首先用多种前沿大语言模型建立基线，通过新对比学习数据集进行反馈；第二，实施结合语音—语义嵌入的引导式思路链流程；第三，采用多智能体生成—判别框架，对双关语进行评价和再生成并持续反馈。

Result: 提出的系统在CLEF JOKER 2025 Task 2竞赛中取得第一和第二名，表现优异，经法语母语专家人工评审认可。同时推动了翻译学与计算语言学的交叉与发展。

Conclusion: 该研究证明了结合大语言模型与专门的文字游戏生成技术，能有效提升英法文字游戏翻译的创造性和幽默感表现，突破了以往直译无法传达趣味和机智的局限。

Abstract: Translating wordplay across languages presents unique challenges that have
long confounded both professional human translators and machine translation
systems. This research proposes a novel approach for translating puns from
English to French by combining state-of-the-art large language models with
specialized techniques for wordplay generation.
  Our methodology employs a three-stage approach. First, we establish a
baseline using multiple frontier large language models with feedback based on a
new contrastive learning dataset. Second, we implement a guided
chain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we
implement a multi-agent generator-discriminator framework for evaluating and
regenerating puns with feedback.
  Moving beyond the limitations of literal translation, our methodology's
primary objective is to capture the linguistic creativity and humor of the
source text wordplay, rather than simply duplicating its vocabulary. Our best
runs earned first and second place in the CLEF JOKER 2025 Task 2 competition
where they were evaluated manually by expert native French speakers.
  This research addresses a gap between translation studies and computational
linguistics by implementing linguistically-informed techniques for wordplay
translation, advancing our understanding of how language models can be
leveraged to handle the complex interplay between semantic ambiguity, phonetic
similarity, and the implicit cultural and linguistic awareness needed for
successful humor.

</details>


### [25] [Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues](https://arxiv.org/abs/2507.06910)
*Fareya Ikram,Alexander Scarlatos,Andrew Lan*

Main category: cs.CL

TL;DR: 研究发现现有大语言模型难以准确预测未来的导师策略，而导师策略又对学生结果有显著影响，表明需要开发更强的预测方法。


<details>
  <summary>Details</summary>
Motivation: 在线学习兴起和大语言模型推动的AI导师能力提升，促使研究人员关注导师在辅导对话中的策略对学生结果的影响。然而，关于预测导师下一步策略的研究较少。

Method: 本文采用Llama 3和GPT-4o两种先进的LLM，对两个数学辅导对话数据集进行实验，评估其预测未来导师行为和学生结果的能力。

Result: 即使是最先进的LLM在预测未来导师策略方面依然表现较差，而老师的策略对学生结果又有很强的指示作用。

Conclusion: 现有LLM在预测导师策略方面能力有限，需要更强大的方法来提升这一任务的表现。

Abstract: Tutoring dialogues have gained significant attention in recent years, given
the prominence of online learning and the emerging tutoring abilities of
artificial intelligence (AI) agents powered by large language models (LLMs).
Recent studies have shown that the strategies used by tutors can have
significant effects on student outcomes, necessitating methods to predict how
tutors will behave and how their actions impact students. However, few works
have studied predicting tutor strategy in dialogues. Therefore, in this work we
investigate the ability of modern LLMs, particularly Llama 3 and GPT-4o, to
predict both future tutor moves and student outcomes in dialogues, using two
math tutoring dialogue datasets. We find that even state-of-the-art LLMs
struggle to predict future tutor strategy while tutor strategy is highly
indicative of student outcomes, outlining a need for more powerful methods to
approach this task.

</details>


### [26] [SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers](https://arxiv.org/abs/2507.06517)
*Zicong Tang,Shi Luohe,Zuchao Li,Baoyuan Qi,Guoming Liu,Lefei Zhang,Ping Wang*

Main category: cs.CL

TL;DR: 本文提出SpindleKV，一种兼顾浅层和深层KV缓存压缩的新方法，在减少内存消耗的同时保持了模型性能优势。


<details>
  <summary>Details</summary>
Motivation: KV缓存的内存消耗日益增加，成为大语言模型推理系统中的挑战。虽然现有方法发现深层KV缓存有冗余可压缩，但浅层KV缓存压缩效果有限。作者注意到KV缓存高度相似性，驱动新方法提出。

Method: 提出SpindleKV，一种针对不同层次采取不同策略的KV缓存压缩方法：深层采用基于注意力权重的驱逐机制；浅层采用通过相似性学习和合并策略训练出的码本替换方法。此外，还解决了现有方法在分组查询注意力（GQA）机制下的难题。

Result: 在两个常用基准和三种不同大语言模型上，SpindleKV实现了比基线方法更好的KV缓存压缩效果，并保持了相近或更优的模型性能。

Conclusion: SpindleKV方法在压缩KV缓存方面取得了优异表现，能有效减少内存消耗且不影响模型精度，尤其解决了不同层级KV缓存压缩的平衡和GQA难题。

Abstract: Large Language Models (LLMs) have achieved impressive accomplishments in
recent years. However, the increasing memory consumption of KV cache has
possessed a significant challenge to the inference system. Eviction methods
have revealed the inherent redundancy within the KV cache, demonstrating its
potential for reduction, particularly in deeper layers. However, KV cache
reduction for shallower layers has been found to be insufficient. Based on our
observation that, the KV cache exhibits a high degree of similarity. Based on
this observation, we proposed a novel KV cache reduction method, SpindleKV,
which balances both shallow and deep layers. For deep layers, we employ an
attention weight based eviction method, while for shallow layers, we apply a
codebook based replacement approach which is learnt by similarity and merging
policy. Moreover, SpindleKV addressed the Grouped-Query Attention (GQA) dilemma
faced by other attention based eviction methods. Experiments on two common
benchmarks with three different LLMs shown that SpindleKV obtained better KV
cache reduction effect compared to baseline methods, while preserving similar
or even better model performance.

</details>


### [27] [InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior](https://arxiv.org/abs/2507.06528)
*Huisheng Wang,Zhuoshi Pan,Hangjing Zhang,Mingxiao Liu,Hanqing Gao,H. Vicky Zhao*

Main category: cs.CL

TL;DR: 本文提出InvestAlign框架，通过利用理论解合成SFT数据，低成本高效地训练LLM，使其更好地模拟投资者在羊群行为下的决策，实验和理论分析均表明该方法优于传统使用真实用户数据的方式。


<details>
  <summary>Details</summary>
Motivation: 行为金融领域关注让大型语言模型（LLM）更好地模拟投资者在羊群行为下的决策过程，但由于真实用户数据稀缺，受监督微调（SFT）面临数据收集成本高和隐私风险的问题。

Method: 提出InvestAlign框架，利用类似、简单最优投资问题的理论解代替复杂情景，合成高质量SFT微调数据。通过理论分析和实验，比较了用InvestAlign数据与真实用户数据训练LLM的表现。

Result: 用InvestAlign生成的数据训练的LLM参数收敛更快，学习效率更高。基于InvestAlign微调的InvestAgent在各类投资问题上与真实用户数据的对齐度优于未微调模型。

Conclusion: InvestAlign为解决投资领域复杂决策建模和LLM对齐提供了高效、低成本、隐私友好的新方案。实验验证其在行为金融领域应用的可行性和潜力。

Abstract: Aligning Large Language Models (LLMs) with investor decision-making processes
under herd behavior is a critical challenge in behavioral finance, which
grapples with a fundamental limitation: the scarcity of real-user data needed
for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM
outputs and human behavioral patterns, its reliance on massive authentic data
imposes substantial collection costs and privacy risks. We propose InvestAlign,
a novel framework that constructs high-quality SFT datasets by leveraging
theoretical solutions to similar and simple optimal investment problems rather
than complex scenarios. Our theoretical analysis demonstrates that training
LLMs with InvestAlign-generated data achieves faster parameter convergence than
using real-user data, suggesting superior learning efficiency. Furthermore, we
develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which
demonstrates significantly closer alignment to real-user data than pre-SFT
models in both simple and complex investment problems. This highlights our
proposed InvestAlign as a promising approach with the potential to address
complex optimal investment problems and align LLMs with investor
decision-making processes under herd behavior. Our code is publicly available
at https://github.com/thu-social-network-research-group/InvestAlign.

</details>


### [28] [Large Language Model for Extracting Complex Contract Information in Industrial Scenes](https://arxiv.org/abs/2507.06539)
*Yunyang Cao,Yanjun Li,Silong Dai*

Main category: cs.CL

TL;DR: 本文提出一种高质量数据集构建方法结合大模型微调，成功提升了合同信息抽取的准确性与鲁棒性，为工业实际应用提供了高效方案。


<details>
  <summary>Details</summary>
Motivation: 工业场景下的合同信息提取任务复杂，缺乏高质量数据集限制了模型性能提升。

Method: 首先对合同文本聚类分析，借助GPT-4和GPT-3.5自动抽取关键信息生成高质量标注数据。其次使用关键词随机组合和大模型（GPT-3.5）生成新的非结构化合同文本进行数据增强。最后用这些高质量数据集对大语言模型进行微调，同时应用LoRA、数据均衡等技术。

Result: 实验表明该方法在保证高召回率和高精度的情况下，取得了出色的整体性能，且解析效率良好。数据增强、均衡、LoRA显著提升了模型的准确性和鲁棒性。

Conclusion: 所提出的数据集构建与模型微调方法，有效提升了工业合同信息抽取的整体表现，是面向该领域的一种新颖且高效的解决方案。

Abstract: This paper proposes a high-quality dataset construction method for complex
contract information extraction tasks in industrial scenarios and fine-tunes a
large language model based on this dataset. Firstly, cluster analysis is
performed on industrial contract texts, and GPT-4 and GPT-3.5 are used to
extract key information from the original contract data, obtaining high-quality
data annotations. Secondly, data augmentation is achieved by constructing new
texts, and GPT-3.5 generates unstructured contract texts from randomly combined
keywords, improving model robustness. Finally, the large language model is
fine-tuned based on the high-quality dataset. Experimental results show that
the model achieves excellent overall performance while ensuring high field
recall and precision and considering parsing efficiency. LoRA, data balancing,
and data augmentation effectively enhance model accuracy and robustness. The
proposed method provides a novel and efficient solution for industrial contract
information extraction tasks.

</details>


### [29] [The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production](https://arxiv.org/abs/2507.06565)
*Juan B. Gutiérrez*

Main category: cs.CL

TL;DR: 本论文提出，将人和大语言模型节点组建成带有互评公共机制的话语网络，比单一完善模型更能提高整体文本输出的真实性和可靠性。通过数学建模与FOO算法实验，在多代理互相批改下，虚假信息可大幅度被抑制，网络输出更稳定真实。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型面临事实、逻辑、结构性错误频发的问题，单一模型难以根本解决。作者旨在探讨如何通过网络结构改变与提高生成文本的可靠性。

Method: 作者首先以人和LLM为平等节点构建话语网络数学模型，分析典型失效（invalidations）及其四种风险来源，并开发Flaws-of-Others (FOO)算法，将同行互评机制嵌入网络，通过多代理互相批判和结论整合来验证这一机制的有效性。

Result: 理论模型显示，仅有“漂移与自我修正”机制尚可稳定于中等错误率；若加入虚构，则与现有LLM错误率吻合。引入同行评议后，哪怕只给每条错误信息微小的纠错机会，系统就能显著转向以真实为主导的状态。FOO算法实验也证实了这种机制的有效性。

Conclusion: 该文提出，与其追求单一大模型的完美，不如将多个不完美模型/人组网，通过彼此纠错来提高整体输出的可靠性，这种网络结构更有助于信息的真实与准确流动。

Abstract: Large-language models turn writing into a live exchange between humans and
software. We capture this new medium with a discursive-network model that
treats people and LLMs as equal nodes and tracks how their statements
circulate. Broadening the focus from isolated hallucinations, we define
invalidation (any factual, logical, or structural breach) and show it follows
four hazards: drift from truth, self-repair, fresh fabrication, and external
detection. A general mathematical model of discursive networks is developed to
provide valuable insights: A network governed only by drift and self-repair
stabilizes at a modest error rate; adding fabrication reproduces the high rates
seen in current LLMs. Giving each false claim even a small chance of peer
review shifts the system to a truth-dominant state. We operationalize peer
review with the open-source \emph{Flaws-of-Others (FOO) algorithm}: a
configurable loop in which any set of agents critique one another while a
harmoniser merges their verdicts. The takeaway is practical and cultural:
reliability in this new medium comes not from perfecting single models but from
wiring imperfect ones into networks that keep each other honest.

</details>


### [30] [Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review](https://arxiv.org/abs/2507.06623)
*James Stewart-Evans,Emma Wilson,Tessa Langley,Andrew Prayle,Angela Hands,Karen Exley,Jo Leonardi-Bee*

Main category: cs.CL

TL;DR: 本文评估了利用LLM+协议自动化数据提取的效果，对简单数据项有效但复杂度提升后召回率极低，对错误的识别能力也较差。LLM可辅助协议优化，但全面替代人工尚不现实，需进一步测试并谨慎使用。


<details>
  <summary>Details</summary>
Motivation: 数据提取是系统综述中的高资源消耗环节，研究者希望通过利用在线大语言模型（LLMs）和综述方案，提高数据提取的效率和准确性。本文尝试用Claude 3.5 Sonnet探索如何通过协议驱动的提示来自动化此过程。

Method: 本文基于案例研究法，在一项scoping review中从10个证据源中尝试了两种基于综述协议的数据提取方法，并用协议辅助复审抽取数据。性能评估包括准确率、精确率、召回率及F1值等常见指标。另有一组含有刻意错误的数据用以测试错误检测能力。

Result: 两种方法在提取简单明确定义的引文详细信息时准确率较高（83.3%与100%），但对于复杂主观数据的准确率较低（9.6%和15.8%）。总体上两者的精确率均大于90%，但召回率低于25%，F1值不到40%。对故意引入错误的数据集，错误检出率仅5%。LLM在反馈修订方面有一定贡献，但错漏依然较多。

Conclusion: 基于协议的LLM数据提取在复杂综述情境下表现尚不理想，精确率高但召回率与全面性不足，错误检测能力有限。该方法尚需在不同LLM及综述场景下开展更系统的评估，并与经典prompt工程法对比。建议未来在实际应用时需严格评估和报告LLM表现，并结合LLM反馈优化综述协议。

Abstract: The data extraction stages of reviews are resource-intensive, and researchers
may seek to expediate data extraction using online (large language models) LLMs
and review protocols. Claude 3.5 Sonnet was used to trial two approaches that
used a review protocol to prompt data extraction from 10 evidence sources
included in a case study scoping review. A protocol-based approach was also
used to review extracted data. Limited performance evaluation was undertaken
which found high accuracy for the two extraction approaches (83.3% and 100%)
when extracting simple, well-defined citation details; accuracy was lower (9.6%
and 15.8%) when extracting more complex, subjective data items. Considering all
data items, both approaches had precision >90% but low recall (<25%) and F1
scores (<40%). The context of a complex scoping review, open response types and
methodological approach likely impacted performance due to missed and
misattributed data. LLM feedback considered the baseline extraction accurate
and suggested minor amendments: four of 15 (26.7%) to citation details and 8 of
38 (21.1%) to key findings data items were considered to potentially add value.
However, when repeating the process with a dataset featuring deliberate errors,
only 2 of 39 (5%) errors were detected. Review-protocol-based methods used for
expediency require more robust performance evaluation across a range of LLMs
and review contexts with comparison to conventional prompt engineering
approaches. We recommend researchers evaluate and report LLM performance if
using them similarly to conduct data extraction or review extracted data. LLM
feedback contributed to protocol adaptation and may assist future review
protocol drafting.

</details>


### [31] [Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis](https://arxiv.org/abs/2507.06571)
*Srihari K B,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 利用多模态知识图谱和生成式AI，极大提升了美食问答系统的准确性与多样性，表现优于以往方法。


<details>
  <summary>Details</summary>
Motivation: 现有美食领域的问答系统在多模态信息（如文本、图片）整合和知识的全面性方面存在不足，因此需要一个能够结合大规模知识与生成式AI的方法来提升问答的准确性与多样性。

Method: 提出了一个统一的美食领域问答框架，将大规模多模态知识图谱（MMKG）与生成式AI相结合。构建了包含13,000个菜谱、3,000个食材、140,000个关系和14,000张图片的MMKG，通过40种模板和LLaVA/DeepSeek增强生成4万组问答配对。联合微调Meta LLaMA 3.1-8B与Stable Diffusion 3.5-Large，并利用CLIP和LLaVA进行诊断分析和错误检测。采用检索-生成混合策略提升问答性能。

Result: BERTScore提升16.2%，FID降低37.8%，CLIP对齐提升31.1%；CLIP错误检测率从35.2%降至7.3%；LLaVA幻觉检查进一步提升事实和视觉的准确性；94.1%的图片复用准确率和85%的合成充分性。

Conclusion: 结构化知识与多模态生成的协同应用可有效提升美食领域问答系统的可靠性和多样性。

Abstract: We propose a unified food-domain QA framework that combines a large-scale
multimodal knowledge graph (MMKG) with generative AI. Our MMKG links 13,000
recipes, 3,000 ingredients, 140,000 relations, and 14,000 images. We generate
40,000 QA pairs using 40 templates and LLaVA/DeepSeek augmentation. Joint
fine-tuning of Meta LLaMA 3.1-8B and Stable Diffusion 3.5-Large improves
BERTScore by 16.2\%, reduces FID by 37.8\%, and boosts CLIP alignment by
31.1\%. Diagnostic analyses-CLIP-based mismatch detection (35.2\% to 7.3\%) and
LLaVA-driven hallucination checks-ensure factual and visual fidelity. A hybrid
retrieval-generation strategy achieves 94.1\% accurate image reuse and 85\%
adequacy in synthesis. Our results demonstrate that structured knowledge and
multimodal generation together enhance reliability and diversity in food QA.

</details>


### [32] [Elite Polarization in European Parliamentary Speeches: a Novel Measurement Approach Using Large Language Models](https://arxiv.org/abs/2507.06658)
*Gennadii Iakovlev*

Main category: cs.CL

TL;DR: 该文提出利用人工智能自动识别和量化议会演讲中的政治精英极化，并开发出精英极化指数，能敏感捕捉政治重大事件带来的变化，具有较强实证价值。


<details>
  <summary>Details</summary>
Motivation: 当前对精英极化的测量依赖人工标注和主观判断，缺乏标准化、可跨国且长时间序列的数据。因此，作者提出开发自动化、量化工具，提升分析效率和客观性。

Method: 通过人工智能对议会演讲中的发言者和被提及者进行识别，分析情感倾向，并构建“相互外党敌意指数”作为精英极化衡量工具。

Result: 构建了可按党派和季度细分的精英极化指数，验证了其对重要政治事件具有良好反应和解释力，并为建立跨欧盟长期数据打下基础。

Conclusion: 新的精英极化指标有效反映了政党间的敌意，并能够动态跟踪相关政治事件带来的变化，证明其可用性和有效性。

Abstract: This project introduces a new measure of elite polarization via actor and
subject detection using artificial intelligence. I identify when politicians
mention one another in parliamentary speeches, note who is speaking and who is
being addressed, and assess the emotional temperature behind these evaluations.
This maps how elites evaluate their various out-parties, allowing us to create
an index of mutual out-party hostility, that is, elite polarization. While I
analyzed polarization data over the past four decades for the UK, and two
decades for Hungary and Italy, my approach lays the groundwork for a
twenty-year, EU-wide time-series dataset on elite polarization. I obtain the
results that can be aggregated by party and quarter. The resulting index
demonstrates a good face validity: it reacts to events such as electoral
campaigns, country- and party-level crises, and to parties losing and assuming
power.

</details>


### [33] [Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation](https://arxiv.org/abs/2507.06607)
*Liliang Ren,Congcong Chen,Haoran Xu,Young Jin Kim,Adam Atkinson,Zheng Zhan,Jiankai Sun,Baolin Peng,Liyuan Liu,Shuohang Wang,Hao Cheng,Jianfeng Gao,Weizhu Chen,Yelong Shen*

Main category: cs.CL

TL;DR: 本论文提出的GMU模块及基于其的SambaY混合架构，通过跨层记忆共享，显著提升了长序列推理效率和下游推理任务能力，对比主流YOCO基线在多个维度取得突破，代码已开源。


<details>
  <summary>Details</summary>
Motivation: 近年来状态空间模型（SSMs）在高效序列建模方面表现突出，部分混合架构（如Samba, YOCO）已优于经典Transformer。但现有研究尚未探索SSM层间表示共享的效率潜能。

Method: 提出了一种名为Gated Memory Unit（GMU）的机制，实现跨层高效记忆共享。基于此，设计了SambaY架构，通过在交叉解码器中利用GMU共享Samba式自解码器的记忆读出状态，从而优化了混合解码九构架。

Result: SambaY提升了解码效率、保持线性预填充时间复杂度且增强了长上下文性能，无需显式位置编码。在大规模实验中，对YOCO基线展现了更低的不可约损失，表现更优。集成差分注意力的最大模型Phi4-mini-Flash-Reasoning在多个推理任务上优于Phi4-mini-Reasoning，并能在长序列推理场景下带来高达10倍的推理吞吐量提升。

Conclusion: GMU机制和SambaY架构有效实现了跨层记忆共享，显著提升了模型的推理效率和大规模推理任务表现。

Abstract: Recent advances in language modeling have demonstrated the effectiveness of
State Space Models (SSMs) for efficient sequence modeling. While hybrid
architectures such as Samba and the decoder-decoder architecture, YOCO, have
shown promising performance gains over Transformers, prior works have not
investigated the efficiency potential of representation sharing between SSM
layers. In this paper, we introduce the Gated Memory Unit (GMU), a simple yet
effective mechanism for efficient memory sharing across layers. We apply it to
create SambaY, a decoder-hybrid-decoder architecture that incorporates GMUs in
the cross-decoder to share memory readout states from a Samba-based
self-decoder. SambaY significantly enhances decoding efficiency, preserves
linear pre-filling time complexity, and boosts long-context performance, all
while eliminating the need for explicit positional encoding. Through extensive
scaling experiments, we demonstrate that our model exhibits a significantly
lower irreducible loss compared to a strong YOCO baseline, indicating superior
performance scalability under large-scale compute regimes. Our largest model
enhanced with Differential Attention, Phi4-mini-Flash-Reasoning, achieves
significantly better performance than Phi4-mini-Reasoning on reasoning tasks
such as Math500, AIME24/25, and GPQA Diamond without any reinforcement
learning, while delivering up to 10x higher decoding throughput on 2K-length
prompts with 32K generation length under the vLLM inference framework. We
release our training codebase on open-source data at
https://github.com/microsoft/ArchScale.

</details>


### [34] [CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs](https://arxiv.org/abs/2507.06715)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: 该论文提出用于临床文本生成的新框架CLI-RAG，结合分层分块与双阶段检索，在结构化医疗文本生成上超过医生写作水平，并保证了高一致性与可复现性。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在医疗文本生成中的应用面临两个主要挑战：患者数据高度非结构化、异构且分散于多种笔记类型中；医疗笔记冗长且语义密集，传统提示方法难以涵盖所有关键信息。

Method: 提出了CLI-RAG框架，用于结构化和医学事实支撑的文本生成。该方法采用分层文本分块策略，结合特定任务的双阶段检索机制。第一阶段全局检索相关笔记类型，第二阶段局部检索笔记内部有价值的信息，实现文档和章节级别的信息相关性。

Result: 在MIMIC-III数据集上，利用15种临床笔记类型生成结构化病程记录。实验表明该方法能保持不同就诊间的时序和语义一致性，平均对齐分数为87.7%，高于真实医生笔记的80.7%，生成内容在不同大模型间的一致性高，增强了可复现性和临床信任。

Conclusion: CLI-RAG通过创新的分层分块和双阶段检索，有效解决了临床笔记生成中的结构化和关键信息提取难题，显著提升了文本生成的质量和一致性。

Abstract: Large language models (LLMs), including zero-shot and few-shot paradigms,
have shown promising capabilities in clinical text generation. However,
real-world applications face two key challenges: (1) patient data is highly
unstructured, heterogeneous, and scattered across multiple note types and (2)
clinical notes are often long and semantically dense, making naive prompting
infeasible due to context length constraints and the risk of omitting
clinically relevant information.
  We introduce CLI-RAG (Clinically Informed Retrieval-Augmented Generation), a
domain-specific framework for structured and clinically grounded text
generation using LLMs. It incorporates a novel hierarchical chunking strategy
that respects clinical document structure and introduces a task-specific
dual-stage retrieval mechanism. The global stage identifies relevant note types
using evidence-based queries, while the local stage extracts high-value content
within those notes creating relevance at both document and section levels.
  We apply the system to generate structured progress notes for individual
hospital visits using 15 clinical note types from the MIMIC-III dataset.
Experiments show that it preserves temporal and semantic alignment across
visits, achieving an average alignment score of 87.7%, surpassing the 80.7%
baseline from real clinician-authored notes. The generated outputs also
demonstrate high consistency across LLMs, reinforcing deterministic behavior
essential for reproducibility, reliability, and clinical trust.

</details>


### [35] [FuDoBa: Fusing Document and Knowledge Graph-based Representations with Bayesian Optimisation](https://arxiv.org/abs/2507.06622)
*Boshko Koloski,Senja Pollak,Roberto Navigli,Blaž Škrlj*

Main category: cs.CL

TL;DR: 本论文提出FuDoBa，一种融合领域知识与LLM嵌入、低维高效的文档表征方法，实现了比现有LLM表征更好的领域适应和分类效果。


<details>
  <summary>Details</summary>
Motivation: 受大语言模型（LLM）在文档表示领域成功的启发，但其高维嵌入常存在泛化性强、对特定领域效率低和计算成本高等问题，限制了实际应用。作者希望提升领域相关性和效率。

Method: 提出FuDoBa方法，利用贝叶斯优化，将LLM生成的嵌入与领域结构化知识（如WikiData等外部库和本地知识）进行融合，并生成低维且与任务相关的表示，同时输出可解释的融合权重。

Result: 在六个数据集、两个领域下，结合AutoML分类器后，该低维表征在分类任务上表现可与或优于传统LLM嵌入基线。

Conclusion: FuDoBa有效融合LLM嵌入与领域知识，提升了表征的效率、相关性和可解释性，为领域特定文档表示提供了优于现有LLM方法的新途径。

Abstract: Building on the success of Large Language Models (LLMs), LLM-based
representations have dominated the document representation landscape, achieving
great performance on the document embedding benchmarks. However, the
high-dimensional, computationally expensive embeddings from LLMs tend to be
either too generic or inefficient for domain-specific applications. To address
these limitations, we introduce FuDoBa a Bayesian optimisation-based method
that integrates LLM-based embeddings with domain-specific structured knowledge,
sourced both locally and from external repositories like WikiData. This fusion
produces low-dimensional, task-relevant representations while reducing training
complexity and yielding interpretable early-fusion weights for enhanced
classification performance. We demonstrate the effectiveness of our approach on
six datasets in two domains, showing that when paired with robust AutoML-based
classifiers, our proposed representation learning approach performs on par
with, or surpasses, those produced solely by the proprietary LLM-based
embedding baselines.

</details>


### [36] [KAConvText: Novel Approach to Burmese Sentence Classification using Kolmogorov-Arnold Convolution](https://arxiv.org/abs/2507.06753)
*Ye Kyaw Thu,Thura Aung,Thazin Myint Oo,Thepchai Supnithi*

Main category: cs.CL

TL;DR: 本文首次将KAConvText卷积结构应用于文本分类，显著提升了仇恨言论检测、新闻分类和语言识别三项任务的准确性和F1分数，同时兼顾了性能和解释性，表现超过传统CNN及其变种。


<details>
  <summary>Details</summary>
Motivation: 目前文本分类领域存在诸如类别不平衡、模型可解释性等挑战，因此，本文旨在提出新的建模方式以提升分类效果且增强模型解释能力。

Method: 本文首次将Kolmogorov-Arnold卷积应用于文本分类（KAConvText），针对三项任务：不平衡的二分类仇恨言论检测、均衡的多分类新闻分类、不平衡的多分类民族语言识别。研究对比了多种词嵌入及网络结构，并尝试不同分类头。

Result: KAConvText-MLP与微调后的fastText嵌入结合，在三项任务上分别取得了91.23%、92.66%、99.82%的准确率，F1分数分别为0.9109、0.9267和0.9982。

Conclusion: KAConvText在文本分类中的首次应用取得了显著效果，特别是结合MLP分类头和微调词向量时，在三种类型任务上均超越了基线方法，并通过KAN分类头提升了模型解释性。

Abstract: This paper presents the first application of Kolmogorov-Arnold Convolution
for Text (KAConvText) in sentence classification, addressing three tasks:
imbalanced binary hate speech detection, balanced multiclass news
classification, and imbalanced multiclass ethnic language identification. We
investigate various embedding configurations, comparing random to fastText
embeddings in both static and fine-tuned settings, with embedding dimensions of
100 and 300 using CBOW and Skip-gram models. Baselines include standard CNNs
and CNNs augmented with a Kolmogorov-Arnold Network (CNN-KAN). In addition, we
investigated KAConvText with different classification heads - MLP and KAN,
where using KAN head supports enhanced interpretability. Results show that
KAConvText-MLP with fine-tuned fastText embeddings achieves the best
performance of 91.23% accuracy (F1-score = 0.9109) for hate speech detection,
92.66% accuracy (F1-score = 0.9267) for news classification, and 99.82%
accuracy (F1-score = 0.9982) for language identification.

</details>


### [37] [Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications](https://arxiv.org/abs/2507.06795)
*Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon*

Main category: cs.CL

TL;DR: 针对企业缺乏大模型部署能力的问题，本文验证了用DACP方法提升小型模型领域适应性，实验证明其可在保证通用能力的同时，显著提升目标任务表现，适合企业大规模部署。


<details>
  <summary>Details</summary>
Motivation: 许多企业缺乏部署和维护大规模语言模型（LLMs）的基础设施，因此更加关注性能有限但更易管理的小模型（sLLMs）。领域自适应持续预训练（DACP）虽然被探讨用于领域适应，但其在商业应用中的有效性尚未充分验证。

Method: 本文在多种基础模型和服务领域上，采用并验证了基于DACP的小语言模型提升领域适应性的方案。通过大量实验和实际应用评测，检验了该方法的有效性。

Result: 实验和真实应用结果表明，采用DACP的小型模型在目标领域表现显著提升，同时保持了通用能力，具备成本效益高、可扩展性强的优势，适合企业部署。

Conclusion: DACP方法能够显著提升小型语言模型在特定领域的表现，是满足企业级部署需求的高性价比解决方案。

Abstract: The emergence of open-source large language models (LLMs) has expanded
opportunities for enterprise applications; however, many organizations still
lack the infrastructure to deploy and maintain large-scale models. As a result,
small LLMs (sLLMs) have become a practical alternative, despite their inherent
performance limitations. While Domain Adaptive Continual Pretraining (DACP) has
been previously explored as a method for domain adaptation, its utility in
commercial applications remains under-examined. In this study, we validate the
effectiveness of applying a DACP-based recipe across diverse foundation models
and service domains. Through extensive experiments and real-world evaluations,
we demonstrate that DACP-applied sLLMs achieve substantial gains in target
domain performance while preserving general capabilities, offering a
cost-efficient and scalable solution for enterprise-level deployment.

</details>


### [38] [On the Effect of Uncertainty on Layer-wise Inference Dynamics](https://arxiv.org/abs/2507.06722)
*Sunwoo Kim,Haneul Yoo,Alice Oh*

Main category: cs.CL

TL;DR: 本文发现大语言模型的不确定性未明显影响其推理过程，多数情况下输出概率轨迹对齐，仅有更强模型在处理不确定性上表现不同，这对利用简单方法检测模型不确定性提出了挑战。


<details>
  <summary>Details</summary>
Motivation: 深入理解大语言模型内部如何表示和处理预测中的不确定性，以及这种不确定性是否影响其推理过程，进而改进检测幻觉和提升模型可靠性的方法。

Method: 使用Tuned Lens方法分析5种模型在11个数据集上对最终预测token的分层概率轨迹，对比确定性和不确定性的预测结果。

Result: 对于正确（确定）和错误（不确定）预测，模型的输出概率轨迹层层对齐，表明绝大多数情况下不确定性未影响推理过程，但更好的模型显示出处理不确定性手法的变化。

Conclusion: 不确定性并未显著影响LLM的推理动态，唯有更强大的模型才可能学会不同处理不确定性的方式。

Abstract: Understanding how large language models (LLMs) internally represent and
process their predictions is central to detecting uncertainty and preventing
hallucinations. While several studies have shown that models encode uncertainty
in their hidden states, it is underexplored how this affects the way they
process such hidden states. In this work, we demonstrate that the dynamics of
output token probabilities across layers for certain and uncertain outputs are
largely aligned, revealing that uncertainty does not seem to affect inference
dynamics. Specifically, we use the Tuned Lens, a variant of the Logit Lens, to
analyze the layer-wise probability trajectories of final prediction tokens
across 11 datasets and 5 models. Using incorrect predictions as those with
higher epistemic uncertainty, our results show aligned trajectories for certain
and uncertain predictions that both observe abrupt increases in confidence at
similar layers. We balance this finding by showing evidence that more competent
models may learn to process uncertainty differently. Our findings challenge the
feasibility of leveraging simplistic methods for detecting uncertainty at
inference. More broadly, our work demonstrates how interpretability methods may
be used to investigate the way uncertainty affects inference.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [39] [Development and Real-World Application of Commercial Motor Vehicle Safety Enforcement Dashboards](https://arxiv.org/abs/2507.06351)
*Dhairya Parekh,Mark L. Franz Ph. D,Sara Zahedian Ph. D,Narjes Shayesteh*

Main category: cs.CE

TL;DR: 本文开发并应用了运输执法人员指导下的商用车辆安全仪表板，帮助识别和分析安全隐患及执法成效。实证案例显示工具有效但评估结果差异较大，未来需更细致的数据提升执法评估精度。


<details>
  <summary>Details</summary>
Motivation: 商用机动车辆（CMV）安全对于交通管理和公共安全至关重要。由于CMV涉及大量交通事故，因此对其安全及安检的高效监测具有重要意义。

Method: 本文在马里兰州警察局（MSP）、运输署公路管理局（MDOT-SHA）及联邦汽车运输安全管理局（FMCSA）的专业指导下，开发出能够直观、高效分析CMV安全绩效的仪表板工具。研究采用了CMV车辆速度、检查/处罚数据、巡查执法及虚拟称重站等多维数据。并以I-81公路的一段为案例，配合MSP实际合作，评估了定向执法对提升安全的影响。

Result: 利用开发的仪表板工具，CMV安全专业人员可以快速识别存在安全隐患的地点，并自动分析执法行动带来的成效。执法行动后的安全评估结果出现了好坏参半的情况，表明需要更详细的处罚数据以支持更深入的分析。

Conclusion: 本文设计并实际应用了CMV安全绩效仪表板，实现了安全问题的高效发现与执法成效的自动分析，为道路运输安全管理提供了技术支持，但进一步精细的数据采集仍然是提升绩效评估的关键。

Abstract: Commercial Motor Vehicle (CMV) safety is crucial in traffic management and
public safety. CMVs account for numerous traffic incidents, so monitoring CMV
safety and safety inspections is essential for ensuring safe and efficient
highway movement. This paper presents the development and real-world
application of CMV dashboards designed under the guidance of CMV safety
enforcement professionals from the Maryland State Police (MSP), the Maryland
Department of Transportation - State Highway Administration (MDOT - SHA), and
the Federal Motor Carrier Safety Administration (FMCSA) to enable intuitive and
efficient analysis of CMV safety performance measures. First, three CMV safety
dashboards enable CMV safety professionals to identify sites with a history of
safety performance issues. A supplemental dashboard automates the analysis of
CMV enforcement initiatives using the same performance measures. These
performance measures are based on CMV probe vehicle speeds, inspection/citation
data from Truck Weigh and Inspection Stations (TWIS), patrolling enforcement,
and Virtual Weigh Stations (VWS). The authors collaborated with MSP to identify
a portion of I-81 in Maryland, susceptible to improvement from targeted CMV
enforcement. The supplemental enforcement assessment dashboard was employed to
evaluate the impact of enforcement, including the post-enforcement halo effect.
The results of the post-enforcement evaluation were mixed, indicating a need
for more fine-grained citation data.

</details>


### [40] [Eyes on the Road, Mind Beyond Vision: Context-Aware Multi-modal Enhanced Risk Anticipation](https://arxiv.org/abs/2507.06444)
*Jiaxun Zhang,Haicheng Liao,Yumu Xie,Chengyue Wang,Yanchen Guan,Bin Rao,Zhenning Li*

Main category: cs.CE

TL;DR: 该文提出融合多模态信息和自适应机制的CAMERA框架，实现更可靠的事故预判，在多个数据集上达到领先水平。


<details>
  <summary>Details</summary>
Motivation: 现有事故预判方法往往低估了驾驶员认知和动态道路条件，导致在复杂交通场景中准确率不高。

Method: 提出了一种名为CAMERA的多模态框架，整合了行车记录仪视频、文本注释和驾驶员注意力图。该方法采用自适应机制，根据场景复杂度和注视熵动态调整风险门限，通过分层融合和Bi-GRU捕捉时空依赖，并用Geo-Context模块输出可解释的风险提示。

Result: 在DADA-2000等基准数据集上，CAMERA取得了业界领先的准确率和预判提前量，有效降低了误报率并保持高召回率。

Conclusion: 建模驾驶员注意、语境描述和自适应风险门限，能够有效提升事故预判的可靠性。

Abstract: Accurate accident anticipation remains challenging when driver cognition and
dynamic road conditions are underrepresented in predictive models. In this
paper, we propose CAMERA (Context-Aware Multi-modal Enhanced Risk
Anticipation), a multi-modal framework integrating dashcam video, textual
annotations, and driver attention maps for robust accident anticipation. Unlike
existing methods that rely on static or environment-centric thresholds, CAMERA
employs an adaptive mechanism guided by scene complexity and gaze entropy,
reducing false alarms while maintaining high recall in dynamic, multi-agent
traffic scenarios. A hierarchical fusion pipeline with Bi-GRU (Bidirectional
GRU) captures spatio-temporal dependencies, while a Geo-Context Vision-Language
module translates 3D spatial relationships into interpretable, human-centric
alerts. Evaluations on the DADA-2000 and benchmarks show that CAMERA achieves
state-of-the-art performance, improving accuracy and lead time. These results
demonstrate the effectiveness of modeling driver attention, contextual
description, and adaptive risk thresholds to enable more reliable accident
anticipation.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [41] [The Emotional Alignment Design Policy](https://arxiv.org/abs/2507.06263)
*Eric Schwitzgebel,Jeff Sebo*

Main category: cs.CY

TL;DR: 论文提出“情感对齐设计准则”，要求人工智能等实体激发与自身能力和道德地位相符的情感。作者讨论了准则被违反的方式，并分析了实际执行面临的伦理与实践难题，例如用户自主、价值分歧和公众认知等，指出未来仍需深入研究。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和其他人工实体的普及，用户与智能体的情感交互变得越来越重要。作者提出应关注人工实体被设计成激发与其能力和道德地位相符的情感反应——即“情感对齐设计准则”，以减少不当情感反应带来的伦理风险。

Method: 文章采用伦理哲学分析，构建理论模型，系统梳理人工智能与用户之间情感对齐的原则及其违反方式，并讨论相关伦理和实践挑战。

Result: 提出情感对齐设计准则：人工实体应激发与自身能力及其道德地位相符的情感反应。论文总结了三大挑战，包括尊重用户自主、处理事实与价值观争议，以及用户假设与态度的问题。此外，还提出了错误类型（情感过度、缺乏、或类型错误）的具体实例与理论分析。

Conclusion: 情感对齐设计准则为人工智能伦理设计提供了新的思路，但其实际应用面临诸多挑战，需要在尊重用户以及社会伦理多样性的前提下，慎重推进。

Abstract: According to what we call the Emotional Alignment Design Policy, artificial
entities should be designed to elicit emotional reactions from users that
appropriately reflect the entities' capacities and moral status, or lack
thereof. This principle can be violated in two ways: by designing an artificial
system that elicits stronger or weaker emotional reactions than its capacities
and moral status warrant (overshooting or undershooting), or by designing a
system that elicits the wrong type of emotional reaction (hitting the wrong
target). Although presumably attractive, practical implementation faces several
challenges including: How can we respect user autonomy while promoting
appropriate responses? How should we navigate expert and public disagreement
and uncertainty about facts and values? What if emotional alignment seems to
require creating or destroying entities with moral status? To what extent
should designs conform to versus attempt to alter user assumptions and
attitudes?

</details>


### [42] [A Collectivist, Economic Perspective on AI](https://arxiv.org/abs/2507.06268)
*Michael I. Jordan*

Main category: cs.CY

TL;DR: 信息技术应关注人类社会性，系统融合社会、经济和推理方法，让社会福祉成为技术发展的核心目标。


<details>
  <summary>Details</summary>
Motivation: 当前信息技术飞速发展，智能技术广泛应用，但目前主要关注人类认知智能，忽略了人类智力的社会性与文化性来源，并且技术的社会影响常被事后才考虑。

Method: 提出“将经济与社会概念和计算、推理方法深度融合”的观点，倡导系统层次下以社会福祉为核心目标的设计理念。

Result: 呼吁信息技术和人工智能领域，超越单纯认知和符号处理，推动以人为本、关注社会福利的新工科方向的发展。

Conclusion: 技术发展应综合考量经济、社会、推理等多维度因素，把社会影响与社会福祉摆在首要位置，推动新时代以人和社会为核心的技术工程学科的诞生。

Abstract: Information technology is in the midst of a revolution in which omnipresent
data collection and machine learning are impacting the human world as never
before. The word "intelligence" is being used as a North Star for the
development of this technology, with human cognition viewed as a baseline. This
view neglects the fact that humans are social animals, and that much of our
intelligence is social and cultural in origin. A related issue is that the
current view treats the social consequences of technology as an afterthought.
The path forward is not merely more data and compute, and not merely more
attention paid to cognitive or symbolic representations, but a thorough
blending of economic and social concepts with computational and inferential
concepts, in the service of system-level designs in which social welfare is a
first-class citizen, and with the aspiration that a new human-centric
engineering field will emerge.

</details>


### [43] [The Prompt War: How AI Decides on a Military Intervention](https://arxiv.org/abs/2507.06277)
*Maxim Chupilkin*

Main category: cs.CY

TL;DR: 本研究系统分析了AI在军事干预决策中的主要驱动因素，发现国内支持和成功概率最影响AI决策，三大主流AI模型表现出一致性。


<details>
  <summary>Details</summary>
Motivation: 目前AI在军事游戏和决策中的应用越来越多，但尚未有系统性地分析其军事干预决策主要驱动因素的研究。作者希望揭示AI在何种条件下更倾向于支持军事干预。

Method: 采用联合分析实验（conjoint experiment），设计了640个情景，每个情景运行100次，系统性探讨AI对于是否进行军事干预的决策偏好。涉及的AI模型包括OpenAI GPT、Anthropic Claude和Google Gemini。

Result: 实验发现，影响AI做出干预决策的最大因素是高国内支持率及高成功概率。国际谴责、士兵死亡、平民死亡、经济负面影响对AI决策也有显著影响，但这些因素的影响力约为前两者的一半。“窗口机会”的紧迫性只有与其他变量交互时才显著。

Conclusion: 各种AI模型对于军事干预决策的偏好模式高度一致，AI倾向于在国内支持率高及成功概率大的情况下做出干预，成本因素虽重要但权重较低。该研究揭示了AI军事决策的内在逻辑。

Abstract: Which factors determine AI propensity for military intervention? While the
use of AI in war games and military planning is growing exponentially, the
simple analysis of key drivers embedded in the models has not yet been done.
This paper does a simple conjoint experiment proposing a model to decide on
military intervention in 640 vignettes where each was run for 100 times
allowing to explore AI decision on military intervention systematically. The
analysis finds that largest predictors of AI decision to intervene are high
domestic support and high probability of success. Costs such as international
condemnation, military deaths, civilian deaths, and negative economic effect
are statistically significant, but their effect is around half of domestic
support and probability of victory. Closing window of opportunity only reaches
statistical significance in interaction with other factors. The results are
remarkably consistent across scenarios and across different models (OpenAI GPT,
Anthropic Claude, Google Gemini) suggesting a pattern in AI decision-making.

</details>


### [44] [Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles](https://arxiv.org/abs/2507.06310)
*Yongchao Zeng,Calum Brown,Mark Rounsevell*

Main category: cs.CY

TL;DR: LLM的高拟真能力并非总适合社会模拟，容易带来抽象性和可解释性的问题，应当谨慎选择其应用场景。


<details>
  <summary>Details</summary>
Motivation: 近年来，大型语言模型（LLM）在社会模拟中因其生成流畅、上下文连贯对话的能力而被广泛采用。尽管这种能力提升了模型的拟真性，但作者认为，追求极致的拟真性与建模的认识论基础并不总是兼容，需要重新思考如何合理运用LLM。

Method: 通过一个模型构建的思想实验，将经典的Bass扩散模型转化为基于LLM的变体，系统地揭示了在社会模拟中使用LLM代理面临的核心困境。

Result: 作者总结出五大困境：时序分辨率与建模步长的不匹配、对生成对话介入的两难、引入规则提示与自然对话的冲突、角色一致性与演化的张力、系统级涌现被细碎文本掩盖。这些问题让LLM代理处于一个尴尬的“拟真鸿沟”中，既不够抽象又不够自然，反而可能掩盖社会动力学。

Conclusion: LLM代理在关注语言细节、交互自然、角色稳定且系统级涌现非核心的情境下更为适用。作者呼吁未来社会模拟应该重新定位LLM代理的应用场景，警惕其高拟真性带来的认识误区。

Abstract: Large language models (LLMs) have been increasingly used to build agents in
social simulation because of their impressive abilities to generate fluent,
contextually coherent dialogues. Such abilities can enhance the realism of
models. However, the pursuit of realism is not necessarily compatible with the
epistemic foundation of modelling. We argue that LLM agents, in many regards,
are too human to model: they are too expressive, detailed and intractable to be
consistent with the abstraction, simplification, and interpretability typically
demanded by modelling. Through a model-building thought experiment that
converts the Bass diffusion model to an LLM-based variant, we uncover five core
dilemmas: a temporal resolution mismatch between natural conversation and
abstract time steps; the need for intervention in conversations while avoiding
undermining spontaneous agent outputs; the temptation to introduce rule-like
instructions in prompts while maintaining conversational naturalness; the
tension between role consistency and role evolution across time; and the
challenge of understanding emergence, where system-level patterns become
obscured by verbose micro textual outputs. These dilemmas steer the LLM agents
towards an uncanny valley: not abstract enough to clarify underlying social
mechanisms, while not natural enough to represent realistic human behaviour.
This exposes an important paradox: the realism of LLM agents can obscure,
rather than clarify, social dynamics when misapplied. We tease out the
conditions in which LLM agents are ideally suited: where system-level emergence
is not the focus, linguistic nuances and meaning are central, interactions
unfold in natural time, and stable role identity is more important than
long-term behavioural evolution. We call for repositioning LLM agents in the
ecosystem of social simulation for future applications.

</details>


### [45] [Domestic frontier AI regulation, an IAEA for AI, an NPT for AI, and a US-led Allied Public-Private Partnership for AI: Four institutions for governing and developing frontier AI](https://arxiv.org/abs/2507.06379)
*Haydn Belfield*

Main category: cs.CY

TL;DR: 本文提出以算力（硬件芯片）为主线，推动国内外AI治理措施，包括建立国际AI机构、芯片协议和美西方主导的AI合伙开发项目，通过计算资源激励，促进安全、有序、共赢的前沿AI发展。


<details>
  <summary>Details</summary>
Motivation: 前沿人工智能（AI）带来重大的风险与挑战，现有的国际机制难以有效监管AI的发展和使用。论文动机是探讨以算力治理为基础，建立更有效的国际治理架构，以降低风险、保障安全。

Method: 作者提出以算力指标为核心，结合国内与国际多层次治理措施。具体包括风险评估、数据中心使用报告、发布门控等国内管理方法。同时，建议建立国际AI机构（类似国际原子能机构IAEA），推动《安全芯片协议》（类似核不扩散条约NPT），并倡议由美西方主导的AI公共-私营合伙项目。

Result: 作者分析了四种治理与发展前沿AI的国际机构模式。论证通过“芯片”这一激励机制，引导各国参与算力与AI的协同治理，有望促进AI安全和全球共享，并减少误用风险。强调制度建设是长远的、渐进的，现已启动初步探索。

Conclusion: 算力治理可为前沿AI国际治理机构提供可行的基础。通过多层次措施和强激励机制，能够实现既安全又公平的AI开发及应用，但需要耐心推进和国际合作。

Abstract: Compute governance can underpin international institutions for the governance
of frontier AI. To demonstrate this I explore four institutions for governing
and developing frontier AI. Next steps for compute-indexed domestic frontier AI
regulation could include risk assessments and pre-approvals, data centre usage
reports, and release gate regulation. Domestic regimes could be harmonized and
monitored through an International AI Agency - an International Atomic Energy
Agency (IAEA) for AI. This could be backed up by a Secure Chips Agreement - a
Non-Proliferation Treaty (NPT) for AI. This would be a non-proliferation regime
for advanced chips, building on the chip export controls - states that do not
have an IAIA-certified frontier regulation regime would not be allowed to
import advanced chips. Frontier training runs could be carried out by a
megaproject between the USA and its allies - a US-led Allied Public-Private
Partnership for frontier AI. As a project to develop advanced AI, this could
have significant advantages over alternatives led by Big Tech or particular
states: it could be more legitimate, secure, safe, non-adversarial, peaceful,
and less prone to misuse. For each of these four scenarios, a key incentive for
participation is access to the advanced AI chips that are necessary for
frontier training runs and large-scale inference. Together, they can create a
situation in which governments can be reassured that frontier AI is developed
and deployed in a secure manner with misuse minimised and benefits widely
shared. Building these institutions may take years or decades, but progress is
incremental and evolutionary and the first steps have already been taken.

</details>


### [46] [Deprecating Benchmarks: Criteria and Framework](https://arxiv.org/abs/2507.06434)
*Ayrton San Joaquin,Rokas Gipiškis,Leon Staufer,Ariel Gil*

Main category: cs.CY

TL;DR: 论文指出了当前AI基准测试在失效后缺乏明确弃用机制所带来的风险，提出了一套弃用标准和操作框架，旨在规范评估，推动AI模型科学健康发展。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型快速发展，不同模型的评估离不开基准测试（benchmarks）。然而，缺乏有关何时及如何弃用已不再有效的基准的指导，可能导致对模型能力的高估或能力掩盖甚至安全风险被忽视。

Method: 回顾现有的基准测试实践，作者提出了一套标准，用于判断何时（完全或部分）弃用基准，并建立了一个弃用框架。

Result: 提出了弃用基准的标准和相应框架，有助于推进评估更为严格、高质量，尤其针对前沿AI模型。

Conclusion: 这些工作和建议将造福基准开发者、用户、AI治理相关人员和政策制定者，提升AI评估体系的科学性和严谨性。

Abstract: As frontier artificial intelligence (AI) models rapidly advance, benchmarks
are integral to comparing different models and measuring their progress in
different task-specific domains. However, there is a lack of guidance on when
and how benchmarks should be deprecated once they cease to effectively perform
their purpose. This risks benchmark scores over-valuing model capabilities, or
worse, obscuring capabilities and safety-washing. Based on a review of
benchmarking practices, we propose criteria to decide when to fully or
partially deprecate benchmarks, and a framework for deprecating benchmarks. Our
work aims to advance the state of benchmarking towards rigorous and quality
evaluations, especially for frontier models, and our recommendations are aimed
to benefit benchmark developers, benchmark users, AI governance actors (across
governments, academia, and industry panels), and policy makers.

</details>


### [47] [Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study](https://arxiv.org/abs/2507.06438)
*Kaléu Delphino*

Main category: cs.CY

TL;DR: 学生用AI工具抄袭的比例较高，问卷可有效调查此现象，而面谈难以获得真实反馈。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言生成代码工具（如ChatGPT）的出现，传统的计算机科学教育面临学生利用AI作弊的新挑战。但目前尚不清楚有多少学生实际在利用这些工具进行抄袭。

Method: 研究者在一门大规模计算机科学课程（n=120）中，通过匿名问卷调查和面谈，评估用匿名调查量化AI抄袭行为的可行性。

Result: 超过25%的受访学生承认存在AI抄袭行为，但仅有一名学生同意接受面谈。

Conclusion: 问卷调查是一种有效评估AI抄袭的途径，而面谈因响应率低需要重新设计或避免使用。

Abstract: Tools that can generate computer code in response to inputs written in
natural language, such as ChatGPT, pose an existential threat to Computer
Science education in its current form, since students can now use these tools
to solve assignments without much effort. While that risk has already been
recognized by scholars, the proportion of the student body that is incurring in
this new kind of plagiarism is still an open problem. We conducted a pilot
study in a large CS class (n=120) to assess the feasibility of estimating AI
plagiarism through anonymous surveys and interviews. More than 25% of the
survey respondents admitted to committing AI plagiarism. Conversely, only one
student accepted to be interviewed. Given the high levels of misconduct
acknowledgment, we conclude that surveys are an effective method for studies on
the matter, while interviews should be avoided or designed in a way that can
entice participation.

</details>


### [48] [Google Search Advertising after Dobbs v. Jackson](https://arxiv.org/abs/2507.06640)
*Yelena Mejova,Ronald E. Robertson,Catherine A. Gimbrone,Sarah McKetta*

Main category: cs.CY

TL;DR: 美国最高法院Dobbs判决后，谷歌上与堕胎相关广告由CPCs主导，而堕胎诊所广告较少。广告类型随州及时间变化大但与法律无显著联系，提示搜索引擎广告存在信息获取不公和地域偏见问题。


<details>
  <summary>Details</summary>
Motivation: 自2022年美国最高法院Dobbs v. Jackson判决后，各州对堕胎的法规差异加大，影响到人们获取生殖健康信息的方式。鉴于搜索引擎已成为医疗信息的主要获取渠道，研究希望了解用户在谷歌搜索与堕胎相关信息时接收到的广告内容，从而评估信息的准确性和获取公平性。

Method: 作者对美国各州范围内用户在谷歌搜索堕胎信息时看到的广告进行了系统性审查，涵盖Dobbs判决后的一年。通过收集和统计各类型广告（危机怀孕中心与堕胎诊所等）出现的比例，并使用阶梯增强合成控制方法（Staggered Augmented Synthetic Control Methods）分析广告变化与州法律变化的关联。

Result: 研究发现，危机怀孕中心（CPCs）占广告的47%，堕胎诊所仅占30%。CPCs广告不仅数量多，还常出现在用户检索信息和安全相关查询时。州与州之间广告类型差异大，例如亚利桑那州以堕胎诊所广告居多，明尼苏达州最少。虽然各州广告比例随时间变化，但方法分析显示，这些变化未与各州堕胎法律变化显著相关。

Conclusion: 各地谷歌搜索结果中，寻求堕胎信息的用户面临大量由不提供堕胎服务的危机怀孕中心广告，意味着获取医疗信息受到限制且精准度存疑。需要对搜索引擎广告政策和地域偏差进行更深入研究，以保障医疗信息的准确与公平获取。

Abstract: Search engines have become the gateway to information, products, and
services, including those concerning healthcare. Access to reproductive health
has been especially complicated in the wake of the 2022 Dobbs v. Jackson
decision by the Supreme Court of the United States, splintering abortion
regulations among the states. In this study, we performed an audit of the
advertisements shown to Google Search users seeking information about abortion
across the United States during the year following the Dobbs decision. We found
that Crisis Pregnancy Centers (CPCs) -- organizations that target women with
unexpected or "crisis" pregnancies, but do not provide abortions -- accounted
for 47% of advertisements, whereas abortion clinics -- for 30%. Advertisements
from CPCs were often returned for queries concerning information and safety.
The type of advertisements returned, however, varied widely within each state,
with Arizona returning the most advertisements from abortion clinics and other
pro-choice organizations, and Minnesota the least. The proportion of pro-choice
vs. anti-choice advertisements returned also varied over time, but estimates
from Staggered Augmented Synthetic Control Methods did not indicate that
changes in advertisement results were attributable to changes in state abortion
laws. Our findings raise questions about the access to accurate medical
information across the U.S. and point to a need for further examination of
search engine advertisement policies and geographical bias.

</details>


### [49] [Connecting the Unconnected -- Sentiment Analysis of Field Survey of Internet Connectivity in Emerging Economies](https://arxiv.org/abs/2507.06827)
*Dibakar Das,Barath S Narayan,Aarna Bhammar,Jyotsna Bapat*

Main category: cs.CY

TL;DR: 本文通过对尼泊尔加德满都部分区域居民互联网使用状况的问卷调查，揭示了用户对互联网普及的积极态度及对高效优质网络服务的强烈期望，并基于数据分析发现各属性间虽有一定关联，但无单一主导因素。


<details>
  <summary>Details</summary>
Motivation: 因部分地区互联网严重拥堵，亟需了解市民实际互联网使用状况、主要诉求及未来期望。

Method: 通过对加德满都部分地区居民进行实地问卷调查，并结合情感分析与人口统计信息，对互联网使用体验及其影响进行分析。

Result: 调查显示用户最期望获得高速、低价、可靠且安全的互联网服务。大部分问题反馈的正面情感较多，负面情感的方差较小。在属性之间发现相关性和聚类现象，但数据中不存在主导成分。

Conclusion: 整体来看，受访者对互联网的态度大多是积极的，但缺乏单一主导因素。

Abstract: Internet has significantly improved the quality of citizens across the world.
Though the internet coverage is quite high, 40% of global population do not
have access to broadband internet. This paper presents an analysis of a field
survey of population in some areas of Kathmandu, Nepal, an emerging economy.
This survey was triggered by intermittent severe congestion of internet in
certain areas of the city. People from three different areas were asked about
their present experience of internet usage, its impact on their lives and their
aspirations for the future. Survey pointed to high speed, low cost, reliable
and secure internet as a major aspiration of the respondents. Based on their
inputs, this paper presents a sentiment analysis as well as demographic
information. Keys insights from this analysis shows that overall sentiment to
most queries are positive. The variances of positive sentiments are high
whereas those for negative ones are low. Also, some correlations and clusters
are observed among the attributes though no dominant component exists in the
data.

</details>


### [50] [Winning and losing with Artificial Intelligence: What public discourse about ChatGPT tells us about how societies make sense of technological change](https://arxiv.org/abs/2507.06876)
*Adrian Rauchfleisch,Joshua Philip Suarez,Nikka Marie Sales,Andreas Jungherr*

Main category: cs.CY

TL;DR: 研究分析了ChatGPT发布后Twitter上的全球讨论，发现不同职业和文化背景显著影响了公众何时、以何种态度参与AI话题。技术类职业更积极，写作类更怀疑；文化上，个人主义高国家更早但更批判性。不同时期的情绪变化主要来自新群体的加入，而非早期参与者态度转变。


<details>
  <summary>Details</summary>
Motivation: 人工智能（AI）领域的公共产品发布往往能引发社会的广泛关注，但不同人群和文化背景如何影响他们对AI事件的感知与回应尚不清楚。作者希望通过量化分析社交媒体上的讨论，探索经济利益和文化价值观如何塑造公众对AI（如ChatGPT），特别是在其发布初期的集体反应。

Method: 分析了2022年ChatGPT公开发布后，来自117个国家160万用户发的380万条推文。利用用户职业技能类型（写作、编程、数学）近似经济利益，用霍夫斯泰德文化维度（个人主义、不确定性规避、权力距离）量化国家文化取向，通过内容分析与分群等方法判断不同群体的活跃时间、参与强度与态度倾向。

Result: 技术型岗位（如编程、数学）的人更早参与，态度更积极，而写作类岗位用户更晚加入并持更怀疑的态度；国家层面，个人主义更高的社会人群更早参与讨论却更消极，不确定性规避较高的人群虽不影响加入速度但更少表达积极态度。整体上，对ChatGPT的负面态度并非早期用户态度转变，而是后续更持怀疑态度群体的加入导致。

Conclusion: 公众对AI产品的反应受职业类型与文化因素双重影响。未来AI技术推广和讨论需要深入考虑不同经济利益相关者及文化背景人群的诉求和立场。

Abstract: Public product launches in Artificial Intelligence can serve as focusing
events for collective attention, surfacing how societies react to technological
change. Social media provide a window into the sensemaking around these events,
surfacing hopes and fears and showing who chooses to engage in the discourse
and when. We demonstrate that public sensemaking about AI is shaped by economic
interests and cultural values of those involved. We analyze 3.8 million tweets
posted by 1.6 million users across 117 countries in response to the public
launch of ChatGPT in 2022. Our analysis shows how economic self-interest,
proxied by occupational skill types in writing, programming, and mathematics,
and national cultural orientations, as measured by Hofstede's individualism,
uncertainty avoidance, and power distance dimensions, shape who speaks, when
they speak, and their stance towards ChatGPT. Roles requiring more technical
skills, such as programming and mathematics, tend to engage earlier and express
more positive stances, whereas writing-centric occupations join later with
greater skepticism. At the cultural level, individualism predicts both earlier
engagement and a more negative stance, and uncertainty avoidance reduces the
prevalence of positive stances but does not delay when users first engage with
ChatGPT. Aggregate sentiment trends mask the dynamics observed in our study.
The shift toward a more critical stance towards ChatGPT over time stems
primarily from the entry of more skeptical voices rather than a change of heart
among early adopters. Our findings underscore the importance of both the
occupational background and cultural context in understanding public reactions
to AI.

</details>


### [51] [Do AI tutors empower or enslave learners? Toward a critical use of AI in education](https://arxiv.org/abs/2507.06878)
*Lucile Favero,Juan-Antonio Pérez-Ortiz,Tanja Käser,Nuria Oliver*

Main category: cs.CY

TL;DR: 本文分析了教育领域AI工具带来的机遇与挑战，警示过度依赖AI会损害学生能力与福祉，并主张采取以学生为本、明确且负责任的AI使用策略。


<details>
  <summary>Details</summary>
Motivation: 随着AI工具在教育领域的广泛应用，如何平衡其赋能作用与对学生关键能力（如批判性思维）潜在威胁成为重要议题。

Method: 本文立场论文，结合认知科学与教育学理论分析AI在教学中的作用及风险，并提出具体策略，旨在将AI作为有效的学习辅助而非认知捷径。

Result: AI工具若不加管控，可能导致学生认知退化、自主性丧失、情感风险与伦理隐忧，破坏教育的根本目标。采取透明、审慎、以学生为中心的方法，能有效缓解这些问题。

Conclusion: 应鼓励有意识、透明、批判性地使用AI，让其成为助力而非障碍，从而真正赋权学生而非削弱其能力。

Abstract: The increasing integration of AI tools in education presents both
opportunities and challenges, particularly regarding the development of the
students' critical thinking skills. This position paper argues that while AI
can support learning, its unchecked use may lead to cognitive atrophy, loss of
agency, emotional risks, and ethical concerns, ultimately undermining the core
goals of education. Drawing on cognitive science and pedagogy, the paper
explores how over-reliance on AI can disrupt meaningful learning, foster
dependency and conformity, undermine the students' self-efficacy, academic
integrity, and well-being, and raise concerns about questionable privacy
practices. It also highlights the importance of considering the students'
perspectives and proposes actionable strategies to ensure that AI serves as a
meaningful support rather than a cognitive shortcut. The paper advocates for an
intentional, transparent, and critically informed use of AI that empowers
rather than diminishes the learner.

</details>


### [52] [Exploring Public Perceptions of Generative AI in Libraries: A Social Media Analysis of X Discussions](https://arxiv.org/abs/2507.07047)
*Yuan Li,Teja Mandaloju,Haihua Chen*

Main category: cs.CY

TL;DR: 本研究大规模分析了X平台上关于生成式AI在图书馆的讨论，发现公众讨论普遍较为负面，关注点集中在伦理和知识产权问题，社交网络中既有权威机构也有促进跨界交流的个人用户。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能在图书馆及GLAM行业的应用日益增加，了解公众对其的认知与讨论，对于预测和引导未来发展方向至关重要。

Method: 采用了混合方法，包括时间趋势分析、情感分类和社交网络分析，对X平台上的相关帖子进行大规模分析。

Result: 讨论主要呈现负面情感色彩，情感波动与伦理与知识产权相关话题密切相关。社交网络揭示了机构和个人在推动跨领域交流中的不同作用。

Conclusion: 公共对话大多持负面态度，负面讨论主要围绕伦理与知识产权问题，与GenAI相关的讨论在图书馆和GLAM领域尤为集中，社交网络中既有机构权威也有促进行业交叉沟通的个人用户。

Abstract: This study investigates public perceptions of generative artificial
intelligence (GenAI) in libraries through a large-scale analysis of posts on X
(formerly Twitter). Using a mixed-method approach that combines temporal trend
analysis, sentiment classification, and social network analysis, this paper
explores how public discourse around GenAI and libraries has evolved over time,
the emotional tones that dominate the conversation, and the key users or
organizations driving engagement. The findings reveal that discussions are
predominantly negative in tone, with surges linked to concerns about ethics and
intellectual property. Furthermore, social network analysis identifies both
institutional authority and individual bridge users who facilitate cross-domain
engagement. The results in this paper contribute to the growing body of
literature on GenAI in the library and GLAM (Galleries, Libraries, Archives,
and Museums) sectors and offer a real-time, public-facing perspective on the
emerging opportunities and concerns GenAI presents.

</details>


### [53] [Girlhood Feminism as Soft Resistance: Affective Counterpublics and Algorithmic Negotiation on RedNote](https://arxiv.org/abs/2507.07059)
*Meng Liang,Xiaoyue Zhang,Linqi Ye*

Main category: cs.CY

TL;DR: 中国女性通过生活方式App和标签实践，利用“girlhood feminism”温和表达女权抵抗，在算法和文化限制下创造隐秘的反抗空间，提出东亚本土化的解释框架，区别于西方对抗性女权主义。


<details>
  <summary>Details</summary>
Motivation: 在算法和文化双重压制下，中国女性如何利用数字平台开展女权抵抗，以及这种抵抗形式与西方对抗性自由女权主义有何不同。

Method: 采用Computer-Assisted Learning and Measurement（CALM）框架，分析了1580篇女性主导生活方式App中的相关帖子，通过定性和定量方法解读用户互动与行为。

Result: 用户通过自我幼态化、算法戏耍和审美撤退等策略，巧妙绕开审查与父权压制，创造了富有情感与象征意义的抗议空间。这改变了女权公共空间的运作和表达方式。

Conclusion: 本研究提出“girlhood feminism（少女女权主义）”的概念，强调中国女性用户通过策略性利用平台和标签，创造温和、情感化但有效的抵抗空间。这种抵抗规避了直接对抗和可见性挑战，以低调和情感共鸣方式改变性别话语。

Abstract: This article explores how Chinese female users tactically mobilise platform
features and hashtag practices to construct vernacular forms and an exclusive
space of feminist resistance under algorithmic and cultural constraints.
Focusing on the reappropriation of the hashtag Baby Supplementary Food (BSF), a
female-dominated lifestyle app with over 300 million users, we analyse how
users create a female-centered counterpublic through self-infantilisation,
algorithmic play, and aesthetic withdrawal. Using the Computer-Assisted
Learning and Measurement (CALM) framework, we analysed 1580 posts and propose
the concept of girlhood feminism: an affective, culturally grounded form of
soft resistance that refuses patriarchal life scripts without seeking direct
confrontation or visibility. Rather than challenging censorship and misogyny
directly, users rework platform affordances and domestic idioms to carve out
emotional and symbolic spaces of dissent. Situated within the broader dynamics
of East Asia's compressed modernity, this essay challenges liberal feminist
paradigms grounded in confrontation and transparency. It advances a regionally
grounded framework for understanding how gendered publics are navigated,
negotiated, and quietly reimagined in algorithmically governed spaces.

</details>


<div id='q-fin.TR'></div>

# q-fin.TR [[Back]](#toc)

### [54] [Reinforcement Learning for Trade Execution with Market Impact](https://arxiv.org/abs/2507.06345)
*Patrick Cheridito,Moritz Weiss*

Main category: q-fin.TR

TL;DR: 提出强化学习新方法优化限价订单簿中的交易执行，收益优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 近年来算法交易对最佳交易执行问题的关注度持续上升，如何在限价订单簿环境下高效下单，以提升收益成为重要研究方向。

Method: 提出了一种新颖的强化学习框架，将交易执行问题建模为动态分配任务，结合多变量logistic-normal分布模拟随机分配，以提升强化学习算法的训练效率。

Result: 实验结果表明，该方法在包含随机交易者、战术交易者和战略交易者等多主体复杂仿真环境下，优于传统基准策略。

Conclusion: 本文强化学习框架有效提升了限价订单簿环境下交易执行的表现和收益，有望为实际交易系统带来应用价值。

Abstract: In this paper, we introduce a novel reinforcement learning framework for
optimal trade execution in a limit order book. We formulate the trade execution
problem as a dynamic allocation task whose objective is the optimal placement
of market and limit orders to maximize expected revenue. By employing
multivariate logistic-normal distributions to model random allocations, the
framework enables efficient training of the reinforcement learning algorithm.
Numerical experiments show that the proposed method outperforms traditional
benchmark strategies in simulated limit order book environments featuring noise
traders submitting random orders, tactical traders responding to order book
imbalances, and a strategic trader seeking to acquire or liquidate an asset
position.

</details>
