<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 9]
- [cs.CL](#cs.CL) [Total: 8]
- [cs.CE](#cs.CE) [Total: 7]
- [cs.CY](#cs.CY) [Total: 7]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Signal Use and Emergent Cooperation](https://arxiv.org/abs/2506.18920)
*Michael Williams*

Main category: cs.AI

TL;DR: 作者通过NEC-DAC系统，研究智能体部落如何通过通信信号自组织成合作文化，提升效率。文化可以代际传递，社交结构与信号方式对集体表现有重大作用。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在探究自主智能体如何通过通信信号实现协同，提高集体效率，并聚焦于文化自组织与通信方式对协作和适应度的影响。

Method: 采用NEC-DAC（神经编码文化-分布式自主通信体）系统，智能体各自用神经网络进行决策，通过学习和信号交流发展出共享的行为系统。分析不同社交结构及通信策略下的集体文化形成与传承。

Result: 发现通信信号促进了文化的自组织和代际传递，且不同社交结构（如权威层级）与协作文化显著提升了部落整体表现。协调行为和通信机制在智能体神经网络内部有协同优势。

Conclusion: 自主智能体部落能借助通信信号形成有利于合作的文化，优化集体效率，并能通过信号传承文化，社交结构和通信策略对文化形成和部落表现有重要影响。

Abstract: In this work, we investigate how autonomous agents, organized into tribes,
learn to use communication signals to coordinate their activities and enhance
their collective efficiency. Using the NEC-DAC (Neurally Encoded Culture -
Distributed Autonomous Communicators) system, where each agent is equipped with
its own neural network for decision-making, we demonstrate how these agents
develop a shared behavioral system -- akin to a culture -- through learning and
signalling. Our research focuses on the self-organization of culture within
these tribes of agents and how varying communication strategies impact their
fitness and cooperation. By analyzing different social structures, such as
authority hierarchies, we show that the culture of cooperation significantly
influences the tribe's performance. Furthermore, we explore how signals not
only facilitate the emergence of culture but also enable its transmission
across generations of agents. Additionally, we examine the benefits of
coordinating behavior and signaling within individual agents' neural networks.

</details>


### [2] [Do LLMs Know When to Flip a Coin? Strategic Randomization through Reasoning and Experience](https://arxiv.org/abs/2506.18928)
*Lingyu Yang*

Main category: cs.AI

TL;DR: 本文设计了一个考验LLM随机化战略能力的博弈实验，发现强LLM在明确提示下能采用更佳的随机化策略，对弱模型可策略性压制。但整体战略推理与适应性仍有待加强。


<details>
  <summary>Details</summary>
Motivation: 战略性随机化是博弈论中的一个核心思想，但大型语言模型（LLMs）在这方面的表现尚未深入研究。现有研究常常混淆了“认知决策去随机化”与“机械地生成随机性”，导致评估不全面。因此，作者希望找到一种能更准确评估和研究LLM随机化能力的方法。

Method: 作者提出了一种受田忌赛马启发的零和游戏，该游戏的纳什均衡对应于最大熵策略。通过多种prompt风格（指引、普通、暗示等）对五种LLM进行多轮竞技玩法，并加入系统生成的随机选择，以分离“决策随机化”的能力。通过实际对弈胜负和贝叶斯因子分析LLM的策略推理能力。

Result: 实验发现，较弱的模型无论收到哪种prompt，决策始终偏于确定性，无法真正做到随机化，而更强的模型在有明确暗示时才会更多采用随机策略。当对手为弱模型时，强模型会利用其偏差采用确定性策略获取胜利。但遇到同等级模型时，会趋于纳什均衡的最大熵（即随机化）策略。

Conclusion: LLM在战略性随机化和策略推理上的能力随着模型强度提升有显著提升，但当前距离人类灵活抽象推理和自适应学习能力仍有明显不足，未来提升空间很大。

Abstract: Strategic randomization is a key principle in game theory, yet it remains
underexplored in large language models (LLMs). Prior work often conflates the
cognitive decision to randomize with the mechanical generation of randomness,
leading to incomplete evaluations. To address this, we propose a novel zero-sum
game inspired by the Tian Ji Horse Race, where the Nash equilibrium corresponds
to a maximal entropy strategy. The game's complexity masks this property from
untrained humans and underdeveloped LLMs. We evaluate five LLMs across prompt
styles -- framed, neutral, and hinted -- using competitive multi-tournament
gameplay with system-provided random choices, isolating the decision to
randomize. Results show that weaker models remain deterministic regardless of
prompts, while stronger models exhibit increased randomization under explicit
hints. When facing weaker models, strong LLMs adopt deterministic strategies to
exploit biases, but converge toward equilibrium play when facing peers. Through
win/loss outcomes and Bayes factor analysis, we demonstrate meaningful
variation in LLMs' strategic reasoning capabilities, highlighting opportunities
for improvement in abstract reasoning and adaptive learning. We make our
implementation publicly available at
https://github.com/ocelopus/llm-when-to-throw-coin to ensure full
reproducibility.

</details>


### [3] [A Comment On "The Illusion of Thinking": Reframing the Reasoning Cliff as an Agentic Gap](https://arxiv.org/abs/2506.18957)
*Sheraz Khan,Subha Madhavan,Kannan Natarajan*

Main category: cs.AI

TL;DR: 传统静态文本评估低估了大模型推理能力，引入agentic工具后，模型突破‘推理悬崖’，证明限制在于系统工具和执行能力，而非固有推理瓶颈。


<details>
  <summary>Details</summary>
Motivation: Shojaee等人提出大模型（LRMs）在特定复杂度阈值后的推理能力突变下降（reasoning cliff），并归因于链式思维（CoT）推理的固有限制。本文作者对此观点持质疑态度，认为实验方法本身存在混淆因素。

Method: 本文采用实证分析，对比在仅限文本生成与允许工具使用的模型表现，重点考查agentic tool的引入对模型推理能力的影响。同时对比不同工具化模型（如o4-mini和GPT-4o）在解决复杂任务时的层次性变现。

Result: 实验证明，之前仅用文本生成时无法解决的难题，在允许模型调用agentic工具后能够被轻松突破，且模型可应对更复杂变体。此外，工具化模型展示出从常规操作到自我修正的推理层次体系。

Conclusion: 链式推理（CoT）模型性能崩溃并非认知本质受限，而是评测范式（如工具受限、上下文记忆限制等）导致的表观问题。高阶推理和智能表现与系统执行环境和能力密切相关。“思考的幻觉”本质是工具缺失下能力的展现。

Abstract: The recent work by Shojaee et al. (2025), titled The Illusion of Thinking:
Understanding the Strengths and Limitations of Reasoning Models via the Lens of
Problem Complexity, presents a compelling empirical finding, a reasoning cliff,
where the performance of Large Reasoning Models (LRMs) collapses beyond a
specific complexity threshold, which the authors posit as an intrinsic scaling
limitation of Chain-of-Thought (CoT) reasoning. This commentary, while
acknowledging the study's methodological rigor, contends that this conclusion
is confounded by experimental artifacts. We argue that the observed failure is
not evidence of a fundamental cognitive boundary, but rather a predictable
outcome of system-level constraints in the static, text-only evaluation
paradigm, including tool use restrictions, context window recall issues, the
absence of crucial cognitive baselines, inadequate statistical reporting, and
output generation limits. We reframe this performance collapse through the lens
of an agentic gap, asserting that the models are not failing at reasoning, but
at execution within a profoundly restrictive interface. We empirically
substantiate this critique by demonstrating a striking reversal. A model,
initially declaring a puzzle impossible when confined to text-only generation,
now employs agentic tools to not only solve it but also master variations of
complexity far beyond the reasoning cliff it previously failed to surmount.
Additionally, our empirical analysis of tool-enabled models like o4-mini and
GPT-4o reveals a hierarchy of agentic reasoning, from simple procedural
execution to complex meta-cognitive self-correction, which has significant
implications for how we define and measure machine intelligence. The illusion
of thinking attributed to LRMs is less a reasoning deficit and more a
consequence of an otherwise capable mind lacking the tools for action.

</details>


### [4] [From Rows to Yields: How Foundation Models for Tabular Data Simplify Crop Yield Prediction](https://arxiv.org/abs/2506.19046)
*Filip Sabo,Michele Meroni,Maria Piles,Martin Claverie,Fanie Ferreira,Elna Van Den Berg,Francesco Collivignarelli,Felix Rembold*

Main category: cs.AI

TL;DR: 本文将TabPFN基础模型首次应用于南非区域作物产量预测，结果显示其预测精度与主流ML模型相当，但调参速度更快、特征工程需求低，在实际应用中更具优势。


<details>
  <summary>Details</summary>
Motivation: 目前对于南非的区域级夏季作物产量预测，传统机器学习方法虽然较为常用，但存在调参和特征工程成本高、效率较低等问题。为提升实际应用的便捷性与效率，需要探索更高效且准确的建模方案。TabPFN近期在回归与分类任务上显示优越性能，成为值得关注的基础模型。

Method: 本文将Foundation Model（TabPFN）应用于南非区域级作物产量预测。输入数据包括十天期的遥感（FAPAR、土壤湿度）和天气数据（气温、降水、辐射）。使用23年、8个省的数据，按区域提取并按月聚合特征。以留一年交叉验证方式，比较TabPFN与六种机器学习模型及三种基线模型的预测表现。评估指标包括预测精度、模型调参耗时及特征工程需求。

Result: TabPFN与主流ML模型在预测准确率方面相当，且均优于基线模型。但TabPFN在模型调参耗时更短，对特征工程依赖更少，体现出在实际应用中更高的实用性。对于强调效率与易用性的产量预测任务，TabPFN更具优势。

Conclusion: TabPFN基础模型在南非区域级作物产量预测任务上，不仅能提供和现有主流机器学习模型相当甚至更好的精度，还显著降低了调参和特征工程的时间成本，更适合实际大规模应用场景。

Abstract: We present an application of a foundation model for small- to medium-sized
tabular data (TabPFN), to sub-national yield forecasting task in South Africa.
TabPFN has recently demonstrated superior performance compared to traditional
machine learning (ML) models in various regression and classification tasks. We
used the dekadal (10-days) time series of Earth Observation (EO; FAPAR and soil
moisture) and gridded weather data (air temperature, precipitation and
radiation) to forecast the yield of summer crops at the sub-national level. The
crop yield data was available for 23 years and for up to 8 provinces. Covariate
variables for TabPFN (i.e., EO and weather) were extracted by region and
aggregated at a monthly scale. We benchmarked the results of the TabPFN against
six ML models and three baseline models. Leave-one-year-out cross-validation
experiment setting was used in order to ensure the assessment of the models
capacity to forecast an unseen year. Results showed that TabPFN and ML models
exhibit comparable accuracy, outperforming the baselines. Nonetheless, TabPFN
demonstrated superior practical utility due to its significantly faster tuning
time and reduced requirement for feature engineering. This renders TabPFN a
more viable option for real-world operation yield forecasting applications,
where efficiency and ease of implementation are paramount.

</details>


### [5] [Baba is LLM: Reasoning in a Game with Dynamic Rules](https://arxiv.org/abs/2506.19095)
*Fien van Wetten,Aske Plaat,Max van Duijn*

Main category: cs.AI

TL;DR: 本论文测试了大语言模型在解2D益智游戏“Baba is You”中的推理能力。结果表明，即使是最先进的模型和经过微调后，LLM依然难以应对动态规则变化，提示此类游戏可用于测试模型高阶推理能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在语言任务上表现优秀，但在推理任务上存在不足。论文希望通过2D益智游戏“Baba is You”测试LLMs在动态规则推理方面的能力。

Method: 评估6种不同的LLM，设计三种提示类型（简单、规则扩展、动作扩展）；另外对Mistral和OLMo进行了基于游戏文本和结构数据的微调。通过比较不同模型和提示类型下的表现，分析其推理与解密能力。

Result: 较大的模型（特别是GPT-4o）在推理和解密上表现更好；小型未微调模型难以识别游戏机制或应用规则更改。微调虽然提升了对游戏关卡的分析能力，但对实际解题帮助有限。即使是最先进和经过微调的LLM，在处理动态规则变化时依然非常困难。

Conclusion: 目前LLM即便是先进或经过微调，仍难以深入理解和推理涉及动态变化规则的问题，特别是区分规则的“使用”与“陈述”（use-mention distinction）。这说明基于动态规则变化的游戏可作为LLM推理能力的良好测试平台。

Abstract: Large language models (LLMs) are known to perform well on language tasks, but
struggle with reasoning tasks. This paper explores the ability of LLMs to play
the 2D puzzle game Baba is You, in which players manipulate rules by
rearranging text blocks that define object properties. Given that this
rule-manipulation relies on language abilities and reasoning, it is a
compelling challenge for LLMs. Six LLMs are evaluated using different prompt
types, including (1) simple, (2) rule-extended and (3) action-extended prompts.
In addition, two models (Mistral, OLMo) are finetuned using textual and
structural data from the game. Results show that while larger models
(particularly GPT-4o) perform better in reasoning and puzzle solving, smaller
unadapted models struggle to recognize game mechanics or apply rule changes.
Finetuning improves the ability to analyze the game levels, but does not
significantly improve solution formulation. We conclude that even for
state-of-the-art and finetuned LLMs, reasoning about dynamic rule changes is
difficult (specifically, understanding the use-mention distinction). The
results provide insights into the applicability of LLMs to complex
problem-solving tasks and highlight the suitability of games with dynamically
changing rules for testing reasoning and reflection by LLMs.

</details>


### [6] [Spiritual-LLM : Gita Inspired Mental Health Therapy In the Era of LLMs](https://arxiv.org/abs/2506.19185)
*Janak Kapuriya,Aman Singh,Jainendra Shukla,Rajiv Ratn Shah*

Main category: cs.AI

TL;DR: 作者通过将《薄伽梵歌》灵性智慧融入大语言模型，构建了GITes数据集，显著提升了AI心理支持的共情与灵性评分，验证了灵性引导对AI心理健康干预的积极作用，并为后续研究提供了公开资源。


<details>
  <summary>Details</summary>
Motivation: 传统的心理健康支持系统主要依靠对用户当前情绪和情境的反应，导致介入表浅，难以满足用户更深层次的情感需求。本研究希望通过引入灵性智慧，提高AI心理支持的有效性和深度。

Method: 本研究提出了一种新框架，将《薄伽梵歌》的灵性智慧与GPT-4o大模型结合，开发了GITes（Gita Integrated Therapy for Emotional Support）数据集。该数据集在原有ExTES心理健康数据集基础上，增加了10,729条由GPT-4o生成、领域专家评估的灵性化心理支持回复。模型性能对比了12个目前主流的通用及心理健康专用大模型，并引入了创新的Spiritual Insight（灵性洞见）评价指标及LLM自动评审体系，用chain-of-thought提示实现自动打分。

Result: 通过灵性指导与AI结合，最佳模型Phi3-Mini 3.2B Instruct在NLP指标（ROUGE、METEOR、BERT score）和新提出的灵性评价指标（Spiritual Insight、Sufficiency、Relevance）上均实现了显著提升，提升幅度均在8%至126%之间。

Conclusion: 引入灵性智慧显著提升了AI心理支持系统的共情与有效性，显示了极大的应用潜力，但还需进一步在真实用户人群中进行临床检验。该研究为精神引导型AI支持系统打开新方向，相关代码与数据集将公开，推动后续研究。

Abstract: Traditional mental health support systems often generate responses based
solely on the user's current emotion and situations, resulting in superficial
interventions that fail to address deeper emotional needs. This study
introduces a novel framework by integrating spiritual wisdom from the Bhagavad
Gita with advanced large language model GPT-4o to enhance emotional well-being.
We present the GITes (Gita Integrated Therapy for Emotional Support) dataset,
which enhances the existing ExTES mental health dataset by including 10,729
spiritually guided responses generated by GPT-4o and evaluated by domain
experts. We benchmark GITes against 12 state-of-the-art LLMs, including both
mental health specific and general purpose models. To evaluate spiritual
relevance in generated responses beyond what conventional n-gram based metrics
capture, we propose a novel Spiritual Insight metric and automate assessment
via an LLM as jury framework using chain-of-thought prompting. Integrating
spiritual guidance into AI driven support enhances both NLP and spiritual
metrics for the best performing LLM Phi3-Mini 3.2B Instruct, achieving
improvements of 122.71% in ROUGE, 126.53% in METEOR, 8.15% in BERT score,
15.92% in Spiritual Insight, 18.61% in Sufficiency and 13.22% in Relevance
compared to its zero-shot counterpart. While these results reflect substantial
improvements across automated empathy and spirituality metrics, further
validation in real world patient populations remains a necessary step. Our
findings indicate a strong potential for AI systems enriched with spiritual
guidance to enhance user satisfaction and perceived support outcomes. The code
and dataset will be publicly available to advance further research in this
emerging area.

</details>


### [7] [Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition](https://arxiv.org/abs/2506.19191)
*Craig Steven Wright*

Main category: cs.AI

TL;DR: 本文通过贝叶斯推断及群体动力学，提出可信的AI多主体进化框架，系统主体以对真理的对齐程度为生存依据，经知识竞争与信念修正逐步趋于真实与稳健；并通过加密与因果工具强化溯源及推理能力，为构建可验证知识的AI系统奠定了理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有的人工智能系统在群体智能、信念修正和个体间竞争方面存在理论不足，缺乏严密的数学框架。本文旨在填补这一空白，提出一种基于概率主体、贝叶斯推断及群体动力学的新型AI架构，以刻画可信知识的演化机制。

Method: 本文基于贝叶斯推断、测度理论和群体动力学，提出了一种由概率代理组成的AI系统结构。系统中主体通过离散时间竞争与信念修正，使用与外部真理源（oracle）对齐程度定义适应度。主体根据对结果的观察调整后验信念，通过配对比较与真实对齐的效用进行评分。高分主体复制，低分主体灭绝。引入基于哈希的加密身份和do-calculus因果推断算子，保证主体可追溯性和因果推断能力，推进系统的演化、稳健性与收敛性理论证明。

Result: 证明了该系统具备诚实知识进化吸引子的特性。在多主体对抗环境中，真理作为演化吸引子出现，系统在可信度、稳健性和演化稳定性方面满足形式化收敛定理，并能通过加密身份保证主体操作可追溯，信念更新具备一致性和收敛性。

Conclusion: 通过建立具备信念修正、竞争与身份可追溯加固的AI多主体系统，在理论层面展示了真理知识如何在可计算自调节群体中，经由对抗性知识压力自然涌现。该框架为建构强健和可验证的人工智能系统提供了坚实的数学基础。

Abstract: We introduce a mathematically rigorous framework for an artificial
intelligence system composed of probabilistic agents evolving through
structured competition and belief revision. The architecture, grounded in
Bayesian inference, measure theory, and population dynamics, defines agent
fitness as a function of alignment with a fixed external oracle representing
ground truth. Agents compete in a discrete-time environment, adjusting
posterior beliefs through observed outcomes, with higher-rated agents
reproducing and lower-rated agents undergoing extinction. Ratings are updated
via pairwise truth-aligned utility comparisons, and belief updates preserve
measurable consistency and stochastic convergence. We introduce hash-based
cryptographic identity commitments to ensure traceability, alongside causal
inference operators using do-calculus. Formal theorems on convergence,
robustness, and evolutionary stability are provided. The system establishes
truth as an evolutionary attractor, demonstrating that verifiable knowledge
arises from adversarial epistemic pressure within a computable, self-regulating
swarm.

</details>


### [8] [GBGC: Efficient and Adaptive Graph Coarsening via Granular-ball Computing](https://arxiv.org/abs/2506.19224)
*Shuyin Xia,Guan Wang,Gaojie Xu,Sen Zhao,Guoyin Wang*

Main category: cs.AI

TL;DR: 本文提出的GBGC是一种高效、准确的自适应多粒度图简化方法，能大幅提升计算速度，同时更好地保留图结构信息，有望成为图数据处理的标准流程。


<details>
  <summary>Details</summary>
Motivation: 图谱简化（graph coarsening）的目标是生成更小、更易管理的图，同时保留原始图的重要信息。现有方法大多注重谱保持（spectrum-preserving），但忽视了原始图中的多粒度子区域结构。作者希望利用图的多粒度特性，自动选择最优粒度进行简化。

Method: 作者借鉴了粒球计算（granular-ball computing）的思想，提出了一种新的多粒度、自适应的图简化方法（GBGC）。具体做法是引入自适应粒球细化机制，根据不同粒度将原始图自适应分割，利用这些粒球作为超节点构造简化图。

Result: 相比现有最先进的图简化算法，GBGC方法的处理速度提高至数十倍甚至上百倍，且拥有更低的时间复杂度。在准确性上，由于粒球计算的鲁棒性和泛化能力，GBGC几乎总是优于原始图。

Conclusion: GBGC方法在效率和准确性上均优于现有方法，具有较强的潜力成为标准的图数据预处理手段。

Abstract: The objective of graph coarsening is to generate smaller, more manageable
graphs while preserving key information of the original graph. Previous work
were mainly based on the perspective of spectrum-preserving, using some
predefined coarsening rules to make the eigenvalues of the Laplacian matrix of
the original graph and the coarsened graph match as much as possible. However,
they largely overlooked the fact that the original graph is composed of
subregions at different levels of granularity, where highly connected and
similar nodes should be more inclined to be aggregated together as nodes in the
coarsened graph. By combining the multi-granularity characteristics of the
graph structure, we can generate coarsened graph at the optimal granularity. To
this end, inspired by the application of granular-ball computing in
multi-granularity, we propose a new multi-granularity, efficient, and adaptive
coarsening method via granular-ball (GBGC), which significantly improves the
coarsening results and efficiency. Specifically, GBGC introduces an adaptive
granular-ball graph refinement mechanism, which adaptively splits the original
graph from coarse to fine into granular-balls of different sizes and optimal
granularity, and constructs the coarsened graph using these granular-balls as
supernodes. In addition, compared with other state-of-the-art graph coarsening
methods, the processing speed of this method can be increased by tens to
hundreds of times and has lower time complexity. The accuracy of GBGC is almost
always higher than that of the original graph due to the good robustness and
generalization of the granular-ball computing, so it has the potential to
become a standard graph data preprocessing method.

</details>


### [9] [RecLLM-R1: A Two-Stage Training Paradigm with Reinforcement Learning and Chain-of-Thought v1](https://arxiv.org/abs/2506.19235)
*Yu Xie,Xingkai Ren,Ying Qi,Yao Hu,Lianlei Shan*

Main category: cs.AI

TL;DR: RecLLM-R1结合大语言模型和强化学习，提升了推荐准确性与多样性，显著减轻过滤气泡，为业务政策与推荐模型一体化带来新契机。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统存在过滤气泡、外部知识利用不足及模型与业务政策脱节等问题，促使作者探索融合LLM和强化学习优化推荐质量与业务目标的方案。

Method: 提出RecLLM-R1框架，利用LLM解释用户与物品信息成为自然语言prompt，采用两阶段训练：首先通过有监督微调（SFT）赋予推荐能力，下一步用结合思维链（CoT）的群体相对策略优化（GRPO）进行基于奖励函数的强化学习，使系统优化多元业务指标。

Result: 实验证明，RecLLM-R1在大规模社交平台真实数据集上，大幅优于主流基线，在准确性、多样性、新颖性等多维上表现突出，并有效缓解过滤气泡。

Conclusion: RecLLM-R1显著优于现有基线方法，在提升推荐准确性、多样性、新颖性等指标的同时，有效缓解了过滤气泡效应，为推荐系统与业务目标一体化优化提供了新方向。

Abstract: Traditional recommendation systems often grapple with "filter bubbles",
underutilization of external knowledge, and a disconnect between model
optimization and business policy iteration. To address these limitations, this
paper introduces RecLLM-R1, a novel recommendation framework leveraging Large
Language Models (LLMs) and drawing inspiration from the DeepSeek R1
methodology. The framework initiates by transforming user profiles, historical
interactions, and multi-faceted item attributes into LLM-interpretable natural
language prompts through a carefully engineered data construction process.
Subsequently, a two-stage training paradigm is employed: the initial stage
involves Supervised Fine-Tuning (SFT) to imbue the LLM with fundamental
recommendation capabilities. The subsequent stage utilizes Group Relative
Policy Optimization (GRPO), a reinforcement learning technique, augmented with
a Chain-of-Thought (CoT) mechanism. This stage guides the model through
multi-step reasoning and holistic decision-making via a flexibly defined reward
function, aiming to concurrently optimize recommendation accuracy, diversity,
and other bespoke business objectives. Empirical evaluations on a real-world
user behavior dataset from a large-scale social media platform demonstrate that
RecLLM-R1 significantly surpasses existing baseline methods across a spectrum
of evaluation metrics, including accuracy, diversity, and novelty. It
effectively mitigates the filter bubble effect and presents a promising avenue
for the integrated optimization of recommendation models and policies under
intricate business goals.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [10] [MemeMind: A Large-Scale Multimodal Dataset with Chain-of-Thought Reasoning for Harmful Meme Detection](https://arxiv.org/abs/2506.18919)
*Hexiang Gu,Qifan Yu,Saihui Hou,Zhiqin Fang,Huijia Wu,Zhaofeng He*

Main category: cs.CL

TL;DR: 本文提出了包含中英文的大规模有害梗图数据集MemeMind，并引入MemeGuard检测框架，显著提升了多模态有害梗图的检测能力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中有害内容的传播愈发严重，特别是图文结合的有害梗图因其隐含语义和多模态特性，对自动检测提出了巨大挑战。目前虽然检测的准确性和可解释性有所提升，但缺乏系统性、大规模、多样性和高可解释性的数据集，阻碍了进一步研究。

Method: 提出MemeMind数据集，具有科学标准、大规模、多样性、中英文双语支持以及详细的链式思维注释，并创新性地提出了MemeGuard检测框架，将多模态信息与推理过程建模结合，实现更有效的有害梗图识别。

Result: 在MemeMind数据集上的实验表明，MemeGuard在有害梗图检测任务中，相较于现有最先进方法具有更优异的性能。

Conclusion: MemeMind数据集和MemeGuard框架为有害梗图检测提供了坚实基础，有力推动多模态有害内容检测领域的发展。

Abstract: The rapid development of social media has intensified the spread of harmful
content. Harmful memes, which integrate both images and text, pose significant
challenges for automated detection due to their implicit semantics and complex
multimodal interactions. Although existing research has made progress in
detection accuracy and interpretability, the lack of a systematic, large-scale,
diverse, and highly explainable dataset continues to hinder further advancement
in this field. To address this gap, we introduce MemeMind, a novel dataset
featuring scientifically rigorous standards, large scale, diversity, bilingual
support (Chinese and English), and detailed Chain-of-Thought (CoT) annotations.
MemeMind fills critical gaps in current datasets by offering comprehensive
labeling and explicit reasoning traces, thereby providing a solid foundation
for enhancing harmful meme detection. In addition, we propose an innovative
detection framework, MemeGuard, which effectively integrates multimodal
information with reasoning process modeling, significantly improving models'
ability to understand and identify harmful memes. Extensive experiments
conducted on the MemeMind dataset demonstrate that MemeGuard consistently
outperforms existing state-of-the-art methods in harmful meme detection tasks.

</details>


### [11] [Mirage of Mastery: Memorization Tricks LLMs into Artificially Inflated Self-Knowledge](https://arxiv.org/abs/2506.18998)
*Sahil Kale,Vijaykant Nadadur*

Main category: cs.CL

TL;DR: 本文发现大模型在STEM推理任务中容易“记忆替代推理”，对自己能力的评估有超45%的不一致，特别在科学和医学等标准化领域最为明显，强调需提升大模型自我知识的一致性和泛化能力以保证可信度。


<details>
  <summary>Details</summary>
Motivation: 近年来，人工智能大模型（LLMs）在推理任务中取得了惊人的成果，但人们发现它们往往会将记忆等同于智慧，这容易产生对模型推理能力的虚假信任。目前关于LLMs记忆和自我知识缺陷的研究大多分开讨论，未能揭示两者之间相互影响、共同影响大模型可信度的问题。

Method: 作者提出了一个全新评估框架，通过设计任务扰动，检验LLMs是在真正学习推理范式，还是仅仅在记忆答案。他们重点在STEM领域测试模型，通过自验证和逻辑一致性考察LLMs应对相似问题时的泛化能力及自我知识水平。

Result: 分析表明，LLMs在自我验证的逻辑一致任务扰动下，对自身推理能力的可行性评估出现了超过45%的不一致，这说明模型更多依赖记忆而非真实推理，且自信心较高。尤其是在科学和医学等术语高度标准化的领域，这一问题更加突出，暴露了现有架构和训练方法在模型自我知识一致性和泛化性上的严重缺陷。

Conclusion: 本文揭示了LLMs记忆与自我知识混淆、导致泛化能力不足及对自身推理能力的过度信心，强调需发展新方法以提升模型自我知识一致性，从而增强AI可解释性与可信度。

Abstract: When artificial intelligence mistakes memorization for intelligence, it
creates a dangerous mirage of reasoning. Existing studies treat memorization
and self-knowledge deficits in LLMs as separate issues and do not recognize an
intertwining link that degrades the trustworthiness of LLM responses. In our
study, we utilize a novel framework to ascertain if LLMs genuinely learn
reasoning patterns from training data or merely memorize them to assume
competence across problems of similar complexity focused on STEM domains. Our
analysis shows a noteworthy problem in generalization: LLMs draw confidence
from memorized solutions to infer a higher self-knowledge about their reasoning
ability, which manifests as an over 45% inconsistency in feasibility
assessments when faced with self-validated, logically coherent task
perturbations. This effect is most pronounced in science and medicine domains,
which tend to have maximal standardized jargon and problems, further confirming
our approach. Significant wavering within the self-knowledge of LLMs also shows
flaws in current architectures and training patterns, highlighting the need for
techniques that ensure a balanced, consistent stance on models' perceptions of
their own knowledge for maximum AI explainability and trustworthiness. Our code
and results are available publicly at
https://github.com/knowledge-verse-ai/LLM-Memorization_SK_Eval-.

</details>


### [12] [Broken Tokens? Your Language Model can Secretly Handle Non-Canonical Tokenizations](https://arxiv.org/abs/2506.19004)
*Brian Siyuan Zheng,Alisa Liu,Orevaoghene Ahia,Jonathan Hayase,Yejin Choi,Noah A. Smith*

Main category: cs.CL

TL;DR: 论文发现，大模型对未见过的非规范分词有很强鲁棒性，并在特殊任务上通过调整分词方式提升性能，指出模型与分词器并非高度绑定，部分能力来源于指令微调。


<details>
  <summary>Details</summary>
Motivation: 当前主流的分词器将文本转换为单一的“规范”token序列，但实际上同一个字符串可以被分词器词表编码为多种非规范token序列。研究者好奇，模型对从未见过的非规范分词是否具备鲁棒性，并探索改变分词方式是否能够提升模型表现。

Method: 在20个基准测试集上，以不同的非规范分词方式（如随机分词、字符级分词等）对instruction-tuned语言模型进行评估，对比其性能下降情况。同时，尝试在部分任务上用非规范分词方式提升性能，并分析模型鲁棒性的来源。

Result: Instruction-tuned模型在随机采样分词下保留原性能的93.4%，字符级分词下仍有90.8%。强模型更鲁棒，分词偏离越大鲁棒性下降更显著。在部分任务（如字符串操作、代码理解与大数字运算）中，字符级与右侧对齐的分词等非规范分词方式可大幅提升表现。鲁棒性主要来自指令微调阶段。基础模型仅识别但难以容错非规范分词，并可能生成无意义内容，而指令微调模型仍能流畅作答。

Conclusion: LLM对分词器不如预期敏感，合理调整推理时分词策略可以提升某些下游任务性能。分词干预是一种有效提升模型能力的新方法。

Abstract: Modern tokenizers employ deterministic algorithms to map text into a single
"canonical" token sequence, yet the same string can be encoded as many
non-canonical tokenizations using the tokenizer vocabulary. In this work, we
investigate the robustness of LMs to text encoded with non-canonical
tokenizations entirely unseen during training. Surprisingly, when evaluated
across 20 benchmarks, we find that instruction-tuned models retain up to 93.4%
of their original performance when given a randomly sampled tokenization, and
90.8% with character-level tokenization. We see that overall stronger models
tend to be more robust, and robustness diminishes as the tokenization departs
farther from the canonical form. Motivated by these results, we then identify
settings where non-canonical tokenization schemes can *improve* performance,
finding that character-level segmentation improves string manipulation and code
understanding tasks by up to +14%, and right-aligned digit grouping enhances
large-number arithmetic by +33%. Finally, we investigate the source of this
robustness, finding that it arises in the instruction-tuning phase. We show
that while both base and post-trained models grasp the semantics of
non-canonical tokenizations (perceiving them as containing misspellings), base
models try to mimic the imagined mistakes and degenerate into nonsensical
output, while post-trained models are committed to fluent responses. Overall,
our findings suggest that models are less tied to their tokenizer than
previously believed, and demonstrate the promise of intervening on tokenization
at inference time to boost performance.

</details>


### [13] [Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective](https://arxiv.org/abs/2506.19028)
*Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy*

Main category: cs.CL

TL;DR: 该文提出FiSCo框架，通过语义层面主张分解与统计分析，更可靠地检测LLM输出中的群体偏见，并在多项实验中效果优于传统指标。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法忽视了长文本回答中的偏见及LLM输出的内在变异性，导致无法准确衡量模型群体公平性。

Method: 提出了FiSCo统计框架，将模型输出分解为语义上独立的主张，并通过蕴含判断和统计假设检验对组内与组间的语义相似性进行比较，从而检测出细微的群体偏见。还形式化了新的群体反事实公平性定义。

Result: FiSCo在包含性别、种族、年龄等多领域的合成与人工标注数据集上都能更好识别微妙的偏见，且优于现有多种评估指标。

Conclusion: FiSCo 能更可靠地识别大语言模型在群体间（如性别、种族、年龄）长文本回答中的细微偏见，并且减少了LLM输出随机性的影响。其评估效果优于现有多种评价指标。

Abstract: Large Language Models (LLMs) often generate responses with inherent biases,
undermining their reliability in real-world applications. Existing evaluation
methods often overlook biases in long-form responses and the intrinsic
variability of LLM outputs. To address these challenges, we propose
FiSCo(Fine-grained Semantic Computation), a novel statistical framework to
evaluate group-level fairness in LLMs by detecting subtle semantic differences
in long-form responses across demographic groups. Unlike prior work focusing on
sentiment or token-level comparisons, FiSCo goes beyond surface-level analysis
by operating at the claim level, leveraging entailment checks to assess the
consistency of meaning across responses. We decompose model outputs into
semantically distinct claims and apply statistical hypothesis testing to
compare inter- and intra-group similarities, enabling robust detection of
subtle biases. We formalize a new group counterfactual fairness definition and
validate FiSCo on both synthetic and human-annotated datasets spanning gender,
race, and age. Experiments show that FiSco more reliably identifies nuanced
biases while reducing the impact of stochastic LLM variability, outperforming
various evaluation metrics.

</details>


### [14] [Plan for Speed -- Dilated Scheduling for Masked Diffusion Language Models](https://arxiv.org/abs/2506.19037)
*Omer Luxembourg,Haim Permuter,Eliya Nachmani*

Main category: cs.CL

TL;DR: 本文针对掩码扩散语言模型并行推理的低效问题，提出DUS膨胀调度掩码解码方法，无需额外训练，以分组并行方式大幅提升生成速度和质量，在数学与代码任务中展现优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于掩码扩散的语言模型（MDLM）采样器在进行非自回归文本生成时，采用了隐式规划方式——如依据去噪器置信度或熵分数来选择解码token的位置。这些启发式方法在并行解码时无法处理tokens间的依赖性，限制了推理速度与自回归模型近似。

Method: 提出了一种新的Dilated-scheduled Unmasking Strategy（DUS）解码策略，无需额外训练，基于一阶马尔可夫假设，把序列位置按膨胀方式分组（non-adjacent/non-contiguous tokens），使每一步可以并行独立地解码，保留局部上下文信息，从而最小化每次迭代的联合熵。与以往semi-AR的block方法不同，DUS每个生成块只需调用O(log B)次去噪器，极大降低计算开销。

Result: 在GSM8K（数学）和Humaneval、MBPP（代码补全）等benchmark上，DUS在不更改底层去噪器的前提下，性能优于并行置信度规划法。推理效率与生成质量显著提升。

Conclusion: DUS提供了一种轻量级、效率高、质量好的MDLM并行解码新路径，有助于推动掩码扩散语言模型实际应用。

Abstract: Masked diffusion language models (MDLM) have shown strong promise for
non-autoregressive text generation, yet existing samplers act as implicit
planners, selecting tokens to unmask via denoiser confidence or entropy scores.
Such heuristics falter under parallel unmasking - they ignore pairwise
interactions between tokens and cannot account for dependencies when unmasking
multiple positions at once, limiting their inference time to traditional
auto-regressive (AR) models. We introduce the Dilated-scheduled Unmasking
Strategy (DUS), an inference-only, planner-model-free method that requires no
additional training. DUS leverages a first-order Markov assumption to partition
sequence positions into dilation-based groups of non-adjacent tokens, enabling
independent, parallel unmasking steps that respect local context that minimizes
the joint entropy of each iteration step. Unlike semi-AR block approaches
(e.g., LLADA and Dream) that still invoke the denoiser per block, DUS reduces
the number of denoiser calls to O(log B) per generation block - yielding
substantial speedup over the O(B) run time of state-of-the-art diffusion
models, where B is the block size in the semi-AR inference process. In
experiments on math (GSM8K) and code completion (Humaneval, MBPP) benchmarks -
domains suited to non-ordinal generation - DUS improves scores over parallel
confidence-based planner, without modifying the underlying denoiser. DUS offers
a lightweight, budget-aware approach to efficient, high-quality text
generation, paving the way to unlock the true capabilities of MDLMs.

</details>


### [15] [NLPnorth @ TalentCLEF 2025: Comparing Discriminative, Contrastive, and Prompt-Based Methods for Job Title and Skill Matching](https://arxiv.org/abs/2506.19058)
*Mike Zhang,Rob van der Goot*

Main category: cs.CL

TL;DR: 本文针对职位名称匹配和基于职位的技能预测两任务，比较了不同NLP方法，发现大型多语种语言模型及prompting方法表现优异，在竞赛中排名前列，并验证了额外多语种数据的价值。


<details>
  <summary>Details</summary>
Motivation: 职位名称匹配在计算职业市场领域中至关重要，它能够提升自动候选人匹配、职业路径预测和职位市场分析的效果。将职位与技能进行对齐也是该任务的扩展，对相同的下游任务也有重要意义。

Method: 作者针对人才大赛TalentCLEF 2025，分别进行了多语种职位名称匹配和基于职位的技能预测两项任务。方法上，作者比较了（微调的）分类、（微调的）对比学习和prompting三种方法，并利用了来自ESCO的多语言职位与技能描述的额外数据。

Result: 在多语种职位名称匹配任务中，prompting方法表现最佳，测试集平均MAP为0.492（涵盖英语、西班牙语和德语）；在基于职位的技能预测任务中，微调分类法MAP为0.290。总体上，多语种大型语言模型在这两个任务上均表现最优。团队在职位匹配任务中排名第五（共20队），在技能预测任务中排名第三（共14队，按唯一团队计算）。

Conclusion: 多语种大型语言模型在职位名称匹配及基于职位的技能预测中具备较强能力，properly fine-tuned的prompting和分类方法能达到较优效果，借助多语种职位和技能信息有助于提升模型表现。

Abstract: Matching job titles is a highly relevant task in the computational job market
domain, as it improves e.g., automatic candidate matching, career path
prediction, and job market analysis. Furthermore, aligning job titles to job
skills can be considered an extension to this task, with similar relevance for
the same downstream tasks. In this report, we outline NLPnorth's submission to
TalentCLEF 2025, which includes both of these tasks: Multilingual Job Title
Matching, and Job Title-Based Skill Prediction. For both tasks we compare
(fine-tuned) classification-based, (fine-tuned) contrastive-based, and
prompting methods. We observe that for Task A, our prompting approach performs
best with an average of 0.492 mean average precision (MAP) on test data,
averaged over English, Spanish, and German. For Task B, we obtain an MAP of
0.290 on test data with our fine-tuned classification-based approach.
Additionally, we made use of extra data by pulling all the language-specific
titles and corresponding \emph{descriptions} from ESCO for each job and skill.
Overall, we find that the largest multilingual language models perform best for
both tasks. Per the provisional results and only counting the unique teams, the
ranking on Task A is 5$^{\text{th}}$/20 and for Task B 3$^{\text{rd}}$/14.

</details>


### [16] [MFTCXplain: A Multilingual Benchmark Dataset for Evaluating the Moral Reasoning of LLMs through Hate Speech Multi-hop Explanation](https://arxiv.org/abs/2506.19073)
*Jackson Trager,Francielle Vargas,Diego Alves,Matteo Guida,Mikel K. Ngueajio,Ameeta Agrawal,Flor Plaza-del-Arco,Yalda Daryanai,Farzan Karimi-Malekabadi*

Main category: cs.CL

TL;DR: 本文构建了基于道德基础理论的多语言数据集，评估大语言模型的道德推理和理由解释能力。结果显示，LLM在仇恨言论识别效果良好，但道德推理和理由解释能力偏弱，特别是在英以外语言。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型（LLMs）在社会敏感任务中应用广泛，但关于其道德推理能力的评估存在缺陷，包括缺乏道德分类依据的标注和评估对象过于集中在英语，影响透明度、可解释性和多文化适应性。

Method: 作者提出并构建了MFTCXplain多语言数据集，涵盖葡萄牙语、意大利语、波斯语和英语，包含3,000条推文，标注了仇恨言论、道德类别及文本对应理由。利用道德基础理论（MFT），通过多跳解释方式对LLM道德推理能力进行评估。

Result: 实验证明，现有LLM在仇恨言论检测任务中表现良好（F1最高0.836），但在道德情感预测上表现较弱（F1低于0.35），且在理由解释上与人类标注存在较大差距，尤其是在非主流语言中。

Conclusion: 当前LLM在内化与反映人类道德推理能力方面还有显著不足。特别是在多语言和提供可解释理由方面，系统表现有限。

Abstract: Ensuring the moral reasoning capabilities of Large Language Models (LLMs) is
a growing concern as these systems are used in socially sensitive tasks.
Nevertheless, current evaluation benchmarks present two major shortcomings: a
lack of annotations that justify moral classifications, which limits
transparency and interpretability; and a predominant focus on English, which
constrains the assessment of moral reasoning across diverse cultural settings.
In this paper, we introduce MFTCXplain, a multilingual benchmark dataset for
evaluating the moral reasoning of LLMs via hate speech multi-hop explanation
using Moral Foundation Theory (MFT). The dataset comprises 3,000 tweets across
Portuguese, Italian, Persian, and English, annotated with binary hate speech
labels, moral categories, and text span-level rationales. Empirical results
highlight a misalignment between LLM outputs and human annotations in moral
reasoning tasks. While LLMs perform well in hate speech detection (F1 up to
0.836), their ability to predict moral sentiments is notably weak (F1 < 0.35).
Furthermore, rationale alignment remains limited mainly in underrepresented
languages. These findings show the limited capacity of current LLMs to
internalize and reflect human moral reasoning.

</details>


### [17] [Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting](https://arxiv.org/abs/2506.19089)
*Nathaniel Getachew,Abulhair Saparov*

Main category: cs.CL

TL;DR: 本文提出StorySim框架，通过生成新故事精确测试LLM的心智理论与世界建模能力，发现模型对心理推理仍有局限，对近期或早期事件存在偏见，评测工具已开源。


<details>
  <summary>Details</summary>
Motivation: 现有的理论心智（ToM）和世界建模（WM）基准数据集可能受到预训练数据污染，难以精确评测大模型在这些能力上的表现，需要一个可控且新颖的方法来评估大语言模型。

Method: 提出了StorySim框架，通过Storyboard可编程和合成生成新颖故事，并可精确控制人物视角和事件变量。基于此设计了一阶、二阶ToM任务及WM任务，细致考察LLM跟踪和建模心理状态的能力，并对一组主流大模型进行测评。

Result: 大多数大语言模型在世界模型任务表现优于心智推理任务；在推理任务中，与人类相关的故事比与无生命物体相关的故事表现更好。同时发现了模型存在如“新近性偏见”、“过度依赖早期事件”等启发式行为。

Conclusion: StorySim为LLM心理状态建模和推理能力的评测提供了一个可控、可扩展的新工具，揭示了当前模型的优势与局限。相关代码已开放，便于社区广泛应用。

Abstract: We introduce $\texttt{StorySim}$, a programmable framework for synthetically
generating stories to evaluate the theory of mind (ToM) and world modeling (WM)
capabilities of large language models (LLMs). Unlike prior benchmarks that may
suffer from contamination in pretraining data, $\texttt{StorySim}$ produces
novel, compositional story prompts anchored by a highly controllable
$\texttt{Storyboard}$, enabling precise manipulation of character perspectives
and events. We use this framework to design first- and second-order ToM tasks
alongside WM tasks that control for the ability to track and model mental
states. Our experiments across a suite of state-of-the-art LLMs reveal that
most models perform better on WM tasks than ToM tasks, and that models tend to
perform better reasoning with humans compared to inanimate objects.
Additionally, our framework enabled us to find evidence of heuristic behavior
such as recency bias and an over-reliance on earlier events in the story. All
code for generating data and evaluations is freely available.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [18] [Which Company Adjustment Matter? Insights from Uplift Modeling on Financial Health](https://arxiv.org/abs/2506.19049)
*Xinlin Wang,Mats Brorsson*

Main category: cs.CE

TL;DR: 该文将激励建模用于分析企业调整决策对财务状况的影响，提出时序相关的MTDnet方法，实验证明考虑调整顺序可大幅提高效果估计准确性。


<details>
  <summary>Details</summary>
Motivation: 现有激励建模（uplift modeling）多集中于简单的二元、多元或连续干预，而公司调整行为通常为多步且具时间依赖性，无法用传统方法充分建模。作者希望通过新的建模方法更准确地估算公司调整（作为干预）对财务状况的影响。

Method: 首先，作者收集了卢森堡公司财务报表和相关行为数据，将公司调整简化为二元干预，用两种meta-learner和三种著名激励模型进行分析。之后，作者提出了新的时间依赖激励建模框架（MTDnet），用于处理公司调整的时序特性。

Result: 实验结果表明，考虑公司调整时序特性的MTDnet框架，能更好地估计干预效果，证明在公司调整影响评估中纳入时序因素很有必要。

Conclusion: 面向公司调整流程，传统激励建模在未考虑时序依赖时有局限性；作者提出的MTDnet方法能更准确建模复杂、时间相关的干预影响，有助于分析企业调整决策对财务结果的真实作用。

Abstract: Uplift modeling has achieved significant success in various fields,
particularly in online marketing. It is a method that primarily utilizes
machine learning and deep learning to estimate individual treatment effects.
This paper we apply uplift modeling to analyze the effect of company adjustment
on their financial status, and we treat these adjustment as treatments or
interventions in this study. Although there have been extensive studies and
application regarding binary treatments, multiple treatments, and continuous
treatments, company adjustment are often more complex than these scenarios, as
they constitute a series of multiple time-dependent actions. The effect
estimation of company adjustment needs to take into account not only individual
treatment traits but also the temporal order of this series of treatments. This
study collects a real-world data set about company financial statements and
reported behavior in Luxembourg for the experiments. First, we use two
meta-learners and three other well-known uplift models to analyze different
company adjustment by simplifying the adjustment as binary treatments.
Furthermore, we propose a new uplift modeling framework (MTDnet) to address the
time-dependent nature of these adjustment, and the experimental result shows
the necessity of considering the timing of these adjustment.

</details>


### [19] [LKA: Large Kernel Adapter for Enhanced Medical Image Classification](https://arxiv.org/abs/2506.19118)
*Ziquan Zhu,Si-Yuan Lu,Tianjin Huang,Lu Liu,Zhe Liu*

Main category: cs.CE

TL;DR: 医学影像领域，当前高效微调方法因感受野不足表现受限，作者提出大卷积核适配器（LKA），能以高效参数提升感受野，大幅提升迁移性能，准确率领先同类方法。


<details>
  <summary>Details</summary>
Motivation: 当前参数高效微调（PEFT）方法在医学数据集上的表现不佳，主要因为医学影像存在较大解剖变化和低对比度，需要较大的感受野捕捉关键特征，而现有PEFT方法未显式增强感受野。

Method: 提出了Large Kernel Adapter (LKA)，采用下投影、通道内大卷积核和上投影三部分，有效扩大感受野同时保证参数高效。

Result: 在多个医学影像数据集和预训练模型上，LKA明显提升了预训练模型的适应能力，在五个医学数据集上top-1准确率超过11种主流PEFT方法，提升3.5%。

Conclusion: 扩大感受野对医学影像模型迁移非常关键，LKA能显著提升PEFT在医学影像分析的表现，优于现有主流方法。

Abstract: Despite the notable success of current Parameter-Efficient Fine-Tuning (PEFT)
methods across various domains, their effectiveness on medical datasets falls
short of expectations. This limitation arises from two key factors: (1) medical
images exhibit extensive anatomical variation and low contrast, necessitating a
large receptive field to capture critical features, and (2) existing PEFT
methods do not explicitly address the enhancement of receptive fields. To
overcome these challenges, we propose the Large Kernel Adapter (LKA), designed
to expand the receptive field while maintaining parameter efficiency. The
proposed LKA consists of three key components: down-projection, channel-wise
large kernel convolution, and up-projection. Through extensive experiments on
various datasets and pre-trained models, we demonstrate that the incorporation
of a larger kernel size is pivotal in enhancing the adaptation of pre-trained
models for medical image analysis. Our proposed LKA outperforms 11 commonly
used PEFT methods, surpassing the state-of-the-art by 3.5% in top-1 accuracy
across five medical datasets.

</details>


### [20] [Physics-Informed Neural Networks for Industrial Gas Turbines: Recent Trends, Advancements and Challenges](https://arxiv.org/abs/2506.19503)
*Afila Ajithkumar Sophiya,Sepehr Maleki,Giuseppe Bruni,Senthil K. Krishnababu*

Main category: cs.CE

TL;DR: 本文综述了PINNs在工业燃气轮机中的多种应用及技术进展，指出其已有明显成效但仍面临实现和推广的挑战，并给出未来发展建议。


<details>
  <summary>Details</summary>
Motivation: Physics-Informed Neural Networks (PINNs)虽然已被用于求解各类微分方程，但在燃气轮机这一工业重要领域的应用仍处于初步阶段，存在诸多待提升和规范化的环节。亟需对相关研究现状和发展进行综述，为实际应用提供参考。

Method: 本文通过全面调研PINNs在工业燃气轮机（IGTs）领域的应用文献，总结其在气动和气动机械现象分析、流场重建、疲劳评估和颤振预测等方面的贡献，并梳理了相关的技术进展、主要研究工作、实现挑战及未来方向。

Result: PINNs在燃气轮机领域已初步展现出对精度、计算效率和混合建模策略的积极作用，其在若干关键工程场景下具有应用潜力与前景。然而，仍面临健壮性和可扩展性等挑战，需要进一步的技术完善和标准化。

Conclusion: PINNs为燃气轮机相关物理问题的建模和分析带来了新的计算范式，但要实现更广泛的实际应用，还需解决实现效率、精度、健壮性和标准化等多方面的问题。未来的研究应聚焦于算法优化和融合多源信息以提升模型表现。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a promising
computational framework for solving differential equations by integrating deep
learning with physical constraints. However, their application in gas turbines
is still in its early stages, requiring further refinement and standardization
for wider adoption. This survey provides a comprehensive review of PINNs in
Industrial Gas Turbines (IGTs) research, highlighting their contributions to
the analysis of aerodynamic and aeromechanical phenomena, as well as their
applications in flow field reconstruction, fatigue evaluation, and flutter
prediction, and reviews recent advancements in accuracy, computational
efficiency, and hybrid modelling strategies. In addition, it explores key
research efforts, implementation challenges, and future directions aimed at
improving the robustness and scalability of PINNs.

</details>


### [21] [A Spline-Based Stress Function Approach for the Principle of Minimum Complementary Energy](https://arxiv.org/abs/2506.19534)
*Fabian Key,Lukas Freinberger*

Main category: cs.CE

TL;DR: 本文提出了一种基于样条应力函数的新型数值方法，在复杂结构应力预测中展现了更高的灵活性和计算效率，用更少的自由度实现了与传统有限元法相当甚至更优的精度，为结构分析与设计提供了有前景的新工具。


<details>
  <summary>Details</summary>
Motivation: 目前主流位移法有限元虽然常用但需大量未知数才能获得高精度，而现有应力法数值方法又存在复杂性与实用性不足，难以作为可行替代方案。因此，亟需一种既高效又具普适性的应力预测新方法。

Method: 论文提出利用最小互补能原理，构建基于样条函数的应力函数数值方法，专注于平面线性弹性静力学问题，对解析解和两个复杂算例进行了验证和测试。

Result: 新方法不仅在常规解析解下得到了验证，在各向异性材料双层悬臂梁和抛物线非等截面悬臂梁两个极具挑战性的案例上，均展现出精度可与主流有限元法媲美，但仅需显著更少的自由度，且适用于一般几何及边界。

Conclusion: 该研究提出了一种新的基于样条的应力函数数值方法，能够以更少的自由度实现对复杂几何和边界条件下结构应力的高精度预测。该方法不仅灵活高效，还能在多种具有挑战性的工况下达到甚至超越现有主流位移法有限元在应力预测方面的精度。

Abstract: In computational engineering, ensuring the integrity and safety of structures
in fields such as aerospace and civil engineering relies on accurate stress
prediction. However, analytical methods are limited to simple test cases, and
displacement-based finite element methods (FEMs), while commonly used, require
a large number of unknowns to achieve high accuracy; stress-based numerical
methods have so far failed to provide a simple and effective alternative. This
work aims to develop a novel numerical approach that overcomes these
limitations by enabling accurate stress prediction with improved flexibility
for complex geometries and boundary conditions and fewer degrees of freedom
(DOFs). The proposed method is based on a spline-based stress function
formulation for the principle of minimum complementary energy, which we apply
to plane, linear elastostatics. The method is first validated against an
analytical power series solution and then tested on two test cases challenging
for current state-of-the-art numerical schemes, a bi-layer cantilever with
anisotropic material behavior, and a cantilever with a non-prismatic,
parabolic-shaped beam geometry. Results demonstrate that our approach, unlike
analytical methods, can be easily applied to general geometries and boundary
conditions, and achieves stress accuracy comparable to that reported in the
literature for displacement-based FEMs, while requiring significantly fewer
DOFs. This novel spline-based stress function approach thus provides an
efficient and flexible tool for accurate stress prediction, with promising
applications in structural analysis and numerical design.

</details>


### [22] [V2T-CoT: From Vision to Text Chain-of-Thought for Medical Reasoning and Diagnosis](https://arxiv.org/abs/2506.19610)
*Yuan Wang,Jiaxiang Liu,Shujian Gao,Bin Feng,Zhihang Tang,Xiaotang Gai,Jian Wu,Zuozhu Liu*

Main category: cs.CE

TL;DR: V2T-CoT方法通过自动定位医学图像中的关键区域并结合推理路径生成，实现了性能和可解释性的大幅提升，是医学视觉问答领域的重要进展。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉问答(Med-VQA)方法主要关注图像全局特征，忽视了诊断中关键的局部疾病区域定位。此外，当前研究更重视答案准确率，而忽略了临床诊断同样重要的推理路径解释。

Method: 提出了一种从视觉到文本思维链（V2T-CoT）方法，自动在生物医学图像中定位偏好区域，并将该定位结果以区域级像素注意力形式融入视觉思维链模型中；通过对构建的R-Med 39K数据集进行视觉-语言模型微调，实现医学推理路径生成。

Result: V2T-CoT在四个Med-VQA基准测试上取得了最先进的表现，在性能和可解释性方面均有显著提升。

Conclusion: 通过结合视觉定位和文本推理，V2T-CoT能够生成准确且可解释性的诊断结果，且实验验证其在医学视问答场景下的优越性。

Abstract: Recent advances in multimodal techniques have led to significant progress in
Medical Visual Question Answering (Med-VQA). However, most existing models
focus on global image features rather than localizing disease-specific regions
crucial for diagnosis. Additionally, current research tends to emphasize answer
accuracy at the expense of the reasoning pathway, yet both are crucial for
clinical decision-making. To address these challenges, we propose From Vision
to Text Chain-of-Thought (V2T-CoT), a novel approach that automates the
localization of preference areas within biomedical images and incorporates this
localization into region-level pixel attention as knowledge for Vision CoT. By
fine-tuning the vision language model on constructed R-Med 39K dataset, V2T-CoT
provides definitive medical reasoning paths. V2T-CoT integrates visual
grounding with textual rationale generation to establish precise and
explainable diagnostic results. Experimental results across four Med-VQA
benchmarks demonstrate state-of-the-art performance, achieving substantial
improvements in both performance and interpretability.

</details>


### [23] [ReLink: Computational Circular Design of Planar Linkage Mechanisms Using Available Standard Parts](https://arxiv.org/abs/2506.19657)
*Maxime Escande,Kristina Shea*

Main category: cs.CE

TL;DR: 本文提出ReLink框架，实现了基于标准件复用的循环设计方法，能在确保机构性能的同时，显著降低新件消耗和环境影响，为可持续机械设计提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 当前机械设计领域大多假设可以无限定制并获取零部件，这种方式难以契合循环经济对资源可持续利用的需求。本文希望通过促进标准件的复用以减少新零件的消耗，探索循环设计对机械连杆机构的实现路径。

Method: 提出了名为ReLink的计算框架。该框架由两个主要部分组成：一是基于现有标准零件清单进行机制生成的生成式设计算法；二是结合优化方法，通过逆向设计来满足用户自定义运动轨迹。设计过程中还兼顾运动性能与碳足迹的权衡，并对组合优化和解空间约束等难题进行了针对性解决。

Result: ReLink能成功在标准件资源受限的情况下，为平面连杆机构生成可行且低环境影响的解决方案，在性能与环保之间实现了平衡。同时为今后更多兼顾可持续发展的机械产品设计提供了方法论基础。

Conclusion: 将循环经济理念与机械运动合成结合，为机械设计中零部件重复利用和减碳创新提供了新引擎。所提出的ReLink不仅能提升设计可持续性，也展示了解决复杂组合设计难题的计算手段，为后续相关研究奠定了基础。

Abstract: The Circular Economy framework emphasizes sustainability by reducing resource
consumption and waste through the reuse of components and materials. This paper
presents ReLink, a computational framework for the circular design of planar
linkage mechanisms using available standard parts. Unlike most mechanism design
methods, which assume the ability to create custom parts and infinite part
availability, ReLink prioritizes the reuse of discrete, standardized
components, thus minimizing the need for new parts. The framework consists of
two main components: design generation, where a generative design algorithm
generates mechanisms from an inventory of available parts, and inverse design,
which uses optimization methods to identify designs that match a user-defined
trajectory curve. The paper also examines the trade-offs between kinematic
performance and CO2 footprint when incorporating new parts. Challenges such as
the combinatorial nature of the design problem and the enforcement of valid
solutions are addressed. By combining sustainability principles with kinematic
synthesis, ReLink lays the groundwork for further research into computational
circular design to support the development of systems that integrate reused
components into mechanical products.

</details>


### [24] [A modular and extensible library for parameterized terrain generation](https://arxiv.org/abs/2506.19751)
*Erik Wallin*

Main category: cs.CE

TL;DR: 作者提出了一个可参数化的Python模块化地形生成库，以灵活生成各类可控地形，支持机器学习和自动化流程，具有易配置、可扩展和高可重复性的优势。


<details>
  <summary>Details</summary>
Motivation: 现有的地形生成工具主要面向艺术设计和视觉真实性，缺乏参数化、可重复性和脚本化支持，不适合模拟驱动的智能机器开发。

Method: 提出了一个基于Python的模块化过程地形生成库，通过简单模块的串联，可灵活构建参数化复杂地形。该系统支持结构化和噪声型地形元素，并可与Blender集成进行渲染与对象放置。

Result: 系统实现了地形特征（如坡度、粗糙度、岩石数量等）的细粒度可控，并易于扩展到更多指标，适合需要可重复、可变和自动化流程集成的需求。

Conclusion: 该模块化地形生成库提供了高度灵活、易于配置和扩展的地形生成能力，非常适合需要合成地形、机器学习训练、知觉任务等高标准地形数据的流程。

Abstract: Simulation-driven development of intelligent machines benefits from
artificial terrains with controllable, well-defined characteristics. However,
most existing tools for terrain generation focus on artist-driven workflows and
visual realism, with limited support for parameterization, reproducibility, or
scripting. We present a modular, Python-based library for procedural terrain
generation that enables users to construct complex, parameterized terrains by
chaining together simple modules. The system supports both structured and
noise-based terrain elements, and integrates with Blender for rendering and
object placement. The framework is designed to support applications such as
generating synthetic terrains for training machine learning models or producing
ground truth for perception tasks. By using a minimal but extensible set of
modules, the system achieves high flexibility while remaining easy to configure
and expand. We demonstrate that this enables fine-grained control over features
such as slope, roughness, and the number of rocks, as well as extension to
additional measures. This makes it well suited for workflows that demand
reproducibility, variation, and integration with automated pipelines.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [25] [AI-based Approach in Early Warning Systems: Focus on Emergency Communication Ecosystem and Citizen Participation in Nordic Countries](https://arxiv.org/abs/2506.18926)
*Fuzel Shaik,Getnet Demil,Mourad Oussalah*

Main category: cs.CY

TL;DR: 论文梳理了AI技术在气候变化和自然灾害风险管理全流程中的作用，突出预警系统、风险建模和案例分析，强调应急沟通与心理认知，提出整体应对策略。


<details>
  <summary>Details</summary>
Motivation: 气候变化和自然灾害带来的社会、经济和环境影响日益严峻，全球需要高效、复杂的应对生态系统。

Method: 采用整体性视角，将应对工作分为准备、应急响应和危机后阶段，重点分析预警系统、风险建模与缓解措施，梳理AI赋能技术在各阶段的应用，以INFORM风险框架和预警系统为核心，结合北欧国家案例研究。

Result: 明确了AI技术在灾害管理各阶段的潜力，完善了INFORM框架和预警系统在实际管理中的关键作用，并通过北欧案例展现实用成效。

Conclusion: 全面管理气候和灾害风险需全过程考虑AI与信息系统的集成，强调应急沟通与心理风险认知，提升整体应灾能力。

Abstract: Climate change and natural disasters are recognized as worldwide challenges
requiring complex and efficient ecosystems to deal with social, economic, and
environmental effects. This chapter advocates a holistic approach,
distinguishing preparedness, emergency responses, and postcrisis phases. The
role of the Early Warning System (EWS), Risk modeling and mitigation measures
are particularly emphasized. The chapter reviews the various Artificial
Intelligence (AI)-enabler technologies that can be leveraged at each phase,
focusing on the INFORM risk framework and EWSs. Emergency communication and
psychological risk perception have been emphasized in emergency response times.
Finally, a set of case studies from Nordic countries has been highlighted.

</details>


### [26] [AI Safety vs. AI Security: Demystifying the Distinction and Boundaries](https://arxiv.org/abs/2506.18932)
*Zhiqiang Lin,Huan Sun,Ness Shroff*

Main category: cs.CY

TL;DR: 本文厘清了AI安全（关注系统本身出错及防止有害行为）与AI安保（关注外部攻击和恶意利用）的区别及联系，为政策和研究提供了理论框架。


<details>
  <summary>Details</summary>
Motivation: AI正在被广泛应用于关键领域，但“AI安全”和“AI安保”在风险管理讨论中常被混用，造成概念混淆。因此需要清晰界定二者区别和联系。

Method: 论文通过提出严格定义、划分各自研究重点，并借用信息传递与建筑结构的类比，系统阐述AI安全与AI安保之间的区别和相互作用。

Result: 明确区分了AI安全和AI安保的研究边界，解释了二者互相关联的机制，为未来跨学科合作和政策制定提供了理论基础。

Conclusion: 理清AI安全与AI安保的概念有助于指导今后研究方向，促进协作，提高政策效力，推动可信AI系统的建设。

Abstract: Artificial Intelligence (AI) is rapidly being integrated into critical
systems across various domains, from healthcare to autonomous vehicles. While
its integration brings immense benefits, it also introduces significant risks,
including those arising from AI misuse. Within the discourse on managing these
risks, the terms "AI Safety" and "AI Security" are often used, sometimes
interchangeably, resulting in conceptual confusion. This paper aims to
demystify the distinction and delineate the precise research boundaries between
AI Safety and AI Security. We provide rigorous definitions, outline their
respective research focuses, and explore their interdependency, including how
security breaches can precipitate safety failures and vice versa. Using clear
analogies from message transmission and building construction, we illustrate
these distinctions. Clarifying these boundaries is crucial for guiding precise
research directions, fostering effective cross-disciplinary collaboration,
enhancing policy effectiveness, and ultimately, promoting the deployment of
trustworthy AI systems.

</details>


### [27] [Can AI support student engagement in classroom activities in higher education?](https://arxiv.org/abs/2506.18941)
*Neha Rani,Sharan Majumder,Ishan Bhardwaj,Pedro Guillermo Feijoo Garcia*

Main category: cs.CY

TL;DR: 本研究验证了在大班软件工程课中，应用ChatGPT可显著提升学生与学习内容的互动与参与度。


<details>
  <summary>Details</summary>
Motivation: 随着计算机科学专业的就业前景和创造性机会越来越吸引学生，相关课程的注册人数激增，导致班级规模巨大，带来师生、内容互动不足的问题。如何提升大班课堂中学生与学习内容的深度互动成为挑战。当前大语言模型（LLM）技术进步，为这一问题提供了新解决路径。

Method: 在美国某大学的大型软件工程课程中设计了一个课堂活动，让学生分两组，一组使用会话型AI（ChatGPT）辅助学习，另一组未用AI，采用组内对照的实验设计，比较两组学生课堂参与度。

Result: 使用会话型AI（ChatGPT）的学生，在课堂活动中与学习内容的互动和参与度显著提升，尤其在大班教学环境下效果明显。

Conclusion: 会话型AI如ChatGPT能够有效提升大规模课堂中学生与内容的互动和参与度，对大班教学有积极促进作用。

Abstract: Lucrative career prospects and creative opportunities often attract students
to enroll in computer science majors and pursue advanced studies in the field.
Consequently, there has been a significant surge in enrollment in computer
science courses, resulting in large class sizes that can range from hundreds to
even thousands of students. A common challenge in such large classrooms is the
lack of engagement between students and both the instructor and the learning
material. However, with advancements in technology and improvements in large
language models (LLMs), there is a considerable opportunity to utilize
LLM-based AI models, such as conversational artificial intelligence (CAI), to
enhance student engagement with learning content in large classes. To explore
the potential of CAI to support engagement, especially with learning content,
we designed an activity in a software Engineering course (with a large class
size) where students used CAI for an in-class activity. We conducted a
within-subject investigation in a large classroom at a US university where we
compared student engagement during an in-class activity that used CAI tool vs.
one without CAI tool. The CAI tool we used was ChatGPT due to its widespread
popularity and familiarity. Our results indicate that CAI (ChatGPT) has the
potential to support engagement with learning content during in-class
activities, especially in large class sizes. We further discuss the
implications of our findings.

</details>


### [28] [Advanced Applications of Generative AI in Actuarial Science: Case Studies Beyond ChatGPT](https://arxiv.org/abs/2506.18942)
*Simon Hatzesberger,Iris Nonneman*

Main category: cs.CY

TL;DR: 本文通过四大案例阐述GenAI对精算科学和保险行业的革命性影响，从理赔预测到自动化报告，表明GenAI能显著提升效率和智能化水平，但同时需解决监管、伦理和技术瓶颈。


<details>
  <summary>Details</summary>
Motivation: 近年来生成式人工智能（GenAI）的快速发展为精算科学和保险行业带来了新机遇和挑战，需要系统性分析其影响和实际应用价值。

Method: 本文以回顾AI发展历史为基础，通过四个具体案例分析GenAI在精算科学中的实际应用，包括大语言模型处理非结构化文本、基于GenAI的检索增强生成、视觉增强LLM和多智能体系统的自动化报告生成。

Result: 1. LLM从文本数据中提取特征后可显著提升理赔费用预测准确性；2. 检索增强生成支持自动化保险市场比对；3. 视觉增强LLM有效分类车损种类并提取信息；4. 多智能体系统可自动分析数据生成报告。此外，提出GenAI在保险理赔自动化、欺诈检测及合规审核等方面的前景，同时讨论了监管、伦理及技术等限制。

Conclusion: GenAI技术对于提升保险业数据处理、决策与流程自动化能力具有显著推动作用，但实际落地需关注相关监管、伦理和技术挑战。

Abstract: This article demonstrates the transformative impact of Generative AI (GenAI)
on actuarial science, illustrated by four implemented case studies. It begins
with a historical overview of AI, tracing its evolution from early neural
networks to modern GenAI technologies. The first case study shows how Large
Language Models (LLMs) improve claims cost prediction by deriving significant
features from unstructured textual data, significantly reducing prediction
errors in the underlying machine learning task. In the second case study, we
explore the automation of market comparisons using the GenAI concept of
Retrieval-Augmented Generation to identify and process relevant information
from documents. A third case study highlights the capabilities of fine-tuned
vision-enabled LLMs in classifying car damage types and extracting contextual
information. The fourth case study presents a multi-agent system that
autonomously analyzes data from a given dataset and generates a corresponding
report detailing the key findings. In addition to these case studies, we
outline further potential applications of GenAI in the insurance industry, such
as the automation of claims processing and fraud detection, and the
verification of document compliance with internal or external policies.
Finally, we discuss challenges and considerations associated with the use of
GenAI, covering regulatory issues, ethical concerns, and technical limitations,
among others.

</details>


### [29] [Citizenship Challenges in Artificial Intelligence Education](https://arxiv.org/abs/2506.18955)
*Margarida Romero*

Main category: cs.CY

TL;DR: 该章节探讨了AI融入教育时涉及的公民身份和伦理挑战，提出通过批判性和计算思维训练等多种策略，提升师生AI素养，实现负责任和创新性的AI教育应用。


<details>
  <summary>Details</summary>
Motivation: 随着AI在教育领域日益普及，学生、教师和相关利益相关者需应对AI带来的伦理和社会挑战，有必要通过教育手段鼓励理性、批判性和创造性的AI使用方式。

Method: 本章通过文献综述和概念探讨，提出了培养AI意识、采用社会批判性方法进行AI培训、以及促进批判性和计算思维技能的具体策略。

Result: 本章提出了提升AI素养的具体策略，强调了合理应用AI和发展批判性、计算思维对未来教育的重要性，并指出需优先考虑伦理与社会相关的AI应用方式。

Conclusion: 该章节强调了在教育中整合AI时，需要关注公民身份相关的挑战，呼吁教育工作者和学生发展批判性思维和计算思维，并采取有意识和伦理的AI应用。

Abstract: This chapter addresses the citizenship challenges related to AI in education,
particularly concerning students, teachers, and other educational stakeholders
in the context of AI integration. We first explore how to foster AI awareness
and education, along with various strategies to promote a socio-critical
approach to AI training, aiming to identify relevant and ethical uses to
prioritise. In the second part, we discuss critical thinking and computational
thinking skills that can be mobilised within certain AI-supported educational
activities, depending on the degree of creative and transformative engagement
those activities require.

</details>


### [30] [Canary in the Mine: An LLM Augmented Survey of Disciplinary Complaints to the Ordre des ingénieurs du Québec (OIQ)](https://arxiv.org/abs/2506.19775)
*Tammy Mackenzie,Varsha Kesavan,Thomas Mekhael,Animesh Paul,Branislav Radeljic,Sara Kodeiri,Sreyoshi Bhaduri*

Main category: cs.CY

TL;DR: 本文通过大型语言模型分析魁北克工程师纪律档案，总结违规事件类型及成因，并为工程教育改革和职业道德培养提供针对性建议，有助于提升工程师的职业素养和道德责任。


<details>
  <summary>Details</summary>
Motivation: 研究魁北克工程师的纪律违规事件及其根本原因，揭示当前工程教育中存在的关键缺口，从而为工程教育改革和提升提供实证依据。

Method: 利用预训练大型语言模型（LLMs）对魁北克工程师协会（OIQ）2010至2024年纪律档案进行主题分析，结合工程教育与人力资源管理专家合作，从中归纳事件类型、趋势和改进空间。

Result: 识别出纪律事件中反复出现的主题及其根本原因，针对这些原因提出改进建议，旨在减少类似事件的发生，最终推动工程教育课程和专业发展。

Conclusion: 本研究为工程教育和职业发展提供了基于实证的数据支持，帮助提升工程师的职业道德和专业责任感，促进工程教育界对职业精神和伦理规范的理解和实践。通过主题分析明确了当前工程教育中的不足与改进路径。

Abstract: This study uses pre-trained LLMs to conduct thematic analysis to investigate
disciplinary incidents involving engineers in Quebec, shedding light on
critical gaps in engineering education. Through a comprehensive review of the
disciplinary register of the Ordre des ing\'enieurs du Qu\'ebec (OIQ)'s
disciplinary register for 2010 to 2024, researchers from engineering education
and human resources management in technological development laboratories
conducted a thematic analysis of reported incidents to identify patterns,
trends, and areas for improvement. The analysis aims to uncover the most common
types of disciplinary incidents, underlying causes, and implications for the
field in how engineering education addresses (or fails to address) these
issues. Our findings identify recurring themes, analyze root causes, and offer
recommendations for engineering educators and students to mitigate similar
incidents. This research has implications for informing curriculum development,
professional development, and performance evaluation, ultimately fostering a
culture of professionalism and ethical responsibility in engineering. By
providing empirical evidence of disciplinary incidents and their causes, this
study contributes to evidence-based practices for engineering education and
professional development, enhancing the engineering education community's
understanding of professionalism and ethics.

</details>


### [31] [LLM-Based Social Simulations Require a Boundary](https://arxiv.org/abs/2506.19806)
*Zengqing Wu,Run Peng,Takayuki Ito,Chuan Xiao*

Main category: cs.CY

TL;DR: 本文分析了LLM在社会模拟中的能力与局限，强调了对齐性、行为一致性和鲁棒性的重要性，并提出了应用边界与核查清单，建议将LLM主要用于分析群体行为模式、并需结合验证手段。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLM）在模拟类人代理方面显示出比传统基于代理的建模更优的能力，研究人员希望利用LLM推动社会科学建模发展，但其可靠性和方法边界存争议。

Method: 文章梳理LLM在社会模拟中的三大核心边界问题：行为一致性、模型与现实的对齐性、以及结果的可复现性，从理论层面提出启发式边界标准。最终，作者提出一份实用核查清单，用于指导研究者如何合理使用LLM进行社会模拟研究。

Result: 作者认为LLM驱动的社会模拟在聚焦集体模式、不追求个体轨迹后，若代理平均行为与现实群体一致、且有适当的验证方法，则具有推动社会科学的价值。文章也为学界提供了明确的适用范围和合理声明的标准。

Conclusion: LLM社会模拟必须设立明确的边界与核查规范，只有在符合行为对齐性、结果一致性、以及鲁棒性测试前提下，方能对社会科学研究做出可靠贡献。聚焦集体模式、群体平均行为及严谨的验证方法是LLM在该领域应用的核心方向。

Abstract: This position paper argues that large language model (LLM)-based social
simulations should establish clear boundaries to meaningfully contribute to
social science research. While LLMs offer promising capabilities for modeling
human-like agents compared to traditional agent-based modeling, they face
fundamental limitations that constrain their reliability for social pattern
discovery. The core issue lies in LLMs' tendency towards an ``average persona''
that lacks sufficient behavioral heterogeneity, a critical requirement for
simulating complex social dynamics. We examine three key boundary problems:
alignment (simulated behaviors matching real-world patterns), consistency
(maintaining coherent agent behavior over time), and robustness
(reproducibility under varying conditions). We propose heuristic boundaries for
determining when LLM-based simulations can reliably advance social science
understanding. We believe that these simulations are more valuable when
focusing on (1) collective patterns rather than individual trajectories, (2)
agent behaviors aligning with real population averages despite limited
variance, and (3) proper validation methods available for testing simulation
robustness. We provide a practical checklist to guide researchers in
determining the appropriate scope and claims for LLM-based social simulations.

</details>
