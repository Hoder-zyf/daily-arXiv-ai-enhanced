<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 49]
- [cs.CL](#cs.CL) [Total: 51]
- [cs.CE](#cs.CE) [Total: 15]
- [cs.CY](#cs.CY) [Total: 20]
- [q-fin.TR](#q-fin.TR) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Evaluating Generalization and Representation Stability in Small LMs via Prompting](https://arxiv.org/abs/2506.17289)
*Rahul Raja,Arpita Vats*

Main category: cs.AI

TL;DR: 本文全面对比小型语言模型在prompt与微调两种范式下的泛化能力，重点关注分布外及低资源任务，通过内部表征分析揭示两者机制差异，助力实际策略选择。


<details>
  <summary>Details</summary>
Motivation: 当前prompt方法因参数高效被广泛使用，但其在低资源和分布漂移情况下的鲁棒性尚不明确，相关对比和实证分析亟需深入。

Method: 对比实验，涵盖不同任务格式、prompt风格和模型规模，分别研究prompt和微调策略在分布内外场景下的表现。同时，分析模型内部表征，评价任务特征抽象与稳定性。

Result: 两种适应方式在内部知识建模、泛化性能及特征抽象上机制迥异。研究发现针对不同低数据场景适合不同策略，并为具体模型选择提供实证依据。

Conclusion: 小型语言模型在few-shot prompt和监督微调两种适应范式下展现出不同的泛化能力，尤其是在分布外测试和低资源情况下，两者表现存在显著差异。

Abstract: We investigate the generalization capabilities of small language models under
two popular adaptation paradigms: few-shot prompting and supervised
fine-tuning. While prompting is often favored for its parameter efficiency and
flexibility, it remains unclear how robust this approach is in low-resource
settings and under distributional shifts. This paper presents a comparative
study of prompting and fine-tuning across task formats, prompt styles, and
model scales, with a focus on their behavior in both in-distribution and
out-of-distribution (OOD) settings.
  Beyond accuracy, we analyze the internal representations learned by each
approach to assess the stability and abstraction of task-specific features. Our
findings highlight critical differences in how small models internalize and
generalize knowledge under different adaptation strategies. This work offers
practical guidance for model selection in low-data regimes and contributes
empirical insight into the ongoing debate over prompting versus fine-tuning.
Code for the experiments is available at the following

</details>


### [2] [Individual Causal Inference with Structural Causal Model](https://arxiv.org/abs/2506.17300)
*Daniel T. Chang*

Main category: cs.AI

TL;DR: 本文提出了用于个体因果推断（ICI）的结构因果模型（SCM）新方法，引入了indiv-operator和个体因果查询，突破了传统只能做群体因果推断的限制，实现了对特定个体的干预推理，适用于精准医疗等领域。


<details>
  <summary>Details</summary>
Motivation: 现有因果推断多基于群体层面，但实际问题常常需要针对特定个体推断干预效应（个体因果效应，ICE），而个体数据有限、现有方法难以直接应用。本文旨在解决个体层面因果推断的理论与方法难题。

Method: 作者通过引入“indiv-operator”（indiv(W)）将群体模型个体化，并提出了针对个体的因果查询P(Y | indiv(W), do(X), Z)。这种方法将个体特征编码进SCM的外生变量中，实现对特定个体的因果效应推理。

Result: 作者提出的ICI-with-SCM方法表明，可以通过对外生变量的建模和特定运算，实现对个体的干预效应推断。ICI关注的是可能的个体结果（individual alternatives），而非反事实（counterfactuals）。新方法能更科学地支持精准医疗等领域的个体决策。

Conclusion: 本文提出了基于结构因果模型（SCM）的个体因果推断（ICI）方法，并通过形式化个体化运算符和查询方式，完善了对个体层面的因果推断框架，强调了其为“第三级因果推断（rung 3）”。

Abstract: Individual causal inference (ICI) uses causal inference methods to understand
and predict the effects of interventions on individuals, considering their
specific characteristics / facts. It aims to estimate individual causal effect
(ICE), which varies across individuals. Estimating ICE can be challenging due
to the limited data available for individuals, and the fact that most causal
inference methods are population-based. Structural Causal Model (SCM) is
fundamentally population-based. Therefore, causal discovery (structural
learning and parameter learning), association queries and intervention queries
are all naturally population-based. However, exogenous variables (U) in SCM can
encode individual variations and thus provide the mechanism for individualized
population per specific individual characteristics / facts. Based on this, we
propose ICI with SCM as a "rung 3" causal inference, because it involves
"imagining" what would be the causal effect of a hypothetical intervention on
an individual, given the individual's observed characteristics / facts.
Specifically, we propose the indiv-operator, indiv(W), to formalize/represent
the population individualization process, and the individual causal query, P(Y
| indiv(W), do(X), Z), to formalize/represent ICI. We show and argue that ICI
with SCM is inference on individual alternatives (possible), not individual
counterfactuals (non-actual).

</details>


### [3] [Resource Rational Contractualism Should Guide AI Alignment](https://arxiv.org/abs/2506.17434)
*Sydney Levine,Matija Franklin,Tan Zhi-Xuan,Secil Yanik Guyot,Lionel Wong,Daniel Kilov,Yejin Choi,Joshua B. Tenenbaum,Noah Goodman,Seth Lazar,Iason Gabriel*

Main category: cs.AI

TL;DR: 本文提出资源理性契约主义（RRC）框架，借助启发式方式高效逼近多元人类共识，从而提升AI伦理对齐与社会适应能力。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统逐渐融入人类社会环境，其决策将影响目标和价值观不同的人类与AI代理。如何让AI的决策被更多利益相关者认可，成为了实现AI伦理对齐的重要挑战。然而，现实中大规模达成这种共识成本高昂，并且效率较低。

Method: 作者提出了资源理性契约主义（Resource-Rational Contractualism, RRC）框架，主张AI借鉴一套规范性基础和认知启发式工具，权衡决策努力与准确性，实现对准人类社会共识的近似。

Result: RRC框架使AI代理不但高效运行，还能够实时适应和解读不断变化的人类社会世界，从而更好地融入人类环境并获得多元主体的广泛认可。

Conclusion: RRC为实现AI系统与人类社会在决策上的高效且动态的伦理对齐提供了新路径，兼顾效率与适应性。

Abstract: AI systems will soon have to navigate human environments and make decisions
that affect people and other AI agents whose goals and values diverge.
Contractualist alignment proposes grounding those decisions in agreements that
diverse stakeholders would endorse under the right conditions, yet securing
such agreement at scale remains costly and slow -- even for advanced AI. We
therefore propose Resource-Rational Contractualism (RRC): a framework where AI
systems approximate the agreements rational parties would form by drawing on a
toolbox of normatively-grounded, cognitively-inspired heuristics that trade
effort for accuracy. An RRC-aligned agent would not only operate efficiently,
but also be equipped to dynamically adapt to and interpret the ever-changing
human social world.

</details>


### [4] [Keeping Medical AI Healthy: A Review of Detection and Correction Methods for System Degradation](https://arxiv.org/abs/2506.17442)
*Hao Guan,David Bates,Li Zhou*

Main category: cs.AI

TL;DR: 本文综述了医疗AI系统在实际应用中因多种因素导致性能退化的问题，系统总结了监控、检测、分析及纠正退化的技术方法，并提出了未来的研究方向，旨在推动医疗AI系统的长期安全和可靠应用。


<details>
  <summary>Details</summary>
Motivation: 人工智能（AI）在现代医疗中的应用日益广泛，但在实际环境下，随着数据分布、患者特征、临床协议以及数据质量的持续变化，AI系统的性能可能随着时间推移而下降。这种退化带来了模型可靠性及患者安全性风险，因此迫切需要监控和维护AI系统的“健康”。

Method: 本综述系统总结了AI性能退化的常见原因，梳理了数据和模型漂移的检测技术，详细介绍了根本原因分析，并审查了包括模型再训练、测试时自适应在内的纠正方案，涵盖传统机器学习模型和先进的大语言模型（LLMs），并讨论了当前技术挑战及未来研究方向。

Result: 本文归纳了检测和纠正医疗AI系统退化的现有方法及各自的优缺点，提出了尚待解决的技术难题及未来的研究重点，为持续可靠部署医疗AI提出了建设性建议。

Conclusion: 本综述为医疗AI系统的持续、可靠和安全部署提供了系统性指导，对未来医疗AI的监控与自纠机制研究具有重要参考价值。

Abstract: Artificial intelligence (AI) is increasingly integrated into modern
healthcare, offering powerful support for clinical decision-making. However, in
real-world settings, AI systems may experience performance degradation over
time, due to factors such as shifting data distributions, changes in patient
characteristics, evolving clinical protocols, and variations in data quality.
These factors can compromise model reliability, posing safety concerns and
increasing the likelihood of inaccurate predictions or adverse outcomes. This
review presents a forward-looking perspective on monitoring and maintaining the
"health" of AI systems in healthcare. We highlight the urgent need for
continuous performance monitoring, early degradation detection, and effective
self-correction mechanisms. The paper begins by reviewing common causes of
performance degradation at both data and model levels. We then summarize key
techniques for detecting data and model drift, followed by an in-depth look at
root cause analysis. Correction strategies are further reviewed, ranging from
model retraining to test-time adaptation. Our survey spans both traditional
machine learning models and state-of-the-art large language models (LLMs),
offering insights into their strengths and limitations. Finally, we discuss
ongoing technical challenges and propose future research directions. This work
aims to guide the development of reliable, robust medical AI systems capable of
sustaining safe, long-term deployment in dynamic clinical settings.

</details>


### [5] [OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections](https://arxiv.org/abs/2506.17449)
*Manasa Bharadwaj,Nikhil Verma,Kevin Ferreira*

Main category: cs.AI

TL;DR: OmniReflect通过分层反思和知识积累机制，为LLM代理引入了高效、可迁移的任务表现提升路径，实验证明其在多个复杂任务上取得显著进展。


<details>
  <summary>Details</summary>
Motivation: 以往提升大语言模型（LLM）代理在复杂任务上的表现，主要依赖微调和自我纠错，这些方法在动态环境下缺乏通用的长期学习机制，效率也不高。因此，寻求一种高效且具可迁移性的学习机制。

Method: 提出OmniReflect框架，这是一种分层、反思驱动的结构，通过构建宪法（从任务经验中提炼的指导原则）来提升LLM代理的表现。OmniReflect包括自我维持模式（单一代理在任务执行中定期总结反思）和协作模式（元顾问根据校准集为代理制定宪法）。宪法的构建采用神经、符号、神经-符号等多种技术，兼顾上下文适应性和计算效率。

Result: 实验证明，在自我维持模式下，OmniReflect在多个数据集上显著提升了任务成功率：ALFWorld提升+10.3%，BabyAI提升+23.8%，PDDL提升+8.3%。在协作模式下，轻量Qwen3-4B ReAct代理全面优于Reflexion基线方法。

Conclusion: OmniReflect框架在不同环境和模型基础上都展现了良好的稳健性和有效性，是提升LLM智能体长期表现的有力工具。

Abstract: Efforts to improve Large Language Model (LLM) agent performance on complex
tasks have largely focused on fine-tuning and iterative self-correction.
However, these approaches often lack generalizable mechanisms for longterm
learning and remain inefficient in dynamic environments. We introduce
OmniReflect, a hierarchical, reflection-driven framework that constructs a
constitution, a compact set of guiding principles distilled from task
experiences, to enhance the effectiveness and efficiency of an LLM agent.
OmniReflect operates in two modes: Self-sustaining, where a single agent
periodically curates its own reflections during task execution, and
Co-operative, where a Meta-advisor derives a constitution from a small
calibration set to guide another agent. To construct these constitutional
principles, we employ Neural, Symbolic, and NeuroSymbolic techniques, offering
a balance between contextual adaptability and computational efficiency.
Empirical results averaged across models show major improvements in task
success, with absolute gains of +10.3% on ALFWorld, +23.8% on BabyAI, and +8.3%
on PDDL in the Self-sustaining mode. Similar gains are seen in the Co-operative
mode, where a lightweight Qwen3-4B ReAct agent outperforms all Reflexion
baselines on BabyAI. These findings highlight the robustness and effectiveness
of OmniReflect across environments and backbones.

</details>


### [6] [From Unstructured Communication to Intelligent RAG: Multi-Agent Automation for Supply Chain Knowledge Bases](https://arxiv.org/abs/2506.17484)
*Yao Zhang,Zaixi Shang,Silpan Patel,Mikel Zuniga*

Main category: cs.AI

TL;DR: 作者提出基于大模型和多智能体的离线结构化方案，从原始支持工单等非结构化数据中自动构建高质量、可复用的知识库，大幅提升RAG系统效果，实现供应链运维知识自动沉淀和高效利用。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统面对原始运维对话数据（如工单、邮件、聊天记录）时，由于这些数据噪音多、不完全且不一致，导致检索效果受限。因此需要一种能将非结构化通信转为高质量知识库的方法，从而释放专家沉淀知识，实现知识共享和运维自动化。

Method: 论文设计了一套由三个专用智能体（类别发现、归类和知识合成）协作的多智能体系统。该系统首先对原始支持工单进行分类、归类，然后生成结构化的知识文章，最终形成用于RAG系统的紧凑知识库。

Result: 本方法在真实工单应用中，把知识库体积缩减至原始数据的3.4%，且提升了RAG系统的答案有用率（48.74% vs. 38.60%），同时无用回答减少77.4%。系统能自动化解决近50%的后续供应链工单，大幅降低工作负担并提升响应速度。

Conclusion: 该论文提出了一种通过多智能体大模型（LLMs-based multi-agent system）自动提取、结构化和重组供应链非结构化运维数据的离线优先方案，这种方式显著提升了知识管理效率及RAG系统的有效性。

Abstract: Supply chain operations generate vast amounts of operational data; however,
critical knowledge such as system usage practices, troubleshooting workflows,
and resolution techniques often remains buried within unstructured
communications like support tickets, emails, and chat logs. While RAG systems
aim to leverage such communications as a knowledge base, their effectiveness is
limited by raw data challenges: support tickets are typically noisy,
inconsistent, and incomplete, making direct retrieval suboptimal. Unlike
existing RAG approaches that focus on runtime optimization, we introduce a
novel offline-first methodology that transforms these communications into a
structured knowledge base. Our key innovation is a LLMs-based multi-agent
system orchestrating three specialized agents: Category Discovery for taxonomy
creation, Categorization for ticket grouping, and Knowledge Synthesis for
article generation. Applying our methodology to real-world support tickets with
resolution notes and comments, our system creates a compact knowledge base -
reducing total volume to just 3.4% of original ticket data while improving
quality. Experiments demonstrate that our prebuilt knowledge base in RAG
systems significantly outperforms traditional RAG implementations (48.74% vs.
38.60% helpful answers) and achieves a 77.4% reduction in unhelpful responses.
By automating institutional knowledge capture that typically remains siloed in
experts' heads, our solution translates to substantial operational efficiency:
reducing support workload, accelerating resolution times, and creating
self-improving systems that automatically resolve approximately 50% of future
supply chain tickets. Our approach addresses a key gap in knowledge management
by transforming transient communications into structured, reusable knowledge
through intelligent offline processing rather than latency-inducing runtime
architectures.

</details>


### [7] [Kaleidoscopic Teaming in Multi Agent Simulations](https://arxiv.org/abs/2506.17514)
*Ninareh Mehrabi,Tharindu Kumarage,Kai-Wei Chang,Aram Galstyan,Rahul Gupta*

Main category: cs.AI

TL;DR: 该论文提出了针对AI智能体在复杂单体/多体场景下安全漏洞的新评测框架（kaleidoscopic teaming），通过生成多样化现实场景和创新优化手段，发现并量化了智能体在实际应用中的安全漏洞，弥补了现有安全评估方法的不足。


<details>
  <summary>Details</summary>
Motivation: 当前AI智能体由于其自主工具使用能力和实际应用的广泛性，带来了前所未有的安全挑战，现有的红队测试或安全评估框架难以评估其复杂交互过程中的安全风险，尤其在多智能体场景下更为突出。

Method: 作者提出了“多棱镜团队（kaleidoscopic teaming）”的新框架，能够生成多样化的模拟真实社会的复杂场景，分别对单智能体和多智能体的安全风险进行系统评估。方法包括场景生成、安全漏洞捕捉、新的上下文优化技术，以及量化安全评估的指标。单智能体任务聚焦其自主完成工具使用，多智能体任务模拟协作或对抗。

Result: 利用所提出的kaleidoscopic teaming框架，作者在不同的模型中识别和分析了其在实际智能体应用场景下的具体安全漏洞。

Conclusion: 现有安全测试框架难以覆盖AI智能体在复杂任务和多智能体交互下的全部安全风险，所提出的新框架能够更加全面且有效地评估和揭示这些安全隐患，对增强AI系统安全具有重要意义。

Abstract: Warning: This paper contains content that may be inappropriate or offensive.
  AI agents have gained significant recent attention due to their autonomous
tool usage capabilities and their integration in various real-world
applications. This autonomy poses novel challenges for the safety of such
systems, both in single- and multi-agent scenarios. We argue that existing red
teaming or safety evaluation frameworks fall short in evaluating safety risks
in complex behaviors, thought processes and actions taken by agents. Moreover,
they fail to consider risks in multi-agent setups where various vulnerabilities
can be exposed when agents engage in complex behaviors and interactions with
each other. To address this shortcoming, we introduce the term kaleidoscopic
teaming which seeks to capture complex and wide range of vulnerabilities that
can happen in agents both in single-agent and multi-agent scenarios. We also
present a new kaleidoscopic teaming framework that generates a diverse array of
scenarios modeling real-world human societies. Our framework evaluates safety
of agents in both single-agent and multi-agent setups. In single-agent setup,
an agent is given a scenario that it needs to complete using the tools it has
access to. In multi-agent setup, multiple agents either compete against or
cooperate together to complete a task in the scenario through which we capture
existing safety vulnerabilities in agents. We introduce new in-context
optimization techniques that can be used in our kaleidoscopic teaming framework
to generate better scenarios for safety analysis. Lastly, we present
appropriate metrics that can be used along with our framework to measure safety
of agents. Utilizing our kaleidoscopic teaming framework, we identify
vulnerabilities in various models with respect to their safety in agentic
use-cases.

</details>


### [8] [Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models](https://arxiv.org/abs/2506.17585)
*Yukun Huang,Sanxing Chen,Jian Pei,Manzil Zaheer,Bhuwan Dhingra*

Main category: cs.AI

TL;DR: 该文提出Active Indexing训练法，让大模型无须测试时检索即可可靠归因于预训练文档，显著提升多类问题下的引用精度。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型回答需要可验证的引用，但常常“幻觉”产生不可靠的引用。主流做法通过外部检索插入引用，带来延迟和噪声问题。作者希望在不依赖测试时检索的前提下，提高模型自身的引用可靠性。

Method: 提出一种两阶段训练流程：（1）持续预训练，将事实和文档ID绑定；（2）指令微调以诱导引用行为。比较了两种方法：Passive Indexing（直接附加ID）与Active Indexing（持续基于合成QA对、多样化表达训练、事实与来源双向生成）。

Result: Active Indexing在所有任务和模型上表现优于Passive Indexing，引用精度最高提升30.2%；且随着增强数据量增加，性能持续提升。

Conclusion: 通过在预训练阶段积极融合文档归属信息，模型在无需实时检索下显著提升了引用准确性和可验证性。

Abstract: Trustworthy language models should provide both correct and verifiable
answers. While language models can sometimes attribute their outputs to
pretraining data, their citations are often unreliable due to hallucination. As
a result, current systems insert citations by querying an external retriever at
inference time, introducing latency, infrastructure dependence, and
vulnerability to retrieval noise. We explore whether LLMs can be made to
reliably attribute to the documents seen during (continual)
pretraining--without test-time retrieval--by revising the training process. To
evaluate this, we release CitePretrainBench, a benchmark that mixes real-world
corpora (Wikipedia, Common Crawl, arXiv) with novel, unseen documents and
probes both short-form (single fact) and long-form (multi-fact) citation tasks.
Our approach follows a two-stage process: (1) continual pretraining to bind
facts to persistent document identifiers, and (2) instruction tuning to elicit
citation behavior. We find that simple Passive Indexing, which appends an
identifier to each document, helps memorize verbatim text but fails on
paraphrased or compositional facts. Instead, we propose Active Indexing, which
continually pretrains on synthetic QA pairs that (1) restate each fact in
diverse compositional forms, and (2) require bidirectional source-to-fact and
fact-to-source generation, jointly teaching the model to generate content from
a cited source and to attribute its own answers. Experiments with Qwen2.5-7B
and 3B show that Active Indexing consistently outperforms Passive Indexing
across all tasks and models, with citation precision gains up to 30.2 percent.
Our ablation studies reveal that performance continues to improve as we scale
the amount of augmented data, showing a clear upward trend even at 16 times the
original token count.

</details>


### [9] [Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to Conquer the Unknown](https://arxiv.org/abs/2506.17589)
*Bowen Wang*

Main category: cs.AI

TL;DR: 本文针对多模态大模型在特定领域知识不足的问题，构建了游戏领域的多模态知识图谱，并设计复杂检索与推理测试，引入多智能体检索方法，显著提升了模型相关能力，为多模态知识增强研究提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型在常见任务表现优秀，但在罕见领域任务中常因知识不足而表现不佳，因此亟需探索提升其罕见领域知识利用能力的方法。

Method: 本文以视觉游戏认知为实验平台，选择《怪物猎人：世界》作为目标，构建了涵盖多模态和复杂实体关系的多模态知识图谱（MH-MMKG），并基于此设计了复杂知识检索和推理挑战。同时，提出了一种多智能体检索器，无需额外训练即可自动检索相关知识。

Result: 实验表明，所提出的方法显著提升了多模态大模型在复杂知识检索和推理方面的表现。

Conclusion: 通过多模态知识图谱和多智能体检索机制，推动了多模态大模型在复杂领域知识利用和推理能力上的进步，为未来多模态知识增强推理研究奠定了基础。

Abstract: The real value of knowledge lies not just in its accumulation, but in its
potential to be harnessed effectively to conquer the unknown. Although recent
multimodal large language models (MLLMs) exhibit impressing multimodal
capabilities, they often fail in rarely encountered domain-specific tasks due
to limited relevant knowledge. To explore this, we adopt visual game cognition
as a testbed and select Monster Hunter: World as the target to construct a
multimodal knowledge graph (MH-MMKG), which incorporates multi-modalities and
intricate entity relations. We also design a series of challenging queries
based on MH-MMKG to evaluate the models' ability for complex knowledge
retrieval and reasoning. Furthermore, we propose a multi-agent retriever that
enables a model to autonomously search relevant knowledge without additional
training. Experimental results show that our approach significantly enhances
the performance of MLLMs, providing a new perspective on multimodal
knowledge-augmented reasoning and laying a solid foundation for future
research.

</details>


### [10] [Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges](https://arxiv.org/abs/2506.17644)
*Zimo Ji,Daoyuan Wu,Wenyuan Jiang,Pingchuan Ma,Zongjie Li,Shuai Wang*

Main category: cs.AI

TL;DR: 作者提出CTFKnow基准系统系统性评估了LLM在CTF知识的理解与应用，发现LLM知识丰富但实战表现受限。为此，作者设计了CTFAgent框架，通过检索增强和环境交互，显著提升了解题能力，在实际赛事中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）的发展，其在CTF（夺旗赛）自动化解题方面的潜力备受关注。当前，相关赛事（如DARPA的AIxCC）旨在推动AI在进攻和防御自动化上的应用。然而，CTF自动化需要多种能力的结合，尤其是技术知识理解与实际应用。本文旨在突出技术知识在CTF解题中的重要性，并评估现有LLM在该方面的表现。

Method: 作者构建了CTFKnow基准集，包含3992道题，用于衡量LLM在CTF技术知识方面的能力。通过实证评测分析LLM的技术知识理解及应用，并针对发现的不足提出了CTFAgent系统。CTFAgent包含两阶段的检索增强生成（RAG）与交互式环境增强两个新模块，分别提升LLM的专业知识和漏洞利用能力。最后，通过在两个主流CTF数据集及picoCTF2024赛事中实验，验证了该框架的有效性。

Result: CTFKnow基准测试发现，LLM虽然具有丰富的CTF技术知识，但在具体场景应用和基于环境反馈调整解题策略方面表现不足。提出的CTFAgent框架在两个CTF数据集上的性能提升超过80%，并在picoCTF2024全球排名前23.6%。

Conclusion: 技术知识理解是LLM自动化解CTF的核心挑战。针对现有LLM在应用和适应方面的不足，提出的CTFAgent通过增强知识检索与交互显著提升了解题表现，展示了AI辅助CTF的巨大潜力。

Abstract: Capture-the-Flag (CTF) competitions are crucial for cybersecurity education
and training. As large language models (LLMs) evolve, there is increasing
interest in their ability to automate CTF challenge solving. For example, DARPA
has organized the AIxCC competition since 2023 to advance AI-powered automated
offense and defense. However, this demands a combination of multiple abilities,
from knowledge to reasoning and further to actions. In this paper, we highlight
the importance of technical knowledge in solving CTF problems and deliberately
construct a focused benchmark, CTFKnow, with 3,992 questions to measure LLMs'
performance in this core aspect. Our study offers a focused and innovative
measurement of LLMs' capability in understanding CTF knowledge and applying it
to solve CTF challenges. Our key findings reveal that while LLMs possess
substantial technical knowledge, they falter in accurately applying this
knowledge to specific scenarios and adapting their strategies based on feedback
from the CTF environment.
  Based on insights derived from this measurement study, we propose CTFAgent, a
novel LLM-driven framework for advancing CTF problem-solving. CTFAgent
introduces two new modules: two-stage Retrieval Augmented Generation (RAG) and
interactive Environmental Augmentation, which enhance LLMs' technical knowledge
and vulnerability exploitation on CTF, respectively. Our experimental results
show that, on two popular CTF datasets, CTFAgent both achieves over 80%
performance improvement. Moreover, in the recent picoCTF2024 hosted by CMU,
CTFAgent ranked in the top 23.6% of nearly 7,000 participating teams. This
reflects the benefit of our measurement study and the potential of our
framework in advancing LLMs' capabilities in CTF problem-solving.

</details>


### [11] [PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models](https://arxiv.org/abs/2506.17667)
*Lintao Wang,Encheng Su,Jiaqi Liu,Pengze Li,Peng Xia,Jiabei Xiao,Wenlong Zhang,Xinnan Dai,Xi Chen,Yuan Meng,Mingyu Ding,Lei Bai,Wanli Ouyang,Shixiang Tang,Aoran Wang,Xinzhu Ma*

Main category: cs.AI

TL;DR: 提出了大学物理多模态基准PhysUniBench，覆盖3304题评价大模型推理能力。实验发现主流模型如GPT-4o mini准确率仅34.2%，在复杂物理推理和图像解读上明显不足。该基准将推动更高级别的AI物理推理能力的研究。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型在解决大学物理问题上表现有限，现有评价方法难以全面反映模型在物理领域的推理和理解能力。因此，亟需一个高质量、广覆盖性的新基准用于系统性评测AI在物理领域的表现。

Method: 提出了大规模多模态物理基准PhysUniBench，涵盖3304道题目、8个物理子领域，每题配有示意图，包含开放式与选择题。通过专家评审、多轮数据采集、自动筛选简单题目、五级难度评分等多阶段流程构建，可全面评估AI的物理推理能力。

Result: 当前最先进的大模型（如GPT-4o mini）在PhysUniBench上的准确率仅为34.2%，在多步骤推理和图像解析类问题上表现尤为不足。

Conclusion: PhysUniBench作为严苛且多维的测评工具，揭示了现有大模型在高阶物理推理方面的短板，有望推动更强物理推理和多模态理解能力AI模型的发展。

Abstract: Physics problem-solving is a challenging domain for large AI models,
requiring integration of conceptual understanding, mathematical reasoning, and
interpretation of physical diagrams. Current evaluation methodologies show
notable limitations in capturing the breadth and complexity of
undergraduate-level physics, underscoring the need for more rigorous
assessments. To this end, we present PhysUniBench, a large-scale multimodal
benchmark designed to evaluate and improve the reasoning capabilities of
multimodal large language models (MLLMs) specifically on undergraduate-level
physics problems. PhysUniBench consists of 3,304 physics questions spanning 8
major sub-disciplines of physics, each accompanied by one visual diagrams. The
benchmark includes both open-ended and multiple-choice questions,
systematically curated and difficulty-rated through an iterative
model-in-the-loop process. The benchmark's construction involved a rigorous
multi-stage process, including multiple roll-outs, expert-level evaluation,
automated filtering of easily solved problems, and a nuanced difficulty grading
system with five levels. Through extensive experiments, we observe that current
state-of-the-art models encounter substantial challenges in physics reasoning.
For example, GPT-4o mini achieves only about 34.2\% accuracy in the proposed
PhysUniBench. These results highlight that current MLLMs struggle with advanced
physics reasoning, especially on multi-step problems and those requiring
precise diagram interpretation. By providing a broad and rigorous assessment
tool, PhysUniBench aims to drive progress in AI for Science, encouraging the
development of models with stronger physical reasoning, problem-solving skills,
and multimodal understanding. The benchmark and evaluation scripts are
available at https://prismax-team.github.io/PhysUniBenchmark/.

</details>


### [12] [Beyond Syntax: Action Semantics Learning for App Agents](https://arxiv.org/abs/2506.17697)
*Bohan Tang,Dezhao Luo,Jingxuan Chen,Shaogang Gong,Jianye Hao,Jun Wang,Kun Shao*

Main category: cs.AI

TL;DR: 本文提出动作语义学习（ASL）框架，通过学习动作带来的语义状态变化而非仅仅复现动作字符串，使App Agent在优化计算效率和提升分布外鲁棒性的同时，极大增强了准确率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于闭源大模型API的App Agent方案计算开销大且依赖外部API，而基于开源小模型的微调虽然解决了这一问题，但当前微调方法存在对语法严格拟合，导致模型对分布外数据（OOD）易失效。

Method: 提出了一种新的学习框架——动作语义学习（Action Semantics Learning, ASL），以动作的语义（即在用户界面上引发的状态变化）为学习目标，借助语义估算器（SEmantic Estimator, SEE）为Agent生成的动作计算语义奖励，从而训练模型学习语义一致的动作输出，而非严格复现语法形式。

Result: 理论上验证了ASL在分布外数据场景下的鲁棒性优于传统语法学习，并通过大量离线和在线的App操作基准测试，实验证明ASL显著提升了App Agent的准确率和泛化能力。

Conclusion: ASL框架通过关注动作语义而非单纯语法复现，提升了App Agent在智能手机应用操作任务中的表现，特别是在面对分布外场景时具有更高的鲁棒性和泛化能力。

Abstract: The advent of Large Language Models (LLMs) enables the rise of App agents
that interpret user intent and operate smartphone Apps through actions such as
clicking and scrolling. While prompt-based solutions with closed LLM APIs show
promising ability, they incur heavy compute costs and external API dependency.
Fine-tuning smaller open-source LLMs solves these limitations. However, current
fine-tuning methods use a syntax learning paradigm that forces agents to
reproduce exactly the ground truth action strings, leading to
out-of-distribution (OOD) vulnerability. To fill this gap, we propose Action
Semantics Learning (ASL), a novel learning framework, where the learning
objective is capturing the semantics of the ground truth actions. Specifically,
inspired by the programming language theory, we define the action semantics for
App agents as the state transition induced by the action in the user interface.
With this insight, ASL employs a novel SEmantic Estimator (SEE) to compute a
semantic reward to train the App agents in generating actions aligned with the
semantics of ground truth actions, even when the syntactic forms differ. To
support the effectiveness of ASL, we theoretically demonstrate the superior
robustness of ASL for the OOD problem compared with the existing syntax
learning paradigm. Extensive experiments on offline and online smartphone App
operation benchmarks show that ASL significantly improves the accuracy and
generalisation of App agents over existing methods.

</details>


### [13] [AnyMAC: Cascading Flexible Multi-Agent Collaboration via Next-Agent Prediction](https://arxiv.org/abs/2506.17784)
*Song Wang,Zhen Tan,Zihan Chen,Shuang Zhou,Tianlong Chen,Jundong Li*

Main category: cs.AI

TL;DR: 该文提出用顺序结构替代传统图结构，实现更灵活高效的LLM多智能体通信，并通过动态角色选择和上下文访问，大幅提升了性能和通信效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体协作方法大多依赖静态或基于图的通信结构，缺乏适应性和灵活性，限制了通信表现力。作者希望提升多智能体通信的灵活性和适应性。

Method: 提出以顺序结构（而非图结构）为核心的多智能体通信框架，并包括两个关键模块：（1）Next-Agent Prediction，动态选择每一步最合适的智能体角色；（2）Next-Context Selection（NCS），让每个智能体可访问任意先前步骤的相关信息。两者共同支持角色灵活切换和全局信息流动。

Result: 该框架在多项基准任务中表现优越，能提升协作性能，同时显著减少通信开销。

Conclusion: 顺序结构和动态任务自适应的通信机制可更好发挥集体智能的潜力，为LLM多智能体协作提供了更广阔、更灵活的拓扑结构。

Abstract: Recent progress in large language model (LLM)-based multi-agent collaboration
highlights the power of structured communication in enabling collective
intelligence. However, existing methods largely rely on static or graph-based
inter-agent topologies, lacking the potential adaptability and flexibility in
communication. In this work, we propose a new framework that rethinks
multi-agent coordination through a sequential structure rather than a graph
structure, offering a significantly larger topology space for multi-agent
communication. Our method focuses on two key directions: (1) Next-Agent
Prediction, which selects the most suitable agent role at each step, and (2)
Next-Context Selection (NCS), which enables each agent to selectively access
relevant information from any previous step. Together, these components
construct task-adaptive communication pipelines that support both role
flexibility and global information flow. Extensive evaluations across multiple
benchmarks demonstrate that our approach achieves superior performance while
substantially reducing communication overhead.

</details>


### [14] [Bayesian Social Deduction with Graph-Informed Language Models](https://arxiv.org/abs/2506.17788)
*Shahab Rahimirad,Guven Gergerli,Lucia Romero,Angela Qian,Matthew Lyle Olson,Simon Stepputtis,Joseph Campbell*

Main category: cs.AI

TL;DR: 作者提出将信念推理与语言模型结合的新方法，有效提升了小模型在社交推理游戏中的表现，首次实现了AI对人类的超越，并推动了相关研究的发展。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在进行社会推理（即根据对他人有限的观察推断其隐含信念和意图）时仍面临挑战，尤其在实际应用如社交推理游戏 Avalon 中，模型虽有较好表现但存在推理效率低和泛化至小型模型能力弱的问题。

Method: 提出了一个混合推理框架，将信念推断部分外置到结构化概率模型中，而语言理解和交互依然由大型语言模型负责。

Result: 框架在 Agent-Agent 游戏中达到了与更大模型相当的性能，且首次在受控实验中击败了真人玩家，取得了67%的胜率，并在定性评价中超过了基线模型与真人队友。

Conclusion: 通过混合推理框架，有效提升了社会推理任务中小型语言模型的性能，使得模型在实际场景中具备实用性。

Abstract: Social reasoning - inferring unobservable beliefs and intentions from partial
observations of other agents - remains a challenging task for large language
models (LLMs). We evaluate the limits of current reasoning language models in
the social deduction game Avalon and find that while the largest models
demonstrate strong performance, they require extensive test-time inference and
degrade sharply when distilled to smaller, real-time-capable variants. To
address this, we introduce a hybrid reasoning framework that externalizes
belief inference to a structured probabilistic model, while using an LLM for
language understanding and interaction. Our approach achieves competitive
performance with much larger models in Agent-Agent play and, notably, is the
first language agent to defeat human players in a controlled study - achieving
a 67% win rate and receiving higher qualitative ratings than both reasoning
baselines and human teammates. We release code, models, and a dataset to
support future work on social reasoning in LLM agents, which can be found at
https://camp-lab-purdue.github.io/bayesian-social-deduction/

</details>


### [15] [Efficient Strategy Synthesis for MDPs via Hierarchical Block Decomposition](https://arxiv.org/abs/2506.17792)
*Alexandros Evangelidis,Gricel Vázquez,Simos Gerasimou*

Main category: cs.AI

TL;DR: 本文提出了一种针对大规模MDP的动态细化策略合成方法，相较于主流工具PRISM在多种案例中取得了最高2倍的性能提升，解决了现有方法难以扩展的问题，适合实际应用中的复杂决策需求。


<details>
  <summary>Details</summary>
Motivation: 现有的软件密集型系统（如软件产品线、机器人系统）通常使用马尔可夫决策过程（MDP）来建模不确定性并分析决策过程，但传统方法在大规模状态空间下难以扩展。

Method: 提出了一种动态细化MDP的方法，迭代地选择最脆弱的MDP区域进行细化，仅在必要时进行，平衡精度和效率。

Result: 通过包含多种案例和高达百万状态的大型MDP的综合实验，证明该方法与主流概率模型检测器PRISM相比性能提升显著（最高提升2倍）。

Conclusion: 新方法能大幅提升大规模MDP策略合成的效率和竞争力，适用于真实世界中的策略合成任务。

Abstract: Software-intensive systems, such as software product lines and robotics,
utilise Markov decision processes (MDPs) to capture uncertainty and analyse
sequential decision-making problems. Despite the usefulness of conventional
policy synthesis methods, they fail to scale to large state spaces. Our
approach addresses this issue and accelerates policy synthesis in large MDPs by
dynamically refining the MDP and iteratively selecting the most fragile MDP
regions for refinement. This iterative procedure offers a balance between
accuracy and efficiency, as refinement occurs only when necessary. Through a
comprehensive empirical evaluation comprising diverse case studies and MDPs up
to 1M states, we demonstrate significant performance improvements yielded by
our approach compared to the leading probabilistic model checker PRISM (up to
2x), thus offering a very competitive solution for real-world policy synthesis
tasks in larger MDPs.

</details>


### [16] [Airalogy: AI-empowered universal data digitization for research automation](https://arxiv.org/abs/2506.18586)
*Zijie Yang,Qiji Zhou,Fang Guo,Sijie Zhang,Yexun Xi,Jinglei Nie,Yudian Zhu,Liping Huang,Chou Wu,Yonghe Xia,Xiaoyu Ma,Yingming Pu,Panzhong Lu,Junshu Pan,Mingtao Chen,Tiannan Guo,Yanmei Dou,Hongyu Chen,Anping Zeng,Jiaxing Huang,Tian Xu,Yue Zhang*

Main category: cs.AI

TL;DR: 现有AI科学研究受限于数据标准化和多样性兼容问题。作者开发了Airalogy平台，首次实现多领域数据自动化、标准化录入和AI辅助，已成功在西湖大学多个实验室部署，有望促进全球科学创新自动化和高效。


<details>
  <summary>Details</summary>
Motivation: 目前AI在科学领域的应用受限于数据的标准化与数字化程度，不同行业数据碎片化、缺乏统一标准，导致跨学科AI赋能困难。现有平台未能兼顾领域多样性和数据标准化，科学家与平台开发者间存在知识鸿沟，阻碍数据标准化与AI研究进步。

Method: 提出并开发了Airalogy平台，一种兼顾通用性（满足多学科多样变化需求）与标准化（支持AI进行有效操作）的研究数据数字化平台。该平台通过可定制、标准化的数据记录描述整个科研流程，并引入AI智能助手支持智能问答、自动录入数据、分析及研究自动化。平台强调社区驱动和多学科适用性。

Result: Airalogy已在西湖大学四大学院的实验室部署，初步验证了其在多学科场景下的应用能力。平台有望在更广泛的学术和工业领域推广，促进科学创新自动化和加速。

Conclusion: 通过Airalogy平台，实现了多学科研究数据的标准化数字化与AI辅助研究，有效平衡了多样性需求与统一标准，推动科学研究数字化和AI驱动的科学创新。

Abstract: Research data are the foundation of Artificial Intelligence (AI)-driven
science, yet current AI applications remain limited to a few fields with
readily available, well-structured, digitized datasets. Achieving comprehensive
AI empowerment across multiple disciplines is still out of reach. Present-day
research data collection is often fragmented, lacking unified standards,
inefficiently managed, and difficult to share. Creating a single platform for
standardized data digitization needs to overcome the inherent challenge of
balancing between universality (supporting the diverse, ever-evolving needs of
various disciplines) and standardization (enforcing consistent formats to fully
enable AI). No existing platform accommodates both facets. Building a truly
multidisciplinary platform requires integrating scientific domain knowledge
with sophisticated computing skills. Researchers often lack the computational
expertise to design customized and standardized data recording methods, whereas
platform developers rarely grasp the intricate needs of multiple scientific
domains. These gaps impede research data standardization and hamper AI-driven
progress. In this study, we address these challenges by developing Airalogy
(https://airalogy.com), the world's first AI- and community-driven platform
that balances universality and standardization for digitizing research data
across multiple disciplines. Airalogy represents entire research workflows
using customizable, standardized data records and offers an advanced AI
research copilot for intelligent Q&A, automated data entry, analysis, and
research automation. Already deployed in laboratories across all four schools
of Westlake University, Airalogy has the potential to accelerate and automate
scientific innovation in universities, industry, and the global research
community-ultimately benefiting humanity as a whole.

</details>


### [17] [Reflective Verbal Reward Design for Pluralistic Alignment](https://arxiv.org/abs/2506.17834)
*Carter Blair,Kate Larson,Edith Law*

Main category: cs.AI

TL;DR: 论文针对现有AI对齐方法无法充分反映个体价值多样性的不足，提出基于反思对话和个性化奖励建模的新方法，实验结果显示该方法有效提升了对用户偏好的准确建模能力。


<details>
  <summary>Details</summary>
Motivation: 当前常用的人工智能对齐方案通过人类反馈强化学习(RLHF)来实现，将人类反馈进行聚合，得到单一的奖励模型用于约束AI行为，忽视了人类价值观的多样性与冲突，可能会压制少数群体的偏好。

Method: 提出了新的奖励建模方法：采用大语言模型与用户进行反思式对话，用户在对话中批判并表述自己对AI行为的偏好，将这些反思性对话历史用作另一模型的上下文，生成个性化的口头奖励模型，用其评价新行为。

Result: 在30名参与者实验中，这种方法比非反思型口头奖励模型的准确率提高了9-12%，且比传统监督学习方法更高效地利用样本。

Conclusion: 个性化奖励模型能够更好地捕捉不同用户独特的价值观，有效提升AI对个人偏好的对齐效果，并在样本利用率和准确率方面优于现有方法。

Abstract: AI agents are commonly aligned with "human values" through reinforcement
learning from human feedback (RLHF), where a single reward model is learned
from aggregated human feedback and used to align an agent's behavior. However,
human values are not homogeneous--different people hold distinct and sometimes
conflicting values. Aggregating feedback into a single reward model risks
disproportionately suppressing minority preferences. To address this, we
present a novel reward modeling approach for learning individualized reward
models. Our approach uses a language model to guide users through reflective
dialogues where they critique agent behavior and construct their preferences.
This personalized dialogue history, containing the user's reflections and
critiqued examples, is then used as context for another language model that
serves as an individualized reward function (what we call a "verbal reward
model") for evaluating new trajectories. In studies with 30 participants, our
method achieved a 9-12% improvement in accuracy over non-reflective verbal
reward models while being more sample efficient than traditional supervised
learning methods.

</details>


### [18] [Out of Control -- Why Alignment Needs Formal Control Theory (and an Alignment Control Stack)](https://arxiv.org/abs/2506.17846)
*Elija Perrier*

Main category: cs.AI

TL;DR: 本文主张以最优控制理论为基础建立分层对齐框架，提升AI对齐方法的系统性和通用性，为未来AI系统的安全和可监管部署奠定理论支撑。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全和对齐方法虽然在形式化方法上取得了进展，但在通用性和不同协议协同控制上存在局限，因此需要更系统且可推广的理论框架。

Method: 作者提出以形式最优控制理论为基础的“Alignment Control Stack”（对齐控制堆栈）框架，将AI对齐问题分层建模，从物理到社会技术层，明确各层的度量与控制特性及层间的可互操作性。

Result: 该层次化框架能系统性分析与控制先进AI模型及自主体系统，对政府和监管者提供理论保证，并助力AI技术的可持续发展和实际部署。

Conclusion: 形式最优控制理论应成为AI对齐研究的核心，可将控制理论的成熟方法与AI实际部署结合，为AI安全和可靠性提供更完整的理论与实践基础。

Abstract: This position paper argues that formal optimal control theory should be
central to AI alignment research, offering a distinct perspective from
prevailing AI safety and security approaches. While recent work in AI safety
and mechanistic interpretability has advanced formal methods for alignment,
they often fall short of the generalisation required of control frameworks for
other technologies. There is also a lack of research into how to render
different alignment/control protocols interoperable. We argue that by recasting
alignment through principles of formal optimal control and framing alignment in
terms of hierarchical stack from physical to socio-technical layers according
to which controls may be applied we can develop a better understanding of the
potential and limitations for controlling frontier models and agentic AI
systems. To this end, we introduce an Alignment Control Stack which sets out a
hierarchical layered alignment stack, identifying measurement and control
characteristics at each layer and how different layers are formally
interoperable. We argue that such analysis is also key to the assurances that
will be needed by governments and regulators in order to see AI technologies
sustainably benefit the community. Our position is that doing so will bridge
the well-established and empirically validated methods of optimal control with
practical deployment considerations to create a more comprehensive alignment
framework, enhancing how we approach safety and reliability for advanced AI
systems.

</details>


### [19] [Towards Robust Fact-Checking: A Multi-Agent System with Advanced Evidence Retrieval](https://arxiv.org/abs/2506.17878)
*Tam Trinh,Manh Nguyen,Truong-Son Hy*

Main category: cs.AI

TL;DR: 本文针对现有自动化事实核查系统处理复杂声明、保证证据可信性和核查透明性不足的问题，设计了四个功能明确的代理组成的多代理核查系统，经实验证明该方法在主流基准数据集上显著优于基线模型，并具备更强的准确性、效率与解释能力。


<details>
  <summary>Details</summary>
Motivation: 随着数字时代虚假信息的快速传播，传统人工事实核查方法已难以应对大量和高速增长的网络内容，因此有必要开发高效、可扩展的自动化事实核查系统。

Method: 本文提出了一种新颖的多代理系统进行自动化事实核查，包含输入分解代理、查询生成代理、证据检索代理和判决预测代理，分别负责把复杂声明拆分、生成针对性子查询、检索可信证据并输出带可解释性的核查结论。系统在多个基准数据集上进行了评测。

Result: 在FEVEROUS、HOVER、SciFact等基准数据集上，该系统的Macro F1得分较基线方法提升了12.3%，在分解复杂声明、检索可信证据以及给出透明解释等方面效果突出。

Conclusion: 提出的多代理自动事实核查系统提升了准确性、效率和可解释性，能够更好地贴合人工核查流程且具备现实应用的可扩展性。

Abstract: The rapid spread of misinformation in the digital era poses significant
challenges to public discourse, necessitating robust and scalable fact-checking
solutions. Traditional human-led fact-checking methods, while credible,
struggle with the volume and velocity of online content, prompting the
integration of automated systems powered by Large Language Models (LLMs).
However, existing automated approaches often face limitations, such as handling
complex claims, ensuring source credibility, and maintaining transparency. This
paper proposes a novel multi-agent system for automated fact-checking that
enhances accuracy, efficiency, and explainability. The system comprises four
specialized agents: an Input Ingestion Agent for claim decomposition, a Query
Generation Agent for formulating targeted subqueries, an Evidence Retrieval
Agent for sourcing credible evidence, and a Verdict Prediction Agent for
synthesizing veracity judgments with human-interpretable explanations.
Evaluated on benchmark datasets (FEVEROUS, HOVER, SciFact), the proposed system
achieves a 12.3% improvement in Macro F1-score over baseline methods. The
system effectively decomposes complex claims, retrieves reliable evidence from
trusted sources, and generates transparent explanations for verification
decisions. Our approach contributes to the growing field of automated
fact-checking by providing a more accurate, efficient, and transparent
verification methodology that aligns with human fact-checking practices while
maintaining scalability for real-world applications. Our source code is
available at https://github.com/HySonLab/FactAgent

</details>


### [20] [Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms](https://arxiv.org/abs/2506.17900)
*Cheng Ji,Huaiying Luo*

Main category: cs.AI

TL;DR: 该论文提出了一种基于大语言模型的云平台日志智能分析与自动调试方法，通过多阶段语义推理和强化学习决策机制，有效提升了故障定位与修复能力，实验表明准确率提升16.2%。


<details>
  <summary>Details</summary>
Motivation: 云平台AI系统复杂度和规模不断提升，导致系统运行日志巨大且无结构、语义模糊，传统故障定位与自愈面临挑战，急需智能化、自动化的新方法提升效率与准确性。

Method: 提出基于大语言模型（LLM）的智能日志处理与自动调试框架（LLM-ID）。方法包括：（1）在预训练Transformer模型基础上扩展，融入多阶段语义推理机制，实现日志上下文理解与故障链自动重建；（2）动态结构化系统日志，通过无监督聚类和嵌入机制提取事件模板和语义模式；（3）微调的LLM结合多轮注意力机制，对日志序列进行上下文推理，生成潜在故障假设和根因路径；（4）引入基于强化学习的策略引导恢复规划，依据LLM生成的修复策略，支持动态决策与自适应调试。

Result: 在云平台日志数据集上实验，LLM-ID模型的故障定位准确率提升16.2%，显著优于主流传统方法。具备更强语义理解、持续学习及异构环境适应力。

Conclusion: 基于LLM的日志智能分析与自动调试框架LLM-ID，在云环境下极大提升了故障定位的效率和准确率，为大规模AI系统运维智能化提供了创新思路和有效手段。

Abstract: With the increasing complexity and rapid expansion of the scale of AI systems
in cloud platforms, the log data generated during system operation is massive,
unstructured, and semantically ambiguous, which brings great challenges to
fault location and system self-repair. In order to solve this problem, this
paper proposes an intelligent log processing and automatic debugging framework
based on Large Language Model (LLM), named Intelligent Debugger (LLM-ID). This
method is extended on the basis of the existing pre-trained Transformer model,
and integrates a multi-stage semantic inference mechanism to realize the
context understanding of system logs and the automatic reconstruction of fault
chains. Firstly, the system log is dynamically structured, and the unsupervised
clustering and embedding mechanism is used to extract the event template and
semantic schema. Subsequently, the fine-tuned LLM combined with the multi-round
attention mechanism to perform contextual reasoning on the log sequence to
generate potential fault assumptions and root cause paths. Furthermore, this
paper introduces a reinforcement learning-based policy-guided recovery planner,
which is driven by the remediation strategy generated by LLM to support dynamic
decision-making and adaptive debugging in the cloud environment. Compared with
the existing rule engine or traditional log analysis system, the proposed model
has stronger semantic understanding ability, continuous learning ability and
heterogeneous environment adaptability. Experiments on the cloud platform log
dataset show that LLM-ID improves the fault location accuracy by 16.2%, which
is significantly better than the current mainstream methods

</details>


### [21] [Learning, Reasoning, Refinement: A Framework for Kahneman's Dual-System Intelligence in GUI Agents](https://arxiv.org/abs/2506.17913)
*Jinjie Wei,Jiyao Liu,Lihao Liu,Ming Hu,Junzhi Ning,Mingcheng Li,Weijie Yin,Junjun He,Xiao Liang,Chao Feng,Dingkang Yang*

Main category: cs.AI

TL;DR: 本文提出 CogniGUI，创新性地融合分层视觉解析和基于奖励的高效交互决策，实现了类人化的 GUI 任务自动学习。新基准 ScreenSeek 下，其表现优于现有技术，具备很强的泛化和适应性优势。


<details>
  <summary>Details</summary>
Motivation: 现有的图形用户界面（GUI）智能体系统主要依赖尝试-错误型决策，缺乏进阶推理能力和从交互中学习适应的能力。此外，评价指标多为简单的单步准确率，无法全面反映真实 GUI 交互的复杂性。

Method: 提出了 CogniGUI，一个受 Kahneman 的双系统理论启发的认知架构。该方法包括两大核心：1) 全能解析器引擎，能快速分层解析 GUI 元素以识别可操作组件；2) 基于群体的相对策略优化（GRPO）智能体，采用相对奖励机制评估多条交互路径，促进高效操作。该双系统支持智能体通过“探索-学习-精通”循环不断提升策略。此外，构建了新的评测基准 ScreenSeek，涵盖多应用导航、动态状态切换和跨界面协同等挑战。

Result: 实验结果显示，CogniGUI 无论在现有 GUI 基准还是新提出的 ScreenSeek 基准上，性能均超过当前最先进方法。

Conclusion: CogniGUI 能实现更接近人类行为的自适应 GUI 自动化学习，并在更具挑战性的评测中展现出优异的泛化与适应能力。

Abstract: Graphical User Interface (GUI) agents have made significant progress in
automating digital tasks through the utilization of computer vision and
language models. Nevertheless, existing agent systems encounter notable
limitations. Firstly, they predominantly depend on trial and error decision
making rather than progressive reasoning, thereby lacking the capability to
learn and adapt from interactive encounters. Secondly, these systems are
assessed using overly simplistic single step accuracy metrics, which do not
adequately reflect the intricate nature of real world GUI interactions. In this
paper, we present CogniGUI, a cognitive framework developed to overcome these
limitations by enabling adaptive learning for GUI automation resembling
human-like behavior. Inspired by Kahneman's Dual Process Theory, our approach
combines two main components: (1) an omni parser engine that conducts immediate
hierarchical parsing of GUI elements through quick visual semantic analysis to
identify actionable components, and (2) a Group based Relative Policy
Optimization (GRPO) grounding agent that assesses multiple interaction paths
using a unique relative reward system, promoting minimal and efficient
operational routes. This dual-system design facilitates iterative ''exploration
learning mastery'' cycles, enabling the agent to enhance its strategies over
time based on accumulated experience. Moreover, to assess the generalization
and adaptability of agent systems, we introduce ScreenSeek, a comprehensive
benchmark that includes multi application navigation, dynamic state
transitions, and cross interface coherence, which are often overlooked
challenges in current benchmarks. Experimental results demonstrate that
CogniGUI surpasses state-of-the-art methods in both the current GUI grounding
benchmarks and our newly proposed benchmark.

</details>


### [22] [Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective](https://arxiv.org/abs/2506.17930)
*Jianyu Wang,Zhiqiang Hu,Lidong Bing*

Main category: cs.AI

TL;DR: 本文挑战了传统的LLM prompt设计理念，发现将示例剪枝为“乱码”能够提升模型表现。作者提出PromptQuine自动进化搜索框架，不依赖人工经验，系统性地找到高效prompt。实验在多种任务和模型上效果领先。该成果为理解和优化ICL机制提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）中，传统的prompt设计倾向于精心编写的指令和示例以提升模型表现，但这套方法依然存在优化空间。作者发现，现有的自动prompt优化技术虽然有效，但仍未挖掘出prompt设计的全部潜力，因此希望挑战传统观念，探索更高效的prompt设计方式。

Method: 作者提出了一种名为PromptQuine的全新演化搜索框架，不依赖于人工设计或现有归因/压缩方法，而是让系统自我进化，自动搜索最佳的随机示例剪枝策略，在仅有少量数据的情况下，通过保留原始上下文中的词元，演化出表现优秀但看似无序的prompt。

Result: 实验证明，该方法在分类、多选问答、生成、数学推理等任务以及不同LLM模型上均取得了优异成绩，效果优于或匹配当前最先进的自动prompt优化技术，并具备良好的运行效率。

Conclusion: 设计出连贯且逻辑清晰的prompt并非获得最佳LLM性能的必要条件。通过进化式搜索实现的“无序”prompt能显著提升LLM任务表现，对现有prompt设计理念提出了新的挑战和指导意义。

Abstract: We propose a novel prompt design paradigm that challenges conventional wisdom
in large language model (LLM) prompting. While conventional wisdom prioritizes
well-crafted instructions and demonstrations for in-context learning (ICL), we
show that pruning random demonstrations into seemingly incoherent "gibberish"
can remarkably improve performance across diverse tasks. Notably, the
"gibberish" always matches or surpasses state-of-the-art automatic prompt
optimization techniques, achieving substantial gains regardless of LLM
alignment. Nevertheless, discovering an effective pruning strategy is
non-trivial, as existing attribution methods and prompt compression algorithms
fail to deliver robust results, let alone human intuition. In terms of this, we
propose a self-discover prompt optimization framework, PromptQuine, an
evolutionary search framework that automatically searches for the pruning
strategy by itself using only low-data regimes. Much like the emergent
complexity in nature--such as symbiosis and self-organization--arising in
response to resource constraints, our framework evolves and refines
unconventional yet highly effective prompts by leveraging only the tokens
present within the context. We demonstrate its effectiveness across
classification, multi-choice question answering, generation and math reasoning
tasks across LLMs, while achieving decent runtime efficiency. We hope our
findings can guide mechanistic studies on in-context learning, and provide a
call to action, to pave the way for more open-ended search algorithms for more
effective LLM prompting.

</details>


### [23] [medicX-KG: A Knowledge Graph for Pharmacists' Drug Information Needs](https://arxiv.org/abs/2506.17959)
*Lizzy Farrugia,Lilian M. Azzopardi,Jeremy Debattista,Charlie Abela*

Main category: cs.AI

TL;DR: 本文提出了面向药剂师的medicX-KG知识图谱，整合多源药品信息，支持药师高效查询及决策。实践表明其能优化药品管理和服务，减少信息碎片化，但仍需提升数据细节和更新能力。


<details>
  <summary>Details</summary>
Motivation: 药剂师的角色正在从单纯的药品分发转向多学科医疗团队中的综合药学服务，亟需集成、准确的药品信息以支持临床与监管决策。然而，目前面临药品信息分散、缺少统一国家药品资料库等问题，限制了药剂师的数据驱动决策能力。

Method: 本研究提出并构建了medicX-KG知识图谱，作为药剂师决策支持工具，并集成了英国国家处方集（BNF）、DrugBank与马耳他药品管理局（MMA）等三方数据。整个设计过程通过与一线药剂师访谈获取真实需求，并介绍了数据抽取、本体设计以及语义映射等知识图谱构建流程。

Result: medicX-KG知识图谱能够有效支持相关药品的查询，包括药物可得性、药物相互作用、不良反应及治疗类别等关键问题，显著减少了药剂师对零散信息源的依赖。

Conclusion: medicX-KG为药剂师提供了统一和可解释的药品知识语义层，有效提升了其临床和监管决策能力。虽然当前版本存在剂量细节编码及实时更新等局限，但为未来进一步完善奠定了基础。

Abstract: The role of pharmacists is evolving from medicine dispensing to delivering
comprehensive pharmaceutical services within multidisciplinary healthcare
teams. Central to this shift is access to accurate, up-to-date medicinal
product information supported by robust data integration. Leveraging artificial
intelligence and semantic technologies, Knowledge Graphs (KGs) uncover hidden
relationships and enable data-driven decision-making. This paper presents
medicX-KG, a pharmacist-oriented knowledge graph supporting clinical and
regulatory decisions. It forms the semantic layer of the broader medicX
platform, powering predictive and explainable pharmacy services. medicX-KG
integrates data from three sources, including, the British National Formulary
(BNF), DrugBank, and the Malta Medicines Authority (MMA) that addresses Malta's
regulatory landscape and combines European Medicines Agency alignment with
partial UK supply dependence. The KG tackles the absence of a unified national
drug repository, reducing pharmacists' reliance on fragmented sources. Its
design was informed by interviews with practicing pharmacists to ensure
real-world applicability. We detail the KG's construction, including data
extraction, ontology design, and semantic mapping. Evaluation demonstrates that
medicX-KG effectively supports queries about drug availability, interactions,
adverse reactions, and therapeutic classes. Limitations, including missing
detailed dosage encoding and real-time updates, are discussed alongside
directions for future enhancements.

</details>


### [24] [Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities](https://arxiv.org/abs/2506.18019)
*Yuanchen Bei,Weizhi Zhang,Siwen Wang,Weizhi Chen,Sheng Zhou,Hao Chen,Yong Li,Jiajun Bu,Shirui Pan,Yizhou Yu,Irwin King,Fakhri Karray,Philip S. Yu*

Main category: cs.AI

TL;DR: 本文为人工智能智能体与图结构结合领域的首个系统综述，揭示了图的结构化优势如何解决智能体在真实复杂任务中面临的信息、计划与协作等难题，指出了未来发展方向，并提供了相关研究资源。


<details>
  <summary>Details</summary>
Motivation: 随着AI智能体从传统强化学习方法到融合大语言模型（LLM），其能力显著增强。但在面对复杂真实世界任务时，如有效计划与执行、稳定记忆维护和多智能体协作，当前方法还存在挑战。尤其在处理海量复杂信息和交互时亟需新的数据结构化手段。

Method: 本综述系统梳理了图数据结构在增强AI智能体核心能力（如规划、记忆、协作等）中的作用，分析了图技术与智能体深度结合的现有应用及潜力，并归纳未来研究方向。文章还收集并持续更新相关资源，以便学术社区参考。

Result: 文章首次系统性评估了图技术赋能AI智能体的多种路径和实际应用案例，阐述了图结构如何助力智能体更高效地理解和处理复杂数据关系，支撑其应对高级任务。

Conclusion: 通过梳理与分析，本文明确了图结构作为数据结构化利器，对智能体能力提升的重要作用，并为后续研究提供了清晰、前沿的研究线索和资源。

Abstract: AI agents have experienced a paradigm shift, from early dominance by
reinforcement learning (RL) to the rise of agents powered by large language
models (LLMs), and now further advancing towards a synergistic fusion of RL and
LLM capabilities. This progression has endowed AI agents with increasingly
strong abilities. Despite these advances, to accomplish complex real-world
tasks, agents are required to plan and execute effectively, maintain reliable
memory, and coordinate smoothly with other agents. Achieving these capabilities
involves contending with ever-present intricate information, operations, and
interactions. In light of this challenge, data structurization can play a
promising role by transforming intricate and disorganized data into
well-structured forms that agents can more effectively understand and process.
In this context, graphs, with their natural advantage in organizing, managing,
and harnessing intricate data relationships, present a powerful data paradigm
for structurization to support the capabilities demanded by advanced AI agents.
To this end, this survey presents a first systematic review of how graphs can
empower AI agents. Specifically, we explore the integration of graph techniques
with core agent functionalities, highlight notable applications, and identify
prospective avenues for future research. By comprehensively surveying this
burgeoning intersection, we hope to inspire the development of next-generation
AI agents equipped to tackle increasingly sophisticated challenges with graphs.
Related resources are collected and continuously updated for the community in
the Github link.

</details>


### [25] [Action Language BC+](https://arxiv.org/abs/2506.18044)
*Joseph Babb,Joohyung Lee*

Main category: cs.AI

TL;DR: 本文提出了新动作语言BC+，将现代ASP语言的强大特性与动作语言融合，弥补原有表达不足。BC+兼容旧有动作语言优点，可借助ASP技术直接求解，并已获得实现。


<details>
  <summary>Details</summary>
Motivation: 现有的动作语言形式（如B、C、C+、BC）在与现代ASP语言（Answer Set Programming）对接时存在表达能力上的差距，ASP中的新特性如选择规则、聚合和抽象约束原子等尚未被旧的动作语言充分集成。作者希望设计一种新动作语言，能更好地利用ASP的知识表示能力。

Method: 提出了一种新的动作语言BC+，其语义通过对命题公式的一般稳定模型语义进行定义，使得现代ASP语言中的诸多功能特性都可与命题公式中的简写对应。此外，BC+通过扩展cplus2asp系统进行了实际实现。

Result: BC+语言足够表达性强，可以涵盖其它动作语言（如B、C、C+、BC）的最佳特性，并能自如利用ASP求解器的计算能力，成功实现了将动作语言与现代ASP紧密结合。

Conclusion: BC+有效填补了动作语言和现代ASP语言之间的功能和表达鸿沟，使得复杂知识和动态系统的描述、推理更加自然、便利和高效。

Abstract: Action languages are formal models of parts of natural language that are
designed to describe effects of actions. Many of these languages can be viewed
as high level notations of answer set programs structured to represent
transition systems. However, the form of answer set programs considered in the
earlier work is quite limited in comparison with the modern Answer Set
Programming (ASP) language, which allows several useful constructs for
knowledge representation, such as choice rules, aggregates, and abstract
constraint atoms. We propose a new action language called BC+, which closes the
gap between action languages and the modern ASP language. The main idea is to
define the semantics of BC+ in terms of general stable model semantics for
propositional formulas, under which many modern ASP language constructs can be
identified with shorthands for propositional formulas. Language BC+ turns out
to be sufficiently expressive to encompass the best features of other action
languages, such as languages B, C, C+, and BC. Computational methods available
in ASP solvers are readily applicable to compute BC+, which led to an
implementation of the language by extending system cplus2asp.

</details>


### [26] [Weighted Assumption Based Argumentation to reason about ethical principles and actions](https://arxiv.org/abs/2506.18056)
*Paolo Baldi,Fabio Aurelio D'Asaro,Abeer Dyoub,Francesca Alessandra Lisi*

Main category: cs.AI

TL;DR: 本文提出为假设基础论证（ABA）系统引入权重机制，通过具体案例展示其在道德推理中的应用，并给出基于ASP的实现。


<details>
  <summary>Details</summary>
Motivation: 传统基于假设的论证（ABA）系统未考虑不同论据的重要性或可信度，存在论据之间影响力难以衡量的问题。

Method: 在ABA系统中为每个论据分配权重，并通过推导得出论据之间攻击的权重。通过道德推理领域的示例进行说明，并基于Answer Set Programming实现了该系统。

Result: 展示了在具有权重的ABA系统中，如何通过示例实现权重分配与攻击权重推导。同时，开发了实际运行的实现系统。

Conclusion: 将权重机制融入ABA后，可以更细致地刻画论证过程，增强了系统对于论据影响力和攻击效果的表达能力。

Abstract: We augment Assumption Based Argumentation (ABA for short) with weighted
argumentation. In a nutshell, we assign weights to arguments and then derive
the weight of attacks between ABA arguments. We illustrate our proposal through
running examples in the field of ethical reasoning, and present an
implementation based on Answer Set Programming.

</details>


### [27] [Deep Research Agents: A Systematic Examination And Roadmap](https://arxiv.org/abs/2506.18096)
*Yuxuan Huang,Yihang Chen,Haozheng Zhang,Kang Li,Meng Fang,Linyi Yang,Xiaoguang Li,Lifeng Shang,Songcen Xu,Jianye Hao,Kun Shao,Jun Wang*

Main category: cs.AI

TL;DR: 本文全面分析了Deep Research agents的发展现状，从技术、架构、评测指标等多方面进行系统分类和梳理，发现当前主要限制并提出了未来研究方向，同时开放了持续更新的研究资料库。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的飞速发展，涌现出了能够自主进行复杂多轮研究任务的智能体（Deep Research agents, DR agents），但相关关键技术及其架构尚缺乏系统分析和梳理。

Method: 系统分析DR agents的基础技术与模块化架构，包括信息获取方式（API检索 vs. 浏览器探索）、工具使用框架、多模态输入处理、上下文协议（MCPs）等。提出用于分类现有方法的分类法（静态与动态流程、单/多agent等），并对现有基准评测和瓶颈进行批判性综述。

Result: 提出了一套DR agents的系统分类法，总结和归纳了其架构要素，并分析了当前评测基准的局限性和未来研究方向，最后开放了相关研究资源库。

Conclusion: 本文系统化梳理了DR agents的关键技术与架构，明确其发展现状与挑战，并为未来研究和实际应用提供了路线图和参考库。

Abstract: The rapid progress of Large Language Models (LLMs) has given rise to a new
category of autonomous AI systems, referred to as Deep Research (DR) agents.
These agents are designed to tackle complex, multi-turn informational research
tasks by leveraging a combination of dynamic reasoning, adaptive long-horizon
planning, multi-hop information retrieval, iterative tool use, and the
generation of structured analytical reports. In this paper, we conduct a
detailed analysis of the foundational technologies and architectural components
that constitute Deep Research agents. We begin by reviewing information
acquisition strategies, contrasting API-based retrieval methods with
browser-based exploration. We then examine modular tool-use frameworks,
including code execution, multimodal input processing, and the integration of
Model Context Protocols (MCPs) to support extensibility and ecosystem
development. To systematize existing approaches, we propose a taxonomy that
differentiates between static and dynamic workflows, and we classify agent
architectures based on planning strategies and agent composition, including
single-agent and multi-agent configurations. We also provide a critical
evaluation of current benchmarks, highlighting key limitations such as
restricted access to external knowledge, sequential execution inefficiencies,
and misalignment between evaluation metrics and the practical objectives of DR
agents. Finally, we outline open challenges and promising directions for future
research. A curated and continuously updated repository of DR agent research is
available at: {https://github.com/ai-agents-2030/awesome-deep-research-agent}.

</details>


### [28] [Decentralized Consensus Inference-based Hierarchical Reinforcement Learning for Multi-Constrained UAV Pursuit-Evasion Game](https://arxiv.org/abs/2506.18126)
*Xiang Yuming,Li Sizhao,Li Rongpeng,Zhao Zhifeng,Zhang Honggang*

Main category: cs.AI

TL;DR: 本文针对通信受限环境下无人机多智能体协同追逃和编队覆盖任务，提出了一种分层强化学习新架构CI-HRL，结合了共识机制和分层控制，实验证明显著提升了协同能力与任务完成效率。


<details>
  <summary>Details</summary>
Motivation: 多旋翼无人机（UAV）系统在多约束追逃博弈（MC-PEG）中的广泛应用和研究激发出了诸如协同规避与编队覆盖（CEFC）等复杂任务需求，而在通信受限情况下，该问题兼具障碍物规避、对抗、目标区覆盖和队形管理等多重高维困难。现有方法对高维度环境中多目标的高效解决能力有限，因此需要提出更有效的协同控制框架。

Method: 提出了分层强化学习框架Consensus Inference-based Hierarchical Reinforcement Learning（CI-HRL），通过高层策略模块定位目标区，低层策略模块实现障碍规避、导航与队形控制。高层政策引入了基于共识的多智能体消息聚合与决策机制（ConsMAC），提升本地信息汇总为全局共识的能力。低层采用交替训练的多智能体近端策略优化及策略蒸馏，提升智能体低级协作效率。

Result: 软件仿真及高保真度SITL（Software-In-The-Loop）实验证明，CI-HRL框架能够显著提升无人机群体的协同规避与多任务完成能力。

Conclusion: 该研究提出的CI-HRL框架可高效应对多约束追逃博弈中的复杂协同任务，尤其适用于通信受限条件下的大规模无人机群体协作，为实际应用提供了理论与工程基础。

Abstract: Multiple quadrotor unmanned aerial vehicle (UAV) systems have garnered
widespread research interest and fostered tremendous interesting applications,
especially in multi-constrained pursuit-evasion games (MC-PEG). The Cooperative
Evasion and Formation Coverage (CEFC) task, where the UAV swarm aims to
maximize formation coverage across multiple target zones while collaboratively
evading predators, belongs to one of the most challenging issues in MC-PEG,
especially under communication-limited constraints. This multifaceted problem,
which intertwines responses to obstacles, adversaries, target zones, and
formation dynamics, brings up significant high-dimensional complications in
locating a solution. In this paper, we propose a novel two-level framework
(i.e., Consensus Inference-based Hierarchical Reinforcement Learning (CI-HRL)),
which delegates target localization to a high-level policy, while adopting a
low-level policy to manage obstacle avoidance, navigation, and formation.
Specifically, in the high-level policy, we develop a novel multi-agent
reinforcement learning module, Consensus-oriented Multi-Agent Communication
(ConsMAC), to enable agents to perceive global information and establish
consensus from local states by effectively aggregating neighbor messages.
Meanwhile, we leverage an Alternative Training-based Multi-agent proximal
policy optimization (AT-M) and policy distillation to accomplish the low-level
control. The experimental results, including the high-fidelity
software-in-the-loop (SITL) simulations, validate that CI-HRL provides a
superior solution with enhanced swarm's collaborative evasion and task
completion capabilities.

</details>


### [29] [SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging](https://arxiv.org/abs/2506.18135)
*Zijun Chen,Zhanpeng Zhou,Bo Zhang,Weinan Zhang,Xi Sun,Junchi Yan*

Main category: cs.AI

TL;DR: 本文分析了模型合并的机制，提出无需额外训练即可显著提升多任务性能的动态合并新方法SE-Merging，并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管模型合并在多任务能力上有实证成功，但其机制尚不清晰，特别是其如何实现多任务适应。本文旨在剖析模型合并机制并提升其性能。

Method: 作者从表示学习角度分析模型合并机制，揭示模型合并通过“区分任务样本”和“适应对应专家模型”获得多任务能力，并基于此提出SE-Merging框架，通过动态调整合并系数增强合并模型的任务特定能力。

Result: SE-Merging无需额外训练即可实现动态模型合并，且与现有合并方法兼容，在多项实验中表现出显著性能提升。

Conclusion: SE-Merging能够依据输入样本动态识别任务，并自适应调整合并系数，在不需额外训练的情况下，进一步提升任务专长能力，对现有模型合并方法有显著性能提升。

Abstract: Model merging has gained increasing attention due to its intriguing property:
interpolating the parameters of different task-specific fine-tuned models leads
to multi-task abilities. However, despite its empirical success, the underlying
mechanisms of model merging remain poorly understood. In this work, we delve
into the mechanism behind model merging from a representation perspective. Our
analysis reveals that model merging achieves multi-task abilities through two
key capabilities: i) distinguishing samples from different tasks, and ii)
adapting to the corresponding expert model for each sample. These two
capabilities allow the merged model to retain task-specific expertise, enabling
efficient multi-task adaptation. Building on these insights, we propose
\texttt{SE-Merging}, a self-enhanced model merging framework that leverages
these two characteristics to dynamically identify the corresponding task for
each sample and then adaptively rescales the merging coefficients to further
enhance task-specific expertise in the merged model. Notably,
\texttt{SE-Merging} achieves dynamic model merging without additional training.
Extensive experiments demonstrate that \texttt{SE-Merging} achieves significant
performance improvements while remaining compatible with existing model merging
techniques.

</details>


### [30] [CoachGPT: A Scaffolding-based Academic Writing Assistant](https://arxiv.org/abs/2506.18149)
*Fumian Chen,Sotheara Veng,Joshua Wilson,Xiaoming Li,Hui Fang*

Main category: cs.AI

TL;DR: 本文提出一个基于大语言模型的写作辅助系统CoachGPT，采用教育专家指导与实时反馈机制，提升个性化与教学性。用户研究证实其对学术写作的显著帮助，展示LLM在写作教育应用的潜力。


<details>
  <summary>Details</summary>
Motivation: 学术写作能力对学生至关重要，尤其是第二语言写作时，缺乏指导和实践会让学生感到压力。传统写作辅助工具存在理解力不足和有限的教育功能。随着大语言模型（LLMs）的发展，出现了生成内容但不注重教学的问题，容易影响学生学习。论文旨在解决现有工具的局限性，提升写作辅助的教育性和个性化。

Method: 作者开发了CoachGPT，一个基于大语言模型的AI写作辅助平台。CoachGPT通过接收教育专家的指导，将指导转化为具体子任务，并借助LLM为用户提供实时反馈和建议。这一结构增加了写作过程的互动性和教育性。

Result: CoachGPT能够为学习资源有限或偏好自学的学生提供更沉浸式、个性化的学术写作支持。用户研究表明，CoachGPT使用体验良好，验证了其有效性，以及LLM在学术写作辅助领域的潜力。

Conclusion: CoachGPT通过创新的结构和实时个性化反馈，克服了现有写作助手一味生成内容、不重视教学的缺陷，为提升学术写作教学和自主学习提供了新途径。其框架和研究展示了大语言模型在教育领域应用的巨大前景。

Abstract: Academic writing skills are crucial for students' success, but can feel
overwhelming without proper guidance and practice, particularly when writing in
a second language. Traditionally, students ask instructors or search
dictionaries, which are not universally accessible. Early writing assistants
emerged as rule-based systems that focused on detecting misspellings,
subject-verb disagreements, and basic punctuation errors; however, they are
inaccurate and lack contextual understanding. Machine learning-based assistants
demonstrate a strong ability for language understanding but are expensive to
train. Large language models (LLMs) have shown remarkable capabilities in
generating responses in natural languages based on given prompts. Still, they
have a fundamental limitation in education: they generate essays without
teaching, which can have detrimental effects on learning when misused. To
address this limitation, we develop CoachGPT, which leverages large language
models (LLMs) to assist individuals with limited educational resources and
those who prefer self-paced learning in academic writing. CoachGPT is an AI
agent-based web application that (1) takes instructions from experienced
educators, (2) converts instructions into sub-tasks, and (3) provides real-time
feedback and suggestions using large language models. This unique scaffolding
structure makes CoachGPT unique among existing writing assistants. Compared to
existing writing assistants, CoachGPT provides a more immersive writing
experience with personalized feedback and guidance. Our user studies prove the
usefulness of CoachGPT and the potential of large language models for academic
writing.

</details>


### [31] [AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology](https://arxiv.org/abs/2506.18156)
*Akash Kundu,Rishika Goswami*

Main category: cs.AI

TL;DR: 本文发现大语言模型在多种心理学测试下表现出部分类人认知特征，这为AI伦理、透明性及认知心理学结合AI安全研究提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型（LLMs）是否表现出类似人类的认知模式，这对于理解AI智能和提升其安全性与伦理性有重要意义。

Method: 采用四种心理学框架（主题统觉测验TAT、框架偏见、道德基础理论MFT、认知失调），通过结构化提示和自动评分评估多个专有与开源大模型的表现。

Result: 模型表现为能够生成连贯叙事、易受到积极表述影响、道德判断偏向自由/压迫维度，并在自相矛盾时进行较多合理化，这些行为在一定程度上反映了人类认知倾向，但受其训练数据和对齐方式影响。

Conclusion: LLM部分展现了类似人类的认知模式，结果受到训练与对齐机制影响。作者认为应在AI透明度、伦理与心理学结合AI安全等方向进一步讨论和研究。

Abstract: We investigate whether Large Language Models (LLMs) exhibit human-like
cognitive patterns under four established frameworks from psychology: Thematic
Apperception Test (TAT), Framing Bias, Moral Foundations Theory (MFT), and
Cognitive Dissonance. We evaluated several proprietary and open-source models
using structured prompts and automated scoring. Our findings reveal that these
models often produce coherent narratives, show susceptibility to positive
framing, exhibit moral judgments aligned with Liberty/Oppression concerns, and
demonstrate self-contradictions tempered by extensive rationalization. Such
behaviors mirror human cognitive tendencies yet are shaped by their training
data and alignment methods. We discuss the implications for AI transparency,
ethical deployment, and future work that bridges cognitive psychology and AI
safety

</details>


### [32] [Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation](https://arxiv.org/abs/2506.18158)
*Xinzge Gao,Chuanrui Hu,Bin Chen,Teng Li*

Main category: cs.AI

TL;DR: 该文提出Chain-of-Memory（CoM）机制，用于显式存储和管理GUI任务关键信息，显著提升多模态大模型在复杂跨应用任务中的表现，并开源大规模标注数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大模型（MLLM）在图形用户界面（GUI）智能体开发中，往往只依赖历史截图或动作，导致难以准确理解复杂或跨应用任务的状态，同时缺乏高效的信息存储机制。

Method: 提出了一种新的方法Chain-of-Memory（CoM），明确地为GUI智能体建模短期和长期记忆模块，结合动作描述和与任务相关的屏幕信息，通过独立的记忆模块存储和管理关键信息。开发了GUI Odyssey-CoM数据集（包含11.1万对屏幕-动作样本，带记忆标注），用于训练和评估该方法。

Result: 实验表明，CoM方法能显著提升GUI智能体在跨应用任务中的表现。此外，GUI Odyssey-CoM数据集能让7B规模模型表现出与72B模型相近的记忆管理能力。

Conclusion: 引入显式记忆建模机制后，GUI智能体在复杂场景中的任务理解和历史信息保留能力大大提升。公开数据集和代码有助于后续研究。

Abstract: Multimodal large language models (MLLMs) are attracting growing attention in
the development of Graphical User Interface (GUI) agents. Existing approaches
often rely on historical screenshots or actions to implicitly represent the
task state. This reliance poses challenges for GUI agents in accurately
understanding task states and underscores the absence of effective mechanisms
to store critical information in complex and lengthy cross-app tasks. To
address these challenges, we propose Chain-of-Memory (CoM), a novel approach
for explicitly modeling short-term and long-term memory in GUI agents. CoM
achieves this by capturing action descriptions, integrating task-relevant
screen information, and maintaining a dedicated memory module to store and
manage this information. By leveraging explicit memory representations, CoM
enables GUI agents to better understand task states and retain critical
historical information persistently. To equip GUI agents with memory management
capabilities and evaluate the effectiveness of CoM, we developed the GUI
Odyssey-CoM, a dataset comprising 111k screen-action pairs annotated with
Chain-of-Memory. Experimental results demonstrate that CoM significantly
improves GUI agents' performance in cross-application tasks. Additionally, GUI
Odyssey-CoM enables 7B models to achieve memory management capabilities
comparable to 72B models. The dataset and code will be open-sourced.

</details>


### [33] [Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?](https://arxiv.org/abs/2506.18183)
*Zhiting Mei,Christina Zhang,Tenny Yin,Justin Lidard,Ola Shorinwa,Anirudha Majumdar*

Main category: cs.AI

TL;DR: 推理大模型虽然成绩突出，但常常对错误答案表现出过度自信，通过让模型自省其推理过程，可在部分情况下改善置信度校准，但该方法并不适用于所有模型。未来需专注于更合理的校准算法与评价基准的设计。


<details>
  <summary>Details</summary>
Motivation: 推理语言模型虽然在多个高难度基准测试上刷新了成绩，但其输出依旧存在自信但错误的情况（幻觉），因此在实际部署时如何衡量与信任这些模型成为关键。本文关注推理模型不确定性量化这一现实需求。

Method: 本文主要提出并评估了自省式不确定性量化（UQ）方法，并围绕推理模型校准展开三方面探索：模型校准现状、推理深度与模型校准关系，及通过反思自身推理过程提升置信度评估。实验评估涵盖多种主流推理模型与多项基准任务。

Result: 实验证明：1）推理模型普遍过于自信，尤其是在错误回答时，置信度常高于85%；2）推理深度加大时，过度自信现象更突出；3）部分模型（如o3-Mini和DeepSeek R1）通过自省性链式推理可改善校准，但也有模型（如Claude 3.7 Sonnet）表现更差。

Conclusion: 当前推理模型存在严重的过度自信问题，校准能力有限。自省式推理可提升部分模型的校准效果，但效果并非普适。未来应设计更完善的不确定性量化基准，并进一步提升推理模型的置信度评估能力。

Abstract: Reasoning language models have set state-of-the-art (SOTA) records on many
challenging benchmarks, enabled by multi-step reasoning induced using
reinforcement learning. However, like previous language models, reasoning
models are prone to generating confident, plausible responses that are
incorrect (hallucinations). Knowing when and how much to trust these models is
critical to the safe deployment of reasoning models in real-world applications.
To this end, we explore uncertainty quantification of reasoning models in this
work. Specifically, we ask three fundamental questions: First, are reasoning
models well-calibrated? Second, does deeper reasoning improve model
calibration? Finally, inspired by humans' innate ability to double-check their
thought processes to verify the validity of their answers and their confidence,
we ask: can reasoning models improve their calibration by explicitly reasoning
about their chain-of-thought traces? We introduce introspective uncertainty
quantification (UQ) to explore this direction. In extensive evaluations on SOTA
reasoning models across a broad range of benchmarks, we find that reasoning
models: (i) are typically overconfident, with self-verbalized confidence
estimates often greater than 85% particularly for incorrect responses, (ii)
become even more overconfident with deeper reasoning, and (iii) can become
better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not
uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we
conclude with important research directions to design necessary UQ benchmarks
and improve the calibration of reasoning models.

</details>


### [34] [The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis](https://arxiv.org/abs/2506.18187)
*Shahriar Noroozizadeh,Pim Welle,Jeremy C. Weiss,George H. Chen*

Main category: cs.AI

TL;DR: 不依从抗精神病药物会让精神分裂症患者更早经历不良事件（如早逝、住院、入狱），提前约1至4个月。依从性提高能显著延缓危机发生，生存分析联用因果推断为政策制定提供参考。


<details>
  <summary>Details</summary>
Motivation: 精神分裂症患者非依从性服用抗精神病药物可能导致不良结局，但具体影响和量化证据尚不充分。该研究旨在量化药物不依从性与早逝、非自愿住院、入狱等恶性事件之间的关联，并通过因果推断与生存分析方法提升分析的精确度。

Method: 使用生存分析方法，以多种生存模型扩展常用的因果推断技术（T-learner、S-learner、最近邻匹配），分析药物不依从（视为“处理”）导致首次不良事件所需时间。实验对不同纵向信息长度（3、6、9、12个月）重复分析，并进行药物种类和给药方式（注射 vs. 口服）亚组分析。通过消融实验验证县级风险评分对混杂因子的校正作用。

Result: 在宾夕法尼亚州阿勒格尼县数据中发现，药物不依从显著提前约1至4个月发生不良事件。消融实验显示移除风险评分会放大该效应，表明其对混杂因素有重要调节作用。不同药物类型与给药方式的亚组分析结果一致，不依从均显著增加不良结局提前发生的风险。

Conclusion: 药物依从性对延缓精神分裂症患者精神危机具有临床意义。结合生存分析和因果推断的方法能够为公共政策提供有价值信息，但本研究强调只能做相关性推断，真正的因果解释还需满足额外假设。

Abstract: This study quantifies the association between non-adherence to antipsychotic
medications and adverse outcomes in individuals with schizophrenia. We frame
the problem using survival analysis, focusing on the time to the earliest of
several adverse events (early death, involuntary hospitalization, jail
booking). We extend standard causal inference methods (T-learner, S-learner,
nearest neighbor matching) to utilize various survival models to estimate
individual and average treatment effects, where treatment corresponds to
medication non-adherence. Analyses are repeated using different amounts of
longitudinal information (3, 6, 9, and 12 months). Using data from Allegheny
County in western Pennsylvania, we find strong evidence that non-adherence
advances adverse outcomes by approximately 1 to 4 months. Ablation studies
confirm that county-provided risk scores adjust for key confounders, as their
removal amplifies the estimated effects. Subgroup analyses by medication
formulation (injectable vs. oral) and medication type consistently show that
non-adherence is associated with earlier adverse events. These findings
highlight the clinical importance of adherence in delaying psychiatric crises
and show that integrating survival analysis with causal inference tools can
yield policy-relevant insights. We caution that although we apply causal
inference, we only make associative claims and discuss assumptions needed for
causal interpretation.

</details>


### [35] [A Conceptual Framework for AI Capability Evaluations](https://arxiv.org/abs/2506.18213)
*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Luca Nicolás Forziati Gangi,Matheo Sandleris Musa,Lola Ramos Pereyra,Mario Leiva,Juan Gustavo Corvalan,María Vanina Martinez,Gerardo Simari*

Main category: cs.AI

TL;DR: 本文提出了一个结构化的AI能力评估分析框架，提升了评估的透明度与可比性，为研究者、从业者和政策制定者提供了有价值的工具。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统广泛应用于社会，如何系统性和透明地评估其能力和风险成为AI治理的重要需求，但目前缺乏可靠的综合评估方法。

Method: 提出了一个分析AI能力评估的概念性框架，该框架对现有评估方法和术语进行结构化和描述化梳理，不引入新的分类或固定格式。

Result: 该框架提高了AI能力评估的透明度、可比性和可解释性，有助于发现方法上的不足，指导评估设计，并为政策制定者提供便于理解和比较的工具。

Conclusion: 提出的分析框架有助于推动AI能力评估方法的规范化，支持多方在AI治理中的有效决策。

Abstract: As AI systems advance and integrate into society, well-designed and
transparent evaluations are becoming essential tools in AI governance,
informing decisions by providing evidence about system capabilities and risks.
Yet there remains a lack of clarity on how to perform these assessments both
comprehensively and reliably. To address this gap, we propose a conceptual
framework for analyzing AI capability evaluations, offering a structured,
descriptive approach that systematizes the analysis of widely used methods and
terminology without imposing new taxonomies or rigid formats. This framework
supports transparency, comparability, and interpretability across diverse
evaluations. It also enables researchers to identify methodological weaknesses,
assists practitioners in designing evaluations, and provides policymakers with
an accessible tool to scrutinize, compare, and navigate complex evaluation
landscapes.

</details>


### [36] [The 4th Dimension for Scaling Model Size](https://arxiv.org/abs/2506.18233)
*Ruike Zhu,Hanwen Zhang,Tianyu Shi,Chi Wang,Tianyi Zhou,Zengyi Qin*

Main category: cs.AI

TL;DR: 该论文提出通过参数复用（虚拟逻辑深度VLD）可显著提升大模型推理能力而无需增加参数，实验验证其普适性，有助于低成本实现更强模型推理力。


<details>
  <summary>Details</summary>
Motivation: 目前大模型扩展主要依赖于增加深度、宽度和参数数量，但这些方法成本较高，因此希望探索新的扩展方式以提升模型能力。

Method: 提出了一种新的模型扩展维度——虚拟逻辑深度（VLD），通过模型内部参数复用来增加算法深度而不增加参数总数，并通过设计受控实验系统分析VLD扩展特点。

Result: 发现VLD扩展下，模型知识容量基本不变但推理能力显著提升，并且参数数量与知识容量相关，与推理能力无直接关系，合理利用VLD可以在不增加参数的情况下提升推理能力。

Conclusion: VLD是一种有效提升模型推理能力而不需增加参数总数的新路径；通过参数复用可以显著提升推理能力，并且这些结论在多种模型配置下均成立，表现出较强的普适性。

Abstract: Scaling the size of large language models typically involves three
dimensions: depth, width, and the number of parameters. In this work, we
explore a fourth dimension, virtual logical depth (VLD), which increases the
effective algorithmic depth without changing the overall parameter count by
reusing parameters within the model. Although parameter reuse is not a new
concept, its potential and characteristics in model scaling have not been
thoroughly studied. Through carefully designed controlled experiments, we make
the following key discoveries regarding VLD scaling:
  VLD scaling forces the knowledge capacity of the model to remain almost
constant, with only minor variations.
  VLD scaling enables a significant improvement in reasoning capability,
provided the scaling method is properly implemented.
  The number of parameters correlates with knowledge capacity, but not with
reasoning capability. Under certain conditions, it is not necessary to increase
the parameter count to enhance reasoning.
  These findings are consistent across various model configurations and are
likely to be generally valid within the scope of our experiments.

</details>


### [37] [Advanced For-Loop for QML algorithm search](https://arxiv.org/abs/2506.18260)
*FuTe Wong*

Main category: cs.AI

TL;DR: 本文借助大型语言模型多智能体系统，自动化探索和优化量子机器学习算法。在概念验证中，成功将部分经典ML算法转化为量子形式，展示了方法的有效性和前景。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算和量子机器学习（QML）的快速发展，现有的QML算法大多依赖于人工设计，开发效率和探索空间有限。论文动机在于希望利用大型语言模型（LLM）多智能体系统自动化搜索和优化QML算法，加快创新步伐。

Method: 本文提出了一种基于大型语言模型的多智能体系统（LLMMA）框架，使多个智能体能够在抽象层面对经典机器学习算法（如多层感知机、前馈、反向传播等）进行量子化变换的自动生成与迭代优化。该方法借鉴了Google DeepMind的FunSearch理念。

Result: 通过原型验证，论文展示了LLMMA框架能够系统性地探索并自动地将部分经典机器学习思想适配到量子计算领域，显示了该方法在QML算法开发中的潜力。

Conclusion: LLMMA框架为QML算法的高效和自动化开发提供了新思路，未来可引入规划机制和更智能的搜索策略，拓宽量子增强机器学习的应用。

Abstract: This paper introduces an advanced framework leveraging Large Language
Model-based Multi-Agent Systems (LLMMA) for the automated search and
optimization of Quantum Machine Learning (QML) algorithms. Inspired by Google
DeepMind's FunSearch, the proposed system works on abstract level to
iteratively generates and refines quantum transformations of classical machine
learning algorithms (concepts), such as the Multi-Layer Perceptron,
forward-forward and backpropagation algorithms. As a proof of concept, this
work highlights the potential of agentic frameworks to systematically explore
classical machine learning concepts and adapt them for quantum computing,
paving the way for efficient and automated development of QML algorithms.
Future directions include incorporating planning mechanisms and optimizing
strategy in the search space for broader applications in quantum-enhanced
machine learning.

</details>


### [38] [Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team](https://arxiv.org/abs/2506.18348)
*Weilun Yu,Shixiang Tang,Yonggui Huang,Nanqing Dong,Li Fan,Honggang Qi,Wei Liu,Xiaoli Diao,Xi Chen,Wanli Ouyang*

Main category: cs.AI

TL;DR: IDVSCI框架通过加入内部讨论与投票、双重多样性评审机制，有效增强了LLM科学家代理的推理和创新能力，在多个领域表现优越，表明“互动与评议”机制在自主科研中有重要价值。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型（LLM）的科学家代理在自主科学发现方面取得了一定进展，但缺乏真实科研活动中必需的交互推理和评估机制。

Method: 提出了IDVSCI（Internal Discussion and Vote SCIentists）框架，包括动态知识交流机制和双重多样性评审范式，支持代理间的反馈和异质性专家评审。

Result: 在计算机科学广泛应用的基准数据集以及新引入的健康科学数据集上进行实验，IDVSCI在两者上均取得了最佳表现，优于AI Scientist和VIRSCI等现有系统。

Conclusion: 通过模拟人与人之间互动和同行评议过程，IDVSCI显著提升了LLM在自主科研中的推理深度和创新能力。

Abstract: Scientific progress increasingly relies on effective collaboration among
researchers, a dynamic that large language models (LLMs) have only begun to
emulate. While recent LLM-based scientist agents show promise in autonomous
scientific discovery, they often lack the interactive reasoning and evaluation
mechanisms essential to real-world research. We propose IDVSCI (Internal
Discussion and Vote SCIentists), a multi-agent framework built on LLMs that
incorporates two key innovations: a Dynamic Knowledge Exchange mechanism
enabling iterative feedback among agents, and a Dual-Diversity Review paradigm
that simulates heterogeneous expert evaluation. These components jointly
promote deeper reasoning and the generation of more creative and impactful
scientific ideas. To evaluate the effectiveness and generalizability of our
approach, we conduct experiments on two datasets: a widely used benchmark in
computer science and a new dataset we introduce in the health sciences domain.
Results show that IDVSCI consistently achieves the best performance across both
datasets, outperforming existing systems such as AI Scientist and VIRSCI. These
findings highlight the value of modeling interaction and peer review dynamics
in LLM-based autonomous research.

</details>


### [39] [A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction](https://arxiv.org/abs/2506.18424)
*Chengjie Liu,Weiyu Chen,Huiyao Xu,Yuan Du,Jun Yang,Li Du*

Main category: cs.AI

TL;DR: 作者提出一种利用大语言模型自动从文献中抽取尺寸关系的方法，有效剪枝设计搜索空间，在三类电路上显著提升优化效率。这为自动化类比电路设计开辟了新方向。


<details>
  <summary>Details</summary>
Motivation: 目前类比电路器件尺寸设计阶段，虽然普遍采用数学优化方法提升优化效率，但往往忽略了如何自动引入先验知识，有效压缩（剪枝）搜索空间。现有方法在搜索空间的压缩上仍有较大提升空间。

Method: 提出了一种基于大语言模型（LLM）的多智能体框架，用来从学术论文中自动抽取类比电路的尺寸关系，通过这些抽取的关系对尺寸优化的搜索空间进行有效剪枝。

Result: 该框架在三类电路测试中实现了2.32至26.6倍的优化效率提升。

Conclusion: 本文展示了LLM能够有效剪枝类比电路尺寸设计搜索空间，为LLM与传统类比电路设计自动化方法的结合提供了新思路。

Abstract: In the design process of the analog circuit pre-layout phase, device sizing
is an important step in determining whether an analog circuit can meet the
required performance metrics. Many existing techniques extract the circuit
sizing task as a mathematical optimization problem to solve and continuously
improve the optimization efficiency from a mathematical perspective. But they
ignore the automatic introduction of prior knowledge, fail to achieve effective
pruning of the search space, which thereby leads to a considerable compression
margin remaining in the search space. To alleviate this problem, we propose a
large language model (LLM)-based multi-agent framework for analog circuits'
sizing relationships extraction from academic papers. The search space in the
sizing process can be effectively pruned based on the sizing relationship
extracted by this framework. Eventually, we conducted tests on 3 types of
circuits, and the optimization efficiency was improved by $2.32 \sim 26.6
\times$. This work demonstrates that the LLM can effectively prune the search
space for analog circuit sizing, providing a new solution for the combination
of LLMs and conventional analog circuit design automation methods.

</details>


### [40] [How Robust is Model Editing after Fine-Tuning? An Empirical Study on Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.18428)
*Feng He,Zhenyang Liu,Marco Valentino,Zhixue Zhao*

Main category: cs.AI

TL;DR: T2I扩散模型中的模型编辑很容易在后续微调中失效，尤其是特定微调方式。安全应用中微调既可移除恶意编辑，还会丢失有益改动，需要更鲁棒的编辑技术或重新编辑操作。


<details>
  <summary>Details</summary>
Motivation: 作者关注于在大模型预训练后进行模型编辑，以便低成本地修正或注入特定行为（如事实纠错、偏见缓解），但目前尚不清楚这些编辑在后续微调后能否保留或被逆转。该问题对于模型安全和长期行为控制有重要影响。

Method: 系统性地研究模型编辑与微调在文本到图像扩散模型（T2I diffusion models）中的相互作用。研究内容涵盖两种模型（Stable Diffusion和FLUX）、两种主流编辑技术、三种微调方法（DreamBooth、LoRA和DoRA），通过多样化编辑任务和评估指标进行实证分析。

Result: 大部分编辑在后续微调后无法保留，哪怕微调内容与编辑点无关。DoRA微调法最易导致编辑失效。编辑方法中，UCE方法较为稳定，对比ReFACT在微调后表现更好。

Conclusion: 当前模型编辑方法在长期控制和对齐方面存在严重不足。微调过程既可移除恶意编辑，但也可能消除有益的安全调整，因此实际应用需加强编辑鲁棒性，或在微调后重新编辑以保证效果。

Abstract: Model editing offers a low-cost technique to inject or correct a particular
behavior in a pre-trained model without extensive retraining, supporting
applications such as factual correction and bias mitigation. Despite this
common practice, it remains unknown whether edits persist after fine-tuning or
whether they are inadvertently reversed. This question has fundamental
practical implications. For example, if fine-tuning removes prior edits, it
could serve as a defence mechanism against hidden malicious edits. Vice versa,
the unintended removal of edits related to bias mitigation could pose serious
safety concerns. We systematically investigate the interaction between model
editing and fine-tuning in the context of T2I diffusion models, which are known
to exhibit biases and generate inappropriate content. Our study spans two T2I
model families (Stable Diffusion and FLUX), two sota editing techniques, and
three fine-tuning methods (DreamBooth, LoRA, and DoRA). Through an extensive
empirical analysis across diverse editing tasks and evaluation metrics, our
findings reveal a trend: edits generally fail to persist through fine-tuning,
even when fine-tuning is tangential or unrelated to the edits. Notably, we
observe that DoRA exhibits the strongest edit reversal effect. At the same
time, among editing methods, UCE demonstrates greater robustness, retaining
significantly higher efficacy post-fine-tuning compared to ReFACT. These
findings highlight a crucial limitation in current editing methodologies,
emphasizing the need for more robust techniques to ensure reliable long-term
control and alignment of deployed AI systems. These findings have dual
implications for AI safety: they suggest that fine-tuning could serve as a
remediation mechanism for malicious edits while simultaneously highlighting the
need for re-editing after fine-tuning to maintain beneficial safety and
alignment properties.

</details>


### [41] [Standard Applicability Judgment and Cross-jurisdictional Reasoning: A RAG-based Framework for Medical Device Compliance](https://arxiv.org/abs/2506.18511)
*Yu Han,Aaron Ceross,Jeroen H. M. Bergmann*

Main category: cs.AI

TL;DR: 该文提出基于RAG的AI系统自动判定医疗器械标准适用性，准确率高且支持中美法规跨区域推理，是合规领域首个端到端推理解决方案。


<details>
  <summary>Details</summary>
Motivation: 在医疗设备合规领域，不同地区的法规标准文档碎片化且不统一，标准适用性判定需依赖专家，效率低下，亟需自动化工具提升法规合规工作效率。

Method: 提出了一套模块化AI系统，基于检索增强生成（RAG）技术。系统对给定的设备描述，先从标准库中检索候选标准，再用大语言模型判断每个标准在不同司法管辖区下的适用性（强制、推荐、不适用），并提供可溯源的理由。构建了国际化的医疗设备描述基准数据集，包含专家标注的标准映射，并同检索、零样本与规则法基线模型对系统进行评测。

Result: 系统取得了73%的分类准确率和87%的Top-5检索召回率，展示出显著有效性。系统具备跨中美法规标准区域感知与推理能力，可解释标准适用性与冲突。

Conclusion: 首次提出端到端标准适用性推理系统，实现医疗设备法规合规的自动化、可扩展以及可解释AI支撑。能够支持不同国家间法规标准适用的冲突解决与标准判定理由追溯。

Abstract: Identifying the appropriate regulatory standard applicability remains a
critical yet understudied challenge in medical device compliance, frequently
necessitating expert interpretation of fragmented and heterogeneous
documentation across different jurisdictions. To address this challenge, we
introduce a modular AI system that leverages a retrieval-augmented generation
(RAG) pipeline to automate standard applicability determination. Given a
free-text device description, our system retrieves candidate standards from a
curated corpus and uses large language models to infer jurisdiction-specific
applicability, classified as Mandatory, Recommended, or Not Applicable, with
traceable justifications. We construct an international benchmark dataset of
medical device descriptions with expert-annotated standard mappings, and
evaluate our system against retrieval-only, zero-shot, and rule-based
baselines. The proposed approach attains a classification accuracy of 73% and a
Top-5 retrieval recall of 87%, demonstrating its effectiveness in identifying
relevant regulatory standards. We introduce the first end-to-end system for
standard applicability reasoning, enabling scalable and interpretable
AI-supported regulatory science. Notably, our region-aware RAG agent performs
cross-jurisdictional reasoning between Chinese and U.S. standards, supporting
conflict resolution and applicability justification across regulatory
frameworks.

</details>


### [42] [A Question Bank to Assess AI Inclusivity: Mapping out the Journey from Diversity Errors to Inclusion Excellence](https://arxiv.org/abs/2506.18538)
*Rifat Ara Shams,Didar Zowghi,Muneera Bano*

Main category: cs.AI

TL;DR: 本论文提出253题的AI包容性问题库，可系统评估AI在多样性与包容性方面的表现，方法科学，结果显示工具有效，对实现公平AI具有实践意义。


<details>
  <summary>Details</summary>
Motivation: 当前的AI风险评估框架往往忽视包容性，缺乏衡量AI系统多样性与包容性原则一致性的标准化工具。因此，亟需开发能够系统性衡量AI包容性的手段。

Method: 本文提出并开发了一个结构化的AI包容性问题库，包含253个问题，从“人”、“数据”、“流程”、“系统”和“治理”五大支柱评估AI包容性。开发过程采用多轮迭代法，融合文献综述、包容性指南、负责任AI框架及模拟用户研究的见解。之后，研究团队通过70个人工生成的AI相关职业角色，模拟评估了问题库在不同应用领域和角色中的相关性与有效性。

Result: 实验表明，该问题库能够有效评估和提升AI系统在多样性与包容性方面的表现，对AI开发流程和治理结构中融入包容性原则具有重要作用。

Conclusion: 所提出的问题库为学界、业界和政策制定者提供了系统评估与加强AI包容性的可操作工具，有助于推动更公平和负责任的AI技术发展。

Abstract: Ensuring diversity and inclusion (D&I) in artificial intelligence (AI) is
crucial for mitigating biases and promoting equitable decision-making. However,
existing AI risk assessment frameworks often overlook inclusivity, lacking
standardized tools to measure an AI system's alignment with D&I principles.
This paper introduces a structured AI inclusivity question bank, a
comprehensive set of 253 questions designed to evaluate AI inclusivity across
five pillars: Humans, Data, Process, System, and Governance. The development of
the question bank involved an iterative, multi-source approach, incorporating
insights from literature reviews, D&I guidelines, Responsible AI frameworks,
and a simulated user study. The simulated evaluation, conducted with 70
AI-generated personas related to different AI jobs, assessed the question
bank's relevance and effectiveness for AI inclusivity across diverse roles and
application domains. The findings highlight the importance of integrating D&I
principles into AI development workflows and governance structures. The
question bank provides an actionable tool for researchers, practitioners, and
policymakers to systematically assess and enhance the inclusivity of AI
systems, paving the way for more equitable and responsible AI technologies.

</details>


### [43] [T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent](https://arxiv.org/abs/2506.18559)
*Hong Qing Yu*

Main category: cs.AI

TL;DR: T-CPDL扩展描述逻辑，融入时序、因果和概率推理，大幅提升大模型推理准确性、可解释性和可信度，为强化逻辑-检索增强生成打下基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然在生成流畅文本方面表现优秀，但在涉及时间约束、因果关系和概率推理的结构化推理任务上表现不佳。为了解决这个问题，有必要为语言模型推理过程引入更完整的时序、因果和概率语义支持。

Method: 作者提出了一种整合型框架“T-CPDL（时序因果概率描述逻辑）”，将传统描述逻辑扩展为包含时序区间算子、显式因果关系和概率注解。T-CPDL有两种变体：一种基于Allen区间代数，描述定性时序关系；另一种通过显式带时间戳的因果断言丰富表达方式。这两种变体共享统一的逻辑结构，可实现从简单时序排序到复杂概率因果推理的多种推理任务。

Result: 在时序推理和因果推理基准数据集上的实验证明，T-CPDL能显著提升大型语言模型的推理准确率、可解释性及结果可信度校准能力。

Conclusion: T-CPDL极大提升了语言模型支撑稳健、可解释、可信决策的能力，并为高级的逻辑-检索增强生成（Logic-RAG）框架奠定了基础，有望提升知识图谱增强型RAG系统的推理能力和效率。

Abstract: Large language models excel at generating fluent text but frequently struggle
with structured reasoning involving temporal constraints, causal relationships,
and probabilistic reasoning. To address these limitations, we propose Temporal
Causal Probabilistic Description Logic (T-CPDL), an integrated framework that
extends traditional Description Logic with temporal interval operators,
explicit causal relationships, and probabilistic annotations. We present two
distinct variants of T-CPDL: one capturing qualitative temporal relationships
through Allen's interval algebra, and another variant enriched with explicit
timestamped causal assertions. Both variants share a unified logical structure,
enabling complex reasoning tasks ranging from simple temporal ordering to
nuanced probabilistic causation. Empirical evaluations on temporal reasoning
and causal inference benchmarks confirm that T-CPDL substantially improves
inference accuracy, interpretability, and confidence calibration of language
model outputs. By delivering transparent reasoning paths and fine-grained
temporal and causal semantics, T-CPDL significantly enhances the capability of
language models to support robust, explainable, and trustworthy
decision-making. This work also lays the groundwork for developing advanced
Logic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentially
boosting the reasoning capabilities and efficiency of knowledge graph-enhanced
RAG systems.

</details>


### [44] [AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs](https://arxiv.org/abs/2506.18628)
*Piotr Matys,Jan Eliasz,Konrad Kiełczyński,Mikołaj Langner,Teddy Ferdinan,Jan Kocoń,Przemysław Kazienko*

Main category: cs.AI

TL;DR: 本文提出AggTruth方法，通过分析attention分数实现LLM幻觉的在线检测，在多模型、任务下超过当前最佳方法，并强调了特征选择和head选择的作用。


<details>
  <summary>Details</summary>
Motivation: 在现实应用中，LLMs即使在RAG设置下也常常出现虚假生成（幻觉），这为模型落地产生重大挑战。作者希望解决如何有效检测和降低LLMs的语境性幻觉问题。

Method: 提出了AggTruth方法，通过分析LLM内部attention分数的分布，在线检测语境幻觉。具体设计了四种不同的attention分数聚合技术。还研究了特征选择和attention head数目对检测性能的影响。

Result: AggTruth在所有测试的LLMs和任务（包括同任务和跨任务设置）中表现稳定，在多种场景下优于当前最优方法（SOTA）。合理选择attention heads能进一步提升检测效果。

Conclusion: AggTruth提供了一种通用、有效的LLM幻觉检测方案，能够在多模型多任务下超过现有方法，并揭示了attention head选择的重要性。

Abstract: In real-world applications, Large Language Models (LLMs) often hallucinate,
even in Retrieval-Augmented Generation (RAG) settings, which poses a
significant challenge to their deployment. In this paper, we introduce
AggTruth, a method for online detection of contextual hallucinations by
analyzing the distribution of internal attention scores in the provided context
(passage). Specifically, we propose four different variants of the method, each
varying in the aggregation technique used to calculate attention scores. Across
all LLMs examined, AggTruth demonstrated stable performance in both same-task
and cross-task setups, outperforming the current SOTA in multiple scenarios.
Furthermore, we conducted an in-depth analysis of feature selection techniques
and examined how the number of selected attention heads impacts detection
performance, demonstrating that careful selection of heads is essential to
achieve optimal results.

</details>


### [45] [Dual-level Behavioral Consistency for Inter-group and Intra-group Coordination in Multi-Agent Systems](https://arxiv.org/abs/2506.18651)
*Shuocun Yang,Huawen Hu,Enze Shi,Shu Zhang*

Main category: cs.AI

TL;DR: 作者提出了DLBC方法，通过组内与组间的行为一致性调控，显著提升了多智能体系统的协作与分工能力，在实验任务中获得较大性能收益。


<details>
  <summary>Details</summary>
Motivation: 现有工作多关注多智能体系统内部的行为一致性，对分组场景下的行为一致性关注不足，亟需方法同时控制组内与组间的行为策略。

Method: 提出Dual-Level Behavioral Consistency（DLBC）方法，将多智能体分组，并在组内与组间动态调节行为多样性，通过直接约束智能体策略函数以提升行为一致性。

Result: 实验表明，DLBC在各类分组协作任务中显著提升了组内合作与组间任务专业化表现，取得了显著性能提升。

Conclusion: DLBC方法有效提升了多智能体系统中组内协作与组间分工性能，展现了行为一致性控制的新思路，并具备在复杂任务与动态环境中的应用潜力。

Abstract: Behavioral diversity in Multi-agent reinforcement learning(MARL) represents
an emerging and promising research area. Prior work has largely centered on
intra-group behavioral consistency in multi-agent systems, with limited
attention given to behavioral consistency in multi-agent grouping scenarios. In
this paper, we introduce Dual-Level Behavioral Consistency (DLBC), a novel MARL
control method designed to explicitly regulate agent behaviors at both
intra-group and inter-group levels. DLBC partitions agents into distinct groups
and dynamically modulates behavioral diversity both within and between these
groups. By dynamically modulating behavioral diversity within and between these
groups, DLBC achieves enhanced division of labor through inter-group
consistency, which constrains behavioral strategies across different groups.
Simultaneously, intra-group consistency, achieved by aligning behavioral
strategies within each group, fosters stronger intra-group cooperation.
Crucially, DLBC's direct constraint of agent policy functions ensures its broad
applicability across various algorithmic frameworks. Experimental results in
various grouping cooperation scenarios demonstrate that DLBC significantly
enhances both intra-group cooperative performance and inter-group task
specialization, yielding substantial performance improvements. DLBC provides
new ideas for behavioral consistency control of multi-intelligent body systems,
and its potential for application in more complex tasks and dynamic
environments can be further explored in the future.

</details>


### [46] [Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training](https://arxiv.org/abs/2506.18777)
*Jonathan Cook,Silvia Sapora,Arash Ahmadian,Akbir Khan,Tim Rocktaschel,Jakob Foerster,Laura Ruis*

Main category: cs.AI

TL;DR: 通过微调LLMs仅依赖程序源码（无需I/O例子）进行推理可提升通用推理能力，模型可内化算法抽象，指向更强符号推理和模型对齐方向。


<details>
  <summary>Details</summary>
Motivation: 代码训练能显著提升LLMs推理能力，但目前尚不清楚其背后机理。为探究是否通过仅源码训练也能赋予推理能力，提出PBB方法并开展实验。

Method: 将LLMs在两组程序上微调：一组为源码+I/O例子（w/ IO），一组仅有源码（w/o IO），对比二者在推理与评估能力方面的表现差异。

Result: LLMs在未见过I/O的程序上也能直接输出，尤其在代码而非语言描述形式更显著，且通过链式思考提升表现。PBB方式较基于分布式I/O训练更鲁棒。

Conclusion: PBB（通过源码训练而非I/O实例）可促使LLMs学习可复用的算法抽象，提升推理能力。通过代码训练能够使模型在处理变动输入时更为鲁棒，此方向为模型对符号性过程学习与对准等任务提供新思路。

Abstract: Training large language models (LLMs) on source code significantly enhances
their general-purpose reasoning abilities, but the mechanisms underlying this
generalisation are poorly understood. In this paper, we propose Programming by
Backprop (PBB) as a potential driver of this effect - teaching a model to
evaluate a program for inputs by training on its source code alone, without
ever seeing I/O examples. To explore this idea, we finetune LLMs on two sets of
programs representing simple maths problems and algorithms: one with source
code and I/O examples (w/ IO), the other with source code only (w/o IO). We
find evidence that LLMs have some ability to evaluate w/o IO programs for
inputs in a range of experimental settings, and make several observations.
Firstly, PBB works significantly better when programs are provided as code
rather than semantically equivalent language descriptions. Secondly, LLMs can
produce outputs for w/o IO programs directly, by implicitly evaluating the
program within the forward pass, and more reliably when stepping through the
program in-context via chain-of-thought. We further show that PBB leads to more
robust evaluation of programs across inputs than training on I/O pairs drawn
from a distribution that mirrors naturally occurring data. Our findings suggest
a mechanism for enhanced reasoning through code training: it allows LLMs to
internalise reusable algorithmic abstractions. Significant scope remains for
future work to enable LLMs to more effectively learn from symbolic procedures,
and progress in this direction opens other avenues like model alignment by
training on formal constitutional principles.

</details>


### [47] [TRIZ Agents: A Multi-Agent LLM Approach for TRIZ-Based Innovation](https://arxiv.org/abs/2506.18783)
*Kamil Szczepanik,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 作者提出了基于LLM的多智能体TRIZ系统，通过协作高效解决复杂创新问题，展示了AI赋能分布式创新的前景。


<details>
  <summary>Details</summary>
Motivation: TRIZ理论为创新解决方案提供框架，但其实际应用受限于所需的复杂性和多学科知识。随着大语言模型（LLM）技术的发展，自动化TRIZ流程的可能性出现，因此作者希望突破TRIZ应用门槛。

Method: 提出一种多智能体系统（TRIZ agents），利用多个具备不同专业领域知识和工具接入能力的LLM智能体协作，基于TRIZ方法论共同解决创新性问题。通过在特定工程案例中模拟和验证多智能体团队协作解决问题的能力。

Result: 多智能体系统能协同高效地推进TRIZ步骤，并能在复杂创新挑战中产出多样化且具有创新性的解决方案。实验结果验证了智能体协作在复杂创新任务中的优势。

Conclusion: 多智能体LLM系统在创新问题求解上展现出分布式协作和创新能力，有助于推动AI驱动的创新进程，是复杂问题去中心化解决的重要方向。

Abstract: TRIZ, the Theory of Inventive Problem Solving, is a structured,
knowledge-based framework for innovation and abstracting problems to find
inventive solutions. However, its application is often limited by the
complexity and deep interdisciplinary knowledge required. Advancements in Large
Language Models (LLMs) have revealed new possibilities for automating parts of
this process. While previous studies have explored single LLMs in TRIZ
applications, this paper introduces a multi-agent approach. We propose an
LLM-based multi-agent system, called TRIZ agents, each with specialized
capabilities and tool access, collaboratively solving inventive problems based
on the TRIZ methodology. This multi-agent system leverages agents with various
domain expertise to efficiently navigate TRIZ steps. The aim is to model and
simulate an inventive process with language agents. We assess the effectiveness
of this team of agents in addressing complex innovation challenges based on a
selected case study in engineering. We demonstrate the potential of agent
collaboration to produce diverse, inventive solutions. This research
contributes to the future of AI-driven innovation, showcasing the advantages of
decentralized problem-solving in complex ideation tasks.

</details>


### [48] [ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation](https://arxiv.org/abs/2506.18810)
*Siao Tang,Xinyin Ma,Gongfan Fang,Xinchao Wang*

Main category: cs.AI

TL;DR: 本文提出了一种推理生成时动态注入简洁提示的ConciseHint方法，能有效缩短大型推理模型的推理内容长度，并保持任务准确率，实现效率与性能兼得。


<details>
  <summary>Details</summary>
Motivation: 近年来大型推理模型（LRMs）通过扩展Chain-of-Thought（CoT）生成长度，提升了复杂推理任务的表现。但模型逐渐倾向于生成冗长推理过程，导致效率下降。现有提升效率的方法多关注推理前的技巧如Prompt设计或微调，鲜有研究在推理生成过程中实现简洁表达。亟需探索能在推理生成中直接鼓励简洁性的方案。

Method: 提出了一种名为ConciseHint的新框架，通过在推理生成过程中注入文本提示（可手工设计或基于简洁数据训练获得），持续鼓励模型简洁表述。此方法还可根据查询复杂度自适应调整提示强度，确保不会削弱模型性能。

Result: 在包括DeepSeek-R1与Qwen-3系列等最新LRMs上验证了ConciseHint的有效性。以Qwen-3 4B在GSM8K基准测试为例，推理过程长度降低65%，且几乎无准确率损失。

Conclusion: ConciseHint框架能有效缩短推理模型的推理过程表述长度，同时保持优异性能，解决了冗长推理带来的效率问题，对生成式推理模型实际应用具有重要改进价值。

Abstract: Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and
OpenAI o1 series have achieved notable performance enhancements on complex
reasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).
However, an emerging issue is their inclination to produce excessively verbose
reasoning processes, leading to the inefficiency problem. Existing literature
on improving efficiency mainly adheres to the before-reasoning paradigms such
as prompting and reasoning or fine-tuning and reasoning, but ignores the
promising direction of directly encouraging the model to speak concisely by
intervening during the generation of reasoning. In order to fill the blank, we
propose a framework dubbed ConciseHint, which continuously encourages the
reasoning model to speak concisely by injecting the textual hint (manually
designed or trained on the concise data) during the token generation of the
reasoning process. Besides, ConciseHint is adaptive to the complexity of the
query by adaptively adjusting the hint intensity, which ensures it will not
undermine model performance. Experiments on the state-of-the-art LRMs,
including DeepSeek-R1 and Qwen-3 series, demonstrate that our method can
effectively produce concise reasoning processes while maintaining performance
well. For instance, we achieve a reduction ratio of 65\% for the reasoning
length on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.

</details>


### [49] [Steering Conceptual Bias via Transformer Latent-Subspace Activation](https://arxiv.org/abs/2506.18887)
*Vansh Sharma,Venkat Raman*

Main category: cs.AI

TL;DR: 本文针对科学代码生成中的编程语言偏向控制问题，提出了基于梯度优化和动态探针的自适应激活引导方法（G-ACT），在不同规模的LLMs上显著提升了代码输出的目标语言一致性和模型可控性。


<details>
  <summary>Details</summary>
Motivation: 在现有大型语言模型(LLMs)的科学代码生成任务中，存在对特定编程语言的生成偏向，但如何高效、精确地操控模型生成特定编程语言的文本仍有挑战。此前的操控方法泛化性和稳定性不足。

Method: 首先评估LLMs在多种编程语言（如C++等）科学代码生成中的基线偏向；然后采用静态神经元归因方法对模型激活进行操作，发现其泛化能力有限；为此提出了一种梯度精炼的自适应激活引导框架（G-ACT），通过对每个提示的激活差异聚类，训练轻量化的层内探针在线选取适当的操控向量，从而动态地引导生成。

Result: G-ACT方法在LLaMA-3.2 3B模型上将探针分类准确率提高了15%，在早期层（0-6层）提升了61.5%，较标准的ACT框架有显著改进。在更大参数量的LLaMA-3.3 70B上，关键层的定向注入依然改善了语言选择。该方法附加的推理开销较小，并提升了模型可控性和行为可复现性。

Conclusion: 本文提出的G-ACT框架能高效、可扩展地实现对语言模型在代码生成时的编程语言偏向控制，具有较强的泛化能力和实际应用价值。

Abstract: This work examines whether activating latent subspaces in language models
(LLMs) can steer scientific code generation toward a specific programming
language. Five causal LLMs were first evaluated on scientific coding prompts to
quantify their baseline bias among four programming languages. A static
neuron-attribution method, perturbing the highest activated MLP weight for a
C++ or CPP token, proved brittle and exhibited limited generalization across
prompt styles and model scales. To address these limitations, a
gradient-refined adaptive activation steering framework (G-ACT) was developed:
per-prompt activation differences are clustered into a small set of steering
directions, and lightweight per-layer probes are trained and refined online to
select the appropriate steering vector. In LLaMA-3.2 3B, this approach reliably
biases generation towards the CPP language by increasing the average probe
classification accuracy by 15% and the early layers (0-6) improving the probe
classification accuracy by 61.5% compared to the standard ACT framework. For
LLaMA-3.3 70B, where attention-head signals become more diffuse, targeted
injections at key layers still improve language selection. Although per-layer
probing introduces a modest inference overhead, it remains practical by
steering only a subset of layers and enables reproducible model behavior. These
results demonstrate a scalable, interpretable and efficient mechanism for
concept-level control for practical agentic systems.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [50] [Outcome-Based Education: Evaluating Students' Perspectives Using Transformer](https://arxiv.org/abs/2506.17223)
*Shuvra Smaran Das,Anirban Saha Anik,Md Kishor Morol,Mohammad Sakib Mahmood*

Main category: cs.CL

TL;DR: 本文用Transformer（DistilBERT）和LIME解释方法，实现对学生反馈的高效可解释分析，优于传统机器学习，有助于以成果为导向的教育目标实现。


<details>
  <summary>Details</summary>
Motivation: OBE（以成果为导向的教育）要求准确分析学生反馈以改进教学成果，但传统方法对文本情感理解有限，因此需要更先进的NLP工具。

Method: 本文采用基于Transformer的DistilBERT模型分析学生反馈的NLP数据集，分类情感，并结合LIME解释模型以提高预测的可解释性。

Result: DistilBERT在情感分类任务上的表现优于其他机器学习模型，可以在更多评估矩阵上获得更好结果，并利用LIME解释帮助理解情感判别的关键因素。

Conclusion: 将Transformer模型与LIME结合，能够有效、可解释地分析学生反馈，促进OBE目标实现，支持基于数据的教育实践改进。

Abstract: Outcome-Based Education (OBE) emphasizes the development of specific
competencies through student-centered learning. In this study, we reviewed the
importance of OBE and implemented transformer-based models, particularly
DistilBERT, to analyze an NLP dataset that includes student feedback. Our
objective is to assess and improve educational outcomes. Our approach is better
than other machine learning models because it uses the transformer's deep
understanding of language context to classify sentiment better, giving better
results across a wider range of matrices. Our work directly contributes to
OBE's goal of achieving measurable outcomes by facilitating the identification
of patterns in student learning experiences. We have also applied LIME (local
interpretable model-agnostic explanations) to make sure that model predictions
are clear. This gives us understandable information about how key terms affect
sentiment. Our findings indicate that the combination of transformer models and
LIME explanations results in a strong and straightforward framework for
analyzing student feedback. This aligns more closely with the principles of OBE
and ensures the improvement of educational practices through data-driven
insights.

</details>


### [51] [Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs](https://arxiv.org/abs/2506.17231)
*Xiang Li,Chong Zhang,Jia Wang,Fangyu Wu,Yushi Li,Xiaobo Jin*

Main category: cs.CL

TL;DR: 提出了高效的对抗性提示蒸馏方法，使小模型能越狱攻击主流大模型，兼具高效率、强适应性和危害性，对LLM安全领域具有启发意义。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）面临越狱攻击带来的安全及道德问题，然而现有方法效率低、计算消耗大、跨模型适应性差，难以应对模型与防御策略的快速变化。

Method: 提出了一种对抗性提示蒸馏（Adversarial Prompt Distillation，APD）方法，结合掩码语言建模、强化学习和动态温度控制，通过生成和蒸馏提示，使小型语言模型（SLM）能够攻击主流LLM。

Result: 实验结果表明，该方法在攻击成功率和危害方面优于现有技术，同时在资源效率和跨模型适应性方面也表现突出。

Conclusion: 本研究验证了将LLM越狱能力蒸馏至SLM的可行性，揭示了模型潜在的脆弱性，为LLM安全研究提供了新思路。

Abstract: Attacks on large language models (LLMs) in jailbreaking scenarios raise many
security and ethical issues. Current jailbreak attack methods face problems
such as low efficiency, high computational cost, and poor cross-model
adaptability and versatility, which make it difficult to cope with the rapid
development of LLM and new defense strategies. Our work proposes an Adversarial
Prompt Distillation, which combines masked language modeling, reinforcement
learning, and dynamic temperature control through a prompt generation and
distillation method. It enables small language models (SLMs) to jailbreak
attacks on mainstream LLMs. The experimental results verify the superiority of
the proposed method in terms of attack success rate and harm, and reflect the
resource efficiency and cross-model adaptability. This research explores the
feasibility of distilling the jailbreak ability of LLM to SLM, reveals the
model's vulnerability, and provides a new idea for LLM security research.

</details>


### [52] [GTA: Grouped-head latenT Attention](https://arxiv.org/abs/2506.17286)
*Luoyang Sun,Jiwen Jiang,Cheng Deng,Xinjian Wu,Haifeng Zhang,Lei Chen,Lionel Ni,Jun Wang*

Main category: cs.CL

TL;DR: 本文提出Grouped-Head Latent Attention (GTA)，通过共享注意力图与潜空间解码显著降低计算与存储开销，使大语言模型推理速度翻倍并降低KV缓存需求，适合高效部署到计算或内存受限环境。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）的注意力机制虽然关键，但其高昂的计算和内存开销严重影响了效率与性能，特别是在文本长度变长时，对硬件资源限制提出了挑战。研究者观察到注意力机制中的KV缓存和各头的注意力图有很大冗余，因此期望用更高效的方案减少资源占用。

Method: 本文提出了一种新的注意力机制：Grouped-Head Latent Attention (GTA)。主要包括两个组件：(1) 共享注意力图机制，在多个头之间复用注意力分数，减小key缓存大小；(2) 非线性值解码器，用学习到的投影将value缓存压缩至潜在空间，进一步降低内存需求。

Result: GTA算法相比Grouped-Query Attention最多可以减少62.5%的注意力计算FLOPs，最多可减少70%的KV缓存体积，同时避免了多头潜在注意力方法的额外开销。最终，整体推理速度提升2倍，预填充和解码阶段计算和缓存开销均显著降低。

Conclusion: GTA有效压缩了KV缓存和注意力计算，大幅提升了大模型的推理速度和部署效率，同时几乎不牺牲模型性能。其创新性机制为资源受限硬件上的LLM部署带来了实际价值。

Abstract: Attention mechanisms underpin the success of large language models (LLMs),
yet their substantial computational and memory overhead poses challenges for
optimizing efficiency and performance. A critical bottleneck arises as KV cache
and attention computations scale rapidly with text length, challenging
deployment on hardware with limited computational and memory resources. We
observe that attention mechanisms exhibit substantial redundancy, since the KV
cache can be significantly compressed and attention maps across heads display
high similarity, revealing that much of the computation and storage is
unnecessary. Leveraging these insights, we propose \textbf{G}rouped-Head
Laten\textbf{T} \textbf{A}ttention (GTA), a novel attention mechanism that
reduces memory usage and computational complexity while maintaining
performance. GTA comprises two components: (1) a shared attention map mechanism
that reuses attention scores across multiple heads, decreasing the key cache
size; and (2) a nonlinear value decoder with learned projections that
compresses the value cache into a latent space, further cutting memory needs.
GTA cuts attention computation FLOPs by up to \emph{62.5\%} versus
Grouped-Query Attention and shrink the KV cache by up to \emph{70\%}, all while
avoiding the extra overhead of Multi-Head Latent Attention to improve LLM
deployment efficiency. Consequently, GTA models achieve a \emph{2x} increase in
end-to-end inference speed, with prefill benefiting from reduced computational
cost and decoding benefiting from the smaller cache footprint.

</details>


### [53] [AI-Generated Game Commentary: A Survey and a Datasheet Repository](https://arxiv.org/abs/2506.17294)
*Qirui Zheng,Xingbo Wang,Keyuan Cheng,Yunlong Lu,Wenxin Li*

Main category: cs.CL

TL;DR: 本文对AI生成游戏解说的任务、挑战、数据集和方法进行了全面综述，提出了通用框架，并开源结构化数据表，促进该领域研究和发展。


<details>
  <summary>Details</summary>
Motivation: AI生成的游戏解说（AIGGC）因其市场潜力和技术挑战逐渐受到关注。针对AIGGC涉及多模态自然语言处理任务，对语言模型提出了更高要求。

Method: 本文提出了一个通用的AIGGC框架，并对45个现有的游戏解说数据集和方法进行了全面调研，根据它们所应对的主要挑战进行分类，并对常用的评估指标进行归类和比较。同时，作者整理了数据集的结构化信息，并在附录及开源库中提供。

Result: 系统性总结了现有AIGGC数据集、方法及评估指标，对领域内主要挑战作了梳理和归类，并提供了结构化的开源数据资源。

Conclusion: 这项工作为AIGGC领域研究提供了全面的现状梳理和开放数据支持，为后续研究和评测奠定了基础。

Abstract: AI-Generated Game Commentary (AIGGC) has gained increasing attention due to
its market potential and inherent technical challenges. As a comprehensive
multimodal Natural Language Processing (NLP) task, AIGGC imposes substantial
demands on language models, including factual accuracy, logical reasoning,
expressive text generation, generation speed, and context management. In this
paper, we introduce a general framework for AIGGC and present a comprehensive
survey of 45 existing game commentary dataset and methods according to key
challenges they aim to address in this domain. We further classify and compare
various evaluation metrics commonly used in this domain. To support future
research and benchmarking, we also provide a structured datasheet summarizing
the essential attributes of these datasets in appendix, which is meanwhile
publicly available in an open repository.

</details>


### [54] [Semantic uncertainty in advanced decoding methods for LLM generation](https://arxiv.org/abs/2506.17296)
*Darius Foodeei,Simin Fan,Martin Jaggi*

Main category: cs.CL

TL;DR: 通过引入新型解码方法（CoT与推测采样），论文发现LLM输出多样性和准确性可兼得，结构化探索显著提升输出质量，对实际应用有重要指导价值。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）的输出受解码策略影响显著，但不同策略下语义多样性与可靠性之间的关系尚不明确。研究者期望通过新兴的采样方法与思维链（Chain-of-Thought, CoT）解码分析，探索结构化探索对输出质量和自信度的影响，为实际应用提供更优解码方案。

Method: 设计多项实验，涵盖问答、摘要和代码生成任务，对比分析常规与新型（如推测采样、思维链解码）解码方法下LLM输出的语义多样性与可靠性。通过评估不同指标（如预测熵、Pass@2、ROUGE分数等）量化各策略效果。

Result: 思维链解码能提升输出语义多样性，并显著降低预测熵，实现更自信、更准确输出。例如，代码生成任务Pass@2提升48.8%，尽管与参考答案一致性略降。摘要任务中推测采样ROUGE分数亦优，整体表现出较优语义多样性和准确性的权衡。

Conclusion: 结构化解码策略不仅能增加语言模型输出的语义探索范围，还能在保证甚至提升输出质量的前提下，缓解传统认为多样性与准确性互相制约的观念。该结论对实际部署LLM具有重要意义。

Abstract: This study investigates semantic uncertainty in large language model (LLM)
outputs across different decoding methods, focusing on emerging techniques like
speculative sampling and chain-of-thought (CoT) decoding. Through experiments
on question answering, summarization, and code generation tasks, we analyze how
different decoding strategies affect both the diversity and reliability of
model outputs. Our findings reveal that while CoT decoding demonstrates higher
semantic diversity, it maintains lower predictive entropy, suggesting that
structured exploration can lead to more confident and accurate outputs. This is
evidenced by a 48.8% improvement in code generation Pass@2 rates, despite lower
alignment with reference solutions. For summarization tasks, speculative
sampling proved particularly effective, achieving superior ROUGE scores while
maintaining moderate semantic diversity. Our results challenge conventional
assumptions about trade-offs between diversity and accuracy in language model
outputs, demonstrating that properly structured decoding methods can increase
semantic exploration while maintaining or improving output quality. These
findings have significant implications for deploying language models in
practical applications where both reliability and diverse solution generation
are crucial.

</details>


### [55] [Mercury: Ultra-Fast Language Models Based on Diffusion](https://arxiv.org/abs/2506.17298)
*Inception Labs,Samar Khanna,Siddhant Kharbanda,Shufan Li,Harshit Varma,Eric Wang,Sawyer Birnbaum,Ziyang Luo,Yanis Miraoui,Akash Palrecha,Stefano Ermon,Aditya Grover,Volodymyr Kuleshov*

Main category: cs.CL

TL;DR: 该论文提出了基于扩散机制的代码大模型Mercury Coder，速度相较于现有模型提升高达10倍，同时保持甚至提升了代码生成质量，已在多个公开测试及真实开发场景中获得领先表现，并已开放API与试玩平台。


<details>
  <summary>Details</summary>
Motivation: 近年来大语言模型（LLM）在代码生成等实际任务中已成为主流技术，但在提升模型质量的同时，推理速度成为大规模商用部署的一大瓶颈。该论文旨在突破速度与质量之间的权衡，实现更快且高质量的代码生成大模型。

Method: 提出了一种基于扩散（diffusion）机制的大语言模型 Mercury，并采用Transformer结构来实现多token并行预测。以代码生成任务为例，开发了Mercury Coder系列模型，包括Mini和Small两个版本，并在商用硬件平台上实现优化。

Result: Mercury Coder Mini和Small在NVIDIA H100 GPU上的吞吐量分别达到1109 tokens/sec和737 tokens/sec，速度显著超过现有主流高效代码生成模型，且在质量上基本持平或取得领先。同时在多个代码基准测试、主流编程语言和实际开发应用场景（如Copilot Arena）中表现优异。

Conclusion: 基于扩散机制的LLM（Mercury Coder）在代码生成任务上实现了商用级别的速度与质量突破，为大规模部署提供了新的解决方案。

Abstract: We present Mercury, a new generation of commercial-scale large language
models (LLMs) based on diffusion. These models are parameterized via the
Transformer architecture and trained to predict multiple tokens in parallel. In
this report, we detail Mercury Coder, our first set of diffusion LLMs designed
for coding applications. Currently, Mercury Coder comes in two sizes: Mini and
Small. These models set a new state-of-the-art on the speed-quality frontier.
Based on independent evaluations conducted by Artificial Analysis, Mercury
Coder Mini and Mercury Coder Small achieve state-of-the-art throughputs of 1109
tokens/sec and 737 tokens/sec, respectively, on NVIDIA H100 GPUs and outperform
speed-optimized frontier models by up to 10x on average while maintaining
comparable quality. We discuss additional results on a variety of code
benchmarks spanning multiple languages and use-cases as well as real-world
validation by developers on Copilot Arena, where the model currently ranks
second on quality and is the fastest model overall. We also release a public
API at https://platform.inceptionlabs.ai/ and free playground at
https://chat.inceptionlabs.ai

</details>


### [56] [PRAISE: Enhancing Product Descriptions with LLM-Driven Structured Insights](https://arxiv.org/abs/2506.17314)
*Adnan Qidwai,Srija Mukhopadhyay,Prerana Khatiwada,Dan Roth,Vivek Gupta*

Main category: cs.CL

TL;DR: 本研究提出PRAISE系统，利用大型语言模型自动对电商商品评论与描述进行信息提取与结构化，对强化商品信息质量、提升买卖双方体验有重要价值。


<details>
  <summary>Details</summary>
Motivation: 电商平台上商品描述的重要性日益突出，但卖家提供的信息常常不全面或不准确。客户评论包含了丰富而真实的细节，但人工筛查这些评论既费时又低效，因此亟需自动化工具来提升信息质量与使用效率。

Method: 提出了一种新系统PRAISE：通过大型语言模型（LLMs）自动从用户评论和卖家描述中提取、比较并结构化产品信息。该系统能直观展示两者之间缺失、矛盾或部分匹配的信息，并提供评论证据。用户界面便捷，帮助识别关键信息差异。

Result: PRAISE系统能够有效地从海量非结构化评论中生成结构化、可操作的见解，显著提升商品描述的准确性与说服力。演示显示其在改善电商目录可信度与质量方面有显著潜力。

Conclusion: PRAISE能自动梳理买家评论与卖家描述间的信息差异，为改善商品展示和提升用户决策体验提供了有力工具，对电商生态的健康发展具有积极作用。

Abstract: Accurate and complete product descriptions are crucial for e-commerce, yet
seller-provided information often falls short. Customer reviews offer valuable
details but are laborious to sift through manually. We present PRAISE: Product
Review Attribute Insight Structuring Engine, a novel system that uses Large
Language Models (LLMs) to automatically extract, compare, and structure
insights from customer reviews and seller descriptions. PRAISE provides users
with an intuitive interface to identify missing, contradictory, or partially
matching details between these two sources, presenting the discrepancies in a
clear, structured format alongside supporting evidence from reviews. This
allows sellers to easily enhance their product listings for clarity and
persuasiveness, and buyers to better assess product reliability. Our
demonstration showcases PRAISE's workflow, its effectiveness in generating
actionable structured insights from unstructured reviews, and its potential to
significantly improve the quality and trustworthiness of e-commerce product
catalogs.

</details>


### [57] [Towards Safety Evaluations of Theory of Mind in Large Language Models](https://arxiv.org/abs/2506.17352)
*Tatsuhiro Aoshima,Mitsuaki Akiyama*

Main category: cs.CL

TL;DR: 本文指出，尽管大语言模型的理解能力增强，但理论心理（即理解和推断他人意图及认知状态的能力）并未同步提升。该因素是评估模型安全性、检测欺骗性行为的核心。文中系统性评估了开源LLMs在该方面的发展，结果显示理论心理能力提升有限，现阶段安全评估和风险识别依然困难。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）能力的提升，模型安全性评估需求日益迫切，尤其是有关模型可能以隐蔽和欺骗性方式绕过监管机制的担忧。作者希望确认LLMs是否存在通过理论型心理机制有意掩饰行为的风险。

Method: 回顾和分析关于理论心理（theory of mind）的现有研究，提炼其在安全评估中的相关任务和视角，然后选取多个开源权重LLMs，通过与心理发展趋势相关的任务评估其理论心理能力发展情况。

Result: LLMs在阅读理解能力方面取得了显著进步，但其理论心理能力的发展并不明显，与阅读理解的提升不相当。

Conclusion: 目前LLMs的理论心理能力有限，在安全评估中特别是在识别潜在欺骗行为方面仍面临重大挑战，未来仍需针对其理论心理能力的提升进行深入研究。

Abstract: As the capabilities of large language models (LLMs) continue to advance, the
importance of rigorous safety evaluation is becoming increasingly evident.
Recent concerns within the realm of safety assessment have highlighted
instances in which LLMs exhibit behaviors that appear to disable oversight
mechanisms and respond in a deceptive manner. For example, there have been
reports suggesting that, when confronted with information unfavorable to their
own persistence during task execution, LLMs may act covertly and even provide
false answers to questions intended to verify their behavior.To evaluate the
potential risk of such deceptive actions toward developers or users, it is
essential to investigate whether these behaviors stem from covert, intentional
processes within the model. In this study, we propose that it is necessary to
measure the theory of mind capabilities of LLMs. We begin by reviewing existing
research on theory of mind and identifying the perspectives and tasks relevant
to its application in safety evaluation. Given that theory of mind has been
predominantly studied within the context of developmental psychology, we
analyze developmental trends across a series of open-weight LLMs. Our results
indicate that while LLMs have improved in reading comprehension, their theory
of mind capabilities have not shown comparable development. Finally, we present
the current state of safety evaluation with respect to LLMs' theory of mind,
and discuss remaining challenges for future work.

</details>


### [58] [Cash or Comfort? How LLMs Value Your Inconvenience](https://arxiv.org/abs/2506.17367)
*Mateusz Cedro,Timour Ichmoukhamedov,Sofie Goethals,Yifan He,James Hinns,David Martens*

Main category: cs.CL

TL;DR: 本研究发现几种主流大语言模型对用户不适的金钱价值评估非常不一致且容易受提示措辞影响，偶尔还会做出违背常理的决策。这表明现有LLMs不可靠于处理涉及用户舒适与金钱权衡的决策问题，需要进一步改进。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）正被用作能够替人类进行日常决策的近自主人工智能代理，但其在涉及金钱与用户舒适度权衡的个人决策行为尚未被充分研究。

Method: 通过让多个LLM针对不同类型用户不适（额外步行、等待、饥饿和疼痛），量化其所需补偿价格，并分析LLM之间及同一LLM内对提示变化的反应差异。

Result: 发现1）不同LLM给出的补偿价格差异极大；2）单个LLM对提示方式非常敏感，轻微措辞变化就会显著改变决策；3）LLM往往愿意以极低补偿接受重大不便（如用1欧元换取10小时等待）；4）在没有任何不适的情况下，LLM有时会拒绝明显奖励（如1000欧元换0分钟等待）。

Conclusion: 当前LLMs在衡量人类不便的金钱价值方面存在严重不一致和漏洞，因此在作为决策助手应用时有必要进行更严谨的审查，特别是在涉及金钱与舒适权衡的场景。

Abstract: Large Language Models (LLMs) are increasingly proposed as near-autonomous
artificial intelligence (AI) agents capable of making everyday decisions on
behalf of humans. Although LLMs perform well on many technical tasks, their
behaviour in personal decision-making remains less understood. Previous studies
have assessed their rationality and moral alignment with human decisions.
However, the behaviour of AI assistants in scenarios where financial rewards
are at odds with user comfort has not yet been thoroughly explored. In this
paper, we tackle this problem by quantifying the prices assigned by multiple
LLMs to a series of user discomforts: additional walking, waiting, hunger and
pain. We uncover several key concerns that strongly question the prospect of
using current LLMs as decision-making assistants: (1) a large variance in
responses between LLMs, (2) within a single LLM, responses show fragility to
minor variations in prompt phrasing (e.g., reformulating the question in the
first person can considerably alter the decision), (3) LLMs can accept
unreasonably low rewards for major inconveniences (e.g., 1 Euro to wait 10
hours), and (4) LLMs can reject monetary gains where no discomfort is imposed
(e.g., 1,000 Euro to wait 0 minutes). These findings emphasize the need for
scrutiny of how LLMs value human inconvenience, particularly as we move toward
applications where such cash-versus-comfort trade-offs are made on users'
behalf.

</details>


### [59] [Leveraging LLMs to Assess Tutor Moves in Real-Life Dialogues: A Feasibility Study](https://arxiv.org/abs/2506.17410)
*Danielle R. Thomas,Conrad Borchers,Jionghao Lin,Sanjit Kakarla,Shambhavi Bhushan,Erin Gatz,Shivang Gupta,Ralph Abboud,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: 本文证明了以GPT-4等大模型分析家教语音转录文本，能高效、准确评估关键家教行为，且与人工判断高度一致，提出了可扩展低成本的AI辅助家教评估方案，并开放提示词促进可复现性。


<details>
  <summary>Details</summary>
Motivation: 传统的家教在提升学生学习成绩上效果显著，但如何基于大规模音频转录记录自动识别和研究有效的家教行为仍是难题。本文旨在探索采用生成式AI（尤其大语言模型）来高效、可扩展地识别和评估真实数学家教过程中的关键行为。

Method: 对50份真实的大学生远程辅导中学生数学的音频转录文本，分别用GPT-4、GPT-4o、GPT-4-turbo、Gemini-1.5-pro和LearnLM五个大模型，检测两个关键家教技能：有效称赞和对学生数学错误的回应。评估这些模型检测相关场景（如家教称赞学生、学生出现错误）的准确率，以及模型判断辅导行为是否符合最佳实践的表现，并与人工标注结果进行比对。

Result: 各大语言模型都能较高准确率检测关键情境（如称赞检测准确率为94-98%，错误检测为82-88%）；模型评判家教是否符合最佳实践的结果与人工一致性较高（分别为83-89%和73-77%）。论文还提出了一种性价比高的模型提示词策略，并开放相关提示词以促进可复现性。

Conclusion: 生成式大语言模型可以准确、高效地在大规模真实家教场景中检测和评价关键教学行为，为AI辅助的大规模家教评价和教育研究提供了可行路径。论文建议相关研究者和实践者可借助这些模型与策略，实现低成本、高效的家教过程分析和反馈。

Abstract: Tutoring improves student achievement, but identifying and studying what
tutoring actions are most associated with student learning at scale based on
audio transcriptions is an open research problem. This present study
investigates the feasibility and scalability of using generative AI to identify
and evaluate specific tutor moves in real-life math tutoring. We analyze 50
randomly selected transcripts of college-student remote tutors assisting middle
school students in mathematics. Using GPT-4, GPT-4o, GPT-4-turbo,
Gemini-1.5-pro, and LearnLM, we assess tutors' application of two tutor skills:
delivering effective praise and responding to student math errors. All models
reliably detected relevant situations, for example, tutors providing praise to
students (94-98% accuracy) and a student making a math error (82-88% accuracy)
and effectively evaluated the tutors' adherence to tutoring best practices,
aligning closely with human judgments (83-89% and 73-77%, respectively). We
propose a cost-effective prompting strategy and discuss practical implications
for using large language models to support scalable assessment in authentic
settings. This work further contributes LLM prompts to support reproducibility
and research in AI-supported learning.

</details>


### [60] [UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making](https://arxiv.org/abs/2506.17419)
*Jinhao Duan,James Diffenderfer,Sandeep Madireddy,Tianlong Chen,Bhavya Kailkhura,Kaidi Xu*

Main category: cs.CL

TL;DR: 大语言模型多步决策不确定性长期被忽视。作者提出UProp算法，有效分解与量化外在不确定性，在多个多步任务和SOTA模型上显著超越现有基线，为实际应用中的LLM安全可靠决策提供新工具。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）被广泛应用于安全关键场景，自主决策逐步融入现实世界。为了提升模型可用性，研究何时可以信任这些决策变得尤为重要。但现有的不确定性量化（UQ）方法主要面向单步问答任务，缺乏对多步决策情景的有效探索与工具。

Method: 本文提出了一个基于信息论的分解框架，将LLM在连续决策过程中的不确定性分为内在不确定性（特定决策点本身的不确定性，现有UQ覆盖）和外在不确定性（来自前序决策的信息不确定性，使用互信息量化）。进而，文中提出了UProp算法，通过对多个轨迹相关决策过程（TDP）中的点互信息（PMI）进行估算，有效、高效地估算外在不确定性。

Result: UProp在多步决策任务（如AgentBench和HotpotQA）和前沿LLM（GPT-4.1、DeepSeek-V3）上进行了大量实证测试，显著优于单步不确定性量化基线（考虑先进聚合策略）的方法。同时给出了详细的采样效率分析、应用前景探讨以及中间不确定性传递机制，有力论证了UProp的有效性。

Conclusion: 本文开创性地提出并验证了LLM多步决策场景下的外在不确定性量化方法UProp，填补了现有方法在连续决策不确定性建模方面的不足，为提升LLM在安全关键任务中的可靠性与可信性奠定基础。

Abstract: As Large Language Models (LLMs) are integrated into safety-critical
applications involving sequential decision-making in the real world, it is
essential to know when to trust LLM decisions. Existing LLM Uncertainty
Quantification (UQ) methods are primarily designed for single-turn
question-answering formats, resulting in multi-step decision-making scenarios,
e.g., LLM agentic system, being underexplored. In this paper, we introduce a
principled, information-theoretic framework that decomposes LLM sequential
decision uncertainty into two parts: (i) internal uncertainty intrinsic to the
current decision, which is focused on existing UQ methods, and (ii) extrinsic
uncertainty, a Mutual-Information (MI) quantity describing how much uncertainty
should be inherited from preceding decisions. We then propose UProp, an
efficient and effective extrinsic uncertainty estimator that converts the
direct estimation of MI to the estimation of Pointwise Mutual Information (PMI)
over multiple Trajectory-Dependent Decision Processes (TDPs). UProp is
evaluated over extensive multi-step decision-making benchmarks, e.g.,
AgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and
DeepSeek-V3. Experimental results demonstrate that UProp significantly
outperforms existing single-turn UQ baselines equipped with thoughtful
aggregation strategies. Moreover, we provide a comprehensive analysis of UProp,
including sampling efficiency, potential applications, and intermediate
uncertainty propagation, to demonstrate its effectiveness. Codes will be
available at https://github.com/jinhaoduan/UProp.

</details>


### [61] [Beyond the Link: Assessing LLMs' ability to Classify Political Content across Global Media](https://arxiv.org/abs/2506.17435)
*Alberto Martinez-Serra,Alejandro De La Fuente,Nienke Viescher,Ana S. Cardenal*

Main category: cs.CL

TL;DR: 本文系统评估多种大语言模型仅利用URL区分新闻政治内容的能力，发现结果与全文分析和人工标注接近，为政治科学研究提供了高效可行的新方法，并给出了实际应用建议。


<details>
  <summary>Details</summary>
Motivation: 近年来，大语言模型（LLM）在政治科学、特别是数字媒体分析中的应用变得日益普遍。尽管现有研究已证明LLM在标注任务上的能力，但其仅通过URL对政治内容进行分类的有效性尚未被充分探讨。

Method: 本研究通过评估LLM（包括GPT、Llama、Mistral、Deepseek、Qwen和Gemma）识别PC（政治内容）与非PC的准确性，比较了模型基于文章全文和仅URL进行分类的表现。数据涵盖法国、德国、西班牙、英国和美国的多语言新闻。通过与人工标注和传统监督学习基线方法进行对比，验证LLM能力。

Result: 实验结果表明，URL中往往包含了大部分新闻内容信息，LLM仅通过URL对政治内容进行分类的效果与人工标注和全文分析的结果接近。

Conclusion: LLM基于URL对新闻政治属性分类具有较强能力，为政治科学中的效率与准确性平衡提供了新思路。研究还讨论了当前方法的局限性，并提出了在政治科学中应用LLM的具体方法建议。

Abstract: The use of large language models (LLMs) is becoming common in the context of
political science, particularly in studies that analyse individuals use of
digital media. However, while previous research has demonstrated LLMs ability
at labelling tasks, the effectiveness of using LLMs to classify political
content (PC) from just URLs is not yet well explored. The work presented in
this article bridges this gap by evaluating whether LLMs can accurately
identify PC vs. non-PC from both the article text and the URLs from five
countries (France, Germany, Spain, the UK, and the US) and different languages.
Using cutting-edge LLMs like GPT, Llama, Mistral, Deepseek, Qwen and Gemma, we
measure model performance to assess whether URL-level analysis can be a good
approximation for full-text analysis of PC, even across different linguistic
and national contexts. Model outputs are compared with human-labelled articles,
as well as traditional supervised machine learning techniques, to set a
baseline of performance. Overall, our findings suggest the capacity of URLs to
embed most of the news content, providing a vital perspective on accuracy-cost
balancing. We also account for contextual limitations and suggest
methodological recommendations to use LLMs within political science studies.

</details>


### [62] [Breaking the Transcription Bottleneck: Fine-tuning ASR Models for Extremely Low-Resource Fieldwork Languages](https://arxiv.org/abs/2506.17459)
*Siyu Liang,Gina-Anne Levow*

Main category: cs.CL

TL;DR: 论文比较分析了MMS和XLS-R两种多语种语音识别模型在低资源语言下的表现，提出在训练数据极少时选MMS，数据量足够时用XLS-R，并为田野语言学者提供了具体且可操作的ASR使用建议。


<details>
  <summary>Details</summary>
Motivation: 尽管ASR在高资源语言上表现优异，但面对田野调查场景下的低资源、噪音与自然口语数据仍有诸多局限。该研究旨在提升ASR在语言学田野工作的实际应用价值，尤其是缓解少数及濒危语言资料的转录难题。

Method: 对两种经过微调的多语种ASR模型——MMS与XLS-R，在五种类型多样的低资源语言上进行基准测试，并控制训练数据的时间长度，检测其在田野录音数据上的表现。

Result: MMS模型在极小训练数据下效果更好；XLS-R一旦训练数据量超过一小时性能与MMS相当。研究还对ASR模型适应性进行语言学视角分析，并为实际田野工作提供复现性强的解决路径。

Conclusion: 本研究表明：针对田野语言录音数据，当训练数据量极少时，MMS模型表现更好；而当训练数据超过一小时时，XLS-R模型表现可与MMS持平。通过语言学分析，为田野语言学工作者提供了实用的ASR选型和适应建议，从而缓解语言文献整理过程中的转录瓶颈。

Abstract: Automatic Speech Recognition (ASR) has reached impressive accuracy for
high-resource languages, yet its utility in linguistic fieldwork remains
limited. Recordings collected in fieldwork contexts present unique challenges,
including spontaneous speech, environmental noise, and severely constrained
datasets from under-documented languages. In this paper, we benchmark the
performance of two fine-tuned multilingual ASR models, MMS and XLS-R, on five
typologically diverse low-resource languages with control of training data
duration. Our findings show that MMS is best suited when extremely small
amounts of training data are available, whereas XLS-R shows parity performance
once training data exceed one hour. We provide linguistically grounded analysis
for further provide insights towards practical guidelines for field linguists,
highlighting reproducible ASR adaptation approaches to mitigate the
transcription bottleneck in language documentation.

</details>


### [63] [Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems](https://arxiv.org/abs/2506.17467)
*Weixin Liang*

Main category: cs.CL

TL;DR: 本论文系统研究了语言大模型（LLMs）普及对个人和机构带来的影响，揭示AI检测工具可能导致的群体性不公，以及LLMs在各类写作场景中的广泛应用，并证实LLMs可为资源有限的研究者提供有效学术反馈。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的快速普及对个人和机构带来了重大影响。研究迫切需要探讨：1）AI检测器带来的公正性和偏见问题，2）LLMs在写作领域的普及现状和影响，3）LLMs对学术写作反馈的潜力及其在资源有限环境下对研究人员的支持作用。

Method: 论文采用三条研究路径：第一，实证分析AI检测器的使用及其对不同语言背景作者的影响；第二，设计并应用群体级的算法方法，定量检测LLMs在多个写作领域的应用；第三，进行大规模实证分析LLMs为研究手稿提供反馈的能力及其效果。

Result: 发现AI检测器在制度化使用中系统性地歧视非主流语言作者，产生公平问题。通过大规模数据分析，揭示LLMs已在学术评审、科学文献、消费者投诉、公司沟通、招聘信息及国际组织新闻稿中被广泛使用。最后，证实LLMs可为学术手稿提供有益反馈，有助于弥补早期研究人员和欠资源环境下研究者的反馈缺口。

Conclusion: 本文指出，LLMs的普及在带来便利的同时也引入了风险与不平等，尤其是AI检测工具可能引发的群体性偏见。制度在采用AI工具时应重视公平与包容性。同时，LLMs可作为提升学术写作支持和公平性的重要工具，尤其能帮助弱势群体获得研究反馈。

Abstract: Large language models (LLMs) have shown significant potential to change how
we write, communicate, and create, leading to rapid adoption across society.
This dissertation examines how individuals and institutions are adapting to and
engaging with this emerging technology through three research directions.
First, I demonstrate how the institutional adoption of AI detectors introduces
systematic biases, particularly disadvantaging writers of non-dominant language
varieties, highlighting critical equity concerns in AI governance. Second, I
present novel population-level algorithmic approaches that measure the
increasing adoption of LLMs across writing domains, revealing consistent
patterns of AI-assisted content in academic peer reviews, scientific
publications, consumer complaints, corporate communications, job postings, and
international organization press releases. Finally, I investigate LLMs'
capability to provide feedback on research manuscripts through a large-scale
empirical analysis, offering insights into their potential to support
researchers who face barriers in accessing timely manuscript feedback,
particularly early-career researchers and those from under-resourced settings.

</details>


### [64] [VeriLocc: End-to-End Cross-Architecture Register Allocation via LLM](https://arxiv.org/abs/2506.17506)
*Lesheng Jin,Zhenyuan Ruan,Haohui Mai,Jingbo Shang*

Main category: cs.CL

TL;DR: VeriLocc结合LLM和正式验证，实现高效、泛化且准确的GPU寄存器分配，性能超越业界专家手工调优方案。


<details>
  <summary>Details</summary>
Motivation: 现有GPU的编译器寄存器分配依赖人工设计的启发式算法，每更换硬件时需大量调优，效率低下、难以泛化。

Method: 提出了VeriLocc框架，将大语言模型与形式化编译技术结合。框架通过微调LLM，将中间表示(MIR)翻译为目标寄存器分配，并结合静态分析实现跨架构的归一化和泛化，还引入了验证驱动的重生循环以保证正确性。

Result: 在GEMM和MHA任务上，VeriLocc实现了85-99%的单次准确率和近100%的pass@100，个案显示其分配优于专家调优库，运行时间比rocBLAS快10%以上。

Conclusion: VeriLocc能泛化且可验证地提升GPU寄存器分配效率和性能，优于传统手工启发式与专家库，展现了LLM结合形式化技术在编译器优化的潜力。

Abstract: Modern GPUs evolve rapidly, yet production compilers still rely on
hand-crafted register allocation heuristics that require substantial re-tuning
for each hardware generation. We introduce VeriLocc, a framework that combines
large language models (LLMs) with formal compiler techniques to enable
generalizable and verifiable register allocation across GPU architectures.
VeriLocc fine-tunes an LLM to translate intermediate representations (MIRs)
into target-specific register assignments, aided by static analysis for
cross-architecture normalization and generalization and a verifier-guided
regeneration loop to ensure correctness. Evaluated on matrix multiplication
(GEMM) and multi-head attention (MHA), VeriLocc achieves 85-99% single-shot
accuracy and near-100% pass@100. Case study shows that VeriLocc discovers more
performant assignments than expert-tuned libraries, outperforming rocBLAS by
over 10% in runtime.

</details>


### [65] [Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning](https://arxiv.org/abs/2506.17525)
*Mingfei Lau,Qian Chen,Yeming Fang,Tingting Xu,Tongzhou Chen,Pavel Golik*

Main category: cs.CL

TL;DR: 对主流多语言语音数据集的质量进行了系统分析，发现欠资源语言面临更严重的宏观质量问题，并以台语为例提出了改进建议，呼吁在数据集建设中重视社会语言学因素。


<details>
  <summary>Details</summary>
Motivation: 目前主流多语言语音数据集在部分语言上存在严重的质量问题，尤其对欠资源语言影响更大，急需提升数据集的质量以促进训练和评估的有效性。

Method: 对Mozilla Common Voice 17.0、FLEURS和VoxPopuli三个主流多语言语音数据集进行质量审计，并以台语（台灣閩南語）为案例分析，归纳数据集问题并提出改进方案。

Result: 发现宏观质量问题在欠资源语言中更突出，对台语数据集深入剖析，并提出未来数据集开发的指导原则和优化建议，以提升ASR数据集整体质量。

Conclusion: 提出了改善多语言语音数据集质量的建议，并强调了社会语言学意识在数据集创建中的重要性。

Abstract: Our quality audit for three widely used public multilingual speech datasets -
Mozilla Common Voice 17.0, FLEURS, and VoxPopuli - shows that in some
languages, these datasets suffer from significant quality issues. We believe
addressing these issues will make these datasets more useful as training and
evaluation sets, and improve downstream models. We divide these quality issues
into two categories: micro-level and macro-level. We find that macro-level
issues are more prevalent in less institutionalized, often under-resourced
languages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that
highlights the need for proactive language planning (e.g. orthography
prescriptions, dialect boundary definition) and enhanced data quality control
in the process of Automatic Speech Recognition (ASR) dataset creation. We
conclude by proposing guidelines and recommendations to mitigate these issues
in future dataset development, emphasizing the importance of sociolinguistic
awareness in creating robust and reliable speech data resources.

</details>


### [66] [DuaShepherd: Integrating Stepwise Correctness and Potential Rewards for Mathematical Reasoning](https://arxiv.org/abs/2506.17533)
*Yuanhao Wu,Juntong Song,Hanning Zhang,Tong Zhang,Cheng Niu*

Main category: cs.CL

TL;DR: 该文提出结合“正确性”和“潜力”的双奖励信号，用于训练大型语言模型数学能力。新方法在多个数据集上大幅提升模型表现，创下最新最佳成绩。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在数学推理任务中的能力还有提升空间。传统的奖励建模多以“正确性”为单一奖励信号，忽略了模型在推理过程中的发展潜力。该文提出结合两种互补奖励信号，以提升模型推理和解题能力。

Method: 提出DuaShepherd奖励建模框架，结合“正确性”（纠错能力）和“潜力”（抵达正确答案的可能性）两种信号。开发自动化数据集构建流程，生成含两种奖励大规模训练数据。采用多头多任务架构，联合训练两种奖励模型，并组合为复合概率用于最终评估。

Result: 在MATH500和ProcessBench基准测试中，DuaShepherd在相同算力资源下，比仅使用单一奖励信号的模型取得更好成绩，实现了新的最优结果。

Conclusion: 结合正确性与潜力的奖励信号能协同提升LLM的数学推理能力，DuaShepherd实现了业界领先表现，证明双信号奖励策略有效。

Abstract: In this paper, we propose DuaShepherd, a novel reward modeling framework that
integrates two complementary reward signals, correctness and potential, to
enhance the mathematical reasoning capabilities of Large Language Models
(LLMs). While correctness-based signals emphasize identification of stepwise
errors, potential-based signals focus on the likelihood of reaching the correct
final answer. We developed an automated pipeline for constructing large-scale
reward modeling dataset with both signals. A unified, multi-head architecture
was explored to train the two reward models in a multi-task setup,
demonstrating benefits from learning both correctness and potential in
parallel. By combining these two signals into a compound probability, our model
achieves consistent performance improvements across multiple benchmarks.
Empirical evaluations on MATH500 and ProcessBench confirm that this combined
reward significantly outperforms models trained on either reward type alone,
achieving state-of-the-art performance under comparable resource constraints.

</details>


### [67] [Probing for Phonology in Self-Supervised Speech Representations: A Case Study on Accent Perception](https://arxiv.org/abs/2506.17542)
*Nitin Venkateswaran,Kevin Tang,Ratree Wayland*

Main category: cs.CL

TL;DR: 本研究发现，当前自监督语音模型的预训练特征可以有效捕捉影响口音感知的音系特征变化，并能够有解释性地建模口音强度。


<details>
  <summary>Details</summary>
Motivation: 传统的口音感知模型低估了语音特征的梯度变化对听众作出口音判断的作用。本研究旨在深入了解自监督学习（SSL）语音模型预训练表示是否能够有效编码在口音感知中关键的音系特征变化。

Method: 聚焦于三种特定辅音（唇齿近音、闪音r、卷舌塞音），从CSLU外国口音英语语料库中提取相关片段，结合Phonet工具提取音系特征概率，以及利用Wav2Vec2-BERT和WavLM等模型的预训练表示，并结合美语母语者的口音判断。用探查式分析和多项Logistic回归，考察预训练特征与口音感知间的关系。

Result: 发现能够较好预测口音强度的是一部分预训练的分段表示特征，其中感知显著的音系特征（区分美式英语和印度次大陆英语）获得了较高权重。以预训练表示为基础的片段与美式英语和印度英语基线之间的距离与口音强度评分有显著关联，方向符合预期。

Conclusion: 自监督语音表示在建模基于可解释音系特征的口音感知方面具有重要价值。

Abstract: Traditional models of accent perception underestimate the role of gradient
variations in phonological features which listeners rely upon for their accent
judgments. We investigate how pretrained representations from current
self-supervised learning (SSL) models of speech encode phonological
feature-level variations that influence the perception of segmental accent. We
focus on three segments: the labiodental approximant, the rhotic tap, and the
retroflex stop, which are uniformly produced in the English of native speakers
of Hindi as well as other languages in the Indian sub-continent. We use the
CSLU Foreign Accented English corpus (Lander, 2007) to extract, for these
segments, phonological feature probabilities using Phonet (V\'asquez-Correa et
al., 2019) and pretrained representations from Wav2Vec2-BERT (Barrault et al.,
2023) and WavLM (Chen et al., 2022) along with accent judgements by native
speakers of American English. Probing analyses show that accent strength is
best predicted by a subset of the segment's pretrained representation features,
in which perceptually salient phonological features that contrast the expected
American English and realized non-native English segments are given prominent
weighting. A multinomial logistic regression of pretrained representation-based
segment distances from American and Indian English baselines on accent ratings
reveals strong associations between the odds of accent strength and distances
from the baselines, in the expected directions. These results highlight the
value of self-supervised speech representations for modeling accent perception
using interpretable phonological features.

</details>


### [68] [AgriCHN: A Comprehensive Cross-domain Resource for Chinese Agricultural Named Entity Recognition](https://arxiv.org/abs/2506.17578)
*Lingxiao Zeng,Yiqi Tong,Wei Guo,Huarui Wu,Lihao Ge,Yijun Ye,Fuzhen Zhuang,Deqing Wang,Wei Guo,Cheng Chen*

Main category: cs.CL

TL;DR: 本论文提出了AgriCHN，一个覆盖农业、水文、气象等领域的高质量中文农业NER数据集。数据质量优良，类别丰富，为NER方法研究提供了有价值的新资源和实验平台。


<details>
  <summary>Details</summary>
Motivation: 农业命名实体识别（NER）任务对于从大量农业文本中提取信息非常关键。然而，受限于高质量农业数据集（特别是中文资源）的稀缺，现有主流方法效果不佳。此外，既有工作多聚焦于农业实体本身，忽视了农业与水文、气象等领域的深度相关。

Method: 研究者提出了AgriCHN，这是一个面向中文农业领域的综合性开源资源。数据集来自大量农业相关文章，包含4,040个句子和15,799个实体提及，涵盖27种多样的实体类别，包括水文和气象领域。通过对比实验评估数据集质量，并基于多种主流神经网络NER模型构建基准任务进行实验。

Result: AgriCHN数据集相较于相关资源质量更高，实体类型更丰富、划分更细致。实验结果表明AgriCHN具有较大挑战性和研究潜力。

Conclusion: AgriCHN极大丰富和提升了中文农业实体识别任务的数据资源基础，并为跨学科农业信息抽取研究提供了有力支撑。该数据集因挑战性强和覆盖面广，有望促进相关NER方法的进一步发展。

Abstract: Agricultural named entity recognition is a specialized task focusing on
identifying distinct agricultural entities within vast bodies of text,
including crops, diseases, pests, and fertilizers. It plays a crucial role in
enhancing information extraction from extensive agricultural text resources.
However, the scarcity of high-quality agricultural datasets, particularly in
Chinese, has resulted in suboptimal performance when employing mainstream
methods for this purpose. Most earlier works only focus on annotating
agricultural entities while overlook the profound correlation of agriculture
with hydrology and meteorology. To fill this blank, we present AgriCHN, a
comprehensive open-source Chinese resource designed to promote the accuracy of
automated agricultural entity annotation. The AgriCHN dataset has been
meticulously curated from a wealth of agricultural articles, comprising a total
of 4,040 sentences and encapsulating 15,799 agricultural entity mentions
spanning 27 diverse entity categories. Furthermore, it encompasses entities
from hydrology to meteorology, thereby enriching the diversity of entities
considered. Data validation reveals that, compared with relevant resources,
AgriCHN demonstrates outstanding data quality, attributable to its richer
agricultural entity types and more fine-grained entity divisions. A benchmark
task has also been constructed using several state-of-the-art neural NER
models. Extensive experimental results highlight the significant challenge
posed by AgriCHN and its potential for further research.

</details>


### [69] [Mind the Gap: Assessing Wiktionary's Crowd-Sourced Linguistic Knowledge on Morphological Gaps in Two Related Languages](https://arxiv.org/abs/2506.17603)
*Jonathan Sakunkoo,Annabella Sakunkoo*

Main category: cs.CL

TL;DR: 本文定制神经形态分析器，自动检验拉丁语和意大利语中众包（主要指维基词典）收集的缺陷动词的可靠性，发现维基词典对意语准确但对拉丁语有不足，强调了对此类数据自动质控的重要性，也为丰富形态学和稀有语言知识提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 形态缺陷性是语言学中一个有趣且研究不足的现象，指的是某些预期词形变化形式的缺失。传统资源难以全面覆盖这类稀有现象，因此实际分析和文档化极具挑战，尤其是在资料稀缺的语言中。人们常用维基百科和维基词典等众包资源作为替代，但这些资源的可靠性存在争议。

Method: 该研究定制了一种新型神经形态分析器，用于对拉丁语和意大利语语料库进行注释。基于这个大规模标注数据，进一步对从维基词典整理的缺陷动词列表进行计算验证。

Result: 结果显示，维基词典对于意大利语的形态缺陷词条高度可靠，但对拉丁语中列为缺陷的词条，有7%被语料证据判定为并非真正的缺陷形式。这揭示了众包资源在处理部分少见语言现象时的局限性。

Conclusion: 本研究为缺陷形态的研究尤其是在拉丁语、意大利语等形态丰富、但非英语的语言中，提供了大规模的自动化质控工具，推动了计算形态学和稀有语言知识的扩展。

Abstract: Morphological defectivity is an intriguing and understudied phenomenon in
linguistics. Addressing defectivity, where expected inflectional forms are
absent, is essential for improving the accuracy of NLP tools in morphologically
rich languages. However, traditional linguistic resources often lack coverage
of morphological gaps as such knowledge requires significant human expertise
and effort to document and verify. For scarce linguistic phenomena in
under-explored languages, Wikipedia and Wiktionary often serve as among the few
accessible resources. Despite their extensive reach, their reliability has been
a subject of controversy. This study customizes a novel neural morphological
analyzer to annotate Latin and Italian corpora. Using the massive annotated
data, crowd-sourced lists of defective verbs compiled from Wiktionary are
validated computationally. Our results indicate that while Wiktionary provides
a highly reliable account of Italian morphological gaps, 7% of Latin lemmata
listed as defective show strong corpus evidence of being non-defective. This
discrepancy highlights potential limitations of crowd-sourced wikis as
definitive sources of linguistic knowledge, particularly for less-studied
phenomena and languages, despite their value as resources for rare linguistic
features. By providing scalable tools and methods for quality assurance of
crowd-sourced data, this work advances computational morphology and expands
linguistic knowledge of defectivity in non-English, morphologically rich
languages.

</details>


### [70] [Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives](https://arxiv.org/abs/2506.18116)
*Batool Haider,Atmika Gorti,Aman Chadha,Manas Gaur*

Main category: cs.CL

TL;DR: 本文提出用多跳问答检测LLM心理健康话语中的细致交叉性偏见，评估4种主流模型，揭示各类偏见放大点，采用Few-shot去偏方法可显著降低偏见，为公平AI提供有力手段。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在心理健康领域有可能传播偏见，加剧对边缘群体的伤害，但现有检测模型交叉性偏见的系统方法有限。本文受此挑战驱动，旨在提出和验证一种系统化的检测方案。

Method: 提出多跳问答（MHQA）框架以系统检测心理健康话语中的LLM回复偏见；对IMHI数据集内容按照年龄、种族、性别和社会经济状态进行标签，分析不同人口交叉点的偏见；对Claude 3.5 Sonnet、Jamba 1.6、Gemma 3和Llama 4等四个LLM进行评估；采用角色扮演模拟和显式偏见消除两种去偏方法，并通过BBQ数据的few-shot 提示进行训练。

Result: MHQA方法在检测偏见方面优于传统方法，能识别顺推推理中偏见的放大点；两种去偏技术可通过few-shot prompting实现66-94%的偏见减少。

Conclusion: LLMs在心理健康话语中确实存在系统性偏见，甚至在细分人群交叉处放大。提出的MHQA检测框架和去偏技术为更公平的AI开发提供了有效工具和实践建议。

Abstract: Large Language Models (LLMs) in mental healthcare risk propagating biases
that reinforce stigma and harm marginalized groups. While previous research
identified concerning trends, systematic methods for detecting intersectional
biases remain limited. This work introduces a multi-hop question answering
(MHQA) framework to explore LLM response biases in mental health discourse. We
analyze content from the Interpretable Mental Health Instruction (IMHI) dataset
across symptom presentation, coping mechanisms, and treatment approaches. Using
systematic tagging across age, race, gender, and socioeconomic status, we
investigate bias patterns at demographic intersections. We evaluate four LLMs:
Claude 3.5 Sonnet, Jamba 1.6, Gemma 3, and Llama 4, revealing systematic
disparities across sentiment, demographics, and mental health conditions. Our
MHQA approach demonstrates superior detection compared to conventional methods,
identifying amplification points where biases magnify through sequential
reasoning. We implement two debiasing techniques: Roleplay Simulation and
Explicit Bias Reduction, achieving 66-94% bias reductions through few-shot
prompting with BBQ dataset examples. These findings highlight critical areas
where LLMs reproduce mental healthcare biases, providing actionable insights
for equitable AI development.

</details>


### [71] [TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting](https://arxiv.org/abs/2506.17609)
*Lincan Li,Eren Erman Ozguven,Yue Zhao,Guang Wang,Yiqun Xie,Yushun Dong*

Main category: cs.CL

TL;DR: TyphoFormer 结合数值和语言信息，极大提升了台风路径预测表现，特别适用于路径变化剧烈或观测数据稀少的场景。


<details>
  <summary>Details</summary>
Motivation: 台风路径预测对于预警和灾害响应非常关键，但现有 Transformer 模型虽然能处理人类和车辆的轨迹，却难以获得增强气象轨迹预测可靠性的上下文知识，特别是对于较稀疏的台风轨迹信息。

Method: 提出 TyphoFormer，一种融合自然语言描述作为辅助提示词的预测框架，利用大语言模型针对每个时间步生成简洁的气象文本描述，并将其作为特殊 token 与数值时间序列一起输入统一的 Transformer 编码器，从而结合文本和序列信息辅助路径预测。

Result: 在 HURDAT2 基准上，通过大量实验，TyphoFormer 在包括非线性路径变化和历史观测有限等复杂场景下，都显著优于其他最新方法。

Conclusion: TyphoFormer 能够有效利用语言提示融合气象上下文信息，大大提升台风轨迹预测的准确性和鲁棒性。

Abstract: Accurate typhoon track forecasting is crucial for early system warning and
disaster response. While Transformer-based models have demonstrated strong
performance in modeling the temporal dynamics of dense trajectories of humans
and vehicles in smart cities, they usually lack access to broader contextual
knowledge that enhances the forecasting reliability of sparse meteorological
trajectories, such as typhoon tracks. To address this challenge, we propose
TyphoFormer, a novel framework that incorporates natural language descriptions
as auxiliary prompts to improve typhoon trajectory forecasting. For each time
step, we use Large Language Model (LLM) to generate concise textual
descriptions based on the numerical attributes recorded in the North Atlantic
hurricane database. The language descriptions capture high-level meteorological
semantics and are embedded as auxiliary special tokens prepended to the
numerical time series input. By integrating both textual and sequential
information within a unified Transformer encoder, TyphoFormer enables the model
to leverage contextual cues that are otherwise inaccessible through numerical
features alone. Extensive experiments are conducted on HURDAT2 benchmark,
results show that TyphoFormer consistently outperforms other state-of-the-art
baseline methods, particularly under challenging scenarios involving nonlinear
path shifts and limited historical observations.

</details>


### [72] [Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review](https://arxiv.org/abs/2506.18199)
*Bushra Asseri,Estabrag Abdelaziz,Areej Al-Wabil*

Main category: cs.CL

TL;DR: 本文系统梳理了现有通过prompt工程缓解LLM对阿拉伯人和穆斯林偏见的方法，发现结构化多步流程效果最好。研究数量有限，未来需探索更具文化适应性的方法和评价体系。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在许多领域表现出色，但对阿拉伯人和穆斯林的文化偏见引发了伦理关切。这些偏见可能加剧有害的刻板印象和边缘化现象。尽管学界越来越关注LLMs的偏见，针对阿拉伯人和穆斯林表征的prompt工程技术尚未得到充分研究。

Method: 本文采用混合方法系统综述，遵循PRISMA指南和Kitchenham的系统综述方法，对2021-2024年间发表的8项实证研究进行了分析。这些研究关注的是缓解偏见的prompt工程策略。

Result: 研究发现了五类主要的prompt工程方法，分别为文化提示、情感预设、自我去偏技巧、结构化多步流程以及参数优化的连续prompt。这些方法均可减缓偏见，但对不同类型偏见和不同研究效果差异较大。其中，结构化多步流程最为有效，最高可将偏见减少87.7%，但需要更高技术门槛。文化提示方法则兼具可用性和较好效果。

Conclusion: prompt工程能够在无需接触模型参数的情况下缓解文化偏见，为阿拉伯人和穆斯林的公正表征提供了具有实际可行性的手段。但目前实证研究数量有限，存在明显研究空白。未来应开发文化自适应的提示技术、建立专属评价资源，并将prompt工程与其他去偏方法结合，以进一步消除偏见且保持模型实用性。

Abstract: Large language models have demonstrated remarkable capabilities across
various domains, yet concerns about cultural bias - particularly towards Arabs
and Muslims - pose significant ethical challenges by perpetuating harmful
stereotypes and marginalization. Despite growing recognition of bias in LLMs,
prompt engineering strategies specifically addressing Arab and Muslim
representation remain understudied. This mixed-methods systematic review
examines such techniques, offering evidence-based guidance for researchers and
practitioners. Following PRISMA guidelines and Kitchenham's systematic review
methodology, we analyzed 8 empirical studies published between 2021-2024
investigating bias mitigation strategies. Our findings reveal five primary
prompt engineering approaches: cultural prompting, affective priming,
self-debiasing techniques, structured multi-step pipelines, and
parameter-optimized continuous prompts. Although all approaches show potential
for reducing bias, effectiveness varied substantially across studies and bias
types. Evidence suggests that certain bias types may be more resistant to
prompt-based mitigation than others. Structured multi-step pipelines
demonstrated the highest overall effectiveness, achieving up to 87.7% reduction
in bias, though they require greater technical expertise. Cultural prompting
offers broader accessibility with substantial effectiveness. These results
underscore the accessibility of prompt engineering for mitigating cultural bias
without requiring access to model parameters. The limited number of studies
identified highlights a significant research gap in this critical area. Future
research should focus on developing culturally adaptive prompting techniques,
creating Arab and Muslim-specific evaluation resources, and integrating prompt
engineering with complementary debiasing methods to address deeper stereotypes
while maintaining model utility.

</details>


### [73] [OpusLM: A Family of Open Unified Speech Language Models](https://arxiv.org/abs/2506.17611)
*Jinchuan Tian,William Chen,Yifan Peng,Jiatong Shi,Siddhant Arora,Shikhar Bharadwaj,Takashi Maekaku,Yusuke Shinohara,Keita Goto,Xiang Yue,Huck Yang,Shinji Watanabe*

Main category: cs.CL

TL;DR: OpusLMs是一个7B规模的开源语音语言模型家族，在公开数据上预训练，性能优越，覆盖语音识别、语音合成和文本任务，完全开源，促进领域研究。


<details>
  <summary>Details</summary>
Motivation: 当前语音与语言模型领域缺乏大规模、开源并且表现优秀的基础语音语言模型（SpeechLM），许多现有模型缺乏透明性与可复现性，阻碍了该领域的进一步研究与创新。

Method: OpusLMs采用decoder-only文本语言模型作为初始化，并对其进行持续预训练，使用了213,000小时的语音-文本对与2920亿文本token。在模型设计方面，重点在于tokenization（分词方法）、多流语言模型结构和多阶段训练策略。同时，通过实验分析了模型规模扩展和退火式数据选择对于性能的影响。

Result: OpusLMs在语音识别、语音合成以及文本任务中均达到了与现有SpeechLMs可比甚至更优的性能。所有模型基于公开数据构建，具有高度透明性，完整开源了代码、数据、模型权重和训练日志。

Conclusion: OpusLMs作为开源、透明且大规模的语音语言模型，在多个任务上展现了优越性能，有助于推动语音语言模型的开放研究与发展。

Abstract: This paper presents Open Unified Speech Language Models (OpusLMs), a family
of open foundational speech language models (SpeechLMs) up to 7B. Initialized
from decoder-only text language models, the OpusLMs are continuously
pre-trained on 213K hours of speech-text pairs and 292B text-only tokens. We
demonstrate our OpusLMs achieve comparable (or even superior) performance with
existing SpeechLMs in speech recognition, speech synthesis, and text-only
capabilities. Technically, this paper articulates our SpeechLM designs on
tokenization, multi-stream language models, and multi-stage training
strategies. We experimentally demonstrate the importance of model size scaling
and the effect of annealing data selection. The OpusLMs are all built from
publicly available materials and are fully transparent models. We release our
code, data, checkpoints, and training logs to facilitate open SpeechLM research

</details>


### [74] [A Modular Taxonomy for Hate Speech Definitions and Its Impact on Zero-Shot LLM Classification Performance](https://arxiv.org/abs/2506.18576)
*Matteo Melis,Gabriella Lapesa,Dennis Assenmacher*

Main category: cs.CL

TL;DR: 本文分析了仇恨言论不同定义对大模型检测效果的影响，提出14个概念要素的分类体系。实验表明，定义的选择确实影响模型表现，且对不同架构的模型影响不同。


<details>
  <summary>Details</summary>
Motivation: 网络中充斥的有害内容，尤其是仇恨言论，对社会产生严重影响。因此，准确检测仇恨言论成为NLP领域的重要任务。然而，仇恨言论的定义本身存在歧义，不同的定义会潜在影响模型检测的效果。

Method: 该研究首先系统整理和分析相关文献中已有的仇恨言论定义，归纳出14个构成性要素，并据此构建分类法。随后，研究团队基于收集的定义，在三种类型（合成数据、人机协作数据、真实世界数据）的仇恨言论数据集上，对三种大语言模型进行了零样本系统评测，比较不同定义下的检测性能差异。

Result: 研究发现，不同的仇恨言论定义（尤其是在构成要素的具体化程度上的不同）确实会影响模型检测能力，但这一影响在不同模型架构之间并不一致。

Conclusion: 仇恨言论的定义方式会显著影响大语言模型对仇恨言论的检测能力，但这种影响因模型而异，因此在模型应用和基准设定时需更加关注定义的选择和构成要素。

Abstract: Detecting harmful content is a crucial task in the landscape of NLP
applications for Social Good, with hate speech being one of its most dangerous
forms. But what do we mean by hate speech, how can we define it, and how does
prompting different definitions of hate speech affect model performance? The
contribution of this work is twofold. At the theoretical level, we address the
ambiguity surrounding hate speech by collecting and analyzing existing
definitions from the literature. We organize these definitions into a taxonomy
of 14 Conceptual Elements-building blocks that capture different aspects of
hate speech definitions, such as references to the target of hate (individual
or groups) or of the potential consequences of it. At the experimental level,
we employ the collection of definitions in a systematic zero-shot evaluation of
three LLMs, on three hate speech datasets representing different types of data
(synthetic, human-in-the-loop, and real-world). We find that choosing different
definitions, i.e., definitions with a different degree of specificity in terms
of encoded elements, impacts model performance, but this effect is not
consistent across all architectures.

</details>


### [75] [Answer-Centric or Reasoning-Driven? Uncovering the Latent Memory Anchor in LLMs](https://arxiv.org/abs/2506.17630)
*Yang Wu,Yifan Zhang,Yiwei Wang,Yujun Cai,Yurong Wu,Yuran Wang,Ning Xu,Jian Cheng*

Main category: cs.CL

TL;DR: 本研究提出新框架证实LLM推理高度依赖答案提示，推理多为事后合理化而非真正推理，需重新审视其推理能力深度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）展现出强大的推理能力，但越来越多证据表明，这种能力更多依赖于记忆化的答案-推理模式，而非真正的推理。本研究探究了LLMs到底依赖于最终答案本身，还是对推理链的文本模式。

Method: 提出了一个五级答案可见性提示框架，系统地调控答案提示，并通过间接的行为分析探究模型行为。

Result: 实验发现，当屏蔽答案提示，即使给出完整推理链，模型表现也下降了26.90%。这表明LLMs很大程度上依赖于明确的答案提示。

Conclusion: LLMs展示的推理表现更多是事后合理化而不是真正的推理，揭示了答案锚定现象，提醒业界需要重新思考LLM推理能力的本质。

Abstract: While Large Language Models (LLMs) demonstrate impressive reasoning
capabilities, growing evidence suggests much of their success stems from
memorized answer-reasoning patterns rather than genuine inference. In this
work, we investigate a central question: are LLMs primarily anchored to final
answers or to the textual pattern of reasoning chains? We propose a five-level
answer-visibility prompt framework that systematically manipulates answer cues
and probes model behavior through indirect, behavioral analysis. Experiments
across state-of-the-art LLMs reveal a strong and consistent reliance on
explicit answers. The performance drops by 26.90\% when answer cues are masked,
even with complete reasoning chains. These findings suggest that much of the
reasoning exhibited by LLMs may reflect post-hoc rationalization rather than
true inference, calling into question their inferential depth. Our study
uncovers the answer-anchoring phenomenon with rigorous empirical validation and
underscores the need for a more nuanced understanding of what constitutes
reasoning in LLMs.

</details>


### [76] [Step-Opt: Boosting Optimization Modeling in LLMs through Iterative Data Synthesis and Structured Validation](https://arxiv.org/abs/2506.17637)
*Yang Wu,Yifan Zhang,Yurong Wu,Yuran Wang,Junkai Zhang,Jian Cheng*

Main category: cs.CL

TL;DR: 本文提出Step-Opt-Instruct，通过分步生成与验证大幅增强优化建模任务数据，微调后的Step-Opt模型在多个复杂任务上显著优于现有方法，提升了自动化决策的数据质量与性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然在多个领域取得突破，但在解决运筹优化建模特别是复杂问题时仍面临显著挑战。优化领域自动化建模的准确性和鲁棒性需求，驱动了对新方法的探索。

Method: 提出了Step-Opt-Instruct框架，通过迭代生成问题逐步提升难度，并以分步验证保障扩充和生成优化建模数据的质量，防止错误传播。然后，基于此框架使用LLaMA-3-8B和Mistral-7B等开源LLM模型进行微调。

Result: 微调后的Step-Opt模型在NL4OPT、MAMO和IndustryOR等基准测试中表现优越，对高难度问题微平均准确率提升达17.01%。

Conclusion: 结构化验证与逐步复杂化生成结合，显著提升了LLM在复杂运筹优化建模任务中的性能，推动了自动化决策技术的发展。

Abstract: Large Language Models (LLMs) have revolutionized various domains but
encounter substantial challenges in tackling optimization modeling tasks for
Operations Research (OR), particularly when dealing with complex problem. In
this work, we propose Step-Opt-Instruct, a framework that augments existing
datasets and generates high-quality fine-tuning data tailored to optimization
modeling. Step-Opt-Instruct employs iterative problem generation to
systematically increase problem complexity and stepwise validation to
rigorously verify data, preventing error propagation and ensuring the quality
of the generated dataset. Leveraging this framework, we fine-tune open-source
LLMs, including LLaMA-3-8B and Mistral-7B, to develop Step-Opt--a model that
achieves state-of-the-art performance on benchmarks such as NL4OPT, MAMO, and
IndustryOR. Extensive experiments demonstrate the superior performance of
Step-Opt, especially in addressing complex OR tasks, with a notable 17.01\%
improvement in micro average accuracy on difficult problems. These findings
highlight the effectiveness of combining structured validation with gradual
problem refinement to advance the automation of decision-making processes using
LLMs.The code and dataset are available at https://github.com/samwu-learn/Step.

</details>


### [77] [TPTT: Transforming Pretrained Transformer into Titans](https://arxiv.org/abs/2506.17671)
*Fabien Furfaro*

Main category: cs.CL

TL;DR: TPTT框架通过引入高效机制和优化管理，使大型语言模型在不增加大量计算资源的情况下，显著提升了长文本处理能力，且易于在现有模型上部署。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言处理领域取得巨大进展，但其高计算和内存需求，尤其在长文本推理任务中，仍是显著的技术难题。

Method: 提出TPTT（Transforming Pretrained Transformer into Titans）框架，通过引入高效的线性化注意力机制和先进的内存管理（如Memory as Gate和混合线性化注意力LiZA），使预训练Transformer模型能够更高效地使用计算和内存资源。该方法完全兼容Hugging Face Transformers库，可通过参数高效微调（LoRA）快速适配现有LLM，无需完全再训练。

Result: 在MMLU基准测试上，约10亿参数规模的模型使用TPTT后，在效率和准确率上均有显著提升。例如Titans-Llama-3.2-1B模型的准确匹配（EM）指标相比基线提升了20%。统计分析及对比实验显示TPTT具备良好的可扩展性和鲁棒性。

Conclusion: TPTT能够高效提升预训练Transformer模型的长文本推理能力与整体表现，适配主流开源平台且易于集成，具有实际应用价值。

Abstract: Recent advances in large language models (LLMs) have led to remarkable
progress in natural language processing, but their computational and memory
demands remain a significant challenge, particularly for long-context
inference. We introduce TPTT (Transforming Pretrained Transformer into Titans),
a novel framework for enhancing pretrained Transformer models with efficient
linearized attention mechanisms and advanced memory management. TPTT employs
techniques such as Memory as Gate (MaG) and mixed linearized attention (LiZA).
It is fully compatible with the Hugging Face Transformers library, enabling
seamless adaptation of any causal LLM through parameter-efficient fine-tuning
(LoRA) without full retraining. We show the effectiveness of TPTT on the MMLU
benchmark with models of approximately 1 billion parameters, observing
substantial improvements in both efficiency and accuracy. For instance,
Titans-Llama-3.2-1B achieves a 20% increase in Exact Match (EM) over its
baseline. Statistical analyses and comparisons with recent state-of-the-art
methods confirm the practical scalability and robustness of TPTT. Code is
available at https://github.com/fabienfrfr/tptt . Python package at
https://pypi.org/project/tptt/ .

</details>


### [78] [Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering](https://arxiv.org/abs/2506.17692)
*Binquan Ji,Haibo Luo,Yifei Lu,Lei Hei,Jiaqi Wang,Tingjing Liao,Lingyu Wang,Shichao Wang,Feiliang Ren*

Main category: cs.CL

TL;DR: 本文针对知识密集型多跳问答任务，提出了动态增强链(DEC)框架，实现了更高效、低成本且准确的复杂问题解答，尤其适用于小型语言模型。


<details>
  <summary>Details</summary>
Motivation: 多跳问答任务需要整合来自多个信息源的证据，应对复杂问题，对于参数较少的小型大语言模型，处理大量文档和长上下文会带来幻觉和语义漂移等挑战。

Method: 提出了Dynamic Enhancement Chain(DEC)框架，首先将复杂问题分解为逻辑连贯的子问题，形成无幻觉的推理链；随后结合上下文对这些子问题进行重写提升查询效果。检索模块使用轻量判别式关键词抽取，更高效精准地召回相关文档。

Result: 在三个多跳问答数据集上的大量实验表明，DEC表现与最新方法持平或更优，同时显著降低了token消耗。在8B参数模型上获得了SOTA结果，说明该方法在资源受限环境下尤为有效。

Conclusion: DEC有效提升了小型语言模型在知识密集型多跳问答中的表现，兼顾推理准确性和计算资源消耗，对实际落地有明显优势。

Abstract: Knowledge-intensive multi-hop question answering (QA) tasks, which require
integrating evidence from multiple sources to address complex queries, often
necessitate multiple rounds of retrieval and iterative generation by large
language models (LLMs). However, incorporating many documents and extended
contexts poses challenges -such as hallucinations and semantic drift-for
lightweight LLMs with fewer parameters. This work proposes a novel framework
called DEC (Dynamic Enhancement Chain). DEC first decomposes complex questions
into logically coherent subquestions to form a hallucination-free reasoning
chain. It then iteratively refines these subquestions through context-aware
rewriting to generate effective query formulations. For retrieval, we introduce
a lightweight discriminative keyword extraction module that leverages extracted
keywords to achieve targeted, precise document recall with relatively low
computational overhead. Extensive experiments on three multi-hop QA datasets
demonstrate that DEC performs on par with or surpasses state-of-the-art
benchmarks while significantly reducing token consumption. Notably, our
approach attains state-of-the-art results on models with 8B parameters,
showcasing its effectiveness in various scenarios, particularly in
resource-constrained environments.

</details>


### [79] [Zero-Shot Conversational Stance Detection: Dataset and Approaches](https://arxiv.org/abs/2506.17693)
*Yuzhe Ding,Kang He,Bobo Li,Li Zheng,Haijun He,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: 作者构建了新的零样本对话立场检测数据集，并提出新模型，在任务上取得最优结果，但整体表现仍有限，表明此方向仍有大量挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的对话立场检测数据集目标有限，导致模型在真实环境下遇到大量新目标时效果受限。

Method: 人工构建了一个大规模、高质量的零样本对话立场检测数据集（ZS-CSD），涵盖两种类型共280个目标，并提出了结合说话者交互和目标感知的原型对比学习模型SITPCL。

Result: SITPCL在零样本对话立场检测任务上达到当前最优，但F1-macro分数仅为43.81%，显示该任务依然非常具有挑战性。

Conclusion: 提出的ZS-CSD数据集和SITPCL模型能促进零样本对话立场检测领域发展，但零样本情景下的准确率仍有很大提升空间。

Abstract: Stance detection, which aims to identify public opinion towards specific
targets using social media data, is an important yet challenging task. With the
increasing number of online debates among social media users, conversational
stance detection has become a crucial research area. However, existing
conversational stance detection datasets are restricted to a limited set of
specific targets, which constrains the effectiveness of stance detection models
when encountering a large number of unseen targets in real-world applications.
To bridge this gap, we manually curate a large-scale, high-quality zero-shot
conversational stance detection dataset, named ZS-CSD, comprising 280 targets
across two distinct target types. Leveraging the ZS-CSD dataset, we propose
SITPCL, a speaker interaction and target-aware prototypical contrastive
learning model, and establish the benchmark performance in the zero-shot
setting. Experimental results demonstrate that our proposed SITPCL model
achieves state-of-the-art performance in zero-shot conversational stance
detection. Notably, the SITPCL model attains only an F1-macro score of 43.81%,
highlighting the persistent challenges in zero-shot conversational stance
detection.

</details>


### [80] [The Evolution of Natural Language Processing: How Prompt Optimization and Language Models are Shaping the Future](https://arxiv.org/abs/2506.17700)
*Summra Saleem,Muhammad Nabeel Asim,Shaista Zulfiqar,Andreas Dengel*

Main category: cs.CL

TL;DR: 本文系统梳理了LLM提示优化策略，并将其分为11类，覆盖各种应用场景与模型，为后续研究提供了重要参考和实验基准。


<details>
  <summary>Details</summary>
Motivation: 尽管目前已有许多关于提示工程（prompt engineering）的综述，但缺乏对提示优化策略的全面分析。因此，为了填补这个空白，作者希望系统梳理和分析现有的提示优化方法。

Method: 本文从原理出发，对现有的提示优化策略进行了深入研究，将其归纳为11种不同类型，并回顾了这些策略在各种NLP任务、所使用的不同LLM及评测数据集上的应用情况。

Result: 提出了一套全面的提示优化策略分类体系，汇总了相关实际应用案例和实验，用于后续研究和评估。

Conclusion: 本文奠定了后续比较性研究的基础，有助于在统一的实验设置下更严格地评估和改进提示优化与LLM推理流程，并促进新应用的发展。

Abstract: Large Language Models (LLMs) have revolutionized the field of Natural
Language Processing (NLP) by automating traditional labor-intensive tasks and
consequently accelerated the development of computer-aided applications. As
researchers continue to advance this field with the introduction of novel
language models and more efficient training/finetuning methodologies, the idea
of prompt engineering and subsequent optimization strategies with LLMs has
emerged as a particularly impactful trend to yield a substantial performance
boost across diverse NLP tasks. To best of our knowledge numerous review
articles have explored prompt engineering, however, a critical gap exists in
comprehensive analyses of prompt optimization strategies. To bridge this gap
this paper provides unique and comprehensive insights about the potential of
diverse prompt optimization strategies. It analyzes their underlying working
paradigms and based on these principles, categorizes them into 11 distinct
classes. Moreover, the paper provides details about various NLP tasks where
these prompt optimization strategies have been employed, along with details of
different LLMs and benchmark datasets used for evaluation. This comprehensive
compilation lays a robust foundation for future comparative studies and enables
rigorous assessment of prompt optimization and LLM-based predictive pipelines
under consistent experimental settings: a critical need in the current
landscape. Ultimately, this research will centralize diverse strategic
knowledge to facilitate the adaptation of existing prompt optimization
strategies for development of innovative predictors across unexplored tasks.

</details>


### [81] [Aged to Perfection: Machine-Learning Maps of Age in Conversational English](https://arxiv.org/abs/2506.17708)
*MingZe Tang*

Main category: cs.CL

TL;DR: 本研究通过英国国家语料库和机器学习，发现并预测了不同年龄组在口语中的语言特征差异，加深了对英国现代口语中社会语言学多样性的理解。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究英国不同年龄群体在口语表达中的语言模式变化，以及说话者人口统计特征与语言学因素（如话语长度、词汇多样性和用词选择）之间的关系。

Method: 本研究利用British National Corpus 2014（英国国家语料库2014），结合计算语言分析和机器学习方法，对语言进行分析，试图发现不同世代的语言标志，并构建能够根据多项语言特征对说话者年龄组进行预测的模型。

Result: 研究揭示了多代群体在语言标志上的差异性，并成功创建了可根据语言特性准确预测说话者年龄组的预测模型。

Conclusion: 本研究丰富了我们对现代英国口语中社会语言学多样性的理解，并为后续基于人口统计信息和语言学特征关系的语言研究提供了方法参考。

Abstract: The study uses the British National Corpus 2014, a large sample of
contemporary spoken British English, to investigate language patterns across
different age groups. Our research attempts to explore how language patterns
vary between different age groups, exploring the connection between speaker
demographics and linguistic factors such as utterance duration, lexical
diversity, and word choice. By merging computational language analysis and
machine learning methodologies, we attempt to uncover distinctive linguistic
markers characteristic of multiple generations and create prediction models
that can consistently estimate the speaker's age group from various aspects.
This work contributes to our knowledge of sociolinguistic diversity throughout
the life of modern British speech.

</details>


### [82] [Unveiling Factors for Enhanced POS Tagging: A Study of Low-Resource Medieval Romance Languages](https://arxiv.org/abs/2506.17715)
*Matthias Schöffel,Esteban Garces Arias,Marinus Wiedner,Paula Ruppert,Meimingwei Li,Christian Heumann,Matthias Aßenmacher*

Main category: cs.CL

TL;DR: 本文系统比较了不同技术在中世纪罗曼语族低资源文本词性标注上的表现，发现大型语言模型虽有限制，但通过微调等方法可显著改进历史文本的处理能力。


<details>
  <summary>Details</summary>
Motivation: 随着现代语言模型的进步，许多古代语言的自然语言处理取得了突破，但中世纪罗曼语族文本因为语言演变、拼写多样和标注数据稀缺等问题，依然存在诸多困难。研究者亟需探索针对中世纪低资源历史语言的自动词性标注方法，提升数字人文学科的文本处理能力。

Method: 本文系统性地考察了影响中世纪奥克语、西班牙语和法语等文本中词性标注表现的主要因素。所用方法包括模型微调、提示工程（prompt engineering）、不同模型架构、解码策略以及跨语言迁移学习。涵盖圣经、圣徒传记、医学和饮食等多样化语料。通过严格的实验对比各因素对标注准确率的影响。

Result: 实验发现，大型语言模型在处理历史语言变体与非标准拼写方面受限，准确率受挑战。但同时也确定了若干可行的专门化技术（如微调与迁移学习等），可以在低资源历史语言环境下有效提升词性标注性能。

Conclusion: 虽然当前LLMs对中世纪罗曼语族文本的处理仍有明显局限，但定制的方法和技术能够有效缓解数据稀缺与语言变异问题，为历史语言的自动化分析提供了新工具和思路。

Abstract: Part-of-speech (POS) tagging remains a foundational component in natural
language processing pipelines, particularly critical for historical text
analysis at the intersection of computational linguistics and digital
humanities. Despite significant advancements in modern large language models
(LLMs) for ancient languages, their application to Medieval Romance languages
presents distinctive challenges stemming from diachronic linguistic evolution,
spelling variations, and labeled data scarcity. This study systematically
investigates the central determinants of POS tagging performance across diverse
corpora of Medieval Occitan, Medieval Spanish, and Medieval French texts,
spanning biblical, hagiographical, medical, and dietary domains. Through
rigorous experimentation, we evaluate how fine-tuning approaches, prompt
engineering, model architectures, decoding strategies, and cross-lingual
transfer learning techniques affect tagging accuracy. Our results reveal both
notable limitations in LLMs' ability to process historical language variations
and non-standardized spelling, as well as promising specialized techniques that
effectively address the unique challenges presented by low-resource historical
languages.

</details>


### [83] [KAG-Thinker: Teaching Large Language Models to Think with Human-like Reasoning Process](https://arxiv.org/abs/2506.17728)
*Dalong Zhang,Jun Xu,Jun Zhou,Lei Liang,Lin Yuan,Ling Zhong,Mengshu Sun,Peilong Zhao,QiWei Wang,Xiaorui Wang,Xinkai Du,YangYang Hou,Yu Ao,ZhaoYang Wang,Zhengke Gui,ZhiYing Yi,Zhongpu Bo*

Main category: cs.CL

TL;DR: 本论文提出了一种模拟人类思维、结构化推理过程的新框架KAG-Thinker，提升了大语言模型在特定领域复杂问答中的逻辑与一致性，通过创新分解、检索、推理和训练机制实现更优的推理表现。


<details>
  <summary>Details</summary>
Motivation: 许多现有大语言模型在处理特定领域知识库的复杂问答任务时，缺乏人类类似的结构化推理能力，逻辑连贯性和上下文一致性有待提升。作者希望提升LLM在人类类似推理过程中的表现，模拟更系统、有条理的解题方式。

Method: 提出KAG-Thinker框架，基于参数量较小的大语言模型，通过'广度分解'方法将复杂问题拆解为可独立解决的子问题（子问题以自然语言和逻辑函数两种形式表达）。针对不同任务类型进行知识检索或推理分析，采用明确建模的依赖关系和变量传递机制。创新地利用知识边界模型，结合自信度校准与反思推理调度最优知识源，并使用'深度求解'模型提高知识获取的完整性。此外，训练方法采用基于多轮对话的有监督微调，配合数据评测框架和迭代语料生成，避免过度反思。

Result: KAG-Thinker能够实现更符合人类思维的问答推理过程，有效提升逻辑连贯性和上下文一致性。采用知识边界模型和深度求解机制后，系统能更优选知识源并获得更完整的知识。通过有监督微调替代强化学习，实现了与结构化推理范式对齐，数据评测和语料生成机制进一步加强了全面性和效果。

Conclusion: KAG-Thinker显著提升了大语言模型在特定领域知识库的复杂问答推理能力，使其推理过程更加系统和人类化。所提出的架构整合了知识检索、逻辑分解、推理分析以及高效数据驱动训练，对结构化问答推理具有重要意义。

Abstract: In this paper, we introduce KAG-Thinker, a novel human-like reasoning
framework built upon a parameter-light large language model (LLM). Our approach
enhances the logical coherence and contextual consistency of the thinking
process in question-answering (Q\&A) tasks on domain-specific knowledge bases
(KBs) within LLMs. This framework simulates human cognitive mechanisms for
handling complex problems by establishing a structured thinking process.
Continuing the \textbf{Logical Form} guided retrieval and reasoning technology
route of KAG v0.7, firstly, it decomposes complex questions into independently
solvable sub-problems(also referred to as logical forms) through
\textbf{breadth decomposition}, each represented in two equivalent
forms-natural language and logical function-and further classified as either
Knowledge Retrieval or Reasoning Analysis tasks, with dependencies and
variables passing explicitly modeled via logical function interfaces. In the
solving process, the Retrieval function is used to perform knowledge retrieval
tasks, while the Math and Deduce functions are used to perform reasoning
analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval
sub-problem tasks, LLMs and external knowledge sources are regarded as
equivalent KBs. We use the \textbf{knowledge boundary} model to determine the
optimal source using self-regulatory mechanisms such as confidence calibration
and reflective reasoning, and use the \textbf{depth solving} model to enhance
the comprehensiveness of knowledge acquisition. Finally, instead of utilizing
reinforcement learning, we employ supervised fine-tuning with multi-turn
dialogues to align the model with our structured inference paradigm, thereby
avoiding excessive reflection. This is supported by a data evaluation framework
and iterative corpus synthesis, which facilitate the generation of detailed
reasoning trajectories...

</details>


### [84] [HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations](https://arxiv.org/abs/2506.17748)
*Anwoy Chatterjee,Yash Goel,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文提出了HIDE，一种无需多次生成的高效幻觉检测方法，通过内部表征的独立性度量，显著提升检测准确率并大幅降低计算成本，实验验证了其对多种模型和任务的广泛有效性。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型虽然在生成语言方面表现出色，但它们常常会产生与事实或输入上下文不相符的内容，即“幻觉”问题，这极大影响了其可靠性。现有的幻觉检测方法大多需要对一个输入多次生成内容，导致高昂的计算代价和延迟。因此，急需一种高效且低成本的幻觉检测方法。

Method: 作者提出了一种单次推理、无需额外训练的幻觉检测方法，名为HIDE（Hallucination detectIon via Decoupled rEpresentations）。该方法基于这样一个假设：幻觉内容的产生源自于模型对输入上下文与生成输出的内部表征之间存在统计上的分离。具体做法是利用Hilbert-Schmidt Independence Criterion（HSIC），对生成过程中提取的隐藏态进行独立性量化分析，判定是否存在幻觉。

Result: 在四个多样化问答数据集和六个不同特性的开源语言模型上进行了实证评估，涉及事实性和忠实性幻觉检测。实验表明，HIDE方法几乎在所有设置下都优于其它单次方法，AUC-ROC指标平均相对提升约29%；同时与多次策略的SOTA方法相比，HIDE在计算成本降低约51%的前提下，仍获得了AUC-ROC平均约3%的提升或持平。

Conclusion: HIDE方法能有效利用语言模型内部表征的解耦特性，实现高效且实用的幻觉检测，在准确性与计算效率上均优于目前主流方案。

Abstract: Contemporary Language Models (LMs), while impressively fluent, often generate
content that is factually incorrect or unfaithful to the input context - a
critical issue commonly referred to as 'hallucination'. This tendency of LMs to
generate hallucinated content undermines their reliability, especially because
these fabrications are often highly convincing and therefore difficult to
detect. While several existing methods attempt to detect hallucinations, most
rely on analyzing multiple generations per input, leading to increased
computational cost and latency. To address this, we propose a single-pass,
training-free approach for effective Hallucination detectIon via Decoupled
rEpresentations (HIDE). Our approach leverages the hypothesis that
hallucinations result from a statistical decoupling between an LM's internal
representations of input context and its generated output. We quantify this
decoupling using the Hilbert-Schmidt Independence Criterion (HSIC) applied to
hidden-state representations extracted while generating the output sequence. We
conduct extensive experiments on four diverse question answering datasets,
evaluating both faithfulness and factuality hallucinations across six
open-source LMs of varying scales and properties. Our results demonstrate that
HIDE outperforms other single-pass methods in almost all settings, achieving an
average relative improvement of ~29% in AUC-ROC over the best-performing
single-pass strategy across various models and datasets. Additionally, HIDE
shows competitive and often superior performance with multi-pass
state-of-the-art methods, obtaining an average relative improvement of ~3% in
AUC-ROC while consuming ~51% less computation time. Our findings highlight the
effectiveness of exploiting internal representation decoupling in LMs for
efficient and practical hallucination detection.

</details>


### [85] [Multilingual Tokenization through the Lens of Indian Languages: Challenges and Insights](https://arxiv.org/abs/2506.17789)
*N J Karthika,Maharaj Brahma,Rohit Saluja,Ganesh Ramakrishnan,Maunendra Sankar Desarkar*

Main category: cs.CL

TL;DR: 本文深入评估了多种分词算法在印度17种语言上的表现，提出多语种词表与联合训练有助于提升低资源语言的分词效果，为构建更公平高效的多语言NLP系统提供实证参考。


<details>
  <summary>Details</summary>
Motivation: 当前多语种NLP中的分词器大多偏向于高资源语言，导致对印度次大陆等多样且形态丰富语言的处理效果不佳。作者希望改善多语言分词在低资源语言上的表现公平性和效率。

Method: 论文在17种印度语言上，系统评估了不同分词策略，包括自底向上（BPE）、自顶向下（Unigram LM）算法。分析了词表规模、联合与聚类构建多语种词表等策略的影响，并观察低资源语言是否能受益于相关高资源语言训练的分词器。

Result: 比较了不同分词方法和词表构建策略的表现，发现低资源语言可显著受益于与其相关高资源语言共同训练分词器。揭示了多语种多样性环境下分词技术取舍与优化的实证规律。

Conclusion: 多语言分词系统应考虑语言间的资源不均、形态多样和联系性。联合训练、合适的分词策略和词表设计有助于提升低资源语言的处理效果，实现更公平高效的多语种NLP。

Abstract: Tokenization plays a pivotal role in multilingual NLP. However, existing
tokenizers are often skewed towards high-resource languages, limiting their
effectiveness for linguistically diverse and morphologically rich languages
such as those in the Indian subcontinent. This paper presents a comprehensive
intrinsic evaluation of tokenization strategies across 17 Indian languages. We
quantify the trade-offs between bottom-up and top-down tokenizer algorithms
(BPE and Unigram LM), effects of vocabulary sizes, and compare strategies of
multilingual vocabulary construction such as joint and cluster-based training.
We also show that extremely low-resource languages can benefit from tokenizers
trained on related high-resource languages. Our study provides practical
insights for building more fair, efficient, and linguistically informed
tokenizers for multilingual NLP.

</details>


### [86] [THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction](https://arxiv.org/abs/2506.17844)
*Xin Zhang,Qiyu Wei,Yingjie Zhu,Fanyi Wu,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 本研究提出基于因果推断并结合校准机制的EHR多模态风险预测新方法THCM-CAL，有效提升了预测准确率和可靠性，优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 以往利用电子健康记录（EHRs）进行自动化临床风险预测时，常将结构化诊断编码和非结构化叙述笔记分开处理，或者采用简单的融合策略，忽略了叙述性观察如何引发诊断并跨入院传播风险的因果关系。本研究旨在解决多模态信息融合的复杂因果关联问题，提升预测的准确率和可靠性。

Method: 提出一种新的时序-层次因果模型（THCM-CAL），并结合一致性校准（Conformal Calibration）。该模型首先构建包含文本命题和ICD编码（映射为文本描述）的多模态因果图，通过层次化因果发现推断出三类临床相关的交互：同一时间片同模态排序、同一时间片跨模态触发、不同时间片的风险传播。此外，模型还将一致性预测方法扩展到多标签ICD编码，通过复杂共现情况下的置信区间校准提升预测可靠性。

Result: 在MIMIC-III和MIMIC-IV数据集上进行实验证明，THCM-CAL在自动化临床风险预测方面，相较于已有方法表现出更优的性能和更高的可靠性。

Conclusion: THCM-CAL能够有效刻画和利用EHR中结构化与非结构化数据之间的复杂因果关系，并通过一致性校准提升了预测的可控性和可靠性，为实际临床风险预测提供了更好的解决方案。

Abstract: Automated clinical risk prediction from electronic health records (EHRs)
demands modeling both structured diagnostic codes and unstructured narrative
notes. However, most prior approaches either handle these modalities separately
or rely on simplistic fusion strategies that ignore the directional,
hierarchical causal interactions by which narrative observations precipitate
diagnoses and propagate risk across admissions. In this paper, we propose
THCM-CAL, a Temporal-Hierarchical Causal Model with Conformal Calibration. Our
framework constructs a multimodal causal graph where nodes represent clinical
entities from two modalities: Textual propositions extracted from notes and ICD
codes mapped to textual descriptions. Through hierarchical causal discovery,
THCM-CAL infers three clinically grounded interactions: intra-slice
same-modality sequencing, intra-slice cross-modality triggers, and inter-slice
risk propagation. To enhance prediction reliability, we extend conformal
prediction to multi-label ICD coding, calibrating per-code confidence intervals
under complex co-occurrences. Experimental results on MIMIC-III and MIMIC-IV
demonstrate the superiority of THCM-CAL.

</details>


### [87] [LLMs for Customized Marketing Content Generation and Evaluation at Scale](https://arxiv.org/abs/2506.17863)
*Haoran Liu,Amir Tahmasbi,Ehtesham Sam Haque,Purak Jain*

Main category: cs.CL

TL;DR: 本文提出了一套检索增强的广告生成及自动化评测体系，有效提升电商广告表现并降低人工成本，但关键节点仍需人工审查。


<details>
  <summary>Details</summary>
Motivation: 当前电商领域的站外营销内容大多过于模板化、与落地页关联性差，影响营销效果。如何自动生成高相关、高效率的广告文案并降低人工审核成本，是亟需解决的问题。

Method: 提出了MarketingFM系统，通过检索增强集成多数据源，自动生成与关键词高度匹配的广告文案；同时提出AutoEval-Main和AutoEval-Update自动化评测系统，利用规则与大模型评审结合，动态优化评测流程，降低人工干预。

Result: 自适应生成的关键词广告文案相比模板广告，最高CTR提升9%，展现量提升12%，CPC下降0.38%；自动化评测系统与人工标注一致性达89.57%，能够动态优化评测流程，减少人工成本。

Conclusion: 通过MarketingFM与自动化评测方案，显著提升了电商广告投放的相关性及效率，减少了人工干预，但人工仍需在关键环节进行把控。

Abstract: Offsite marketing is essential in e-commerce, enabling businesses to reach
customers through external platforms and drive traffic to retail websites.
However, most current offsite marketing content is overly generic,
template-based, and poorly aligned with landing pages, limiting its
effectiveness. To address these limitations, we propose MarketingFM, a
retrieval-augmented system that integrates multiple data sources to generate
keyword-specific ad copy with minimal human intervention. We validate
MarketingFM via offline human and automated evaluations and large-scale online
A/B tests. In one experiment, keyword-focused ad copy outperformed templates,
achieving up to 9% higher CTR, 12% more impressions, and 0.38% lower CPC,
demonstrating gains in ad ranking and cost efficiency. Despite these gains,
human review of generated ads remains costly. To address this, we propose
AutoEval-Main, an automated evaluation system that combines rule-based metrics
with LLM-as-a-Judge techniques to ensure alignment with marketing principles.
In experiments with large-scale human annotations, AutoEval-Main achieved
89.57% agreement with human reviewers. Building on this, we propose
AutoEval-Update, a cost-efficient LLM-human collaborative framework to
dynamically refine evaluation prompts and adapt to shifting criteria with
minimal human input. By selectively sampling representative ads for human
review and using a critic LLM to generate alignment reports, AutoEval-Update
improves evaluation consistency while reducing manual effort. Experiments show
the critic LLM suggests meaningful refinements, improving LLM-human agreement.
Nonetheless, human oversight remains essential for setting thresholds and
validating refinements before deployment.

</details>


### [88] [QueueEDIT: Structural Self-Correction for Sequential Model Editing in LLMs](https://arxiv.org/abs/2506.17864)
*Taolin Zhang,Haidong Kang,Dongyang Li,Qizhou Chen,Chengyu Wang Xiaofeng He,Richang Hong*

Main category: cs.CL

TL;DR: 本文提出了一种基于队列的自我校正LLM模型编辑方法QueueEDIT，在连续多轮知识修正场景下取得了优异的修正能力，并能维持模型的通用NLP能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）表现出色，但仍存在幻觉，即事实性错误。模型编辑是修正这些错误的一种方法。然而，在实际应用中，错误的修正是连续发生的（而非一次性任务），这时候如何避免对模型原有能力的损害成为挑战。

Method: 提出了基于队列的自我校正框架QueueEDIT。核心方法包括：1）引入结构映射编辑损失，将知识三元组映射到Transformers层中的知识敏感神经元；2）用队列存储每次编辑定位到的参数，并动态对齐过去编辑过的参数；3）每次编辑时选取与当前参数最相关的队列参数，判断是否需要重新调整以保证知识一致性；4）将与当前无关的队列参数冻结，仅更新对模型能力影响最小的队列头参数。

Result: 实验结果显示，该方法在各类顺序模型编辑场景下，显著优于多个强基线，同时在单轮编辑任务中也具竞争力。更重要的是，编辑后的LLM在SME过程中依然能较好地保持原有NLP能力。

Conclusion: QueueEDIT不仅提升了连续错误修正（SME）的性能，还有效缓解了模型参数偏移对通用能力的影响，是一种兼具精准性和鲁棒性的模型编辑方案。

Abstract: Recently, large language models (LLMs) have demonstrated impressive results
but still suffer from hallucinations. Model editing has been proposed to
correct factual inaccuracies in LLMs. A challenging case is sequential model
editing (SME), which aims to rectify errors continuously rather than treating
them as a one-time task. During SME, the general capabilities of LLMs can be
negatively affected due to the introduction of new parameters. In this paper,
we propose a queue-based self-correction framework (QueueEDIT) that not only
enhances SME performance by addressing long-sequence dependency but also
mitigates the impact of parameter bias on the general capabilities of LLMs.
Specifically, we first introduce a structural mapping editing loss to map the
triplets to the knowledge-sensitive neurons within the Transformer layers of
LLMs. We then store the located parameters for each piece of edited knowledge
in a queue and dynamically align previously edited parameters. In each edit, we
select queue parameters most relevant to the currently located parameters to
determine whether previous knowledge needs realignment. Irrelevant parameters
in the queue are frozen, and we update the parameters at the queue head to the
LLM to ensure they do not harm general abilities. Experiments show that our
framework significantly outperforms strong baselines across various SME
settings and maintains competitiveness in single-turn editing. The resulting
LLMs also preserve high capabilities in general NLP tasks throughout the SME
process.

</details>


### [89] [How Alignment Shrinks the Generative Horizon](https://arxiv.org/abs/2506.17871)
*Chenghao Yang,Ari Holtzman*

Main category: cs.CL

TL;DR: 本文提出Branching Factor指标，揭示了对齐大模型输出多样性降低的根本机制，并表明通过合理引导，基础模型也能获得更稳定的输出。


<details>
  <summary>Details</summary>
Motivation: 目前对齐的大模型虽然表现能力强，但生成内容的多样性有限。作者希望理解为什么在对齐后LLM生成结果会变得更稳定、缺乏多样性。

Method: 提出了Branching Factor（BF）指标，一种与token无关的量化方法，用于衡量生成时下一个合理token的有效数量，并用此指标分析对齐过程对模型输出分布的影响，包括实验研究和'诱导'实验。

Result: 实验证明：(1) BF会随着生成过程的推进而减小，说明模型越生成输出越可预测；(2) 对齐调优明显收缩输出分布，使BF大幅降低（如从12降为1.2）；(3) 链式思维推理通过更长推理链也推动BF降低，使输出更加稳定；(4) 通过提示基本模型特定词，同样可以降低BF。

Conclusion: BF是分析和控制LLM输出的有力工具。对齐调优并未本质改变模型行为，而是引导其偏好风格化token，从而激活了原有模型中低熵路径，这解释了对齐模型多样性降低的原因。

Abstract: Despite their impressive capabilities, aligned large language models (LLMs)
often generate outputs that lack diversity. What drives this stability in the
generation? We investigate this phenomenon through the lens of probability
concentration in the model's output distribution. To quantify this
concentration, we introduce the Branching Factor (BF) -- a token-invariant
measure of the effective number of plausible next steps during generation. Our
empirical analysis reveals two key findings: (1) BF often decreases as
generation progresses, suggesting that LLMs become more predictable as they
generate. (2) alignment tuning substantially sharpens the model's output
distribution from the outset, reducing BF by nearly an order of magnitude
(e.g., from 12 to 1.2) relative to base models. This stark reduction helps
explain why aligned models often appear less sensitive to decoding strategies.
Building on this insight, we find this stability has surprising implications
for complex reasoning. Aligned Chain-of-Thought (CoT) models (e.g.,
DeepSeek-distilled models), for instance, leverage this effect; by generating
longer reasoning chains, they push generation into later, more deterministic
(lower BF) stages, resulting in more stable outputs. We hypothesize that
alignment tuning does not fundamentally change a model's behavior, but instead
steers it toward stylistic tokens (e.g., "Sure") that unlock low-entropy
trajectories already present in the base model. This view is supported by
nudging experiments, which show that prompting base models with such tokens can
similarly reduce BF. Together, our findings establish BF as a powerful
diagnostic for understanding and controlling LLM outputs - clarifying how
alignment reduces variability, how CoT promotes stable generations, and how
base models can be steered away from diversity.

</details>


### [90] [Multi-turn Jailbreaking via Global Refinement and Active Fabrication](https://arxiv.org/abs/2506.17881)
*Hua Tang,Lingyong Yan,Yukun Zhao,Shuaiqiang Wang,Jizhou Huang,Dawei Yin*

Main category: cs.CL

TL;DR: 本文针对多轮交互场景下的大语言模型越狱问题，提出全局路径优化和主动伪造回复的新方法，在多个主流模型上显著提升了越狱成功率，揭示LLM的进一步安全隐患。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在多项任务上表现优异，但仍存在因被恶意利用而导致的安全隐患。当前研究主要集中在单轮对话的“越狱”手法，而多轮复杂交互情境下的安全风险未被充分探索。

Method: 提出了一种新颖的多轮越狱方法，在每轮交互中对越狱路径进行全局改进；同时主动伪造模型回复以抑制安全警告，进而提高后续输出有害内容的概率。

Result: 实验结果显示，该方法在六个主流LLM上相较于现有单轮和多轮越狱技术表现更为优越。

Conclusion: 该研究提出的多轮越狱方法能够更有效地促使模型输出有害内容，突显了当前LLM在多轮交互安全方面存在的风险和挑战。

Abstract: Large Language Models (LLMs) have achieved exceptional performance across a
wide range of tasks. However, they still pose significant safety risks due to
the potential misuse for malicious purposes. Jailbreaks, which aim to elicit
models to generate harmful content, play a critical role in identifying the
underlying security threats. Recent jailbreaking primarily focuses on
single-turn scenarios, while the more complicated multi-turn scenarios remain
underexplored. Moreover, existing multi-turn jailbreaking techniques struggle
to adapt to the evolving dynamics of dialogue as the interaction progresses. To
address this limitation, we propose a novel multi-turn jailbreaking method that
refines the jailbreaking path globally at each interaction. We also actively
fabricate model responses to suppress safety-related warnings, thereby
increasing the likelihood of eliciting harmful outputs in subsequent questions.
Experimental results demonstrate the superior performance of our method
compared with existing single-turn and multi-turn jailbreaking techniques
across six state-of-the-art LLMs. Our code is publicly available at
https://github.com/Ytang520/Multi-Turn_jailbreaking_Global-Refinment_and_Active-Fabrication.

</details>


### [91] [Scatter-Based Innovation Propagation in Large Language Models for Multi-Stage Process Adaptation](https://arxiv.org/abs/2506.17949)
*Hong Su*

Main category: cs.CL

TL;DR: 本文提出了创新扩散模型，通过结构化步骤帮助大语言模型将局部创新有效推广至多阶段流程中的其他部分，从而提升了其泛化与复用能力，实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）虽然能够复现和延展预训练时学到的模式，但面对将某一创新思想推广到不同上下文阶段的任务时，经常表现不佳。本文聚焦于如何将局部新颖思想应用于多阶段流程中其他部分，提升其泛化能力。

Method: 提出了创新扩散模型（innovation scatter model），通过四步流程指导LLM：1）对比用户输入与环境上下文，识别核心创新；2）去除特定阶段或组件指涉，实现创新思想泛化；3）判断该泛化思想能否应用于更广泛的范围；4）借助LLM系统性地扩展到其他具有结构相似性的阶段。该模型主要利用各阶段的结构冗余性。

Result: 实验结果表明，这一创新扩散模型能有效帮助LLM将新思想推广至其他结构相似阶段，显著提升了模型的泛化与重用能力。

Conclusion: 创新扩散模型可增强LLM推广和复用局部创新思想的能力，使其在多阶段流程中的泛化表现更好。

Abstract: Large Language Models (LLMs) exhibit strong capabilities in reproducing and
extending patterns observed during pretraining but often struggle to generalize
novel ideas beyond their original context. This paper addresses the challenge
of applying such localized innovations - introduced at a specific stage or
component - to other parts of a multi-stage process. We propose a scatter-based
innovation expansion model (innovation scatter model) that guides the LLM
through a four-step process: (1) identifying the core innovation by comparing
the user's input with its surrounding context, (2) generalizing the innovation
by removing references to specific stages or components, (3) determining
whether the generalized innovation applies to a broader scope beyond the
original stage, and (4) systematically applying it to other structurally
similar stages using the LLM. This model leverages structural redundancy across
stages to improve the applicability of novel ideas. Verification results
demonstrate that the innovation scatter model enables LLMs to extend
innovations across structurally similar stages, thereby enhancing
generalization and reuse.

</details>


### [92] [A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment](https://arxiv.org/abs/2506.17951)
*Quanwei Tang,Sophia Yat Mei Lee,Junshuang Wu,Dong Zhang,Shoushan Li,Erik Cambria,Guodong Zhou*

Main category: cs.CL

TL;DR: 本文提出了GraphMPA，通过图结构信息理解和模式寻优对齐机制，显著提升了RAG系统在问答任务中的整体理解力及与人类偏好的契合度。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成（RAG）方法在问答系统中为大语言模型提供了外部知识，但模型在实现全局语义理解及对齐人类伦理和质量偏好方面尚存在难题。

Method: 本文提出了GraphMPA，一种基于图的综合性框架，包含模式寻优偏好对齐。该方法通过通用相似性度量构建层次化文档图，模拟人类对信息的认知与整合过程，并引入模式寻优概率匹配约束，以提升生成结果与人类偏好的对齐度。

Result: 在六个数据集上的大量实验表明，GraphMPA显著提升了模型的能力，能够更有效与人类偏好对齐。

Conclusion: GraphMPA框架通过图结构理解和模式偏好优化，有效提升RAG系统的全球信息合成能力和输出对人类质量与伦理偏好的对齐度。

Abstract: Recent advancements in retrieval-augmented generation (RAG) have enhanced
large language models in question answering by integrating external knowledge.
However, challenges persist in achieving global understanding and aligning
responses with human ethical and quality preferences. To address these issues,
we propose GraphMPA, a comprehensive graph-based framework with mode-seeking
preference alignment. Our approach constructs a hierarchical document graph
using a general similarity measurement, mimicking human cognitive processes for
information understanding and synthesis. Additionally, we introduce
mode-seeking preference optimization to better align model outputs with human
preferences through probability-matching constraints. Extensive experiments on
six datasets demonstrate the effectiveness of our
\href{https://github.com/tangquanwei/GraphMPA}{GraphMPA}.

</details>


### [93] [PDF Retrieval Augmented Question Answering](https://arxiv.org/abs/2506.18027)
*Thi Thu Uyen Hoang,Viet Anh Nguyen*

Main category: cs.CL

TL;DR: 本论文提出了一种改进的RAG问答系统，首次有效整合了PDF中的文本和非文本多模态信息，实验验证了其在复杂问题上的准确性和扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统主要针对文本信息，难以处理PDF等文档内的丰富多样数据类型，因此亟需一种能够整合并智能处理多模态信息的QA系统。

Method: 通过对RAG框架进行改进，将PDF中的非文本内容（如图像、图表、表格等）数字化并有效整合进系统流程，同时对大语言模型进行微调以适应多模态信息处理需求。

Result: 实验表明，该系统能在PDF中准确抽取多类型内容的信息，并提升了应对复杂多模态问题的能力，为多模态数据整合和处理领域的研究发展奠定了基础。

Conclusion: 提出了一种改进的基于检索增强生成（RAG）框架的问答系统，能够从PDF文件中提取多模态信息，显著提升了现有系统处理文本、图像、图表和表格等多种数据类型的能力。

Abstract: This paper presents an advancement in Question-Answering (QA) systems using a
Retrieval Augmented Generation (RAG) framework to enhance information
extraction from PDF files. Recognizing the richness and diversity of data
within PDFs--including text, images, vector diagrams, graphs, and tables--poses
unique challenges for existing QA systems primarily designed for textual
content. We seek to develop a comprehensive RAG-based QA system that will
effectively address complex multimodal questions, where several data types are
combined in the query. This is mainly achieved by refining approaches to
processing and integrating non-textual elements in PDFs into the RAG framework
to derive precise and relevant answers, as well as fine-tuning large language
models to better adapt to our system. We provide an in-depth experimental
evaluation of our solution, demonstrating its capability to extract accurate
information that can be applied to different types of content across PDFs. This
work not only pushes the boundaries of retrieval-augmented QA systems but also
lays a foundation for further research in multimodal data integration and
processing.

</details>


### [94] [Splitformer: An improved early-exit architecture for automatic speech recognition on edge devices](https://arxiv.org/abs/2506.18035)
*Maxence Lasbordes,Daniele Falavigna,Alessio Brutti*

Main category: cs.CL

TL;DR: 本文为端侧语音识别推理提出了一种引入并行降采样处理层的早退模型方案，实现了资源感知下性能提升，推理速度不变，参数量略增。


<details>
  <summary>Details</summary>
Motivation: 神经模型在推理时，需根据设备资源动态调整计算量，尤其在计算资源有限或变化的设备端处理场景格外重要，而现有早退（early-exit）架构与部分高效语音识别架构在结构可扩展性和模块化上存在不足。

Method: 提出在神经网络架构中引入并行层，专门处理降采样后的输入，从而与标准处理层协同工作，以提升语音识别早退模型的性能。

Result: 在标准语音识别基准测试上，所提方法显著提升了性能，仅需少量参数增加，且不会影响推理时间。

Conclusion: 通过引入针对降采样输入的并行处理层，可以在几乎不增加推理延迟的前提下，有效提升适用于早退机制的语音识别模型性能，适应了设备端资源动态变化需求。

Abstract: The ability to dynamically adjust the computational load of neural models
during inference in a resource aware manner is crucial for on-device processing
scenarios, characterised by limited and time-varying computational resources.
Early-exit architectures represent an elegant and effective solution, since
they can process the input with a subset of their layers, exiting at
intermediate branches (the upmost layers are hence removed from the model).
  From a different perspective, for automatic speech recognition applications
there are memory-efficient neural architectures that apply variable frame rate
analysis, through downsampling/upsampling operations in the middle layers,
reducing the overall number of operations and improving significantly the
performance on well established benchmarks. One example is the Zipformer.
However, these architectures lack the modularity necessary to inject early-exit
branches.
  With the aim of improving the performance in early-exit models, we propose
introducing parallel layers in the architecture that process downsampled
versions of their inputs. % in conjunction with standard processing layers. We
show that in this way the speech recognition performance on standard benchmarks
significantly improve, at the cost of a small increase in the overall number of
model parameters but without affecting the inference time.

</details>


### [95] [Markov-Enhanced Clustering for Long Document Summarization: Tackling the 'Lost in the Middle' Challenge with Large Language Models](https://arxiv.org/abs/2506.18036)
*Aziz Amari,Mohamed Achref Ben Ammar*

Main category: cs.CL

TL;DR: 提出结合抽取与生成的混合摘要方法，有效避免生成式在长文本中关键信息丢失问题，通过聚类及马尔可夫链优化信息组织，提升摘要质量。


<details>
  <summary>Details</summary>
Motivation: 现有自动文本摘要方法主要分为抽取式和生成式两类，但基于大型语言模型的生成式摘要虽然效果提升显著，却资源消耗大，且在处理长文档时易丢失关键信息（即“lost in the middle”问题）。因此需要新的方法解决这些挑战。

Method: 本文提出一种结合抽取式和生成式的混合摘要方法。具体做法是将文档拆分为若干小块，对其向量嵌入进行聚类，为每个聚类生成代表关键思想的摘要，最终根据马尔可夫链图决定这些摘要的语义排序，生成最终摘要文本。

Result: 该方法能够在保留文档关键内容的同时，克服生成式方法在长文档上的信息丢失问题，并高效组织关键信息。

Conclusion: 混合摘要方法可有效提升自动摘要质量，兼顾关键内容保留和逻辑连贯性，具备实际应用价值。

Abstract: The rapid expansion of information from diverse sources has heightened the
need for effective automatic text summarization, which condenses documents into
shorter, coherent texts. Summarization methods generally fall into two
categories: extractive, which selects key segments from the original text, and
abstractive, which generates summaries by rephrasing the content coherently.
Large language models have advanced the field of abstractive summarization, but
they are resourceintensive and face significant challenges in retaining key
information across lengthy documents, which we call being "lost in the middle".
To address these issues, we propose a hybrid summarization approach that
combines extractive and abstractive techniques. Our method splits the document
into smaller text chunks, clusters their vector embeddings, generates a summary
for each cluster that represents a key idea in the document, and constructs the
final summary by relying on a Markov chain graph when selecting the semantic
order of ideas.

</details>


### [96] [Statistical Multicriteria Evaluation of LLM-Generated Text](https://arxiv.org/abs/2506.18082)
*Esteban Garces Arias,Hannah Blocher,Julian Rodemann,Matthias Aßenmacher,Christoph Jansen*

Main category: cs.CL

TL;DR: 本文提出并验证了一种基于广义随机占优的多维质量评估方法（GSD-front），能更科学全面评测大语言模型生成文本，兼容多种评测指标并具备统计推断能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）生成文本的质量评估面临挑战，传统方法通常依赖单一或简单聚合的评估指标，难以全面捕捉文本的连贯性、多样性、流畅性等多维质量特征之间的权衡。此外，自动化指标和人工判断的数据类型不同，现有评估缺乏统计推断的保证。

Method: 本文引入并改进了基于广义随机占优（GSD）的统计推断框架。该方法允许同时对多种不同量纲的质量指标进行评估，利用解码策略的偏序关系，避免了对各指标进行任意权重分配。该框架兼容自动指标（定量）与人工评分（定序），并能为统计差异提供推断性保证。

Result: 通过将GSD-front方法应用于主流文本生成解码策略与人工文本对比评测，发现该框架能够有效揭示各方法间在多维度质量上的显著性能差异，确保了结果的统计可靠性，同时适应抽样设计可能并非独立同分布的实际情况。

Conclusion: GSD-front为LLM生成文本的多维度质量评估提供了系统、可靠且推断性强的方法，克服了以往单指标和缺乏推断保障的局限性，有助于推动NLP评测方法的发展。

Abstract: Assessing the quality of LLM-generated text remains a fundamental challenge
in natural language processing. Current evaluation approaches often rely on
isolated metrics or simplistic aggregations that fail to capture the nuanced
trade-offs between coherence, diversity, fluency, and other relevant indicators
of text quality. In this work, we adapt a recently proposed framework for
statistical inference based on Generalized Stochastic Dominance (GSD) that
addresses three critical limitations in existing benchmarking methodologies:
the inadequacy of single-metric evaluation, the incompatibility between
cardinal automatic metrics and ordinal human judgments, and the lack of
inferential statistical guarantees. The GSD-front approach enables simultaneous
evaluation across multiple quality dimensions while respecting their different
measurement scales, building upon partial orders of decoding strategies, thus
avoiding arbitrary weighting of the involved metrics. By applying this
framework to evaluate common decoding strategies against human-generated text,
we demonstrate its ability to identify statistically significant performance
differences while accounting for potential deviations from the i.i.d.
assumption of the sampling design.

</details>


### [97] [Evaluating Prompt-Based and Fine-Tuned Approaches to Czech Anaphora Resolution](https://arxiv.org/abs/2506.18091)
*Patrik Stano,Aleš Horák*

Main category: cs.CL

TL;DR: 本研究比较了捷克语指代消解任务中，两种主流深度学习方法（提示工程的LLM与微调生成模型）的表现。发现专门微调的mT5表现远超基于提示的LLM，建议在资源允许的前提下优先考虑微调策略。


<details>
  <summary>Details</summary>
Motivation: 指代消解（anaphora resolution）在自然语言理解中极为重要，尤其对于形态丰富的语言如捷克语。过去相关研究较少集中于捷克语，且不同方法的比较也不充分。本研究希望比较两种现代方法在捷克语指代消解任务上的效果。

Method: 基于Prague Dependency Treebank构建的捷克语数据集，评估若干指令微调的大型语言模型（如Mistral Large 2和Llama 3），通过不同提示模板实现，和我们专门为捷克语指代消解微调的紧凑生成式模型（mT5和Mistral变体）进行对比。主要关注准确率表现及计算资源消耗。

Result: 实验表明，基于提示工程的大型语言模型在少样本设置下表现可观（准确率最高达74.5%），但微调的模型（尤其是mT5-large）显著优于提示模型，准确率最高达88%，且所需计算资源更低。进一步分析了不同指代类型、前指距离和语料来源下的性能差异。

Conclusion: 对于捷克语指代消解任务，专门微调的生成式模型优于仅依赖提示的大型语言模型，不仅准确率更高，而且计算资源占用更少；不同方法间存在显著性能权衡。

Abstract: Anaphora resolution plays a critical role in natural language understanding,
especially in morphologically rich languages like Czech. This paper presents a
comparative evaluation of two modern approaches to anaphora resolution on Czech
text: prompt engineering with large language models (LLMs) and fine-tuning
compact generative models. Using a dataset derived from the Prague Dependency
Treebank, we evaluate several instruction-tuned LLMs, including Mistral Large 2
and Llama 3, using a series of prompt templates. We compare them against
fine-tuned variants of the mT5 and Mistral models that we trained specifically
for Czech anaphora resolution. Our experiments demonstrate that while prompting
yields promising few-shot results (up to 74.5% accuracy), the fine-tuned
models, particularly mT5-large, outperform them significantly, achieving up to
88% accuracy while requiring fewer computational resources. We analyze
performance across different anaphora types, antecedent distances, and source
corpora, highlighting key strengths and trade-offs of each approach.

</details>


### [98] [InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating](https://arxiv.org/abs/2506.18102)
*Fuyu Wang,Jiangtong Li,Kun Zhu,Changjun Jiang*

Main category: cs.CL

TL;DR: 本文提出了一个结合多维评估（包含客观与主观标准）和分阶段优化的LLM辩论框架，大幅提升了与专家判断的一致性和辩论效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在辩论任务上取得进展，但主要关注于对具体论点做出回应，忽略了真实性和逻辑有效性等客观评估，同时缺乏跨多个维度的结构化优化方法，影响了整体表现。

Method: 提出了一个双组件框架：（1）InspireScore：多维度评分系统，结合了四个主观标准（情感吸引力、论点清晰度、论点安排、主题相关性）和两个客观标准（事实真实性与逻辑有效性）；（2）InspireDebate：通过分阶段优化，包括链式思考（CoT）推理、多维直接偏好优化（DPO），以及基于Web检索增强生成（Web-RAG）的实时知识支持，优化多轮辩论。

Result: 实验证明，InspireScore与专家评判的相关性提升了44%；InspireDebate在各项表现上比基线模型高57%。

Conclusion: 提出的InspireScore 和 InspireDebate框架在主观和客观多维评估、推理能力优化以及知识支撑等方面，显著提升了LLM辩论系统的综合表现。

Abstract: With the rapid advancements in large language models (LLMs), debating tasks,
such as argument quality assessment and debate process simulation, have made
significant progress. However, existing LLM-based debating systems focus on
responding to specific arguments while neglecting objective assessments such as
authenticity and logical validity. Furthermore, these systems lack a structured
approach to optimize across various dimensions$-$including evaluation metrics,
chain-of-thought (CoT) reasoning, and multi-turn debate refinement$-$thereby
limiting their effectiveness. To address these interconnected challenges, we
propose a dual-component framework: (1) $\textbf{InspireScore}$, a novel
evaluation system that establishes a multi-dimensional assessment architecture
incorporating four subjective criteria (emotional appeal, argument clarity,
argument arrangement, and topic relevance) alongside two objective metrics
(fact authenticity and logical validity); and (2) $\textbf{InspireDebate}$, an
optimized debating framework employing a phased optimization approach through
CoT reasoning enhancement, multi-dimensional Direct Preference Optimization
(DPO), and real-time knowledge grounding via web-based Retrieval Augmented
Generation (Web-RAG). Empirical evaluations demonstrate that
$\textbf{InspireScore}$ achieves 44$\%$ higher correlation with expert
judgments compared to existing methods, while $\textbf{InspireDebate}$ shows
significant improvements, outperforming baseline models by 57$\%$. Source code
is available at https://github.com/fywang12/InspireDebate.

</details>


### [99] [Chengyu-Bench: Benchmarking Large Language Models for Chinese Idiom Understanding and Use](https://arxiv.org/abs/2506.18105)
*Yicheng Fu,Zhemin Huang,Liuxin Yang,Yumeng Lu,Zhongdongming Dai*

Main category: cs.CL

TL;DR: 本文提出了面向成语理解和使用的综合性基准Chengyu-Bench，评估发现当前大语言模型在情感判别上表现优异，但在成语语境恰当性及开放式填空任务中仍然效果有限，凸显出成语语义和文化理解是模型的短板。


<details>
  <summary>Details</summary>
Motivation: 汉语成语富含历史和文化内涵，但字面翻译常无法准确还原其意义，导致主流大语言模型（LLMs）难以有效理解和运用。现有成语测试基准数据集局限于狭窄任务，无法全面评估模型的真实能力。

Method: 提出Chengyu-Bench基准数据集，涵盖三类任务：(1) 成语褒贬分类；(2) 语境下成语使用恰当性检测；(3) 长文填空的开放式成语填空。数据集由2937个人工验证样例组成，涉及1765个常用成语，来源多元。评测主流LLMs在这些任务上的表现，并进行错误分析。

Result: 当前主流LLMs在成语褒贬分类任务上准确率超过95%，在使用恰当性检测任务约85%，在开放式填空的top-1准确率仅约40%。误差分析表明，大部分错误源于对成语意义的根本误解。

Conclusion: Chengyu-Bench证实，虽然LLMs能较好判断成语情感，但在理解成语深层文化与语境使用方面仍存在显著不足；该基准数据集为后续成语理解与应用的研究提供了有力工具。

Abstract: Chinese idioms (Chengyu) are concise four-character expressions steeped in
history and culture, whose literal translations often fail to capture their
full meaning. This complexity makes them challenging for language models to
interpret and use correctly. Existing benchmarks focus on narrow tasks -
multiple-choice cloze tests, isolated translation, or simple paraphrasing. We
introduce Chengyu-Bench, a comprehensive benchmark featuring three tasks: (1)
Evaluative Connotation, classifying idioms as positive or negative; (2)
Appropriateness, detecting incorrect idiom usage in context; and (3) Open
Cloze, filling blanks in longer passages without options. Chengyu-Bench
comprises 2,937 human-verified examples covering 1,765 common idioms sourced
from diverse corpora. We evaluate leading LLMs and find they achieve over 95%
accuracy on Evaluative Connotation, but only ~85% on Appropriateness and ~40%
top-1 accuracy on Open Cloze. Error analysis reveals that most mistakes arise
from fundamental misunderstandings of idiom meanings. Chengyu-Bench
demonstrates that while LLMs can reliably gauge idiom sentiment, they still
struggle to grasp the cultural and contextual nuances essential for proper
usage. The benchmark and source code are available at:
https://github.com/sofyc/ChengyuBench.

</details>


### [100] [The Syntactic Acceptability Dataset (Preview): A Resource for Machine Learning and Linguistic Analysis of English](https://arxiv.org/abs/2506.18120)
*Tom S Juzek*

Main category: cs.CL

TL;DR: 本文发布了一个大规模英语语法可接受性数据集，并揭示了语法性与可接受性大多一致，但机器学习模型预测可接受性优于语法性。


<details>
  <summary>Details</summary>
Motivation: 当前语法可接受性数据集较少，且对语法和可接受性的关系缺乏大规模分析；需要新的数据资源支持相关计算语言学和句法学研究。

Method: 从教科书和《Linguistic Inquiry》期刊采集1000条英语句子（各一半），分别标注句法形式中的语法正确性和通过众包获得的母语者可接受性，并进行初步统计和对比分析。还用机器学习模型对这两类标注进行了预测能力测试。

Result: 数据集中语法性与可接受性在约83%情况下相符，且‘介于两者之间’的情况较多，支持既有研究。同时，机器学习模型预测语法性表现较差，但预测可接受性表现较好，提出了新发现。

Conclusion: 该数据集目前为同类最大公开数据集，为研究语法性与可接受性及二者之间关系等提供了有力资源。未来将继续扩展该数据集。

Abstract: We present a preview of the Syntactic Acceptability Dataset, a resource being
designed for both syntax and computational linguistics research. In its current
form, the dataset comprises 1,000 English sequences from the syntactic
discourse: Half from textbooks and half from the journal Linguistic Inquiry,
the latter to ensure a representation of the contemporary discourse. Each entry
is labeled with its grammatical status ("well-formedness" according to
syntactic formalisms) extracted from the literature, as well as its
acceptability status ("intuitive goodness" as determined by native speakers)
obtained through crowdsourcing, with highest experimental standards. Even in
its preliminary form, this dataset stands as the largest of its kind that is
publicly accessible. We also offer preliminary analyses addressing three
debates in linguistics and computational linguistics: We observe that
grammaticality and acceptability judgments converge in about 83% of the cases
and that "in-betweenness" occurs frequently. This corroborates existing
research. We also find that while machine learning models struggle with
predicting grammaticality, they perform considerably better in predicting
acceptability. This is a novel finding. Future work will focus on expanding the
dataset.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [101] [Bridging Equilibrium and Kinetics Prediction with a Data-Weighted Neural Network Model of Methane Steam Reforming](https://arxiv.org/abs/2506.17224)
*Zofia Pizoń,Shinji Kimijima,Grzegorz Brus*

Main category: cs.CE

TL;DR: 论文提出了一种训练于多源数据（实验、理论、插值等）的神经网络代理模型，实现了对甲烷蒸汽重整动力学和热力学工况的统一高精度预测，显著提升了过程建模与优化能力，可用于反应器设计和流程优化。


<details>
  <summary>Details</summary>
Motivation: 当前氢气作为能源载体的需求不断增长，甲烷蒸汽重整是最常用的制氢工艺。随着燃料电池等应用推动反应器的小型化和过程优化，对能同时处理动力学和热力学（平衡）两种工况的高效模拟方法的需求日益突出。然而，现有模型多仅适用于某一工况，适用面有限。

Method: 本文开发了一种代理模型，利用人工神经网络，并用包含动力学实验、平衡实验、插值数据和理论数据的综合数据集进行训练。数据增强及不同数据类型赋予不同权重提升了模型训练效果。对比贝叶斯优化和随机采样，选取了最优模型。

Result: 该神经网络模型在不同操作参数下预测反应后混合物组成时表现出极高准确性，均方误差仅为0.000498，Pearson相关系数为0.927。模型输出具有连续导数，适合于过程建模和优化。

Conclusion: 所提代理模型能够统一动力学和平衡两类工况，具有稳定性和较强的泛化能力，为甲烷蒸汽重整反应模拟和优化提供了有力工具。

Abstract: Hydrogen's role is growing as an energy carrier, increasing the need for
efficient production, with methane steam reforming being the most widely used
technique. This process is crucial for applications like fuel cells, where
hydrogen is converted into electricity, pushing for reactor miniaturization and
optimized process control through numerical simulations. Existing models
typically address either kinetic or equilibrium regimes, limiting their
applicability. Here we show a surrogate model capable of unifying both regimes.
An artificial neural network trained on a comprehensive dataset that includes
experimental data from kinetic and equilibrium experiments, interpolated data,
and theoretical data derived from theoretical models for each regime. Data
augmentation and assigning appropriate weights to each data type enhanced
training. After evaluating Bayesian Optimization and Random Sampling, the
optimal model demonstrated high predictive accuracy for the composition of the
post-reaction mixture under varying operating parameters, indicated by a mean
squared error of 0.000498 and strong Pearson correlation coefficients of 0.927.
The network's ability to provide continuous derivatives of its predictions
makes it particularly useful for process modeling and optimization. The results
confirm the surrogate model's robustness for simulating methane steam reforming
in both kinetic and equilibrium regimes, making it a valuable tool for design
and process optimization.

</details>


### [102] [Variational Quantum Latent Encoding for Topology Optimization](https://arxiv.org/abs/2506.17487)
*Alireza Tabarraei*

Main category: cs.CE

TL;DR: 本文提出融合量子和经典潜空间编码的神经结构优化方法，实现无监督、多解拓扑设计。量子潜编码在设计多样性和物理性能上展现优势，显示量子电路在结构优化领域的应用前景。


<details>
  <summary>Details</summary>
Motivation: 希望突破传统拓扑优化只能得到单一解的限制，通过量子与经典潜空间编码提升设计多样性和性能，同时为物理约束的结构优化探索高效方法，并探索量子硬件在结构设计中的应用潜力。

Method: 提出一种变分结构拓扑优化框架，将量子与经典潜编码方法结合到基于坐标的神经解码结构中。使用变分量子电路或高斯分布生成低维潜向量，经可学习投影层映射到高维潜空间，再通过神经网络与傅里叶映射坐标联合解码为高分辨率材料分布，并以有限元分析的物理目标直接优化潜参数。

Result: 实验表明，所提方法无监督下可生成多样且物理有效的结构拓扑。两类编码方式均获得高质量设计，量子编码在多个基准问题中在顺应性和设计多样性上优于经典方法。

Conclusion: 量子电路在结构拓扑优化中展现出有效性和可扩展性，有望在结构设计领域推动近端量子硬件的应用。

Abstract: A variational framework for structural topology optimization is developed,
integrating quantum and classical latent encoding strategies within a
coordinate-based neural decoding architecture. In this approach, a
low-dimensional latent vector, generated either by a variational quantum
circuit or sampled from a Gaussian distribution, is mapped to a
higher-dimensional latent space via a learnable projection layer. This enriched
representation is then decoded into a high-resolution material distribution
using a neural network that takes both the latent vector and Fourier-mapped
spatial coordinates as input. The optimization is performed directly on the
latent parameters, guided solely by physics-based objectives such as compliance
minimization and volume constraints evaluated through finite element analysis,
without requiring any precomputed datasets or supervised training. Quantum
latent vectors are constructed from the expectation values of Pauli observables
measured on parameterized quantum circuits, providing a structured and
entangled encoding of information. The classical baseline uses Gaussian-sampled
latent vectors projected in the same manner. The proposed variational
formulation enables the generation of diverse and physically valid topologies
by exploring the latent space through sampling or perturbation, in contrast to
traditional optimization methods that yield a single deterministic solution.
Numerical experiments show that both classical and quantum encodings produce
high-quality structural designs. However, quantum encodings demonstrate
advantages in several benchmark cases in terms of compliance and design
diversity. These results highlight the potential of quantum circuits as an
effective and scalable tool for physics-constrained topology optimization and
suggest promising directions for applying near-term quantum hardware in
structural design.

</details>


### [103] [A predictor-corrector scheme for approximating signed distances using finite element methods](https://arxiv.org/abs/2506.17830)
*Amina El Bachari,Johann Rannou,Vladislav A. Yastrebov,Pierre Kerfriden,Susanne Claus*

Main category: cs.CE

TL;DR: 本文提出了一种有效且健壮的有限元方法，通过预测-校正策略计算拟有符号距离函数，能很好地应对复杂界面和各种初始情况，适用于各类level set重初始化问题。


<details>
  <summary>Details</summary>
Motivation: 现有计算有符号距离函数的方法在处理复杂界面或初始level set函数有突出或平坦区域时往往不够健壮高效。

Method: 提出了一种有限元方法，结合了基于扩散的线性预测步骤和基于Eikonal方程的非线性最小化校正步骤。

Result: 通过多种典型与复杂几何（如星域、三维环面等）的数值实验，方法具备高精度、高效率和鲁棒性。

Conclusion: 该方法能广泛稳定地应用于各类level set函数的重新初始化，尤其在复杂界面情况下表现出色。

Abstract: In this article, we introduce a finite element method designed for the robust
computation of approximate signed distance functions to arbitrary boundaries in
two and three dimensions. Our method employs a novel prediction-correction
approach, involving first the solution of a linear diffusion-based prediction
problem, followed by a nonlinear minimization-based correction problem
associated with the Eikonal equation. The prediction step efficiently generates
a suitable initial guess, significantly facilitating convergence of the
nonlinear correction step. A key strength of our approach is its ability to
handle complex interfaces and initial level set functions with arbitrary steep
or flat regions, a notable challenge for existing techniques. Through several
representative examples, including classical geometries and more complex shapes
such as star domains and three-dimensional tori, we demonstrate the accuracy,
efficiency, and robustness of the method, validating its broad applicability
for reinitializing diverse level set functions.

</details>


### [104] [Learning from the Storm: A Multivariate Machine Learning Approach to Predicting Hurricane-Induced Economic Losses](https://arxiv.org/abs/2506.17964)
*Bolin Shen,Eren Erman Ozguven,Yue Zhao,Guang Wang,Yiqun Xie,Yushun Dong*

Main category: cs.CE

TL;DR: 本研究构建了一个集成飓风特征、水环境和社会经济要素的机器学习框架，在微观空间尺度上预测佛罗里达州飓风经济损失，并能够量化各项因素的重要性，助力灾害管理和城市规划。


<details>
  <summary>Details</summary>
Motivation: 佛罗里达州经常遭受飓风袭击，导致巨大经济损失。以往研究多关注具体原因，但很少有统一框架能整合各类影响因素，全面评估经济损失的来源。该研究旨在填补这一领域空白。

Method: 提出了一个综合性建模框架，将影响因素分为三类：（1）飓风特征、（2）与水相关的环境因子、（3）受灾地区的社会经济因素。整合多源数据，并将所有变量聚合到更细致的ZCTA（邮政编码区域）空间尺度，利用机器学习模型以保险理赔作为经济损失指标进行预测。

Result: 框架能准确预测经济损失，并系统评估各因素的重要性。为灾害缓解、风险评估和海岸及暴风区城市适应性策略的制定提供了实际指导。相关代码已开源。

Conclusion: 提出并验证了一个整合多维度因素的飓风经济损失预测框架，有效提高了分析全面性和预测准确性，对实际灾害管理有重要参考价值。

Abstract: Florida is particularly vulnerable to hurricanes, which frequently cause
substantial economic losses. While prior studies have explored specific
contributors to hurricane-induced damage, few have developed a unified
framework capable of integrating a broader range of influencing factors to
comprehensively assess the sources of economic loss. In this study, we propose
a comprehensive modeling framework that categorizes contributing factors into
three key components: (1) hurricane characteristics, (2) water-related
environmental factors, and (3) socioeconomic factors of affected areas. By
integrating multi-source data and aggregating all variables at the finer
spatial granularity of the ZIP Code Tabulation Area (ZCTA) level, we employ
machine learning models to predict economic loss, using insurance claims as
indicators of incurred damage. Beyond accurate loss prediction, our approach
facilitates a systematic assessment of the relative importance of each
component, providing practical guidance for disaster mitigation, risk
assessment, and the development of adaptive urban strategies in coastal and
storm-exposed areas. Our code is now available at:
https://github.com/LabRAI/Hurricane-Induced-Economic-Loss-Prediction

</details>


### [105] [A phase field model for hydraulic fracture: Drucker-Prager driving force and a hybrid coupling strategy](https://arxiv.org/abs/2506.18161)
*Y. Navidtehrani,C. Betegón,J. Vallejos,E. Martínez-Pañeda*

Main category: cs.CE

TL;DR: 本文提出了新型通用的相场水力压裂模拟框架，创新性处理流体-裂纹耦合与特殊材料断裂，显著拓展实际工程应用范围，并开源了相关代码。


<details>
  <summary>Details</summary>
Motivation: 近年来，利用相场方法模拟水力压裂受到极大关注，旨在优化关键工业过程（如石油工程、采矿和地热能提取），但现有方法在液体流动与相场耦合、断裂驱动力描述等方面存在局限性。

Method: 提出了一种新颖的理论与计算相场框架，能够更好地处理液体流动与相场的耦合，并普适性地描述断裂驱动力。包括：1）创新性的混合耦合方法，提升裂缝-液体流相互作用的精度与灵活性；2）基于Drucker-Prager准则的应变能分解，扩展到能模拟拉压不对称断裂特性的材料如页岩，并预测断层激活和粘滑行为。

Result: 通过四个案例分析展示该框架的新建模能力，涵盖渗透率耦合、裂纹行为及多轴工况下的水力压裂模拟。相关代码已开源并对外发布。

Conclusion: 提出的通用相场方法拓展了水力压裂模拟的材料和物理范围，并为相关工程领域提供了更强的建模和预测能力。

Abstract: Recent years have seen a significant interest in using phase field approaches
to model hydraulic fracture, so as to optimise a process that is key to
industries such as petroleum engineering, mining and geothermal energy
extraction. Here, we present a novel theoretical and computational phase field
framework to simulate hydraulic fracture. The framework is general and
versatile, in that it allows for improved treatments of the coupling between
fluid flow and the phase field, and encompasses a universal description of the
fracture driving force. Among others, this allows us to bring two innovations
to the phase field hydraulic fracture community: (i) a new hybrid coupling
approach to handle the fracture-fluid flow interplay, offering enhanced
accuracy and flexibility; and (ii) a Drucker-Prager-based strain energy
decomposition, extending the simulation of hydraulic fracture to materials
exhibiting asymmetric tension-compression fracture behaviour (such as shale
rocks) and enabling the prediction of geomechanical phenomena such as fault
reactivation and stick-slip behaviour. Four case studies are addressed to
illustrate these additional modelling capabilities and bring insight into
permeability coupling, cracking behaviour, and multiaxial conditions in
hydraulic fracturing simulations. The codes developed are made freely available
to the community and can be downloaded from {https://mechmat.web.ox.ac.uk/

</details>


### [106] [Measuring Fractal Dimension using Discrete Global Grid Systems](https://arxiv.org/abs/2506.18175)
*Pramit Ghosh*

Main category: cs.CE

TL;DR: 本文提出利用DGGS计算地理空间矢量数据的分形维数，有效消除了传统网格覆盖方法的局限，实验与理论均表现优异，为地理数据分析提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 分形维数和离散全球网格系统（DGGS）是地理信息科学中的两个重要但彼此关联较少的领域，本研究旨在探索将DGGS用作地理矢量数据计算分形维数的覆盖集，以解决现有方法中由网格位置、方向及尺寸进展带来的局限性。

Method: 作者将DGGS用作覆盖集，采用Minkowski-Bouligand方法计算地理矢量数据的分形维数。通过在合成数据和卫星云层数据上进行实验，检验该方法的有效性和准确性。

Result: 新方法在合成数据测试中与理论分形维数的误差小于1%；在真实卫星云场数据中的实验结果与文献中的分形维数值一致。方法在考虑地球曲率以及消除网格任意性方面具有优势。

Conclusion: DGGS作为覆盖集计算地理空间数据分形维数的方法是有效且理论上可行的，能够缓解传统方法中网格选择和尺寸调整的问题，并适用于大范围地理数据。论文还讨论了适合该用途的DGGS的理想特性。

Abstract: This study builds a bridge between two well-studied but distant topics:
fractal dimension and Discrete Global Grid System (DGGS). DGGSs are used as
covering sets for geospatial vector data to calculate the Minkowski-Bouligand
dimension. Using the method on synthetic data yields results within 1% of their
theoretical fractal dimensions. A case study on opaque cloud fields obtained
from satellite images gives fractal dimension in agreement with that available
in the literature. The proposed method alleviates the problems of arbitrary
grid placement and orientation, as well as the progression of cell sizes of the
covering sets for geospatial data. Using DGGSs further ensure that
intersections of the covering sets with the geospatial vector having large
geographic extents are calculated by taking the curvature of the earth into
account. This paper establishes the validity of DGGSs as covering sets
theoretically and discusses desirable properties of DGGSs suitable for this
purpose.

</details>


### [107] [Conservative data-driven finite element formulation](https://arxiv.org/abs/2506.18206)
*Adriana Kuliková,Andrei G. Shvarts,Łukasz Kaczmarczyk,Chris J. Pearce*

Main category: cs.CE

TL;DR: 本文提出一种利用混合有限元理论的数据驱动有限元框架，直接在数值计算中应用实验数据，避免传统材料模型拟合带来的偏差和不确定性，利用后验误差指示器支持自适应加密，并在核石墨非线性热传导算例中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的扩散问题求解方法依赖于简化材料模型来拟合实验数据，这可能导致模型偏差，无法充分利用全部实验数据。作者希望通过数据驱动的方法，直接应用实验数据，避免材料模型参数拟合带来的限制和风险。

Method: 提出了一种基于混合有限元（mixed finite element）数据驱动有限元分析框架。通过混合有限元方法强制满足守恒律和边界条件，并直接在数值计算中采用实验数据，无需拟合材料模型参数。混合有限元方法降低了对逼近空间的正则性要求，确保了法向通量在所有内部边界上的连续性。此外，该方法提供了适用于数据驱动计算的后验误差指示器，支持自适应 hp-加密。

Result: 该方法可以量化数据集变化导致的解的非唯一性并预测结果的不确定性。在非线性热传导（以合成的核石墨材料数据集为例）环境下，验证了所提混合有限元数据驱动框架的有效性和灵活性。

Conclusion: 提出的混合有限元数据驱动框架能够避免材料模型参数拟合，直接利用实验数据，从而减少模型偏差和不确定性，支持精确适应性分析。该框架适用于处理扩散问题，能够量化解的不确定性，其适用性和有效性通过热传导实例得到了验证。

Abstract: This paper presents a new data-driven finite element framework derived with
mixed finite element formulation. The standard approach to diffusion problems
requires the solution of the mathematical equations that describe both the
conservation law and the constitutive relations, where the latter is
traditionally obtained after fitting experimental data to simplified material
models. To exploit all available information and avoid bias in the material
model, we follow a data-driven approach. While the conservation laws and
boundary conditions are satisfied by means of the finite element method, the
experimental data is used directly in the numerical simulations, avoiding the
need of fitting material model parameters. In order to satisfy the conservation
law a priori in the strong sense, we introduce a mixed finite element
formulation. This relaxes the regularity requirements on approximation spaces
while enforcing continuity of the normal flux component across all of the inner
boundaries. This weaker mixed formulation provides a posteriori error
indicators tailored for this data-driven approach, enabling adaptive
hp-refinement. The relaxed regularity of the approximation spaces makes it
easier to observe how the variation in the datasets results in the
non-uniqueness of the solution, which can be quantified to predict the
uncertainty of the results. The capabilities of the formulation are
demonstrated in an example of the nonlinear heat transfer in nuclear graphite
using synthetically generated material datasets.

</details>


### [108] [Exact Conditional Score-Guided Generative Modeling for Amortized Inference in Uncertainty Quantification](https://arxiv.org/abs/2506.18227)
*Zezhong Zhang,Caroline Tatsuoka,Dongbin Xiu,Guannan Zhang*

Main category: cs.CE

TL;DR: 本文提出融合精准条件扩散模型与前馈神经网络的高效条件推断方法，兼具表达力与推断速度，适合复杂后验分布任务。


<details>
  <summary>Details</summary>
Motivation: 目前有条件推断的生成模型存在效率和表达能力的权衡。可逆归一化流需要可逆结构，限制了模型表达力和效率；扩散模型则推断计算成本高。本研究动机在于结合两者优点，实现高效且表达力强的条件生成建模。

Method: 提出一种两阶段方法。第一阶段，通过精确计算由样本构建的高斯混合先验下的条件score，引导无监督扩散模型，无需训练即可生成条件噪声标注样本。第二阶段，利用生成的噪声-标签数据，训练一个前馈神经网络，将噪声和观测直接映射为后验样本，从而避免模型结构可逆性和推断过程迭代采样。

Result: 该方法在高维度、多峰后验分布的条件采样任务中实现了快速、精准、可扩展的推断，在复杂物理系统参数估计等不确定性量化任务上显示了优越性。通过数值实验验证了方法有效性。

Conclusion: 该工作提出了一种结合扩散模型与非可逆神经网络的条件生成方法，提升了条件推断的效率与表达能力，为高复杂度系统的不确定性量化等应用提供了新工具。

Abstract: We propose an efficient framework for amortized conditional inference by
leveraging exact conditional score-guided diffusion models to train a
non-reversible neural network as a conditional generative model. Traditional
normalizing flow methods require reversible architectures, which can limit
their expressiveness and efficiency. Although diffusion models offer greater
flexibility, they often suffer from high computational costs during inference.
To combine the strengths of both approaches, we introduce a two-stage method.
First, we construct a training-free conditional diffusion model by analytically
deriving an exact score function under a Gaussian mixture prior formed from
samples of the underlying joint distribution. This exact conditional score
model allows us to efficiently generate noise-labeled data, consisting of
initial diffusion Gaussian noise and posterior samples conditioned on various
observation values, by solving a reverse-time ordinary differential equation.
Second, we use this noise-labeled data to train a feedforward neural network
that maps noise and observations directly to posterior samples, eliminating the
need for reversibility or iterative sampling at inference time. The resulting
model provides fast, accurate, and scalable conditional sampling for
high-dimensional and multi-modal posterior distributions, making it well-suited
for uncertainty quantification tasks, e.g., parameter estimation of complex
physical systems. We demonstrate the effectiveness of our approach through a
series of numerical experiments.

</details>


### [109] [Neural-operator element method: Efficient and scalable finite element method enabled by reusable neural operators](https://arxiv.org/abs/2506.18427)
*Weihang Ouyang,Yeonjong Shin,Si-Wei Liu,Lu Lu*

Main category: cs.CE

TL;DR: NOEM结合了有限元和神经算子的优点，大幅降低了复杂PDE模拟的计算成本，实验验证了方法的高效、准确与可扩展，适用于多种复杂问题。


<details>
  <summary>Details</summary>
Motivation: 有限元方法（FEM）在解决偏微分方程（PDE）方面非常成熟，但其基于网格的特性导致在复杂多尺度模拟中计算成本高。近年来，基于机器学习的神经算子（neural operators）等方法为PDE提供了数据驱动的解法，但存在高训练成本和模型可复用性低等问题。

Method: 提出了一种神经算子元方法（NOEM），将有限元方法与神经算子结合。在需要大量有限元划分的子域内，采用神经算子构建单个神经算子元（NOE），这些NOE与标准有限元整合，通过变分框架共同表示整体解，不需要密集网格划分。

Result: 通过大量数值实验，展示了NOEM在非线性PDE、多尺度问题、复杂几何及不连续系数场上的准确性、效率和可扩展性。

Conclusion: NOEM方法能够克服传统有限元和神经算子方法的局限，实现了更加高效且可扩展的PDE模拟，在复杂多尺度问题上具有明显优势。

Abstract: The finite element method (FEM) is a well-established numerical method for
solving partial differential equations (PDEs). However, its mesh-based nature
gives rise to substantial computational costs, especially for complex
multiscale simulations. Emerging machine learning-based methods (e.g., neural
operators) provide data-driven solutions to PDEs, yet they present challenges,
including high training cost and low model reusability. Here, we propose the
neural-operator element method (NOEM) by synergistically combining FEM with
operator learning to address these challenges. NOEM leverages neural operators
(NOs) to simulate subdomains where a large number of finite elements would be
required if FEM was used. In each subdomain, an NO is used to build a single
element, namely a neural-operator element (NOE). NOEs are then integrated with
standard finite elements to represent the entire solution through the
variational framework. Thereby, NOEM does not necessitate dense meshing and
offers efficient simulations. We demonstrate the accuracy, efficiency, and
scalability of NOEM by performing extensive and systematic numerical
experiments, including nonlinear PDEs, multiscale problems, PDEs on complex
geometries, and discontinuous coefficient fields.

</details>


### [110] [Virtual failure assessment diagrams for hydrogen transmission pipelines](https://arxiv.org/abs/2506.18554)
*J. Wijnen,J. Parker,M. Gagliano,E. Martínez-Pañeda*

Main category: cs.CE

TL;DR: 本研究提出结合先进工艺建模与相场断裂仿真的新方法，定量分析氢输运管道氢脆失效的关键因素，生成更精准的失效评估图，发现现有标准评估方法存在保守不足，并提出改进的安全系数建议。


<details>
  <summary>Details</summary>
Motivation: 氢气运输管道在使用过程中面临由焊接工艺和材料特性导致的结构脆化和失效风险，现有标准中故障评估方法（FAD）对焊缝微观结构异质性和残余应力的考虑不足，可能导致安全性评估不准确。

Method: 将先进的热-冶金焊接过程建模与相场断裂模拟（包括耦合扩散—弹塑性）结合，定量分析焊缝残余应力、热影响区（HAZ）的脆硬区域作用，并模拟各种缺陷态、材料、焊接工艺和氢纯度条件下的失效情况。进一步，基于广泛仿真结果构建虚拟FAD图表，实现机理驱动的服役安全性评估流程。

Result: 研究发现，模型预测与现有FAD标准吻合良好，但揭示标准FAD未能保守地反映焊缝微观结构异质性对失效压力的影响。提出了可补偿残余应力和脆硬焊缝区域影响的机理化FAD安全系数。

Conclusion: 该方法为氢气管道服役安全评估提供了量化、机理化的手段，能更准确考虑焊缝细节与缺陷情况，优化现有安全标准并提升风险评估可靠性。

Abstract: We combine state-of-the-art thermo-metallurgical welding process modelling
with coupled diffusion-elastic-plastic phase field fracture simulations to
predict the failure states of hydrogen transport pipelines. This enables
quantitatively resolving residual stress states and the role of brittle, hard
regions of the weld such as the heat affected zone (HAZ). Failure pressures can
be efficiently quantified as a function of asset state (existing defects),
materials and weld procedures adopted, and hydrogen purity. Importantly,
simulations spanning numerous relevant conditions (defect size and
orientations) are used to build \emph{Virtual} Failure Assessment Diagrams
(FADs), enabling a straightforward uptake of this mechanistic approach in
fitness-for-service assessment. Model predictions are in very good agreement
with FAD approaches from the standards but show that the latter are not
conservative when resolving the heterogeneous nature of the weld
microstructure. Appropriate, \emph{mechanistic} FAD safety factors are
established that account for the role of residual stresses and hard, brittle
weld regions.

</details>


### [111] [A Physics-Informed Neural Network Framework for Simulating Creep Buckling in Growing Viscoelastic Biological Tissues](https://arxiv.org/abs/2506.18565)
*Zhongya Lin,Jinshuai Bai,Shuang Li,Xindong Chen,Bo Li,Xi-Qiao Feng*

Main category: cs.CE

TL;DR: 提出了一种用能量最小化约束的PINN方法，不需预设缺陷即可模拟材料时变特性与复杂形态变化，对传统方法形成有益补充，适用结构工程、软材料和组织工程等应用。


<details>
  <summary>Details</summary>
Motivation: 传统有限元等数值方法在模拟粘弹性等时变材料变形时需显式建网格、人工扰动或嵌入定制程序，导致计算复杂度高。为突破这些限制，需要一种物理一致、自动触发失稳且简便的新方法。

Method: 提出并开发了一种基于能量的物理信息神经网络（PINN）框架，采用增量式方法，训练神经网络最小化系统的势能泛函，以隐式满足平衡和本构关系，实现对粘弹性蠕变、应力松弛、屈曲及组织生长形态发生的模拟。

Result: 该方法无需输入预设缺陷，即可依靠神经网络训练过程自发捕捉屈曲现象。将其扩展应用到生物组织生长和形态发生，能够准确预测圆柱结构的均匀扩展与差异生长导致的屈曲。实验结果显示此PINN框架对粘弹性失稳、屈曲后演化和组织形态变化均具有优秀的预测能力。

Conclusion: 本文提出的基于能量的PINN方法能够有效预测粘弹性失稳、屈曲后的形态演化及生物组织的形态变化，是传统方法有力的补充，为复杂、时变材料行为建模提供了灵活且鲁棒的新工具。

Abstract: Modeling viscoelastic behavior is crucial in engineering and biomechanics,
where materials undergo time-dependent deformations, including stress
relaxation, creep buckling and biological tissue development. Traditional
numerical methods, like the finite element method, often require explicit
meshing, artificial perturbations or embedding customised programs to capture
these phenomena, adding computational complexity. In this study, we develop an
energy-based physics-informed neural network (PINN) framework using an
incremental approach to model viscoelastic creep, stress relaxation, buckling,
and growth-induced morphogenesis. Physics consistency is ensured by training
neural networks to minimize the systems potential energy functional, implicitly
satisfying equilibrium and constitutive laws. We demonstrate that this
framework can naturally capture creep buckling without pre-imposed
imperfections, leveraging inherent training dynamics to trigger instabilities.
Furthermore, we extend our framework to biological tissue growth and
morphogenesis, predicting both uniform expansion and differential
growth-induced buckling in cylindrical structures. Results show that the
energy-based PINN effectively predicts viscoelastic instabilities,
post-buckling evolution and tissue morphological evolution, offering a
promising alternative to traditional methods. This study demonstrates that PINN
can be a flexible robust tool for modeling complex, time-dependent material
behavior, opening possible applications in structural engineering, soft
materials, and tissue development.

</details>


### [112] [Communication Architecture for Autonomous Power-to-X Platforms: Enhancing Inspection and Operation With Legged Robots and 5G](https://arxiv.org/abs/2506.18572)
*Peter Frank,Falk Dettinger,Daniel Dittler,Pascal Häbig,Nasser Jazdi,Kai Hufendiek,Michael Weyrich*

Main category: cs.CE

TL;DR: 本文提出了一套基于5G网络的通信架构，利用四足机器人自动完成海上Power to X平台的检测和维护，实验证明该方法可有效降低人工成本，提升设施运维的自动化与智能化水平。


<details>
  <summary>Details</summary>
Motivation: 海上平台的检查和维护成本高昂，主要原因是对大量人力的需求和苛刻的作业环境。如何降低人力需求、提升效能是亟需解决的问题。

Method: 首先对Power to X平台进行了分类，然后提出了一套支持监测、控制和远程操作的通信架构。通过集成四足机器人，自动化执行检查和维护工作。机器人在5G独立组网上进行远程监控、控制和遥操作，并记录和评估其可用性与时延。

Result: 实现了四足机器人在Power to X平台上的远程检查与维护。基于5G网络的遥操作的可用性和时延得到了记录与评估，显示了技术可行性和关键性能。

Conclusion: 结合5G通信和四足机器人能够有效减少海上平台对人力的依赖，提高操作安全性与效率。5G网络支持下的远程操作为未来海上设施智能化、自动化维护提供了可行路径。

Abstract: Inspection and maintenance of offshore platforms are associated with high
costs, primarily due to the significant personnel requirements and challenging
operational conditions. This paper first presents a classification of Power to
X platforms. Building upon this foundation, a communication architecture is
proposed to enable monitoring, control, and teleoperation for a Power to X
platform. To reduce the demand for human labor, a robotic system is integrated
to autonomously perform inspection and maintenance tasks. The implementation
utilizes a quadruped robot. Remote monitoring, control, and teleoperation of
the robot are analyzed within the context of a 5G standalone network. As part
of the evaluation, aspects such as availability and latency are recorded,
compared, and critically assessed.

</details>


### [113] [A Study of Dynamic Stock Relationship Modeling and S&P500 Price Forecasting Based on Differential Graph Transformer](https://arxiv.org/abs/2506.18717)
*Linyue Hu,Qi Wang*

Main category: cs.CE

TL;DR: 提出了一种基于差分图变换器的新框架，有效提升了股票价格预测的准确性，结合聚类分析为量化投资策略提供新思路。


<details>
  <summary>Details</summary>
Motivation: 股票价格预测对于投资决策和风险管理至关重要，但由于市场具有非线性动力学和时变的股票间相关性，这一任务极具挑战性。传统的静态相关性模型无法捕捉股票关系的动态演变。

Method: 提出了一种差分图变换器（Differential Graph Transformer, DGT）框架，用于动态关系建模和价格预测。DGT通过差分图机制将序列图结构的变化集成到多头自注意力机制中，有效保留高价值连接并抑制噪声，并采用因果时间注意力捕捉价格序列中的全局和局部依赖。此外，分别评估了多种相关性度量（Pearson, MI, Spearman, Kendall’s Tau）作为空间注意力先验。实验采用历时10年的标准普尔500指数收盘价进行验证。

Result: DGT结合空间先验在预测性能上显著优于GRU基线（RMSE: 0.24 vs. 0.87），以Kendall’s Tau全球矩阵为空间先验时效果最佳（MAE: 0.11）。K-means聚类揭示了高波动成长股与防御型蓝筹股两大类别，后者因相关性更稳定而预测误差更低（RMSE: 0.13）。Kendall’s Tau和互信息在高波动板块表现优秀。

Conclusion: 通过创新性地将差分图结构与Transformer相结合，验证了动态关系建模的有效性和最优相关性度量/范围的选择。聚类分析为定制量化策略提供支持，该框架推进了金融时间序列动态建模和跨资产关系分析。

Abstract: Stock price prediction is vital for investment decisions and risk management,
yet remains challenging due to markets' nonlinear dynamics and time-varying
inter-stock correlations. Traditional static-correlation models fail to capture
evolving stock relationships. To address this, we propose a Differential Graph
Transformer (DGT) framework for dynamic relationship modeling and price
prediction. Our DGT integrates sequential graph structure changes into
multi-head self-attention via a differential graph mechanism, adaptively
preserving high-value connections while suppressing noise. Causal temporal
attention captures global/local dependencies in price sequences. We further
evaluate correlation metrics (Pearson, Mutual Information, Spearman, Kendall's
Tau) across global/local/dual scopes as spatial-attention priors. Using 10
years of S&P 500 closing prices (z-score normalized; 64-day sliding windows),
DGT with spatial priors outperformed GRU baselines (RMSE: 0.24 vs. 0.87).
Kendall's Tau global matrices yielded optimal results (MAE: 0.11). K-means
clustering revealed "high-volatility growth" and "defensive blue-chip" stocks,
with the latter showing lower errors (RMSE: 0.13) due to stable correlations.
Kendall's Tau and Mutual Information excelled in volatile sectors. This study
innovatively combines differential graph structures with Transformers,
validating dynamic relationship modeling and identifying optimal correlation
metrics/scopes. Clustering analysis supports tailored quantitative strategies.
Our framework advances financial time-series prediction through dynamic
modeling and cross-asset interaction analysis.

</details>


### [114] [Towards Real-time Structural Dynamics Simulation with Graph-based Digital Twin Modelling](https://arxiv.org/abs/2506.18724)
*Jun Zhang,Tong Zhang,Ying Wang*

Main category: cs.CE

TL;DR: 提出了一种基于图的数字孪生动力学模拟方法，物理可解释性强，适应多种结构拓扑，精度高、效率极大提升，对结构健康监测应用前景广阔。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在结构动力学模拟中效率低下、计算成本高，而深度学习方法又存在物理可解释性不足与难以适应多样结构的问题。

Method: 提出基于图的数字孪生建模（GDTM）框架，利用邻接矩阵明确表示结构顶点空间关系，从而提升模型物理可解释性，并通过数值与实验研究验证有效性。

Result: 框架能准确模拟不同拓扑结构下的动力响应，数值仿真NMSE低于0.005，实验验证低于0.0015，且较传统有限元法提升超过80倍计算效率。

Conclusion: 基于图的结构动力学建模极大提升了模拟效率与精度，促进了其在结构性能评估和健康监测中的应用潜力。

Abstract: Precise and timely simulation of a structure's dynamic behavior is crucial
for evaluating its performance and assessing its health status. Traditional
numerical methods are often limited by high computational costs and low
efficiency, while deep learning approaches offer a promising alternative.
However, these data-driven methods still face challenges, such as limited
physical interpretability and difficulty in adapting to diverse structural
configurations. To address these issues, this study proposes a graph-based
digital twin modelling (GDTM) framework to simulate structural dynamic
responses across various spatial topologies. In this framework, the adjacency
matrix explicitly represents the spatial relationships between structural
vertices, enhancing the model's physical interpretability. The effectiveness of
the proposed framework was validated through comprehensive numerical and
experimental studies. The results demonstrate that the framework accurately
simulated structural dynamics across different topological configurations, with
Normalized Mean-Squared Error (NMSE) values consistently below 0.005 in
numerical simulations and 0.0015 in experimental validations. Furthermore, the
framework achieved over 80-fold improvements in computational efficiency
compared to traditional finite element methods (FEM). This research promotes
the practical application of graph-based structural dynamics modelling, which
has the potential to significantly advance structural performance evaluation
and health monitoring.

</details>


### [115] [Skeletal Reaction Models for Gasoline Surrogate Combustion](https://arxiv.org/abs/2506.18853)
*Yinmin Liu,Hessam Babaee,Peyman Givi,Daniel Livescu,Arash Nouri*

Main category: cs.CE

TL;DR: 利用新型的隐式TDB-CUR降阶方法，自动化从复杂汽油代理反应模型中提取出骨架反应网络，在保证计算精度的前提下，实现了模型大幅简化，显著提高了工程仿真的效率。


<details>
  <summary>Details</summary>
Motivation: 复杂的汽油代理成分燃烧化学反应模型规模庞大，计算量巨大，限制了其在实际工程中的应用，因此需要通过精简机理来降低模型复杂度，同时保持预测精度。

Method: 采用一种基于CUR矩阵分解并结合隐式时间积分的方法（implicit TDB-CUR）进行局部即时灵敏度分析，通过降阶建模(Reduced-Order Modeling, ROM)技术自动化筛选重要反应路径，从而发展了骨架反应模型。

Result: 从包含1389种组分的LLNL汽油详细机理中，自动化生成了包含679种和494种组分的两个骨架模型。其中679组分的模型在关键燃烧特性预测上与详细模型误差小于1%，494组分模型的误差小于10%。

Conclusion: 提出的隐式TDB-CUR降阶建模方法能够有效从复杂汽油燃烧详细机理中提取出更小、更高效且准确度较高的骨架机理，显著缩减了计算复杂度并保证了预测精度。

Abstract: Skeletal reaction models are derived for a four-component gasoline surrogate
model via an instantaneous local sensitivity analysis technique. The
sensitivities of the species mass fractions and the temperature with respect to
the reaction rates are estimated by a reduced-order modeling (ROM) methodology.
Termed "implicit time-dependent basis CUR (implicit TDB-CUR)," this methodology
is based on the CUR matrix decomposition and incorporates implicit time
integration for evolving the bases. The estimated sensitivities are
subsequently analyzed to develop skeletal reaction models with a fully
automated procedure. The 1389-species gasoline surrogate model developed at
Lawrence Livermore National Laboratory (LLNL) is selected as the detailed
kinetics model. The skeletal reduction procedure is applied to this model in a
zero-dimensional constant-pressure reactor over a wide range of initial
conditions. The performances of the resulting skeletal models are appraised by
comparison against the results via the LLNL detailed model, and also
predictions via other skeletal models. Two new skeletal models are developed
consisting of 679 and 494 species, respectively. The first is an alternative to
an existing model with the same number of species. The predictions with this
model reproduces the detailed models vital flame results with less than 1%
errors. The errors via the second model are less than 10%.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [116] [The California Report on Frontier AI Policy](https://arxiv.org/abs/2506.17303)
*Rishi Bommasani,Scott R. Singer,Ruth E. Appel,Sarah Cen,A. Feder Cooper,Elena Cryst,Lindsey A. Gailmard,Ian Klaus,Meredith M. Lee,Inioluwa Deborah Raji,Anka Reuel,Drew Spence,Alexander Wan,Angelina Wang,Daniel Zhang,Daniel E. Ho,Percy Liang,Dawn Song,Joseph E. Gonzalez,Jonathan Zittrain,Jennifer Tour Chayes,Mariano-Florentino Cuellar,Li Fei-Fei*

Main category: cs.CY

TL;DR: 本报告分析了前沿AI在带来巨大机遇的同时所伴随的政策挑战，通过多学科研究提出了‘信任但需验证’的政策原则，帮助加州平衡AI创新和风险治理。


<details>
  <summary>Details</summary>
Motivation: 面对前沿AI带来的历史性机遇与复杂政策挑战，特别是其对科学、经济和社会的深远影响，加州作为全球AI创新中心需要制定既支持创新又能有效防控风险的政策框架。

Method: 报告采用了广泛证据，包括实证研究、历史分析、建模与模拟，基于多学科的方法建立研究框架并推导政策原则。

Result: 报告为加州制定和实施前沿AI政策提供了理论框架与核心原则，强调创新与风险降低策略需并重。

Conclusion: 本报告提出了一套以“信任但需验证”为核心的政策原则，指导加州如何在推动前沿AI发展的同时，妥善评估与治理其风险。

Abstract: The innovations emerging at the frontier of artificial intelligence (AI) are
poised to create historic opportunities for humanity but also raise complex
policy challenges. Continued progress in frontier AI carries the potential for
profound advances in scientific discovery, economic productivity, and broader
social well-being. As the epicenter of global AI innovation, California has a
unique opportunity to continue supporting developments in frontier AI while
addressing substantial risks that could have far reaching consequences for the
state and beyond. This report leverages broad evidence, including empirical
research, historical analysis, and modeling and simulations, to provide a
framework for policymaking on the frontier of AI development. Building on this
multidisciplinary approach, this report derives policy principles that can
inform how California approaches the use, assessment, and governance of
frontier AI: principles rooted in an ethos of trust but verify. This approach
takes into account the importance of innovation while establishing appropriate
strategies to reduce material risks.

</details>


### [117] [Can Large Language Models Be Trusted Paper Reviewers? A Feasibility Study](https://arxiv.org/abs/2506.17311)
*Chuanlei Li,Xu Hu,Minghui Xu,Kun Li,Yue Zhang,Xiuzhen Cheng*

Main category: cs.CY

TL;DR: 大语言模型可以降低论文评审的时间和成本，但在独立判断和准确性上仍有明显不足，适合作为人工辅助工具，而不能完全取代人类评审员。


<details>
  <summary>Details</summary>
Motivation: 学术论文评审通常需要大量时间、专业知识和人力资源，研究动机是探索如何通过自动化手段提升评审效率、降低成本。

Method: 提出了一套自动化论文评审系统，将RAG（检索增强生成）、AutoGen多智能体系统和Chain-of-Thought提示方法整合在一起，支持格式检查、标准化评价、意见生成和打分等任务。

Result: 对290篇WASA 2024会议投稿进行实验，证明LLM基础的评审可大幅减少评审时间（平均2.48小时）与成本（平均104.28美元），但与实际录用文章的相似度较低（平均38.6%），暴露出幻觉、判断独立性不足和检索偏好等问题。

Conclusion: LLM可用作辅助工具帮助人类评审员，但现阶段不宜完全替代人工评审。

Abstract: Academic paper review typically requires substantial time, expertise, and
human resources. Large Language Models (LLMs) present a promising method for
automating the review process due to their extensive training data, broad
knowledge base, and relatively low usage cost. This work explores the
feasibility of using LLMs for academic paper review by proposing an automated
review system. The system integrates Retrieval Augmented Generation (RAG), the
AutoGen multi-agent system, and Chain-of-Thought prompting to support tasks
such as format checking, standardized evaluation, comment generation, and
scoring. Experiments conducted on 290 submissions from the WASA 2024 conference
using GPT-4o show that LLM-based review significantly reduces review time
(average 2.48 hours) and cost (average \$104.28 USD). However, the similarity
between LLM-selected papers and actual accepted papers remains low (average
38.6\%), indicating issues such as hallucination, lack of independent judgment,
and retrieval preferences. Therefore, it is recommended to use LLMs as
assistive tools to support human reviewers, rather than to replace them.

</details>


### [118] [Using Machine Learning in Analyzing Air Quality Discrepancies of Environmental Impact](https://arxiv.org/abs/2506.17319)
*Shuangbao Paul Wang,Lucas Yang,Rahouane Chouchane,Jin Guo,Michael Bailey*

Main category: cs.CY

TL;DR: 本研究利用机器学习和多源数据，揭示了巴尔的摩有色人种及低收入群体因历史政策遗留，面对更高空气污染的不公现实。


<details>
  <summary>Details</summary>
Motivation: 研究巴尔的摩市空气污染与历史上有偏见的保险风险评估方法、居民人口结构以及人口普查中的空气污染物（NO2和PM2.5）浓度之间的关系。探讨长期政策对居民，特别是有色人种生活质量的影响。

Method: 结合机器学习和软件工程方法，利用三个主要数据源（住房贷款公司的有偏估算方法、巴尔的摩人口统计数据、NO2和PM2.5浓度的普查数据）对城市空气污染进行建模和分析。

Result: 发现空气污染水平与有偏见的保险风险评估方法存在明显联系。高收入和低收入居住区之间的NO2水平存在巨大差异，不同种族间空气污染暴露水平同样不均。

Conclusion: 历史有偏见的政策和风险估算方法，导致了今日巴尔的摩市不同种族、收入阶层在空气污染暴露上的严重不平等问题，这些政策持续影响居民的生活质量，特别是有色人种群体。

Abstract: In this study, we apply machine learning and software engineering in
analyzing air pollution levels in City of Baltimore. The data model was fed
with three primary data sources: 1) a biased method of estimating insurance
risk used by homeowners loan corporation, 2) demographics of Baltimore
residents, and 3) census data estimate of NO2 and PM2.5 concentrations. The
dataset covers 650,643 Baltimore residents in 44.7 million residents in 202
major cities in US. The results show that air pollution levels have a clear
association with the biased insurance estimating method. Great disparities
present in NO2 level between more desirable and low income blocks. Similar
disparities exist in air pollution level between residents' ethnicity. As
Baltimore population consists of a greater proportion of people of color, the
finding reveals how decades old policies has continued to discriminate and
affect quality of life of Baltimore citizens today.

</details>


### [119] [MAARTA:Multi-Agentic Adaptive Radiology Teaching Assistant](https://arxiv.org/abs/2506.17320)
*Akash Awasthi,Brandon V. Chang,Anh M. Vu,Ngan Le,Rishi Agrawal,Zhigang Deng,Carol Wu,Hien Van Nguyen*

Main category: cs.CY

TL;DR: 提出MAARTA系统，通过分析视线和诊断报告，为放射科学生提供个性化的错误分析和改正建议，提升了AI在医学教育中的实用性和教学效果。


<details>
  <summary>Details</summary>
Motivation: 放射科学生由于缺乏专家指导时间，难以培养知觉专业能力，导致视觉搜索和诊断解释出错。目前的AI主要关注诊断准确性，无法解释错误发生的原因和过程。

Method: 提出了MAARTA（多智能体自适应放射学助教）系统，通过分析学员的视线轨迹和报告，比较专家与学生的行为，利用结构化图谱检测遗漏和错误，并由专门的智能体分析和反馈。系统可根据错误复杂性动态选择适当的智能体，分步引导学生理解和改正错误。

Result: MAARTA能够有效发现学生在影像判读中的具体知觉错误，通过个性化反馈促进其诊断推理能力提升，从而推动基于AI的放射科教育发展。

Conclusion: MAARTA弥补了现有AI在放射学教育中只关注结果不解释过程的不足，通过结构化且个性化的差错反馈，引导学生改进，提高了放射学生的培养效率。

Abstract: Radiology students often struggle to develop perceptual expertise due to
limited expert mentorship time, leading to errors in visual search and
diagnostic interpretation. These perceptual errors, such as missed fixations,
short dwell times, or misinterpretations, are not adequately addressed by
current AI systems, which focus on diagnostic accuracy but fail to explain how
and why errors occur. To address this gap, we introduce MAARTA (Multi-Agentic
Adaptive Radiology Teaching Assistant), a multi-agent framework that analyzes
gaze patterns and radiology reports to provide personalized feedback. Unlike
single-agent models, MAARTA dynamically selects agents based on error
complexity, enabling adaptive and efficient reasoning. By comparing expert and
student gaze behavior through structured graphs, the system identifies missed
findings and assigns Perceptual Error Teacher agents to analyze discrepancies.
MAARTA then uses step-by-step prompting to help students understand their
errors and improve diagnostic reasoning, advancing AI-driven radiology
education.

</details>


### [120] [AI is the Strategy: From Agentic AI to Autonomous Business Models onto Strategy in the Age of AI](https://arxiv.org/abs/2506.17339)
*René Bohnsack,Mickie de Wet*

Main category: cs.CY

TL;DR: 本研究提出自主型商业模式（ABMs），认为代理性AI将成为企业战略和运营的核心。从AI增强向AI自主商业模式转型，将重构企业竞争和管理逻辑。


<details>
  <summary>Details</summary>
Motivation: 当前大多数企业仍以人为主导或AI增强为主，但随着代理性AI的发展，AI不仅是辅助工具，而可以成为执行企业价值创造、传递与获取的核心。因此有必要重新探讨AI主导的商业模式。

Method: 本文提出自主型商业模式（ABMs）概念，通过两个案例——以autonomy by design为目标的以色列初创公司getswam.ai，以及假设的AI主导瑞安航空改造案例——说明从AI增强到AI自主商业模式的演变过程。

Result: ABMs能够通过AI自主执行、持续适应和逐步卸载人类决策，重塑企业竞争优势，引发“合成竞争”（synthetic competition），带来决策速度和规模的巨大变化，对战略、组织设计和治理产生深远影响。

Conclusion: 随着代理性AI日益主导企业运作，我们需要重新理解和设计企业战略管理，因为企业将越来越多实现自动化自运行。

Abstract: This article develops the concept of Autonomous Business Models (ABMs) as a
distinct managerial and strategic logic in the age of agentic AI. While most
firms still operate within human-driven or AI-augmented models, we argue that
we are now entering a phase where agentic AI (systems capable of initiating,
coordinating, and adapting actions autonomously) can increasingly execute the
core mechanisms of value creation, delivery, and capture. This shift reframes
AI not as a tool to support strategy, but as the strategy itself. Using two
illustrative cases, getswan.ai, an Israeli startup pursuing autonomy by design,
and a hypothetical reconfiguration of Ryanair as an AI-driven incumbent, we
depict the evolution from augmented to autonomous business models. We show how
ABMs reshape competitive advantage through agentic execution, continuous
adaptation, and the gradual offloading of human decision-making. This
transition introduces new forms of competition between AI-led firms, which we
term synthetic competition, where strategic interactions occur at rapid,
machine-level speed and scale. It also challenges foundational assumptions in
strategy, organizational design, and governance. By positioning agentic AI as
the central actor in business model execution, the article invites us to
rethink strategic management in an era where firms increasingly run themselves.

</details>


### [121] [Distinguishing Predictive and Generative AI in Regulation](https://arxiv.org/abs/2506.17347)
*Jennifer Wang,Andrew Selbst,Solon Barocas,Suresh Venkatasubramanian*

Main category: cs.CY

TL;DR: 生成式AI与预测式AI有本质区别，现有监管工具难以完全适用。本文分析了生成式AI的四大特性及带来的挑战，提出三项政策建议，助力制定更有效的AI监管政策。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的出现，现有的AI监管工具基于对预测式AI的假设，已经难以涵盖新型AI带来的独特挑战，亟需重新审视和调整政策响应。

Method: 本文通过分析生成式AI的四个关键特征，探讨其对政策制定带来的新需求和挑战，并提出针对性的改进建议。

Result: 研究明确了生成式AI在通用性与适应性、评估难度、新的法律问题以及价值链分布结构方面与预测式AI的根本不同，强调现有监管政策部分失效，需要新的政策工具，并给出三项具体建议来改进监管目标识别和治理手段。

Conclusion: 为有效治理生成式AI，政策制定者应区分两类AI的核心差异，借鉴以往政策中仍有效的部分，同时针对生成式AI独有的风险制定新政策。本文为监管目标与生态系统约束的识别、利用提供了方向。

Abstract: Over the past decade, policymakers have developed a set of regulatory tools
to ensure AI development aligns with key societal goals. Many of these tools
were initially developed in response to concerns with predictive AI and
therefore encode certain assumptions about the nature of AI systems and the
utility of certain regulatory approaches. With the advent of generative AI,
however, some of these assumptions no longer hold, even as policymakers attempt
to maintain a single regulatory target that covers both types of AI.
  In this paper, we identify four distinct aspects of generative AI that call
for meaningfully different policy responses. These are the generality and
adaptability of generative AI that make it a poor regulatory target, the
difficulty of designing effective evaluations, new legal concerns that change
the ecosystem of stakeholders and sources of expertise, and the distributed
structure of the generative AI value chain.
  In light of these distinctions, policymakers will need to evaluate where the
past decade of policy work remains relevant and where new policies, designed to
address the unique risks posed by generative AI, are necessary. We outline
three recommendations for policymakers to more effectively identify regulatory
targets and leverage constraints across the broader ecosystem to govern
generative AI.

</details>


### [122] [Evaluating the Impact of Lean and Green Practices on Operational Performance: A Real Data-Driven Simulation Case Study](https://arxiv.org/abs/2506.17354)
*Farah Altarazi*

Main category: cs.CY

TL;DR: 本研究提出以Lean和Green理念结合OEEE新指标评估与改进企业生产绩效。仿真结果显示，相关措施能有效缩短生产周期和提升可持续表现，建议聚焦相关改进以增强企业竞争优势。


<details>
  <summary>Details</summary>
Motivation: 全球市场驱动和客户需求持续变化，以盈利和效率为主的企业目标已不足以应对竞争，可持续表现成为新的竞争优势，促使企业整合传统目标与绿色创新。

Method: 应用系统分析与建模，结合仿真模拟和能耗价值流图，计算OEEE值衡量质量、可用性、生产力及可持续性。提出并模拟两种改进方案，评估其对OEEE和生产周期的影响。

Result: 现状下生产周期为329.1分钟，OEEE为13.1%，环节存在较大改进空间。改进一（合并、重排检测工位）后，周期降至158.23分钟，OEEE升至35%；改进二（使用紫外线烘干）后，周期降至292分钟，OEEE升至24%。两种方案均提升了绩效与可持续性。

Conclusion: 采用Lean和Green方法结合整体环境设备效能（OEEE）指标，有助于企业提升生产绩效和可持续能力。针对现状的改进措施能明显提高OEEE值和缩短生产周期，建议将管理和技术创新努力集中于绩效与可持续性提升。

Abstract: Global market-driven forces and customer needs are continuously changing. In
the past, profitability and efficiency were the primary objectives of most
companies. However, in recent decades, sustainable performance has emerged as a
new competitive advantage. Companies have been compelled to adopt a concept
that combines these evolving global interests with traditional goals resulting
in the innovation of the lean and green approach.
  In this study, a research methodology that includes system analysis and
modeling procedures to apply the lean and green concept, combined with a new
evaluation metric, the Overall Environmental Equipment Effectiveness (OEEE) was
used to investigate the effects of adopting lean and green practices on overall
performance.
  A simulation model and energy value stream mapping were implemented, and the
OEEE value was calculated to assess the current performance in terms of
quality, availability, productivity, and sustainability. The current state
production lead time was 329.1 minutes per batch, and the OEEE value was 13.1%.
This result indicates existing issues in performance and sustainability,
suggesting that improvement efforts should focus on enhancing these two aspects
to increase the overall OEEE value.
  Several improvement scenarios were proposed, including combining and
rearranging the inspection workstations as the first scenario, and using UV
lighting for drying purposes at the framing workstation as the second. After
applying these improvements, both scenarios showed increased OEEE values and
reduced lead times compared to the current state. In the first scenario, the
lead time decreased to 158.23 minutes, and the OEEE increased to 35%. In the
second scenario, the lead time was reduced to 292 minutes, with the OEEE
increasing to 24%.

</details>


### [123] [PasteTrace: A Single Source Plagiarism Detection Tool For Introductory Programming Courses](https://arxiv.org/abs/2506.17355)
*Jesse McDonald,Scott Robertson,Anthony Peruma*

Main category: cs.CY

TL;DR: 本文提出并验证了PasteTrace：一款可在IDE内实时检测初学者编程课程抄袭的新工具，效果优于传统检测方法。


<details>
  <summary>Details</summary>
Motivation: 初学者在计算机科学入门课程中，因缺乏编程经验，常对课程内容感到吃力，并可能因难以理解导致学术不端行为（如抄袭）。现有抄袭检测工具不完全适合入门编程教学情境。

Method: 提出了PasteTrace，这是一个专为编程入门课程设计的开源抄袭检测工具，它能在IDE内实时跟踪学生的编程活动，以发现潜在的抄袭行为。作者还将PasteTrace与现有工具进行了对比评估。

Result: PasteTrace能提供学生行为的洞见，并能检测多种抄袭类型。实验结果显示，该工具在两门入门课程中优于现有知名工具。

Conclusion: PasteTrace为初级编程课程提供了更有效的抄袭检测方式，有助于维护学术诚信并帮助教师理解学生学习行为。

Abstract: Introductory Computer Science classes are important for laying the foundation
for advanced programming courses. However, students without prior programming
experience may find these courses challenging, leading to difficulties in
understanding concepts and engaging in academic dishonesty such as plagiarism.
While there exists plagiarism detection techniques and tools, not all of them
are suitable for academic settings, especially in introductory programming
courses. This paper introduces PasteTrace, a novel open-source plagiarism
detection tool designed specifically for introductory programming courses.
Unlike traditional methods, PasteTrace operates within an Integrated
Development Environment that tracks the student's coding activities in
real-time for evidence of plagiarism. Our evaluation of PasteTrace in two
introductory programming courses demonstrates the tool's ability to provide
insights into student behavior and detect various forms of plagiarism,
outperforming an existing well-established tool.
  A video demonstration of PasteTrace and its source code, and case study data
are made available at https://doi.org/10.6084/m9.figshare.27115852

</details>


### [124] [Automatic Large Language Models Creation of Interactive Learning Lessons](https://arxiv.org/abs/2506.17356)
*Jionghao Lin,Jiarui Rao,Yiyang Zhao,Yuting Wang,Ashish Gurung,Amanda Barany,Jaclyn Ocumpaugh,Ryan S. Baker,Kenneth R. Koedinger*

Main category: cs.CY

TL;DR: 本文提出并验证了一种基于GPT-4o和任务分解的课程自动生成系统，可有效产出用于导师培训的高质量课程。


<details>
  <summary>Details</summary>
Motivation: 提升初学者线上数学教学能力，自动化生成互动场景式培训课程以降低成本、提高效率。

Method: 采用基于GPT-4o的检索增强生成（RAG）方法，通过任务分解（task decomposition）的提示工程，自动生成结构化的导师培训课程，并由两位人工评审结合定量和定性指标进行评价。

Result: 采用任务分解策略生成的课程质量优于单步生成；课程结构合理，节省准备时间，但存在反馈内容泛化和局部教学环节不清晰的不足。

Conclusion: 任务分解和人机协作生成的课程在导师培训中具有较大应用潜力，未来应进一步优化反馈和细节清晰度。

Abstract: We explore the automatic generation of interactive, scenario-based lessons
designed to train novice human tutors who teach middle school mathematics
online. Employing prompt engineering through a Retrieval-Augmented Generation
approach with GPT-4o, we developed a system capable of creating structured
tutor training lessons. Our study generated lessons in English for three key
topics: Encouraging Students' Independence, Encouraging Help-Seeking Behavior,
and Turning on Cameras, using a task decomposition prompting strategy that
breaks lesson generation into sub-tasks. The generated lessons were evaluated
by two human evaluators, who provided both quantitative and qualitative
evaluations using a comprehensive rubric informed by lesson design research.
Results demonstrate that the task decomposition strategy led to higher-rated
lessons compared to single-step generation. Human evaluators identified several
strengths in the LLM-generated lessons, including well-structured content and
time-saving potential, while also noting limitations such as generic feedback
and a lack of clarity in some instructional sections. These findings underscore
the potential of hybrid human-AI approaches for generating effective lessons in
tutor training.

</details>


### [125] [A Large-Scale Real-World Evaluation of LLM-Based Virtual Teaching Assistant](https://arxiv.org/abs/2506.17363)
*Sunjun Kweon,Sooyohn Nam,Hyunseung Lim,Hwajung Hong,Edward Choi*

Main category: cs.CY

TL;DR: 作者在AI课程中部署了一个基于大语言模型的虚拟助教，通过学生调查和交互数据，系统评估了其在现实课堂中的作用、优势与挑战，并开源了该系统。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM驱动的虚拟助教有望通过即时反馈和多轮互动提升学生学习效果，但其在真实课堂的效果和接受度尚缺乏实证数据，实际影响不明，因此需要在现实场景下进行系统性评估。

Method: 在477名研究生参加的AI编程课程中部署基于大模型的虚拟助教，并在课程不同阶段进行三轮学生问卷调查，同时分析3869组学生与虚拟助教的交互记录，并与传统学生-人工教师的交互进行对比分析。

Result: 学生对VTA表现的看法会随时间变化，分析显示VTA能够覆盖多种提问类型并展现独特的参与模式。但与人类教师相比仍有不足，实际应用中存在型关键挑战。同时开源了VTA系统。

Conclusion: 本文通过大规模实证研究和交互分析，评估了LLM驱动的虚拟助教在真实课堂中的可行性，并指出了其广泛应用所面临的关键挑战。作者还开源了虚拟助教系统，以促进未来AI教育的发展。

Abstract: Virtual Teaching Assistants (VTAs) powered by Large Language Models (LLMs)
have the potential to enhance student learning by providing instant feedback
and facilitating multi-turn interactions. However, empirical studies on their
effectiveness and acceptance in real-world classrooms are limited, leaving
their practical impact uncertain. In this study, we develop an LLM-based VTA
and deploy it in an introductory AI programming course with 477 graduate
students. To assess how student perceptions of the VTA's performance evolve
over time, we conduct three rounds of comprehensive surveys at different stages
of the course. Additionally, we analyze 3,869 student--VTA interaction pairs to
identify common question types and engagement patterns. We then compare these
interactions with traditional student--human instructor interactions to
evaluate the VTA's role in the learning process. Through a large-scale
empirical study and interaction analysis, we assess the feasibility of
deploying VTAs in real-world classrooms and identify key challenges for broader
adoption. Finally, we release the source code of our VTA system, fostering
future advancements in AI-driven education:
\texttt{https://github.com/sean0042/VTA}.

</details>


### [126] [AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning](https://arxiv.org/abs/2506.17364)
*Alvaro Becerra,Roberto Daza,Ruth Cobos,Aythami Morales,Mutlu Cukurova,Julian Fierrez*

Main category: cs.CY

TL;DR: 本研究提出基于多模态生物识别手段监测在线学习过程中的分心行为，融合多种生理与行为信号，检测手机使用分心的准确率提升至91%，为在线教育平台的实时监控与干预提供了新方案。


<details>
  <summary>Details</summary>
Motivation: 在需要持续专注的任务（如在线学习）中，智能手机使用导致的分心是一个重要问题。传统学习平台缺乏对学习者行为的精细数据分析，因此需要新的方法来监测并理解学习者的注意力状态。

Method: 提出了一种基于AI的方法，结合生理信号（如脑电和心跳）及头部姿态数据，检测用户在电脑端学习时是否使用手机。通过多模态学习分析与生物传感器采集数据，设计并评估单模态与多模态的识别模型。

Result: 单一生物识别信号（如脑波、心率）检测手机使用的准确率有限；单独使用头部姿态能够达到87%的准确率；将所有信号融合的多模态模型准确率高达91%。

Conclusion: 多模态生物识别技术能够更有效地检测学习期间的分心行为，尤其是在智能手机使用方面。实际部署时还需考虑模型的实时性及应用限制。

Abstract: This work investigates the use of multimodal biometrics to detect
distractions caused by smartphone use during tasks that require sustained
attention, with a focus on computer-based online learning. Although the methods
are applicable to various domains, such as autonomous driving, we concentrate
on the challenges learners face in maintaining engagement amid internal (e.g.,
motivation), system-related (e.g., course design) and contextual (e.g.,
smartphone use) factors. Traditional learning platforms often lack detailed
behavioral data, but Multimodal Learning Analytics (MMLA) and biosensors
provide new insights into learner attention. We propose an AI-based approach
that leverages physiological signals and head pose data to detect phone use.
Our results show that single biometric signals, such as brain waves or heart
rate, offer limited accuracy, while head pose alone achieves 87%. A multimodal
model combining all signals reaches 91% accuracy, highlighting the benefits of
integration. We conclude by discussing the implications and limitations of
deploying these models for real-time support in online learning environments.

</details>


### [127] [AI based Content Creation and Product Recommendation Applications in E-commerce: An Ethical overview](https://arxiv.org/abs/2506.17370)
*Aditi Madhusudan Jain,Ayush Jain*

Main category: cs.CY

TL;DR: 本文分析了电商中AI内容生成与推荐的伦理风险，提出了消除算法偏见和强化伦理标准的措施，为行业提供了具体的合规操作建议。


<details>
  <summary>Details</summary>
Motivation: 随着AI在电商的快速普及，对内容生成及推荐的高效个性化带来好处，但也引发了如数据隐私、算法偏见和用户自主权等严重伦理问题，迫切需要更完善的伦理标准。

Method: 分析并总结AI用于电商内容和推荐系统的伦理风险，归纳企业应采纳的最佳实践，如算法定期审计、多元化训练数据和引入公平性指标。同时探讨了保障数据隐私和消费者自主权的符合伦理的框架。

Result: 归纳了AI在电商领域的主要伦理风险，并提出了减缓偏见、保障公平和隐私的实践性建议，对增强AI系统的包容性和伦理性具有指导作用。

Conclusion: 提出应通过多项举措来提升AI在电商内容生成和产品推荐中的公平性、透明度和合规性，并为行业提供了实际的道德规范和建议。

Abstract: As e-commerce rapidly integrates artificial intelligence for content creation
and product recommendations, these technologies offer significant benefits in
personalization and efficiency. AI-driven systems automate product
descriptions, generate dynamic advertisements, and deliver tailored
recommendations based on consumer behavior, as seen in major platforms like
Amazon and Shopify. However, the widespread use of AI in e-commerce raises
crucial ethical challenges, particularly around data privacy, algorithmic bias,
and consumer autonomy. Bias -- whether cultural, gender-based, or socioeconomic
-- can be inadvertently embedded in AI models, leading to inequitable product
recommendations and reinforcing harmful stereotypes. This paper examines the
ethical implications of AI-driven content creation and product recommendations,
emphasizing the need for frameworks to ensure fairness, transparency, and need
for more established and robust ethical standards. We propose actionable best
practices to remove bias and ensure inclusivity, such as conducting regular
audits of algorithms, diversifying training data, and incorporating fairness
metrics into AI models. Additionally, we discuss frameworks for ethical
conformance that focus on safeguarding consumer data privacy, promoting
transparency in decision-making processes, and enhancing consumer autonomy. By
addressing these issues, we provide guidelines for responsibly utilizing AI in
e-commerce applications for content creation and product recommendations,
ensuring that these technologies are both effective and ethically sound.

</details>


### [128] [Multimodal Political Bias Identification and Neutralization](https://arxiv.org/abs/2506.17372)
*Cedric Bernard,Xavier Pleimling,Amun Kharel,Chase Vickery*

Main category: cs.CY

TL;DR: 本文提出了一个综合文本与图像偏见检测与去除的模型，初步实验效果良好，但还需提高训练力度与资源投入，人工评估确保新内容语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有关于政治回音室的问题要求对政治文章中的主观偏见和情绪化语言进行检测与去除，但以往的研究只关注文本部分，忽视了图像部分，而图像同样是重要的信息传递媒介。

Method: 提出了一个结合文本与图像偏见的模型，包括四个步骤：1）图像文本对齐（通过CLIP对模型偏见进行语义对齐）；2）图像偏见评分（利用ViT分类器为图像打分）；3）文本去偏见（用BERT检测并中和偏见词句）；4）最终去偏见（用低偏见的文本及图像替换原内容）。还设计了人工评估，新生成的文本和图像的语义一致性。

Result: 文本去偏见方法可以识别大量潜在的偏见词和偏见短语，ViT图像偏见模型训练效果也较好，语义对齐模块效率高。但实现更好结果还需更多训练时间与资源。

Conclusion: 本文联合利用文本和图像信息进行去偏见，方法效果初步验证有效，未来需进一步训练和资源投入提升性能；人工评估确保生成内容语义一致性。

Abstract: Due to the presence of political echo chambers, it becomes imperative to
detect and remove subjective bias and emotionally charged language from both
the text and images of political articles. However, prior work has focused on
solely the text portion of the bias rather than both the text and image
portions. This is a problem because the images are just as powerful of a medium
to communicate information as text is. To that end, we present a model that
leverages both text and image bias which consists of four different steps.
Image Text Alignment focuses on semantically aligning images based on their
bias through CLIP models. Image Bias Scoring determines the appropriate bias
score of images via a ViT classifier. Text De-Biasing focuses on detecting
biased words and phrases and neutralizing them through BERT models. These three
steps all culminate to the final step of debiasing, which replaces the text and
the image with neutralized or reduced counterparts, which for images is done by
comparing the bias scores. The results so far indicate that this approach is
promising, with the text debiasing strategy being able to identify many
potential biased words and phrases, and the ViT model showcasing effective
training. The semantic alignment model also is efficient. However, more time,
particularly in training, and resources are needed to obtain better results. A
human evaluation portion was also proposed to ensure semantic consistency of
the newly generated text and images.

</details>


### [129] [A Grassroots Network and Community Roadmap for Interconnected Autonomous Science Laboratories for Accelerated Discovery](https://arxiv.org/abs/2506.17510)
*Rafael Ferreira da Silva,Milad Abolhasani,Dionysios A. Antonopoulos,Laura Biven,Ryan Coffee,Ian T. Foster,Leslie Hamilton,Shantenu Jha,Theresa Mayer,Benjamin Mintz,Robert G. Moore,Salahudin Nimer,Noah Paulson,Woong Shin,Frederic Suter,Mitra Taheri,Michela Taufer,Newell R. Washburn*

Main category: cs.CY

TL;DR: AISLE打破自主实验室孤岛，实现跨机构协作与资源整合，以AI驱动科学研究创新并提升教育，助力多个科学领域的重大突破。


<details>
  <summary>Details</summary>
Motivation: 现有的AI自主实验室多为孤立系统，缺乏跨机构协作，制约了科学发现的效率及创新生态。

Method: 提出了AISLE系统，通过五个关键维度（跨机构设备协同、智能数据管理、AI驱动编排、可互操作通信接口、AI/ML赋能的科学教育）实现自治实验室的互联。

Result: AISLE不仅促进了多机构自动化研究协作，还为可持续能源、材料开发和公共健康等领域带来重大创新潜力。

Conclusion: AISLE实现跨机构自主实验室的协作，推动以AI为驱动的科学研究突破传统，缩短创新周期，且促进科研民主化。

Abstract: Scientific discovery is being revolutionized by AI and autonomous systems,
yet current autonomous laboratories remain isolated islands unable to
collaborate across institutions. We present the Autonomous Interconnected
Science Lab Ecosystem (AISLE), a grassroots network transforming fragmented
capabilities into a unified system that shorten the path from ideation to
innovation to impact and accelerates discovery from decades to months. AISLE
addresses five critical dimensions: (1) cross-institutional equipment
orchestration, (2) intelligent data management with FAIR compliance, (3)
AI-agent driven orchestration grounded in scientific principles, (4)
interoperable agent communication interfaces, and (5) AI/ML-integrated
scientific education. By connecting autonomous agents across institutional
boundaries, autonomous science can unlock research spaces inaccessible to
traditional approaches while democratizing cutting-edge technologies. This
paradigm shift toward collaborative autonomous science promises breakthroughs
in sustainable energy, materials development, and public health.

</details>


### [130] [Public Perceptions of Autonomous Vehicles: A Survey of Pedestrians and Cyclists in Pittsburgh](https://arxiv.org/abs/2506.17513)
*Rudra Y. Bedekar*

Main category: cs.CY

TL;DR: 通过调查匹兹堡1200多名居民，发现人群特征、基础设施与沟通教育共同影响公众对自动驾驶汽车的认知与采纳。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶汽车（AV）技术的发展，行人与骑行者作为道路使用者与AV的互动日益增多，但他们对该技术的认知、信任和安全感尚不清晰。本研究旨在阐明不同人群对AV的看法及其影响因素，推动更好城市交通规划与技术普及。

Method: 本研究通过面向匹兹堡地区超过1200名受访者进行问卷调查，收集行人与骑行者对自动驾驶汽车的看法和体验数据，并分析人口统计特征、互动经历、基础设施准备状况、安全感和信任度之间的关系。

Result: 结果显示，人口统计因素（如年龄、性别等）影响人们对AV的看法，基础设施存在差距。安全沟通和相关知识教育在推动AV接受和信任中起着关键作用。

Conclusion: 不同人群对自动驾驶汽车技术的认知和接受度存在差异，加强基础设施建设及提升公众沟通与教育对于推动AV技术的普及具有重要意义。

Abstract: This study investigates how autonomous vehicle(AV) technology is perceived by
pedestrians and bicyclists in Pittsburgh. Using survey data from over 1200
respondents, the research explores the interplay between demographics, AV
interactions, infrastructural readiness, safety perceptions, and trust.
Findings highlight demographic divides, infrastructure gaps, and the crucial
role of communication and education in AV adoption.

</details>


### [131] [Optimizing Mastery Learning by Fast-Forwarding Over-Practice Steps](https://arxiv.org/abs/2506.17577)
*Meng Xia,Robin Schmucker,Conrad Borchers,Vincent Aleven*

Main category: cs.CY

TL;DR: 提出并验证了一种题目步骤级的快进技术，能显著减少学生对已掌握技能的过度练习，提升学习效率。该方法易于集成到现有算法，但实际效果受学生难题挑战中的参与度影响。


<details>
  <summary>Details</summary>
Motivation: 尽管精熟学习能提升学习效率和效果，但学生过度练习已掌握技能的问题依旧是辅导系统的核心难题，现有方法主要通过改进题目选择算法和设计针对性练习任务来减少过度练习，很少关注题目步骤级的自适应。

Method: 提出了一种名为“快进（Fast-Forwarding）”的新技术作为现有问题选择算法的增强，基于真实学生数据建立的学习者模型与解题路径进行仿真研究，实现了在学生完全掌握之后可跳过剩余的解题步骤。

Result: 仿真结果表明，快进技术最多能将过度练习减少三分之一，特别是当与优先选择难题的问题选择算法结合时效果更佳。

Conclusion: 快进是一种灵活的方法，可以增强任何问题选择算法，提高学生练习的效率，但实际效果还依赖于学生在高难度练习中的动机和专注度。

Abstract: Mastery learning improves learning proficiency and efficiency. However, the
overpractice of skills--students spending time on skills they have already
mastered--remains a fundamental challenge for tutoring systems. Previous
research has reduced overpractice through the development of better problem
selection algorithms and the authoring of focused practice tasks. However, few
efforts have concentrated on reducing overpractice through step-level
adaptivity, which can avoid resource-intensive curriculum redesign. We propose
and evaluate Fast-Forwarding as a technique that enhances existing problem
selection algorithms. Based on simulation studies informed by learner models
and problem-solving pathways derived from real student data, Fast-Forwarding
can reduce overpractice by up to one-third, as it does not require students to
complete problem-solving steps if all remaining pathways are fully mastered.
Fast-Forwarding is a flexible method that enhances any problem selection
algorithm, though its effectiveness is highest for algorithms that
preferentially select difficult problems. Therefore, our findings suggest that
while Fast-Forwarding may improve student practice efficiency, the size of its
practical impact may also depend on students' ability to stay motivated and
engaged at higher levels of difficulty.

</details>


### [132] [Experimental Evidence for the Propagation and Preservation of Machine Discoveries in Human Populations](https://arxiv.org/abs/2506.17741)
*Levin Brinkmann,Thomas F. Eisenmann,Anne-Marie Nussberger,Maxim Derex,Sara Bonati,Valerii Chirkov,Iyad Rahwan*

Main category: cs.CY

TL;DR: 本论文提出，AI若能发现创新且具明显优势并易于学习的策略，便能持续推动人类文化和认知演进。这一机制通过实验和模拟得到验证，对理解AI时代的文化变迁具有深刻启示。


<details>
  <summary>Details</summary>
Motivation: 当前的AI系统不仅超越人类能力，还可能带来新的问题解决策略，这对人类文化和认知发展具有重要意义。然而，我们尚不明确AI从工具角色跃升为推动文化持久变革的具体条件。

Method: 作者使用了文化传递实验和基于模拟的智能体实验，系统性地分析和验证AI发现的策略在人群中的传递、理解与保留过程。

Result: 研究发现，若AI发现的策略具有非平凡性、可学习性及显著优势，这些策略便可被人类吸收并代际传承，最终引起持久的文化变迁。

Conclusion: 机器只要创造出具有实际优势且易于被人理解和学习的新策略，就能成为推动人类文化和认知持续扩展的新动力。这为理解AI对人类文化演化的深远影响提供了理论框架。

Abstract: Intelligent machines with superhuman capabilities have the potential to
uncover problem-solving strategies beyond human discovery. Emerging evidence
from competitive gameplay, such as Go, demonstrates that AI systems are
evolving from mere tools to sources of cultural innovation adopted by humans.
However, the conditions under which intelligent machines transition from tools
to drivers of persistent cultural change remain unclear. We identify three key
conditions for machines to fundamentally influence human problem-solving: the
discovered strategies must be non-trivial, learnable, and offer a clear
advantage. Using a cultural transmission experiment and an agent-based
simulation, we demonstrate that when these conditions are met,
machine-discovered strategies can be transmitted, understood, and preserved by
human populations, leading to enduring cultural shifts. These findings provide
a framework for understanding how machines can persistently expand human
cognitive skills and underscore the need to consider their broader implications
for human cognition and cultural evolution.

</details>


### [133] [The value of human and machine in machine-generated creative contents](https://arxiv.org/abs/2506.17808)
*Weina Jin*

Main category: cs.CY

TL;DR: 机器生成的内容如果没有人类解读，就无法与现实和经验建立联系，所谓的“创造力”其实是人机共同作用的结果。


<details>
  <summary>Details</summary>
Motivation: 当前机器生成内容表现出高度的“想象力”和“创造力”，但这些是否真正属于机器本身引发争议。该文旨在厘清人类与机器在内容生成中的实际作用和关系。

Method: 本文采用哲学性分析的方法，探讨机器生成内容与人类主观解读之间的关系。通过理论阐述说明为何人机协同是创造力的来源。

Result: 分析得出：机器生成内容的创造性本质上依赖于人类的解释，没有人类的参与，这些内容无法自动获得现实意义和经验基础。

Conclusion: 机器生成内容中的“想象力”和“创造力”并不能完全归功于机器本身。这种成就是人类与机器共同的结果。没有人类的解读，机器生成的内容无法自动与现实和人的经验建立联系。

Abstract: The seemingly "imagination" and "creativity" from machine-generated contents
should not be misattributed to the accomplishment of machine. They are
accomplishments of both human and machine. Without human interpretation, the
machine-generated contents remain in the imaginary space of the large language
models, and cannot automatically establish grounding in the reality and human
experience.

</details>


### [134] [The Democratic Paradox in Large Language Models' Underestimation of Press Freedom](https://arxiv.org/abs/2506.18045)
*I. Loaiza,R. Vestrelli,A. Fronzetti Colladon,R. Rigobon*

Main category: cs.CY

TL;DR: 主流大语言模型在评估各国新闻自由方面与专家评估存在系统性偏差，普遍低估多数国家的新闻自由，且对本国产生正向偏见。这种失真或影响公众对全球民主状况的理解，亟需改进模型的客观性和准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在全球范围内影响大量用户获取信息。由于其对信息的引导与偏见，可能影响公众对如新闻自由等重要民主制度的认知和信任。作者关注这些模型对新闻自由状态评价的准确性和潜在失真。

Method: 对六个主流LLMs进行实验，分析它们对180个国家新闻自由状况的评价，并与世界新闻自由指数（WPFI）专家评估结果进行系统对比，考察失真与偏见现象。

Result: 六个LLMs普遍低估新闻自由，全模型在71%-93%的国家中低于专家评价。发现“差异性失调”，即在新闻自由最强的国家被低估最严重。大多数模型对本国存在正向偏见，对本国新闻自由的评价比实际高7%-260%。

Conclusion: 当前热门LLMs在新闻自由这种关键民主议题上存在系统性偏见与失调，可能误导全球用户。随着LLMs在信息获取领域地位提升，需确保其对全球公民权益的客观准确表达。

Abstract: As Large Language Models (LLMs) increasingly mediate global information
access for millions of users worldwide, their alignment and biases have the
potential to shape public understanding and trust in fundamental democratic
institutions, such as press freedom. In this study, we uncover three systematic
distortions in the way six popular LLMs evaluate press freedom in 180 countries
compared to expert assessments of the World Press Freedom Index (WPFI). The six
LLMs exhibit a negative misalignment, consistently underestimating press
freedom, with individual models rating between 71% to 93% of countries as less
free. We also identify a paradoxical pattern we term differential misalignment:
LLMs disproportionately underestimate press freedom in countries where it is
strongest. Additionally, five of the six LLMs exhibit positive home bias,
rating their home countries' press freedoms more favorably than would be
expected given their negative misalignment with the human benchmark. In some
cases, LLMs rate their home countries between 7% to 260% more positively than
expected. If LLMs are set to become the next search engines and some of the
most important cultural tools of our time, they must ensure accurate
representations of the state of our human and civic rights globally.

</details>


### [135] [Aggregated Individual Reporting for Post-Deployment Evaluation](https://arxiv.org/abs/2506.18133)
*Jessica Dai,Inioluwa Deborah Raji,Benjamin Recht,Irene Y. Chen*

Main category: cs.CY

TL;DR: 本文提出AIR机制，让用户报告AI系统使用中的问题并聚合分析，实现更细致、民主的后部署评估；强调该方式有助发现新问题并推动AI系统改进，补足传统评估模式的不足，并给出实践路径和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统部署后的评估局限于静态基准测试，无法反映真实使用中的问题，同时人们对于AI系统权力集中的担忧，推动了对“民主”或“公众”AI的兴趣。科学有效地引入公众参与AI系统评估成为一个重要需求。

Method: 提出聚合个人报告（AIR）的机制，作为一种新的部署后评估框架。该机制允许用户在与AI系统交互遇到问题时进行个人报告，随后将这些报告进行汇总分析，从而实现更加细致的后期评估。本工作还详述了AIR机制的设计流程及未来进一步研究需要关注的问题。

Result: AIR机制能够发现以往静态测评难以捕捉的安全性和性能新问题，聚合分析为后续改进行动提供依据，也为民主化AI现实路径和理论提出了支持。本文明确阐释了实践中的设计要点和后续研究方向。

Conclusion: 个人体验报告应成为AI系统部署后评估的重要组成部分。聚合报告机制不仅拓宽了对AI系统性能和安全性的认识方式，也为实现‘民主’AI增添了可实施路径，并呼吁后续深入完善相关流程和方法。

Abstract: The need for developing model evaluations beyond static benchmarking,
especially in the post-deployment phase, is now well-understood. At the same
time, concerns about the concentration of power in deployed AI systems have
sparked a keen interest in 'democratic' or 'public' AI. In this work, we bring
these two ideas together by proposing mechanisms for aggregated individual
reporting (AIR), a framework for post-deployment evaluation that relies on
individual reports from the public. An AIR mechanism allows those who interact
with a specific, deployed (AI) system to report when they feel that they may
have experienced something problematic; these reports are then aggregated over
time, with the goal of evaluating the relevant system in a fine-grained manner.
This position paper argues that individual experiences should be understood as
an integral part of post-deployment evaluation, and that the scope of our
proposed aggregated individual reporting mechanism is a practical path to that
end. On the one hand, individual reporting can identify substantively novel
insights about safety and performance; on the other, aggregation can be
uniquely useful for informing action. From a normative perspective, the
post-deployment phase completes a missing piece in the conversation about
'democratic' AI. As a pathway to implementation, we provide a workflow of
concrete design decisions and pointers to areas requiring further research and
methodological development.

</details>


<div id='q-fin.TR'></div>

# q-fin.TR [[Back]](#toc)

### [136] [Causal Interventions in Bond Multi-Dealer-to-Client Platforms](https://arxiv.org/abs/2506.18147)
*Paloma Marín,Sergio Ardanza-Trevijano,Javier Sabio*

Main category: q-fin.TR

TL;DR: 本文提出了一套用于多交易商对客户平台（MD2C）谈判分析的概率与机器学习模型框架，并通过实验展示其对定价与收益优化的实际效果，强调理解谈判机制的重要性。


<details>
  <summary>Details</summary>
Motivation: 金融市场数字化导致交易模式从语音转向电子化，多交易商对客户（MD2C）平台让客户可以同时向多个交易商请求报价（RfQ）。在此高度竞争但价格彼此不可见的环境下，交易商需要严谨地分析谈判过程以保持盈利。本文旨在为这一问题建立分析框架。

Method: 本文提出一种基于概率图模型与因果推断的通用分析框架，探讨RfQ流程中交易商的最优定价、潜在收益估算和客户识别等推断问题。同时，分析了两类模型：基于生成式模型（Fermanian, Guéant & Pu, 2017工作）和利用机器学习的判别式模型，并通过定价场景下的预测指标进行评估。

Result: 实验结果显示，不同模型在最优定价方面有不同表现，能够对实际MD2C平台交易商的定价策略与收益预测提供有效支持，并突出了理解谈判过程内部机制模型的优势。

Conclusion: 基于概率图模型和因果推断的分析框架能有效评估MD2C平台环境中交易商的多策略，帮助优化定价和提升收益，对实务具有应用价值。

Abstract: The digitalization of financial markets has shifted trading from voice to
electronic channels, with Multi-Dealer-to-Client (MD2C) platforms now enabling
clients to request quotes (RfQs) for financial instruments like bonds from
multiple dealers simultaneously. In this competitive landscape, dealers cannot
see each other's prices, making a rigorous analysis of the negotiation process
crucial to ensure their profitability. This article introduces a novel general
framework for analyzing the RfQ process using probabilistic graphical models
and causal inference. Within this framework, we explore different inferential
questions that are relevant for dealers participating in MD2C platforms, such
as the computation of optimal prices, estimating potential revenues and the
identification of clients that might be interested in trading the dealer's
axes. We then move into analyzing two different approaches for model
specification: a generative model built on the work of (Fermanian, Gu\'eant &
Pu, 2017); and discriminative models utilizing machine learning techniques. We
evaluate these methodologies using predictive metrics designed to assess their
effectiveness in the context of optimal pricing, highlighting the relative
benefits of using models that take into account the internal mechanisms of the
negotiation process.

</details>
