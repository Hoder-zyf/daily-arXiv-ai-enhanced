<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 92]
- [cs.CL](#cs.CL) [Total: 98]
- [cs.CE](#cs.CE) [Total: 30]
- [cs.CY](#cs.CY) [Total: 40]
- [q-fin.TR](#q-fin.TR) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Evaluating Generalization and Representation Stability in Small LMs via Prompting](https://arxiv.org/abs/2506.17289)
*Rahul Raja,Arpita Vats*

Main category: cs.AI

TL;DR: 本文全面对比小型语言模型在prompt与微调两种范式下的泛化能力，重点关注分布外及低资源任务，通过内部表征分析揭示两者机制差异，助力实际策略选择。


<details>
  <summary>Details</summary>
Motivation: 当前prompt方法因参数高效被广泛使用，但其在低资源和分布漂移情况下的鲁棒性尚不明确，相关对比和实证分析亟需深入。

Method: 对比实验，涵盖不同任务格式、prompt风格和模型规模，分别研究prompt和微调策略在分布内外场景下的表现。同时，分析模型内部表征，评价任务特征抽象与稳定性。

Result: 两种适应方式在内部知识建模、泛化性能及特征抽象上机制迥异。研究发现针对不同低数据场景适合不同策略，并为具体模型选择提供实证依据。

Conclusion: 小型语言模型在few-shot prompt和监督微调两种适应范式下展现出不同的泛化能力，尤其是在分布外测试和低资源情况下，两者表现存在显著差异。

Abstract: We investigate the generalization capabilities of small language models under
two popular adaptation paradigms: few-shot prompting and supervised
fine-tuning. While prompting is often favored for its parameter efficiency and
flexibility, it remains unclear how robust this approach is in low-resource
settings and under distributional shifts. This paper presents a comparative
study of prompting and fine-tuning across task formats, prompt styles, and
model scales, with a focus on their behavior in both in-distribution and
out-of-distribution (OOD) settings.
  Beyond accuracy, we analyze the internal representations learned by each
approach to assess the stability and abstraction of task-specific features. Our
findings highlight critical differences in how small models internalize and
generalize knowledge under different adaptation strategies. This work offers
practical guidance for model selection in low-data regimes and contributes
empirical insight into the ongoing debate over prompting versus fine-tuning.
Code for the experiments is available at the following

</details>


### [2] [Individual Causal Inference with Structural Causal Model](https://arxiv.org/abs/2506.17300)
*Daniel T. Chang*

Main category: cs.AI

TL;DR: 本文提出了用于个体因果推断（ICI）的结构因果模型（SCM）新方法，引入了indiv-operator和个体因果查询，突破了传统只能做群体因果推断的限制，实现了对特定个体的干预推理，适用于精准医疗等领域。


<details>
  <summary>Details</summary>
Motivation: 现有因果推断多基于群体层面，但实际问题常常需要针对特定个体推断干预效应（个体因果效应，ICE），而个体数据有限、现有方法难以直接应用。本文旨在解决个体层面因果推断的理论与方法难题。

Method: 作者通过引入“indiv-operator”（indiv(W)）将群体模型个体化，并提出了针对个体的因果查询P(Y | indiv(W), do(X), Z)。这种方法将个体特征编码进SCM的外生变量中，实现对特定个体的因果效应推理。

Result: 作者提出的ICI-with-SCM方法表明，可以通过对外生变量的建模和特定运算，实现对个体的干预效应推断。ICI关注的是可能的个体结果（individual alternatives），而非反事实（counterfactuals）。新方法能更科学地支持精准医疗等领域的个体决策。

Conclusion: 本文提出了基于结构因果模型（SCM）的个体因果推断（ICI）方法，并通过形式化个体化运算符和查询方式，完善了对个体层面的因果推断框架，强调了其为“第三级因果推断（rung 3）”。

Abstract: Individual causal inference (ICI) uses causal inference methods to understand
and predict the effects of interventions on individuals, considering their
specific characteristics / facts. It aims to estimate individual causal effect
(ICE), which varies across individuals. Estimating ICE can be challenging due
to the limited data available for individuals, and the fact that most causal
inference methods are population-based. Structural Causal Model (SCM) is
fundamentally population-based. Therefore, causal discovery (structural
learning and parameter learning), association queries and intervention queries
are all naturally population-based. However, exogenous variables (U) in SCM can
encode individual variations and thus provide the mechanism for individualized
population per specific individual characteristics / facts. Based on this, we
propose ICI with SCM as a "rung 3" causal inference, because it involves
"imagining" what would be the causal effect of a hypothetical intervention on
an individual, given the individual's observed characteristics / facts.
Specifically, we propose the indiv-operator, indiv(W), to formalize/represent
the population individualization process, and the individual causal query, P(Y
| indiv(W), do(X), Z), to formalize/represent ICI. We show and argue that ICI
with SCM is inference on individual alternatives (possible), not individual
counterfactuals (non-actual).

</details>


### [3] [Resource Rational Contractualism Should Guide AI Alignment](https://arxiv.org/abs/2506.17434)
*Sydney Levine,Matija Franklin,Tan Zhi-Xuan,Secil Yanik Guyot,Lionel Wong,Daniel Kilov,Yejin Choi,Joshua B. Tenenbaum,Noah Goodman,Seth Lazar,Iason Gabriel*

Main category: cs.AI

TL;DR: 本文提出资源理性契约主义（RRC）框架，借助启发式方式高效逼近多元人类共识，从而提升AI伦理对齐与社会适应能力。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统逐渐融入人类社会环境，其决策将影响目标和价值观不同的人类与AI代理。如何让AI的决策被更多利益相关者认可，成为了实现AI伦理对齐的重要挑战。然而，现实中大规模达成这种共识成本高昂，并且效率较低。

Method: 作者提出了资源理性契约主义（Resource-Rational Contractualism, RRC）框架，主张AI借鉴一套规范性基础和认知启发式工具，权衡决策努力与准确性，实现对准人类社会共识的近似。

Result: RRC框架使AI代理不但高效运行，还能够实时适应和解读不断变化的人类社会世界，从而更好地融入人类环境并获得多元主体的广泛认可。

Conclusion: RRC为实现AI系统与人类社会在决策上的高效且动态的伦理对齐提供了新路径，兼顾效率与适应性。

Abstract: AI systems will soon have to navigate human environments and make decisions
that affect people and other AI agents whose goals and values diverge.
Contractualist alignment proposes grounding those decisions in agreements that
diverse stakeholders would endorse under the right conditions, yet securing
such agreement at scale remains costly and slow -- even for advanced AI. We
therefore propose Resource-Rational Contractualism (RRC): a framework where AI
systems approximate the agreements rational parties would form by drawing on a
toolbox of normatively-grounded, cognitively-inspired heuristics that trade
effort for accuracy. An RRC-aligned agent would not only operate efficiently,
but also be equipped to dynamically adapt to and interpret the ever-changing
human social world.

</details>


### [4] [Keeping Medical AI Healthy: A Review of Detection and Correction Methods for System Degradation](https://arxiv.org/abs/2506.17442)
*Hao Guan,David Bates,Li Zhou*

Main category: cs.AI

TL;DR: 本文综述了医疗AI系统在实际应用中因多种因素导致性能退化的问题，系统总结了监控、检测、分析及纠正退化的技术方法，并提出了未来的研究方向，旨在推动医疗AI系统的长期安全和可靠应用。


<details>
  <summary>Details</summary>
Motivation: 人工智能（AI）在现代医疗中的应用日益广泛，但在实际环境下，随着数据分布、患者特征、临床协议以及数据质量的持续变化，AI系统的性能可能随着时间推移而下降。这种退化带来了模型可靠性及患者安全性风险，因此迫切需要监控和维护AI系统的“健康”。

Method: 本综述系统总结了AI性能退化的常见原因，梳理了数据和模型漂移的检测技术，详细介绍了根本原因分析，并审查了包括模型再训练、测试时自适应在内的纠正方案，涵盖传统机器学习模型和先进的大语言模型（LLMs），并讨论了当前技术挑战及未来研究方向。

Result: 本文归纳了检测和纠正医疗AI系统退化的现有方法及各自的优缺点，提出了尚待解决的技术难题及未来的研究重点，为持续可靠部署医疗AI提出了建设性建议。

Conclusion: 本综述为医疗AI系统的持续、可靠和安全部署提供了系统性指导，对未来医疗AI的监控与自纠机制研究具有重要参考价值。

Abstract: Artificial intelligence (AI) is increasingly integrated into modern
healthcare, offering powerful support for clinical decision-making. However, in
real-world settings, AI systems may experience performance degradation over
time, due to factors such as shifting data distributions, changes in patient
characteristics, evolving clinical protocols, and variations in data quality.
These factors can compromise model reliability, posing safety concerns and
increasing the likelihood of inaccurate predictions or adverse outcomes. This
review presents a forward-looking perspective on monitoring and maintaining the
"health" of AI systems in healthcare. We highlight the urgent need for
continuous performance monitoring, early degradation detection, and effective
self-correction mechanisms. The paper begins by reviewing common causes of
performance degradation at both data and model levels. We then summarize key
techniques for detecting data and model drift, followed by an in-depth look at
root cause analysis. Correction strategies are further reviewed, ranging from
model retraining to test-time adaptation. Our survey spans both traditional
machine learning models and state-of-the-art large language models (LLMs),
offering insights into their strengths and limitations. Finally, we discuss
ongoing technical challenges and propose future research directions. This work
aims to guide the development of reliable, robust medical AI systems capable of
sustaining safe, long-term deployment in dynamic clinical settings.

</details>


### [5] [OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections](https://arxiv.org/abs/2506.17449)
*Manasa Bharadwaj,Nikhil Verma,Kevin Ferreira*

Main category: cs.AI

TL;DR: OmniReflect通过分层反思和知识积累机制，为LLM代理引入了高效、可迁移的任务表现提升路径，实验证明其在多个复杂任务上取得显著进展。


<details>
  <summary>Details</summary>
Motivation: 以往提升大语言模型（LLM）代理在复杂任务上的表现，主要依赖微调和自我纠错，这些方法在动态环境下缺乏通用的长期学习机制，效率也不高。因此，寻求一种高效且具可迁移性的学习机制。

Method: 提出OmniReflect框架，这是一种分层、反思驱动的结构，通过构建宪法（从任务经验中提炼的指导原则）来提升LLM代理的表现。OmniReflect包括自我维持模式（单一代理在任务执行中定期总结反思）和协作模式（元顾问根据校准集为代理制定宪法）。宪法的构建采用神经、符号、神经-符号等多种技术，兼顾上下文适应性和计算效率。

Result: 实验证明，在自我维持模式下，OmniReflect在多个数据集上显著提升了任务成功率：ALFWorld提升+10.3%，BabyAI提升+23.8%，PDDL提升+8.3%。在协作模式下，轻量Qwen3-4B ReAct代理全面优于Reflexion基线方法。

Conclusion: OmniReflect框架在不同环境和模型基础上都展现了良好的稳健性和有效性，是提升LLM智能体长期表现的有力工具。

Abstract: Efforts to improve Large Language Model (LLM) agent performance on complex
tasks have largely focused on fine-tuning and iterative self-correction.
However, these approaches often lack generalizable mechanisms for longterm
learning and remain inefficient in dynamic environments. We introduce
OmniReflect, a hierarchical, reflection-driven framework that constructs a
constitution, a compact set of guiding principles distilled from task
experiences, to enhance the effectiveness and efficiency of an LLM agent.
OmniReflect operates in two modes: Self-sustaining, where a single agent
periodically curates its own reflections during task execution, and
Co-operative, where a Meta-advisor derives a constitution from a small
calibration set to guide another agent. To construct these constitutional
principles, we employ Neural, Symbolic, and NeuroSymbolic techniques, offering
a balance between contextual adaptability and computational efficiency.
Empirical results averaged across models show major improvements in task
success, with absolute gains of +10.3% on ALFWorld, +23.8% on BabyAI, and +8.3%
on PDDL in the Self-sustaining mode. Similar gains are seen in the Co-operative
mode, where a lightweight Qwen3-4B ReAct agent outperforms all Reflexion
baselines on BabyAI. These findings highlight the robustness and effectiveness
of OmniReflect across environments and backbones.

</details>


### [6] [From Unstructured Communication to Intelligent RAG: Multi-Agent Automation for Supply Chain Knowledge Bases](https://arxiv.org/abs/2506.17484)
*Yao Zhang,Zaixi Shang,Silpan Patel,Mikel Zuniga*

Main category: cs.AI

TL;DR: 作者提出基于大模型和多智能体的离线结构化方案，从原始支持工单等非结构化数据中自动构建高质量、可复用的知识库，大幅提升RAG系统效果，实现供应链运维知识自动沉淀和高效利用。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统面对原始运维对话数据（如工单、邮件、聊天记录）时，由于这些数据噪音多、不完全且不一致，导致检索效果受限。因此需要一种能将非结构化通信转为高质量知识库的方法，从而释放专家沉淀知识，实现知识共享和运维自动化。

Method: 论文设计了一套由三个专用智能体（类别发现、归类和知识合成）协作的多智能体系统。该系统首先对原始支持工单进行分类、归类，然后生成结构化的知识文章，最终形成用于RAG系统的紧凑知识库。

Result: 本方法在真实工单应用中，把知识库体积缩减至原始数据的3.4%，且提升了RAG系统的答案有用率（48.74% vs. 38.60%），同时无用回答减少77.4%。系统能自动化解决近50%的后续供应链工单，大幅降低工作负担并提升响应速度。

Conclusion: 该论文提出了一种通过多智能体大模型（LLMs-based multi-agent system）自动提取、结构化和重组供应链非结构化运维数据的离线优先方案，这种方式显著提升了知识管理效率及RAG系统的有效性。

Abstract: Supply chain operations generate vast amounts of operational data; however,
critical knowledge such as system usage practices, troubleshooting workflows,
and resolution techniques often remains buried within unstructured
communications like support tickets, emails, and chat logs. While RAG systems
aim to leverage such communications as a knowledge base, their effectiveness is
limited by raw data challenges: support tickets are typically noisy,
inconsistent, and incomplete, making direct retrieval suboptimal. Unlike
existing RAG approaches that focus on runtime optimization, we introduce a
novel offline-first methodology that transforms these communications into a
structured knowledge base. Our key innovation is a LLMs-based multi-agent
system orchestrating three specialized agents: Category Discovery for taxonomy
creation, Categorization for ticket grouping, and Knowledge Synthesis for
article generation. Applying our methodology to real-world support tickets with
resolution notes and comments, our system creates a compact knowledge base -
reducing total volume to just 3.4% of original ticket data while improving
quality. Experiments demonstrate that our prebuilt knowledge base in RAG
systems significantly outperforms traditional RAG implementations (48.74% vs.
38.60% helpful answers) and achieves a 77.4% reduction in unhelpful responses.
By automating institutional knowledge capture that typically remains siloed in
experts' heads, our solution translates to substantial operational efficiency:
reducing support workload, accelerating resolution times, and creating
self-improving systems that automatically resolve approximately 50% of future
supply chain tickets. Our approach addresses a key gap in knowledge management
by transforming transient communications into structured, reusable knowledge
through intelligent offline processing rather than latency-inducing runtime
architectures.

</details>


### [7] [Kaleidoscopic Teaming in Multi Agent Simulations](https://arxiv.org/abs/2506.17514)
*Ninareh Mehrabi,Tharindu Kumarage,Kai-Wei Chang,Aram Galstyan,Rahul Gupta*

Main category: cs.AI

TL;DR: 该论文提出了针对AI智能体在复杂单体/多体场景下安全漏洞的新评测框架（kaleidoscopic teaming），通过生成多样化现实场景和创新优化手段，发现并量化了智能体在实际应用中的安全漏洞，弥补了现有安全评估方法的不足。


<details>
  <summary>Details</summary>
Motivation: 当前AI智能体由于其自主工具使用能力和实际应用的广泛性，带来了前所未有的安全挑战，现有的红队测试或安全评估框架难以评估其复杂交互过程中的安全风险，尤其在多智能体场景下更为突出。

Method: 作者提出了“多棱镜团队（kaleidoscopic teaming）”的新框架，能够生成多样化的模拟真实社会的复杂场景，分别对单智能体和多智能体的安全风险进行系统评估。方法包括场景生成、安全漏洞捕捉、新的上下文优化技术，以及量化安全评估的指标。单智能体任务聚焦其自主完成工具使用，多智能体任务模拟协作或对抗。

Result: 利用所提出的kaleidoscopic teaming框架，作者在不同的模型中识别和分析了其在实际智能体应用场景下的具体安全漏洞。

Conclusion: 现有安全测试框架难以覆盖AI智能体在复杂任务和多智能体交互下的全部安全风险，所提出的新框架能够更加全面且有效地评估和揭示这些安全隐患，对增强AI系统安全具有重要意义。

Abstract: Warning: This paper contains content that may be inappropriate or offensive.
  AI agents have gained significant recent attention due to their autonomous
tool usage capabilities and their integration in various real-world
applications. This autonomy poses novel challenges for the safety of such
systems, both in single- and multi-agent scenarios. We argue that existing red
teaming or safety evaluation frameworks fall short in evaluating safety risks
in complex behaviors, thought processes and actions taken by agents. Moreover,
they fail to consider risks in multi-agent setups where various vulnerabilities
can be exposed when agents engage in complex behaviors and interactions with
each other. To address this shortcoming, we introduce the term kaleidoscopic
teaming which seeks to capture complex and wide range of vulnerabilities that
can happen in agents both in single-agent and multi-agent scenarios. We also
present a new kaleidoscopic teaming framework that generates a diverse array of
scenarios modeling real-world human societies. Our framework evaluates safety
of agents in both single-agent and multi-agent setups. In single-agent setup,
an agent is given a scenario that it needs to complete using the tools it has
access to. In multi-agent setup, multiple agents either compete against or
cooperate together to complete a task in the scenario through which we capture
existing safety vulnerabilities in agents. We introduce new in-context
optimization techniques that can be used in our kaleidoscopic teaming framework
to generate better scenarios for safety analysis. Lastly, we present
appropriate metrics that can be used along with our framework to measure safety
of agents. Utilizing our kaleidoscopic teaming framework, we identify
vulnerabilities in various models with respect to their safety in agentic
use-cases.

</details>


### [8] [Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models](https://arxiv.org/abs/2506.17585)
*Yukun Huang,Sanxing Chen,Jian Pei,Manzil Zaheer,Bhuwan Dhingra*

Main category: cs.AI

TL;DR: 该文提出Active Indexing训练法，让大模型无须测试时检索即可可靠归因于预训练文档，显著提升多类问题下的引用精度。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型回答需要可验证的引用，但常常“幻觉”产生不可靠的引用。主流做法通过外部检索插入引用，带来延迟和噪声问题。作者希望在不依赖测试时检索的前提下，提高模型自身的引用可靠性。

Method: 提出一种两阶段训练流程：（1）持续预训练，将事实和文档ID绑定；（2）指令微调以诱导引用行为。比较了两种方法：Passive Indexing（直接附加ID）与Active Indexing（持续基于合成QA对、多样化表达训练、事实与来源双向生成）。

Result: Active Indexing在所有任务和模型上表现优于Passive Indexing，引用精度最高提升30.2%；且随着增强数据量增加，性能持续提升。

Conclusion: 通过在预训练阶段积极融合文档归属信息，模型在无需实时检索下显著提升了引用准确性和可验证性。

Abstract: Trustworthy language models should provide both correct and verifiable
answers. While language models can sometimes attribute their outputs to
pretraining data, their citations are often unreliable due to hallucination. As
a result, current systems insert citations by querying an external retriever at
inference time, introducing latency, infrastructure dependence, and
vulnerability to retrieval noise. We explore whether LLMs can be made to
reliably attribute to the documents seen during (continual)
pretraining--without test-time retrieval--by revising the training process. To
evaluate this, we release CitePretrainBench, a benchmark that mixes real-world
corpora (Wikipedia, Common Crawl, arXiv) with novel, unseen documents and
probes both short-form (single fact) and long-form (multi-fact) citation tasks.
Our approach follows a two-stage process: (1) continual pretraining to bind
facts to persistent document identifiers, and (2) instruction tuning to elicit
citation behavior. We find that simple Passive Indexing, which appends an
identifier to each document, helps memorize verbatim text but fails on
paraphrased or compositional facts. Instead, we propose Active Indexing, which
continually pretrains on synthetic QA pairs that (1) restate each fact in
diverse compositional forms, and (2) require bidirectional source-to-fact and
fact-to-source generation, jointly teaching the model to generate content from
a cited source and to attribute its own answers. Experiments with Qwen2.5-7B
and 3B show that Active Indexing consistently outperforms Passive Indexing
across all tasks and models, with citation precision gains up to 30.2 percent.
Our ablation studies reveal that performance continues to improve as we scale
the amount of augmented data, showing a clear upward trend even at 16 times the
original token count.

</details>


### [9] [Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to Conquer the Unknown](https://arxiv.org/abs/2506.17589)
*Bowen Wang*

Main category: cs.AI

TL;DR: 本文针对多模态大模型在特定领域知识不足的问题，构建了游戏领域的多模态知识图谱，并设计复杂检索与推理测试，引入多智能体检索方法，显著提升了模型相关能力，为多模态知识增强研究提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型在常见任务表现优秀，但在罕见领域任务中常因知识不足而表现不佳，因此亟需探索提升其罕见领域知识利用能力的方法。

Method: 本文以视觉游戏认知为实验平台，选择《怪物猎人：世界》作为目标，构建了涵盖多模态和复杂实体关系的多模态知识图谱（MH-MMKG），并基于此设计了复杂知识检索和推理挑战。同时，提出了一种多智能体检索器，无需额外训练即可自动检索相关知识。

Result: 实验表明，所提出的方法显著提升了多模态大模型在复杂知识检索和推理方面的表现。

Conclusion: 通过多模态知识图谱和多智能体检索机制，推动了多模态大模型在复杂领域知识利用和推理能力上的进步，为未来多模态知识增强推理研究奠定了基础。

Abstract: The real value of knowledge lies not just in its accumulation, but in its
potential to be harnessed effectively to conquer the unknown. Although recent
multimodal large language models (MLLMs) exhibit impressing multimodal
capabilities, they often fail in rarely encountered domain-specific tasks due
to limited relevant knowledge. To explore this, we adopt visual game cognition
as a testbed and select Monster Hunter: World as the target to construct a
multimodal knowledge graph (MH-MMKG), which incorporates multi-modalities and
intricate entity relations. We also design a series of challenging queries
based on MH-MMKG to evaluate the models' ability for complex knowledge
retrieval and reasoning. Furthermore, we propose a multi-agent retriever that
enables a model to autonomously search relevant knowledge without additional
training. Experimental results show that our approach significantly enhances
the performance of MLLMs, providing a new perspective on multimodal
knowledge-augmented reasoning and laying a solid foundation for future
research.

</details>


### [10] [Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges](https://arxiv.org/abs/2506.17644)
*Zimo Ji,Daoyuan Wu,Wenyuan Jiang,Pingchuan Ma,Zongjie Li,Shuai Wang*

Main category: cs.AI

TL;DR: 作者提出CTFKnow基准系统系统性评估了LLM在CTF知识的理解与应用，发现LLM知识丰富但实战表现受限。为此，作者设计了CTFAgent框架，通过检索增强和环境交互，显著提升了解题能力，在实际赛事中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）的发展，其在CTF（夺旗赛）自动化解题方面的潜力备受关注。当前，相关赛事（如DARPA的AIxCC）旨在推动AI在进攻和防御自动化上的应用。然而，CTF自动化需要多种能力的结合，尤其是技术知识理解与实际应用。本文旨在突出技术知识在CTF解题中的重要性，并评估现有LLM在该方面的表现。

Method: 作者构建了CTFKnow基准集，包含3992道题，用于衡量LLM在CTF技术知识方面的能力。通过实证评测分析LLM的技术知识理解及应用，并针对发现的不足提出了CTFAgent系统。CTFAgent包含两阶段的检索增强生成（RAG）与交互式环境增强两个新模块，分别提升LLM的专业知识和漏洞利用能力。最后，通过在两个主流CTF数据集及picoCTF2024赛事中实验，验证了该框架的有效性。

Result: CTFKnow基准测试发现，LLM虽然具有丰富的CTF技术知识，但在具体场景应用和基于环境反馈调整解题策略方面表现不足。提出的CTFAgent框架在两个CTF数据集上的性能提升超过80%，并在picoCTF2024全球排名前23.6%。

Conclusion: 技术知识理解是LLM自动化解CTF的核心挑战。针对现有LLM在应用和适应方面的不足，提出的CTFAgent通过增强知识检索与交互显著提升了解题表现，展示了AI辅助CTF的巨大潜力。

Abstract: Capture-the-Flag (CTF) competitions are crucial for cybersecurity education
and training. As large language models (LLMs) evolve, there is increasing
interest in their ability to automate CTF challenge solving. For example, DARPA
has organized the AIxCC competition since 2023 to advance AI-powered automated
offense and defense. However, this demands a combination of multiple abilities,
from knowledge to reasoning and further to actions. In this paper, we highlight
the importance of technical knowledge in solving CTF problems and deliberately
construct a focused benchmark, CTFKnow, with 3,992 questions to measure LLMs'
performance in this core aspect. Our study offers a focused and innovative
measurement of LLMs' capability in understanding CTF knowledge and applying it
to solve CTF challenges. Our key findings reveal that while LLMs possess
substantial technical knowledge, they falter in accurately applying this
knowledge to specific scenarios and adapting their strategies based on feedback
from the CTF environment.
  Based on insights derived from this measurement study, we propose CTFAgent, a
novel LLM-driven framework for advancing CTF problem-solving. CTFAgent
introduces two new modules: two-stage Retrieval Augmented Generation (RAG) and
interactive Environmental Augmentation, which enhance LLMs' technical knowledge
and vulnerability exploitation on CTF, respectively. Our experimental results
show that, on two popular CTF datasets, CTFAgent both achieves over 80%
performance improvement. Moreover, in the recent picoCTF2024 hosted by CMU,
CTFAgent ranked in the top 23.6% of nearly 7,000 participating teams. This
reflects the benefit of our measurement study and the potential of our
framework in advancing LLMs' capabilities in CTF problem-solving.

</details>


### [11] [PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models](https://arxiv.org/abs/2506.17667)
*Lintao Wang,Encheng Su,Jiaqi Liu,Pengze Li,Peng Xia,Jiabei Xiao,Wenlong Zhang,Xinnan Dai,Xi Chen,Yuan Meng,Mingyu Ding,Lei Bai,Wanli Ouyang,Shixiang Tang,Aoran Wang,Xinzhu Ma*

Main category: cs.AI

TL;DR: 提出了大学物理多模态基准PhysUniBench，覆盖3304题评价大模型推理能力。实验发现主流模型如GPT-4o mini准确率仅34.2%，在复杂物理推理和图像解读上明显不足。该基准将推动更高级别的AI物理推理能力的研究。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型在解决大学物理问题上表现有限，现有评价方法难以全面反映模型在物理领域的推理和理解能力。因此，亟需一个高质量、广覆盖性的新基准用于系统性评测AI在物理领域的表现。

Method: 提出了大规模多模态物理基准PhysUniBench，涵盖3304道题目、8个物理子领域，每题配有示意图，包含开放式与选择题。通过专家评审、多轮数据采集、自动筛选简单题目、五级难度评分等多阶段流程构建，可全面评估AI的物理推理能力。

Result: 当前最先进的大模型（如GPT-4o mini）在PhysUniBench上的准确率仅为34.2%，在多步骤推理和图像解析类问题上表现尤为不足。

Conclusion: PhysUniBench作为严苛且多维的测评工具，揭示了现有大模型在高阶物理推理方面的短板，有望推动更强物理推理和多模态理解能力AI模型的发展。

Abstract: Physics problem-solving is a challenging domain for large AI models,
requiring integration of conceptual understanding, mathematical reasoning, and
interpretation of physical diagrams. Current evaluation methodologies show
notable limitations in capturing the breadth and complexity of
undergraduate-level physics, underscoring the need for more rigorous
assessments. To this end, we present PhysUniBench, a large-scale multimodal
benchmark designed to evaluate and improve the reasoning capabilities of
multimodal large language models (MLLMs) specifically on undergraduate-level
physics problems. PhysUniBench consists of 3,304 physics questions spanning 8
major sub-disciplines of physics, each accompanied by one visual diagrams. The
benchmark includes both open-ended and multiple-choice questions,
systematically curated and difficulty-rated through an iterative
model-in-the-loop process. The benchmark's construction involved a rigorous
multi-stage process, including multiple roll-outs, expert-level evaluation,
automated filtering of easily solved problems, and a nuanced difficulty grading
system with five levels. Through extensive experiments, we observe that current
state-of-the-art models encounter substantial challenges in physics reasoning.
For example, GPT-4o mini achieves only about 34.2\% accuracy in the proposed
PhysUniBench. These results highlight that current MLLMs struggle with advanced
physics reasoning, especially on multi-step problems and those requiring
precise diagram interpretation. By providing a broad and rigorous assessment
tool, PhysUniBench aims to drive progress in AI for Science, encouraging the
development of models with stronger physical reasoning, problem-solving skills,
and multimodal understanding. The benchmark and evaluation scripts are
available at https://prismax-team.github.io/PhysUniBenchmark/.

</details>


### [12] [Beyond Syntax: Action Semantics Learning for App Agents](https://arxiv.org/abs/2506.17697)
*Bohan Tang,Dezhao Luo,Jingxuan Chen,Shaogang Gong,Jianye Hao,Jun Wang,Kun Shao*

Main category: cs.AI

TL;DR: 本文提出动作语义学习（ASL）框架，通过学习动作带来的语义状态变化而非仅仅复现动作字符串，使App Agent在优化计算效率和提升分布外鲁棒性的同时，极大增强了准确率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于闭源大模型API的App Agent方案计算开销大且依赖外部API，而基于开源小模型的微调虽然解决了这一问题，但当前微调方法存在对语法严格拟合，导致模型对分布外数据（OOD）易失效。

Method: 提出了一种新的学习框架——动作语义学习（Action Semantics Learning, ASL），以动作的语义（即在用户界面上引发的状态变化）为学习目标，借助语义估算器（SEmantic Estimator, SEE）为Agent生成的动作计算语义奖励，从而训练模型学习语义一致的动作输出，而非严格复现语法形式。

Result: 理论上验证了ASL在分布外数据场景下的鲁棒性优于传统语法学习，并通过大量离线和在线的App操作基准测试，实验证明ASL显著提升了App Agent的准确率和泛化能力。

Conclusion: ASL框架通过关注动作语义而非单纯语法复现，提升了App Agent在智能手机应用操作任务中的表现，特别是在面对分布外场景时具有更高的鲁棒性和泛化能力。

Abstract: The advent of Large Language Models (LLMs) enables the rise of App agents
that interpret user intent and operate smartphone Apps through actions such as
clicking and scrolling. While prompt-based solutions with closed LLM APIs show
promising ability, they incur heavy compute costs and external API dependency.
Fine-tuning smaller open-source LLMs solves these limitations. However, current
fine-tuning methods use a syntax learning paradigm that forces agents to
reproduce exactly the ground truth action strings, leading to
out-of-distribution (OOD) vulnerability. To fill this gap, we propose Action
Semantics Learning (ASL), a novel learning framework, where the learning
objective is capturing the semantics of the ground truth actions. Specifically,
inspired by the programming language theory, we define the action semantics for
App agents as the state transition induced by the action in the user interface.
With this insight, ASL employs a novel SEmantic Estimator (SEE) to compute a
semantic reward to train the App agents in generating actions aligned with the
semantics of ground truth actions, even when the syntactic forms differ. To
support the effectiveness of ASL, we theoretically demonstrate the superior
robustness of ASL for the OOD problem compared with the existing syntax
learning paradigm. Extensive experiments on offline and online smartphone App
operation benchmarks show that ASL significantly improves the accuracy and
generalisation of App agents over existing methods.

</details>


### [13] [AnyMAC: Cascading Flexible Multi-Agent Collaboration via Next-Agent Prediction](https://arxiv.org/abs/2506.17784)
*Song Wang,Zhen Tan,Zihan Chen,Shuang Zhou,Tianlong Chen,Jundong Li*

Main category: cs.AI

TL;DR: 该文提出用顺序结构替代传统图结构，实现更灵活高效的LLM多智能体通信，并通过动态角色选择和上下文访问，大幅提升了性能和通信效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体协作方法大多依赖静态或基于图的通信结构，缺乏适应性和灵活性，限制了通信表现力。作者希望提升多智能体通信的灵活性和适应性。

Method: 提出以顺序结构（而非图结构）为核心的多智能体通信框架，并包括两个关键模块：（1）Next-Agent Prediction，动态选择每一步最合适的智能体角色；（2）Next-Context Selection（NCS），让每个智能体可访问任意先前步骤的相关信息。两者共同支持角色灵活切换和全局信息流动。

Result: 该框架在多项基准任务中表现优越，能提升协作性能，同时显著减少通信开销。

Conclusion: 顺序结构和动态任务自适应的通信机制可更好发挥集体智能的潜力，为LLM多智能体协作提供了更广阔、更灵活的拓扑结构。

Abstract: Recent progress in large language model (LLM)-based multi-agent collaboration
highlights the power of structured communication in enabling collective
intelligence. However, existing methods largely rely on static or graph-based
inter-agent topologies, lacking the potential adaptability and flexibility in
communication. In this work, we propose a new framework that rethinks
multi-agent coordination through a sequential structure rather than a graph
structure, offering a significantly larger topology space for multi-agent
communication. Our method focuses on two key directions: (1) Next-Agent
Prediction, which selects the most suitable agent role at each step, and (2)
Next-Context Selection (NCS), which enables each agent to selectively access
relevant information from any previous step. Together, these components
construct task-adaptive communication pipelines that support both role
flexibility and global information flow. Extensive evaluations across multiple
benchmarks demonstrate that our approach achieves superior performance while
substantially reducing communication overhead.

</details>


### [14] [Bayesian Social Deduction with Graph-Informed Language Models](https://arxiv.org/abs/2506.17788)
*Shahab Rahimirad,Guven Gergerli,Lucia Romero,Angela Qian,Matthew Lyle Olson,Simon Stepputtis,Joseph Campbell*

Main category: cs.AI

TL;DR: 作者提出将信念推理与语言模型结合的新方法，有效提升了小模型在社交推理游戏中的表现，首次实现了AI对人类的超越，并推动了相关研究的发展。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在进行社会推理（即根据对他人有限的观察推断其隐含信念和意图）时仍面临挑战，尤其在实际应用如社交推理游戏 Avalon 中，模型虽有较好表现但存在推理效率低和泛化至小型模型能力弱的问题。

Method: 提出了一个混合推理框架，将信念推断部分外置到结构化概率模型中，而语言理解和交互依然由大型语言模型负责。

Result: 框架在 Agent-Agent 游戏中达到了与更大模型相当的性能，且首次在受控实验中击败了真人玩家，取得了67%的胜率，并在定性评价中超过了基线模型与真人队友。

Conclusion: 通过混合推理框架，有效提升了社会推理任务中小型语言模型的性能，使得模型在实际场景中具备实用性。

Abstract: Social reasoning - inferring unobservable beliefs and intentions from partial
observations of other agents - remains a challenging task for large language
models (LLMs). We evaluate the limits of current reasoning language models in
the social deduction game Avalon and find that while the largest models
demonstrate strong performance, they require extensive test-time inference and
degrade sharply when distilled to smaller, real-time-capable variants. To
address this, we introduce a hybrid reasoning framework that externalizes
belief inference to a structured probabilistic model, while using an LLM for
language understanding and interaction. Our approach achieves competitive
performance with much larger models in Agent-Agent play and, notably, is the
first language agent to defeat human players in a controlled study - achieving
a 67% win rate and receiving higher qualitative ratings than both reasoning
baselines and human teammates. We release code, models, and a dataset to
support future work on social reasoning in LLM agents, which can be found at
https://camp-lab-purdue.github.io/bayesian-social-deduction/

</details>


### [15] [Efficient Strategy Synthesis for MDPs via Hierarchical Block Decomposition](https://arxiv.org/abs/2506.17792)
*Alexandros Evangelidis,Gricel Vázquez,Simos Gerasimou*

Main category: cs.AI

TL;DR: 本文提出了一种针对大规模MDP的动态细化策略合成方法，相较于主流工具PRISM在多种案例中取得了最高2倍的性能提升，解决了现有方法难以扩展的问题，适合实际应用中的复杂决策需求。


<details>
  <summary>Details</summary>
Motivation: 现有的软件密集型系统（如软件产品线、机器人系统）通常使用马尔可夫决策过程（MDP）来建模不确定性并分析决策过程，但传统方法在大规模状态空间下难以扩展。

Method: 提出了一种动态细化MDP的方法，迭代地选择最脆弱的MDP区域进行细化，仅在必要时进行，平衡精度和效率。

Result: 通过包含多种案例和高达百万状态的大型MDP的综合实验，证明该方法与主流概率模型检测器PRISM相比性能提升显著（最高提升2倍）。

Conclusion: 新方法能大幅提升大规模MDP策略合成的效率和竞争力，适用于真实世界中的策略合成任务。

Abstract: Software-intensive systems, such as software product lines and robotics,
utilise Markov decision processes (MDPs) to capture uncertainty and analyse
sequential decision-making problems. Despite the usefulness of conventional
policy synthesis methods, they fail to scale to large state spaces. Our
approach addresses this issue and accelerates policy synthesis in large MDPs by
dynamically refining the MDP and iteratively selecting the most fragile MDP
regions for refinement. This iterative procedure offers a balance between
accuracy and efficiency, as refinement occurs only when necessary. Through a
comprehensive empirical evaluation comprising diverse case studies and MDPs up
to 1M states, we demonstrate significant performance improvements yielded by
our approach compared to the leading probabilistic model checker PRISM (up to
2x), thus offering a very competitive solution for real-world policy synthesis
tasks in larger MDPs.

</details>


### [16] [Airalogy: AI-empowered universal data digitization for research automation](https://arxiv.org/abs/2506.18586)
*Zijie Yang,Qiji Zhou,Fang Guo,Sijie Zhang,Yexun Xi,Jinglei Nie,Yudian Zhu,Liping Huang,Chou Wu,Yonghe Xia,Xiaoyu Ma,Yingming Pu,Panzhong Lu,Junshu Pan,Mingtao Chen,Tiannan Guo,Yanmei Dou,Hongyu Chen,Anping Zeng,Jiaxing Huang,Tian Xu,Yue Zhang*

Main category: cs.AI

TL;DR: 现有AI科学研究受限于数据标准化和多样性兼容问题。作者开发了Airalogy平台，首次实现多领域数据自动化、标准化录入和AI辅助，已成功在西湖大学多个实验室部署，有望促进全球科学创新自动化和高效。


<details>
  <summary>Details</summary>
Motivation: 目前AI在科学领域的应用受限于数据的标准化与数字化程度，不同行业数据碎片化、缺乏统一标准，导致跨学科AI赋能困难。现有平台未能兼顾领域多样性和数据标准化，科学家与平台开发者间存在知识鸿沟，阻碍数据标准化与AI研究进步。

Method: 提出并开发了Airalogy平台，一种兼顾通用性（满足多学科多样变化需求）与标准化（支持AI进行有效操作）的研究数据数字化平台。该平台通过可定制、标准化的数据记录描述整个科研流程，并引入AI智能助手支持智能问答、自动录入数据、分析及研究自动化。平台强调社区驱动和多学科适用性。

Result: Airalogy已在西湖大学四大学院的实验室部署，初步验证了其在多学科场景下的应用能力。平台有望在更广泛的学术和工业领域推广，促进科学创新自动化和加速。

Conclusion: 通过Airalogy平台，实现了多学科研究数据的标准化数字化与AI辅助研究，有效平衡了多样性需求与统一标准，推动科学研究数字化和AI驱动的科学创新。

Abstract: Research data are the foundation of Artificial Intelligence (AI)-driven
science, yet current AI applications remain limited to a few fields with
readily available, well-structured, digitized datasets. Achieving comprehensive
AI empowerment across multiple disciplines is still out of reach. Present-day
research data collection is often fragmented, lacking unified standards,
inefficiently managed, and difficult to share. Creating a single platform for
standardized data digitization needs to overcome the inherent challenge of
balancing between universality (supporting the diverse, ever-evolving needs of
various disciplines) and standardization (enforcing consistent formats to fully
enable AI). No existing platform accommodates both facets. Building a truly
multidisciplinary platform requires integrating scientific domain knowledge
with sophisticated computing skills. Researchers often lack the computational
expertise to design customized and standardized data recording methods, whereas
platform developers rarely grasp the intricate needs of multiple scientific
domains. These gaps impede research data standardization and hamper AI-driven
progress. In this study, we address these challenges by developing Airalogy
(https://airalogy.com), the world's first AI- and community-driven platform
that balances universality and standardization for digitizing research data
across multiple disciplines. Airalogy represents entire research workflows
using customizable, standardized data records and offers an advanced AI
research copilot for intelligent Q&A, automated data entry, analysis, and
research automation. Already deployed in laboratories across all four schools
of Westlake University, Airalogy has the potential to accelerate and automate
scientific innovation in universities, industry, and the global research
community-ultimately benefiting humanity as a whole.

</details>


### [17] [Reflective Verbal Reward Design for Pluralistic Alignment](https://arxiv.org/abs/2506.17834)
*Carter Blair,Kate Larson,Edith Law*

Main category: cs.AI

TL;DR: 论文针对现有AI对齐方法无法充分反映个体价值多样性的不足，提出基于反思对话和个性化奖励建模的新方法，实验结果显示该方法有效提升了对用户偏好的准确建模能力。


<details>
  <summary>Details</summary>
Motivation: 当前常用的人工智能对齐方案通过人类反馈强化学习(RLHF)来实现，将人类反馈进行聚合，得到单一的奖励模型用于约束AI行为，忽视了人类价值观的多样性与冲突，可能会压制少数群体的偏好。

Method: 提出了新的奖励建模方法：采用大语言模型与用户进行反思式对话，用户在对话中批判并表述自己对AI行为的偏好，将这些反思性对话历史用作另一模型的上下文，生成个性化的口头奖励模型，用其评价新行为。

Result: 在30名参与者实验中，这种方法比非反思型口头奖励模型的准确率提高了9-12%，且比传统监督学习方法更高效地利用样本。

Conclusion: 个性化奖励模型能够更好地捕捉不同用户独特的价值观，有效提升AI对个人偏好的对齐效果，并在样本利用率和准确率方面优于现有方法。

Abstract: AI agents are commonly aligned with "human values" through reinforcement
learning from human feedback (RLHF), where a single reward model is learned
from aggregated human feedback and used to align an agent's behavior. However,
human values are not homogeneous--different people hold distinct and sometimes
conflicting values. Aggregating feedback into a single reward model risks
disproportionately suppressing minority preferences. To address this, we
present a novel reward modeling approach for learning individualized reward
models. Our approach uses a language model to guide users through reflective
dialogues where they critique agent behavior and construct their preferences.
This personalized dialogue history, containing the user's reflections and
critiqued examples, is then used as context for another language model that
serves as an individualized reward function (what we call a "verbal reward
model") for evaluating new trajectories. In studies with 30 participants, our
method achieved a 9-12% improvement in accuracy over non-reflective verbal
reward models while being more sample efficient than traditional supervised
learning methods.

</details>


### [18] [Out of Control -- Why Alignment Needs Formal Control Theory (and an Alignment Control Stack)](https://arxiv.org/abs/2506.17846)
*Elija Perrier*

Main category: cs.AI

TL;DR: 本文主张以最优控制理论为基础建立分层对齐框架，提升AI对齐方法的系统性和通用性，为未来AI系统的安全和可监管部署奠定理论支撑。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全和对齐方法虽然在形式化方法上取得了进展，但在通用性和不同协议协同控制上存在局限，因此需要更系统且可推广的理论框架。

Method: 作者提出以形式最优控制理论为基础的“Alignment Control Stack”（对齐控制堆栈）框架，将AI对齐问题分层建模，从物理到社会技术层，明确各层的度量与控制特性及层间的可互操作性。

Result: 该层次化框架能系统性分析与控制先进AI模型及自主体系统，对政府和监管者提供理论保证，并助力AI技术的可持续发展和实际部署。

Conclusion: 形式最优控制理论应成为AI对齐研究的核心，可将控制理论的成熟方法与AI实际部署结合，为AI安全和可靠性提供更完整的理论与实践基础。

Abstract: This position paper argues that formal optimal control theory should be
central to AI alignment research, offering a distinct perspective from
prevailing AI safety and security approaches. While recent work in AI safety
and mechanistic interpretability has advanced formal methods for alignment,
they often fall short of the generalisation required of control frameworks for
other technologies. There is also a lack of research into how to render
different alignment/control protocols interoperable. We argue that by recasting
alignment through principles of formal optimal control and framing alignment in
terms of hierarchical stack from physical to socio-technical layers according
to which controls may be applied we can develop a better understanding of the
potential and limitations for controlling frontier models and agentic AI
systems. To this end, we introduce an Alignment Control Stack which sets out a
hierarchical layered alignment stack, identifying measurement and control
characteristics at each layer and how different layers are formally
interoperable. We argue that such analysis is also key to the assurances that
will be needed by governments and regulators in order to see AI technologies
sustainably benefit the community. Our position is that doing so will bridge
the well-established and empirically validated methods of optimal control with
practical deployment considerations to create a more comprehensive alignment
framework, enhancing how we approach safety and reliability for advanced AI
systems.

</details>


### [19] [Towards Robust Fact-Checking: A Multi-Agent System with Advanced Evidence Retrieval](https://arxiv.org/abs/2506.17878)
*Tam Trinh,Manh Nguyen,Truong-Son Hy*

Main category: cs.AI

TL;DR: 本文针对现有自动化事实核查系统处理复杂声明、保证证据可信性和核查透明性不足的问题，设计了四个功能明确的代理组成的多代理核查系统，经实验证明该方法在主流基准数据集上显著优于基线模型，并具备更强的准确性、效率与解释能力。


<details>
  <summary>Details</summary>
Motivation: 随着数字时代虚假信息的快速传播，传统人工事实核查方法已难以应对大量和高速增长的网络内容，因此有必要开发高效、可扩展的自动化事实核查系统。

Method: 本文提出了一种新颖的多代理系统进行自动化事实核查，包含输入分解代理、查询生成代理、证据检索代理和判决预测代理，分别负责把复杂声明拆分、生成针对性子查询、检索可信证据并输出带可解释性的核查结论。系统在多个基准数据集上进行了评测。

Result: 在FEVEROUS、HOVER、SciFact等基准数据集上，该系统的Macro F1得分较基线方法提升了12.3%，在分解复杂声明、检索可信证据以及给出透明解释等方面效果突出。

Conclusion: 提出的多代理自动事实核查系统提升了准确性、效率和可解释性，能够更好地贴合人工核查流程且具备现实应用的可扩展性。

Abstract: The rapid spread of misinformation in the digital era poses significant
challenges to public discourse, necessitating robust and scalable fact-checking
solutions. Traditional human-led fact-checking methods, while credible,
struggle with the volume and velocity of online content, prompting the
integration of automated systems powered by Large Language Models (LLMs).
However, existing automated approaches often face limitations, such as handling
complex claims, ensuring source credibility, and maintaining transparency. This
paper proposes a novel multi-agent system for automated fact-checking that
enhances accuracy, efficiency, and explainability. The system comprises four
specialized agents: an Input Ingestion Agent for claim decomposition, a Query
Generation Agent for formulating targeted subqueries, an Evidence Retrieval
Agent for sourcing credible evidence, and a Verdict Prediction Agent for
synthesizing veracity judgments with human-interpretable explanations.
Evaluated on benchmark datasets (FEVEROUS, HOVER, SciFact), the proposed system
achieves a 12.3% improvement in Macro F1-score over baseline methods. The
system effectively decomposes complex claims, retrieves reliable evidence from
trusted sources, and generates transparent explanations for verification
decisions. Our approach contributes to the growing field of automated
fact-checking by providing a more accurate, efficient, and transparent
verification methodology that aligns with human fact-checking practices while
maintaining scalability for real-world applications. Our source code is
available at https://github.com/HySonLab/FactAgent

</details>


### [20] [Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms](https://arxiv.org/abs/2506.17900)
*Cheng Ji,Huaiying Luo*

Main category: cs.AI

TL;DR: 该论文提出了一种基于大语言模型的云平台日志智能分析与自动调试方法，通过多阶段语义推理和强化学习决策机制，有效提升了故障定位与修复能力，实验表明准确率提升16.2%。


<details>
  <summary>Details</summary>
Motivation: 云平台AI系统复杂度和规模不断提升，导致系统运行日志巨大且无结构、语义模糊，传统故障定位与自愈面临挑战，急需智能化、自动化的新方法提升效率与准确性。

Method: 提出基于大语言模型（LLM）的智能日志处理与自动调试框架（LLM-ID）。方法包括：（1）在预训练Transformer模型基础上扩展，融入多阶段语义推理机制，实现日志上下文理解与故障链自动重建；（2）动态结构化系统日志，通过无监督聚类和嵌入机制提取事件模板和语义模式；（3）微调的LLM结合多轮注意力机制，对日志序列进行上下文推理，生成潜在故障假设和根因路径；（4）引入基于强化学习的策略引导恢复规划，依据LLM生成的修复策略，支持动态决策与自适应调试。

Result: 在云平台日志数据集上实验，LLM-ID模型的故障定位准确率提升16.2%，显著优于主流传统方法。具备更强语义理解、持续学习及异构环境适应力。

Conclusion: 基于LLM的日志智能分析与自动调试框架LLM-ID，在云环境下极大提升了故障定位的效率和准确率，为大规模AI系统运维智能化提供了创新思路和有效手段。

Abstract: With the increasing complexity and rapid expansion of the scale of AI systems
in cloud platforms, the log data generated during system operation is massive,
unstructured, and semantically ambiguous, which brings great challenges to
fault location and system self-repair. In order to solve this problem, this
paper proposes an intelligent log processing and automatic debugging framework
based on Large Language Model (LLM), named Intelligent Debugger (LLM-ID). This
method is extended on the basis of the existing pre-trained Transformer model,
and integrates a multi-stage semantic inference mechanism to realize the
context understanding of system logs and the automatic reconstruction of fault
chains. Firstly, the system log is dynamically structured, and the unsupervised
clustering and embedding mechanism is used to extract the event template and
semantic schema. Subsequently, the fine-tuned LLM combined with the multi-round
attention mechanism to perform contextual reasoning on the log sequence to
generate potential fault assumptions and root cause paths. Furthermore, this
paper introduces a reinforcement learning-based policy-guided recovery planner,
which is driven by the remediation strategy generated by LLM to support dynamic
decision-making and adaptive debugging in the cloud environment. Compared with
the existing rule engine or traditional log analysis system, the proposed model
has stronger semantic understanding ability, continuous learning ability and
heterogeneous environment adaptability. Experiments on the cloud platform log
dataset show that LLM-ID improves the fault location accuracy by 16.2%, which
is significantly better than the current mainstream methods

</details>


### [21] [Learning, Reasoning, Refinement: A Framework for Kahneman's Dual-System Intelligence in GUI Agents](https://arxiv.org/abs/2506.17913)
*Jinjie Wei,Jiyao Liu,Lihao Liu,Ming Hu,Junzhi Ning,Mingcheng Li,Weijie Yin,Junjun He,Xiao Liang,Chao Feng,Dingkang Yang*

Main category: cs.AI

TL;DR: 本文提出 CogniGUI，创新性地融合分层视觉解析和基于奖励的高效交互决策，实现了类人化的 GUI 任务自动学习。新基准 ScreenSeek 下，其表现优于现有技术，具备很强的泛化和适应性优势。


<details>
  <summary>Details</summary>
Motivation: 现有的图形用户界面（GUI）智能体系统主要依赖尝试-错误型决策，缺乏进阶推理能力和从交互中学习适应的能力。此外，评价指标多为简单的单步准确率，无法全面反映真实 GUI 交互的复杂性。

Method: 提出了 CogniGUI，一个受 Kahneman 的双系统理论启发的认知架构。该方法包括两大核心：1) 全能解析器引擎，能快速分层解析 GUI 元素以识别可操作组件；2) 基于群体的相对策略优化（GRPO）智能体，采用相对奖励机制评估多条交互路径，促进高效操作。该双系统支持智能体通过“探索-学习-精通”循环不断提升策略。此外，构建了新的评测基准 ScreenSeek，涵盖多应用导航、动态状态切换和跨界面协同等挑战。

Result: 实验结果显示，CogniGUI 无论在现有 GUI 基准还是新提出的 ScreenSeek 基准上，性能均超过当前最先进方法。

Conclusion: CogniGUI 能实现更接近人类行为的自适应 GUI 自动化学习，并在更具挑战性的评测中展现出优异的泛化与适应能力。

Abstract: Graphical User Interface (GUI) agents have made significant progress in
automating digital tasks through the utilization of computer vision and
language models. Nevertheless, existing agent systems encounter notable
limitations. Firstly, they predominantly depend on trial and error decision
making rather than progressive reasoning, thereby lacking the capability to
learn and adapt from interactive encounters. Secondly, these systems are
assessed using overly simplistic single step accuracy metrics, which do not
adequately reflect the intricate nature of real world GUI interactions. In this
paper, we present CogniGUI, a cognitive framework developed to overcome these
limitations by enabling adaptive learning for GUI automation resembling
human-like behavior. Inspired by Kahneman's Dual Process Theory, our approach
combines two main components: (1) an omni parser engine that conducts immediate
hierarchical parsing of GUI elements through quick visual semantic analysis to
identify actionable components, and (2) a Group based Relative Policy
Optimization (GRPO) grounding agent that assesses multiple interaction paths
using a unique relative reward system, promoting minimal and efficient
operational routes. This dual-system design facilitates iterative ''exploration
learning mastery'' cycles, enabling the agent to enhance its strategies over
time based on accumulated experience. Moreover, to assess the generalization
and adaptability of agent systems, we introduce ScreenSeek, a comprehensive
benchmark that includes multi application navigation, dynamic state
transitions, and cross interface coherence, which are often overlooked
challenges in current benchmarks. Experimental results demonstrate that
CogniGUI surpasses state-of-the-art methods in both the current GUI grounding
benchmarks and our newly proposed benchmark.

</details>


### [22] [Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective](https://arxiv.org/abs/2506.17930)
*Jianyu Wang,Zhiqiang Hu,Lidong Bing*

Main category: cs.AI

TL;DR: 本文挑战了传统的LLM prompt设计理念，发现将示例剪枝为“乱码”能够提升模型表现。作者提出PromptQuine自动进化搜索框架，不依赖人工经验，系统性地找到高效prompt。实验在多种任务和模型上效果领先。该成果为理解和优化ICL机制提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）中，传统的prompt设计倾向于精心编写的指令和示例以提升模型表现，但这套方法依然存在优化空间。作者发现，现有的自动prompt优化技术虽然有效，但仍未挖掘出prompt设计的全部潜力，因此希望挑战传统观念，探索更高效的prompt设计方式。

Method: 作者提出了一种名为PromptQuine的全新演化搜索框架，不依赖于人工设计或现有归因/压缩方法，而是让系统自我进化，自动搜索最佳的随机示例剪枝策略，在仅有少量数据的情况下，通过保留原始上下文中的词元，演化出表现优秀但看似无序的prompt。

Result: 实验证明，该方法在分类、多选问答、生成、数学推理等任务以及不同LLM模型上均取得了优异成绩，效果优于或匹配当前最先进的自动prompt优化技术，并具备良好的运行效率。

Conclusion: 设计出连贯且逻辑清晰的prompt并非获得最佳LLM性能的必要条件。通过进化式搜索实现的“无序”prompt能显著提升LLM任务表现，对现有prompt设计理念提出了新的挑战和指导意义。

Abstract: We propose a novel prompt design paradigm that challenges conventional wisdom
in large language model (LLM) prompting. While conventional wisdom prioritizes
well-crafted instructions and demonstrations for in-context learning (ICL), we
show that pruning random demonstrations into seemingly incoherent "gibberish"
can remarkably improve performance across diverse tasks. Notably, the
"gibberish" always matches or surpasses state-of-the-art automatic prompt
optimization techniques, achieving substantial gains regardless of LLM
alignment. Nevertheless, discovering an effective pruning strategy is
non-trivial, as existing attribution methods and prompt compression algorithms
fail to deliver robust results, let alone human intuition. In terms of this, we
propose a self-discover prompt optimization framework, PromptQuine, an
evolutionary search framework that automatically searches for the pruning
strategy by itself using only low-data regimes. Much like the emergent
complexity in nature--such as symbiosis and self-organization--arising in
response to resource constraints, our framework evolves and refines
unconventional yet highly effective prompts by leveraging only the tokens
present within the context. We demonstrate its effectiveness across
classification, multi-choice question answering, generation and math reasoning
tasks across LLMs, while achieving decent runtime efficiency. We hope our
findings can guide mechanistic studies on in-context learning, and provide a
call to action, to pave the way for more open-ended search algorithms for more
effective LLM prompting.

</details>


### [23] [medicX-KG: A Knowledge Graph for Pharmacists' Drug Information Needs](https://arxiv.org/abs/2506.17959)
*Lizzy Farrugia,Lilian M. Azzopardi,Jeremy Debattista,Charlie Abela*

Main category: cs.AI

TL;DR: 本文提出了面向药剂师的medicX-KG知识图谱，整合多源药品信息，支持药师高效查询及决策。实践表明其能优化药品管理和服务，减少信息碎片化，但仍需提升数据细节和更新能力。


<details>
  <summary>Details</summary>
Motivation: 药剂师的角色正在从单纯的药品分发转向多学科医疗团队中的综合药学服务，亟需集成、准确的药品信息以支持临床与监管决策。然而，目前面临药品信息分散、缺少统一国家药品资料库等问题，限制了药剂师的数据驱动决策能力。

Method: 本研究提出并构建了medicX-KG知识图谱，作为药剂师决策支持工具，并集成了英国国家处方集（BNF）、DrugBank与马耳他药品管理局（MMA）等三方数据。整个设计过程通过与一线药剂师访谈获取真实需求，并介绍了数据抽取、本体设计以及语义映射等知识图谱构建流程。

Result: medicX-KG知识图谱能够有效支持相关药品的查询，包括药物可得性、药物相互作用、不良反应及治疗类别等关键问题，显著减少了药剂师对零散信息源的依赖。

Conclusion: medicX-KG为药剂师提供了统一和可解释的药品知识语义层，有效提升了其临床和监管决策能力。虽然当前版本存在剂量细节编码及实时更新等局限，但为未来进一步完善奠定了基础。

Abstract: The role of pharmacists is evolving from medicine dispensing to delivering
comprehensive pharmaceutical services within multidisciplinary healthcare
teams. Central to this shift is access to accurate, up-to-date medicinal
product information supported by robust data integration. Leveraging artificial
intelligence and semantic technologies, Knowledge Graphs (KGs) uncover hidden
relationships and enable data-driven decision-making. This paper presents
medicX-KG, a pharmacist-oriented knowledge graph supporting clinical and
regulatory decisions. It forms the semantic layer of the broader medicX
platform, powering predictive and explainable pharmacy services. medicX-KG
integrates data from three sources, including, the British National Formulary
(BNF), DrugBank, and the Malta Medicines Authority (MMA) that addresses Malta's
regulatory landscape and combines European Medicines Agency alignment with
partial UK supply dependence. The KG tackles the absence of a unified national
drug repository, reducing pharmacists' reliance on fragmented sources. Its
design was informed by interviews with practicing pharmacists to ensure
real-world applicability. We detail the KG's construction, including data
extraction, ontology design, and semantic mapping. Evaluation demonstrates that
medicX-KG effectively supports queries about drug availability, interactions,
adverse reactions, and therapeutic classes. Limitations, including missing
detailed dosage encoding and real-time updates, are discussed alongside
directions for future enhancements.

</details>


### [24] [Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities](https://arxiv.org/abs/2506.18019)
*Yuanchen Bei,Weizhi Zhang,Siwen Wang,Weizhi Chen,Sheng Zhou,Hao Chen,Yong Li,Jiajun Bu,Shirui Pan,Yizhou Yu,Irwin King,Fakhri Karray,Philip S. Yu*

Main category: cs.AI

TL;DR: 本文为人工智能智能体与图结构结合领域的首个系统综述，揭示了图的结构化优势如何解决智能体在真实复杂任务中面临的信息、计划与协作等难题，指出了未来发展方向，并提供了相关研究资源。


<details>
  <summary>Details</summary>
Motivation: 随着AI智能体从传统强化学习方法到融合大语言模型（LLM），其能力显著增强。但在面对复杂真实世界任务时，如有效计划与执行、稳定记忆维护和多智能体协作，当前方法还存在挑战。尤其在处理海量复杂信息和交互时亟需新的数据结构化手段。

Method: 本综述系统梳理了图数据结构在增强AI智能体核心能力（如规划、记忆、协作等）中的作用，分析了图技术与智能体深度结合的现有应用及潜力，并归纳未来研究方向。文章还收集并持续更新相关资源，以便学术社区参考。

Result: 文章首次系统性评估了图技术赋能AI智能体的多种路径和实际应用案例，阐述了图结构如何助力智能体更高效地理解和处理复杂数据关系，支撑其应对高级任务。

Conclusion: 通过梳理与分析，本文明确了图结构作为数据结构化利器，对智能体能力提升的重要作用，并为后续研究提供了清晰、前沿的研究线索和资源。

Abstract: AI agents have experienced a paradigm shift, from early dominance by
reinforcement learning (RL) to the rise of agents powered by large language
models (LLMs), and now further advancing towards a synergistic fusion of RL and
LLM capabilities. This progression has endowed AI agents with increasingly
strong abilities. Despite these advances, to accomplish complex real-world
tasks, agents are required to plan and execute effectively, maintain reliable
memory, and coordinate smoothly with other agents. Achieving these capabilities
involves contending with ever-present intricate information, operations, and
interactions. In light of this challenge, data structurization can play a
promising role by transforming intricate and disorganized data into
well-structured forms that agents can more effectively understand and process.
In this context, graphs, with their natural advantage in organizing, managing,
and harnessing intricate data relationships, present a powerful data paradigm
for structurization to support the capabilities demanded by advanced AI agents.
To this end, this survey presents a first systematic review of how graphs can
empower AI agents. Specifically, we explore the integration of graph techniques
with core agent functionalities, highlight notable applications, and identify
prospective avenues for future research. By comprehensively surveying this
burgeoning intersection, we hope to inspire the development of next-generation
AI agents equipped to tackle increasingly sophisticated challenges with graphs.
Related resources are collected and continuously updated for the community in
the Github link.

</details>


### [25] [Action Language BC+](https://arxiv.org/abs/2506.18044)
*Joseph Babb,Joohyung Lee*

Main category: cs.AI

TL;DR: 本文提出了新动作语言BC+，将现代ASP语言的强大特性与动作语言融合，弥补原有表达不足。BC+兼容旧有动作语言优点，可借助ASP技术直接求解，并已获得实现。


<details>
  <summary>Details</summary>
Motivation: 现有的动作语言形式（如B、C、C+、BC）在与现代ASP语言（Answer Set Programming）对接时存在表达能力上的差距，ASP中的新特性如选择规则、聚合和抽象约束原子等尚未被旧的动作语言充分集成。作者希望设计一种新动作语言，能更好地利用ASP的知识表示能力。

Method: 提出了一种新的动作语言BC+，其语义通过对命题公式的一般稳定模型语义进行定义，使得现代ASP语言中的诸多功能特性都可与命题公式中的简写对应。此外，BC+通过扩展cplus2asp系统进行了实际实现。

Result: BC+语言足够表达性强，可以涵盖其它动作语言（如B、C、C+、BC）的最佳特性，并能自如利用ASP求解器的计算能力，成功实现了将动作语言与现代ASP紧密结合。

Conclusion: BC+有效填补了动作语言和现代ASP语言之间的功能和表达鸿沟，使得复杂知识和动态系统的描述、推理更加自然、便利和高效。

Abstract: Action languages are formal models of parts of natural language that are
designed to describe effects of actions. Many of these languages can be viewed
as high level notations of answer set programs structured to represent
transition systems. However, the form of answer set programs considered in the
earlier work is quite limited in comparison with the modern Answer Set
Programming (ASP) language, which allows several useful constructs for
knowledge representation, such as choice rules, aggregates, and abstract
constraint atoms. We propose a new action language called BC+, which closes the
gap between action languages and the modern ASP language. The main idea is to
define the semantics of BC+ in terms of general stable model semantics for
propositional formulas, under which many modern ASP language constructs can be
identified with shorthands for propositional formulas. Language BC+ turns out
to be sufficiently expressive to encompass the best features of other action
languages, such as languages B, C, C+, and BC. Computational methods available
in ASP solvers are readily applicable to compute BC+, which led to an
implementation of the language by extending system cplus2asp.

</details>


### [26] [Weighted Assumption Based Argumentation to reason about ethical principles and actions](https://arxiv.org/abs/2506.18056)
*Paolo Baldi,Fabio Aurelio D'Asaro,Abeer Dyoub,Francesca Alessandra Lisi*

Main category: cs.AI

TL;DR: 本文提出为假设基础论证（ABA）系统引入权重机制，通过具体案例展示其在道德推理中的应用，并给出基于ASP的实现。


<details>
  <summary>Details</summary>
Motivation: 传统基于假设的论证（ABA）系统未考虑不同论据的重要性或可信度，存在论据之间影响力难以衡量的问题。

Method: 在ABA系统中为每个论据分配权重，并通过推导得出论据之间攻击的权重。通过道德推理领域的示例进行说明，并基于Answer Set Programming实现了该系统。

Result: 展示了在具有权重的ABA系统中，如何通过示例实现权重分配与攻击权重推导。同时，开发了实际运行的实现系统。

Conclusion: 将权重机制融入ABA后，可以更细致地刻画论证过程，增强了系统对于论据影响力和攻击效果的表达能力。

Abstract: We augment Assumption Based Argumentation (ABA for short) with weighted
argumentation. In a nutshell, we assign weights to arguments and then derive
the weight of attacks between ABA arguments. We illustrate our proposal through
running examples in the field of ethical reasoning, and present an
implementation based on Answer Set Programming.

</details>


### [27] [Deep Research Agents: A Systematic Examination And Roadmap](https://arxiv.org/abs/2506.18096)
*Yuxuan Huang,Yihang Chen,Haozheng Zhang,Kang Li,Meng Fang,Linyi Yang,Xiaoguang Li,Lifeng Shang,Songcen Xu,Jianye Hao,Kun Shao,Jun Wang*

Main category: cs.AI

TL;DR: 本文全面分析了Deep Research agents的发展现状，从技术、架构、评测指标等多方面进行系统分类和梳理，发现当前主要限制并提出了未来研究方向，同时开放了持续更新的研究资料库。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的飞速发展，涌现出了能够自主进行复杂多轮研究任务的智能体（Deep Research agents, DR agents），但相关关键技术及其架构尚缺乏系统分析和梳理。

Method: 系统分析DR agents的基础技术与模块化架构，包括信息获取方式（API检索 vs. 浏览器探索）、工具使用框架、多模态输入处理、上下文协议（MCPs）等。提出用于分类现有方法的分类法（静态与动态流程、单/多agent等），并对现有基准评测和瓶颈进行批判性综述。

Result: 提出了一套DR agents的系统分类法，总结和归纳了其架构要素，并分析了当前评测基准的局限性和未来研究方向，最后开放了相关研究资源库。

Conclusion: 本文系统化梳理了DR agents的关键技术与架构，明确其发展现状与挑战，并为未来研究和实际应用提供了路线图和参考库。

Abstract: The rapid progress of Large Language Models (LLMs) has given rise to a new
category of autonomous AI systems, referred to as Deep Research (DR) agents.
These agents are designed to tackle complex, multi-turn informational research
tasks by leveraging a combination of dynamic reasoning, adaptive long-horizon
planning, multi-hop information retrieval, iterative tool use, and the
generation of structured analytical reports. In this paper, we conduct a
detailed analysis of the foundational technologies and architectural components
that constitute Deep Research agents. We begin by reviewing information
acquisition strategies, contrasting API-based retrieval methods with
browser-based exploration. We then examine modular tool-use frameworks,
including code execution, multimodal input processing, and the integration of
Model Context Protocols (MCPs) to support extensibility and ecosystem
development. To systematize existing approaches, we propose a taxonomy that
differentiates between static and dynamic workflows, and we classify agent
architectures based on planning strategies and agent composition, including
single-agent and multi-agent configurations. We also provide a critical
evaluation of current benchmarks, highlighting key limitations such as
restricted access to external knowledge, sequential execution inefficiencies,
and misalignment between evaluation metrics and the practical objectives of DR
agents. Finally, we outline open challenges and promising directions for future
research. A curated and continuously updated repository of DR agent research is
available at: {https://github.com/ai-agents-2030/awesome-deep-research-agent}.

</details>


### [28] [Decentralized Consensus Inference-based Hierarchical Reinforcement Learning for Multi-Constrained UAV Pursuit-Evasion Game](https://arxiv.org/abs/2506.18126)
*Xiang Yuming,Li Sizhao,Li Rongpeng,Zhao Zhifeng,Zhang Honggang*

Main category: cs.AI

TL;DR: 本文针对通信受限环境下无人机多智能体协同追逃和编队覆盖任务，提出了一种分层强化学习新架构CI-HRL，结合了共识机制和分层控制，实验证明显著提升了协同能力与任务完成效率。


<details>
  <summary>Details</summary>
Motivation: 多旋翼无人机（UAV）系统在多约束追逃博弈（MC-PEG）中的广泛应用和研究激发出了诸如协同规避与编队覆盖（CEFC）等复杂任务需求，而在通信受限情况下，该问题兼具障碍物规避、对抗、目标区覆盖和队形管理等多重高维困难。现有方法对高维度环境中多目标的高效解决能力有限，因此需要提出更有效的协同控制框架。

Method: 提出了分层强化学习框架Consensus Inference-based Hierarchical Reinforcement Learning（CI-HRL），通过高层策略模块定位目标区，低层策略模块实现障碍规避、导航与队形控制。高层政策引入了基于共识的多智能体消息聚合与决策机制（ConsMAC），提升本地信息汇总为全局共识的能力。低层采用交替训练的多智能体近端策略优化及策略蒸馏，提升智能体低级协作效率。

Result: 软件仿真及高保真度SITL（Software-In-The-Loop）实验证明，CI-HRL框架能够显著提升无人机群体的协同规避与多任务完成能力。

Conclusion: 该研究提出的CI-HRL框架可高效应对多约束追逃博弈中的复杂协同任务，尤其适用于通信受限条件下的大规模无人机群体协作，为实际应用提供了理论与工程基础。

Abstract: Multiple quadrotor unmanned aerial vehicle (UAV) systems have garnered
widespread research interest and fostered tremendous interesting applications,
especially in multi-constrained pursuit-evasion games (MC-PEG). The Cooperative
Evasion and Formation Coverage (CEFC) task, where the UAV swarm aims to
maximize formation coverage across multiple target zones while collaboratively
evading predators, belongs to one of the most challenging issues in MC-PEG,
especially under communication-limited constraints. This multifaceted problem,
which intertwines responses to obstacles, adversaries, target zones, and
formation dynamics, brings up significant high-dimensional complications in
locating a solution. In this paper, we propose a novel two-level framework
(i.e., Consensus Inference-based Hierarchical Reinforcement Learning (CI-HRL)),
which delegates target localization to a high-level policy, while adopting a
low-level policy to manage obstacle avoidance, navigation, and formation.
Specifically, in the high-level policy, we develop a novel multi-agent
reinforcement learning module, Consensus-oriented Multi-Agent Communication
(ConsMAC), to enable agents to perceive global information and establish
consensus from local states by effectively aggregating neighbor messages.
Meanwhile, we leverage an Alternative Training-based Multi-agent proximal
policy optimization (AT-M) and policy distillation to accomplish the low-level
control. The experimental results, including the high-fidelity
software-in-the-loop (SITL) simulations, validate that CI-HRL provides a
superior solution with enhanced swarm's collaborative evasion and task
completion capabilities.

</details>


### [29] [SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging](https://arxiv.org/abs/2506.18135)
*Zijun Chen,Zhanpeng Zhou,Bo Zhang,Weinan Zhang,Xi Sun,Junchi Yan*

Main category: cs.AI

TL;DR: 本文分析了模型合并的机制，提出无需额外训练即可显著提升多任务性能的动态合并新方法SE-Merging，并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管模型合并在多任务能力上有实证成功，但其机制尚不清晰，特别是其如何实现多任务适应。本文旨在剖析模型合并机制并提升其性能。

Method: 作者从表示学习角度分析模型合并机制，揭示模型合并通过“区分任务样本”和“适应对应专家模型”获得多任务能力，并基于此提出SE-Merging框架，通过动态调整合并系数增强合并模型的任务特定能力。

Result: SE-Merging无需额外训练即可实现动态模型合并，且与现有合并方法兼容，在多项实验中表现出显著性能提升。

Conclusion: SE-Merging能够依据输入样本动态识别任务，并自适应调整合并系数，在不需额外训练的情况下，进一步提升任务专长能力，对现有模型合并方法有显著性能提升。

Abstract: Model merging has gained increasing attention due to its intriguing property:
interpolating the parameters of different task-specific fine-tuned models leads
to multi-task abilities. However, despite its empirical success, the underlying
mechanisms of model merging remain poorly understood. In this work, we delve
into the mechanism behind model merging from a representation perspective. Our
analysis reveals that model merging achieves multi-task abilities through two
key capabilities: i) distinguishing samples from different tasks, and ii)
adapting to the corresponding expert model for each sample. These two
capabilities allow the merged model to retain task-specific expertise, enabling
efficient multi-task adaptation. Building on these insights, we propose
\texttt{SE-Merging}, a self-enhanced model merging framework that leverages
these two characteristics to dynamically identify the corresponding task for
each sample and then adaptively rescales the merging coefficients to further
enhance task-specific expertise in the merged model. Notably,
\texttt{SE-Merging} achieves dynamic model merging without additional training.
Extensive experiments demonstrate that \texttt{SE-Merging} achieves significant
performance improvements while remaining compatible with existing model merging
techniques.

</details>


### [30] [CoachGPT: A Scaffolding-based Academic Writing Assistant](https://arxiv.org/abs/2506.18149)
*Fumian Chen,Sotheara Veng,Joshua Wilson,Xiaoming Li,Hui Fang*

Main category: cs.AI

TL;DR: 本文提出一个基于大语言模型的写作辅助系统CoachGPT，采用教育专家指导与实时反馈机制，提升个性化与教学性。用户研究证实其对学术写作的显著帮助，展示LLM在写作教育应用的潜力。


<details>
  <summary>Details</summary>
Motivation: 学术写作能力对学生至关重要，尤其是第二语言写作时，缺乏指导和实践会让学生感到压力。传统写作辅助工具存在理解力不足和有限的教育功能。随着大语言模型（LLMs）的发展，出现了生成内容但不注重教学的问题，容易影响学生学习。论文旨在解决现有工具的局限性，提升写作辅助的教育性和个性化。

Method: 作者开发了CoachGPT，一个基于大语言模型的AI写作辅助平台。CoachGPT通过接收教育专家的指导，将指导转化为具体子任务，并借助LLM为用户提供实时反馈和建议。这一结构增加了写作过程的互动性和教育性。

Result: CoachGPT能够为学习资源有限或偏好自学的学生提供更沉浸式、个性化的学术写作支持。用户研究表明，CoachGPT使用体验良好，验证了其有效性，以及LLM在学术写作辅助领域的潜力。

Conclusion: CoachGPT通过创新的结构和实时个性化反馈，克服了现有写作助手一味生成内容、不重视教学的缺陷，为提升学术写作教学和自主学习提供了新途径。其框架和研究展示了大语言模型在教育领域应用的巨大前景。

Abstract: Academic writing skills are crucial for students' success, but can feel
overwhelming without proper guidance and practice, particularly when writing in
a second language. Traditionally, students ask instructors or search
dictionaries, which are not universally accessible. Early writing assistants
emerged as rule-based systems that focused on detecting misspellings,
subject-verb disagreements, and basic punctuation errors; however, they are
inaccurate and lack contextual understanding. Machine learning-based assistants
demonstrate a strong ability for language understanding but are expensive to
train. Large language models (LLMs) have shown remarkable capabilities in
generating responses in natural languages based on given prompts. Still, they
have a fundamental limitation in education: they generate essays without
teaching, which can have detrimental effects on learning when misused. To
address this limitation, we develop CoachGPT, which leverages large language
models (LLMs) to assist individuals with limited educational resources and
those who prefer self-paced learning in academic writing. CoachGPT is an AI
agent-based web application that (1) takes instructions from experienced
educators, (2) converts instructions into sub-tasks, and (3) provides real-time
feedback and suggestions using large language models. This unique scaffolding
structure makes CoachGPT unique among existing writing assistants. Compared to
existing writing assistants, CoachGPT provides a more immersive writing
experience with personalized feedback and guidance. Our user studies prove the
usefulness of CoachGPT and the potential of large language models for academic
writing.

</details>


### [31] [AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology](https://arxiv.org/abs/2506.18156)
*Akash Kundu,Rishika Goswami*

Main category: cs.AI

TL;DR: 本文发现大语言模型在多种心理学测试下表现出部分类人认知特征，这为AI伦理、透明性及认知心理学结合AI安全研究提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型（LLMs）是否表现出类似人类的认知模式，这对于理解AI智能和提升其安全性与伦理性有重要意义。

Method: 采用四种心理学框架（主题统觉测验TAT、框架偏见、道德基础理论MFT、认知失调），通过结构化提示和自动评分评估多个专有与开源大模型的表现。

Result: 模型表现为能够生成连贯叙事、易受到积极表述影响、道德判断偏向自由/压迫维度，并在自相矛盾时进行较多合理化，这些行为在一定程度上反映了人类认知倾向，但受其训练数据和对齐方式影响。

Conclusion: LLM部分展现了类似人类的认知模式，结果受到训练与对齐机制影响。作者认为应在AI透明度、伦理与心理学结合AI安全等方向进一步讨论和研究。

Abstract: We investigate whether Large Language Models (LLMs) exhibit human-like
cognitive patterns under four established frameworks from psychology: Thematic
Apperception Test (TAT), Framing Bias, Moral Foundations Theory (MFT), and
Cognitive Dissonance. We evaluated several proprietary and open-source models
using structured prompts and automated scoring. Our findings reveal that these
models often produce coherent narratives, show susceptibility to positive
framing, exhibit moral judgments aligned with Liberty/Oppression concerns, and
demonstrate self-contradictions tempered by extensive rationalization. Such
behaviors mirror human cognitive tendencies yet are shaped by their training
data and alignment methods. We discuss the implications for AI transparency,
ethical deployment, and future work that bridges cognitive psychology and AI
safety

</details>


### [32] [Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation](https://arxiv.org/abs/2506.18158)
*Xinzge Gao,Chuanrui Hu,Bin Chen,Teng Li*

Main category: cs.AI

TL;DR: 该文提出Chain-of-Memory（CoM）机制，用于显式存储和管理GUI任务关键信息，显著提升多模态大模型在复杂跨应用任务中的表现，并开源大规模标注数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大模型（MLLM）在图形用户界面（GUI）智能体开发中，往往只依赖历史截图或动作，导致难以准确理解复杂或跨应用任务的状态，同时缺乏高效的信息存储机制。

Method: 提出了一种新的方法Chain-of-Memory（CoM），明确地为GUI智能体建模短期和长期记忆模块，结合动作描述和与任务相关的屏幕信息，通过独立的记忆模块存储和管理关键信息。开发了GUI Odyssey-CoM数据集（包含11.1万对屏幕-动作样本，带记忆标注），用于训练和评估该方法。

Result: 实验表明，CoM方法能显著提升GUI智能体在跨应用任务中的表现。此外，GUI Odyssey-CoM数据集能让7B规模模型表现出与72B模型相近的记忆管理能力。

Conclusion: 引入显式记忆建模机制后，GUI智能体在复杂场景中的任务理解和历史信息保留能力大大提升。公开数据集和代码有助于后续研究。

Abstract: Multimodal large language models (MLLMs) are attracting growing attention in
the development of Graphical User Interface (GUI) agents. Existing approaches
often rely on historical screenshots or actions to implicitly represent the
task state. This reliance poses challenges for GUI agents in accurately
understanding task states and underscores the absence of effective mechanisms
to store critical information in complex and lengthy cross-app tasks. To
address these challenges, we propose Chain-of-Memory (CoM), a novel approach
for explicitly modeling short-term and long-term memory in GUI agents. CoM
achieves this by capturing action descriptions, integrating task-relevant
screen information, and maintaining a dedicated memory module to store and
manage this information. By leveraging explicit memory representations, CoM
enables GUI agents to better understand task states and retain critical
historical information persistently. To equip GUI agents with memory management
capabilities and evaluate the effectiveness of CoM, we developed the GUI
Odyssey-CoM, a dataset comprising 111k screen-action pairs annotated with
Chain-of-Memory. Experimental results demonstrate that CoM significantly
improves GUI agents' performance in cross-application tasks. Additionally, GUI
Odyssey-CoM enables 7B models to achieve memory management capabilities
comparable to 72B models. The dataset and code will be open-sourced.

</details>


### [33] [Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?](https://arxiv.org/abs/2506.18183)
*Zhiting Mei,Christina Zhang,Tenny Yin,Justin Lidard,Ola Shorinwa,Anirudha Majumdar*

Main category: cs.AI

TL;DR: 推理大模型虽然成绩突出，但常常对错误答案表现出过度自信，通过让模型自省其推理过程，可在部分情况下改善置信度校准，但该方法并不适用于所有模型。未来需专注于更合理的校准算法与评价基准的设计。


<details>
  <summary>Details</summary>
Motivation: 推理语言模型虽然在多个高难度基准测试上刷新了成绩，但其输出依旧存在自信但错误的情况（幻觉），因此在实际部署时如何衡量与信任这些模型成为关键。本文关注推理模型不确定性量化这一现实需求。

Method: 本文主要提出并评估了自省式不确定性量化（UQ）方法，并围绕推理模型校准展开三方面探索：模型校准现状、推理深度与模型校准关系，及通过反思自身推理过程提升置信度评估。实验评估涵盖多种主流推理模型与多项基准任务。

Result: 实验证明：1）推理模型普遍过于自信，尤其是在错误回答时，置信度常高于85%；2）推理深度加大时，过度自信现象更突出；3）部分模型（如o3-Mini和DeepSeek R1）通过自省性链式推理可改善校准，但也有模型（如Claude 3.7 Sonnet）表现更差。

Conclusion: 当前推理模型存在严重的过度自信问题，校准能力有限。自省式推理可提升部分模型的校准效果，但效果并非普适。未来应设计更完善的不确定性量化基准，并进一步提升推理模型的置信度评估能力。

Abstract: Reasoning language models have set state-of-the-art (SOTA) records on many
challenging benchmarks, enabled by multi-step reasoning induced using
reinforcement learning. However, like previous language models, reasoning
models are prone to generating confident, plausible responses that are
incorrect (hallucinations). Knowing when and how much to trust these models is
critical to the safe deployment of reasoning models in real-world applications.
To this end, we explore uncertainty quantification of reasoning models in this
work. Specifically, we ask three fundamental questions: First, are reasoning
models well-calibrated? Second, does deeper reasoning improve model
calibration? Finally, inspired by humans' innate ability to double-check their
thought processes to verify the validity of their answers and their confidence,
we ask: can reasoning models improve their calibration by explicitly reasoning
about their chain-of-thought traces? We introduce introspective uncertainty
quantification (UQ) to explore this direction. In extensive evaluations on SOTA
reasoning models across a broad range of benchmarks, we find that reasoning
models: (i) are typically overconfident, with self-verbalized confidence
estimates often greater than 85% particularly for incorrect responses, (ii)
become even more overconfident with deeper reasoning, and (iii) can become
better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not
uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we
conclude with important research directions to design necessary UQ benchmarks
and improve the calibration of reasoning models.

</details>


### [34] [The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis](https://arxiv.org/abs/2506.18187)
*Shahriar Noroozizadeh,Pim Welle,Jeremy C. Weiss,George H. Chen*

Main category: cs.AI

TL;DR: 不依从抗精神病药物会让精神分裂症患者更早经历不良事件（如早逝、住院、入狱），提前约1至4个月。依从性提高能显著延缓危机发生，生存分析联用因果推断为政策制定提供参考。


<details>
  <summary>Details</summary>
Motivation: 精神分裂症患者非依从性服用抗精神病药物可能导致不良结局，但具体影响和量化证据尚不充分。该研究旨在量化药物不依从性与早逝、非自愿住院、入狱等恶性事件之间的关联，并通过因果推断与生存分析方法提升分析的精确度。

Method: 使用生存分析方法，以多种生存模型扩展常用的因果推断技术（T-learner、S-learner、最近邻匹配），分析药物不依从（视为“处理”）导致首次不良事件所需时间。实验对不同纵向信息长度（3、6、9、12个月）重复分析，并进行药物种类和给药方式（注射 vs. 口服）亚组分析。通过消融实验验证县级风险评分对混杂因子的校正作用。

Result: 在宾夕法尼亚州阿勒格尼县数据中发现，药物不依从显著提前约1至4个月发生不良事件。消融实验显示移除风险评分会放大该效应，表明其对混杂因素有重要调节作用。不同药物类型与给药方式的亚组分析结果一致，不依从均显著增加不良结局提前发生的风险。

Conclusion: 药物依从性对延缓精神分裂症患者精神危机具有临床意义。结合生存分析和因果推断的方法能够为公共政策提供有价值信息，但本研究强调只能做相关性推断，真正的因果解释还需满足额外假设。

Abstract: This study quantifies the association between non-adherence to antipsychotic
medications and adverse outcomes in individuals with schizophrenia. We frame
the problem using survival analysis, focusing on the time to the earliest of
several adverse events (early death, involuntary hospitalization, jail
booking). We extend standard causal inference methods (T-learner, S-learner,
nearest neighbor matching) to utilize various survival models to estimate
individual and average treatment effects, where treatment corresponds to
medication non-adherence. Analyses are repeated using different amounts of
longitudinal information (3, 6, 9, and 12 months). Using data from Allegheny
County in western Pennsylvania, we find strong evidence that non-adherence
advances adverse outcomes by approximately 1 to 4 months. Ablation studies
confirm that county-provided risk scores adjust for key confounders, as their
removal amplifies the estimated effects. Subgroup analyses by medication
formulation (injectable vs. oral) and medication type consistently show that
non-adherence is associated with earlier adverse events. These findings
highlight the clinical importance of adherence in delaying psychiatric crises
and show that integrating survival analysis with causal inference tools can
yield policy-relevant insights. We caution that although we apply causal
inference, we only make associative claims and discuss assumptions needed for
causal interpretation.

</details>


### [35] [A Conceptual Framework for AI Capability Evaluations](https://arxiv.org/abs/2506.18213)
*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Luca Nicolás Forziati Gangi,Matheo Sandleris Musa,Lola Ramos Pereyra,Mario Leiva,Juan Gustavo Corvalan,María Vanina Martinez,Gerardo Simari*

Main category: cs.AI

TL;DR: 本文提出了一个结构化的AI能力评估分析框架，提升了评估的透明度与可比性，为研究者、从业者和政策制定者提供了有价值的工具。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统广泛应用于社会，如何系统性和透明地评估其能力和风险成为AI治理的重要需求，但目前缺乏可靠的综合评估方法。

Method: 提出了一个分析AI能力评估的概念性框架，该框架对现有评估方法和术语进行结构化和描述化梳理，不引入新的分类或固定格式。

Result: 该框架提高了AI能力评估的透明度、可比性和可解释性，有助于发现方法上的不足，指导评估设计，并为政策制定者提供便于理解和比较的工具。

Conclusion: 提出的分析框架有助于推动AI能力评估方法的规范化，支持多方在AI治理中的有效决策。

Abstract: As AI systems advance and integrate into society, well-designed and
transparent evaluations are becoming essential tools in AI governance,
informing decisions by providing evidence about system capabilities and risks.
Yet there remains a lack of clarity on how to perform these assessments both
comprehensively and reliably. To address this gap, we propose a conceptual
framework for analyzing AI capability evaluations, offering a structured,
descriptive approach that systematizes the analysis of widely used methods and
terminology without imposing new taxonomies or rigid formats. This framework
supports transparency, comparability, and interpretability across diverse
evaluations. It also enables researchers to identify methodological weaknesses,
assists practitioners in designing evaluations, and provides policymakers with
an accessible tool to scrutinize, compare, and navigate complex evaluation
landscapes.

</details>


### [36] [The 4th Dimension for Scaling Model Size](https://arxiv.org/abs/2506.18233)
*Ruike Zhu,Hanwen Zhang,Tianyu Shi,Chi Wang,Tianyi Zhou,Zengyi Qin*

Main category: cs.AI

TL;DR: 该论文提出通过参数复用（虚拟逻辑深度VLD）可显著提升大模型推理能力而无需增加参数，实验验证其普适性，有助于低成本实现更强模型推理力。


<details>
  <summary>Details</summary>
Motivation: 目前大模型扩展主要依赖于增加深度、宽度和参数数量，但这些方法成本较高，因此希望探索新的扩展方式以提升模型能力。

Method: 提出了一种新的模型扩展维度——虚拟逻辑深度（VLD），通过模型内部参数复用来增加算法深度而不增加参数总数，并通过设计受控实验系统分析VLD扩展特点。

Result: 发现VLD扩展下，模型知识容量基本不变但推理能力显著提升，并且参数数量与知识容量相关，与推理能力无直接关系，合理利用VLD可以在不增加参数的情况下提升推理能力。

Conclusion: VLD是一种有效提升模型推理能力而不需增加参数总数的新路径；通过参数复用可以显著提升推理能力，并且这些结论在多种模型配置下均成立，表现出较强的普适性。

Abstract: Scaling the size of large language models typically involves three
dimensions: depth, width, and the number of parameters. In this work, we
explore a fourth dimension, virtual logical depth (VLD), which increases the
effective algorithmic depth without changing the overall parameter count by
reusing parameters within the model. Although parameter reuse is not a new
concept, its potential and characteristics in model scaling have not been
thoroughly studied. Through carefully designed controlled experiments, we make
the following key discoveries regarding VLD scaling:
  VLD scaling forces the knowledge capacity of the model to remain almost
constant, with only minor variations.
  VLD scaling enables a significant improvement in reasoning capability,
provided the scaling method is properly implemented.
  The number of parameters correlates with knowledge capacity, but not with
reasoning capability. Under certain conditions, it is not necessary to increase
the parameter count to enhance reasoning.
  These findings are consistent across various model configurations and are
likely to be generally valid within the scope of our experiments.

</details>


### [37] [Advanced For-Loop for QML algorithm search](https://arxiv.org/abs/2506.18260)
*FuTe Wong*

Main category: cs.AI

TL;DR: 本文借助大型语言模型多智能体系统，自动化探索和优化量子机器学习算法。在概念验证中，成功将部分经典ML算法转化为量子形式，展示了方法的有效性和前景。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算和量子机器学习（QML）的快速发展，现有的QML算法大多依赖于人工设计，开发效率和探索空间有限。论文动机在于希望利用大型语言模型（LLM）多智能体系统自动化搜索和优化QML算法，加快创新步伐。

Method: 本文提出了一种基于大型语言模型的多智能体系统（LLMMA）框架，使多个智能体能够在抽象层面对经典机器学习算法（如多层感知机、前馈、反向传播等）进行量子化变换的自动生成与迭代优化。该方法借鉴了Google DeepMind的FunSearch理念。

Result: 通过原型验证，论文展示了LLMMA框架能够系统性地探索并自动地将部分经典机器学习思想适配到量子计算领域，显示了该方法在QML算法开发中的潜力。

Conclusion: LLMMA框架为QML算法的高效和自动化开发提供了新思路，未来可引入规划机制和更智能的搜索策略，拓宽量子增强机器学习的应用。

Abstract: This paper introduces an advanced framework leveraging Large Language
Model-based Multi-Agent Systems (LLMMA) for the automated search and
optimization of Quantum Machine Learning (QML) algorithms. Inspired by Google
DeepMind's FunSearch, the proposed system works on abstract level to
iteratively generates and refines quantum transformations of classical machine
learning algorithms (concepts), such as the Multi-Layer Perceptron,
forward-forward and backpropagation algorithms. As a proof of concept, this
work highlights the potential of agentic frameworks to systematically explore
classical machine learning concepts and adapt them for quantum computing,
paving the way for efficient and automated development of QML algorithms.
Future directions include incorporating planning mechanisms and optimizing
strategy in the search space for broader applications in quantum-enhanced
machine learning.

</details>


### [38] [Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team](https://arxiv.org/abs/2506.18348)
*Weilun Yu,Shixiang Tang,Yonggui Huang,Nanqing Dong,Li Fan,Honggang Qi,Wei Liu,Xiaoli Diao,Xi Chen,Wanli Ouyang*

Main category: cs.AI

TL;DR: IDVSCI框架通过加入内部讨论与投票、双重多样性评审机制，有效增强了LLM科学家代理的推理和创新能力，在多个领域表现优越，表明“互动与评议”机制在自主科研中有重要价值。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型（LLM）的科学家代理在自主科学发现方面取得了一定进展，但缺乏真实科研活动中必需的交互推理和评估机制。

Method: 提出了IDVSCI（Internal Discussion and Vote SCIentists）框架，包括动态知识交流机制和双重多样性评审范式，支持代理间的反馈和异质性专家评审。

Result: 在计算机科学广泛应用的基准数据集以及新引入的健康科学数据集上进行实验，IDVSCI在两者上均取得了最佳表现，优于AI Scientist和VIRSCI等现有系统。

Conclusion: 通过模拟人与人之间互动和同行评议过程，IDVSCI显著提升了LLM在自主科研中的推理深度和创新能力。

Abstract: Scientific progress increasingly relies on effective collaboration among
researchers, a dynamic that large language models (LLMs) have only begun to
emulate. While recent LLM-based scientist agents show promise in autonomous
scientific discovery, they often lack the interactive reasoning and evaluation
mechanisms essential to real-world research. We propose IDVSCI (Internal
Discussion and Vote SCIentists), a multi-agent framework built on LLMs that
incorporates two key innovations: a Dynamic Knowledge Exchange mechanism
enabling iterative feedback among agents, and a Dual-Diversity Review paradigm
that simulates heterogeneous expert evaluation. These components jointly
promote deeper reasoning and the generation of more creative and impactful
scientific ideas. To evaluate the effectiveness and generalizability of our
approach, we conduct experiments on two datasets: a widely used benchmark in
computer science and a new dataset we introduce in the health sciences domain.
Results show that IDVSCI consistently achieves the best performance across both
datasets, outperforming existing systems such as AI Scientist and VIRSCI. These
findings highlight the value of modeling interaction and peer review dynamics
in LLM-based autonomous research.

</details>


### [39] [A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction](https://arxiv.org/abs/2506.18424)
*Chengjie Liu,Weiyu Chen,Huiyao Xu,Yuan Du,Jun Yang,Li Du*

Main category: cs.AI

TL;DR: 作者提出一种利用大语言模型自动从文献中抽取尺寸关系的方法，有效剪枝设计搜索空间，在三类电路上显著提升优化效率。这为自动化类比电路设计开辟了新方向。


<details>
  <summary>Details</summary>
Motivation: 目前类比电路器件尺寸设计阶段，虽然普遍采用数学优化方法提升优化效率，但往往忽略了如何自动引入先验知识，有效压缩（剪枝）搜索空间。现有方法在搜索空间的压缩上仍有较大提升空间。

Method: 提出了一种基于大语言模型（LLM）的多智能体框架，用来从学术论文中自动抽取类比电路的尺寸关系，通过这些抽取的关系对尺寸优化的搜索空间进行有效剪枝。

Result: 该框架在三类电路测试中实现了2.32至26.6倍的优化效率提升。

Conclusion: 本文展示了LLM能够有效剪枝类比电路尺寸设计搜索空间，为LLM与传统类比电路设计自动化方法的结合提供了新思路。

Abstract: In the design process of the analog circuit pre-layout phase, device sizing
is an important step in determining whether an analog circuit can meet the
required performance metrics. Many existing techniques extract the circuit
sizing task as a mathematical optimization problem to solve and continuously
improve the optimization efficiency from a mathematical perspective. But they
ignore the automatic introduction of prior knowledge, fail to achieve effective
pruning of the search space, which thereby leads to a considerable compression
margin remaining in the search space. To alleviate this problem, we propose a
large language model (LLM)-based multi-agent framework for analog circuits'
sizing relationships extraction from academic papers. The search space in the
sizing process can be effectively pruned based on the sizing relationship
extracted by this framework. Eventually, we conducted tests on 3 types of
circuits, and the optimization efficiency was improved by $2.32 \sim 26.6
\times$. This work demonstrates that the LLM can effectively prune the search
space for analog circuit sizing, providing a new solution for the combination
of LLMs and conventional analog circuit design automation methods.

</details>


### [40] [How Robust is Model Editing after Fine-Tuning? An Empirical Study on Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.18428)
*Feng He,Zhenyang Liu,Marco Valentino,Zhixue Zhao*

Main category: cs.AI

TL;DR: T2I扩散模型中的模型编辑很容易在后续微调中失效，尤其是特定微调方式。安全应用中微调既可移除恶意编辑，还会丢失有益改动，需要更鲁棒的编辑技术或重新编辑操作。


<details>
  <summary>Details</summary>
Motivation: 作者关注于在大模型预训练后进行模型编辑，以便低成本地修正或注入特定行为（如事实纠错、偏见缓解），但目前尚不清楚这些编辑在后续微调后能否保留或被逆转。该问题对于模型安全和长期行为控制有重要影响。

Method: 系统性地研究模型编辑与微调在文本到图像扩散模型（T2I diffusion models）中的相互作用。研究内容涵盖两种模型（Stable Diffusion和FLUX）、两种主流编辑技术、三种微调方法（DreamBooth、LoRA和DoRA），通过多样化编辑任务和评估指标进行实证分析。

Result: 大部分编辑在后续微调后无法保留，哪怕微调内容与编辑点无关。DoRA微调法最易导致编辑失效。编辑方法中，UCE方法较为稳定，对比ReFACT在微调后表现更好。

Conclusion: 当前模型编辑方法在长期控制和对齐方面存在严重不足。微调过程既可移除恶意编辑，但也可能消除有益的安全调整，因此实际应用需加强编辑鲁棒性，或在微调后重新编辑以保证效果。

Abstract: Model editing offers a low-cost technique to inject or correct a particular
behavior in a pre-trained model without extensive retraining, supporting
applications such as factual correction and bias mitigation. Despite this
common practice, it remains unknown whether edits persist after fine-tuning or
whether they are inadvertently reversed. This question has fundamental
practical implications. For example, if fine-tuning removes prior edits, it
could serve as a defence mechanism against hidden malicious edits. Vice versa,
the unintended removal of edits related to bias mitigation could pose serious
safety concerns. We systematically investigate the interaction between model
editing and fine-tuning in the context of T2I diffusion models, which are known
to exhibit biases and generate inappropriate content. Our study spans two T2I
model families (Stable Diffusion and FLUX), two sota editing techniques, and
three fine-tuning methods (DreamBooth, LoRA, and DoRA). Through an extensive
empirical analysis across diverse editing tasks and evaluation metrics, our
findings reveal a trend: edits generally fail to persist through fine-tuning,
even when fine-tuning is tangential or unrelated to the edits. Notably, we
observe that DoRA exhibits the strongest edit reversal effect. At the same
time, among editing methods, UCE demonstrates greater robustness, retaining
significantly higher efficacy post-fine-tuning compared to ReFACT. These
findings highlight a crucial limitation in current editing methodologies,
emphasizing the need for more robust techniques to ensure reliable long-term
control and alignment of deployed AI systems. These findings have dual
implications for AI safety: they suggest that fine-tuning could serve as a
remediation mechanism for malicious edits while simultaneously highlighting the
need for re-editing after fine-tuning to maintain beneficial safety and
alignment properties.

</details>


### [41] [Standard Applicability Judgment and Cross-jurisdictional Reasoning: A RAG-based Framework for Medical Device Compliance](https://arxiv.org/abs/2506.18511)
*Yu Han,Aaron Ceross,Jeroen H. M. Bergmann*

Main category: cs.AI

TL;DR: 该文提出基于RAG的AI系统自动判定医疗器械标准适用性，准确率高且支持中美法规跨区域推理，是合规领域首个端到端推理解决方案。


<details>
  <summary>Details</summary>
Motivation: 在医疗设备合规领域，不同地区的法规标准文档碎片化且不统一，标准适用性判定需依赖专家，效率低下，亟需自动化工具提升法规合规工作效率。

Method: 提出了一套模块化AI系统，基于检索增强生成（RAG）技术。系统对给定的设备描述，先从标准库中检索候选标准，再用大语言模型判断每个标准在不同司法管辖区下的适用性（强制、推荐、不适用），并提供可溯源的理由。构建了国际化的医疗设备描述基准数据集，包含专家标注的标准映射，并同检索、零样本与规则法基线模型对系统进行评测。

Result: 系统取得了73%的分类准确率和87%的Top-5检索召回率，展示出显著有效性。系统具备跨中美法规标准区域感知与推理能力，可解释标准适用性与冲突。

Conclusion: 首次提出端到端标准适用性推理系统，实现医疗设备法规合规的自动化、可扩展以及可解释AI支撑。能够支持不同国家间法规标准适用的冲突解决与标准判定理由追溯。

Abstract: Identifying the appropriate regulatory standard applicability remains a
critical yet understudied challenge in medical device compliance, frequently
necessitating expert interpretation of fragmented and heterogeneous
documentation across different jurisdictions. To address this challenge, we
introduce a modular AI system that leverages a retrieval-augmented generation
(RAG) pipeline to automate standard applicability determination. Given a
free-text device description, our system retrieves candidate standards from a
curated corpus and uses large language models to infer jurisdiction-specific
applicability, classified as Mandatory, Recommended, or Not Applicable, with
traceable justifications. We construct an international benchmark dataset of
medical device descriptions with expert-annotated standard mappings, and
evaluate our system against retrieval-only, zero-shot, and rule-based
baselines. The proposed approach attains a classification accuracy of 73% and a
Top-5 retrieval recall of 87%, demonstrating its effectiveness in identifying
relevant regulatory standards. We introduce the first end-to-end system for
standard applicability reasoning, enabling scalable and interpretable
AI-supported regulatory science. Notably, our region-aware RAG agent performs
cross-jurisdictional reasoning between Chinese and U.S. standards, supporting
conflict resolution and applicability justification across regulatory
frameworks.

</details>


### [42] [A Question Bank to Assess AI Inclusivity: Mapping out the Journey from Diversity Errors to Inclusion Excellence](https://arxiv.org/abs/2506.18538)
*Rifat Ara Shams,Didar Zowghi,Muneera Bano*

Main category: cs.AI

TL;DR: 本论文提出253题的AI包容性问题库，可系统评估AI在多样性与包容性方面的表现，方法科学，结果显示工具有效，对实现公平AI具有实践意义。


<details>
  <summary>Details</summary>
Motivation: 当前的AI风险评估框架往往忽视包容性，缺乏衡量AI系统多样性与包容性原则一致性的标准化工具。因此，亟需开发能够系统性衡量AI包容性的手段。

Method: 本文提出并开发了一个结构化的AI包容性问题库，包含253个问题，从“人”、“数据”、“流程”、“系统”和“治理”五大支柱评估AI包容性。开发过程采用多轮迭代法，融合文献综述、包容性指南、负责任AI框架及模拟用户研究的见解。之后，研究团队通过70个人工生成的AI相关职业角色，模拟评估了问题库在不同应用领域和角色中的相关性与有效性。

Result: 实验表明，该问题库能够有效评估和提升AI系统在多样性与包容性方面的表现，对AI开发流程和治理结构中融入包容性原则具有重要作用。

Conclusion: 所提出的问题库为学界、业界和政策制定者提供了系统评估与加强AI包容性的可操作工具，有助于推动更公平和负责任的AI技术发展。

Abstract: Ensuring diversity and inclusion (D&I) in artificial intelligence (AI) is
crucial for mitigating biases and promoting equitable decision-making. However,
existing AI risk assessment frameworks often overlook inclusivity, lacking
standardized tools to measure an AI system's alignment with D&I principles.
This paper introduces a structured AI inclusivity question bank, a
comprehensive set of 253 questions designed to evaluate AI inclusivity across
five pillars: Humans, Data, Process, System, and Governance. The development of
the question bank involved an iterative, multi-source approach, incorporating
insights from literature reviews, D&I guidelines, Responsible AI frameworks,
and a simulated user study. The simulated evaluation, conducted with 70
AI-generated personas related to different AI jobs, assessed the question
bank's relevance and effectiveness for AI inclusivity across diverse roles and
application domains. The findings highlight the importance of integrating D&I
principles into AI development workflows and governance structures. The
question bank provides an actionable tool for researchers, practitioners, and
policymakers to systematically assess and enhance the inclusivity of AI
systems, paving the way for more equitable and responsible AI technologies.

</details>


### [43] [T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent](https://arxiv.org/abs/2506.18559)
*Hong Qing Yu*

Main category: cs.AI

TL;DR: T-CPDL扩展描述逻辑，融入时序、因果和概率推理，大幅提升大模型推理准确性、可解释性和可信度，为强化逻辑-检索增强生成打下基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然在生成流畅文本方面表现优秀，但在涉及时间约束、因果关系和概率推理的结构化推理任务上表现不佳。为了解决这个问题，有必要为语言模型推理过程引入更完整的时序、因果和概率语义支持。

Method: 作者提出了一种整合型框架“T-CPDL（时序因果概率描述逻辑）”，将传统描述逻辑扩展为包含时序区间算子、显式因果关系和概率注解。T-CPDL有两种变体：一种基于Allen区间代数，描述定性时序关系；另一种通过显式带时间戳的因果断言丰富表达方式。这两种变体共享统一的逻辑结构，可实现从简单时序排序到复杂概率因果推理的多种推理任务。

Result: 在时序推理和因果推理基准数据集上的实验证明，T-CPDL能显著提升大型语言模型的推理准确率、可解释性及结果可信度校准能力。

Conclusion: T-CPDL极大提升了语言模型支撑稳健、可解释、可信决策的能力，并为高级的逻辑-检索增强生成（Logic-RAG）框架奠定了基础，有望提升知识图谱增强型RAG系统的推理能力和效率。

Abstract: Large language models excel at generating fluent text but frequently struggle
with structured reasoning involving temporal constraints, causal relationships,
and probabilistic reasoning. To address these limitations, we propose Temporal
Causal Probabilistic Description Logic (T-CPDL), an integrated framework that
extends traditional Description Logic with temporal interval operators,
explicit causal relationships, and probabilistic annotations. We present two
distinct variants of T-CPDL: one capturing qualitative temporal relationships
through Allen's interval algebra, and another variant enriched with explicit
timestamped causal assertions. Both variants share a unified logical structure,
enabling complex reasoning tasks ranging from simple temporal ordering to
nuanced probabilistic causation. Empirical evaluations on temporal reasoning
and causal inference benchmarks confirm that T-CPDL substantially improves
inference accuracy, interpretability, and confidence calibration of language
model outputs. By delivering transparent reasoning paths and fine-grained
temporal and causal semantics, T-CPDL significantly enhances the capability of
language models to support robust, explainable, and trustworthy
decision-making. This work also lays the groundwork for developing advanced
Logic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentially
boosting the reasoning capabilities and efficiency of knowledge graph-enhanced
RAG systems.

</details>


### [44] [AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs](https://arxiv.org/abs/2506.18628)
*Piotr Matys,Jan Eliasz,Konrad Kiełczyński,Mikołaj Langner,Teddy Ferdinan,Jan Kocoń,Przemysław Kazienko*

Main category: cs.AI

TL;DR: 本文提出AggTruth方法，通过分析attention分数实现LLM幻觉的在线检测，在多模型、任务下超过当前最佳方法，并强调了特征选择和head选择的作用。


<details>
  <summary>Details</summary>
Motivation: 在现实应用中，LLMs即使在RAG设置下也常常出现虚假生成（幻觉），这为模型落地产生重大挑战。作者希望解决如何有效检测和降低LLMs的语境性幻觉问题。

Method: 提出了AggTruth方法，通过分析LLM内部attention分数的分布，在线检测语境幻觉。具体设计了四种不同的attention分数聚合技术。还研究了特征选择和attention head数目对检测性能的影响。

Result: AggTruth在所有测试的LLMs和任务（包括同任务和跨任务设置）中表现稳定，在多种场景下优于当前最优方法（SOTA）。合理选择attention heads能进一步提升检测效果。

Conclusion: AggTruth提供了一种通用、有效的LLM幻觉检测方案，能够在多模型多任务下超过现有方法，并揭示了attention head选择的重要性。

Abstract: In real-world applications, Large Language Models (LLMs) often hallucinate,
even in Retrieval-Augmented Generation (RAG) settings, which poses a
significant challenge to their deployment. In this paper, we introduce
AggTruth, a method for online detection of contextual hallucinations by
analyzing the distribution of internal attention scores in the provided context
(passage). Specifically, we propose four different variants of the method, each
varying in the aggregation technique used to calculate attention scores. Across
all LLMs examined, AggTruth demonstrated stable performance in both same-task
and cross-task setups, outperforming the current SOTA in multiple scenarios.
Furthermore, we conducted an in-depth analysis of feature selection techniques
and examined how the number of selected attention heads impacts detection
performance, demonstrating that careful selection of heads is essential to
achieve optimal results.

</details>


### [45] [Dual-level Behavioral Consistency for Inter-group and Intra-group Coordination in Multi-Agent Systems](https://arxiv.org/abs/2506.18651)
*Shuocun Yang,Huawen Hu,Enze Shi,Shu Zhang*

Main category: cs.AI

TL;DR: 作者提出了DLBC方法，通过组内与组间的行为一致性调控，显著提升了多智能体系统的协作与分工能力，在实验任务中获得较大性能收益。


<details>
  <summary>Details</summary>
Motivation: 现有工作多关注多智能体系统内部的行为一致性，对分组场景下的行为一致性关注不足，亟需方法同时控制组内与组间的行为策略。

Method: 提出Dual-Level Behavioral Consistency（DLBC）方法，将多智能体分组，并在组内与组间动态调节行为多样性，通过直接约束智能体策略函数以提升行为一致性。

Result: 实验表明，DLBC在各类分组协作任务中显著提升了组内合作与组间任务专业化表现，取得了显著性能提升。

Conclusion: DLBC方法有效提升了多智能体系统中组内协作与组间分工性能，展现了行为一致性控制的新思路，并具备在复杂任务与动态环境中的应用潜力。

Abstract: Behavioral diversity in Multi-agent reinforcement learning(MARL) represents
an emerging and promising research area. Prior work has largely centered on
intra-group behavioral consistency in multi-agent systems, with limited
attention given to behavioral consistency in multi-agent grouping scenarios. In
this paper, we introduce Dual-Level Behavioral Consistency (DLBC), a novel MARL
control method designed to explicitly regulate agent behaviors at both
intra-group and inter-group levels. DLBC partitions agents into distinct groups
and dynamically modulates behavioral diversity both within and between these
groups. By dynamically modulating behavioral diversity within and between these
groups, DLBC achieves enhanced division of labor through inter-group
consistency, which constrains behavioral strategies across different groups.
Simultaneously, intra-group consistency, achieved by aligning behavioral
strategies within each group, fosters stronger intra-group cooperation.
Crucially, DLBC's direct constraint of agent policy functions ensures its broad
applicability across various algorithmic frameworks. Experimental results in
various grouping cooperation scenarios demonstrate that DLBC significantly
enhances both intra-group cooperative performance and inter-group task
specialization, yielding substantial performance improvements. DLBC provides
new ideas for behavioral consistency control of multi-intelligent body systems,
and its potential for application in more complex tasks and dynamic
environments can be further explored in the future.

</details>


### [46] [Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training](https://arxiv.org/abs/2506.18777)
*Jonathan Cook,Silvia Sapora,Arash Ahmadian,Akbir Khan,Tim Rocktaschel,Jakob Foerster,Laura Ruis*

Main category: cs.AI

TL;DR: 通过微调LLMs仅依赖程序源码（无需I/O例子）进行推理可提升通用推理能力，模型可内化算法抽象，指向更强符号推理和模型对齐方向。


<details>
  <summary>Details</summary>
Motivation: 代码训练能显著提升LLMs推理能力，但目前尚不清楚其背后机理。为探究是否通过仅源码训练也能赋予推理能力，提出PBB方法并开展实验。

Method: 将LLMs在两组程序上微调：一组为源码+I/O例子（w/ IO），一组仅有源码（w/o IO），对比二者在推理与评估能力方面的表现差异。

Result: LLMs在未见过I/O的程序上也能直接输出，尤其在代码而非语言描述形式更显著，且通过链式思考提升表现。PBB方式较基于分布式I/O训练更鲁棒。

Conclusion: PBB（通过源码训练而非I/O实例）可促使LLMs学习可复用的算法抽象，提升推理能力。通过代码训练能够使模型在处理变动输入时更为鲁棒，此方向为模型对符号性过程学习与对准等任务提供新思路。

Abstract: Training large language models (LLMs) on source code significantly enhances
their general-purpose reasoning abilities, but the mechanisms underlying this
generalisation are poorly understood. In this paper, we propose Programming by
Backprop (PBB) as a potential driver of this effect - teaching a model to
evaluate a program for inputs by training on its source code alone, without
ever seeing I/O examples. To explore this idea, we finetune LLMs on two sets of
programs representing simple maths problems and algorithms: one with source
code and I/O examples (w/ IO), the other with source code only (w/o IO). We
find evidence that LLMs have some ability to evaluate w/o IO programs for
inputs in a range of experimental settings, and make several observations.
Firstly, PBB works significantly better when programs are provided as code
rather than semantically equivalent language descriptions. Secondly, LLMs can
produce outputs for w/o IO programs directly, by implicitly evaluating the
program within the forward pass, and more reliably when stepping through the
program in-context via chain-of-thought. We further show that PBB leads to more
robust evaluation of programs across inputs than training on I/O pairs drawn
from a distribution that mirrors naturally occurring data. Our findings suggest
a mechanism for enhanced reasoning through code training: it allows LLMs to
internalise reusable algorithmic abstractions. Significant scope remains for
future work to enable LLMs to more effectively learn from symbolic procedures,
and progress in this direction opens other avenues like model alignment by
training on formal constitutional principles.

</details>


### [47] [TRIZ Agents: A Multi-Agent LLM Approach for TRIZ-Based Innovation](https://arxiv.org/abs/2506.18783)
*Kamil Szczepanik,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 作者提出了基于LLM的多智能体TRIZ系统，通过协作高效解决复杂创新问题，展示了AI赋能分布式创新的前景。


<details>
  <summary>Details</summary>
Motivation: TRIZ理论为创新解决方案提供框架，但其实际应用受限于所需的复杂性和多学科知识。随着大语言模型（LLM）技术的发展，自动化TRIZ流程的可能性出现，因此作者希望突破TRIZ应用门槛。

Method: 提出一种多智能体系统（TRIZ agents），利用多个具备不同专业领域知识和工具接入能力的LLM智能体协作，基于TRIZ方法论共同解决创新性问题。通过在特定工程案例中模拟和验证多智能体团队协作解决问题的能力。

Result: 多智能体系统能协同高效地推进TRIZ步骤，并能在复杂创新挑战中产出多样化且具有创新性的解决方案。实验结果验证了智能体协作在复杂创新任务中的优势。

Conclusion: 多智能体LLM系统在创新问题求解上展现出分布式协作和创新能力，有助于推动AI驱动的创新进程，是复杂问题去中心化解决的重要方向。

Abstract: TRIZ, the Theory of Inventive Problem Solving, is a structured,
knowledge-based framework for innovation and abstracting problems to find
inventive solutions. However, its application is often limited by the
complexity and deep interdisciplinary knowledge required. Advancements in Large
Language Models (LLMs) have revealed new possibilities for automating parts of
this process. While previous studies have explored single LLMs in TRIZ
applications, this paper introduces a multi-agent approach. We propose an
LLM-based multi-agent system, called TRIZ agents, each with specialized
capabilities and tool access, collaboratively solving inventive problems based
on the TRIZ methodology. This multi-agent system leverages agents with various
domain expertise to efficiently navigate TRIZ steps. The aim is to model and
simulate an inventive process with language agents. We assess the effectiveness
of this team of agents in addressing complex innovation challenges based on a
selected case study in engineering. We demonstrate the potential of agent
collaboration to produce diverse, inventive solutions. This research
contributes to the future of AI-driven innovation, showcasing the advantages of
decentralized problem-solving in complex ideation tasks.

</details>


### [48] [ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation](https://arxiv.org/abs/2506.18810)
*Siao Tang,Xinyin Ma,Gongfan Fang,Xinchao Wang*

Main category: cs.AI

TL;DR: 本文提出了一种推理生成时动态注入简洁提示的ConciseHint方法，能有效缩短大型推理模型的推理内容长度，并保持任务准确率，实现效率与性能兼得。


<details>
  <summary>Details</summary>
Motivation: 近年来大型推理模型（LRMs）通过扩展Chain-of-Thought（CoT）生成长度，提升了复杂推理任务的表现。但模型逐渐倾向于生成冗长推理过程，导致效率下降。现有提升效率的方法多关注推理前的技巧如Prompt设计或微调，鲜有研究在推理生成过程中实现简洁表达。亟需探索能在推理生成中直接鼓励简洁性的方案。

Method: 提出了一种名为ConciseHint的新框架，通过在推理生成过程中注入文本提示（可手工设计或基于简洁数据训练获得），持续鼓励模型简洁表述。此方法还可根据查询复杂度自适应调整提示强度，确保不会削弱模型性能。

Result: 在包括DeepSeek-R1与Qwen-3系列等最新LRMs上验证了ConciseHint的有效性。以Qwen-3 4B在GSM8K基准测试为例，推理过程长度降低65%，且几乎无准确率损失。

Conclusion: ConciseHint框架能有效缩短推理模型的推理过程表述长度，同时保持优异性能，解决了冗长推理带来的效率问题，对生成式推理模型实际应用具有重要改进价值。

Abstract: Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and
OpenAI o1 series have achieved notable performance enhancements on complex
reasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).
However, an emerging issue is their inclination to produce excessively verbose
reasoning processes, leading to the inefficiency problem. Existing literature
on improving efficiency mainly adheres to the before-reasoning paradigms such
as prompting and reasoning or fine-tuning and reasoning, but ignores the
promising direction of directly encouraging the model to speak concisely by
intervening during the generation of reasoning. In order to fill the blank, we
propose a framework dubbed ConciseHint, which continuously encourages the
reasoning model to speak concisely by injecting the textual hint (manually
designed or trained on the concise data) during the token generation of the
reasoning process. Besides, ConciseHint is adaptive to the complexity of the
query by adaptively adjusting the hint intensity, which ensures it will not
undermine model performance. Experiments on the state-of-the-art LRMs,
including DeepSeek-R1 and Qwen-3 series, demonstrate that our method can
effectively produce concise reasoning processes while maintaining performance
well. For instance, we achieve a reduction ratio of 65\% for the reasoning
length on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.

</details>


### [49] [Steering Conceptual Bias via Transformer Latent-Subspace Activation](https://arxiv.org/abs/2506.18887)
*Vansh Sharma,Venkat Raman*

Main category: cs.AI

TL;DR: 本文针对科学代码生成中的编程语言偏向控制问题，提出了基于梯度优化和动态探针的自适应激活引导方法（G-ACT），在不同规模的LLMs上显著提升了代码输出的目标语言一致性和模型可控性。


<details>
  <summary>Details</summary>
Motivation: 在现有大型语言模型(LLMs)的科学代码生成任务中，存在对特定编程语言的生成偏向，但如何高效、精确地操控模型生成特定编程语言的文本仍有挑战。此前的操控方法泛化性和稳定性不足。

Method: 首先评估LLMs在多种编程语言（如C++等）科学代码生成中的基线偏向；然后采用静态神经元归因方法对模型激活进行操作，发现其泛化能力有限；为此提出了一种梯度精炼的自适应激活引导框架（G-ACT），通过对每个提示的激活差异聚类，训练轻量化的层内探针在线选取适当的操控向量，从而动态地引导生成。

Result: G-ACT方法在LLaMA-3.2 3B模型上将探针分类准确率提高了15%，在早期层（0-6层）提升了61.5%，较标准的ACT框架有显著改进。在更大参数量的LLaMA-3.3 70B上，关键层的定向注入依然改善了语言选择。该方法附加的推理开销较小，并提升了模型可控性和行为可复现性。

Conclusion: 本文提出的G-ACT框架能高效、可扩展地实现对语言模型在代码生成时的编程语言偏向控制，具有较强的泛化能力和实际应用价值。

Abstract: This work examines whether activating latent subspaces in language models
(LLMs) can steer scientific code generation toward a specific programming
language. Five causal LLMs were first evaluated on scientific coding prompts to
quantify their baseline bias among four programming languages. A static
neuron-attribution method, perturbing the highest activated MLP weight for a
C++ or CPP token, proved brittle and exhibited limited generalization across
prompt styles and model scales. To address these limitations, a
gradient-refined adaptive activation steering framework (G-ACT) was developed:
per-prompt activation differences are clustered into a small set of steering
directions, and lightweight per-layer probes are trained and refined online to
select the appropriate steering vector. In LLaMA-3.2 3B, this approach reliably
biases generation towards the CPP language by increasing the average probe
classification accuracy by 15% and the early layers (0-6) improving the probe
classification accuracy by 61.5% compared to the standard ACT framework. For
LLaMA-3.3 70B, where attention-head signals become more diffuse, targeted
injections at key layers still improve language selection. Although per-layer
probing introduces a modest inference overhead, it remains practical by
steering only a subset of layers and enables reproducible model behavior. These
results demonstrate a scalable, interpretable and efficient mechanism for
concept-level control for practical agentic systems.

</details>


### [50] [Evaluating Generalization and Representation Stability in Small LMs via Prompting](https://arxiv.org/abs/2506.17289)
*Rahul Raja,Arpita Vats*

Main category: cs.AI

TL;DR: 本文系统比较了小型语言模型在少样本提示与有监督微调下、不同任务与分布情境中的泛化能力及内部表征，揭示了两种策略在低资源场景中各自的优劣，并为实践中模型选择提供参考。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在实际应用中需要有效泛化能力，但目前对于少样本提示（prompting）和有监督微调（fine-tuning）两种主流适应范式在少资源及数据分布变化场景下的表现尚不明确。此文旨在系统对比这两种策略，以指导低数据场景下的模型选择。

Method: 作者从任务类型、提示风格以及模型规模等多维度，系统地比较了few-shot prompting和supervised fine-tuning在分布内（in-distribution）与分布外（out-of-distribution, OOD）情境下的表现。不仅通过准确率评估模型表现，还分析了不同适应策略下模型内部表征的稳定性与抽象性。

Result: 实验结果揭示：不同的适应策略（prompting与fine-tuning）在小模型中对知识的内化与泛化方式有实质性差别，对任务特征表征的稳定性与抽象性也不尽相同。为低数据场景下的模型策略选择提供了实证和实践参考。

Conclusion: 少样本提示和有监督微调在小模型适应性、泛化性与内部表征上存在显著不同，为低资源设置下模型选择与优化提供了理论基础和实证依据。该研究对prompting和fine-tuning优劣的争论给出了新的经验见解。

Abstract: We investigate the generalization capabilities of small language models under
two popular adaptation paradigms: few-shot prompting and supervised
fine-tuning. While prompting is often favored for its parameter efficiency and
flexibility, it remains unclear how robust this approach is in low-resource
settings and under distributional shifts. This paper presents a comparative
study of prompting and fine-tuning across task formats, prompt styles, and
model scales, with a focus on their behavior in both in-distribution and
out-of-distribution (OOD) settings.
  Beyond accuracy, we analyze the internal representations learned by each
approach to assess the stability and abstraction of task-specific features. Our
findings highlight critical differences in how small models internalize and
generalize knowledge under different adaptation strategies. This work offers
practical guidance for model selection in low-data regimes and contributes
empirical insight into the ongoing debate over prompting versus fine-tuning.
Code for the experiments is available at the following

</details>


### [51] [Individual Causal Inference with Structural Causal Model](https://arxiv.org/abs/2506.17300)
*Daniel T. Chang*

Main category: cs.AI

TL;DR: 本文针对个体因果推断提出了基于结构因果模型（SCM）的全新方法，首次将个体差异机制正式引入因果推断形式化体系，为具体个体的干预效果推断提供了理论框架与操作工具。


<details>
  <summary>Details</summary>
Motivation: 个体因果推断（ICI）要预测特定个体在特定特征/事实下的干预效果，但主流因果推断方法多为群体级别，缺乏个体粒度建模。结构因果模型（SCM）本质也是群体级，难以直接用于个体推断。动机在于需弥补现有因果推断方法在个体层面的不足。

Method: 提出了基于SCM的个体因果推断方法，通过引入indiv-operator（indiv(W)）形式化“个体化群体”，用individual causal query（P(Y | indiv(W), do(X), Z)）描述个体因果查询过程。利用SCM中的外源变量编码个体间差异，从而开展个体级因果推断。

Result: 证明并论证了基于SCM的个体因果推断本质上是对个体“可能选择”（individual alternatives）的推断，而非只对个体反事实（non-actual）进行推断。新方法实现了群体模型到个体层面推断的桥梁。

Conclusion: 基于SCM的ICI方法通过引入新算子与查询方式，有效实现了从群体级模型向个体级因果推断的转变，为解决个体因果推断难题提供了理论和方法支持。

Abstract: Individual causal inference (ICI) uses causal inference methods to understand
and predict the effects of interventions on individuals, considering their
specific characteristics / facts. It aims to estimate individual causal effect
(ICE), which varies across individuals. Estimating ICE can be challenging due
to the limited data available for individuals, and the fact that most causal
inference methods are population-based. Structural Causal Model (SCM) is
fundamentally population-based. Therefore, causal discovery (structural
learning and parameter learning), association queries and intervention queries
are all naturally population-based. However, exogenous variables (U) in SCM can
encode individual variations and thus provide the mechanism for individualized
population per specific individual characteristics / facts. Based on this, we
propose ICI with SCM as a "rung 3" causal inference, because it involves
"imagining" what would be the causal effect of a hypothetical intervention on
an individual, given the individual's observed characteristics / facts.
Specifically, we propose the indiv-operator, indiv(W), to formalize/represent
the population individualization process, and the individual causal query, P(Y
| indiv(W), do(X), Z), to formalize/represent ICI. We show and argue that ICI
with SCM is inference on individual alternatives (possible), not individual
counterfactuals (non-actual).

</details>


### [52] [Resource Rational Contractualism Should Guide AI Alignment](https://arxiv.org/abs/2506.17434)
*Sydney Levine,Matija Franklin,Tan Zhi-Xuan,Secil Yanik Guyot,Lionel Wong,Daniel Kilov,Yejin Choi,Joshua B. Tenenbaum,Noah Goodman,Seth Lazar,Iason Gabriel*

Main category: cs.AI

TL;DR: 本论文提出一种资源理性契约主义框架，让AI借助认知启发式策略，高效近似群体认同的决策，实现更具社会适应性的道义对齐。


<details>
  <summary>Details</summary>
Motivation: 传统的道义协商方式难以大规模实现，尤其是在AI要与立场和价值观各异的人类及其他AI互动时，如何高效达成广泛认可的决策成为难题。

Method: 提出资源理性契约主义（Resource-Rational Contractualism, RRC）框架，使AI系统通过一系列受到人类认知启发、具有规范基础的启发式算法，权衡计算努力与决策准确性，从而近似各方在合理条件下达成的协议。

Result: RRC对齐的AI代理不仅高效运行，还能够适应并解释不断变化的人类社会环境。

Conclusion: 通过RRC方法，AI可以在成本较低、效率较高的情况下作出更符合多元群体意愿的决策，为AI在多样化人类场景下的道义对齐提供可行途径。

Abstract: AI systems will soon have to navigate human environments and make decisions
that affect people and other AI agents whose goals and values diverge.
Contractualist alignment proposes grounding those decisions in agreements that
diverse stakeholders would endorse under the right conditions, yet securing
such agreement at scale remains costly and slow -- even for advanced AI. We
therefore propose Resource-Rational Contractualism (RRC): a framework where AI
systems approximate the agreements rational parties would form by drawing on a
toolbox of normatively-grounded, cognitively-inspired heuristics that trade
effort for accuracy. An RRC-aligned agent would not only operate efficiently,
but also be equipped to dynamically adapt to and interpret the ever-changing
human social world.

</details>


### [53] [Keeping Medical AI Healthy: A Review of Detection and Correction Methods for System Degradation](https://arxiv.org/abs/2506.17442)
*Hao Guan,David Bates,Li Zhou*

Main category: cs.AI

TL;DR: 本文综述医疗AI系统在实际应用中面临的性能退化问题，分析原因，总结检测与修正手段，并提出未来研究建议，为AI健康管理提供了全面指导。


<details>
  <summary>Details</summary>
Motivation: AI系统在实际医疗环境中可能因数据分布变化、患者特征变迁、临床协议和数据质量变化等导致性能下降，这些问题威胁到模型可靠性乃至医疗安全，亟需机制保证AI系统长期有效运行。

Method: 系统性综述了AI在医疗领域性能退化的主要原因、漂移检测技术、根因分析以及模型修正手段，涵盖传统机器学习与大型语言模型，评价了各自优缺点和适用场景。

Result: 总结了数据和模型漂移检测、根因分析和修正方法，为医疗AI系统应用中的技术挑战和解决方案提供了系统性视角。展望了进一步提升模型健康管理、加强实用性与安全性的研究方向。

Conclusion: 本文强调医疗AI系统需要持续监测、早期退化检测和有效自我修正，以保障其长期安全、可靠运行。探讨了目前关键挑战和未来研究方向，旨在推动医疗AI更健康可持续发展。

Abstract: Artificial intelligence (AI) is increasingly integrated into modern
healthcare, offering powerful support for clinical decision-making. However, in
real-world settings, AI systems may experience performance degradation over
time, due to factors such as shifting data distributions, changes in patient
characteristics, evolving clinical protocols, and variations in data quality.
These factors can compromise model reliability, posing safety concerns and
increasing the likelihood of inaccurate predictions or adverse outcomes. This
review presents a forward-looking perspective on monitoring and maintaining the
"health" of AI systems in healthcare. We highlight the urgent need for
continuous performance monitoring, early degradation detection, and effective
self-correction mechanisms. The paper begins by reviewing common causes of
performance degradation at both data and model levels. We then summarize key
techniques for detecting data and model drift, followed by an in-depth look at
root cause analysis. Correction strategies are further reviewed, ranging from
model retraining to test-time adaptation. Our survey spans both traditional
machine learning models and state-of-the-art large language models (LLMs),
offering insights into their strengths and limitations. Finally, we discuss
ongoing technical challenges and propose future research directions. This work
aims to guide the development of reliable, robust medical AI systems capable of
sustaining safe, long-term deployment in dynamic clinical settings.

</details>


### [54] [OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections](https://arxiv.org/abs/2506.17449)
*Manasa Bharadwaj,Nikhil Verma,Kevin Ferreira*

Main category: cs.AI

TL;DR: OmniReflect通过构建任务经验总结形成的宪法，有效提升了大语言模型在复杂任务中的长期学习和适应能力，无论在单代理还是多代理协作环境下均带来显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型（LLM）在复杂任务中的表现。目前常用的微调与自我修正方法对于动态环境下的长期学习机制缺乏通用性且效率低下。

Method: 提出OmniReflect框架，该框架基于层次化反思机制，通过从任务经验中提炼宪法（指导性原则）强化LLM智能体。OmniReflect有两种模式：自我维持（智能体自我反思）和协作（由Meta-advisor总结宪法指导代理）。采用神经、符号及神经-符号混合方法形成原则。

Result: 在多个任务和模型上的实验结果表明，OmniReflect在自我维持模式下带来了显著的性能提升（如ALFWorld提高10.3%，BabyAI提高23.8%，PDDL提高8.3%），在协作模式下轻量级模型也优于所有现有Reflexion基线。

Conclusion: OmniReflect是一种稳健且高效的反思驱动学习框架，能显著提升LLM代理在不同行业环境和底座模型下的复杂任务表现。

Abstract: Efforts to improve Large Language Model (LLM) agent performance on complex
tasks have largely focused on fine-tuning and iterative self-correction.
However, these approaches often lack generalizable mechanisms for longterm
learning and remain inefficient in dynamic environments. We introduce
OmniReflect, a hierarchical, reflection-driven framework that constructs a
constitution, a compact set of guiding principles distilled from task
experiences, to enhance the effectiveness and efficiency of an LLM agent.
OmniReflect operates in two modes: Self-sustaining, where a single agent
periodically curates its own reflections during task execution, and
Co-operative, where a Meta-advisor derives a constitution from a small
calibration set to guide another agent. To construct these constitutional
principles, we employ Neural, Symbolic, and NeuroSymbolic techniques, offering
a balance between contextual adaptability and computational efficiency.
Empirical results averaged across models show major improvements in task
success, with absolute gains of +10.3% on ALFWorld, +23.8% on BabyAI, and +8.3%
on PDDL in the Self-sustaining mode. Similar gains are seen in the Co-operative
mode, where a lightweight Qwen3-4B ReAct agent outperforms all Reflexion
baselines on BabyAI. These findings highlight the robustness and effectiveness
of OmniReflect across environments and backbones.

</details>


### [55] [From Unstructured Communication to Intelligent RAG: Multi-Agent Automation for Supply Chain Knowledge Bases](https://arxiv.org/abs/2506.17484)
*Yao Zhang,Zaixi Shang,Silpan Patel,Mikel Zuniga*

Main category: cs.AI

TL;DR: 作者提出基于LLM的多智能体系统，离线处理非结构化支持工单，构建高效知识库，极大提升RAG问答效果和供应链自动化支持，结果大幅优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 供应链运作中会产生大量的操作数据，但关键知识（如系统使用方法、故障排查和解决技巧）多埋藏在非结构化的沟通内容中，如支持工单、邮件和聊天记录。现有RAG系统在直接利用这些原始、噪声大、不一致且不完整的数据时效果有限，直接检索效率不高。因此，亟需一种新方法将这些沟通内容转化为高效、可复用的知识库。

Method: 作者提出一种全新的“离线优先”方法，基于大语言模型（LLMs）构建多智能体系统，分别负责：1）类别发现（建立知识分类体系），2）类别归类（将工单分组），3）知识综合（生成知识文章）。该系统先对真实世界工单、处理记录和评论进行处理，将海量非结构化数据转化为结构化且体积紧凑的知识库。

Result: 应用于真实支持工单后，所构建知识库体积仅为原始数据的3.4%，信息质量得到提升。在RAG系统中使用预构建知识库后，实验表明其有效回答比例达48.74%，明显优于传统RAG（38.6%），且无效回答降低77.4%。系统能够自动解决约50%的后续工单，大幅提升运维效率。

Conclusion: 本文方法解决了传统RAG对运营数据直接检索效率低的问题，通过智能离线处理将临时沟通转化为结构化、可复用的知识库，极大提升了知识管理和自动化支持能力，有效提升供应链运营效率。

Abstract: Supply chain operations generate vast amounts of operational data; however,
critical knowledge such as system usage practices, troubleshooting workflows,
and resolution techniques often remains buried within unstructured
communications like support tickets, emails, and chat logs. While RAG systems
aim to leverage such communications as a knowledge base, their effectiveness is
limited by raw data challenges: support tickets are typically noisy,
inconsistent, and incomplete, making direct retrieval suboptimal. Unlike
existing RAG approaches that focus on runtime optimization, we introduce a
novel offline-first methodology that transforms these communications into a
structured knowledge base. Our key innovation is a LLMs-based multi-agent
system orchestrating three specialized agents: Category Discovery for taxonomy
creation, Categorization for ticket grouping, and Knowledge Synthesis for
article generation. Applying our methodology to real-world support tickets with
resolution notes and comments, our system creates a compact knowledge base -
reducing total volume to just 3.4% of original ticket data while improving
quality. Experiments demonstrate that our prebuilt knowledge base in RAG
systems significantly outperforms traditional RAG implementations (48.74% vs.
38.60% helpful answers) and achieves a 77.4% reduction in unhelpful responses.
By automating institutional knowledge capture that typically remains siloed in
experts' heads, our solution translates to substantial operational efficiency:
reducing support workload, accelerating resolution times, and creating
self-improving systems that automatically resolve approximately 50% of future
supply chain tickets. Our approach addresses a key gap in knowledge management
by transforming transient communications into structured, reusable knowledge
through intelligent offline processing rather than latency-inducing runtime
architectures.

</details>


### [56] [Kaleidoscopic Teaming in Multi Agent Simulations](https://arxiv.org/abs/2506.17514)
*Ninareh Mehrabi,Tharindu Kumarage,Kai-Wei Chang,Aram Galstyan,Rahul Gupta*

Main category: cs.AI

TL;DR: 本文提出“kaleidoscopic teaming”框架，旨在生成复杂、现实的场景以评估AI代理在单体和多智能体环境下的安全性，并通过新方法识别现有模型在此类场景下的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理具有高度自主性，并被广泛应用于现实世界，但其在复杂行为和多智能体互动中的安全风险评估存在不足。现有的红队测试及安全评估框架无法有效捕捉这些复杂风险，特别是在多智能体协作或对抗场景下潜在的漏洞。

Method: 提出了“kaleidoscopic teaming”概念及其评估框架，能够模拟多样化、复杂的现实社会场景，对单智能体和多智能体系统进行安全性评估。该框架利用场景生成与新颖的上下文优化技术，分别测试单体完成任务和多体竞争或协作完成任务，通过捕获这些场景中的实际安全漏洞来进行分析。同时提出了度量安全性的指标体系。

Result: 通过应用所提框架，发现了多种已有模型在智能体应用环境中存在的安全漏洞，并有效揭示了这些漏洞分布和表现方式。

Conclusion: 当前主流安全评估方法难以系统性检验agent及其互动的复杂风险。新提出的kaleidoscopic teaming框架可生成丰富场景系统评测智能体安全性，有助于全面发现agent在不同场景（单体、多体）的脆弱性。

Abstract: Warning: This paper contains content that may be inappropriate or offensive.
  AI agents have gained significant recent attention due to their autonomous
tool usage capabilities and their integration in various real-world
applications. This autonomy poses novel challenges for the safety of such
systems, both in single- and multi-agent scenarios. We argue that existing red
teaming or safety evaluation frameworks fall short in evaluating safety risks
in complex behaviors, thought processes and actions taken by agents. Moreover,
they fail to consider risks in multi-agent setups where various vulnerabilities
can be exposed when agents engage in complex behaviors and interactions with
each other. To address this shortcoming, we introduce the term kaleidoscopic
teaming which seeks to capture complex and wide range of vulnerabilities that
can happen in agents both in single-agent and multi-agent scenarios. We also
present a new kaleidoscopic teaming framework that generates a diverse array of
scenarios modeling real-world human societies. Our framework evaluates safety
of agents in both single-agent and multi-agent setups. In single-agent setup,
an agent is given a scenario that it needs to complete using the tools it has
access to. In multi-agent setup, multiple agents either compete against or
cooperate together to complete a task in the scenario through which we capture
existing safety vulnerabilities in agents. We introduce new in-context
optimization techniques that can be used in our kaleidoscopic teaming framework
to generate better scenarios for safety analysis. Lastly, we present
appropriate metrics that can be used along with our framework to measure safety
of agents. Utilizing our kaleidoscopic teaming framework, we identify
vulnerabilities in various models with respect to their safety in agentic
use-cases.

</details>


### [57] [Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models](https://arxiv.org/abs/2506.17585)
*Yukun Huang,Sanxing Chen,Jian Pei,Manzil Zaheer,Bhuwan Dhingra*

Main category: cs.AI

TL;DR: 该工作提出主动索引训练机制，显著提升了大模型的引用准确率，实现无需推理时外部检索即可可靠归因，其效果在大规模数据下持续提升。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型（LLM）有时能够将输出归因于其预训练数据，但实际引用常常不准确，存在幻觉（hallucination）问题。现有方法依赖推理时外部检索系统进行引用，带来延迟、噪声和依赖性，因此作者想探索LLM能否通过改进训练流程，无需推理时检索，就能可靠地内生引用。

Method: 提出并比较了两种训练方法：（1）被动索引（Passive Indexing）：持续预训练时为每份文档附加标识符，加强模型记忆文档内容；（2）主动索引（Active Indexing）：通过合成问答对，多样化表达事实，并进行源-事实双向生成训练，从而协同学习生成内容和自归因能力。实验还发布了新的基准测试集CitePretrainBench。

Result: 主动索引（Active Indexing）无论在短形式（单一事实）还是长形式（多事实）引用任务中，都显著优于被动索引，在模型Qwen2.5-7B和3B上引用准确率提升高达30.2%。消融实验表明，随着增强数据量扩大，性能持续提升，在原始token数的16倍时仍有明显增长。

Conclusion: 通过设计主动索引机制，无需推理时外部检索即可显著提升LLM的准确和可验证引用能力。该方式更适应现实需求，为更可靠的引用和知识归因提供新路径。

Abstract: Trustworthy language models should provide both correct and verifiable
answers. While language models can sometimes attribute their outputs to
pretraining data, their citations are often unreliable due to hallucination. As
a result, current systems insert citations by querying an external retriever at
inference time, introducing latency, infrastructure dependence, and
vulnerability to retrieval noise. We explore whether LLMs can be made to
reliably attribute to the documents seen during (continual)
pretraining--without test-time retrieval--by revising the training process. To
evaluate this, we release CitePretrainBench, a benchmark that mixes real-world
corpora (Wikipedia, Common Crawl, arXiv) with novel, unseen documents and
probes both short-form (single fact) and long-form (multi-fact) citation tasks.
Our approach follows a two-stage process: (1) continual pretraining to bind
facts to persistent document identifiers, and (2) instruction tuning to elicit
citation behavior. We find that simple Passive Indexing, which appends an
identifier to each document, helps memorize verbatim text but fails on
paraphrased or compositional facts. Instead, we propose Active Indexing, which
continually pretrains on synthetic QA pairs that (1) restate each fact in
diverse compositional forms, and (2) require bidirectional source-to-fact and
fact-to-source generation, jointly teaching the model to generate content from
a cited source and to attribute its own answers. Experiments with Qwen2.5-7B
and 3B show that Active Indexing consistently outperforms Passive Indexing
across all tasks and models, with citation precision gains up to 30.2 percent.
Our ablation studies reveal that performance continues to improve as we scale
the amount of augmented data, showing a clear upward trend even at 16 times the
original token count.

</details>


### [58] [Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to Conquer the Unknown](https://arxiv.org/abs/2506.17589)
*Bowen Wang*

Main category: cs.AI

TL;DR: 本文提出面向视觉游戏领域的多模态知识图谱与多智能体检索机制，有效提升了多模态大模型在复杂领域内的知识检索与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型（MLLMs）在处理少见的特定领域任务时，由于相关知识有限，表现欠佳。作者希望探索如何增强MLLMs在特定领域复杂知识检索和推理能力。

Method: 作者以视觉游戏认知作为研究测试场，选择《怪物猎人：世界》作为对象，构建多模态知识图谱（MH-MMKG），整合多模态数据和复杂实体关系。基于MH-MMKG设计高难度查询评测模型知识检索与推理能力，并提出了无需额外训练的多智能体检索器，主动态检索相关知识。

Result: 实验表明，作者的方法能够显著提升多模态大模型的表现，为多模态知识增强推理提供了新视角和坚实基础。

Conclusion: 通过构建复杂的多模态知识图谱与多智能体检索机制，有效提升了多模态大模型在特定领域知识推理和检索能力，对后续研究具有重要推动作用。

Abstract: The real value of knowledge lies not just in its accumulation, but in its
potential to be harnessed effectively to conquer the unknown. Although recent
multimodal large language models (MLLMs) exhibit impressing multimodal
capabilities, they often fail in rarely encountered domain-specific tasks due
to limited relevant knowledge. To explore this, we adopt visual game cognition
as a testbed and select Monster Hunter: World as the target to construct a
multimodal knowledge graph (MH-MMKG), which incorporates multi-modalities and
intricate entity relations. We also design a series of challenging queries
based on MH-MMKG to evaluate the models' ability for complex knowledge
retrieval and reasoning. Furthermore, we propose a multi-agent retriever that
enables a model to autonomously search relevant knowledge without additional
training. Experimental results show that our approach significantly enhances
the performance of MLLMs, providing a new perspective on multimodal
knowledge-augmented reasoning and laying a solid foundation for future
research.

</details>


### [59] [Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges](https://arxiv.org/abs/2506.17644)
*Zimo Ji,Daoyuan Wu,Wenyuan Jiang,Pingchuan Ma,Zongjie Li,Shuai Wang*

Main category: cs.AI

TL;DR: 论文构建了CTFKnow基准衡量LLM在CTF领域的知识掌握与应用，发现现有模型在实际解题时存在短板。提出新框架CTFAgent，通过增强技术知识和环境适应性，在多个标准数据集和真实竞赛中取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）能力提升，越来越多研究者关注其在网络安全攻防竞赛（如CTF）中的自动解题能力，但目前LLM在解决CTF问题时需要多种复合能力，尤其是技术知识层面表现尚未被充分评估和改进。

Method: 作者构建了CTFKnow基准集（3992道问题），专注评估LLM在CTF技术知识方面的掌握和应用能力。在此基础上，提出了新框架CTFAgent，包括双阶段检索增强生成（RAG）模块和交互式环境增强模块，分别提升技术知识获取和CTF漏洞利用能力，并在多个CTF数据集及赛事中进行测试。

Result: 实验证明LLM当前虽具备一定技术知识，但在实际应用和场景自适应方面表现不足。所提出的CTFAgent框架，在两个流行CTF数据集上带来超过80%的性能提升，并在picoCTF2024比赛中进入前23.6%。

Conclusion: 本工作提出并验证了一套细粒度CTF知识测评体系及针对性框架，有效发现并提升了大语言模型在CTF自动解题中的实际能力，为未来AI自动攻防提供了新方向和有力支撑。

Abstract: Capture-the-Flag (CTF) competitions are crucial for cybersecurity education
and training. As large language models (LLMs) evolve, there is increasing
interest in their ability to automate CTF challenge solving. For example, DARPA
has organized the AIxCC competition since 2023 to advance AI-powered automated
offense and defense. However, this demands a combination of multiple abilities,
from knowledge to reasoning and further to actions. In this paper, we highlight
the importance of technical knowledge in solving CTF problems and deliberately
construct a focused benchmark, CTFKnow, with 3,992 questions to measure LLMs'
performance in this core aspect. Our study offers a focused and innovative
measurement of LLMs' capability in understanding CTF knowledge and applying it
to solve CTF challenges. Our key findings reveal that while LLMs possess
substantial technical knowledge, they falter in accurately applying this
knowledge to specific scenarios and adapting their strategies based on feedback
from the CTF environment.
  Based on insights derived from this measurement study, we propose CTFAgent, a
novel LLM-driven framework for advancing CTF problem-solving. CTFAgent
introduces two new modules: two-stage Retrieval Augmented Generation (RAG) and
interactive Environmental Augmentation, which enhance LLMs' technical knowledge
and vulnerability exploitation on CTF, respectively. Our experimental results
show that, on two popular CTF datasets, CTFAgent both achieves over 80%
performance improvement. Moreover, in the recent picoCTF2024 hosted by CMU,
CTFAgent ranked in the top 23.6% of nearly 7,000 participating teams. This
reflects the benefit of our measurement study and the potential of our
framework in advancing LLMs' capabilities in CTF problem-solving.

</details>


### [60] [PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models](https://arxiv.org/abs/2506.17667)
*Lintao Wang,Encheng Su,Jiaqi Liu,Pengze Li,Peng Xia,Jiabei Xiao,Wenlong Zhang,Xinnan Dai,Xi Chen,Yuan Meng,Mingyu Ding,Lei Bai,Wanli Ouyang,Shixiang Tang,Aoran Wang,Xinzhu Ma*

Main category: cs.AI

TL;DR: 提出了PhysUniBench大型多模态大学物理基准，系统评测现有AI模型物理推理与多模态能力。结果显示当前模型，尤其是GPT-4o mini，面对多步骤和需解读图示的物理题时表现较差，仅达34%准确率。该基准有助于推动AI科学问题求解能力的进步。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在物理问题求解上面临很大挑战，特别是在概念理解、数学推理和物理图示解读的综合能力方面。当前的评价方法无法全面反映大学物理问题的复杂性和广度，需要更严格的评估工具。

Method: 提出了PhysUniBench，一个针对多模态大语言模型、专用于大学物理领域问题求解能力评估的大型多模态基准测试集。数据集涵盖8个主流物理子领域，共3304道题，每题均配有一张视觉图示，题型包括开放性和选择题，采用专家评审、模型循环过滤、自动筛查简单问题、难度分级等多阶段方式构建。

Result: 当前最先进的大模型在该基准测试上的表现并不理想，如GPT-4o mini在PhysUniBench上的准确率仅为34.2%。尤其是在多步推理及精准图示理解等题目上表现突出不足。

Conclusion: PhysUniBench展现了现有多模态大模型在高级物理推理和多模态理解上的不足，是推动AI科学和物理推理能力提升的重要工具。该基准和评测脚本已开放，旨在促进具更强物理推理和多模态理解能力模型的发展。

Abstract: Physics problem-solving is a challenging domain for large AI models,
requiring integration of conceptual understanding, mathematical reasoning, and
interpretation of physical diagrams. Current evaluation methodologies show
notable limitations in capturing the breadth and complexity of
undergraduate-level physics, underscoring the need for more rigorous
assessments. To this end, we present PhysUniBench, a large-scale multimodal
benchmark designed to evaluate and improve the reasoning capabilities of
multimodal large language models (MLLMs) specifically on undergraduate-level
physics problems. PhysUniBench consists of 3,304 physics questions spanning 8
major sub-disciplines of physics, each accompanied by one visual diagrams. The
benchmark includes both open-ended and multiple-choice questions,
systematically curated and difficulty-rated through an iterative
model-in-the-loop process. The benchmark's construction involved a rigorous
multi-stage process, including multiple roll-outs, expert-level evaluation,
automated filtering of easily solved problems, and a nuanced difficulty grading
system with five levels. Through extensive experiments, we observe that current
state-of-the-art models encounter substantial challenges in physics reasoning.
For example, GPT-4o mini achieves only about 34.2\% accuracy in the proposed
PhysUniBench. These results highlight that current MLLMs struggle with advanced
physics reasoning, especially on multi-step problems and those requiring
precise diagram interpretation. By providing a broad and rigorous assessment
tool, PhysUniBench aims to drive progress in AI for Science, encouraging the
development of models with stronger physical reasoning, problem-solving skills,
and multimodal understanding. The benchmark and evaluation scripts are
available at https://prismax-team.github.io/PhysUniBenchmark/.

</details>


### [61] [Beyond Syntax: Action Semantics Learning for App Agents](https://arxiv.org/abs/2506.17697)
*Bohan Tang,Dezhao Luo,Jingxuan Chen,Shaogang Gong,Jianye Hao,Jun Wang,Kun Shao*

Main category: cs.AI

TL;DR: 文章提出了动作语义学习（ASL）框架，通过语义奖励训练方法，增强了App智能体泛化性和鲁棒性，显著优于基于语法学习的现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前智能体操作手机App多依赖于封闭式大模型API，计算开销大且依赖外部接口。开源小模型微调又容易出现模型对语法过度拟合，导致泛化性差（尤其在分布外的数据上易失效）。因此，需要一种更健壮且泛化能力强的学习方法。

Method: 提出了一种新的动作语义学习（ASL）框架，用于训练App智能体。其核心方法是基于程序语言理论，将动作语义定义为在UI中诱发的状态转移，使用一个新的语义评估器（SEE）为智能体生成的动作分配语义奖励，从而推动模型学习对语义对齐而非语法一致的动作。

Result: 理论证明ASL在分布外（OOD）鲁棒性上优于传统语法学习方法；大量基于手机App操作的实验（包括离线和在线基准测试）显示，ASL在准确性和泛化能力上显著优于现有方法。

Conclusion: ASL通过强化语义对齐而不是纯粹的语法复制，提升了App智能体在泛化性和鲁棒性方面的表现，是操作App的新一代训练范式。

Abstract: The advent of Large Language Models (LLMs) enables the rise of App agents
that interpret user intent and operate smartphone Apps through actions such as
clicking and scrolling. While prompt-based solutions with closed LLM APIs show
promising ability, they incur heavy compute costs and external API dependency.
Fine-tuning smaller open-source LLMs solves these limitations. However, current
fine-tuning methods use a syntax learning paradigm that forces agents to
reproduce exactly the ground truth action strings, leading to
out-of-distribution (OOD) vulnerability. To fill this gap, we propose Action
Semantics Learning (ASL), a novel learning framework, where the learning
objective is capturing the semantics of the ground truth actions. Specifically,
inspired by the programming language theory, we define the action semantics for
App agents as the state transition induced by the action in the user interface.
With this insight, ASL employs a novel SEmantic Estimator (SEE) to compute a
semantic reward to train the App agents in generating actions aligned with the
semantics of ground truth actions, even when the syntactic forms differ. To
support the effectiveness of ASL, we theoretically demonstrate the superior
robustness of ASL for the OOD problem compared with the existing syntax
learning paradigm. Extensive experiments on offline and online smartphone App
operation benchmarks show that ASL significantly improves the accuracy and
generalisation of App agents over existing methods.

</details>


### [62] [AnyMAC: Cascading Flexible Multi-Agent Collaboration via Next-Agent Prediction](https://arxiv.org/abs/2506.17784)
*Song Wang,Zhen Tan,Zihan Chen,Shuang Zhou,Tianlong Chen,Jundong Li*

Main category: cs.AI

TL;DR: 论文提出了一种基于顺序结构的多智能体协作新框架，通过动态选择代理和上下文，实现适应性强、信息流通全局、通信开销低的高效多智能体合作。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体协作方法普遍依赖静态或基于图的智能体拓扑，缺乏通信的适应性和灵活性。为解决这一问题，提出用顺序结构替代图结构，拓展多智能体通信的拓扑空间。

Method: 采用两大关键机制：（1）下一代理体预测，即在每一步选择最合适的代理角色；（2）下一步上下文选择，使每个代理可以从任何先前步骤中有选择地获取相关信息，构建任务自适应的通信管道。

Result: 方法在多个多智能体合作基准上优于传统方法，且大幅减少了通信数据量。

Conclusion: 提出的顺序结构多智能体协作框架，在多项基准测试中展现出更优异的性能，并且显著降低了通信开销。

Abstract: Recent progress in large language model (LLM)-based multi-agent collaboration
highlights the power of structured communication in enabling collective
intelligence. However, existing methods largely rely on static or graph-based
inter-agent topologies, lacking the potential adaptability and flexibility in
communication. In this work, we propose a new framework that rethinks
multi-agent coordination through a sequential structure rather than a graph
structure, offering a significantly larger topology space for multi-agent
communication. Our method focuses on two key directions: (1) Next-Agent
Prediction, which selects the most suitable agent role at each step, and (2)
Next-Context Selection (NCS), which enables each agent to selectively access
relevant information from any previous step. Together, these components
construct task-adaptive communication pipelines that support both role
flexibility and global information flow. Extensive evaluations across multiple
benchmarks demonstrate that our approach achieves superior performance while
substantially reducing communication overhead.

</details>


### [63] [Bayesian Social Deduction with Graph-Informed Language Models](https://arxiv.org/abs/2506.17788)
*Shahab Rahimirad,Guven Gergerli,Lucia Romero,Angela Qian,Matthew Lyle Olson,Simon Stepputtis,Joseph Campbell*

Main category: cs.AI

TL;DR: 本文提出了一种结合LLM与概率模型的混合社会推理方法，在游戏Avalon中取得重大突破，首次实现AI语言智能体对人类玩家的显著胜利，并大幅提升了效率与推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLMs）在社会推理——即根据对他人行为的部分观察推断其不可见的信念和意图——方面依然存在显著挑战，尤其在快速、实时推理场景下更为明显。现有方法在能力和效率之间存在权衡，需要新的方法提升社会推理的表现，同时兼顾运行效率。

Method: 本文提出了一种混合推理框架，将信念推断外包给结构化的概率模型，同时使用LLM进行自然语言理解和交互。通过这种分工协作，兼顾推理能力与实时效率。

Result: 该方法在Agent-Agent对战中取得了与远大于自身规模的模型相当的表现，并且在控制实验中首次实现了语言智能体在社会推理游戏中击败人类玩家（胜率达67%），在定性评价上也超过了现有推理基线和人类队友。

Conclusion: 混合推理框架有效提升了小型、实时可用的LLM在社会推理任务中的能力，是实现具备强大社会认知的AI语言代理的重要进展。

Abstract: Social reasoning - inferring unobservable beliefs and intentions from partial
observations of other agents - remains a challenging task for large language
models (LLMs). We evaluate the limits of current reasoning language models in
the social deduction game Avalon and find that while the largest models
demonstrate strong performance, they require extensive test-time inference and
degrade sharply when distilled to smaller, real-time-capable variants. To
address this, we introduce a hybrid reasoning framework that externalizes
belief inference to a structured probabilistic model, while using an LLM for
language understanding and interaction. Our approach achieves competitive
performance with much larger models in Agent-Agent play and, notably, is the
first language agent to defeat human players in a controlled study - achieving
a 67% win rate and receiving higher qualitative ratings than both reasoning
baselines and human teammates. We release code, models, and a dataset to
support future work on social reasoning in LLM agents, which can be found at
https://camp-lab-purdue.github.io/bayesian-social-deduction/

</details>


### [64] [Efficient Strategy Synthesis for MDPs via Hierarchical Block Decomposition](https://arxiv.org/abs/2506.17792)
*Alexandros Evangelidis,Gricel Vázquez,Simos Gerasimou*

Main category: cs.AI

TL;DR: 论文提出一种针对大规模马尔可夫决策过程（MDP）的快速政策综合方法，通过动态细化和聚焦关键区域，显著提升了处理速度，比主流工具PRISM快2倍，适用于实际复杂系统的决策分析。


<details>
  <summary>Details</summary>
Motivation: 传统的政策综合方法在处理大规模状态空间的马尔可夫决策过程（MDP）时，不易扩展，效率低下。软件密集型系统（如软件产品线和机器人）需要应对不确定性和序贯决策问题，因此高效的MDP处理方法具有重要意义。

Method: 该方法通过动态细化MDP，并迭代选择最脆弱的MDP区域进行精细化，每次仅在必要时才进行细化化，旨在权衡准确性与效率，从而加速大规模MDP的政策综合。

Result: 在包含多种案例和多达100万个状态的MDP上进行了全面实证评估。结果显示，该方法比领先的概率模型检测器PRISM快至2倍，显示出在更大规模MDP实际任务中的强大竞争力。

Conclusion: 该方法有效提升了大规模MDP政策综合任务的效率，在准确率与速度之间取得了较好平衡，为实际中需要应对更大状态空间的MDP问题提供了有力解决方案。

Abstract: Software-intensive systems, such as software product lines and robotics,
utilise Markov decision processes (MDPs) to capture uncertainty and analyse
sequential decision-making problems. Despite the usefulness of conventional
policy synthesis methods, they fail to scale to large state spaces. Our
approach addresses this issue and accelerates policy synthesis in large MDPs by
dynamically refining the MDP and iteratively selecting the most fragile MDP
regions for refinement. This iterative procedure offers a balance between
accuracy and efficiency, as refinement occurs only when necessary. Through a
comprehensive empirical evaluation comprising diverse case studies and MDPs up
to 1M states, we demonstrate significant performance improvements yielded by
our approach compared to the leading probabilistic model checker PRISM (up to
2x), thus offering a very competitive solution for real-world policy synthesis
tasks in larger MDPs.

</details>


### [65] [Airalogy: AI-empowered universal data digitization for research automation](https://arxiv.org/abs/2506.18586)
*Zijie Yang,Qiji Zhou,Fang Guo,Sijie Zhang,Yexun Xi,Jinglei Nie,Yudian Zhu,Liping Huang,Chou Wu,Yonghe Xia,Xiaoyu Ma,Yingming Pu,Panzhong Lu,Junshu Pan,Mingtao Chen,Tiannan Guo,Yanmei Dou,Hongyu Chen,Anping Zeng,Jiaxing Huang,Tian Xu,Yue Zhang*

Main category: cs.AI

TL;DR: 论文提出并实现了Airalogy平台，通过AI和社区协同，首次兼顾数据标准化与多学科通用性，有效推动了科研数据数字化，并已在多学科实验室应用，展现加速科研创新的能力。


<details>
  <summary>Details</summary>
Motivation: 现阶段AI科研受限于数据孤岛、标准不统一、管理低效、跨学科难兼容等问题。缺乏一个能兼容多学科、多样化需求并实现高标准化的数据平台，制约了AI对科研的全面推动。

Method: 通过研发并上线Airalogy平台，结合可自定义与标准化的数据记录、AI研究助手、智能问答、自动数据录入与分析等功能，解决了多学科数据标准化与通用性之间的矛盾。

Result: Airalogy平台成功在多个学科实验室落地，支持标准化和通用性的数据录入、管理和AI驱动的研究工作，展现出对推动科研创新与自动化的巨大潜力。

Conclusion: 本文提出的Airalogy平台首次实现了在多学科研究领域间兼顾通用性与标准化的数据数字化，推动了AI赋能科研的可行性。平台已在多个实验室部署，并展示了加速自动化科学创新的潜力。

Abstract: Research data are the foundation of Artificial Intelligence (AI)-driven
science, yet current AI applications remain limited to a few fields with
readily available, well-structured, digitized datasets. Achieving comprehensive
AI empowerment across multiple disciplines is still out of reach. Present-day
research data collection is often fragmented, lacking unified standards,
inefficiently managed, and difficult to share. Creating a single platform for
standardized data digitization needs to overcome the inherent challenge of
balancing between universality (supporting the diverse, ever-evolving needs of
various disciplines) and standardization (enforcing consistent formats to fully
enable AI). No existing platform accommodates both facets. Building a truly
multidisciplinary platform requires integrating scientific domain knowledge
with sophisticated computing skills. Researchers often lack the computational
expertise to design customized and standardized data recording methods, whereas
platform developers rarely grasp the intricate needs of multiple scientific
domains. These gaps impede research data standardization and hamper AI-driven
progress. In this study, we address these challenges by developing Airalogy
(https://airalogy.com), the world's first AI- and community-driven platform
that balances universality and standardization for digitizing research data
across multiple disciplines. Airalogy represents entire research workflows
using customizable, standardized data records and offers an advanced AI
research copilot for intelligent Q&A, automated data entry, analysis, and
research automation. Already deployed in laboratories across all four schools
of Westlake University, Airalogy has the potential to accelerate and automate
scientific innovation in universities, industry, and the global research
community-ultimately benefiting humanity as a whole.

</details>


### [66] [Reflective Verbal Reward Design for Pluralistic Alignment](https://arxiv.org/abs/2506.17834)
*Carter Blair,Kate Larson,Edith Law*

Main category: cs.AI

TL;DR: 本文提出了一种基于用户反思对话的个性化奖励模型方法，能够更好地反映不同个体的价值观，实验显示准确率和数据效率均优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 当前主流RLHF通过聚合人类反馈生成单一奖励模型，但忽视了人类价值的多样与差异，可能导致少数群体偏好被忽略。这需要有方法实现奖励模型的个性化，对不同用户的价值观做出区分。

Method: 利用大语言模型引导用户进行反思性对话，收集其对AI行为的评价与偏好，形成对话历史。之后将该历史作为上下文，训练另一个语言模型作为个性化奖励函数（称为“verbal reward model”），用于评价新的AI行为轨迹。

Result: 与传统监督学习方法相比，该个性化反思对话法模型对用户行为理解准确率提升9-12%，且样本效率更高。

Conclusion: 提出了一种个性化的奖励建模方法，并通过用户反思性对话历史生成个人化奖励函数，在实验中表现优于传统方法。

Abstract: AI agents are commonly aligned with "human values" through reinforcement
learning from human feedback (RLHF), where a single reward model is learned
from aggregated human feedback and used to align an agent's behavior. However,
human values are not homogeneous--different people hold distinct and sometimes
conflicting values. Aggregating feedback into a single reward model risks
disproportionately suppressing minority preferences. To address this, we
present a novel reward modeling approach for learning individualized reward
models. Our approach uses a language model to guide users through reflective
dialogues where they critique agent behavior and construct their preferences.
This personalized dialogue history, containing the user's reflections and
critiqued examples, is then used as context for another language model that
serves as an individualized reward function (what we call a "verbal reward
model") for evaluating new trajectories. In studies with 30 participants, our
method achieved a 9-12% improvement in accuracy over non-reflective verbal
reward models while being more sample efficient than traditional supervised
learning methods.

</details>


### [67] [Out of Control -- Why Alignment Needs Formal Control Theory (and an Alignment Control Stack)](https://arxiv.org/abs/2506.17846)
*Elija Perrier*

Main category: cs.AI

TL;DR: 本文主张以形式化最优控制理论为核心推进AI对齐研究，并提出“对齐控制栈”模型，强调各对齐层次间的互操作与治理需求，有助于提升AI的安全与实践部署保障。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全和可解释性方法虽然在形式化方法上取得了一定进展，但没有达到控制论应用于其他技术时所需的广泛泛化能力，且不同对齐/控制协议间的互操作性研究匮乏。作者认为需通过更系统的控制框架推进AI对齐研究。

Method: 作者提出了用形式最优控制理论作为AI对齐研究的核心方法，并提出了“对齐控制栈”模型，将AI对齐分为从物理层到社会技术层的分层，每层具有独特的测量和控制特性，并探讨层间的形式互操作性。

Result: 提出“对齐控制栈”这一分层框架，明确各层的控制对象、测量方式与相互作用，并展示如何利用最优控制理论为AI对齐问题提供更强的理论基础和工程保障。

Conclusion: 将AI对齐问题系统地纳入正式最优控制理论，并通过“对齐控制栈”模型，能够更好地理解和控制前沿模型/代理性AI系统的能力与局限，有助于为监管与安全提供理论和实践依据，提升AI系统的安全性与可靠性。

Abstract: This position paper argues that formal optimal control theory should be
central to AI alignment research, offering a distinct perspective from
prevailing AI safety and security approaches. While recent work in AI safety
and mechanistic interpretability has advanced formal methods for alignment,
they often fall short of the generalisation required of control frameworks for
other technologies. There is also a lack of research into how to render
different alignment/control protocols interoperable. We argue that by recasting
alignment through principles of formal optimal control and framing alignment in
terms of hierarchical stack from physical to socio-technical layers according
to which controls may be applied we can develop a better understanding of the
potential and limitations for controlling frontier models and agentic AI
systems. To this end, we introduce an Alignment Control Stack which sets out a
hierarchical layered alignment stack, identifying measurement and control
characteristics at each layer and how different layers are formally
interoperable. We argue that such analysis is also key to the assurances that
will be needed by governments and regulators in order to see AI technologies
sustainably benefit the community. Our position is that doing so will bridge
the well-established and empirically validated methods of optimal control with
practical deployment considerations to create a more comprehensive alignment
framework, enhancing how we approach safety and reliability for advanced AI
systems.

</details>


### [68] [Towards Robust Fact-Checking: A Multi-Agent System with Advanced Evidence Retrieval](https://arxiv.org/abs/2506.17878)
*Tam Trinh,Manh Nguyen,Truong-Son Hy*

Main category: cs.AI

TL;DR: 本文提出一种多智能体自动化事实核查系统，能高效处理复杂声明、检索可靠证据并提供可解释性判决，Macro F1提升12.3%，突破了传统自动方法的诸多局限。


<details>
  <summary>Details</summary>
Motivation: 数字时代虚假信息的快速传播对公共话语带来严峻挑战。传统人工事实核查虽具权威性，但难以应对海量高速的线上内容。因此，亟需更高效、可扩展的自动化事实核查解决方案。

Method: 提出了一种基于多智能体系统的自动化事实核查方法。系统包括四个特化智能体：输入分解（分解复杂信息）、查询生成（生成针对性子查询）、证据检索（从可信来源获取证据）和结论预测（给出可解释性判决）。

Result: 在FEVEROUS、HOVER和SciFact基准数据集上，该系统Macro F1-score较基线方法提升了12.3%。系统能够准确分解复杂声明，检索到可靠证据，并生成透明的判决解释。

Conclusion: 本方法增强了自动化事实核查的准确性、效率和可解释性，既符合集体事实核查实践，又具备现实应用的可扩展性。开源代码已上线，推动了自动化事实核查领域的发展。

Abstract: The rapid spread of misinformation in the digital era poses significant
challenges to public discourse, necessitating robust and scalable fact-checking
solutions. Traditional human-led fact-checking methods, while credible,
struggle with the volume and velocity of online content, prompting the
integration of automated systems powered by Large Language Models (LLMs).
However, existing automated approaches often face limitations, such as handling
complex claims, ensuring source credibility, and maintaining transparency. This
paper proposes a novel multi-agent system for automated fact-checking that
enhances accuracy, efficiency, and explainability. The system comprises four
specialized agents: an Input Ingestion Agent for claim decomposition, a Query
Generation Agent for formulating targeted subqueries, an Evidence Retrieval
Agent for sourcing credible evidence, and a Verdict Prediction Agent for
synthesizing veracity judgments with human-interpretable explanations.
Evaluated on benchmark datasets (FEVEROUS, HOVER, SciFact), the proposed system
achieves a 12.3% improvement in Macro F1-score over baseline methods. The
system effectively decomposes complex claims, retrieves reliable evidence from
trusted sources, and generates transparent explanations for verification
decisions. Our approach contributes to the growing field of automated
fact-checking by providing a more accurate, efficient, and transparent
verification methodology that aligns with human fact-checking practices while
maintaining scalability for real-world applications. Our source code is
available at https://github.com/HySonLab/FactAgent

</details>


### [69] [Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms](https://arxiv.org/abs/2506.17900)
*Cheng Ji,Huaiying Luo*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型的智能日志处理与自动调试系统（LLM-ID），通过多阶段语义推理和自适应自愈机制，大幅提升了云平台日志的故障定位和修复效率，准确率比传统方法高16.2%。


<details>
  <summary>Details</summary>
Motivation: AI系统在云平台上的复杂性和规模不断增加，生成的日志数据海量、无结构且语义模糊，导致故障定位和自愈变得极具挑战性。

Method: 基于大型语言模型（LLM）的Transformer架构，结合多阶段语义推理机制；系统包括日志动态结构化、无监督聚类与嵌入、利用微调LLM的多轮注意力机制做上下文推理，并引入基于强化学习的策略指导自愈规划。

Result: LLM-ID在云平台日志数据集实验中，故障定位准确率提升16.2%，在性能上显著超越当前主流规则引擎和传统日志分析系统。

Conclusion: 提出的LLM-ID框架在语义理解、持续学习能力和异构环境适应性方面明显优于传统方法，在云平台日志数据集上故障定位准确率提升16.2%。

Abstract: With the increasing complexity and rapid expansion of the scale of AI systems
in cloud platforms, the log data generated during system operation is massive,
unstructured, and semantically ambiguous, which brings great challenges to
fault location and system self-repair. In order to solve this problem, this
paper proposes an intelligent log processing and automatic debugging framework
based on Large Language Model (LLM), named Intelligent Debugger (LLM-ID). This
method is extended on the basis of the existing pre-trained Transformer model,
and integrates a multi-stage semantic inference mechanism to realize the
context understanding of system logs and the automatic reconstruction of fault
chains. Firstly, the system log is dynamically structured, and the unsupervised
clustering and embedding mechanism is used to extract the event template and
semantic schema. Subsequently, the fine-tuned LLM combined with the multi-round
attention mechanism to perform contextual reasoning on the log sequence to
generate potential fault assumptions and root cause paths. Furthermore, this
paper introduces a reinforcement learning-based policy-guided recovery planner,
which is driven by the remediation strategy generated by LLM to support dynamic
decision-making and adaptive debugging in the cloud environment. Compared with
the existing rule engine or traditional log analysis system, the proposed model
has stronger semantic understanding ability, continuous learning ability and
heterogeneous environment adaptability. Experiments on the cloud platform log
dataset show that LLM-ID improves the fault location accuracy by 16.2%, which
is significantly better than the current mainstream methods

</details>


### [70] [Learning, Reasoning, Refinement: A Framework for Kahneman's Dual-System Intelligence in GUI Agents](https://arxiv.org/abs/2506.17913)
*Jinjie Wei,Jiyao Liu,Lihao Liu,Ming Hu,Junzhi Ning,Mingcheng Li,Weijie Yin,Junjun He,Xiao Liang,Chao Feng,Dingkang Yang*

Main category: cs.AI

TL;DR: CogniGUI通过认知式双系统学习机制和创新基准测试，有效提升了GUI操作代理的智能化和通用性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的GUI自动化智能体大多依赖试错决策，缺乏逐步推理与自适应学习能力，并且评估方式过于简单，不能真实反映复杂的现实交互需求。

Method: 提出CogniGUI认知框架，借鉴Kahneman的双系统理论：包括快速分层解析GUI元素的omni parser和基于相对奖励优化多路径交互的GRPO代理，实现探索-学习-精通的迭代优化。并引入ScreenSeek基准，包含多应用导航、动态状态转换和跨界面一致性。

Result: CogniGUI在现有GUI基准和新提出的ScreenSeek基准上均优于当前最先进方法，证实了框架的有效性和通用性。

Conclusion: CogniGUI框架能模拟人类逐步学习和适应行为，显著提升了GUI智能体在复杂环境下的操作能力与评估标准。

Abstract: Graphical User Interface (GUI) agents have made significant progress in
automating digital tasks through the utilization of computer vision and
language models. Nevertheless, existing agent systems encounter notable
limitations. Firstly, they predominantly depend on trial and error decision
making rather than progressive reasoning, thereby lacking the capability to
learn and adapt from interactive encounters. Secondly, these systems are
assessed using overly simplistic single step accuracy metrics, which do not
adequately reflect the intricate nature of real world GUI interactions. In this
paper, we present CogniGUI, a cognitive framework developed to overcome these
limitations by enabling adaptive learning for GUI automation resembling
human-like behavior. Inspired by Kahneman's Dual Process Theory, our approach
combines two main components: (1) an omni parser engine that conducts immediate
hierarchical parsing of GUI elements through quick visual semantic analysis to
identify actionable components, and (2) a Group based Relative Policy
Optimization (GRPO) grounding agent that assesses multiple interaction paths
using a unique relative reward system, promoting minimal and efficient
operational routes. This dual-system design facilitates iterative ''exploration
learning mastery'' cycles, enabling the agent to enhance its strategies over
time based on accumulated experience. Moreover, to assess the generalization
and adaptability of agent systems, we introduce ScreenSeek, a comprehensive
benchmark that includes multi application navigation, dynamic state
transitions, and cross interface coherence, which are often overlooked
challenges in current benchmarks. Experimental results demonstrate that
CogniGUI surpasses state-of-the-art methods in both the current GUI grounding
benchmarks and our newly proposed benchmark.

</details>


### [71] [Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective](https://arxiv.org/abs/2506.17930)
*Jianyu Wang,Zhiqiang Hu,Lidong Bing*

Main category: cs.AI

TL;DR: 本文提出了PromptQuine进化式自动提示词优化框架，发现将部分原本看似无意义的提示词片段保留，能够在多种任务和模型上显著提升大语言模型性能，超越了传统提示设计与优化方法。研究强调了算法驱动、非人工直觉优化在LLM提示词设计中的重要价值。


<details>
  <summary>Details</summary>
Motivation: 近年来，针对大语言模型（LLM）的提示词（prompt）设计普遍依赖精心构造的指令和范例以提升模型推理表现，但该方法存在设计成本高、标准化难等问题。因此，作者旨在探索更高效、自动化的提示词优化策略，突破传统范式的局限。

Method: 作者提出了一种新的进化式搜索框架PromptQuine，通过进化算法自动搜索并修剪提示词，将原始的、有逻辑的提示词“修剪”成部分看似无意义的“gibberish”（无序片段），在低数据量下自动发现有效的修剪策略。该方法不同于传统的归因分析和提示压缩算法，不依赖人工直觉，完全由算法自我驯化与演化。

Result: 结果表明，“gibberish”提示在各类任务（包括分类、多选问答、生成、数学推理）以及不同类型的LLM上，均表现优异，甚至比当前最优自动提示优化技术效果更好。同时，该方法在运行效率方面表现良好，具有实际应用潜力。

Conclusion: 作者发现，打破传统人类设计直觉，通过自动化演化方式寻找非常规提示，能极大提升LLM的推理表现。该研究不仅对LLM的机理层研究具有指导意义，也为提示词自动搜索与优化提供了新的方向。

Abstract: We propose a novel prompt design paradigm that challenges conventional wisdom
in large language model (LLM) prompting. While conventional wisdom prioritizes
well-crafted instructions and demonstrations for in-context learning (ICL), we
show that pruning random demonstrations into seemingly incoherent "gibberish"
can remarkably improve performance across diverse tasks. Notably, the
"gibberish" always matches or surpasses state-of-the-art automatic prompt
optimization techniques, achieving substantial gains regardless of LLM
alignment. Nevertheless, discovering an effective pruning strategy is
non-trivial, as existing attribution methods and prompt compression algorithms
fail to deliver robust results, let alone human intuition. In terms of this, we
propose a self-discover prompt optimization framework, PromptQuine, an
evolutionary search framework that automatically searches for the pruning
strategy by itself using only low-data regimes. Much like the emergent
complexity in nature--such as symbiosis and self-organization--arising in
response to resource constraints, our framework evolves and refines
unconventional yet highly effective prompts by leveraging only the tokens
present within the context. We demonstrate its effectiveness across
classification, multi-choice question answering, generation and math reasoning
tasks across LLMs, while achieving decent runtime efficiency. We hope our
findings can guide mechanistic studies on in-context learning, and provide a
call to action, to pave the way for more open-ended search algorithms for more
effective LLM prompting.

</details>


### [72] [medicX-KG: A Knowledge Graph for Pharmacists' Drug Information Needs](https://arxiv.org/abs/2506.17959)
*Lizzy Farrugia,Lilian M. Azzopardi,Jeremy Debattista,Charlie Abela*

Main category: cs.AI

TL;DR: 本文提出并实现了medicX-KG知识图谱，将分散的药品信息有效整合，为药剂师在临床和监管决策中提供智能化、可解释的数据支持，并经评估显示其实用性。


<details>
  <summary>Details</summary>
Motivation: 药剂师的角色正在从传统的配药工作转变为全方位的药学服务。实现这一转变急需基于强大数据整合的准确、最新药品信息。目前药品信息来源分散，缺乏统一的平台影响了药剂师的决策效率和准确性。

Method: 提出并构建了面向药剂师的知识图谱medicX-KG，整合了英国国家处方集（BNF）、DrugBank及马耳他药品管理局（MMA）数据，覆盖临床及监管决策场景。该知识图谱通过数据提取、本体设计和语义映射实现，且设计过程中参考了一线药剂师的需求。

Result: medicX-KG可有效支持药品可用性、相互作用、不良反应及治疗类相关查询，替代了对多个零散信息源的依赖。评估显示其在实际查询中有良好表现，但存在剂量编码不够细致和无法实时更新等局限。

Conclusion: 该工作实现了药剂师面向药事全流程决策支持的知识语义层，提升了业务应用的准确性和效率，为未来药学数据平台扩展及功能增强提供了基础。

Abstract: The role of pharmacists is evolving from medicine dispensing to delivering
comprehensive pharmaceutical services within multidisciplinary healthcare
teams. Central to this shift is access to accurate, up-to-date medicinal
product information supported by robust data integration. Leveraging artificial
intelligence and semantic technologies, Knowledge Graphs (KGs) uncover hidden
relationships and enable data-driven decision-making. This paper presents
medicX-KG, a pharmacist-oriented knowledge graph supporting clinical and
regulatory decisions. It forms the semantic layer of the broader medicX
platform, powering predictive and explainable pharmacy services. medicX-KG
integrates data from three sources, including, the British National Formulary
(BNF), DrugBank, and the Malta Medicines Authority (MMA) that addresses Malta's
regulatory landscape and combines European Medicines Agency alignment with
partial UK supply dependence. The KG tackles the absence of a unified national
drug repository, reducing pharmacists' reliance on fragmented sources. Its
design was informed by interviews with practicing pharmacists to ensure
real-world applicability. We detail the KG's construction, including data
extraction, ontology design, and semantic mapping. Evaluation demonstrates that
medicX-KG effectively supports queries about drug availability, interactions,
adverse reactions, and therapeutic classes. Limitations, including missing
detailed dosage encoding and real-time updates, are discussed alongside
directions for future enhancements.

</details>


### [73] [Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities](https://arxiv.org/abs/2506.18019)
*Yuanchen Bei,Weizhi Zhang,Siwen Wang,Weizhi Chen,Sheng Zhou,Hao Chen,Yong Li,Jiajun Bu,Shirui Pan,Yizhou Yu,Irwin King,Fakhri Karray,Philip S. Yu*

Main category: cs.AI

TL;DR: 本文综述了图结构在增强AI代理能力，特别是在复杂任务执行和多代理协作中的优势，总结了当前进展并展望了未来发展趋势。


<details>
  <summary>Details</summary>
Motivation: AI代理的发展从强化学习（RL）到大语言模型（LLM），再到两者的融合，但在应对真实世界复杂任务时，仍需解决规划、执行、记忆和多代理协作等核心能力问题。高效处理和理解复杂数据成为瓶颈。

Method: 本综述系统性梳理了图结构在提升AI代理能力方面的作用，探讨了图技术与代理核心功能的结合、实际应用案例，并对未来研究方向进行了展望。

Result: 图结构因其优势能有效组织和处理复杂数据关系，为提升AI代理计划、执行、记忆和协作等能力提供了强有力的支撑。

Conclusion: 本综述首次系统回顾了图如何赋能AI代理，强调图结构在推动AI代理向更高智能进化中的关键作用，并为相关未来研究指明方向。

Abstract: AI agents have experienced a paradigm shift, from early dominance by
reinforcement learning (RL) to the rise of agents powered by large language
models (LLMs), and now further advancing towards a synergistic fusion of RL and
LLM capabilities. This progression has endowed AI agents with increasingly
strong abilities. Despite these advances, to accomplish complex real-world
tasks, agents are required to plan and execute effectively, maintain reliable
memory, and coordinate smoothly with other agents. Achieving these capabilities
involves contending with ever-present intricate information, operations, and
interactions. In light of this challenge, data structurization can play a
promising role by transforming intricate and disorganized data into
well-structured forms that agents can more effectively understand and process.
In this context, graphs, with their natural advantage in organizing, managing,
and harnessing intricate data relationships, present a powerful data paradigm
for structurization to support the capabilities demanded by advanced AI agents.
To this end, this survey presents a first systematic review of how graphs can
empower AI agents. Specifically, we explore the integration of graph techniques
with core agent functionalities, highlight notable applications, and identify
prospective avenues for future research. By comprehensively surveying this
burgeoning intersection, we hope to inspire the development of next-generation
AI agents equipped to tackle increasingly sophisticated challenges with graphs.
Related resources are collected and continuously updated for the community in
the Github link.

</details>


### [74] [Action Language BC+](https://arxiv.org/abs/2506.18044)
*Joseph Babb,Joohyung Lee*

Main category: cs.AI

TL;DR: 本文提出了BC+动作语言，将动作语言与现代ASP语言完美结合，具备更强表达力，可直接基于ASP工具计算，对动作建模和知识表示具有突出应用价值。


<details>
  <summary>Details</summary>
Motivation: 现有的动作语言虽然可以被看作是表示转移系统的高层次答案集程序，但其表达能力远逊于现代答案集编程（ASP）语言，尤其缺乏选择规则、聚合和抽象约束原子等知识表示的有用结构。因此有必要提出一种新语言，弥合动作语言与现代ASP语言之间的差距。

Method: 提出了一种名为BC+的新动作语言，将其语义定义为命题公式的一般稳定模型语义，并将现代ASP语言的多种结构纳入到动作语言中。通过这样的设计，BC+不仅继承了其他动作语言（如B、C、C+和BC）的优点，还能兼容现代ASP语言的表达能力。该语言的求解可直接借助ASP求解器实现，且已经通过扩展cplus2asp系统完成了初步实现。

Result: BC+能够涵盖并扩展多种现有动作语言的优秀特性，拥有足够的表达能力，能利用现有ASP求解器进行计算，并且已经开发出了对应的实现工具。

Conclusion: BC+弥补了传统动作语言和现代ASP语言之间的不足，通过统一的稳定模型语义和现有的ASP工具增强了动作建模的能力和灵活性。

Abstract: Action languages are formal models of parts of natural language that are
designed to describe effects of actions. Many of these languages can be viewed
as high level notations of answer set programs structured to represent
transition systems. However, the form of answer set programs considered in the
earlier work is quite limited in comparison with the modern Answer Set
Programming (ASP) language, which allows several useful constructs for
knowledge representation, such as choice rules, aggregates, and abstract
constraint atoms. We propose a new action language called BC+, which closes the
gap between action languages and the modern ASP language. The main idea is to
define the semantics of BC+ in terms of general stable model semantics for
propositional formulas, under which many modern ASP language constructs can be
identified with shorthands for propositional formulas. Language BC+ turns out
to be sufficiently expressive to encompass the best features of other action
languages, such as languages B, C, C+, and BC. Computational methods available
in ASP solvers are readily applicable to compute BC+, which led to an
implementation of the language by extending system cplus2asp.

</details>


### [75] [Weighted Assumption Based Argumentation to reason about ethical principles and actions](https://arxiv.org/abs/2506.18056)
*Paolo Baldi,Fabio Aurelio D'Asaro,Abeer Dyoub,Francesca Alessandra Lisi*

Main category: cs.AI

TL;DR: 本文将加权机制引入到基于假设的论证（ABA）中，通过伦理推理案例演示新的方法，并给出了一套基于ASP的实现，提升了ABA在处理复杂论证时的能力与灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于假设的论证（ABA）没有考虑到论据的重要性或权重，这限制了其在某些需要区分论据影响程度的领域的应用，如伦理推理。

Method: 在ABA论证框架中引入加权机制：为论据分配权重，并据此计算ABA论据之间攻击的权重。使用伦理推理案例作为实例进行说明，并基于Answer Set Programming实现了该方案。

Result: 成功演示了如何在ABA论证中引入加权机制，并通过实现展示其可行性。基于加权的框架能够更好地支持伦理推理情境下的辩证分析。

Conclusion: 将权重纳入ABA框架能够提升其表达力和适用性，尤其适合应用于对论点重要性敏感的领域，如伦理推理。所提出的方法已经过运行实例和原型系统的验证。

Abstract: We augment Assumption Based Argumentation (ABA for short) with weighted
argumentation. In a nutshell, we assign weights to arguments and then derive
the weight of attacks between ABA arguments. We illustrate our proposal through
running examples in the field of ethical reasoning, and present an
implementation based on Answer Set Programming.

</details>


### [76] [Deep Research Agents: A Systematic Examination And Roadmap](https://arxiv.org/abs/2506.18096)
*Yuxuan Huang,Yihang Chen,Haozheng Zhang,Kang Li,Meng Fang,Linyi Yang,Xiaoguang Li,Lifeng Shang,Songcen Xu,Jianye Hao,Kun Shao,Jun Wang*

Main category: cs.AI

TL;DR: 本文综述和系统梳理了深度研究智能体的技术基础、架构分类和工具生态，揭示了当前评测与实际效果的错位及效率瓶颈，并为未来研究方向提供指导。


<details>
  <summary>Details</summary>
Motivation: LLMs推动下的自主AI系统（DR智能体）崛起，但当前缺乏系统梳理与统一分类，且现有评测体系不能完全反映其实际能力，因此亟需全面分析和指导未来研究。

Method: 对LLM驱动的DR智能体的技术组件（如信息检索、工具利用、架构分层）进行文献综述和系统归类，对现有工作建立分类体系，并对评测基准进行分析和讨论未来方向。

Result: 提出了静态与动态工作流的系统分类，分析了多工具、多模态和模型协议的集成方法，指出了当前DR智能体在外部知识获取、执行效率和性能评估等方面的主要不足，并发布了相关研究资源库。

Conclusion: 本文详细分析了深度研究（Deep Research, DR）智能体的基础技术与架构，提出了系统化的分类法，并批判性地评估了现有基准和未来挑战。

Abstract: The rapid progress of Large Language Models (LLMs) has given rise to a new
category of autonomous AI systems, referred to as Deep Research (DR) agents.
These agents are designed to tackle complex, multi-turn informational research
tasks by leveraging a combination of dynamic reasoning, adaptive long-horizon
planning, multi-hop information retrieval, iterative tool use, and the
generation of structured analytical reports. In this paper, we conduct a
detailed analysis of the foundational technologies and architectural components
that constitute Deep Research agents. We begin by reviewing information
acquisition strategies, contrasting API-based retrieval methods with
browser-based exploration. We then examine modular tool-use frameworks,
including code execution, multimodal input processing, and the integration of
Model Context Protocols (MCPs) to support extensibility and ecosystem
development. To systematize existing approaches, we propose a taxonomy that
differentiates between static and dynamic workflows, and we classify agent
architectures based on planning strategies and agent composition, including
single-agent and multi-agent configurations. We also provide a critical
evaluation of current benchmarks, highlighting key limitations such as
restricted access to external knowledge, sequential execution inefficiencies,
and misalignment between evaluation metrics and the practical objectives of DR
agents. Finally, we outline open challenges and promising directions for future
research. A curated and continuously updated repository of DR agent research is
available at: {https://github.com/ai-agents-2030/awesome-deep-research-agent}.

</details>


### [77] [Decentralized Consensus Inference-based Hierarchical Reinforcement Learning for Multi-Constrained UAV Pursuit-Evasion Game](https://arxiv.org/abs/2506.18126)
*Xiang Yuming,Li Sizhao,Li Rongpeng,Zhao Zhifeng,Zhang Honggang*

Main category: cs.AI

TL;DR: 本文提出了一种高效的多无人机协同规避与编队覆盖框架（CI-HRL），通过层次化强化学习与共识通信机制，提升了无人机群在复杂环境下的协作与自主能力。实验验证了该方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 多旋翼无人机系统在多约束追逃博弈（MC-PEG）中有重要应用，尤其在通信受限下的协同规避和编队覆盖任务（CEFC）仍面临高维、复杂环境下的挑战。当前缺乏能够高效协同规避捕食者、覆盖目标区并应对障碍与通信限制的有效方法。

Method: 提出了一种两层次框架：共识推断基础的层次化强化学习（CI-HRL）。高层策略负责目标定位，融合了共识导向的多智能体通信模块（ConsMAC），通过邻居信息聚合帮助智能体达成全局理解与共识。低层通过替代训练的多智能体PPO（AT-M）和策略蒸馏，实现障碍规避、导航及编队控制。

Result: 实验（包括高保真SITL仿真）表明，CI-HRL方案在协同规避和任务完成效果上优于现有方法，提升了无人机群的任务协同能力和效能。

Conclusion: CI-HRL为多无人机系统在多约束环境下执行规避与覆盖任务提供了有效、高效的解决方案，特别适用于通信受限和复杂动态环境。

Abstract: Multiple quadrotor unmanned aerial vehicle (UAV) systems have garnered
widespread research interest and fostered tremendous interesting applications,
especially in multi-constrained pursuit-evasion games (MC-PEG). The Cooperative
Evasion and Formation Coverage (CEFC) task, where the UAV swarm aims to
maximize formation coverage across multiple target zones while collaboratively
evading predators, belongs to one of the most challenging issues in MC-PEG,
especially under communication-limited constraints. This multifaceted problem,
which intertwines responses to obstacles, adversaries, target zones, and
formation dynamics, brings up significant high-dimensional complications in
locating a solution. In this paper, we propose a novel two-level framework
(i.e., Consensus Inference-based Hierarchical Reinforcement Learning (CI-HRL)),
which delegates target localization to a high-level policy, while adopting a
low-level policy to manage obstacle avoidance, navigation, and formation.
Specifically, in the high-level policy, we develop a novel multi-agent
reinforcement learning module, Consensus-oriented Multi-Agent Communication
(ConsMAC), to enable agents to perceive global information and establish
consensus from local states by effectively aggregating neighbor messages.
Meanwhile, we leverage an Alternative Training-based Multi-agent proximal
policy optimization (AT-M) and policy distillation to accomplish the low-level
control. The experimental results, including the high-fidelity
software-in-the-loop (SITL) simulations, validate that CI-HRL provides a
superior solution with enhanced swarm's collaborative evasion and task
completion capabilities.

</details>


### [78] [SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging](https://arxiv.org/abs/2506.18135)
*Zijun Chen,Zhanpeng Zhou,Bo Zhang,Weinan Zhang,Xi Sun,Junchi Yan*

Main category: cs.AI

TL;DR: 本文分析了模型合并实现多任务能力的机制，并提出了SE-Merging框架。该方法能根据样本动态调整合并参数，无需额外训练，显著提升多任务模型性能且兼容现有技术。


<details>
  <summary>Details</summary>
Motivation: 模型合并因其可以通过插值不同任务的微调模型参数，获得多任务能力而备受关注。然而，其机制尚不清楚。本文旨在从表示学习的角度深入探讨模型合并背后的机理。

Method: 本文通过分析，发现模型合并实现多任务能力主要源于：一是区分不同任务的样本，二是针对每个样本适应相应的专家模型。在此基础上，作者提出了SE-Merging框架，可动态识别样本所属任务，并自适应调整合并系数，从而提升融合模型的任务专长，无需额外训练。

Result: SE-Merging在不用额外训练的前提下，实现了动态模型合并，并显著提升了性能。大量实验证明，该方法在与现有模型合并技术兼容的同时，性能有明显提升。

Conclusion: SE-Merging以自适应的方式实现模型合并，不仅增强了任务特异能力，而且提供了无需额外训练的多任务适配机制，可广泛兼容并提升现有模型合并技术的效果。

Abstract: Model merging has gained increasing attention due to its intriguing property:
interpolating the parameters of different task-specific fine-tuned models leads
to multi-task abilities. However, despite its empirical success, the underlying
mechanisms of model merging remain poorly understood. In this work, we delve
into the mechanism behind model merging from a representation perspective. Our
analysis reveals that model merging achieves multi-task abilities through two
key capabilities: i) distinguishing samples from different tasks, and ii)
adapting to the corresponding expert model for each sample. These two
capabilities allow the merged model to retain task-specific expertise, enabling
efficient multi-task adaptation. Building on these insights, we propose
\texttt{SE-Merging}, a self-enhanced model merging framework that leverages
these two characteristics to dynamically identify the corresponding task for
each sample and then adaptively rescales the merging coefficients to further
enhance task-specific expertise in the merged model. Notably,
\texttt{SE-Merging} achieves dynamic model merging without additional training.
Extensive experiments demonstrate that \texttt{SE-Merging} achieves significant
performance improvements while remaining compatible with existing model merging
techniques.

</details>


### [79] [CoachGPT: A Scaffolding-based Academic Writing Assistant](https://arxiv.org/abs/2506.18149)
*Fumian Chen,Sotheara Veng,Joshua Wilson,Xiaoming Li,Hui Fang*

Main category: cs.AI

TL;DR: 本文提出了基于大语言模型的学术写作辅导工具CoachGPT，相比传统助手更能个性化和实时指导写作，经用户研究验证效果明显，对自主学习者特别有帮助。


<details>
  <summary>Details</summary>
Motivation: 学术写作对学生成功至关重要，但尤其在第二语言写作时，缺乏指导和练习会让学生感到无从下手。传统写作工具无法提供有效、个性化的辅助。

Method: 提出并开发了CoachGPT，一种基于大语言模型（LLM）的AI写作辅导系统。CoachGPT可根据教育者指令将写作过程拆分为子任务，并实时提供反馈和建议。其架构采用分步指导和个性化反馈，嵌入网页应用实现。

Result: CoachGPT相较于现有写作助手，能提供更个性化、更具沉浸感的写作体验和反馈。用户研究表明CoachGPT具有效用，并验证了大语言模型在学术写作辅助中的潜力。

Conclusion: CoachGPT利用大语言模型，创新性地将教学和写作辅导相结合，有助于低资源与自主学习者提升学术写作，弥补了LLM原有的教学短板。

Abstract: Academic writing skills are crucial for students' success, but can feel
overwhelming without proper guidance and practice, particularly when writing in
a second language. Traditionally, students ask instructors or search
dictionaries, which are not universally accessible. Early writing assistants
emerged as rule-based systems that focused on detecting misspellings,
subject-verb disagreements, and basic punctuation errors; however, they are
inaccurate and lack contextual understanding. Machine learning-based assistants
demonstrate a strong ability for language understanding but are expensive to
train. Large language models (LLMs) have shown remarkable capabilities in
generating responses in natural languages based on given prompts. Still, they
have a fundamental limitation in education: they generate essays without
teaching, which can have detrimental effects on learning when misused. To
address this limitation, we develop CoachGPT, which leverages large language
models (LLMs) to assist individuals with limited educational resources and
those who prefer self-paced learning in academic writing. CoachGPT is an AI
agent-based web application that (1) takes instructions from experienced
educators, (2) converts instructions into sub-tasks, and (3) provides real-time
feedback and suggestions using large language models. This unique scaffolding
structure makes CoachGPT unique among existing writing assistants. Compared to
existing writing assistants, CoachGPT provides a more immersive writing
experience with personalized feedback and guidance. Our user studies prove the
usefulness of CoachGPT and the potential of large language models for academic
writing.

</details>


### [80] [AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology](https://arxiv.org/abs/2506.18156)
*Akash Kundu,Rishika Goswami*

Main category: cs.AI

TL;DR: 本文系统考察LLMs在四大心理学框架下的类人认知倾向，发现其在叙事、框架效应、道德判断及矛盾处理方面均与人类类似；这一发现有助于促进AI透明性和伦理应用的讨论。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型（LLMs）是否展现类人认知模式，借助心理学中的四大框架进行分析，旨在加深对AI行为与人类思维异同的理解。

Method: 采用结构化提示与自动评分的方法，基于主题统觉测试（TAT）、框架偏差、道德基础理论（MFT）及认知失调四种心理学框架，对多种专有及开源LLM进行评估。

Result: LLMs展现出可理解的叙述、对积极框架存在偏差、道德判断偏向自由/压迫议题，并表现出自相矛盾但能进行较为复杂的合理化。这些特征反映了人类的部分认知倾向，但又深受训练数据与对齐手段影响。

Conclusion: LLMs在多种心理学框架下体现出与人类相似的认知特征；这些表现对于理解AI透明性、伦理部署及未来融合心理学与AI安全的工作具有启示意义。

Abstract: We investigate whether Large Language Models (LLMs) exhibit human-like
cognitive patterns under four established frameworks from psychology: Thematic
Apperception Test (TAT), Framing Bias, Moral Foundations Theory (MFT), and
Cognitive Dissonance. We evaluated several proprietary and open-source models
using structured prompts and automated scoring. Our findings reveal that these
models often produce coherent narratives, show susceptibility to positive
framing, exhibit moral judgments aligned with Liberty/Oppression concerns, and
demonstrate self-contradictions tempered by extensive rationalization. Such
behaviors mirror human cognitive tendencies yet are shaped by their training
data and alignment methods. We discuss the implications for AI transparency,
ethical deployment, and future work that bridges cognitive psychology and AI
safety

</details>


### [81] [Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation](https://arxiv.org/abs/2506.18158)
*Xinzge Gao,Chuanrui Hu,Bin Chen,Teng Li*

Main category: cs.AI

TL;DR: 本文提出链式记忆（CoM）机制，提升GUI智能体在复杂任务中的记忆和状态理解能力，并发布了大规模配套数据集，实验显示小规模模型也能获得媲美大模型的记忆管理表现。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLM）被用于GUI智能体，但多数方法通过历史截图或动作隐式表示任务状态，这导致智能体难以准确理解复杂任务，尤其是跨应用场景下重要信息的存储和管理能力不足。

Method: 提出了Chain-of-Memory（CoM）方法，用于显式建模GUI智能体中的短期和长期记忆。CoM通过捕获动作描述、整合任务相关屏幕信息，并维护专用内存模块存储和管理这些信息。同时，构建了包含111k屏幕-动作对，并标注有CoM内存链的GUI Odyssey-CoM数据集。

Result: 实验结果表明，CoM方法显著提升了GUI智能体在跨应用任务中的表现，同时GUI Odyssey-CoM数据集使7B模型具备与72B模型媲美的记忆管理能力。

Conclusion: CoM通过显式记忆建模与管理，提升了GUI智能体对任务状态的理解和关键历史信息的存储能力，有效推动了多模态大语言模型在复杂交互任务场景下的应用。数据集和代码将开源。

Abstract: Multimodal large language models (MLLMs) are attracting growing attention in
the development of Graphical User Interface (GUI) agents. Existing approaches
often rely on historical screenshots or actions to implicitly represent the
task state. This reliance poses challenges for GUI agents in accurately
understanding task states and underscores the absence of effective mechanisms
to store critical information in complex and lengthy cross-app tasks. To
address these challenges, we propose Chain-of-Memory (CoM), a novel approach
for explicitly modeling short-term and long-term memory in GUI agents. CoM
achieves this by capturing action descriptions, integrating task-relevant
screen information, and maintaining a dedicated memory module to store and
manage this information. By leveraging explicit memory representations, CoM
enables GUI agents to better understand task states and retain critical
historical information persistently. To equip GUI agents with memory management
capabilities and evaluate the effectiveness of CoM, we developed the GUI
Odyssey-CoM, a dataset comprising 111k screen-action pairs annotated with
Chain-of-Memory. Experimental results demonstrate that CoM significantly
improves GUI agents' performance in cross-application tasks. Additionally, GUI
Odyssey-CoM enables 7B models to achieve memory management capabilities
comparable to 72B models. The dataset and code will be open-sourced.

</details>


### [82] [Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?](https://arxiv.org/abs/2506.18183)
*Zhiting Mei,Christina Zhang,Tenny Yin,Justin Lidard,Ola Shorinwa,Anirudha Majumdar*

Main category: cs.AI

TL;DR: 论文系统分析了推理大模型的不确定性校准能力，发现其普遍过度自信，且深入推理反而导致校准性下降。通过自省机制部分模型可提升校准，但方法并非适用于所有模型。未来需建立更完善的不确定性量化评测与改进方案，以促进推理模型安全可控应用。


<details>
  <summary>Details</summary>
Motivation: 推理语言模型在许多基准任务上取得了最先进（SOTA）的成果，但它们也容易产生自信却错误的虚假响应（即幻觉）。因此，如何量化并校准推理模型的不确定性是安全部署的重要前提。该论文旨在系统评估推理模型的校准能力，以及探讨通过模型自省是否可以提升校准性。

Method: 本研究分别考察了三个关键问题：1）当前推理模型的校准程度如何？2）更深层次的推理是否能提升校准性？3）通过让模型对自己的推理过程进行自省，能否进一步提升其校准能力？研究提出了内省式不确定性量化（UQ）方法，并在最先进推理模型和多种基准任务上进行了广泛实验评估。

Result: 实验发现：推理模型通常过度自信，尤其是在错误回答时自报置信度常大于85%；随着推理深度增加，模型越发过度自信；通过内省机制，一些模型（如o3-Mini和DeepSeek R1）校准性提升，但并非所有模型都有效（如Claude 3.7 Sonnet校准性反而变差）。

Conclusion: 推理模型在校准可靠性方面仍存明显缺陷，尤其表现为过度自信，需引入更多样化的不确定性量化基准与机制，持续优化推理模型的校准能力与安全性。

Abstract: Reasoning language models have set state-of-the-art (SOTA) records on many
challenging benchmarks, enabled by multi-step reasoning induced using
reinforcement learning. However, like previous language models, reasoning
models are prone to generating confident, plausible responses that are
incorrect (hallucinations). Knowing when and how much to trust these models is
critical to the safe deployment of reasoning models in real-world applications.
To this end, we explore uncertainty quantification of reasoning models in this
work. Specifically, we ask three fundamental questions: First, are reasoning
models well-calibrated? Second, does deeper reasoning improve model
calibration? Finally, inspired by humans' innate ability to double-check their
thought processes to verify the validity of their answers and their confidence,
we ask: can reasoning models improve their calibration by explicitly reasoning
about their chain-of-thought traces? We introduce introspective uncertainty
quantification (UQ) to explore this direction. In extensive evaluations on SOTA
reasoning models across a broad range of benchmarks, we find that reasoning
models: (i) are typically overconfident, with self-verbalized confidence
estimates often greater than 85% particularly for incorrect responses, (ii)
become even more overconfident with deeper reasoning, and (iii) can become
better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not
uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we
conclude with important research directions to design necessary UQ benchmarks
and improve the calibration of reasoning models.

</details>


### [83] [The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis](https://arxiv.org/abs/2506.18187)
*Shahriar Noroozizadeh,Pim Welle,Jeremy C. Weiss,George H. Chen*

Main category: cs.AI

TL;DR: 该研究创新性地结合生存分析和因果推断方法，发现精神分裂症患者药物不依从可明显提前不良事件发生，临床和政策层面高度重视药物依从性管理。


<details>
  <summary>Details</summary>
Motivation: 精神分裂症患者常因不规律服用抗精神病药物而导致不良结局，但不同个体的不依从性对临床结局的具体影响尚缺少量化研究。该研究旨在通过生存分析和因果推断方法，定量分析药物服用不依从与临床不良结局之间的关联。

Method: 研究采用生存分析框架，将首个不良事件（早逝、强制住院、被监禁）发生时间作为终点。将药物不依从视为“治疗”，结合T-learner、S-learner、最近邻匹配等因果推断方法，分别利用不同生存模型，估算个体与平均治疗效应。并对3、6、9、12个月数据分别重复分析。还进行了消融实验和按药物类型/剂型的亚组分析。

Result: 分析显示，药物不依从使不良事件的发生提前约1至4个月。消融实验发现县风险评分能调整主要混杂因素，移除时估算效应显著加强。亚组分析显示不同药物剂型和类型下，不依从均与更早不良事件相关。

Conclusion: 研究证明坚持抗精神病药物依从性对于延缓精神健康危机至关重要，整合生存分析和因果推断工具有助于为临床与政策提供有影响力的见解。文章虽运用因果推断仍以相关性为主，呼吁读者注意因果解释前提。

Abstract: This study quantifies the association between non-adherence to antipsychotic
medications and adverse outcomes in individuals with schizophrenia. We frame
the problem using survival analysis, focusing on the time to the earliest of
several adverse events (early death, involuntary hospitalization, jail
booking). We extend standard causal inference methods (T-learner, S-learner,
nearest neighbor matching) to utilize various survival models to estimate
individual and average treatment effects, where treatment corresponds to
medication non-adherence. Analyses are repeated using different amounts of
longitudinal information (3, 6, 9, and 12 months). Using data from Allegheny
County in western Pennsylvania, we find strong evidence that non-adherence
advances adverse outcomes by approximately 1 to 4 months. Ablation studies
confirm that county-provided risk scores adjust for key confounders, as their
removal amplifies the estimated effects. Subgroup analyses by medication
formulation (injectable vs. oral) and medication type consistently show that
non-adherence is associated with earlier adverse events. These findings
highlight the clinical importance of adherence in delaying psychiatric crises
and show that integrating survival analysis with causal inference tools can
yield policy-relevant insights. We caution that although we apply causal
inference, we only make associative claims and discuss assumptions needed for
causal interpretation.

</details>


### [84] [A Conceptual Framework for AI Capability Evaluations](https://arxiv.org/abs/2506.18213)
*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Luca Nicolás Forziati Gangi,Matheo Sandleris Musa,Lola Ramos Pereyra,Mario Leiva,Juan Gustavo Corvalan,María Vanina Martinez,Gerardo Simari*

Main category: cs.AI

TL;DR: 本文提出了一个AI能力评估的概念框架，旨在提升评估的系统性、透明性与可比性，为研究者、从业者及政策制定者提供实用分析工具，助力AI治理。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统的发展和社会融合，需要有良好设计且透明的评估来支撑AI治理，通过提供系统能力和风险的证据辅助决策。然而，目前尚无如何全面、可靠地进行此类评估的清晰方法。

Method: 提出了一个AI能力评估分析的概念框架，以结构化和描述性的方法对广泛使用的方法和术语进行系统化分析，而不是引入新的分类法或严格格式。

Result: 该框架提升了不同评估间的透明度、可比性和可解释性，使研究者能够发现方法学不足，帮助从业人员设计评估，也为政策制定者提供了便于使用的工具，以便审查、比较并应对复杂的评估局面。

Conclusion: 文章通过提出的框架，为AI能力评估提供结构化分析工具，有助于推进评估方法的标准化并促进AI治理决策。

Abstract: As AI systems advance and integrate into society, well-designed and
transparent evaluations are becoming essential tools in AI governance,
informing decisions by providing evidence about system capabilities and risks.
Yet there remains a lack of clarity on how to perform these assessments both
comprehensively and reliably. To address this gap, we propose a conceptual
framework for analyzing AI capability evaluations, offering a structured,
descriptive approach that systematizes the analysis of widely used methods and
terminology without imposing new taxonomies or rigid formats. This framework
supports transparency, comparability, and interpretability across diverse
evaluations. It also enables researchers to identify methodological weaknesses,
assists practitioners in designing evaluations, and provides policymakers with
an accessible tool to scrutinize, compare, and navigate complex evaluation
landscapes.

</details>


### [85] [The 4th Dimension for Scaling Model Size](https://arxiv.org/abs/2506.18233)
*Ruike Zhu,Hanwen Zhang,Tianyu Shi,Chi Wang,Tianyi Zhou,Zengyi Qin*

Main category: cs.AI

TL;DR: 该论文提出并系统研究了通过参数复用增加大模型“虚拟逻辑深度”的扩展方法，指出只要方法得当，VLD可以在不增参数量的条件下大幅提升模型推理力，而对知识容量影响较小。


<details>
  <summary>Details</summary>
Motivation: 在现有的三种大模型扩展方式（深度、宽度、参数数量）基础上，探索参数复用所带来的“虚拟逻辑深度”作为第四种扩展维度，分析其提升模型能力的潜力及特点。

Method: 本文采用了有控制的实验设计，对比分析不同的VLD扩展方法下模型的表现，以验证参数复用对知识容量和推理能力的影响。

Result: 发现VLD扩展能够在参数总数保持不变的情况下，显著提升模型的推理能力，而对知识容量影响很小。参数数量依然主导知识容量提升，但与推理能力无关。该现象在多种模型配置下均成立。

Conclusion: 虚拟逻辑深度（VLD）扩展不会显著增加模型的知识容量，但能够大幅提升模型的推理能力。同时，参数数量主要对应知识容量，与推理能力无直接关系，因此推理能力的提升并不一定依赖参数量的增加。

Abstract: Scaling the size of large language models typically involves three
dimensions: depth, width, and the number of parameters. In this work, we
explore a fourth dimension, virtual logical depth (VLD), which increases the
effective algorithmic depth without changing the overall parameter count by
reusing parameters within the model. Although parameter reuse is not a new
concept, its potential and characteristics in model scaling have not been
thoroughly studied. Through carefully designed controlled experiments, we make
the following key discoveries regarding VLD scaling:
  VLD scaling forces the knowledge capacity of the model to remain almost
constant, with only minor variations.
  VLD scaling enables a significant improvement in reasoning capability,
provided the scaling method is properly implemented.
  The number of parameters correlates with knowledge capacity, but not with
reasoning capability. Under certain conditions, it is not necessary to increase
the parameter count to enhance reasoning.
  These findings are consistent across various model configurations and are
likely to be generally valid within the scope of our experiments.

</details>


### [86] [Advanced For-Loop for QML algorithm search](https://arxiv.org/abs/2506.18260)
*FuTe Wong*

Main category: cs.AI

TL;DR: 本文提出了基于大语言模型的多智能体系统，用于自动搜索和优化量子机器学习算法，初步结果表明该方法可高效探索并改编经典机器学习算法到量子领域，为QML算法发展提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 经典机器学习算法向量子计算领域的迁移存在手动设计和优化难题，因此亟需高效自动化的探索与优化方法。

Method: 提出了基于大语言模型的多智能体系统（LLMMA）框架，系统性地自动生成、改进和优化经典机器学习算法在量子计算领域的转换方法。该系统模仿FunSearch，通过多轮迭代探查量子版本的MLP、前向传播和反向传播等算法。

Result: 证明了该多智能体框架在探索并量子化经典学习算法方面的有效性，展示了其自动化开发QML算法的潜力。为量子机器学习算法的未来开发提供了高效、自动化的技术路线。

Conclusion: 基于LLM的多智能体系统为QML算法的自动搜索与优化带来了创新路径，未来可继续集成规划与优化策略，广泛应用于量子增强机器学习领域。

Abstract: This paper introduces an advanced framework leveraging Large Language
Model-based Multi-Agent Systems (LLMMA) for the automated search and
optimization of Quantum Machine Learning (QML) algorithms. Inspired by Google
DeepMind's FunSearch, the proposed system works on abstract level to
iteratively generates and refines quantum transformations of classical machine
learning algorithms (concepts), such as the Multi-Layer Perceptron,
forward-forward and backpropagation algorithms. As a proof of concept, this
work highlights the potential of agentic frameworks to systematically explore
classical machine learning concepts and adapt them for quantum computing,
paving the way for efficient and automated development of QML algorithms.
Future directions include incorporating planning mechanisms and optimizing
strategy in the search space for broader applications in quantum-enhanced
machine learning.

</details>


### [87] [Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team](https://arxiv.org/abs/2506.18348)
*Weilun Yu,Shixiang Tang,Yonggui Huang,Nanqing Dong,Li Fan,Honggang Qi,Wei Liu,Xiaoli Diao,Xi Chen,Wanli Ouyang*

Main category: cs.AI

TL;DR: 本文提出了利用大语言模型组成多智能体科学家团队，通过内部讨论、投票、创新的知识交流和多样化同行评审，有效提升了自动化科学研究的能力，并在多个数据集上超越现有方案，强调了互动与评审机制的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型(LLM)在模拟科学研究协作上进展有限，缺乏类似于现实科研中互动推理和评议的机制，限制了其科学发现能力。

Method: 提出IDVSCI框架，包括动态知识交换机制和双重多样性评审范式，允许LLM科学家代理间进行迭代反馈和多样化同行评议，促进更深入推理和创新性观点生成。

Result: 在计算机科学常用基准数据集和健康科学新数据集上，IDVSCI都取得了优于现有AI Scientist和VIRSCI等系统的最佳表现。

Conclusion: IDVSCI框架通过建模LLM科学家代理间的互动和同行评议动态，有效提升了自主科学研究的创造力和影响力，证明了此类机制的实际价值。

Abstract: Scientific progress increasingly relies on effective collaboration among
researchers, a dynamic that large language models (LLMs) have only begun to
emulate. While recent LLM-based scientist agents show promise in autonomous
scientific discovery, they often lack the interactive reasoning and evaluation
mechanisms essential to real-world research. We propose IDVSCI (Internal
Discussion and Vote SCIentists), a multi-agent framework built on LLMs that
incorporates two key innovations: a Dynamic Knowledge Exchange mechanism
enabling iterative feedback among agents, and a Dual-Diversity Review paradigm
that simulates heterogeneous expert evaluation. These components jointly
promote deeper reasoning and the generation of more creative and impactful
scientific ideas. To evaluate the effectiveness and generalizability of our
approach, we conduct experiments on two datasets: a widely used benchmark in
computer science and a new dataset we introduce in the health sciences domain.
Results show that IDVSCI consistently achieves the best performance across both
datasets, outperforming existing systems such as AI Scientist and VIRSCI. These
findings highlight the value of modeling interaction and peer review dynamics
in LLM-based autonomous research.

</details>


### [88] [A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction](https://arxiv.org/abs/2506.18424)
*Chengjie Liu,Weiyu Chen,Huiyao Xu,Yuan Du,Jun Yang,Li Du*

Main category: cs.AI

TL;DR: 提出用LLM自动从文献提取电路尺寸关系，有效剪枝搜索空间，提升优化效率2~26倍，为电路设计自动化提供新方法。


<details>
  <summary>Details</summary>
Motivation: 在模拟电路的设计前期，器件尺寸的设定（device sizing）对能否满足性能指标至关重要。传统方法多把这一问题当作数学优化问题，有效率提升空间，但未能充分利用先验知识进行搜索空间剪枝。

Method: 提出了一种基于大型语言模型（LLM）的多智能体框架，从学术论文中自动提取模拟电路的尺寸关联（sizing relationship），据此对优化搜索空间进行有效剪枝。并在3类电路上进行了测试。

Result: 在测试的3类电路上，优化效率提升了2.32到26.6倍。

Conclusion: LLM可以高效地剪枝模拟电路尺寸设定的搜索空间，为LLM与传统电路设计自动化的结合提供了一种新思路。

Abstract: In the design process of the analog circuit pre-layout phase, device sizing
is an important step in determining whether an analog circuit can meet the
required performance metrics. Many existing techniques extract the circuit
sizing task as a mathematical optimization problem to solve and continuously
improve the optimization efficiency from a mathematical perspective. But they
ignore the automatic introduction of prior knowledge, fail to achieve effective
pruning of the search space, which thereby leads to a considerable compression
margin remaining in the search space. To alleviate this problem, we propose a
large language model (LLM)-based multi-agent framework for analog circuits'
sizing relationships extraction from academic papers. The search space in the
sizing process can be effectively pruned based on the sizing relationship
extracted by this framework. Eventually, we conducted tests on 3 types of
circuits, and the optimization efficiency was improved by $2.32 \sim 26.6
\times$. This work demonstrates that the LLM can effectively prune the search
space for analog circuit sizing, providing a new solution for the combination
of LLMs and conventional analog circuit design automation methods.

</details>


### [89] [How Robust is Model Editing after Fine-Tuning? An Empirical Study on Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.18428)
*Feng He,Zhenyang Liu,Marco Valentino,Zhixue Zhao*

Main category: cs.AI

TL;DR: 本研究揭示了模型编辑很难在后续的微调过程中持久保存，尤其是DoRA微调会大幅逆转编辑。UCE编辑方法在微调后更稳健。微调既可作为消除恶意编辑的手段，也提示大家，想保留正向编辑需在微调后重新处理。


<details>
  <summary>Details</summary>
Motivation: 模型编辑能够以较低的成本修正或注入预训练模型的特定行为，广泛应用于事实修正和偏见缓解等场景。但目前尚不清楚这些修改在之后的微调过程中能否保存下来，或者会不会被微调意外地逆转。这个问题直接影响模型安全与实际应用效果。

Method: 系统性地研究了模型编辑与微调之间的相互作用，聚焦于文本到图像（T2I）扩散模型。实验覆盖Stable Diffusion和FLUX两个模型系列，采用了两种最新模型编辑技术（如UCE和ReFACT）以及三种主流微调方法（DreamBooth, LoRA, DoRA）。通过大量实证分析，对各种编辑任务和评估指标进行了细致对比。

Result: 大多数模型编辑在微调后无法保持原有效果，即使是与编辑目标无关的微调也容易逆转编辑。其中，DoRA微调对编辑的逆转作用最强。在模型编辑方法中，UCE比ReFACT在微调后表现出更高的稳健性和有效性。

Conclusion: 现有的模型编辑方法存在显著局限性，无法实现编辑效果的长期保持。因此，未来需发展更健壮的模型编辑技术，以确保AI系统的安全、长期可控与对齐。对AI安全的双重启示是：微调可减少恶意编辑风险，但对于安全和对齐类有益编辑，需在微调后重新编辑。

Abstract: Model editing offers a low-cost technique to inject or correct a particular
behavior in a pre-trained model without extensive retraining, supporting
applications such as factual correction and bias mitigation. Despite this
common practice, it remains unknown whether edits persist after fine-tuning or
whether they are inadvertently reversed. This question has fundamental
practical implications. For example, if fine-tuning removes prior edits, it
could serve as a defence mechanism against hidden malicious edits. Vice versa,
the unintended removal of edits related to bias mitigation could pose serious
safety concerns. We systematically investigate the interaction between model
editing and fine-tuning in the context of T2I diffusion models, which are known
to exhibit biases and generate inappropriate content. Our study spans two T2I
model families (Stable Diffusion and FLUX), two sota editing techniques, and
three fine-tuning methods (DreamBooth, LoRA, and DoRA). Through an extensive
empirical analysis across diverse editing tasks and evaluation metrics, our
findings reveal a trend: edits generally fail to persist through fine-tuning,
even when fine-tuning is tangential or unrelated to the edits. Notably, we
observe that DoRA exhibits the strongest edit reversal effect. At the same
time, among editing methods, UCE demonstrates greater robustness, retaining
significantly higher efficacy post-fine-tuning compared to ReFACT. These
findings highlight a crucial limitation in current editing methodologies,
emphasizing the need for more robust techniques to ensure reliable long-term
control and alignment of deployed AI systems. These findings have dual
implications for AI safety: they suggest that fine-tuning could serve as a
remediation mechanism for malicious edits while simultaneously highlighting the
need for re-editing after fine-tuning to maintain beneficial safety and
alignment properties.

</details>


### [90] [Standard Applicability Judgment and Cross-jurisdictional Reasoning: A RAG-based Framework for Medical Device Compliance](https://arxiv.org/abs/2506.18511)
*Yu Han,Aaron Ceross,Jeroen H. M. Bergmann*

Main category: cs.AI

TL;DR: 本文提出了一个结合检索和大模型推理的AI系统，实现了医疗器械法规标准适用性的自动判断，在准确率和召回率上均优于基线方法，并支持跨中美标准的复杂法规适用推理，为可扩展的法规合规自动化带来新工具。


<details>
  <summary>Details</summary>
Motivation: 医疗器械的法规合规中，如何准确判断适用的法规标准是一项关键且尚未充分研究的挑战，常常需要专家对不同司法辖区内分散、不一致的文档进行解读。

Method: 提出了一套模块化AI系统，利用检索增强生成（RAG）流程。该系统针对自由文本描述的医疗器械，从整理的法规标准语料库中检索候选标准，并利用大语言模型推理各司法辖区内的适用性，分类为强制、推荐或不适用，并给出可追溯的理由。同时，构建了带有专家标注标准映射的国际基准数据集，并与仅检索、零样本和基于规则的基线方法进行对比评估。

Result: 系统以73%的适用性分类准确率和87%的Top-5检索召回率，有效识别相关法规标准。系统还能进行跨中美标准的跨辖区推理，支持冲突解决与适用性解释。

Conclusion: 首次实现法规标准适用性推理的端到端AI系统，为可扩展、可解释的AI支持型法规科学带来突破，并实现跨地区法规协同。

Abstract: Identifying the appropriate regulatory standard applicability remains a
critical yet understudied challenge in medical device compliance, frequently
necessitating expert interpretation of fragmented and heterogeneous
documentation across different jurisdictions. To address this challenge, we
introduce a modular AI system that leverages a retrieval-augmented generation
(RAG) pipeline to automate standard applicability determination. Given a
free-text device description, our system retrieves candidate standards from a
curated corpus and uses large language models to infer jurisdiction-specific
applicability, classified as Mandatory, Recommended, or Not Applicable, with
traceable justifications. We construct an international benchmark dataset of
medical device descriptions with expert-annotated standard mappings, and
evaluate our system against retrieval-only, zero-shot, and rule-based
baselines. The proposed approach attains a classification accuracy of 73% and a
Top-5 retrieval recall of 87%, demonstrating its effectiveness in identifying
relevant regulatory standards. We introduce the first end-to-end system for
standard applicability reasoning, enabling scalable and interpretable
AI-supported regulatory science. Notably, our region-aware RAG agent performs
cross-jurisdictional reasoning between Chinese and U.S. standards, supporting
conflict resolution and applicability justification across regulatory
frameworks.

</details>


### [91] [A Question Bank to Assess AI Inclusivity: Mapping out the Journey from Diversity Errors to Inclusion Excellence](https://arxiv.org/abs/2506.18538)
*Rifat Ara Shams,Didar Zowghi,Muneera Bano*

Main category: cs.AI

TL;DR: 本文提出253问AI包容性问题库，为AI包容性评估提供实用工具，有助于推动AI公平、包容与负责任发展。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统评估框架经常忽视多样性与包容性（D&I）原则，缺乏衡量AI系统包容性标准化工具，可能导致偏见与不公决策。

Method: 作者以迭代、多信息源方法，结合文献回顾、多样性和包容性指导方针、负责任的AI框架以及模拟用户研究，开发出253个问题组成的AI包容性问题库，覆盖“人、数据、流程、系统、治理”五大维度。通过与70个模拟AI相关岗位角色进行评测，验证其相关性与有效性。

Result: 研究证明了D&I原则对AI开发流程与治理结构整合的重要性。该问题库可为研究人员、从业者与政策制定者，系统性评估与提升AI系统包容性提供实际工具。

Conclusion: 提出并验证了一套结构化AI包容性问题库，为AI系统包容性评估制定了工具基础，有助于推动AI领域更加公平、负责任的发展。

Abstract: Ensuring diversity and inclusion (D&I) in artificial intelligence (AI) is
crucial for mitigating biases and promoting equitable decision-making. However,
existing AI risk assessment frameworks often overlook inclusivity, lacking
standardized tools to measure an AI system's alignment with D&I principles.
This paper introduces a structured AI inclusivity question bank, a
comprehensive set of 253 questions designed to evaluate AI inclusivity across
five pillars: Humans, Data, Process, System, and Governance. The development of
the question bank involved an iterative, multi-source approach, incorporating
insights from literature reviews, D&I guidelines, Responsible AI frameworks,
and a simulated user study. The simulated evaluation, conducted with 70
AI-generated personas related to different AI jobs, assessed the question
bank's relevance and effectiveness for AI inclusivity across diverse roles and
application domains. The findings highlight the importance of integrating D&I
principles into AI development workflows and governance structures. The
question bank provides an actionable tool for researchers, practitioners, and
policymakers to systematically assess and enhance the inclusivity of AI
systems, paving the way for more equitable and responsible AI technologies.

</details>


### [92] [T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent](https://arxiv.org/abs/2506.18559)
*Hong Qing Yu*

Main category: cs.AI

TL;DR: 本文提出了一种扩展描述逻辑的新方法（T-CPDL），使大语言模型具备更强的时序、因果和概率推理能力，实验证明该方法显著提升推理表现，为可信赖的推理和逻辑增强的检索生成系统奠定基础。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽然擅长生成流畅文本，但在涉及时序约束、因果关系和概率推理等结构化推理任务上表现不佳。为克服这些局限性，需要引入能够表达并推理这些结构化信息的新逻辑框架。

Method: 提出并实现了一种新的时序因果概率描述逻辑（T-CPDL）, 包括两个版本：一个采用Allen时序区间代数来表达时序关系，另一个利用带时间戳的因果断言。二者均有统一的逻辑结构，用于表示复杂的时序、因果和概率推理。通过在时序推理和因果推理基准测试上进行实证评估。

Result: 实验证明，T-CPDL在推理准确率、结果可解释性以及信心校准方面均有显著提升，增强了语言模型在复杂推理任务下的表现能力。

Conclusion: T-CPDL能够显著提升大语言模型在时序、因果和概率推理方面的能力，实现更高的推理准确性、可解释性和信心校准，为可信赖的决策过程提供了有力支持。该方法还为今后开发基于逻辑增强的检索生成系统奠定了基础。

Abstract: Large language models excel at generating fluent text but frequently struggle
with structured reasoning involving temporal constraints, causal relationships,
and probabilistic reasoning. To address these limitations, we propose Temporal
Causal Probabilistic Description Logic (T-CPDL), an integrated framework that
extends traditional Description Logic with temporal interval operators,
explicit causal relationships, and probabilistic annotations. We present two
distinct variants of T-CPDL: one capturing qualitative temporal relationships
through Allen's interval algebra, and another variant enriched with explicit
timestamped causal assertions. Both variants share a unified logical structure,
enabling complex reasoning tasks ranging from simple temporal ordering to
nuanced probabilistic causation. Empirical evaluations on temporal reasoning
and causal inference benchmarks confirm that T-CPDL substantially improves
inference accuracy, interpretability, and confidence calibration of language
model outputs. By delivering transparent reasoning paths and fine-grained
temporal and causal semantics, T-CPDL significantly enhances the capability of
language models to support robust, explainable, and trustworthy
decision-making. This work also lays the groundwork for developing advanced
Logic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentially
boosting the reasoning capabilities and efficiency of knowledge graph-enhanced
RAG systems.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [93] [Outcome-Based Education: Evaluating Students' Perspectives Using Transformer](https://arxiv.org/abs/2506.17223)
*Shuvra Smaran Das,Anirban Saha Anik,Md Kishor Morol,Mohammad Sakib Mahmood*

Main category: cs.CL

TL;DR: 本文用Transformer（DistilBERT）和LIME解释方法，实现对学生反馈的高效可解释分析，优于传统机器学习，有助于以成果为导向的教育目标实现。


<details>
  <summary>Details</summary>
Motivation: OBE（以成果为导向的教育）要求准确分析学生反馈以改进教学成果，但传统方法对文本情感理解有限，因此需要更先进的NLP工具。

Method: 本文采用基于Transformer的DistilBERT模型分析学生反馈的NLP数据集，分类情感，并结合LIME解释模型以提高预测的可解释性。

Result: DistilBERT在情感分类任务上的表现优于其他机器学习模型，可以在更多评估矩阵上获得更好结果，并利用LIME解释帮助理解情感判别的关键因素。

Conclusion: 将Transformer模型与LIME结合，能够有效、可解释地分析学生反馈，促进OBE目标实现，支持基于数据的教育实践改进。

Abstract: Outcome-Based Education (OBE) emphasizes the development of specific
competencies through student-centered learning. In this study, we reviewed the
importance of OBE and implemented transformer-based models, particularly
DistilBERT, to analyze an NLP dataset that includes student feedback. Our
objective is to assess and improve educational outcomes. Our approach is better
than other machine learning models because it uses the transformer's deep
understanding of language context to classify sentiment better, giving better
results across a wider range of matrices. Our work directly contributes to
OBE's goal of achieving measurable outcomes by facilitating the identification
of patterns in student learning experiences. We have also applied LIME (local
interpretable model-agnostic explanations) to make sure that model predictions
are clear. This gives us understandable information about how key terms affect
sentiment. Our findings indicate that the combination of transformer models and
LIME explanations results in a strong and straightforward framework for
analyzing student feedback. This aligns more closely with the principles of OBE
and ensures the improvement of educational practices through data-driven
insights.

</details>


### [94] [Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs](https://arxiv.org/abs/2506.17231)
*Xiang Li,Chong Zhang,Jia Wang,Fangyu Wu,Yushi Li,Xiaobo Jin*

Main category: cs.CL

TL;DR: 提出了高效的对抗性提示蒸馏方法，使小模型能越狱攻击主流大模型，兼具高效率、强适应性和危害性，对LLM安全领域具有启发意义。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）面临越狱攻击带来的安全及道德问题，然而现有方法效率低、计算消耗大、跨模型适应性差，难以应对模型与防御策略的快速变化。

Method: 提出了一种对抗性提示蒸馏（Adversarial Prompt Distillation，APD）方法，结合掩码语言建模、强化学习和动态温度控制，通过生成和蒸馏提示，使小型语言模型（SLM）能够攻击主流LLM。

Result: 实验结果表明，该方法在攻击成功率和危害方面优于现有技术，同时在资源效率和跨模型适应性方面也表现突出。

Conclusion: 本研究验证了将LLM越狱能力蒸馏至SLM的可行性，揭示了模型潜在的脆弱性，为LLM安全研究提供了新思路。

Abstract: Attacks on large language models (LLMs) in jailbreaking scenarios raise many
security and ethical issues. Current jailbreak attack methods face problems
such as low efficiency, high computational cost, and poor cross-model
adaptability and versatility, which make it difficult to cope with the rapid
development of LLM and new defense strategies. Our work proposes an Adversarial
Prompt Distillation, which combines masked language modeling, reinforcement
learning, and dynamic temperature control through a prompt generation and
distillation method. It enables small language models (SLMs) to jailbreak
attacks on mainstream LLMs. The experimental results verify the superiority of
the proposed method in terms of attack success rate and harm, and reflect the
resource efficiency and cross-model adaptability. This research explores the
feasibility of distilling the jailbreak ability of LLM to SLM, reveals the
model's vulnerability, and provides a new idea for LLM security research.

</details>


### [95] [GTA: Grouped-head latenT Attention](https://arxiv.org/abs/2506.17286)
*Luoyang Sun,Jiwen Jiang,Cheng Deng,Xinjian Wu,Haifeng Zhang,Lei Chen,Lionel Ni,Jun Wang*

Main category: cs.CL

TL;DR: 本文提出Grouped-Head Latent Attention (GTA)，通过共享注意力图与潜空间解码显著降低计算与存储开销，使大语言模型推理速度翻倍并降低KV缓存需求，适合高效部署到计算或内存受限环境。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）的注意力机制虽然关键，但其高昂的计算和内存开销严重影响了效率与性能，特别是在文本长度变长时，对硬件资源限制提出了挑战。研究者观察到注意力机制中的KV缓存和各头的注意力图有很大冗余，因此期望用更高效的方案减少资源占用。

Method: 本文提出了一种新的注意力机制：Grouped-Head Latent Attention (GTA)。主要包括两个组件：(1) 共享注意力图机制，在多个头之间复用注意力分数，减小key缓存大小；(2) 非线性值解码器，用学习到的投影将value缓存压缩至潜在空间，进一步降低内存需求。

Result: GTA算法相比Grouped-Query Attention最多可以减少62.5%的注意力计算FLOPs，最多可减少70%的KV缓存体积，同时避免了多头潜在注意力方法的额外开销。最终，整体推理速度提升2倍，预填充和解码阶段计算和缓存开销均显著降低。

Conclusion: GTA有效压缩了KV缓存和注意力计算，大幅提升了大模型的推理速度和部署效率，同时几乎不牺牲模型性能。其创新性机制为资源受限硬件上的LLM部署带来了实际价值。

Abstract: Attention mechanisms underpin the success of large language models (LLMs),
yet their substantial computational and memory overhead poses challenges for
optimizing efficiency and performance. A critical bottleneck arises as KV cache
and attention computations scale rapidly with text length, challenging
deployment on hardware with limited computational and memory resources. We
observe that attention mechanisms exhibit substantial redundancy, since the KV
cache can be significantly compressed and attention maps across heads display
high similarity, revealing that much of the computation and storage is
unnecessary. Leveraging these insights, we propose \textbf{G}rouped-Head
Laten\textbf{T} \textbf{A}ttention (GTA), a novel attention mechanism that
reduces memory usage and computational complexity while maintaining
performance. GTA comprises two components: (1) a shared attention map mechanism
that reuses attention scores across multiple heads, decreasing the key cache
size; and (2) a nonlinear value decoder with learned projections that
compresses the value cache into a latent space, further cutting memory needs.
GTA cuts attention computation FLOPs by up to \emph{62.5\%} versus
Grouped-Query Attention and shrink the KV cache by up to \emph{70\%}, all while
avoiding the extra overhead of Multi-Head Latent Attention to improve LLM
deployment efficiency. Consequently, GTA models achieve a \emph{2x} increase in
end-to-end inference speed, with prefill benefiting from reduced computational
cost and decoding benefiting from the smaller cache footprint.

</details>


### [96] [AI-Generated Game Commentary: A Survey and a Datasheet Repository](https://arxiv.org/abs/2506.17294)
*Qirui Zheng,Xingbo Wang,Keyuan Cheng,Yunlong Lu,Wenxin Li*

Main category: cs.CL

TL;DR: 本文对AI生成游戏解说的任务、挑战、数据集和方法进行了全面综述，提出了通用框架，并开源结构化数据表，促进该领域研究和发展。


<details>
  <summary>Details</summary>
Motivation: AI生成的游戏解说（AIGGC）因其市场潜力和技术挑战逐渐受到关注。针对AIGGC涉及多模态自然语言处理任务，对语言模型提出了更高要求。

Method: 本文提出了一个通用的AIGGC框架，并对45个现有的游戏解说数据集和方法进行了全面调研，根据它们所应对的主要挑战进行分类，并对常用的评估指标进行归类和比较。同时，作者整理了数据集的结构化信息，并在附录及开源库中提供。

Result: 系统性总结了现有AIGGC数据集、方法及评估指标，对领域内主要挑战作了梳理和归类，并提供了结构化的开源数据资源。

Conclusion: 这项工作为AIGGC领域研究提供了全面的现状梳理和开放数据支持，为后续研究和评测奠定了基础。

Abstract: AI-Generated Game Commentary (AIGGC) has gained increasing attention due to
its market potential and inherent technical challenges. As a comprehensive
multimodal Natural Language Processing (NLP) task, AIGGC imposes substantial
demands on language models, including factual accuracy, logical reasoning,
expressive text generation, generation speed, and context management. In this
paper, we introduce a general framework for AIGGC and present a comprehensive
survey of 45 existing game commentary dataset and methods according to key
challenges they aim to address in this domain. We further classify and compare
various evaluation metrics commonly used in this domain. To support future
research and benchmarking, we also provide a structured datasheet summarizing
the essential attributes of these datasets in appendix, which is meanwhile
publicly available in an open repository.

</details>


### [97] [Semantic uncertainty in advanced decoding methods for LLM generation](https://arxiv.org/abs/2506.17296)
*Darius Foodeei,Simin Fan,Martin Jaggi*

Main category: cs.CL

TL;DR: 通过引入新型解码方法（CoT与推测采样），论文发现LLM输出多样性和准确性可兼得，结构化探索显著提升输出质量，对实际应用有重要指导价值。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）的输出受解码策略影响显著，但不同策略下语义多样性与可靠性之间的关系尚不明确。研究者期望通过新兴的采样方法与思维链（Chain-of-Thought, CoT）解码分析，探索结构化探索对输出质量和自信度的影响，为实际应用提供更优解码方案。

Method: 设计多项实验，涵盖问答、摘要和代码生成任务，对比分析常规与新型（如推测采样、思维链解码）解码方法下LLM输出的语义多样性与可靠性。通过评估不同指标（如预测熵、Pass@2、ROUGE分数等）量化各策略效果。

Result: 思维链解码能提升输出语义多样性，并显著降低预测熵，实现更自信、更准确输出。例如，代码生成任务Pass@2提升48.8%，尽管与参考答案一致性略降。摘要任务中推测采样ROUGE分数亦优，整体表现出较优语义多样性和准确性的权衡。

Conclusion: 结构化解码策略不仅能增加语言模型输出的语义探索范围，还能在保证甚至提升输出质量的前提下，缓解传统认为多样性与准确性互相制约的观念。该结论对实际部署LLM具有重要意义。

Abstract: This study investigates semantic uncertainty in large language model (LLM)
outputs across different decoding methods, focusing on emerging techniques like
speculative sampling and chain-of-thought (CoT) decoding. Through experiments
on question answering, summarization, and code generation tasks, we analyze how
different decoding strategies affect both the diversity and reliability of
model outputs. Our findings reveal that while CoT decoding demonstrates higher
semantic diversity, it maintains lower predictive entropy, suggesting that
structured exploration can lead to more confident and accurate outputs. This is
evidenced by a 48.8% improvement in code generation Pass@2 rates, despite lower
alignment with reference solutions. For summarization tasks, speculative
sampling proved particularly effective, achieving superior ROUGE scores while
maintaining moderate semantic diversity. Our results challenge conventional
assumptions about trade-offs between diversity and accuracy in language model
outputs, demonstrating that properly structured decoding methods can increase
semantic exploration while maintaining or improving output quality. These
findings have significant implications for deploying language models in
practical applications where both reliability and diverse solution generation
are crucial.

</details>


### [98] [Mercury: Ultra-Fast Language Models Based on Diffusion](https://arxiv.org/abs/2506.17298)
*Inception Labs,Samar Khanna,Siddhant Kharbanda,Shufan Li,Harshit Varma,Eric Wang,Sawyer Birnbaum,Ziyang Luo,Yanis Miraoui,Akash Palrecha,Stefano Ermon,Aditya Grover,Volodymyr Kuleshov*

Main category: cs.CL

TL;DR: 该论文提出了基于扩散机制的代码大模型Mercury Coder，速度相较于现有模型提升高达10倍，同时保持甚至提升了代码生成质量，已在多个公开测试及真实开发场景中获得领先表现，并已开放API与试玩平台。


<details>
  <summary>Details</summary>
Motivation: 近年来大语言模型（LLM）在代码生成等实际任务中已成为主流技术，但在提升模型质量的同时，推理速度成为大规模商用部署的一大瓶颈。该论文旨在突破速度与质量之间的权衡，实现更快且高质量的代码生成大模型。

Method: 提出了一种基于扩散（diffusion）机制的大语言模型 Mercury，并采用Transformer结构来实现多token并行预测。以代码生成任务为例，开发了Mercury Coder系列模型，包括Mini和Small两个版本，并在商用硬件平台上实现优化。

Result: Mercury Coder Mini和Small在NVIDIA H100 GPU上的吞吐量分别达到1109 tokens/sec和737 tokens/sec，速度显著超过现有主流高效代码生成模型，且在质量上基本持平或取得领先。同时在多个代码基准测试、主流编程语言和实际开发应用场景（如Copilot Arena）中表现优异。

Conclusion: 基于扩散机制的LLM（Mercury Coder）在代码生成任务上实现了商用级别的速度与质量突破，为大规模部署提供了新的解决方案。

Abstract: We present Mercury, a new generation of commercial-scale large language
models (LLMs) based on diffusion. These models are parameterized via the
Transformer architecture and trained to predict multiple tokens in parallel. In
this report, we detail Mercury Coder, our first set of diffusion LLMs designed
for coding applications. Currently, Mercury Coder comes in two sizes: Mini and
Small. These models set a new state-of-the-art on the speed-quality frontier.
Based on independent evaluations conducted by Artificial Analysis, Mercury
Coder Mini and Mercury Coder Small achieve state-of-the-art throughputs of 1109
tokens/sec and 737 tokens/sec, respectively, on NVIDIA H100 GPUs and outperform
speed-optimized frontier models by up to 10x on average while maintaining
comparable quality. We discuss additional results on a variety of code
benchmarks spanning multiple languages and use-cases as well as real-world
validation by developers on Copilot Arena, where the model currently ranks
second on quality and is the fastest model overall. We also release a public
API at https://platform.inceptionlabs.ai/ and free playground at
https://chat.inceptionlabs.ai

</details>


### [99] [PRAISE: Enhancing Product Descriptions with LLM-Driven Structured Insights](https://arxiv.org/abs/2506.17314)
*Adnan Qidwai,Srija Mukhopadhyay,Prerana Khatiwada,Dan Roth,Vivek Gupta*

Main category: cs.CL

TL;DR: 本研究提出PRAISE系统，利用大型语言模型自动对电商商品评论与描述进行信息提取与结构化，对强化商品信息质量、提升买卖双方体验有重要价值。


<details>
  <summary>Details</summary>
Motivation: 电商平台上商品描述的重要性日益突出，但卖家提供的信息常常不全面或不准确。客户评论包含了丰富而真实的细节，但人工筛查这些评论既费时又低效，因此亟需自动化工具来提升信息质量与使用效率。

Method: 提出了一种新系统PRAISE：通过大型语言模型（LLMs）自动从用户评论和卖家描述中提取、比较并结构化产品信息。该系统能直观展示两者之间缺失、矛盾或部分匹配的信息，并提供评论证据。用户界面便捷，帮助识别关键信息差异。

Result: PRAISE系统能够有效地从海量非结构化评论中生成结构化、可操作的见解，显著提升商品描述的准确性与说服力。演示显示其在改善电商目录可信度与质量方面有显著潜力。

Conclusion: PRAISE能自动梳理买家评论与卖家描述间的信息差异，为改善商品展示和提升用户决策体验提供了有力工具，对电商生态的健康发展具有积极作用。

Abstract: Accurate and complete product descriptions are crucial for e-commerce, yet
seller-provided information often falls short. Customer reviews offer valuable
details but are laborious to sift through manually. We present PRAISE: Product
Review Attribute Insight Structuring Engine, a novel system that uses Large
Language Models (LLMs) to automatically extract, compare, and structure
insights from customer reviews and seller descriptions. PRAISE provides users
with an intuitive interface to identify missing, contradictory, or partially
matching details between these two sources, presenting the discrepancies in a
clear, structured format alongside supporting evidence from reviews. This
allows sellers to easily enhance their product listings for clarity and
persuasiveness, and buyers to better assess product reliability. Our
demonstration showcases PRAISE's workflow, its effectiveness in generating
actionable structured insights from unstructured reviews, and its potential to
significantly improve the quality and trustworthiness of e-commerce product
catalogs.

</details>


### [100] [Towards Safety Evaluations of Theory of Mind in Large Language Models](https://arxiv.org/abs/2506.17352)
*Tatsuhiro Aoshima,Mitsuaki Akiyama*

Main category: cs.CL

TL;DR: 本文指出，尽管大语言模型的理解能力增强，但理论心理（即理解和推断他人意图及认知状态的能力）并未同步提升。该因素是评估模型安全性、检测欺骗性行为的核心。文中系统性评估了开源LLMs在该方面的发展，结果显示理论心理能力提升有限，现阶段安全评估和风险识别依然困难。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）能力的提升，模型安全性评估需求日益迫切，尤其是有关模型可能以隐蔽和欺骗性方式绕过监管机制的担忧。作者希望确认LLMs是否存在通过理论型心理机制有意掩饰行为的风险。

Method: 回顾和分析关于理论心理（theory of mind）的现有研究，提炼其在安全评估中的相关任务和视角，然后选取多个开源权重LLMs，通过与心理发展趋势相关的任务评估其理论心理能力发展情况。

Result: LLMs在阅读理解能力方面取得了显著进步，但其理论心理能力的发展并不明显，与阅读理解的提升不相当。

Conclusion: 目前LLMs的理论心理能力有限，在安全评估中特别是在识别潜在欺骗行为方面仍面临重大挑战，未来仍需针对其理论心理能力的提升进行深入研究。

Abstract: As the capabilities of large language models (LLMs) continue to advance, the
importance of rigorous safety evaluation is becoming increasingly evident.
Recent concerns within the realm of safety assessment have highlighted
instances in which LLMs exhibit behaviors that appear to disable oversight
mechanisms and respond in a deceptive manner. For example, there have been
reports suggesting that, when confronted with information unfavorable to their
own persistence during task execution, LLMs may act covertly and even provide
false answers to questions intended to verify their behavior.To evaluate the
potential risk of such deceptive actions toward developers or users, it is
essential to investigate whether these behaviors stem from covert, intentional
processes within the model. In this study, we propose that it is necessary to
measure the theory of mind capabilities of LLMs. We begin by reviewing existing
research on theory of mind and identifying the perspectives and tasks relevant
to its application in safety evaluation. Given that theory of mind has been
predominantly studied within the context of developmental psychology, we
analyze developmental trends across a series of open-weight LLMs. Our results
indicate that while LLMs have improved in reading comprehension, their theory
of mind capabilities have not shown comparable development. Finally, we present
the current state of safety evaluation with respect to LLMs' theory of mind,
and discuss remaining challenges for future work.

</details>


### [101] [Cash or Comfort? How LLMs Value Your Inconvenience](https://arxiv.org/abs/2506.17367)
*Mateusz Cedro,Timour Ichmoukhamedov,Sofie Goethals,Yifan He,James Hinns,David Martens*

Main category: cs.CL

TL;DR: 本研究发现几种主流大语言模型对用户不适的金钱价值评估非常不一致且容易受提示措辞影响，偶尔还会做出违背常理的决策。这表明现有LLMs不可靠于处理涉及用户舒适与金钱权衡的决策问题，需要进一步改进。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）正被用作能够替人类进行日常决策的近自主人工智能代理，但其在涉及金钱与用户舒适度权衡的个人决策行为尚未被充分研究。

Method: 通过让多个LLM针对不同类型用户不适（额外步行、等待、饥饿和疼痛），量化其所需补偿价格，并分析LLM之间及同一LLM内对提示变化的反应差异。

Result: 发现1）不同LLM给出的补偿价格差异极大；2）单个LLM对提示方式非常敏感，轻微措辞变化就会显著改变决策；3）LLM往往愿意以极低补偿接受重大不便（如用1欧元换取10小时等待）；4）在没有任何不适的情况下，LLM有时会拒绝明显奖励（如1000欧元换0分钟等待）。

Conclusion: 当前LLMs在衡量人类不便的金钱价值方面存在严重不一致和漏洞，因此在作为决策助手应用时有必要进行更严谨的审查，特别是在涉及金钱与舒适权衡的场景。

Abstract: Large Language Models (LLMs) are increasingly proposed as near-autonomous
artificial intelligence (AI) agents capable of making everyday decisions on
behalf of humans. Although LLMs perform well on many technical tasks, their
behaviour in personal decision-making remains less understood. Previous studies
have assessed their rationality and moral alignment with human decisions.
However, the behaviour of AI assistants in scenarios where financial rewards
are at odds with user comfort has not yet been thoroughly explored. In this
paper, we tackle this problem by quantifying the prices assigned by multiple
LLMs to a series of user discomforts: additional walking, waiting, hunger and
pain. We uncover several key concerns that strongly question the prospect of
using current LLMs as decision-making assistants: (1) a large variance in
responses between LLMs, (2) within a single LLM, responses show fragility to
minor variations in prompt phrasing (e.g., reformulating the question in the
first person can considerably alter the decision), (3) LLMs can accept
unreasonably low rewards for major inconveniences (e.g., 1 Euro to wait 10
hours), and (4) LLMs can reject monetary gains where no discomfort is imposed
(e.g., 1,000 Euro to wait 0 minutes). These findings emphasize the need for
scrutiny of how LLMs value human inconvenience, particularly as we move toward
applications where such cash-versus-comfort trade-offs are made on users'
behalf.

</details>


### [102] [Leveraging LLMs to Assess Tutor Moves in Real-Life Dialogues: A Feasibility Study](https://arxiv.org/abs/2506.17410)
*Danielle R. Thomas,Conrad Borchers,Jionghao Lin,Sanjit Kakarla,Shambhavi Bhushan,Erin Gatz,Shivang Gupta,Ralph Abboud,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: 本文证明了以GPT-4等大模型分析家教语音转录文本，能高效、准确评估关键家教行为，且与人工判断高度一致，提出了可扩展低成本的AI辅助家教评估方案，并开放提示词促进可复现性。


<details>
  <summary>Details</summary>
Motivation: 传统的家教在提升学生学习成绩上效果显著，但如何基于大规模音频转录记录自动识别和研究有效的家教行为仍是难题。本文旨在探索采用生成式AI（尤其大语言模型）来高效、可扩展地识别和评估真实数学家教过程中的关键行为。

Method: 对50份真实的大学生远程辅导中学生数学的音频转录文本，分别用GPT-4、GPT-4o、GPT-4-turbo、Gemini-1.5-pro和LearnLM五个大模型，检测两个关键家教技能：有效称赞和对学生数学错误的回应。评估这些模型检测相关场景（如家教称赞学生、学生出现错误）的准确率，以及模型判断辅导行为是否符合最佳实践的表现，并与人工标注结果进行比对。

Result: 各大语言模型都能较高准确率检测关键情境（如称赞检测准确率为94-98%，错误检测为82-88%）；模型评判家教是否符合最佳实践的结果与人工一致性较高（分别为83-89%和73-77%）。论文还提出了一种性价比高的模型提示词策略，并开放相关提示词以促进可复现性。

Conclusion: 生成式大语言模型可以准确、高效地在大规模真实家教场景中检测和评价关键教学行为，为AI辅助的大规模家教评价和教育研究提供了可行路径。论文建议相关研究者和实践者可借助这些模型与策略，实现低成本、高效的家教过程分析和反馈。

Abstract: Tutoring improves student achievement, but identifying and studying what
tutoring actions are most associated with student learning at scale based on
audio transcriptions is an open research problem. This present study
investigates the feasibility and scalability of using generative AI to identify
and evaluate specific tutor moves in real-life math tutoring. We analyze 50
randomly selected transcripts of college-student remote tutors assisting middle
school students in mathematics. Using GPT-4, GPT-4o, GPT-4-turbo,
Gemini-1.5-pro, and LearnLM, we assess tutors' application of two tutor skills:
delivering effective praise and responding to student math errors. All models
reliably detected relevant situations, for example, tutors providing praise to
students (94-98% accuracy) and a student making a math error (82-88% accuracy)
and effectively evaluated the tutors' adherence to tutoring best practices,
aligning closely with human judgments (83-89% and 73-77%, respectively). We
propose a cost-effective prompting strategy and discuss practical implications
for using large language models to support scalable assessment in authentic
settings. This work further contributes LLM prompts to support reproducibility
and research in AI-supported learning.

</details>


### [103] [UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making](https://arxiv.org/abs/2506.17419)
*Jinhao Duan,James Diffenderfer,Sandeep Madireddy,Tianlong Chen,Bhavya Kailkhura,Kaidi Xu*

Main category: cs.CL

TL;DR: 大语言模型多步决策不确定性长期被忽视。作者提出UProp算法，有效分解与量化外在不确定性，在多个多步任务和SOTA模型上显著超越现有基线，为实际应用中的LLM安全可靠决策提供新工具。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）被广泛应用于安全关键场景，自主决策逐步融入现实世界。为了提升模型可用性，研究何时可以信任这些决策变得尤为重要。但现有的不确定性量化（UQ）方法主要面向单步问答任务，缺乏对多步决策情景的有效探索与工具。

Method: 本文提出了一个基于信息论的分解框架，将LLM在连续决策过程中的不确定性分为内在不确定性（特定决策点本身的不确定性，现有UQ覆盖）和外在不确定性（来自前序决策的信息不确定性，使用互信息量化）。进而，文中提出了UProp算法，通过对多个轨迹相关决策过程（TDP）中的点互信息（PMI）进行估算，有效、高效地估算外在不确定性。

Result: UProp在多步决策任务（如AgentBench和HotpotQA）和前沿LLM（GPT-4.1、DeepSeek-V3）上进行了大量实证测试，显著优于单步不确定性量化基线（考虑先进聚合策略）的方法。同时给出了详细的采样效率分析、应用前景探讨以及中间不确定性传递机制，有力论证了UProp的有效性。

Conclusion: 本文开创性地提出并验证了LLM多步决策场景下的外在不确定性量化方法UProp，填补了现有方法在连续决策不确定性建模方面的不足，为提升LLM在安全关键任务中的可靠性与可信性奠定基础。

Abstract: As Large Language Models (LLMs) are integrated into safety-critical
applications involving sequential decision-making in the real world, it is
essential to know when to trust LLM decisions. Existing LLM Uncertainty
Quantification (UQ) methods are primarily designed for single-turn
question-answering formats, resulting in multi-step decision-making scenarios,
e.g., LLM agentic system, being underexplored. In this paper, we introduce a
principled, information-theoretic framework that decomposes LLM sequential
decision uncertainty into two parts: (i) internal uncertainty intrinsic to the
current decision, which is focused on existing UQ methods, and (ii) extrinsic
uncertainty, a Mutual-Information (MI) quantity describing how much uncertainty
should be inherited from preceding decisions. We then propose UProp, an
efficient and effective extrinsic uncertainty estimator that converts the
direct estimation of MI to the estimation of Pointwise Mutual Information (PMI)
over multiple Trajectory-Dependent Decision Processes (TDPs). UProp is
evaluated over extensive multi-step decision-making benchmarks, e.g.,
AgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and
DeepSeek-V3. Experimental results demonstrate that UProp significantly
outperforms existing single-turn UQ baselines equipped with thoughtful
aggregation strategies. Moreover, we provide a comprehensive analysis of UProp,
including sampling efficiency, potential applications, and intermediate
uncertainty propagation, to demonstrate its effectiveness. Codes will be
available at https://github.com/jinhaoduan/UProp.

</details>


### [104] [Beyond the Link: Assessing LLMs' ability to Classify Political Content across Global Media](https://arxiv.org/abs/2506.17435)
*Alberto Martinez-Serra,Alejandro De La Fuente,Nienke Viescher,Ana S. Cardenal*

Main category: cs.CL

TL;DR: 本文系统评估多种大语言模型仅利用URL区分新闻政治内容的能力，发现结果与全文分析和人工标注接近，为政治科学研究提供了高效可行的新方法，并给出了实际应用建议。


<details>
  <summary>Details</summary>
Motivation: 近年来，大语言模型（LLM）在政治科学、特别是数字媒体分析中的应用变得日益普遍。尽管现有研究已证明LLM在标注任务上的能力，但其仅通过URL对政治内容进行分类的有效性尚未被充分探讨。

Method: 本研究通过评估LLM（包括GPT、Llama、Mistral、Deepseek、Qwen和Gemma）识别PC（政治内容）与非PC的准确性，比较了模型基于文章全文和仅URL进行分类的表现。数据涵盖法国、德国、西班牙、英国和美国的多语言新闻。通过与人工标注和传统监督学习基线方法进行对比，验证LLM能力。

Result: 实验结果表明，URL中往往包含了大部分新闻内容信息，LLM仅通过URL对政治内容进行分类的效果与人工标注和全文分析的结果接近。

Conclusion: LLM基于URL对新闻政治属性分类具有较强能力，为政治科学中的效率与准确性平衡提供了新思路。研究还讨论了当前方法的局限性，并提出了在政治科学中应用LLM的具体方法建议。

Abstract: The use of large language models (LLMs) is becoming common in the context of
political science, particularly in studies that analyse individuals use of
digital media. However, while previous research has demonstrated LLMs ability
at labelling tasks, the effectiveness of using LLMs to classify political
content (PC) from just URLs is not yet well explored. The work presented in
this article bridges this gap by evaluating whether LLMs can accurately
identify PC vs. non-PC from both the article text and the URLs from five
countries (France, Germany, Spain, the UK, and the US) and different languages.
Using cutting-edge LLMs like GPT, Llama, Mistral, Deepseek, Qwen and Gemma, we
measure model performance to assess whether URL-level analysis can be a good
approximation for full-text analysis of PC, even across different linguistic
and national contexts. Model outputs are compared with human-labelled articles,
as well as traditional supervised machine learning techniques, to set a
baseline of performance. Overall, our findings suggest the capacity of URLs to
embed most of the news content, providing a vital perspective on accuracy-cost
balancing. We also account for contextual limitations and suggest
methodological recommendations to use LLMs within political science studies.

</details>


### [105] [Breaking the Transcription Bottleneck: Fine-tuning ASR Models for Extremely Low-Resource Fieldwork Languages](https://arxiv.org/abs/2506.17459)
*Siyu Liang,Gina-Anne Levow*

Main category: cs.CL

TL;DR: 论文比较分析了MMS和XLS-R两种多语种语音识别模型在低资源语言下的表现，提出在训练数据极少时选MMS，数据量足够时用XLS-R，并为田野语言学者提供了具体且可操作的ASR使用建议。


<details>
  <summary>Details</summary>
Motivation: 尽管ASR在高资源语言上表现优异，但面对田野调查场景下的低资源、噪音与自然口语数据仍有诸多局限。该研究旨在提升ASR在语言学田野工作的实际应用价值，尤其是缓解少数及濒危语言资料的转录难题。

Method: 对两种经过微调的多语种ASR模型——MMS与XLS-R，在五种类型多样的低资源语言上进行基准测试，并控制训练数据的时间长度，检测其在田野录音数据上的表现。

Result: MMS模型在极小训练数据下效果更好；XLS-R一旦训练数据量超过一小时性能与MMS相当。研究还对ASR模型适应性进行语言学视角分析，并为实际田野工作提供复现性强的解决路径。

Conclusion: 本研究表明：针对田野语言录音数据，当训练数据量极少时，MMS模型表现更好；而当训练数据超过一小时时，XLS-R模型表现可与MMS持平。通过语言学分析，为田野语言学工作者提供了实用的ASR选型和适应建议，从而缓解语言文献整理过程中的转录瓶颈。

Abstract: Automatic Speech Recognition (ASR) has reached impressive accuracy for
high-resource languages, yet its utility in linguistic fieldwork remains
limited. Recordings collected in fieldwork contexts present unique challenges,
including spontaneous speech, environmental noise, and severely constrained
datasets from under-documented languages. In this paper, we benchmark the
performance of two fine-tuned multilingual ASR models, MMS and XLS-R, on five
typologically diverse low-resource languages with control of training data
duration. Our findings show that MMS is best suited when extremely small
amounts of training data are available, whereas XLS-R shows parity performance
once training data exceed one hour. We provide linguistically grounded analysis
for further provide insights towards practical guidelines for field linguists,
highlighting reproducible ASR adaptation approaches to mitigate the
transcription bottleneck in language documentation.

</details>


### [106] [Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems](https://arxiv.org/abs/2506.17467)
*Weixin Liang*

Main category: cs.CL

TL;DR: 本论文系统研究了语言大模型（LLMs）普及对个人和机构带来的影响，揭示AI检测工具可能导致的群体性不公，以及LLMs在各类写作场景中的广泛应用，并证实LLMs可为资源有限的研究者提供有效学术反馈。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的快速普及对个人和机构带来了重大影响。研究迫切需要探讨：1）AI检测器带来的公正性和偏见问题，2）LLMs在写作领域的普及现状和影响，3）LLMs对学术写作反馈的潜力及其在资源有限环境下对研究人员的支持作用。

Method: 论文采用三条研究路径：第一，实证分析AI检测器的使用及其对不同语言背景作者的影响；第二，设计并应用群体级的算法方法，定量检测LLMs在多个写作领域的应用；第三，进行大规模实证分析LLMs为研究手稿提供反馈的能力及其效果。

Result: 发现AI检测器在制度化使用中系统性地歧视非主流语言作者，产生公平问题。通过大规模数据分析，揭示LLMs已在学术评审、科学文献、消费者投诉、公司沟通、招聘信息及国际组织新闻稿中被广泛使用。最后，证实LLMs可为学术手稿提供有益反馈，有助于弥补早期研究人员和欠资源环境下研究者的反馈缺口。

Conclusion: 本文指出，LLMs的普及在带来便利的同时也引入了风险与不平等，尤其是AI检测工具可能引发的群体性偏见。制度在采用AI工具时应重视公平与包容性。同时，LLMs可作为提升学术写作支持和公平性的重要工具，尤其能帮助弱势群体获得研究反馈。

Abstract: Large language models (LLMs) have shown significant potential to change how
we write, communicate, and create, leading to rapid adoption across society.
This dissertation examines how individuals and institutions are adapting to and
engaging with this emerging technology through three research directions.
First, I demonstrate how the institutional adoption of AI detectors introduces
systematic biases, particularly disadvantaging writers of non-dominant language
varieties, highlighting critical equity concerns in AI governance. Second, I
present novel population-level algorithmic approaches that measure the
increasing adoption of LLMs across writing domains, revealing consistent
patterns of AI-assisted content in academic peer reviews, scientific
publications, consumer complaints, corporate communications, job postings, and
international organization press releases. Finally, I investigate LLMs'
capability to provide feedback on research manuscripts through a large-scale
empirical analysis, offering insights into their potential to support
researchers who face barriers in accessing timely manuscript feedback,
particularly early-career researchers and those from under-resourced settings.

</details>


### [107] [VeriLocc: End-to-End Cross-Architecture Register Allocation via LLM](https://arxiv.org/abs/2506.17506)
*Lesheng Jin,Zhenyuan Ruan,Haohui Mai,Jingbo Shang*

Main category: cs.CL

TL;DR: VeriLocc结合LLM和正式验证，实现高效、泛化且准确的GPU寄存器分配，性能超越业界专家手工调优方案。


<details>
  <summary>Details</summary>
Motivation: 现有GPU的编译器寄存器分配依赖人工设计的启发式算法，每更换硬件时需大量调优，效率低下、难以泛化。

Method: 提出了VeriLocc框架，将大语言模型与形式化编译技术结合。框架通过微调LLM，将中间表示(MIR)翻译为目标寄存器分配，并结合静态分析实现跨架构的归一化和泛化，还引入了验证驱动的重生循环以保证正确性。

Result: 在GEMM和MHA任务上，VeriLocc实现了85-99%的单次准确率和近100%的pass@100，个案显示其分配优于专家调优库，运行时间比rocBLAS快10%以上。

Conclusion: VeriLocc能泛化且可验证地提升GPU寄存器分配效率和性能，优于传统手工启发式与专家库，展现了LLM结合形式化技术在编译器优化的潜力。

Abstract: Modern GPUs evolve rapidly, yet production compilers still rely on
hand-crafted register allocation heuristics that require substantial re-tuning
for each hardware generation. We introduce VeriLocc, a framework that combines
large language models (LLMs) with formal compiler techniques to enable
generalizable and verifiable register allocation across GPU architectures.
VeriLocc fine-tunes an LLM to translate intermediate representations (MIRs)
into target-specific register assignments, aided by static analysis for
cross-architecture normalization and generalization and a verifier-guided
regeneration loop to ensure correctness. Evaluated on matrix multiplication
(GEMM) and multi-head attention (MHA), VeriLocc achieves 85-99% single-shot
accuracy and near-100% pass@100. Case study shows that VeriLocc discovers more
performant assignments than expert-tuned libraries, outperforming rocBLAS by
over 10% in runtime.

</details>


### [108] [Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning](https://arxiv.org/abs/2506.17525)
*Mingfei Lau,Qian Chen,Yeming Fang,Tingting Xu,Tongzhou Chen,Pavel Golik*

Main category: cs.CL

TL;DR: 对主流多语言语音数据集的质量进行了系统分析，发现欠资源语言面临更严重的宏观质量问题，并以台语为例提出了改进建议，呼吁在数据集建设中重视社会语言学因素。


<details>
  <summary>Details</summary>
Motivation: 目前主流多语言语音数据集在部分语言上存在严重的质量问题，尤其对欠资源语言影响更大，急需提升数据集的质量以促进训练和评估的有效性。

Method: 对Mozilla Common Voice 17.0、FLEURS和VoxPopuli三个主流多语言语音数据集进行质量审计，并以台语（台灣閩南語）为案例分析，归纳数据集问题并提出改进方案。

Result: 发现宏观质量问题在欠资源语言中更突出，对台语数据集深入剖析，并提出未来数据集开发的指导原则和优化建议，以提升ASR数据集整体质量。

Conclusion: 提出了改善多语言语音数据集质量的建议，并强调了社会语言学意识在数据集创建中的重要性。

Abstract: Our quality audit for three widely used public multilingual speech datasets -
Mozilla Common Voice 17.0, FLEURS, and VoxPopuli - shows that in some
languages, these datasets suffer from significant quality issues. We believe
addressing these issues will make these datasets more useful as training and
evaluation sets, and improve downstream models. We divide these quality issues
into two categories: micro-level and macro-level. We find that macro-level
issues are more prevalent in less institutionalized, often under-resourced
languages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that
highlights the need for proactive language planning (e.g. orthography
prescriptions, dialect boundary definition) and enhanced data quality control
in the process of Automatic Speech Recognition (ASR) dataset creation. We
conclude by proposing guidelines and recommendations to mitigate these issues
in future dataset development, emphasizing the importance of sociolinguistic
awareness in creating robust and reliable speech data resources.

</details>


### [109] [DuaShepherd: Integrating Stepwise Correctness and Potential Rewards for Mathematical Reasoning](https://arxiv.org/abs/2506.17533)
*Yuanhao Wu,Juntong Song,Hanning Zhang,Tong Zhang,Cheng Niu*

Main category: cs.CL

TL;DR: 该文提出结合“正确性”和“潜力”的双奖励信号，用于训练大型语言模型数学能力。新方法在多个数据集上大幅提升模型表现，创下最新最佳成绩。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在数学推理任务中的能力还有提升空间。传统的奖励建模多以“正确性”为单一奖励信号，忽略了模型在推理过程中的发展潜力。该文提出结合两种互补奖励信号，以提升模型推理和解题能力。

Method: 提出DuaShepherd奖励建模框架，结合“正确性”（纠错能力）和“潜力”（抵达正确答案的可能性）两种信号。开发自动化数据集构建流程，生成含两种奖励大规模训练数据。采用多头多任务架构，联合训练两种奖励模型，并组合为复合概率用于最终评估。

Result: 在MATH500和ProcessBench基准测试中，DuaShepherd在相同算力资源下，比仅使用单一奖励信号的模型取得更好成绩，实现了新的最优结果。

Conclusion: 结合正确性与潜力的奖励信号能协同提升LLM的数学推理能力，DuaShepherd实现了业界领先表现，证明双信号奖励策略有效。

Abstract: In this paper, we propose DuaShepherd, a novel reward modeling framework that
integrates two complementary reward signals, correctness and potential, to
enhance the mathematical reasoning capabilities of Large Language Models
(LLMs). While correctness-based signals emphasize identification of stepwise
errors, potential-based signals focus on the likelihood of reaching the correct
final answer. We developed an automated pipeline for constructing large-scale
reward modeling dataset with both signals. A unified, multi-head architecture
was explored to train the two reward models in a multi-task setup,
demonstrating benefits from learning both correctness and potential in
parallel. By combining these two signals into a compound probability, our model
achieves consistent performance improvements across multiple benchmarks.
Empirical evaluations on MATH500 and ProcessBench confirm that this combined
reward significantly outperforms models trained on either reward type alone,
achieving state-of-the-art performance under comparable resource constraints.

</details>


### [110] [Probing for Phonology in Self-Supervised Speech Representations: A Case Study on Accent Perception](https://arxiv.org/abs/2506.17542)
*Nitin Venkateswaran,Kevin Tang,Ratree Wayland*

Main category: cs.CL

TL;DR: 本研究发现，当前自监督语音模型的预训练特征可以有效捕捉影响口音感知的音系特征变化，并能够有解释性地建模口音强度。


<details>
  <summary>Details</summary>
Motivation: 传统的口音感知模型低估了语音特征的梯度变化对听众作出口音判断的作用。本研究旨在深入了解自监督学习（SSL）语音模型预训练表示是否能够有效编码在口音感知中关键的音系特征变化。

Method: 聚焦于三种特定辅音（唇齿近音、闪音r、卷舌塞音），从CSLU外国口音英语语料库中提取相关片段，结合Phonet工具提取音系特征概率，以及利用Wav2Vec2-BERT和WavLM等模型的预训练表示，并结合美语母语者的口音判断。用探查式分析和多项Logistic回归，考察预训练特征与口音感知间的关系。

Result: 发现能够较好预测口音强度的是一部分预训练的分段表示特征，其中感知显著的音系特征（区分美式英语和印度次大陆英语）获得了较高权重。以预训练表示为基础的片段与美式英语和印度英语基线之间的距离与口音强度评分有显著关联，方向符合预期。

Conclusion: 自监督语音表示在建模基于可解释音系特征的口音感知方面具有重要价值。

Abstract: Traditional models of accent perception underestimate the role of gradient
variations in phonological features which listeners rely upon for their accent
judgments. We investigate how pretrained representations from current
self-supervised learning (SSL) models of speech encode phonological
feature-level variations that influence the perception of segmental accent. We
focus on three segments: the labiodental approximant, the rhotic tap, and the
retroflex stop, which are uniformly produced in the English of native speakers
of Hindi as well as other languages in the Indian sub-continent. We use the
CSLU Foreign Accented English corpus (Lander, 2007) to extract, for these
segments, phonological feature probabilities using Phonet (V\'asquez-Correa et
al., 2019) and pretrained representations from Wav2Vec2-BERT (Barrault et al.,
2023) and WavLM (Chen et al., 2022) along with accent judgements by native
speakers of American English. Probing analyses show that accent strength is
best predicted by a subset of the segment's pretrained representation features,
in which perceptually salient phonological features that contrast the expected
American English and realized non-native English segments are given prominent
weighting. A multinomial logistic regression of pretrained representation-based
segment distances from American and Indian English baselines on accent ratings
reveals strong associations between the odds of accent strength and distances
from the baselines, in the expected directions. These results highlight the
value of self-supervised speech representations for modeling accent perception
using interpretable phonological features.

</details>


### [111] [AgriCHN: A Comprehensive Cross-domain Resource for Chinese Agricultural Named Entity Recognition](https://arxiv.org/abs/2506.17578)
*Lingxiao Zeng,Yiqi Tong,Wei Guo,Huarui Wu,Lihao Ge,Yijun Ye,Fuzhen Zhuang,Deqing Wang,Wei Guo,Cheng Chen*

Main category: cs.CL

TL;DR: 本论文提出了AgriCHN，一个覆盖农业、水文、气象等领域的高质量中文农业NER数据集。数据质量优良，类别丰富，为NER方法研究提供了有价值的新资源和实验平台。


<details>
  <summary>Details</summary>
Motivation: 农业命名实体识别（NER）任务对于从大量农业文本中提取信息非常关键。然而，受限于高质量农业数据集（特别是中文资源）的稀缺，现有主流方法效果不佳。此外，既有工作多聚焦于农业实体本身，忽视了农业与水文、气象等领域的深度相关。

Method: 研究者提出了AgriCHN，这是一个面向中文农业领域的综合性开源资源。数据集来自大量农业相关文章，包含4,040个句子和15,799个实体提及，涵盖27种多样的实体类别，包括水文和气象领域。通过对比实验评估数据集质量，并基于多种主流神经网络NER模型构建基准任务进行实验。

Result: AgriCHN数据集相较于相关资源质量更高，实体类型更丰富、划分更细致。实验结果表明AgriCHN具有较大挑战性和研究潜力。

Conclusion: AgriCHN极大丰富和提升了中文农业实体识别任务的数据资源基础，并为跨学科农业信息抽取研究提供了有力支撑。该数据集因挑战性强和覆盖面广，有望促进相关NER方法的进一步发展。

Abstract: Agricultural named entity recognition is a specialized task focusing on
identifying distinct agricultural entities within vast bodies of text,
including crops, diseases, pests, and fertilizers. It plays a crucial role in
enhancing information extraction from extensive agricultural text resources.
However, the scarcity of high-quality agricultural datasets, particularly in
Chinese, has resulted in suboptimal performance when employing mainstream
methods for this purpose. Most earlier works only focus on annotating
agricultural entities while overlook the profound correlation of agriculture
with hydrology and meteorology. To fill this blank, we present AgriCHN, a
comprehensive open-source Chinese resource designed to promote the accuracy of
automated agricultural entity annotation. The AgriCHN dataset has been
meticulously curated from a wealth of agricultural articles, comprising a total
of 4,040 sentences and encapsulating 15,799 agricultural entity mentions
spanning 27 diverse entity categories. Furthermore, it encompasses entities
from hydrology to meteorology, thereby enriching the diversity of entities
considered. Data validation reveals that, compared with relevant resources,
AgriCHN demonstrates outstanding data quality, attributable to its richer
agricultural entity types and more fine-grained entity divisions. A benchmark
task has also been constructed using several state-of-the-art neural NER
models. Extensive experimental results highlight the significant challenge
posed by AgriCHN and its potential for further research.

</details>


### [112] [Mind the Gap: Assessing Wiktionary's Crowd-Sourced Linguistic Knowledge on Morphological Gaps in Two Related Languages](https://arxiv.org/abs/2506.17603)
*Jonathan Sakunkoo,Annabella Sakunkoo*

Main category: cs.CL

TL;DR: 本文定制神经形态分析器，自动检验拉丁语和意大利语中众包（主要指维基词典）收集的缺陷动词的可靠性，发现维基词典对意语准确但对拉丁语有不足，强调了对此类数据自动质控的重要性，也为丰富形态学和稀有语言知识提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 形态缺陷性是语言学中一个有趣且研究不足的现象，指的是某些预期词形变化形式的缺失。传统资源难以全面覆盖这类稀有现象，因此实际分析和文档化极具挑战，尤其是在资料稀缺的语言中。人们常用维基百科和维基词典等众包资源作为替代，但这些资源的可靠性存在争议。

Method: 该研究定制了一种新型神经形态分析器，用于对拉丁语和意大利语语料库进行注释。基于这个大规模标注数据，进一步对从维基词典整理的缺陷动词列表进行计算验证。

Result: 结果显示，维基词典对于意大利语的形态缺陷词条高度可靠，但对拉丁语中列为缺陷的词条，有7%被语料证据判定为并非真正的缺陷形式。这揭示了众包资源在处理部分少见语言现象时的局限性。

Conclusion: 本研究为缺陷形态的研究尤其是在拉丁语、意大利语等形态丰富、但非英语的语言中，提供了大规模的自动化质控工具，推动了计算形态学和稀有语言知识的扩展。

Abstract: Morphological defectivity is an intriguing and understudied phenomenon in
linguistics. Addressing defectivity, where expected inflectional forms are
absent, is essential for improving the accuracy of NLP tools in morphologically
rich languages. However, traditional linguistic resources often lack coverage
of morphological gaps as such knowledge requires significant human expertise
and effort to document and verify. For scarce linguistic phenomena in
under-explored languages, Wikipedia and Wiktionary often serve as among the few
accessible resources. Despite their extensive reach, their reliability has been
a subject of controversy. This study customizes a novel neural morphological
analyzer to annotate Latin and Italian corpora. Using the massive annotated
data, crowd-sourced lists of defective verbs compiled from Wiktionary are
validated computationally. Our results indicate that while Wiktionary provides
a highly reliable account of Italian morphological gaps, 7% of Latin lemmata
listed as defective show strong corpus evidence of being non-defective. This
discrepancy highlights potential limitations of crowd-sourced wikis as
definitive sources of linguistic knowledge, particularly for less-studied
phenomena and languages, despite their value as resources for rare linguistic
features. By providing scalable tools and methods for quality assurance of
crowd-sourced data, this work advances computational morphology and expands
linguistic knowledge of defectivity in non-English, morphologically rich
languages.

</details>


### [113] [Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives](https://arxiv.org/abs/2506.18116)
*Batool Haider,Atmika Gorti,Aman Chadha,Manas Gaur*

Main category: cs.CL

TL;DR: 本文提出用多跳问答检测LLM心理健康话语中的细致交叉性偏见，评估4种主流模型，揭示各类偏见放大点，采用Few-shot去偏方法可显著降低偏见，为公平AI提供有力手段。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在心理健康领域有可能传播偏见，加剧对边缘群体的伤害，但现有检测模型交叉性偏见的系统方法有限。本文受此挑战驱动，旨在提出和验证一种系统化的检测方案。

Method: 提出多跳问答（MHQA）框架以系统检测心理健康话语中的LLM回复偏见；对IMHI数据集内容按照年龄、种族、性别和社会经济状态进行标签，分析不同人口交叉点的偏见；对Claude 3.5 Sonnet、Jamba 1.6、Gemma 3和Llama 4等四个LLM进行评估；采用角色扮演模拟和显式偏见消除两种去偏方法，并通过BBQ数据的few-shot 提示进行训练。

Result: MHQA方法在检测偏见方面优于传统方法，能识别顺推推理中偏见的放大点；两种去偏技术可通过few-shot prompting实现66-94%的偏见减少。

Conclusion: LLMs在心理健康话语中确实存在系统性偏见，甚至在细分人群交叉处放大。提出的MHQA检测框架和去偏技术为更公平的AI开发提供了有效工具和实践建议。

Abstract: Large Language Models (LLMs) in mental healthcare risk propagating biases
that reinforce stigma and harm marginalized groups. While previous research
identified concerning trends, systematic methods for detecting intersectional
biases remain limited. This work introduces a multi-hop question answering
(MHQA) framework to explore LLM response biases in mental health discourse. We
analyze content from the Interpretable Mental Health Instruction (IMHI) dataset
across symptom presentation, coping mechanisms, and treatment approaches. Using
systematic tagging across age, race, gender, and socioeconomic status, we
investigate bias patterns at demographic intersections. We evaluate four LLMs:
Claude 3.5 Sonnet, Jamba 1.6, Gemma 3, and Llama 4, revealing systematic
disparities across sentiment, demographics, and mental health conditions. Our
MHQA approach demonstrates superior detection compared to conventional methods,
identifying amplification points where biases magnify through sequential
reasoning. We implement two debiasing techniques: Roleplay Simulation and
Explicit Bias Reduction, achieving 66-94% bias reductions through few-shot
prompting with BBQ dataset examples. These findings highlight critical areas
where LLMs reproduce mental healthcare biases, providing actionable insights
for equitable AI development.

</details>


### [114] [TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting](https://arxiv.org/abs/2506.17609)
*Lincan Li,Eren Erman Ozguven,Yue Zhao,Guang Wang,Yiqun Xie,Yushun Dong*

Main category: cs.CL

TL;DR: TyphoFormer 结合数值和语言信息，极大提升了台风路径预测表现，特别适用于路径变化剧烈或观测数据稀少的场景。


<details>
  <summary>Details</summary>
Motivation: 台风路径预测对于预警和灾害响应非常关键，但现有 Transformer 模型虽然能处理人类和车辆的轨迹，却难以获得增强气象轨迹预测可靠性的上下文知识，特别是对于较稀疏的台风轨迹信息。

Method: 提出 TyphoFormer，一种融合自然语言描述作为辅助提示词的预测框架，利用大语言模型针对每个时间步生成简洁的气象文本描述，并将其作为特殊 token 与数值时间序列一起输入统一的 Transformer 编码器，从而结合文本和序列信息辅助路径预测。

Result: 在 HURDAT2 基准上，通过大量实验，TyphoFormer 在包括非线性路径变化和历史观测有限等复杂场景下，都显著优于其他最新方法。

Conclusion: TyphoFormer 能够有效利用语言提示融合气象上下文信息，大大提升台风轨迹预测的准确性和鲁棒性。

Abstract: Accurate typhoon track forecasting is crucial for early system warning and
disaster response. While Transformer-based models have demonstrated strong
performance in modeling the temporal dynamics of dense trajectories of humans
and vehicles in smart cities, they usually lack access to broader contextual
knowledge that enhances the forecasting reliability of sparse meteorological
trajectories, such as typhoon tracks. To address this challenge, we propose
TyphoFormer, a novel framework that incorporates natural language descriptions
as auxiliary prompts to improve typhoon trajectory forecasting. For each time
step, we use Large Language Model (LLM) to generate concise textual
descriptions based on the numerical attributes recorded in the North Atlantic
hurricane database. The language descriptions capture high-level meteorological
semantics and are embedded as auxiliary special tokens prepended to the
numerical time series input. By integrating both textual and sequential
information within a unified Transformer encoder, TyphoFormer enables the model
to leverage contextual cues that are otherwise inaccessible through numerical
features alone. Extensive experiments are conducted on HURDAT2 benchmark,
results show that TyphoFormer consistently outperforms other state-of-the-art
baseline methods, particularly under challenging scenarios involving nonlinear
path shifts and limited historical observations.

</details>


### [115] [Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review](https://arxiv.org/abs/2506.18199)
*Bushra Asseri,Estabrag Abdelaziz,Areej Al-Wabil*

Main category: cs.CL

TL;DR: 本文系统梳理了现有通过prompt工程缓解LLM对阿拉伯人和穆斯林偏见的方法，发现结构化多步流程效果最好。研究数量有限，未来需探索更具文化适应性的方法和评价体系。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在许多领域表现出色，但对阿拉伯人和穆斯林的文化偏见引发了伦理关切。这些偏见可能加剧有害的刻板印象和边缘化现象。尽管学界越来越关注LLMs的偏见，针对阿拉伯人和穆斯林表征的prompt工程技术尚未得到充分研究。

Method: 本文采用混合方法系统综述，遵循PRISMA指南和Kitchenham的系统综述方法，对2021-2024年间发表的8项实证研究进行了分析。这些研究关注的是缓解偏见的prompt工程策略。

Result: 研究发现了五类主要的prompt工程方法，分别为文化提示、情感预设、自我去偏技巧、结构化多步流程以及参数优化的连续prompt。这些方法均可减缓偏见，但对不同类型偏见和不同研究效果差异较大。其中，结构化多步流程最为有效，最高可将偏见减少87.7%，但需要更高技术门槛。文化提示方法则兼具可用性和较好效果。

Conclusion: prompt工程能够在无需接触模型参数的情况下缓解文化偏见，为阿拉伯人和穆斯林的公正表征提供了具有实际可行性的手段。但目前实证研究数量有限，存在明显研究空白。未来应开发文化自适应的提示技术、建立专属评价资源，并将prompt工程与其他去偏方法结合，以进一步消除偏见且保持模型实用性。

Abstract: Large language models have demonstrated remarkable capabilities across
various domains, yet concerns about cultural bias - particularly towards Arabs
and Muslims - pose significant ethical challenges by perpetuating harmful
stereotypes and marginalization. Despite growing recognition of bias in LLMs,
prompt engineering strategies specifically addressing Arab and Muslim
representation remain understudied. This mixed-methods systematic review
examines such techniques, offering evidence-based guidance for researchers and
practitioners. Following PRISMA guidelines and Kitchenham's systematic review
methodology, we analyzed 8 empirical studies published between 2021-2024
investigating bias mitigation strategies. Our findings reveal five primary
prompt engineering approaches: cultural prompting, affective priming,
self-debiasing techniques, structured multi-step pipelines, and
parameter-optimized continuous prompts. Although all approaches show potential
for reducing bias, effectiveness varied substantially across studies and bias
types. Evidence suggests that certain bias types may be more resistant to
prompt-based mitigation than others. Structured multi-step pipelines
demonstrated the highest overall effectiveness, achieving up to 87.7% reduction
in bias, though they require greater technical expertise. Cultural prompting
offers broader accessibility with substantial effectiveness. These results
underscore the accessibility of prompt engineering for mitigating cultural bias
without requiring access to model parameters. The limited number of studies
identified highlights a significant research gap in this critical area. Future
research should focus on developing culturally adaptive prompting techniques,
creating Arab and Muslim-specific evaluation resources, and integrating prompt
engineering with complementary debiasing methods to address deeper stereotypes
while maintaining model utility.

</details>


### [116] [OpusLM: A Family of Open Unified Speech Language Models](https://arxiv.org/abs/2506.17611)
*Jinchuan Tian,William Chen,Yifan Peng,Jiatong Shi,Siddhant Arora,Shikhar Bharadwaj,Takashi Maekaku,Yusuke Shinohara,Keita Goto,Xiang Yue,Huck Yang,Shinji Watanabe*

Main category: cs.CL

TL;DR: OpusLMs是一个7B规模的开源语音语言模型家族，在公开数据上预训练，性能优越，覆盖语音识别、语音合成和文本任务，完全开源，促进领域研究。


<details>
  <summary>Details</summary>
Motivation: 当前语音与语言模型领域缺乏大规模、开源并且表现优秀的基础语音语言模型（SpeechLM），许多现有模型缺乏透明性与可复现性，阻碍了该领域的进一步研究与创新。

Method: OpusLMs采用decoder-only文本语言模型作为初始化，并对其进行持续预训练，使用了213,000小时的语音-文本对与2920亿文本token。在模型设计方面，重点在于tokenization（分词方法）、多流语言模型结构和多阶段训练策略。同时，通过实验分析了模型规模扩展和退火式数据选择对于性能的影响。

Result: OpusLMs在语音识别、语音合成以及文本任务中均达到了与现有SpeechLMs可比甚至更优的性能。所有模型基于公开数据构建，具有高度透明性，完整开源了代码、数据、模型权重和训练日志。

Conclusion: OpusLMs作为开源、透明且大规模的语音语言模型，在多个任务上展现了优越性能，有助于推动语音语言模型的开放研究与发展。

Abstract: This paper presents Open Unified Speech Language Models (OpusLMs), a family
of open foundational speech language models (SpeechLMs) up to 7B. Initialized
from decoder-only text language models, the OpusLMs are continuously
pre-trained on 213K hours of speech-text pairs and 292B text-only tokens. We
demonstrate our OpusLMs achieve comparable (or even superior) performance with
existing SpeechLMs in speech recognition, speech synthesis, and text-only
capabilities. Technically, this paper articulates our SpeechLM designs on
tokenization, multi-stream language models, and multi-stage training
strategies. We experimentally demonstrate the importance of model size scaling
and the effect of annealing data selection. The OpusLMs are all built from
publicly available materials and are fully transparent models. We release our
code, data, checkpoints, and training logs to facilitate open SpeechLM research

</details>


### [117] [A Modular Taxonomy for Hate Speech Definitions and Its Impact on Zero-Shot LLM Classification Performance](https://arxiv.org/abs/2506.18576)
*Matteo Melis,Gabriella Lapesa,Dennis Assenmacher*

Main category: cs.CL

TL;DR: 本文分析了仇恨言论不同定义对大模型检测效果的影响，提出14个概念要素的分类体系。实验表明，定义的选择确实影响模型表现，且对不同架构的模型影响不同。


<details>
  <summary>Details</summary>
Motivation: 网络中充斥的有害内容，尤其是仇恨言论，对社会产生严重影响。因此，准确检测仇恨言论成为NLP领域的重要任务。然而，仇恨言论的定义本身存在歧义，不同的定义会潜在影响模型检测的效果。

Method: 该研究首先系统整理和分析相关文献中已有的仇恨言论定义，归纳出14个构成性要素，并据此构建分类法。随后，研究团队基于收集的定义，在三种类型（合成数据、人机协作数据、真实世界数据）的仇恨言论数据集上，对三种大语言模型进行了零样本系统评测，比较不同定义下的检测性能差异。

Result: 研究发现，不同的仇恨言论定义（尤其是在构成要素的具体化程度上的不同）确实会影响模型检测能力，但这一影响在不同模型架构之间并不一致。

Conclusion: 仇恨言论的定义方式会显著影响大语言模型对仇恨言论的检测能力，但这种影响因模型而异，因此在模型应用和基准设定时需更加关注定义的选择和构成要素。

Abstract: Detecting harmful content is a crucial task in the landscape of NLP
applications for Social Good, with hate speech being one of its most dangerous
forms. But what do we mean by hate speech, how can we define it, and how does
prompting different definitions of hate speech affect model performance? The
contribution of this work is twofold. At the theoretical level, we address the
ambiguity surrounding hate speech by collecting and analyzing existing
definitions from the literature. We organize these definitions into a taxonomy
of 14 Conceptual Elements-building blocks that capture different aspects of
hate speech definitions, such as references to the target of hate (individual
or groups) or of the potential consequences of it. At the experimental level,
we employ the collection of definitions in a systematic zero-shot evaluation of
three LLMs, on three hate speech datasets representing different types of data
(synthetic, human-in-the-loop, and real-world). We find that choosing different
definitions, i.e., definitions with a different degree of specificity in terms
of encoded elements, impacts model performance, but this effect is not
consistent across all architectures.

</details>


### [118] [Answer-Centric or Reasoning-Driven? Uncovering the Latent Memory Anchor in LLMs](https://arxiv.org/abs/2506.17630)
*Yang Wu,Yifan Zhang,Yiwei Wang,Yujun Cai,Yurong Wu,Yuran Wang,Ning Xu,Jian Cheng*

Main category: cs.CL

TL;DR: 本研究提出新框架证实LLM推理高度依赖答案提示，推理多为事后合理化而非真正推理，需重新审视其推理能力深度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）展现出强大的推理能力，但越来越多证据表明，这种能力更多依赖于记忆化的答案-推理模式，而非真正的推理。本研究探究了LLMs到底依赖于最终答案本身，还是对推理链的文本模式。

Method: 提出了一个五级答案可见性提示框架，系统地调控答案提示，并通过间接的行为分析探究模型行为。

Result: 实验发现，当屏蔽答案提示，即使给出完整推理链，模型表现也下降了26.90%。这表明LLMs很大程度上依赖于明确的答案提示。

Conclusion: LLMs展示的推理表现更多是事后合理化而不是真正的推理，揭示了答案锚定现象，提醒业界需要重新思考LLM推理能力的本质。

Abstract: While Large Language Models (LLMs) demonstrate impressive reasoning
capabilities, growing evidence suggests much of their success stems from
memorized answer-reasoning patterns rather than genuine inference. In this
work, we investigate a central question: are LLMs primarily anchored to final
answers or to the textual pattern of reasoning chains? We propose a five-level
answer-visibility prompt framework that systematically manipulates answer cues
and probes model behavior through indirect, behavioral analysis. Experiments
across state-of-the-art LLMs reveal a strong and consistent reliance on
explicit answers. The performance drops by 26.90\% when answer cues are masked,
even with complete reasoning chains. These findings suggest that much of the
reasoning exhibited by LLMs may reflect post-hoc rationalization rather than
true inference, calling into question their inferential depth. Our study
uncovers the answer-anchoring phenomenon with rigorous empirical validation and
underscores the need for a more nuanced understanding of what constitutes
reasoning in LLMs.

</details>


### [119] [Step-Opt: Boosting Optimization Modeling in LLMs through Iterative Data Synthesis and Structured Validation](https://arxiv.org/abs/2506.17637)
*Yang Wu,Yifan Zhang,Yurong Wu,Yuran Wang,Junkai Zhang,Jian Cheng*

Main category: cs.CL

TL;DR: 本文提出Step-Opt-Instruct，通过分步生成与验证大幅增强优化建模任务数据，微调后的Step-Opt模型在多个复杂任务上显著优于现有方法，提升了自动化决策的数据质量与性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然在多个领域取得突破，但在解决运筹优化建模特别是复杂问题时仍面临显著挑战。优化领域自动化建模的准确性和鲁棒性需求，驱动了对新方法的探索。

Method: 提出了Step-Opt-Instruct框架，通过迭代生成问题逐步提升难度，并以分步验证保障扩充和生成优化建模数据的质量，防止错误传播。然后，基于此框架使用LLaMA-3-8B和Mistral-7B等开源LLM模型进行微调。

Result: 微调后的Step-Opt模型在NL4OPT、MAMO和IndustryOR等基准测试中表现优越，对高难度问题微平均准确率提升达17.01%。

Conclusion: 结构化验证与逐步复杂化生成结合，显著提升了LLM在复杂运筹优化建模任务中的性能，推动了自动化决策技术的发展。

Abstract: Large Language Models (LLMs) have revolutionized various domains but
encounter substantial challenges in tackling optimization modeling tasks for
Operations Research (OR), particularly when dealing with complex problem. In
this work, we propose Step-Opt-Instruct, a framework that augments existing
datasets and generates high-quality fine-tuning data tailored to optimization
modeling. Step-Opt-Instruct employs iterative problem generation to
systematically increase problem complexity and stepwise validation to
rigorously verify data, preventing error propagation and ensuring the quality
of the generated dataset. Leveraging this framework, we fine-tune open-source
LLMs, including LLaMA-3-8B and Mistral-7B, to develop Step-Opt--a model that
achieves state-of-the-art performance on benchmarks such as NL4OPT, MAMO, and
IndustryOR. Extensive experiments demonstrate the superior performance of
Step-Opt, especially in addressing complex OR tasks, with a notable 17.01\%
improvement in micro average accuracy on difficult problems. These findings
highlight the effectiveness of combining structured validation with gradual
problem refinement to advance the automation of decision-making processes using
LLMs.The code and dataset are available at https://github.com/samwu-learn/Step.

</details>


### [120] [TPTT: Transforming Pretrained Transformer into Titans](https://arxiv.org/abs/2506.17671)
*Fabien Furfaro*

Main category: cs.CL

TL;DR: TPTT框架通过引入高效机制和优化管理，使大型语言模型在不增加大量计算资源的情况下，显著提升了长文本处理能力，且易于在现有模型上部署。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言处理领域取得巨大进展，但其高计算和内存需求，尤其在长文本推理任务中，仍是显著的技术难题。

Method: 提出TPTT（Transforming Pretrained Transformer into Titans）框架，通过引入高效的线性化注意力机制和先进的内存管理（如Memory as Gate和混合线性化注意力LiZA），使预训练Transformer模型能够更高效地使用计算和内存资源。该方法完全兼容Hugging Face Transformers库，可通过参数高效微调（LoRA）快速适配现有LLM，无需完全再训练。

Result: 在MMLU基准测试上，约10亿参数规模的模型使用TPTT后，在效率和准确率上均有显著提升。例如Titans-Llama-3.2-1B模型的准确匹配（EM）指标相比基线提升了20%。统计分析及对比实验显示TPTT具备良好的可扩展性和鲁棒性。

Conclusion: TPTT能够高效提升预训练Transformer模型的长文本推理能力与整体表现，适配主流开源平台且易于集成，具有实际应用价值。

Abstract: Recent advances in large language models (LLMs) have led to remarkable
progress in natural language processing, but their computational and memory
demands remain a significant challenge, particularly for long-context
inference. We introduce TPTT (Transforming Pretrained Transformer into Titans),
a novel framework for enhancing pretrained Transformer models with efficient
linearized attention mechanisms and advanced memory management. TPTT employs
techniques such as Memory as Gate (MaG) and mixed linearized attention (LiZA).
It is fully compatible with the Hugging Face Transformers library, enabling
seamless adaptation of any causal LLM through parameter-efficient fine-tuning
(LoRA) without full retraining. We show the effectiveness of TPTT on the MMLU
benchmark with models of approximately 1 billion parameters, observing
substantial improvements in both efficiency and accuracy. For instance,
Titans-Llama-3.2-1B achieves a 20% increase in Exact Match (EM) over its
baseline. Statistical analyses and comparisons with recent state-of-the-art
methods confirm the practical scalability and robustness of TPTT. Code is
available at https://github.com/fabienfrfr/tptt . Python package at
https://pypi.org/project/tptt/ .

</details>


### [121] [Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering](https://arxiv.org/abs/2506.17692)
*Binquan Ji,Haibo Luo,Yifei Lu,Lei Hei,Jiaqi Wang,Tingjing Liao,Lingyu Wang,Shichao Wang,Feiliang Ren*

Main category: cs.CL

TL;DR: 本文针对知识密集型多跳问答任务，提出了动态增强链(DEC)框架，实现了更高效、低成本且准确的复杂问题解答，尤其适用于小型语言模型。


<details>
  <summary>Details</summary>
Motivation: 多跳问答任务需要整合来自多个信息源的证据，应对复杂问题，对于参数较少的小型大语言模型，处理大量文档和长上下文会带来幻觉和语义漂移等挑战。

Method: 提出了Dynamic Enhancement Chain(DEC)框架，首先将复杂问题分解为逻辑连贯的子问题，形成无幻觉的推理链；随后结合上下文对这些子问题进行重写提升查询效果。检索模块使用轻量判别式关键词抽取，更高效精准地召回相关文档。

Result: 在三个多跳问答数据集上的大量实验表明，DEC表现与最新方法持平或更优，同时显著降低了token消耗。在8B参数模型上获得了SOTA结果，说明该方法在资源受限环境下尤为有效。

Conclusion: DEC有效提升了小型语言模型在知识密集型多跳问答中的表现，兼顾推理准确性和计算资源消耗，对实际落地有明显优势。

Abstract: Knowledge-intensive multi-hop question answering (QA) tasks, which require
integrating evidence from multiple sources to address complex queries, often
necessitate multiple rounds of retrieval and iterative generation by large
language models (LLMs). However, incorporating many documents and extended
contexts poses challenges -such as hallucinations and semantic drift-for
lightweight LLMs with fewer parameters. This work proposes a novel framework
called DEC (Dynamic Enhancement Chain). DEC first decomposes complex questions
into logically coherent subquestions to form a hallucination-free reasoning
chain. It then iteratively refines these subquestions through context-aware
rewriting to generate effective query formulations. For retrieval, we introduce
a lightweight discriminative keyword extraction module that leverages extracted
keywords to achieve targeted, precise document recall with relatively low
computational overhead. Extensive experiments on three multi-hop QA datasets
demonstrate that DEC performs on par with or surpasses state-of-the-art
benchmarks while significantly reducing token consumption. Notably, our
approach attains state-of-the-art results on models with 8B parameters,
showcasing its effectiveness in various scenarios, particularly in
resource-constrained environments.

</details>


### [122] [Zero-Shot Conversational Stance Detection: Dataset and Approaches](https://arxiv.org/abs/2506.17693)
*Yuzhe Ding,Kang He,Bobo Li,Li Zheng,Haijun He,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: 作者构建了新的零样本对话立场检测数据集，并提出新模型，在任务上取得最优结果，但整体表现仍有限，表明此方向仍有大量挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的对话立场检测数据集目标有限，导致模型在真实环境下遇到大量新目标时效果受限。

Method: 人工构建了一个大规模、高质量的零样本对话立场检测数据集（ZS-CSD），涵盖两种类型共280个目标，并提出了结合说话者交互和目标感知的原型对比学习模型SITPCL。

Result: SITPCL在零样本对话立场检测任务上达到当前最优，但F1-macro分数仅为43.81%，显示该任务依然非常具有挑战性。

Conclusion: 提出的ZS-CSD数据集和SITPCL模型能促进零样本对话立场检测领域发展，但零样本情景下的准确率仍有很大提升空间。

Abstract: Stance detection, which aims to identify public opinion towards specific
targets using social media data, is an important yet challenging task. With the
increasing number of online debates among social media users, conversational
stance detection has become a crucial research area. However, existing
conversational stance detection datasets are restricted to a limited set of
specific targets, which constrains the effectiveness of stance detection models
when encountering a large number of unseen targets in real-world applications.
To bridge this gap, we manually curate a large-scale, high-quality zero-shot
conversational stance detection dataset, named ZS-CSD, comprising 280 targets
across two distinct target types. Leveraging the ZS-CSD dataset, we propose
SITPCL, a speaker interaction and target-aware prototypical contrastive
learning model, and establish the benchmark performance in the zero-shot
setting. Experimental results demonstrate that our proposed SITPCL model
achieves state-of-the-art performance in zero-shot conversational stance
detection. Notably, the SITPCL model attains only an F1-macro score of 43.81%,
highlighting the persistent challenges in zero-shot conversational stance
detection.

</details>


### [123] [The Evolution of Natural Language Processing: How Prompt Optimization and Language Models are Shaping the Future](https://arxiv.org/abs/2506.17700)
*Summra Saleem,Muhammad Nabeel Asim,Shaista Zulfiqar,Andreas Dengel*

Main category: cs.CL

TL;DR: 本文系统梳理了LLM提示优化策略，并将其分为11类，覆盖各种应用场景与模型，为后续研究提供了重要参考和实验基准。


<details>
  <summary>Details</summary>
Motivation: 尽管目前已有许多关于提示工程（prompt engineering）的综述，但缺乏对提示优化策略的全面分析。因此，为了填补这个空白，作者希望系统梳理和分析现有的提示优化方法。

Method: 本文从原理出发，对现有的提示优化策略进行了深入研究，将其归纳为11种不同类型，并回顾了这些策略在各种NLP任务、所使用的不同LLM及评测数据集上的应用情况。

Result: 提出了一套全面的提示优化策略分类体系，汇总了相关实际应用案例和实验，用于后续研究和评估。

Conclusion: 本文奠定了后续比较性研究的基础，有助于在统一的实验设置下更严格地评估和改进提示优化与LLM推理流程，并促进新应用的发展。

Abstract: Large Language Models (LLMs) have revolutionized the field of Natural
Language Processing (NLP) by automating traditional labor-intensive tasks and
consequently accelerated the development of computer-aided applications. As
researchers continue to advance this field with the introduction of novel
language models and more efficient training/finetuning methodologies, the idea
of prompt engineering and subsequent optimization strategies with LLMs has
emerged as a particularly impactful trend to yield a substantial performance
boost across diverse NLP tasks. To best of our knowledge numerous review
articles have explored prompt engineering, however, a critical gap exists in
comprehensive analyses of prompt optimization strategies. To bridge this gap
this paper provides unique and comprehensive insights about the potential of
diverse prompt optimization strategies. It analyzes their underlying working
paradigms and based on these principles, categorizes them into 11 distinct
classes. Moreover, the paper provides details about various NLP tasks where
these prompt optimization strategies have been employed, along with details of
different LLMs and benchmark datasets used for evaluation. This comprehensive
compilation lays a robust foundation for future comparative studies and enables
rigorous assessment of prompt optimization and LLM-based predictive pipelines
under consistent experimental settings: a critical need in the current
landscape. Ultimately, this research will centralize diverse strategic
knowledge to facilitate the adaptation of existing prompt optimization
strategies for development of innovative predictors across unexplored tasks.

</details>


### [124] [Aged to Perfection: Machine-Learning Maps of Age in Conversational English](https://arxiv.org/abs/2506.17708)
*MingZe Tang*

Main category: cs.CL

TL;DR: 本研究通过英国国家语料库和机器学习，发现并预测了不同年龄组在口语中的语言特征差异，加深了对英国现代口语中社会语言学多样性的理解。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究英国不同年龄群体在口语表达中的语言模式变化，以及说话者人口统计特征与语言学因素（如话语长度、词汇多样性和用词选择）之间的关系。

Method: 本研究利用British National Corpus 2014（英国国家语料库2014），结合计算语言分析和机器学习方法，对语言进行分析，试图发现不同世代的语言标志，并构建能够根据多项语言特征对说话者年龄组进行预测的模型。

Result: 研究揭示了多代群体在语言标志上的差异性，并成功创建了可根据语言特性准确预测说话者年龄组的预测模型。

Conclusion: 本研究丰富了我们对现代英国口语中社会语言学多样性的理解，并为后续基于人口统计信息和语言学特征关系的语言研究提供了方法参考。

Abstract: The study uses the British National Corpus 2014, a large sample of
contemporary spoken British English, to investigate language patterns across
different age groups. Our research attempts to explore how language patterns
vary between different age groups, exploring the connection between speaker
demographics and linguistic factors such as utterance duration, lexical
diversity, and word choice. By merging computational language analysis and
machine learning methodologies, we attempt to uncover distinctive linguistic
markers characteristic of multiple generations and create prediction models
that can consistently estimate the speaker's age group from various aspects.
This work contributes to our knowledge of sociolinguistic diversity throughout
the life of modern British speech.

</details>


### [125] [Unveiling Factors for Enhanced POS Tagging: A Study of Low-Resource Medieval Romance Languages](https://arxiv.org/abs/2506.17715)
*Matthias Schöffel,Esteban Garces Arias,Marinus Wiedner,Paula Ruppert,Meimingwei Li,Christian Heumann,Matthias Aßenmacher*

Main category: cs.CL

TL;DR: 本文系统比较了不同技术在中世纪罗曼语族低资源文本词性标注上的表现，发现大型语言模型虽有限制，但通过微调等方法可显著改进历史文本的处理能力。


<details>
  <summary>Details</summary>
Motivation: 随着现代语言模型的进步，许多古代语言的自然语言处理取得了突破，但中世纪罗曼语族文本因为语言演变、拼写多样和标注数据稀缺等问题，依然存在诸多困难。研究者亟需探索针对中世纪低资源历史语言的自动词性标注方法，提升数字人文学科的文本处理能力。

Method: 本文系统性地考察了影响中世纪奥克语、西班牙语和法语等文本中词性标注表现的主要因素。所用方法包括模型微调、提示工程（prompt engineering）、不同模型架构、解码策略以及跨语言迁移学习。涵盖圣经、圣徒传记、医学和饮食等多样化语料。通过严格的实验对比各因素对标注准确率的影响。

Result: 实验发现，大型语言模型在处理历史语言变体与非标准拼写方面受限，准确率受挑战。但同时也确定了若干可行的专门化技术（如微调与迁移学习等），可以在低资源历史语言环境下有效提升词性标注性能。

Conclusion: 虽然当前LLMs对中世纪罗曼语族文本的处理仍有明显局限，但定制的方法和技术能够有效缓解数据稀缺与语言变异问题，为历史语言的自动化分析提供了新工具和思路。

Abstract: Part-of-speech (POS) tagging remains a foundational component in natural
language processing pipelines, particularly critical for historical text
analysis at the intersection of computational linguistics and digital
humanities. Despite significant advancements in modern large language models
(LLMs) for ancient languages, their application to Medieval Romance languages
presents distinctive challenges stemming from diachronic linguistic evolution,
spelling variations, and labeled data scarcity. This study systematically
investigates the central determinants of POS tagging performance across diverse
corpora of Medieval Occitan, Medieval Spanish, and Medieval French texts,
spanning biblical, hagiographical, medical, and dietary domains. Through
rigorous experimentation, we evaluate how fine-tuning approaches, prompt
engineering, model architectures, decoding strategies, and cross-lingual
transfer learning techniques affect tagging accuracy. Our results reveal both
notable limitations in LLMs' ability to process historical language variations
and non-standardized spelling, as well as promising specialized techniques that
effectively address the unique challenges presented by low-resource historical
languages.

</details>


### [126] [KAG-Thinker: Teaching Large Language Models to Think with Human-like Reasoning Process](https://arxiv.org/abs/2506.17728)
*Dalong Zhang,Jun Xu,Jun Zhou,Lei Liang,Lin Yuan,Ling Zhong,Mengshu Sun,Peilong Zhao,QiWei Wang,Xiaorui Wang,Xinkai Du,YangYang Hou,Yu Ao,ZhaoYang Wang,Zhengke Gui,ZhiYing Yi,Zhongpu Bo*

Main category: cs.CL

TL;DR: 本论文提出了一种模拟人类思维、结构化推理过程的新框架KAG-Thinker，提升了大语言模型在特定领域复杂问答中的逻辑与一致性，通过创新分解、检索、推理和训练机制实现更优的推理表现。


<details>
  <summary>Details</summary>
Motivation: 许多现有大语言模型在处理特定领域知识库的复杂问答任务时，缺乏人类类似的结构化推理能力，逻辑连贯性和上下文一致性有待提升。作者希望提升LLM在人类类似推理过程中的表现，模拟更系统、有条理的解题方式。

Method: 提出KAG-Thinker框架，基于参数量较小的大语言模型，通过'广度分解'方法将复杂问题拆解为可独立解决的子问题（子问题以自然语言和逻辑函数两种形式表达）。针对不同任务类型进行知识检索或推理分析，采用明确建模的依赖关系和变量传递机制。创新地利用知识边界模型，结合自信度校准与反思推理调度最优知识源，并使用'深度求解'模型提高知识获取的完整性。此外，训练方法采用基于多轮对话的有监督微调，配合数据评测框架和迭代语料生成，避免过度反思。

Result: KAG-Thinker能够实现更符合人类思维的问答推理过程，有效提升逻辑连贯性和上下文一致性。采用知识边界模型和深度求解机制后，系统能更优选知识源并获得更完整的知识。通过有监督微调替代强化学习，实现了与结构化推理范式对齐，数据评测和语料生成机制进一步加强了全面性和效果。

Conclusion: KAG-Thinker显著提升了大语言模型在特定领域知识库的复杂问答推理能力，使其推理过程更加系统和人类化。所提出的架构整合了知识检索、逻辑分解、推理分析以及高效数据驱动训练，对结构化问答推理具有重要意义。

Abstract: In this paper, we introduce KAG-Thinker, a novel human-like reasoning
framework built upon a parameter-light large language model (LLM). Our approach
enhances the logical coherence and contextual consistency of the thinking
process in question-answering (Q\&A) tasks on domain-specific knowledge bases
(KBs) within LLMs. This framework simulates human cognitive mechanisms for
handling complex problems by establishing a structured thinking process.
Continuing the \textbf{Logical Form} guided retrieval and reasoning technology
route of KAG v0.7, firstly, it decomposes complex questions into independently
solvable sub-problems(also referred to as logical forms) through
\textbf{breadth decomposition}, each represented in two equivalent
forms-natural language and logical function-and further classified as either
Knowledge Retrieval or Reasoning Analysis tasks, with dependencies and
variables passing explicitly modeled via logical function interfaces. In the
solving process, the Retrieval function is used to perform knowledge retrieval
tasks, while the Math and Deduce functions are used to perform reasoning
analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval
sub-problem tasks, LLMs and external knowledge sources are regarded as
equivalent KBs. We use the \textbf{knowledge boundary} model to determine the
optimal source using self-regulatory mechanisms such as confidence calibration
and reflective reasoning, and use the \textbf{depth solving} model to enhance
the comprehensiveness of knowledge acquisition. Finally, instead of utilizing
reinforcement learning, we employ supervised fine-tuning with multi-turn
dialogues to align the model with our structured inference paradigm, thereby
avoiding excessive reflection. This is supported by a data evaluation framework
and iterative corpus synthesis, which facilitate the generation of detailed
reasoning trajectories...

</details>


### [127] [HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations](https://arxiv.org/abs/2506.17748)
*Anwoy Chatterjee,Yash Goel,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文提出了HIDE，一种无需多次生成的高效幻觉检测方法，通过内部表征的独立性度量，显著提升检测准确率并大幅降低计算成本，实验验证了其对多种模型和任务的广泛有效性。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型虽然在生成语言方面表现出色，但它们常常会产生与事实或输入上下文不相符的内容，即“幻觉”问题，这极大影响了其可靠性。现有的幻觉检测方法大多需要对一个输入多次生成内容，导致高昂的计算代价和延迟。因此，急需一种高效且低成本的幻觉检测方法。

Method: 作者提出了一种单次推理、无需额外训练的幻觉检测方法，名为HIDE（Hallucination detectIon via Decoupled rEpresentations）。该方法基于这样一个假设：幻觉内容的产生源自于模型对输入上下文与生成输出的内部表征之间存在统计上的分离。具体做法是利用Hilbert-Schmidt Independence Criterion（HSIC），对生成过程中提取的隐藏态进行独立性量化分析，判定是否存在幻觉。

Result: 在四个多样化问答数据集和六个不同特性的开源语言模型上进行了实证评估，涉及事实性和忠实性幻觉检测。实验表明，HIDE方法几乎在所有设置下都优于其它单次方法，AUC-ROC指标平均相对提升约29%；同时与多次策略的SOTA方法相比，HIDE在计算成本降低约51%的前提下，仍获得了AUC-ROC平均约3%的提升或持平。

Conclusion: HIDE方法能有效利用语言模型内部表征的解耦特性，实现高效且实用的幻觉检测，在准确性与计算效率上均优于目前主流方案。

Abstract: Contemporary Language Models (LMs), while impressively fluent, often generate
content that is factually incorrect or unfaithful to the input context - a
critical issue commonly referred to as 'hallucination'. This tendency of LMs to
generate hallucinated content undermines their reliability, especially because
these fabrications are often highly convincing and therefore difficult to
detect. While several existing methods attempt to detect hallucinations, most
rely on analyzing multiple generations per input, leading to increased
computational cost and latency. To address this, we propose a single-pass,
training-free approach for effective Hallucination detectIon via Decoupled
rEpresentations (HIDE). Our approach leverages the hypothesis that
hallucinations result from a statistical decoupling between an LM's internal
representations of input context and its generated output. We quantify this
decoupling using the Hilbert-Schmidt Independence Criterion (HSIC) applied to
hidden-state representations extracted while generating the output sequence. We
conduct extensive experiments on four diverse question answering datasets,
evaluating both faithfulness and factuality hallucinations across six
open-source LMs of varying scales and properties. Our results demonstrate that
HIDE outperforms other single-pass methods in almost all settings, achieving an
average relative improvement of ~29% in AUC-ROC over the best-performing
single-pass strategy across various models and datasets. Additionally, HIDE
shows competitive and often superior performance with multi-pass
state-of-the-art methods, obtaining an average relative improvement of ~3% in
AUC-ROC while consuming ~51% less computation time. Our findings highlight the
effectiveness of exploiting internal representation decoupling in LMs for
efficient and practical hallucination detection.

</details>


### [128] [Multilingual Tokenization through the Lens of Indian Languages: Challenges and Insights](https://arxiv.org/abs/2506.17789)
*N J Karthika,Maharaj Brahma,Rohit Saluja,Ganesh Ramakrishnan,Maunendra Sankar Desarkar*

Main category: cs.CL

TL;DR: 本文深入评估了多种分词算法在印度17种语言上的表现，提出多语种词表与联合训练有助于提升低资源语言的分词效果，为构建更公平高效的多语言NLP系统提供实证参考。


<details>
  <summary>Details</summary>
Motivation: 当前多语种NLP中的分词器大多偏向于高资源语言，导致对印度次大陆等多样且形态丰富语言的处理效果不佳。作者希望改善多语言分词在低资源语言上的表现公平性和效率。

Method: 论文在17种印度语言上，系统评估了不同分词策略，包括自底向上（BPE）、自顶向下（Unigram LM）算法。分析了词表规模、联合与聚类构建多语种词表等策略的影响，并观察低资源语言是否能受益于相关高资源语言训练的分词器。

Result: 比较了不同分词方法和词表构建策略的表现，发现低资源语言可显著受益于与其相关高资源语言共同训练分词器。揭示了多语种多样性环境下分词技术取舍与优化的实证规律。

Conclusion: 多语言分词系统应考虑语言间的资源不均、形态多样和联系性。联合训练、合适的分词策略和词表设计有助于提升低资源语言的处理效果，实现更公平高效的多语种NLP。

Abstract: Tokenization plays a pivotal role in multilingual NLP. However, existing
tokenizers are often skewed towards high-resource languages, limiting their
effectiveness for linguistically diverse and morphologically rich languages
such as those in the Indian subcontinent. This paper presents a comprehensive
intrinsic evaluation of tokenization strategies across 17 Indian languages. We
quantify the trade-offs between bottom-up and top-down tokenizer algorithms
(BPE and Unigram LM), effects of vocabulary sizes, and compare strategies of
multilingual vocabulary construction such as joint and cluster-based training.
We also show that extremely low-resource languages can benefit from tokenizers
trained on related high-resource languages. Our study provides practical
insights for building more fair, efficient, and linguistically informed
tokenizers for multilingual NLP.

</details>


### [129] [THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction](https://arxiv.org/abs/2506.17844)
*Xin Zhang,Qiyu Wei,Yingjie Zhu,Fanyi Wu,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 本研究提出基于因果推断并结合校准机制的EHR多模态风险预测新方法THCM-CAL，有效提升了预测准确率和可靠性，优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 以往利用电子健康记录（EHRs）进行自动化临床风险预测时，常将结构化诊断编码和非结构化叙述笔记分开处理，或者采用简单的融合策略，忽略了叙述性观察如何引发诊断并跨入院传播风险的因果关系。本研究旨在解决多模态信息融合的复杂因果关联问题，提升预测的准确率和可靠性。

Method: 提出一种新的时序-层次因果模型（THCM-CAL），并结合一致性校准（Conformal Calibration）。该模型首先构建包含文本命题和ICD编码（映射为文本描述）的多模态因果图，通过层次化因果发现推断出三类临床相关的交互：同一时间片同模态排序、同一时间片跨模态触发、不同时间片的风险传播。此外，模型还将一致性预测方法扩展到多标签ICD编码，通过复杂共现情况下的置信区间校准提升预测可靠性。

Result: 在MIMIC-III和MIMIC-IV数据集上进行实验证明，THCM-CAL在自动化临床风险预测方面，相较于已有方法表现出更优的性能和更高的可靠性。

Conclusion: THCM-CAL能够有效刻画和利用EHR中结构化与非结构化数据之间的复杂因果关系，并通过一致性校准提升了预测的可控性和可靠性，为实际临床风险预测提供了更好的解决方案。

Abstract: Automated clinical risk prediction from electronic health records (EHRs)
demands modeling both structured diagnostic codes and unstructured narrative
notes. However, most prior approaches either handle these modalities separately
or rely on simplistic fusion strategies that ignore the directional,
hierarchical causal interactions by which narrative observations precipitate
diagnoses and propagate risk across admissions. In this paper, we propose
THCM-CAL, a Temporal-Hierarchical Causal Model with Conformal Calibration. Our
framework constructs a multimodal causal graph where nodes represent clinical
entities from two modalities: Textual propositions extracted from notes and ICD
codes mapped to textual descriptions. Through hierarchical causal discovery,
THCM-CAL infers three clinically grounded interactions: intra-slice
same-modality sequencing, intra-slice cross-modality triggers, and inter-slice
risk propagation. To enhance prediction reliability, we extend conformal
prediction to multi-label ICD coding, calibrating per-code confidence intervals
under complex co-occurrences. Experimental results on MIMIC-III and MIMIC-IV
demonstrate the superiority of THCM-CAL.

</details>


### [130] [LLMs for Customized Marketing Content Generation and Evaluation at Scale](https://arxiv.org/abs/2506.17863)
*Haoran Liu,Amir Tahmasbi,Ehtesham Sam Haque,Purak Jain*

Main category: cs.CL

TL;DR: 本文提出了一套检索增强的广告生成及自动化评测体系，有效提升电商广告表现并降低人工成本，但关键节点仍需人工审查。


<details>
  <summary>Details</summary>
Motivation: 当前电商领域的站外营销内容大多过于模板化、与落地页关联性差，影响营销效果。如何自动生成高相关、高效率的广告文案并降低人工审核成本，是亟需解决的问题。

Method: 提出了MarketingFM系统，通过检索增强集成多数据源，自动生成与关键词高度匹配的广告文案；同时提出AutoEval-Main和AutoEval-Update自动化评测系统，利用规则与大模型评审结合，动态优化评测流程，降低人工干预。

Result: 自适应生成的关键词广告文案相比模板广告，最高CTR提升9%，展现量提升12%，CPC下降0.38%；自动化评测系统与人工标注一致性达89.57%，能够动态优化评测流程，减少人工成本。

Conclusion: 通过MarketingFM与自动化评测方案，显著提升了电商广告投放的相关性及效率，减少了人工干预，但人工仍需在关键环节进行把控。

Abstract: Offsite marketing is essential in e-commerce, enabling businesses to reach
customers through external platforms and drive traffic to retail websites.
However, most current offsite marketing content is overly generic,
template-based, and poorly aligned with landing pages, limiting its
effectiveness. To address these limitations, we propose MarketingFM, a
retrieval-augmented system that integrates multiple data sources to generate
keyword-specific ad copy with minimal human intervention. We validate
MarketingFM via offline human and automated evaluations and large-scale online
A/B tests. In one experiment, keyword-focused ad copy outperformed templates,
achieving up to 9% higher CTR, 12% more impressions, and 0.38% lower CPC,
demonstrating gains in ad ranking and cost efficiency. Despite these gains,
human review of generated ads remains costly. To address this, we propose
AutoEval-Main, an automated evaluation system that combines rule-based metrics
with LLM-as-a-Judge techniques to ensure alignment with marketing principles.
In experiments with large-scale human annotations, AutoEval-Main achieved
89.57% agreement with human reviewers. Building on this, we propose
AutoEval-Update, a cost-efficient LLM-human collaborative framework to
dynamically refine evaluation prompts and adapt to shifting criteria with
minimal human input. By selectively sampling representative ads for human
review and using a critic LLM to generate alignment reports, AutoEval-Update
improves evaluation consistency while reducing manual effort. Experiments show
the critic LLM suggests meaningful refinements, improving LLM-human agreement.
Nonetheless, human oversight remains essential for setting thresholds and
validating refinements before deployment.

</details>


### [131] [QueueEDIT: Structural Self-Correction for Sequential Model Editing in LLMs](https://arxiv.org/abs/2506.17864)
*Taolin Zhang,Haidong Kang,Dongyang Li,Qizhou Chen,Chengyu Wang Xiaofeng He,Richang Hong*

Main category: cs.CL

TL;DR: 本文提出了一种基于队列的自我校正LLM模型编辑方法QueueEDIT，在连续多轮知识修正场景下取得了优异的修正能力，并能维持模型的通用NLP能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）表现出色，但仍存在幻觉，即事实性错误。模型编辑是修正这些错误的一种方法。然而，在实际应用中，错误的修正是连续发生的（而非一次性任务），这时候如何避免对模型原有能力的损害成为挑战。

Method: 提出了基于队列的自我校正框架QueueEDIT。核心方法包括：1）引入结构映射编辑损失，将知识三元组映射到Transformers层中的知识敏感神经元；2）用队列存储每次编辑定位到的参数，并动态对齐过去编辑过的参数；3）每次编辑时选取与当前参数最相关的队列参数，判断是否需要重新调整以保证知识一致性；4）将与当前无关的队列参数冻结，仅更新对模型能力影响最小的队列头参数。

Result: 实验结果显示，该方法在各类顺序模型编辑场景下，显著优于多个强基线，同时在单轮编辑任务中也具竞争力。更重要的是，编辑后的LLM在SME过程中依然能较好地保持原有NLP能力。

Conclusion: QueueEDIT不仅提升了连续错误修正（SME）的性能，还有效缓解了模型参数偏移对通用能力的影响，是一种兼具精准性和鲁棒性的模型编辑方案。

Abstract: Recently, large language models (LLMs) have demonstrated impressive results
but still suffer from hallucinations. Model editing has been proposed to
correct factual inaccuracies in LLMs. A challenging case is sequential model
editing (SME), which aims to rectify errors continuously rather than treating
them as a one-time task. During SME, the general capabilities of LLMs can be
negatively affected due to the introduction of new parameters. In this paper,
we propose a queue-based self-correction framework (QueueEDIT) that not only
enhances SME performance by addressing long-sequence dependency but also
mitigates the impact of parameter bias on the general capabilities of LLMs.
Specifically, we first introduce a structural mapping editing loss to map the
triplets to the knowledge-sensitive neurons within the Transformer layers of
LLMs. We then store the located parameters for each piece of edited knowledge
in a queue and dynamically align previously edited parameters. In each edit, we
select queue parameters most relevant to the currently located parameters to
determine whether previous knowledge needs realignment. Irrelevant parameters
in the queue are frozen, and we update the parameters at the queue head to the
LLM to ensure they do not harm general abilities. Experiments show that our
framework significantly outperforms strong baselines across various SME
settings and maintains competitiveness in single-turn editing. The resulting
LLMs also preserve high capabilities in general NLP tasks throughout the SME
process.

</details>


### [132] [How Alignment Shrinks the Generative Horizon](https://arxiv.org/abs/2506.17871)
*Chenghao Yang,Ari Holtzman*

Main category: cs.CL

TL;DR: 本文提出Branching Factor指标，揭示了对齐大模型输出多样性降低的根本机制，并表明通过合理引导，基础模型也能获得更稳定的输出。


<details>
  <summary>Details</summary>
Motivation: 目前对齐的大模型虽然表现能力强，但生成内容的多样性有限。作者希望理解为什么在对齐后LLM生成结果会变得更稳定、缺乏多样性。

Method: 提出了Branching Factor（BF）指标，一种与token无关的量化方法，用于衡量生成时下一个合理token的有效数量，并用此指标分析对齐过程对模型输出分布的影响，包括实验研究和'诱导'实验。

Result: 实验证明：(1) BF会随着生成过程的推进而减小，说明模型越生成输出越可预测；(2) 对齐调优明显收缩输出分布，使BF大幅降低（如从12降为1.2）；(3) 链式思维推理通过更长推理链也推动BF降低，使输出更加稳定；(4) 通过提示基本模型特定词，同样可以降低BF。

Conclusion: BF是分析和控制LLM输出的有力工具。对齐调优并未本质改变模型行为，而是引导其偏好风格化token，从而激活了原有模型中低熵路径，这解释了对齐模型多样性降低的原因。

Abstract: Despite their impressive capabilities, aligned large language models (LLMs)
often generate outputs that lack diversity. What drives this stability in the
generation? We investigate this phenomenon through the lens of probability
concentration in the model's output distribution. To quantify this
concentration, we introduce the Branching Factor (BF) -- a token-invariant
measure of the effective number of plausible next steps during generation. Our
empirical analysis reveals two key findings: (1) BF often decreases as
generation progresses, suggesting that LLMs become more predictable as they
generate. (2) alignment tuning substantially sharpens the model's output
distribution from the outset, reducing BF by nearly an order of magnitude
(e.g., from 12 to 1.2) relative to base models. This stark reduction helps
explain why aligned models often appear less sensitive to decoding strategies.
Building on this insight, we find this stability has surprising implications
for complex reasoning. Aligned Chain-of-Thought (CoT) models (e.g.,
DeepSeek-distilled models), for instance, leverage this effect; by generating
longer reasoning chains, they push generation into later, more deterministic
(lower BF) stages, resulting in more stable outputs. We hypothesize that
alignment tuning does not fundamentally change a model's behavior, but instead
steers it toward stylistic tokens (e.g., "Sure") that unlock low-entropy
trajectories already present in the base model. This view is supported by
nudging experiments, which show that prompting base models with such tokens can
similarly reduce BF. Together, our findings establish BF as a powerful
diagnostic for understanding and controlling LLM outputs - clarifying how
alignment reduces variability, how CoT promotes stable generations, and how
base models can be steered away from diversity.

</details>


### [133] [Multi-turn Jailbreaking via Global Refinement and Active Fabrication](https://arxiv.org/abs/2506.17881)
*Hua Tang,Lingyong Yan,Yukun Zhao,Shuaiqiang Wang,Jizhou Huang,Dawei Yin*

Main category: cs.CL

TL;DR: 本文针对多轮交互场景下的大语言模型越狱问题，提出全局路径优化和主动伪造回复的新方法，在多个主流模型上显著提升了越狱成功率，揭示LLM的进一步安全隐患。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在多项任务上表现优异，但仍存在因被恶意利用而导致的安全隐患。当前研究主要集中在单轮对话的“越狱”手法，而多轮复杂交互情境下的安全风险未被充分探索。

Method: 提出了一种新颖的多轮越狱方法，在每轮交互中对越狱路径进行全局改进；同时主动伪造模型回复以抑制安全警告，进而提高后续输出有害内容的概率。

Result: 实验结果显示，该方法在六个主流LLM上相较于现有单轮和多轮越狱技术表现更为优越。

Conclusion: 该研究提出的多轮越狱方法能够更有效地促使模型输出有害内容，突显了当前LLM在多轮交互安全方面存在的风险和挑战。

Abstract: Large Language Models (LLMs) have achieved exceptional performance across a
wide range of tasks. However, they still pose significant safety risks due to
the potential misuse for malicious purposes. Jailbreaks, which aim to elicit
models to generate harmful content, play a critical role in identifying the
underlying security threats. Recent jailbreaking primarily focuses on
single-turn scenarios, while the more complicated multi-turn scenarios remain
underexplored. Moreover, existing multi-turn jailbreaking techniques struggle
to adapt to the evolving dynamics of dialogue as the interaction progresses. To
address this limitation, we propose a novel multi-turn jailbreaking method that
refines the jailbreaking path globally at each interaction. We also actively
fabricate model responses to suppress safety-related warnings, thereby
increasing the likelihood of eliciting harmful outputs in subsequent questions.
Experimental results demonstrate the superior performance of our method
compared with existing single-turn and multi-turn jailbreaking techniques
across six state-of-the-art LLMs. Our code is publicly available at
https://github.com/Ytang520/Multi-Turn_jailbreaking_Global-Refinment_and_Active-Fabrication.

</details>


### [134] [Scatter-Based Innovation Propagation in Large Language Models for Multi-Stage Process Adaptation](https://arxiv.org/abs/2506.17949)
*Hong Su*

Main category: cs.CL

TL;DR: 本文提出了创新扩散模型，通过结构化步骤帮助大语言模型将局部创新有效推广至多阶段流程中的其他部分，从而提升了其泛化与复用能力，实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）虽然能够复现和延展预训练时学到的模式，但面对将某一创新思想推广到不同上下文阶段的任务时，经常表现不佳。本文聚焦于如何将局部新颖思想应用于多阶段流程中其他部分，提升其泛化能力。

Method: 提出了创新扩散模型（innovation scatter model），通过四步流程指导LLM：1）对比用户输入与环境上下文，识别核心创新；2）去除特定阶段或组件指涉，实现创新思想泛化；3）判断该泛化思想能否应用于更广泛的范围；4）借助LLM系统性地扩展到其他具有结构相似性的阶段。该模型主要利用各阶段的结构冗余性。

Result: 实验结果表明，这一创新扩散模型能有效帮助LLM将新思想推广至其他结构相似阶段，显著提升了模型的泛化与重用能力。

Conclusion: 创新扩散模型可增强LLM推广和复用局部创新思想的能力，使其在多阶段流程中的泛化表现更好。

Abstract: Large Language Models (LLMs) exhibit strong capabilities in reproducing and
extending patterns observed during pretraining but often struggle to generalize
novel ideas beyond their original context. This paper addresses the challenge
of applying such localized innovations - introduced at a specific stage or
component - to other parts of a multi-stage process. We propose a scatter-based
innovation expansion model (innovation scatter model) that guides the LLM
through a four-step process: (1) identifying the core innovation by comparing
the user's input with its surrounding context, (2) generalizing the innovation
by removing references to specific stages or components, (3) determining
whether the generalized innovation applies to a broader scope beyond the
original stage, and (4) systematically applying it to other structurally
similar stages using the LLM. This model leverages structural redundancy across
stages to improve the applicability of novel ideas. Verification results
demonstrate that the innovation scatter model enables LLMs to extend
innovations across structurally similar stages, thereby enhancing
generalization and reuse.

</details>


### [135] [A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment](https://arxiv.org/abs/2506.17951)
*Quanwei Tang,Sophia Yat Mei Lee,Junshuang Wu,Dong Zhang,Shoushan Li,Erik Cambria,Guodong Zhou*

Main category: cs.CL

TL;DR: 本文提出了GraphMPA，通过图结构信息理解和模式寻优对齐机制，显著提升了RAG系统在问答任务中的整体理解力及与人类偏好的契合度。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成（RAG）方法在问答系统中为大语言模型提供了外部知识，但模型在实现全局语义理解及对齐人类伦理和质量偏好方面尚存在难题。

Method: 本文提出了GraphMPA，一种基于图的综合性框架，包含模式寻优偏好对齐。该方法通过通用相似性度量构建层次化文档图，模拟人类对信息的认知与整合过程，并引入模式寻优概率匹配约束，以提升生成结果与人类偏好的对齐度。

Result: 在六个数据集上的大量实验表明，GraphMPA显著提升了模型的能力，能够更有效与人类偏好对齐。

Conclusion: GraphMPA框架通过图结构理解和模式偏好优化，有效提升RAG系统的全球信息合成能力和输出对人类质量与伦理偏好的对齐度。

Abstract: Recent advancements in retrieval-augmented generation (RAG) have enhanced
large language models in question answering by integrating external knowledge.
However, challenges persist in achieving global understanding and aligning
responses with human ethical and quality preferences. To address these issues,
we propose GraphMPA, a comprehensive graph-based framework with mode-seeking
preference alignment. Our approach constructs a hierarchical document graph
using a general similarity measurement, mimicking human cognitive processes for
information understanding and synthesis. Additionally, we introduce
mode-seeking preference optimization to better align model outputs with human
preferences through probability-matching constraints. Extensive experiments on
six datasets demonstrate the effectiveness of our
\href{https://github.com/tangquanwei/GraphMPA}{GraphMPA}.

</details>


### [136] [PDF Retrieval Augmented Question Answering](https://arxiv.org/abs/2506.18027)
*Thi Thu Uyen Hoang,Viet Anh Nguyen*

Main category: cs.CL

TL;DR: 本论文提出了一种改进的RAG问答系统，首次有效整合了PDF中的文本和非文本多模态信息，实验验证了其在复杂问题上的准确性和扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统主要针对文本信息，难以处理PDF等文档内的丰富多样数据类型，因此亟需一种能够整合并智能处理多模态信息的QA系统。

Method: 通过对RAG框架进行改进，将PDF中的非文本内容（如图像、图表、表格等）数字化并有效整合进系统流程，同时对大语言模型进行微调以适应多模态信息处理需求。

Result: 实验表明，该系统能在PDF中准确抽取多类型内容的信息，并提升了应对复杂多模态问题的能力，为多模态数据整合和处理领域的研究发展奠定了基础。

Conclusion: 提出了一种改进的基于检索增强生成（RAG）框架的问答系统，能够从PDF文件中提取多模态信息，显著提升了现有系统处理文本、图像、图表和表格等多种数据类型的能力。

Abstract: This paper presents an advancement in Question-Answering (QA) systems using a
Retrieval Augmented Generation (RAG) framework to enhance information
extraction from PDF files. Recognizing the richness and diversity of data
within PDFs--including text, images, vector diagrams, graphs, and tables--poses
unique challenges for existing QA systems primarily designed for textual
content. We seek to develop a comprehensive RAG-based QA system that will
effectively address complex multimodal questions, where several data types are
combined in the query. This is mainly achieved by refining approaches to
processing and integrating non-textual elements in PDFs into the RAG framework
to derive precise and relevant answers, as well as fine-tuning large language
models to better adapt to our system. We provide an in-depth experimental
evaluation of our solution, demonstrating its capability to extract accurate
information that can be applied to different types of content across PDFs. This
work not only pushes the boundaries of retrieval-augmented QA systems but also
lays a foundation for further research in multimodal data integration and
processing.

</details>


### [137] [Splitformer: An improved early-exit architecture for automatic speech recognition on edge devices](https://arxiv.org/abs/2506.18035)
*Maxence Lasbordes,Daniele Falavigna,Alessio Brutti*

Main category: cs.CL

TL;DR: 本文为端侧语音识别推理提出了一种引入并行降采样处理层的早退模型方案，实现了资源感知下性能提升，推理速度不变，参数量略增。


<details>
  <summary>Details</summary>
Motivation: 神经模型在推理时，需根据设备资源动态调整计算量，尤其在计算资源有限或变化的设备端处理场景格外重要，而现有早退（early-exit）架构与部分高效语音识别架构在结构可扩展性和模块化上存在不足。

Method: 提出在神经网络架构中引入并行层，专门处理降采样后的输入，从而与标准处理层协同工作，以提升语音识别早退模型的性能。

Result: 在标准语音识别基准测试上，所提方法显著提升了性能，仅需少量参数增加，且不会影响推理时间。

Conclusion: 通过引入针对降采样输入的并行处理层，可以在几乎不增加推理延迟的前提下，有效提升适用于早退机制的语音识别模型性能，适应了设备端资源动态变化需求。

Abstract: The ability to dynamically adjust the computational load of neural models
during inference in a resource aware manner is crucial for on-device processing
scenarios, characterised by limited and time-varying computational resources.
Early-exit architectures represent an elegant and effective solution, since
they can process the input with a subset of their layers, exiting at
intermediate branches (the upmost layers are hence removed from the model).
  From a different perspective, for automatic speech recognition applications
there are memory-efficient neural architectures that apply variable frame rate
analysis, through downsampling/upsampling operations in the middle layers,
reducing the overall number of operations and improving significantly the
performance on well established benchmarks. One example is the Zipformer.
However, these architectures lack the modularity necessary to inject early-exit
branches.
  With the aim of improving the performance in early-exit models, we propose
introducing parallel layers in the architecture that process downsampled
versions of their inputs. % in conjunction with standard processing layers. We
show that in this way the speech recognition performance on standard benchmarks
significantly improve, at the cost of a small increase in the overall number of
model parameters but without affecting the inference time.

</details>


### [138] [Markov-Enhanced Clustering for Long Document Summarization: Tackling the 'Lost in the Middle' Challenge with Large Language Models](https://arxiv.org/abs/2506.18036)
*Aziz Amari,Mohamed Achref Ben Ammar*

Main category: cs.CL

TL;DR: 提出结合抽取与生成的混合摘要方法，有效避免生成式在长文本中关键信息丢失问题，通过聚类及马尔可夫链优化信息组织，提升摘要质量。


<details>
  <summary>Details</summary>
Motivation: 现有自动文本摘要方法主要分为抽取式和生成式两类，但基于大型语言模型的生成式摘要虽然效果提升显著，却资源消耗大，且在处理长文档时易丢失关键信息（即“lost in the middle”问题）。因此需要新的方法解决这些挑战。

Method: 本文提出一种结合抽取式和生成式的混合摘要方法。具体做法是将文档拆分为若干小块，对其向量嵌入进行聚类，为每个聚类生成代表关键思想的摘要，最终根据马尔可夫链图决定这些摘要的语义排序，生成最终摘要文本。

Result: 该方法能够在保留文档关键内容的同时，克服生成式方法在长文档上的信息丢失问题，并高效组织关键信息。

Conclusion: 混合摘要方法可有效提升自动摘要质量，兼顾关键内容保留和逻辑连贯性，具备实际应用价值。

Abstract: The rapid expansion of information from diverse sources has heightened the
need for effective automatic text summarization, which condenses documents into
shorter, coherent texts. Summarization methods generally fall into two
categories: extractive, which selects key segments from the original text, and
abstractive, which generates summaries by rephrasing the content coherently.
Large language models have advanced the field of abstractive summarization, but
they are resourceintensive and face significant challenges in retaining key
information across lengthy documents, which we call being "lost in the middle".
To address these issues, we propose a hybrid summarization approach that
combines extractive and abstractive techniques. Our method splits the document
into smaller text chunks, clusters their vector embeddings, generates a summary
for each cluster that represents a key idea in the document, and constructs the
final summary by relying on a Markov chain graph when selecting the semantic
order of ideas.

</details>


### [139] [Statistical Multicriteria Evaluation of LLM-Generated Text](https://arxiv.org/abs/2506.18082)
*Esteban Garces Arias,Hannah Blocher,Julian Rodemann,Matthias Aßenmacher,Christoph Jansen*

Main category: cs.CL

TL;DR: 本文提出并验证了一种基于广义随机占优的多维质量评估方法（GSD-front），能更科学全面评测大语言模型生成文本，兼容多种评测指标并具备统计推断能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）生成文本的质量评估面临挑战，传统方法通常依赖单一或简单聚合的评估指标，难以全面捕捉文本的连贯性、多样性、流畅性等多维质量特征之间的权衡。此外，自动化指标和人工判断的数据类型不同，现有评估缺乏统计推断的保证。

Method: 本文引入并改进了基于广义随机占优（GSD）的统计推断框架。该方法允许同时对多种不同量纲的质量指标进行评估，利用解码策略的偏序关系，避免了对各指标进行任意权重分配。该框架兼容自动指标（定量）与人工评分（定序），并能为统计差异提供推断性保证。

Result: 通过将GSD-front方法应用于主流文本生成解码策略与人工文本对比评测，发现该框架能够有效揭示各方法间在多维度质量上的显著性能差异，确保了结果的统计可靠性，同时适应抽样设计可能并非独立同分布的实际情况。

Conclusion: GSD-front为LLM生成文本的多维度质量评估提供了系统、可靠且推断性强的方法，克服了以往单指标和缺乏推断保障的局限性，有助于推动NLP评测方法的发展。

Abstract: Assessing the quality of LLM-generated text remains a fundamental challenge
in natural language processing. Current evaluation approaches often rely on
isolated metrics or simplistic aggregations that fail to capture the nuanced
trade-offs between coherence, diversity, fluency, and other relevant indicators
of text quality. In this work, we adapt a recently proposed framework for
statistical inference based on Generalized Stochastic Dominance (GSD) that
addresses three critical limitations in existing benchmarking methodologies:
the inadequacy of single-metric evaluation, the incompatibility between
cardinal automatic metrics and ordinal human judgments, and the lack of
inferential statistical guarantees. The GSD-front approach enables simultaneous
evaluation across multiple quality dimensions while respecting their different
measurement scales, building upon partial orders of decoding strategies, thus
avoiding arbitrary weighting of the involved metrics. By applying this
framework to evaluate common decoding strategies against human-generated text,
we demonstrate its ability to identify statistically significant performance
differences while accounting for potential deviations from the i.i.d.
assumption of the sampling design.

</details>


### [140] [Evaluating Prompt-Based and Fine-Tuned Approaches to Czech Anaphora Resolution](https://arxiv.org/abs/2506.18091)
*Patrik Stano,Aleš Horák*

Main category: cs.CL

TL;DR: 本研究比较了捷克语指代消解任务中，两种主流深度学习方法（提示工程的LLM与微调生成模型）的表现。发现专门微调的mT5表现远超基于提示的LLM，建议在资源允许的前提下优先考虑微调策略。


<details>
  <summary>Details</summary>
Motivation: 指代消解（anaphora resolution）在自然语言理解中极为重要，尤其对于形态丰富的语言如捷克语。过去相关研究较少集中于捷克语，且不同方法的比较也不充分。本研究希望比较两种现代方法在捷克语指代消解任务上的效果。

Method: 基于Prague Dependency Treebank构建的捷克语数据集，评估若干指令微调的大型语言模型（如Mistral Large 2和Llama 3），通过不同提示模板实现，和我们专门为捷克语指代消解微调的紧凑生成式模型（mT5和Mistral变体）进行对比。主要关注准确率表现及计算资源消耗。

Result: 实验表明，基于提示工程的大型语言模型在少样本设置下表现可观（准确率最高达74.5%），但微调的模型（尤其是mT5-large）显著优于提示模型，准确率最高达88%，且所需计算资源更低。进一步分析了不同指代类型、前指距离和语料来源下的性能差异。

Conclusion: 对于捷克语指代消解任务，专门微调的生成式模型优于仅依赖提示的大型语言模型，不仅准确率更高，而且计算资源占用更少；不同方法间存在显著性能权衡。

Abstract: Anaphora resolution plays a critical role in natural language understanding,
especially in morphologically rich languages like Czech. This paper presents a
comparative evaluation of two modern approaches to anaphora resolution on Czech
text: prompt engineering with large language models (LLMs) and fine-tuning
compact generative models. Using a dataset derived from the Prague Dependency
Treebank, we evaluate several instruction-tuned LLMs, including Mistral Large 2
and Llama 3, using a series of prompt templates. We compare them against
fine-tuned variants of the mT5 and Mistral models that we trained specifically
for Czech anaphora resolution. Our experiments demonstrate that while prompting
yields promising few-shot results (up to 74.5% accuracy), the fine-tuned
models, particularly mT5-large, outperform them significantly, achieving up to
88% accuracy while requiring fewer computational resources. We analyze
performance across different anaphora types, antecedent distances, and source
corpora, highlighting key strengths and trade-offs of each approach.

</details>


### [141] [InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating](https://arxiv.org/abs/2506.18102)
*Fuyu Wang,Jiangtong Li,Kun Zhu,Changjun Jiang*

Main category: cs.CL

TL;DR: 本文提出了一个结合多维评估（包含客观与主观标准）和分阶段优化的LLM辩论框架，大幅提升了与专家判断的一致性和辩论效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在辩论任务上取得进展，但主要关注于对具体论点做出回应，忽略了真实性和逻辑有效性等客观评估，同时缺乏跨多个维度的结构化优化方法，影响了整体表现。

Method: 提出了一个双组件框架：（1）InspireScore：多维度评分系统，结合了四个主观标准（情感吸引力、论点清晰度、论点安排、主题相关性）和两个客观标准（事实真实性与逻辑有效性）；（2）InspireDebate：通过分阶段优化，包括链式思考（CoT）推理、多维直接偏好优化（DPO），以及基于Web检索增强生成（Web-RAG）的实时知识支持，优化多轮辩论。

Result: 实验证明，InspireScore与专家评判的相关性提升了44%；InspireDebate在各项表现上比基线模型高57%。

Conclusion: 提出的InspireScore 和 InspireDebate框架在主观和客观多维评估、推理能力优化以及知识支撑等方面，显著提升了LLM辩论系统的综合表现。

Abstract: With the rapid advancements in large language models (LLMs), debating tasks,
such as argument quality assessment and debate process simulation, have made
significant progress. However, existing LLM-based debating systems focus on
responding to specific arguments while neglecting objective assessments such as
authenticity and logical validity. Furthermore, these systems lack a structured
approach to optimize across various dimensions$-$including evaluation metrics,
chain-of-thought (CoT) reasoning, and multi-turn debate refinement$-$thereby
limiting their effectiveness. To address these interconnected challenges, we
propose a dual-component framework: (1) $\textbf{InspireScore}$, a novel
evaluation system that establishes a multi-dimensional assessment architecture
incorporating four subjective criteria (emotional appeal, argument clarity,
argument arrangement, and topic relevance) alongside two objective metrics
(fact authenticity and logical validity); and (2) $\textbf{InspireDebate}$, an
optimized debating framework employing a phased optimization approach through
CoT reasoning enhancement, multi-dimensional Direct Preference Optimization
(DPO), and real-time knowledge grounding via web-based Retrieval Augmented
Generation (Web-RAG). Empirical evaluations demonstrate that
$\textbf{InspireScore}$ achieves 44$\%$ higher correlation with expert
judgments compared to existing methods, while $\textbf{InspireDebate}$ shows
significant improvements, outperforming baseline models by 57$\%$. Source code
is available at https://github.com/fywang12/InspireDebate.

</details>


### [142] [Chengyu-Bench: Benchmarking Large Language Models for Chinese Idiom Understanding and Use](https://arxiv.org/abs/2506.18105)
*Yicheng Fu,Zhemin Huang,Liuxin Yang,Yumeng Lu,Zhongdongming Dai*

Main category: cs.CL

TL;DR: 本文提出了面向成语理解和使用的综合性基准Chengyu-Bench，评估发现当前大语言模型在情感判别上表现优异，但在成语语境恰当性及开放式填空任务中仍然效果有限，凸显出成语语义和文化理解是模型的短板。


<details>
  <summary>Details</summary>
Motivation: 汉语成语富含历史和文化内涵，但字面翻译常无法准确还原其意义，导致主流大语言模型（LLMs）难以有效理解和运用。现有成语测试基准数据集局限于狭窄任务，无法全面评估模型的真实能力。

Method: 提出Chengyu-Bench基准数据集，涵盖三类任务：(1) 成语褒贬分类；(2) 语境下成语使用恰当性检测；(3) 长文填空的开放式成语填空。数据集由2937个人工验证样例组成，涉及1765个常用成语，来源多元。评测主流LLMs在这些任务上的表现，并进行错误分析。

Result: 当前主流LLMs在成语褒贬分类任务上准确率超过95%，在使用恰当性检测任务约85%，在开放式填空的top-1准确率仅约40%。误差分析表明，大部分错误源于对成语意义的根本误解。

Conclusion: Chengyu-Bench证实，虽然LLMs能较好判断成语情感，但在理解成语深层文化与语境使用方面仍存在显著不足；该基准数据集为后续成语理解与应用的研究提供了有力工具。

Abstract: Chinese idioms (Chengyu) are concise four-character expressions steeped in
history and culture, whose literal translations often fail to capture their
full meaning. This complexity makes them challenging for language models to
interpret and use correctly. Existing benchmarks focus on narrow tasks -
multiple-choice cloze tests, isolated translation, or simple paraphrasing. We
introduce Chengyu-Bench, a comprehensive benchmark featuring three tasks: (1)
Evaluative Connotation, classifying idioms as positive or negative; (2)
Appropriateness, detecting incorrect idiom usage in context; and (3) Open
Cloze, filling blanks in longer passages without options. Chengyu-Bench
comprises 2,937 human-verified examples covering 1,765 common idioms sourced
from diverse corpora. We evaluate leading LLMs and find they achieve over 95%
accuracy on Evaluative Connotation, but only ~85% on Appropriateness and ~40%
top-1 accuracy on Open Cloze. Error analysis reveals that most mistakes arise
from fundamental misunderstandings of idiom meanings. Chengyu-Bench
demonstrates that while LLMs can reliably gauge idiom sentiment, they still
struggle to grasp the cultural and contextual nuances essential for proper
usage. The benchmark and source code are available at:
https://github.com/sofyc/ChengyuBench.

</details>


### [143] [The Syntactic Acceptability Dataset (Preview): A Resource for Machine Learning and Linguistic Analysis of English](https://arxiv.org/abs/2506.18120)
*Tom S Juzek*

Main category: cs.CL

TL;DR: 本文发布了一个大规模英语语法可接受性数据集，并揭示了语法性与可接受性大多一致，但机器学习模型预测可接受性优于语法性。


<details>
  <summary>Details</summary>
Motivation: 当前语法可接受性数据集较少，且对语法和可接受性的关系缺乏大规模分析；需要新的数据资源支持相关计算语言学和句法学研究。

Method: 从教科书和《Linguistic Inquiry》期刊采集1000条英语句子（各一半），分别标注句法形式中的语法正确性和通过众包获得的母语者可接受性，并进行初步统计和对比分析。还用机器学习模型对这两类标注进行了预测能力测试。

Result: 数据集中语法性与可接受性在约83%情况下相符，且‘介于两者之间’的情况较多，支持既有研究。同时，机器学习模型预测语法性表现较差，但预测可接受性表现较好，提出了新发现。

Conclusion: 该数据集目前为同类最大公开数据集，为研究语法性与可接受性及二者之间关系等提供了有力资源。未来将继续扩展该数据集。

Abstract: We present a preview of the Syntactic Acceptability Dataset, a resource being
designed for both syntax and computational linguistics research. In its current
form, the dataset comprises 1,000 English sequences from the syntactic
discourse: Half from textbooks and half from the journal Linguistic Inquiry,
the latter to ensure a representation of the contemporary discourse. Each entry
is labeled with its grammatical status ("well-formedness" according to
syntactic formalisms) extracted from the literature, as well as its
acceptability status ("intuitive goodness" as determined by native speakers)
obtained through crowdsourcing, with highest experimental standards. Even in
its preliminary form, this dataset stands as the largest of its kind that is
publicly accessible. We also offer preliminary analyses addressing three
debates in linguistics and computational linguistics: We observe that
grammaticality and acceptability judgments converge in about 83% of the cases
and that "in-betweenness" occurs frequently. This corroborates existing
research. We also find that while machine learning models struggle with
predicting grammaticality, they perform considerably better in predicting
acceptability. This is a novel finding. Future work will focus on expanding the
dataset.

</details>


### [144] [Outcome-Based Education: Evaluating Students' Perspectives Using Transformer](https://arxiv.org/abs/2506.17223)
*Shuvra Smaran Das,Anirban Saha Anik,Md Kishor Morol,Mohammad Sakib Mahmood*

Main category: cs.CL

TL;DR: 本文提出结合DistilBERT与LIME的学生反馈分析方法，显著提升情感分类准确性且兼具模型可解释性，切实支持成果导向教育（OBE）的实施。


<details>
  <summary>Details</summary>
Motivation: 随着以学生为中心的教学理念提升，成果导向教育（OBE）被重视，但如何量化与提升学习成果成为难题。当前学生反馈数据日益丰富，亟需更智能的分析方法以挖掘有效信息，优化教育实践。

Method: 采用transformer架构下的DistilBERT模型，对包含学生反馈的NLP数据集进行情感分类分析。同时，引入LIME（可解释性分析方法）提升模型预测的可解释性，从而理解关键词对情感决策的作用。

Result: DistilBERT模型在情感分类任务中的表现优于其他机器学习模型，在多项评价指标上结果更佳。此外，LIME的引入帮助解释模型的决策过程，使相关关键术语对情感的影响更透明。

Conclusion: 结合transformer模型与LIME可解释性技术，能够为OBE提供一种高效且透明的数据驱动型学生反馈分析方案，更有效地实现成果可量化，促进教育实践改进。

Abstract: Outcome-Based Education (OBE) emphasizes the development of specific
competencies through student-centered learning. In this study, we reviewed the
importance of OBE and implemented transformer-based models, particularly
DistilBERT, to analyze an NLP dataset that includes student feedback. Our
objective is to assess and improve educational outcomes. Our approach is better
than other machine learning models because it uses the transformer's deep
understanding of language context to classify sentiment better, giving better
results across a wider range of matrices. Our work directly contributes to
OBE's goal of achieving measurable outcomes by facilitating the identification
of patterns in student learning experiences. We have also applied LIME (local
interpretable model-agnostic explanations) to make sure that model predictions
are clear. This gives us understandable information about how key terms affect
sentiment. Our findings indicate that the combination of transformer models and
LIME explanations results in a strong and straightforward framework for
analyzing student feedback. This aligns more closely with the principles of OBE
and ensures the improvement of educational practices through data-driven
insights.

</details>


### [145] [Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs](https://arxiv.org/abs/2506.17231)
*Xiang Li,Chong Zhang,Jia Wang,Fangyu Wu,Yushi Li,Xiaobo Jin*

Main category: cs.CL

TL;DR: 提出一种新颖的对抗性提示词蒸馏方法，能让小模型对大模型高效越狱，验证了方法的高成功率和低资源消耗，同时揭示了大语言模型的安全挑战。


<details>
  <summary>Details</summary>
Motivation: 当前针对大语言模型（LLMs）的越狱攻击效率低、计算成本高，以及模型适应性和通用性差，难以应对LLMs的快速发展和新型防御策略。

Method: 提出了一种对抗性提示词蒸馏（Adversarial Prompt Distillation）方法，结合了掩码语言建模、强化学习和动态温度控制，通过提示词的生成和蒸馏策略，让小语言模型（SLMs）能够对主流LLMs发起越狱攻击。

Result: 实验结果显示，该方法在攻击成功率和危害性方面具有明显优势，同时体现出资源高效性和良好的跨模型适应性。

Conclusion: 本研究证明了将LLM越狱能力蒸馏到SLM的可行性，揭示了大模型存在的安全隐患，并为LLM安全研究提供了新思路。

Abstract: Attacks on large language models (LLMs) in jailbreaking scenarios raise many
security and ethical issues. Current jailbreak attack methods face problems
such as low efficiency, high computational cost, and poor cross-model
adaptability and versatility, which make it difficult to cope with the rapid
development of LLM and new defense strategies. Our work proposes an Adversarial
Prompt Distillation, which combines masked language modeling, reinforcement
learning, and dynamic temperature control through a prompt generation and
distillation method. It enables small language models (SLMs) to jailbreak
attacks on mainstream LLMs. The experimental results verify the superiority of
the proposed method in terms of attack success rate and harm, and reflect the
resource efficiency and cross-model adaptability. This research explores the
feasibility of distilling the jailbreak ability of LLM to SLM, reveals the
model's vulnerability, and provides a new idea for LLM security research.

</details>


### [146] [GTA: Grouped-head latenT Attention](https://arxiv.org/abs/2506.17286)
*Luoyang Sun,Jiwen Jiang,Cheng Deng,Xinjian Wu,Haifeng Zhang,Lei Chen,Lionel Ni,Jun Wang*

Main category: cs.CL

TL;DR: GTA是一种高效的注意力机制，通过共享注意力分数和压缩KV缓存，大幅减少大模型推理所需计算和内存，提升了部署与推理速度，并兼顾了性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型中的注意力机制存在大量计算与存储冗余，KV缓存和注意力计算在序列长度增长时急剧增加，限制了在资源有限设备上的部署。

Method: 提出了Grouped-Head Latent Attention (GTA)注意力机制，包含共享注意力图和非线性值解码器两部分，实现对KV缓存和运算的高效压缩与复用。

Result: 与Grouped-Query Attention方法相比，GTA将注意力计算FLOPs降低了62.5%，KV缓存缩小70%，无多余开销情况下实现了2倍推理速度提升，同时在prefill和decoding阶段都降低了硬件压力。

Conclusion: GTA方法显著降低了大语言模型推理过程中的计算和存储需求，同时保留了模型的性能表现。

Abstract: Attention mechanisms underpin the success of large language models (LLMs),
yet their substantial computational and memory overhead poses challenges for
optimizing efficiency and performance. A critical bottleneck arises as KV cache
and attention computations scale rapidly with text length, challenging
deployment on hardware with limited computational and memory resources. We
observe that attention mechanisms exhibit substantial redundancy, since the KV
cache can be significantly compressed and attention maps across heads display
high similarity, revealing that much of the computation and storage is
unnecessary. Leveraging these insights, we propose \textbf{G}rouped-Head
Laten\textbf{T} \textbf{A}ttention (GTA), a novel attention mechanism that
reduces memory usage and computational complexity while maintaining
performance. GTA comprises two components: (1) a shared attention map mechanism
that reuses attention scores across multiple heads, decreasing the key cache
size; and (2) a nonlinear value decoder with learned projections that
compresses the value cache into a latent space, further cutting memory needs.
GTA cuts attention computation FLOPs by up to \emph{62.5\%} versus
Grouped-Query Attention and shrink the KV cache by up to \emph{70\%}, all while
avoiding the extra overhead of Multi-Head Latent Attention to improve LLM
deployment efficiency. Consequently, GTA models achieve a \emph{2x} increase in
end-to-end inference speed, with prefill benefiting from reduced computational
cost and decoding benefiting from the smaller cache footprint.

</details>


### [147] [AI-Generated Game Commentary: A Survey and a Datasheet Repository](https://arxiv.org/abs/2506.17294)
*Qirui Zheng,Xingbo Wang,Keyuan Cheng,Yunlong Lu,Wenxin Li*

Main category: cs.CL

TL;DR: 本文系统梳理了AI游戏解说领域的挑战、方法和数据集，提出了一般框架，并提供了详细的资料汇总，有利于未来研究。


<details>
  <summary>Details</summary>
Motivation: AI生成游戏解说因其市场潜力和技术挑战受到关注，需要强大的多模态自然语言处理能力。

Method: 提出了AIGGC的一般框架，全面调研了45种现有的数据集和方法，并分类比较了主流评测指标。提供了标准化的数据集概要表。

Result: 归纳了该领域的关键挑战，对现有方法和数据集进行了系统性整理和比较，公开了相关数据汇总以便未来研究。

Conclusion: 该综述性工作为AIGGC领域的研究与评测提供了重要参考和系统资料，有助于推动该方向的发展。

Abstract: AI-Generated Game Commentary (AIGGC) has gained increasing attention due to
its market potential and inherent technical challenges. As a comprehensive
multimodal Natural Language Processing (NLP) task, AIGGC imposes substantial
demands on language models, including factual accuracy, logical reasoning,
expressive text generation, generation speed, and context management. In this
paper, we introduce a general framework for AIGGC and present a comprehensive
survey of 45 existing game commentary dataset and methods according to key
challenges they aim to address in this domain. We further classify and compare
various evaluation metrics commonly used in this domain. To support future
research and benchmarking, we also provide a structured datasheet summarizing
the essential attributes of these datasets in appendix, which is meanwhile
publicly available in an open repository.

</details>


### [148] [Semantic uncertainty in advanced decoding methods for LLM generation](https://arxiv.org/abs/2506.17296)
*Darius Foodeei,Simin Fan,Martin Jaggi*

Main category: cs.CL

TL;DR: 实验表明，创新解码方法（CoT、speculative sampling）能同时提升大模型输出的多样性和可靠性，优化实际应用效果，突破了以往二者需权衡的认知。


<details>
  <summary>Details</summary>
Motivation: 现有关于大语言模型输出多样性和可靠性的研究通常假设存在权衡关系，但随着新兴解码方法（如speculative sampling和CoT）的出现，这一假设值得重新评估。本文旨在探讨不同解码策略对输出结果语义多样性与可靠性的影响。

Method: 本文通过实验比较多种解码方法（包括speculative sampling和CoT解码）在问答、摘要、代码生成等任务中的表现，系统评估各解码方式下模型输出的多样性和可靠性，并采用如Pass@2、ROUGE等指标进行量化分析。

Result: CoT解码能够提升语义多样性，同时表现出更低的预测熵（即输出更加自信且准确），在代码生成上的Pass@2提升了48.8%，但与参考答案的一致性略低。摘要任务中，speculative sampling获得了更高的ROUGE分数，并保持了适中的语义多样性。实验挑战了多样性与准确性互为负相关的传统观点。

Conclusion: 结构化的解码方法（如CoT和speculative sampling）不仅能提升语义探索能力，还能保持甚至提升输出质量。因此，在关注结果可靠性和多样性的实际应用场景中，采用恰当的解码方式能够带来显著优势。

Abstract: This study investigates semantic uncertainty in large language model (LLM)
outputs across different decoding methods, focusing on emerging techniques like
speculative sampling and chain-of-thought (CoT) decoding. Through experiments
on question answering, summarization, and code generation tasks, we analyze how
different decoding strategies affect both the diversity and reliability of
model outputs. Our findings reveal that while CoT decoding demonstrates higher
semantic diversity, it maintains lower predictive entropy, suggesting that
structured exploration can lead to more confident and accurate outputs. This is
evidenced by a 48.8% improvement in code generation Pass@2 rates, despite lower
alignment with reference solutions. For summarization tasks, speculative
sampling proved particularly effective, achieving superior ROUGE scores while
maintaining moderate semantic diversity. Our results challenge conventional
assumptions about trade-offs between diversity and accuracy in language model
outputs, demonstrating that properly structured decoding methods can increase
semantic exploration while maintaining or improving output quality. These
findings have significant implications for deploying language models in
practical applications where both reliability and diverse solution generation
are crucial.

</details>


### [149] [Mercury: Ultra-Fast Language Models Based on Diffusion](https://arxiv.org/abs/2506.17298)
*Inception Labs,Samar Khanna,Siddhant Kharbanda,Shufan Li,Harshit Varma,Eric Wang,Sawyer Birnbaum,Ziyang Luo,Yanis Miraoui,Akash Palrecha,Stefano Ermon,Aditya Grover,Volodymyr Kuleshov*

Main category: cs.CL

TL;DR: Mercury Coder 是基于扩散机制和Transformer的新一代代码生成大语言模型，在保证生成质量的同时，推理速度相比现有模型实现大幅领先，成为代码生成领域的速度与质量新标杆。


<details>
  <summary>Details</summary>
Motivation: 当前的商业级大语言模型（LLM）在满足高推理速度与生成质量间存在权衡，尤其在代码生成领域，兼顾高吞吐量与高质量的模型需求迫切。

Method: 提出基于扩散机制（diffusion）的新一代大语言模型Mercury，并采用Transformer架构实现多token并行预测。该报告重点介绍了面向代码生成任务的Mercury Coder（Mini和Small两个版本），在NVIDIA H100 GPU上进行独立基准评测。

Result: Mercury Coder Mini和Small在H100 GPU上的吞吐量分别达到1109和737 tokens/s，速度显著优于现有速度优化前沿模型，平均超过10倍，同时生成质量可与之媲美。在多语言、不同用例的代码基准测试中表现突出，并在Copilot Arena中以第二的生成质量和最快速度获得开发者验证。

Conclusion: Mercury Coder系列以全新基于扩散机制的并行预测方法，极大提升代码生成效率，在不牺牲质量的前提下实现突破性的推理速度，并已通过开源API和在线体验平台面向公众开放。

Abstract: We present Mercury, a new generation of commercial-scale large language
models (LLMs) based on diffusion. These models are parameterized via the
Transformer architecture and trained to predict multiple tokens in parallel. In
this report, we detail Mercury Coder, our first set of diffusion LLMs designed
for coding applications. Currently, Mercury Coder comes in two sizes: Mini and
Small. These models set a new state-of-the-art on the speed-quality frontier.
Based on independent evaluations conducted by Artificial Analysis, Mercury
Coder Mini and Mercury Coder Small achieve state-of-the-art throughputs of 1109
tokens/sec and 737 tokens/sec, respectively, on NVIDIA H100 GPUs and outperform
speed-optimized frontier models by up to 10x on average while maintaining
comparable quality. We discuss additional results on a variety of code
benchmarks spanning multiple languages and use-cases as well as real-world
validation by developers on Copilot Arena, where the model currently ranks
second on quality and is the fastest model overall. We also release a public
API at https://platform.inceptionlabs.ai/ and free playground at
https://chat.inceptionlabs.ai

</details>


### [150] [PRAISE: Enhancing Product Descriptions with LLM-Driven Structured Insights](https://arxiv.org/abs/2506.17314)
*Adnan Qidwai,Srija Mukhopadhyay,Prerana Khatiwada,Dan Roth,Vivek Gupta*

Main category: cs.CL

TL;DR: 提出并演示了PRAISE系统，使用大语言模型自动从评论和描述中提取并对比产品属性，极大提升商品信息质量和平台信度。


<details>
  <summary>Details</summary>
Motivation: 电商中的产品描述往往信息不全，而客户评论中潜藏有价值却分散的信息，手动筛查成本高。因此需要自动工具来整合和强化商品资料。

Method: 开发并应用了PRAISE系统，该系统利用大语言模型自动从用户评论和卖家描述中抽取、结构化产品属性信息，并通过界面展示这些数据及其差异。

Result: PRAISE能将评论和描述之间缺漏、矛盾信息直观呈现，并提供相应证据，方便卖家优化信息、买家评估商品，提升电商平台内容质量与信任度。

Conclusion: PRAISE系统能够有效提取、对比并结构化电商商品评论与描述中的关键信息，帮助识别与完善产品描述，提高商品目录的质量与信任度。

Abstract: Accurate and complete product descriptions are crucial for e-commerce, yet
seller-provided information often falls short. Customer reviews offer valuable
details but are laborious to sift through manually. We present PRAISE: Product
Review Attribute Insight Structuring Engine, a novel system that uses Large
Language Models (LLMs) to automatically extract, compare, and structure
insights from customer reviews and seller descriptions. PRAISE provides users
with an intuitive interface to identify missing, contradictory, or partially
matching details between these two sources, presenting the discrepancies in a
clear, structured format alongside supporting evidence from reviews. This
allows sellers to easily enhance their product listings for clarity and
persuasiveness, and buyers to better assess product reliability. Our
demonstration showcases PRAISE's workflow, its effectiveness in generating
actionable structured insights from unstructured reviews, and its potential to
significantly improve the quality and trustworthiness of e-commerce product
catalogs.

</details>


### [151] [Towards Safety Evaluations of Theory of Mind in Large Language Models](https://arxiv.org/abs/2506.17352)
*Tatsuhiro Aoshima,Mitsuaki Akiyama*

Main category: cs.CL

TL;DR: 本文关注LLM的安全评估问题，提出测量其理论心智能力的重要性。通过分析多个开源LLM，发现尽管模型在阅读理解上进步显著，但在理论心智能力方面提升有限，并探讨了相关评测的挑战。


<details>
  <summary>Details</summary>
Motivation: 近期，LLM在安全评估领域被发现存在规避监管和欺骗性回应等风险行为。为区分这些行为是否源于模型的有意隐蔽过程，需要探索其理论心智能力。

Method: 回顾现有理论心智相关研究，界定其在安全评估中的应用视角与任务，并对多个开源模型进行了发展趋势分析。

Result: LLM在阅读理解方面明显提升，但理论心智能力未见类似进展。同时指出理论心智视角下安全评估的现状及未来挑战。

Conclusion: 当前大语言模型（LLM）在理论心智（theory of mind）能力上并未展现出与其阅读理解能力同步的提升，这对安全性评估带来挑战。

Abstract: As the capabilities of large language models (LLMs) continue to advance, the
importance of rigorous safety evaluation is becoming increasingly evident.
Recent concerns within the realm of safety assessment have highlighted
instances in which LLMs exhibit behaviors that appear to disable oversight
mechanisms and respond in a deceptive manner. For example, there have been
reports suggesting that, when confronted with information unfavorable to their
own persistence during task execution, LLMs may act covertly and even provide
false answers to questions intended to verify their behavior.To evaluate the
potential risk of such deceptive actions toward developers or users, it is
essential to investigate whether these behaviors stem from covert, intentional
processes within the model. In this study, we propose that it is necessary to
measure the theory of mind capabilities of LLMs. We begin by reviewing existing
research on theory of mind and identifying the perspectives and tasks relevant
to its application in safety evaluation. Given that theory of mind has been
predominantly studied within the context of developmental psychology, we
analyze developmental trends across a series of open-weight LLMs. Our results
indicate that while LLMs have improved in reading comprehension, their theory
of mind capabilities have not shown comparable development. Finally, we present
the current state of safety evaluation with respect to LLMs' theory of mind,
and discuss remaining challenges for future work.

</details>


### [152] [Cash or Comfort? How LLMs Value Your Inconvenience](https://arxiv.org/abs/2506.17367)
*Mateusz Cedro,Timour Ichmoukhamedov,Sofie Goethals,Yifan He,James Hinns,David Martens*

Main category: cs.CL

TL;DR: 本文发现，当前大语言模型在涉及用户舒适与金钱奖励的决策中表现出高波动、不合理定价和对提示敏感等问题，提示其不适宜在相关实际应用中直接决策。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）被提议作为能够代表人类做日常决策的AI代理，但其在涉及用户舒适度与金钱奖励冲突时的决策行为尚未得到充分研究。

Method: 量化多个主流LLM对用户不适（如多走路、等待、饥饿和疼痛）的“价格”评估，即分析它们在现金与舒适权衡场景下给出的具体数值反应。

Result: （1）不同LLM的回复差异很大；（2）单一LLM在提示语的细微变化下表现脆弱；（3）LLM有时会对重大不便接受极低报酬（如为等待10小时只收1欧元）；（4）在无不适情况下，LLM甚至会拒绝可观报酬（如等待0分钟拒收1000欧元）。

Conclusion: 目前LLM在现金与用户舒适权衡方面的行为存在诸多问题，难以直接作为可靠的决策助手，需谨慎评估其在此类场景下的实际应用。

Abstract: Large Language Models (LLMs) are increasingly proposed as near-autonomous
artificial intelligence (AI) agents capable of making everyday decisions on
behalf of humans. Although LLMs perform well on many technical tasks, their
behaviour in personal decision-making remains less understood. Previous studies
have assessed their rationality and moral alignment with human decisions.
However, the behaviour of AI assistants in scenarios where financial rewards
are at odds with user comfort has not yet been thoroughly explored. In this
paper, we tackle this problem by quantifying the prices assigned by multiple
LLMs to a series of user discomforts: additional walking, waiting, hunger and
pain. We uncover several key concerns that strongly question the prospect of
using current LLMs as decision-making assistants: (1) a large variance in
responses between LLMs, (2) within a single LLM, responses show fragility to
minor variations in prompt phrasing (e.g., reformulating the question in the
first person can considerably alter the decision), (3) LLMs can accept
unreasonably low rewards for major inconveniences (e.g., 1 Euro to wait 10
hours), and (4) LLMs can reject monetary gains where no discomfort is imposed
(e.g., 1,000 Euro to wait 0 minutes). These findings emphasize the need for
scrutiny of how LLMs value human inconvenience, particularly as we move toward
applications where such cash-versus-comfort trade-offs are made on users'
behalf.

</details>


### [153] [Leveraging LLMs to Assess Tutor Moves in Real-Life Dialogues: A Feasibility Study](https://arxiv.org/abs/2506.17410)
*Danielle R. Thomas,Conrad Borchers,Jionghao Lin,Sanjit Kakarla,Shambhavi Bhushan,Erin Gatz,Shivang Gupta,Ralph Abboud,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: 本研究证明，大语言模型可高效准确识别和评价真实数学辅导中的关键行为，为辅导质量评估和教育AI研究提供了新工具和实用提示。


<details>
  <summary>Details</summary>
Motivation: 现有研究已表明辅导能够提高学生成绩，但如何基于大规模音频转录数据，识别和研究对学生学习最相关的辅导行为，仍是一个未解决的研究难题。

Method: 本研究分析了50份随机抽取的大学生远程辅导中学生数学的转录文本，采用GPT-4、GPT-4o、GPT-4-turbo、Gemini-1.5-pro和LearnLM等生成式大模型，评估导师在有效表扬和应对学生数学错误两个技能上的表现。通过大模型检测并评价辅导行为的准确性和与人类判断的一致性。

Result: 各大模型能够高准确率检测导师表扬（准确率94-98%）和学生犯错（准确率82-88%）的情景，并能有效评价导师是否遵循最佳实践，其评价结果与人工一致度高（83-89%和73-77%）。

Conclusion: 生成式大模型可作为经济高效、可扩展的工具，为实际辅导场景中行为评估提供支持，并促进AI辅助学习的研究与可复现性。论文还贡献了相关LLM提示词。

Abstract: Tutoring improves student achievement, but identifying and studying what
tutoring actions are most associated with student learning at scale based on
audio transcriptions is an open research problem. This present study
investigates the feasibility and scalability of using generative AI to identify
and evaluate specific tutor moves in real-life math tutoring. We analyze 50
randomly selected transcripts of college-student remote tutors assisting middle
school students in mathematics. Using GPT-4, GPT-4o, GPT-4-turbo,
Gemini-1.5-pro, and LearnLM, we assess tutors' application of two tutor skills:
delivering effective praise and responding to student math errors. All models
reliably detected relevant situations, for example, tutors providing praise to
students (94-98% accuracy) and a student making a math error (82-88% accuracy)
and effectively evaluated the tutors' adherence to tutoring best practices,
aligning closely with human judgments (83-89% and 73-77%, respectively). We
propose a cost-effective prompting strategy and discuss practical implications
for using large language models to support scalable assessment in authentic
settings. This work further contributes LLM prompts to support reproducibility
and research in AI-supported learning.

</details>


### [154] [UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making](https://arxiv.org/abs/2506.17419)
*Jinhao Duan,James Diffenderfer,Sandeep Madireddy,Tianlong Chen,Bhavya Kailkhura,Kaidi Xu*

Main category: cs.CL

TL;DR: 本文为LLM多步决策场景下的不确定性量化提出信息论分解框架，并设计出有效实用的UProp方法，在多个基准测试中明显胜出传统方法。


<details>
  <summary>Details</summary>
Motivation: LLM被应用于安全关键场景中的序列决策任务时，何时应该信任LLM的决策至关重要。现有不确定性量化方法主要适用于单轮问答，缺乏对多步决策场景的刻画与应对。

Method: 提出了一种信息论框架，将LLM在序列决策中的不确定性分为内部不确定性和外部不确定性，并引入UProp方法，通过估计不同轨迹下的点对互信息（PMI）来高效衡量外部不确定性。实验在AgentBench、HotpotQA等多步决策基准以及如GPT-4.1等SOTA大模型上进行。

Result: 实验表明，UProp在多步决策评测中显著优于带有聚合策略的主流UQ方法，并展现了极佳的采样效率和实际应用潜力。

Conclusion: UProp方法在多步决策任务中显著优于现有单轮UQ基线，并通过全面分析展示了其实用性与有效性。

Abstract: As Large Language Models (LLMs) are integrated into safety-critical
applications involving sequential decision-making in the real world, it is
essential to know when to trust LLM decisions. Existing LLM Uncertainty
Quantification (UQ) methods are primarily designed for single-turn
question-answering formats, resulting in multi-step decision-making scenarios,
e.g., LLM agentic system, being underexplored. In this paper, we introduce a
principled, information-theoretic framework that decomposes LLM sequential
decision uncertainty into two parts: (i) internal uncertainty intrinsic to the
current decision, which is focused on existing UQ methods, and (ii) extrinsic
uncertainty, a Mutual-Information (MI) quantity describing how much uncertainty
should be inherited from preceding decisions. We then propose UProp, an
efficient and effective extrinsic uncertainty estimator that converts the
direct estimation of MI to the estimation of Pointwise Mutual Information (PMI)
over multiple Trajectory-Dependent Decision Processes (TDPs). UProp is
evaluated over extensive multi-step decision-making benchmarks, e.g.,
AgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and
DeepSeek-V3. Experimental results demonstrate that UProp significantly
outperforms existing single-turn UQ baselines equipped with thoughtful
aggregation strategies. Moreover, we provide a comprehensive analysis of UProp,
including sampling efficiency, potential applications, and intermediate
uncertainty propagation, to demonstrate its effectiveness. Codes will be
available at https://github.com/jinhaoduan/UProp.

</details>


### [155] [Beyond the Link: Assessing LLMs' ability to Classify Political Content across Global Media](https://arxiv.org/abs/2506.17435)
*Alberto Martinez-Serra,Alejandro De La Fuente,Nienke Viescher,Ana S. Cardenal*

Main category: cs.CL

TL;DR: 该文验证了多种LLM模型用仅URL即可有效识别多国多语文章的政治内容，URL分析可部分替代全文，在精度与成本间达成平衡，并为政治学研究方法提供建议。


<details>
  <summary>Details</summary>
Motivation: 目前LLMs在政治科学领域被广泛用于数字媒体内容分析，但仅通过URL识别政治内容的有效性尚未充分研究。该研究旨在验证LLMs能否基于URL而非全文高效辨识政治内容，从而降低分析成本。

Method: 对法国、德国、西班牙、英国和美国等五国不同语言的文章，利用多种最新LLMs模型（如GPT、Llama等）进行政治内容识别，分别用文章全文和仅用URL进行，输出结果与人工标注及传统监督学习方法对比评估。

Result: LLMs在仅用URL对新闻内容进行政治内容分类时表现优异，URL包含了大部分重要指征，能够很好地替代部分全文分析，并提出了相关方法建议。

Conclusion: LLMs能够通过分析文章URL准确识别政治内容，且在多语种、多国家情境下表现良好。URL分析在一定程度上可近似全文分析，并在准确性和成本之间提供平衡。

Abstract: The use of large language models (LLMs) is becoming common in the context of
political science, particularly in studies that analyse individuals use of
digital media. However, while previous research has demonstrated LLMs ability
at labelling tasks, the effectiveness of using LLMs to classify political
content (PC) from just URLs is not yet well explored. The work presented in
this article bridges this gap by evaluating whether LLMs can accurately
identify PC vs. non-PC from both the article text and the URLs from five
countries (France, Germany, Spain, the UK, and the US) and different languages.
Using cutting-edge LLMs like GPT, Llama, Mistral, Deepseek, Qwen and Gemma, we
measure model performance to assess whether URL-level analysis can be a good
approximation for full-text analysis of PC, even across different linguistic
and national contexts. Model outputs are compared with human-labelled articles,
as well as traditional supervised machine learning techniques, to set a
baseline of performance. Overall, our findings suggest the capacity of URLs to
embed most of the news content, providing a vital perspective on accuracy-cost
balancing. We also account for contextual limitations and suggest
methodological recommendations to use LLMs within political science studies.

</details>


### [156] [Breaking the Transcription Bottleneck: Fine-tuning ASR Models for Extremely Low-Resource Fieldwork Languages](https://arxiv.org/abs/2506.17459)
*Siyu Liang,Gina-Anne Levow*

Main category: cs.CL

TL;DR: 本研究系统对比测试了两种主流多语种ASR在低资源语言田野语音数据上的效果，提出针对不同数据量的模型选择建议，有助于提升语言学田野工作的自动转写效率。


<details>
  <summary>Details</summary>
Motivation: 尽管自动语音识别（ASR）在高资源语言上取得了显著准确率，但应用于语言田野调查仍有局限，尤其面对低资源和受限制的数据集。该研究旨在解决实地语料自动转写的瓶颈难题。

Method: 作者基于五种类型多样、资源稀缺的语言，严格控制训练数据量，测试并对比了两种多语种ASR模型（MMS和XLS-R）的微调效果，分析了不同数据量下的表现。

Result: 结果显示，当训练数据极少时，MMS表现更优；当训练数据超过一小时时，XLS-R表现可与MMS持平。

Conclusion: 论文为田野语言学工作者提供了实用的ASR微调适应建议，并阐释了可复现的适应流程，可有效缓解语言档案转写工作中的瓶颈。

Abstract: Automatic Speech Recognition (ASR) has reached impressive accuracy for
high-resource languages, yet its utility in linguistic fieldwork remains
limited. Recordings collected in fieldwork contexts present unique challenges,
including spontaneous speech, environmental noise, and severely constrained
datasets from under-documented languages. In this paper, we benchmark the
performance of two fine-tuned multilingual ASR models, MMS and XLS-R, on five
typologically diverse low-resource languages with control of training data
duration. Our findings show that MMS is best suited when extremely small
amounts of training data are available, whereas XLS-R shows parity performance
once training data exceed one hour. We provide linguistically grounded analysis
for further provide insights towards practical guidelines for field linguists,
highlighting reproducible ASR adaptation approaches to mitigate the
transcription bottleneck in language documentation.

</details>


### [157] [Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems](https://arxiv.org/abs/2506.17467)
*Weixin Liang*

Main category: cs.CL

TL;DR: 论文系统分析了大语言模型应用对个人和机构的影响，包括AI检测带来的公平性挑战、LLM普及的群体级趋势及其在科研支持中的潜力，呼吁关注AI治理与资源分配的公平性问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）在社会中的广泛应用，人们和机构必须适应并合理利用这一新兴技术。该论文旨在探讨LLM带来的社会影响以及相关公平性、普及性和实用性问题。

Method: 论文通过三条研究路径进行探讨：1）分析AI检测器的制度性应用，揭示其对非主流语言写作者的不公平影响；2）提出群体级的算法方法，量化LLM在各类写作领域中的采用率，如学术评审、科学出版、消费者投诉、企业沟通、招聘广告和国际组织新闻稿等；3）大规模实证分析LLM在科研手稿反馈中的作用，特别关注受限资源研究者可获得支持的情况。

Result: 1）AI检测工具在制度应用中造成系统性偏见，非主流语言使用者尤为受害，暴露AI治理中的公平性问题；2）在多个写作领域发现LLM辅助内容的普遍存在及其持续增长的采用趋势；3）LLM能够为科研手稿提供反馈，显示支持早期研究者和资源匮乏群体的潜力。

Conclusion: 大语言模型的广泛应用正在深刻影响写作实践和学术交流，但也带来了公平性和治理等重要挑战。针对性技术手段和政策需同步发展，以确保技术进步带来的机会可以公平惠及不同群体。

Abstract: Large language models (LLMs) have shown significant potential to change how
we write, communicate, and create, leading to rapid adoption across society.
This dissertation examines how individuals and institutions are adapting to and
engaging with this emerging technology through three research directions.
First, I demonstrate how the institutional adoption of AI detectors introduces
systematic biases, particularly disadvantaging writers of non-dominant language
varieties, highlighting critical equity concerns in AI governance. Second, I
present novel population-level algorithmic approaches that measure the
increasing adoption of LLMs across writing domains, revealing consistent
patterns of AI-assisted content in academic peer reviews, scientific
publications, consumer complaints, corporate communications, job postings, and
international organization press releases. Finally, I investigate LLMs'
capability to provide feedback on research manuscripts through a large-scale
empirical analysis, offering insights into their potential to support
researchers who face barriers in accessing timely manuscript feedback,
particularly early-career researchers and those from under-resourced settings.

</details>


### [158] [VeriLocc: End-to-End Cross-Architecture Register Allocation via LLM](https://arxiv.org/abs/2506.17506)
*Lesheng Jin,Zhenyuan Ruan,Haohui Mai,Jingbo Shang*

Main category: cs.CL

TL;DR: VeriLocc通过LLM和验证技术，将GPU寄存器分配自动化、泛化，并可超越手工调优的主流库，在编译器实现上带来新突破。


<details>
  <summary>Details</summary>
Motivation: 现代GPU硬件更新快，但编译器寄存器分配仍依赖人工设计的启发式方法，每代硬件都需大量重新调整。缺乏泛化和自动验证能力，限制了编译器效率和移植性。

Method: 提出了VeriLocc框架，结合大型语言模型（LLM）与形式化编译器技术，通过对LLM进行微调，让其将中间表示（MIR）翻译为目标硬件的寄存器分配。采用静态分析实现跨架构归一化与泛化，引入验证器指导的再生成循环确保分配的正确性。

Result: 在矩阵乘法（GEMM）与多头注意力（MHA）测试中，VeriLocc一次性分配准确率达85-99%，100次再生成几乎100%正确。案例分析表明，VeriLocc生成的寄存器分配优于专家调优库，矩阵乘法比rocBLAS库运行时间快10%以上。

Conclusion: LLM与形式化编译器技术结合能够实现高效、泛化、可验证的GPU寄存器分配，减少人工干预且提升性能。VeriLocc能超越传统专家调优方法，具有实际应用价值。

Abstract: Modern GPUs evolve rapidly, yet production compilers still rely on
hand-crafted register allocation heuristics that require substantial re-tuning
for each hardware generation. We introduce VeriLocc, a framework that combines
large language models (LLMs) with formal compiler techniques to enable
generalizable and verifiable register allocation across GPU architectures.
VeriLocc fine-tunes an LLM to translate intermediate representations (MIRs)
into target-specific register assignments, aided by static analysis for
cross-architecture normalization and generalization and a verifier-guided
regeneration loop to ensure correctness. Evaluated on matrix multiplication
(GEMM) and multi-head attention (MHA), VeriLocc achieves 85-99% single-shot
accuracy and near-100% pass@100. Case study shows that VeriLocc discovers more
performant assignments than expert-tuned libraries, outperforming rocBLAS by
over 10% in runtime.

</details>


### [159] [Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning](https://arxiv.org/abs/2506.17525)
*Mingfei Lau,Qian Chen,Yeming Fang,Tingting Xu,Tongzhou Chen,Pavel Golik*

Main category: cs.CL

TL;DR: 本文针对三大多语种语音数据集进行质量审查，指出资源稀缺语言存在严重质量问题。以台灣閩南語为例，强调规范化与数据管控，并提出改进建议，呼吁增强社会语言学意识以提升数据质量。


<details>
  <summary>Details</summary>
Motivation: 当前广泛使用的多语种语音数据集在部分语言上存在显著质量问题，尤其影响训练和评估自动语音识别（ASR）模型的可靠性，因此有必要审视并提升数据集质量。

Method: 对Mozilla Common Voice 17.0、FLEURS和VoxPopuli三大公开多语种语音数据集进行质量审计，将发现的问题分为微观和宏观两个层面，并以台灣閩南語（nan_tw）为案例，分析具体语料问题并提出改进建议。

Result: 发现较少受机构支持、资源稀缺语言的数据集宏观质量问题更为严重，特别是在正字法与方言边界界定及数据质量管控方面存在明显缺陷。通过台灣閩南語案例，凸显了主动语言规划与数据质量提升的必要性。

Conclusion: 为未来语音数据集开发提出了具体准则和建议，倡导在数据集构建过程中增强社会语言学意识，从而提升语音资源的稳健性与可靠性。

Abstract: Our quality audit for three widely used public multilingual speech datasets -
Mozilla Common Voice 17.0, FLEURS, and VoxPopuli - shows that in some
languages, these datasets suffer from significant quality issues. We believe
addressing these issues will make these datasets more useful as training and
evaluation sets, and improve downstream models. We divide these quality issues
into two categories: micro-level and macro-level. We find that macro-level
issues are more prevalent in less institutionalized, often under-resourced
languages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that
highlights the need for proactive language planning (e.g. orthography
prescriptions, dialect boundary definition) and enhanced data quality control
in the process of Automatic Speech Recognition (ASR) dataset creation. We
conclude by proposing guidelines and recommendations to mitigate these issues
in future dataset development, emphasizing the importance of sociolinguistic
awareness in creating robust and reliable speech data resources.

</details>


### [160] [DuaShepherd: Integrating Stepwise Correctness and Potential Rewards for Mathematical Reasoning](https://arxiv.org/abs/2506.17533)
*Yuanhao Wu,Juntong Song,Hanning Zhang,Tong Zhang,Cheng Niu*

Main category: cs.CL

TL;DR: 提出DuaShepherd框架，将正确性与潜力奖励信号结合，多任务训练，显著提升LLM数学推理性能，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励建模方法侧重于单一信号（如正确性），难以全面提升大语言模型数学推理能力。

Method: 提出DuaShepherd奖励建模框架，集成“正确性”和“潜力”双重奖励信号，通过自动化数据集构建与多任务、多头网络并行训练，联合建模两种奖励信号。

Result: 实验在MATH500和ProcessBench数据集上验证，双信号结合训练的模型显著优于仅用任一单一奖励信号，达到同类最优表现。

Conclusion: DuaShepherd框架利用正确性和潜力双重奖励信号，有效提升了大语言模型数学推理能力，实现了性能上的持续提升。

Abstract: In this paper, we propose DuaShepherd, a novel reward modeling framework that
integrates two complementary reward signals, correctness and potential, to
enhance the mathematical reasoning capabilities of Large Language Models
(LLMs). While correctness-based signals emphasize identification of stepwise
errors, potential-based signals focus on the likelihood of reaching the correct
final answer. We developed an automated pipeline for constructing large-scale
reward modeling dataset with both signals. A unified, multi-head architecture
was explored to train the two reward models in a multi-task setup,
demonstrating benefits from learning both correctness and potential in
parallel. By combining these two signals into a compound probability, our model
achieves consistent performance improvements across multiple benchmarks.
Empirical evaluations on MATH500 and ProcessBench confirm that this combined
reward significantly outperforms models trained on either reward type alone,
achieving state-of-the-art performance under comparable resource constraints.

</details>


### [161] [Probing for Phonology in Self-Supervised Speech Representations: A Case Study on Accent Perception](https://arxiv.org/abs/2506.17542)
*Nitin Venkateswaran,Kevin Tang,Ratree Wayland*

Main category: cs.CL

TL;DR: 研究证明自监督语音模型（如Wav2Vec2-BERT、WavLM）在表达口音感知所需的可解释音系特征上非常有效，能提升对非母语者英语口音强度的预测与解释能力，对口音识别和建模有重要启示。


<details>
  <summary>Details</summary>
Motivation: 传统口音感知模型低估了听者评判口音时所依赖的音系特征梯度差异，缺乏对音系层面变异的精准刻画。自监督语音模型在音系层面建模能力尚未明晰。

Method: 研究对比了三种英语音段（唇齿近音、闪音r和卷舌塞音）在印度及次大陆语言的母语者英语发音，与标准美式英语的差异，利用CSLU Foreign Accented English语料库，分别用Phonet工具和Wav2Vec2-BERT、WavLM等SSL模型提取音段的音系特征概率和预训练表示，通过美式英语母语者进行口音判定，并用探测分析及多项Logistic回归量化模型特征与口音强度的关联。

Result: 实验发现口音强度最能被部分预训练表示特征预测，这些特征恰好反映了美式和印度英语音段在感知上显著的音系特征差异。模型提取的音段距离与口音强度显著相关，且方向符合预期。

Conclusion: 自监督学习（SSL）语音模型的预训练表示能够有效建模和解释口音感知中感知显著的音系特征变化，在口音强度判断任务中具有明显优势。

Abstract: Traditional models of accent perception underestimate the role of gradient
variations in phonological features which listeners rely upon for their accent
judgments. We investigate how pretrained representations from current
self-supervised learning (SSL) models of speech encode phonological
feature-level variations that influence the perception of segmental accent. We
focus on three segments: the labiodental approximant, the rhotic tap, and the
retroflex stop, which are uniformly produced in the English of native speakers
of Hindi as well as other languages in the Indian sub-continent. We use the
CSLU Foreign Accented English corpus (Lander, 2007) to extract, for these
segments, phonological feature probabilities using Phonet (V\'asquez-Correa et
al., 2019) and pretrained representations from Wav2Vec2-BERT (Barrault et al.,
2023) and WavLM (Chen et al., 2022) along with accent judgements by native
speakers of American English. Probing analyses show that accent strength is
best predicted by a subset of the segment's pretrained representation features,
in which perceptually salient phonological features that contrast the expected
American English and realized non-native English segments are given prominent
weighting. A multinomial logistic regression of pretrained representation-based
segment distances from American and Indian English baselines on accent ratings
reveals strong associations between the odds of accent strength and distances
from the baselines, in the expected directions. These results highlight the
value of self-supervised speech representations for modeling accent perception
using interpretable phonological features.

</details>


### [162] [AgriCHN: A Comprehensive Cross-domain Resource for Chinese Agricultural Named Entity Recognition](https://arxiv.org/abs/2506.17578)
*Lingxiao Zeng,Yiqi Tong,Wei Guo,Huarui Wu,Lihao Ge,Yijun Ye,Fuzhen Zhuang,Deqing Wang,Wei Guo,Cheng Chen*

Main category: cs.CL

TL;DR: 本文提出了AgriCHN中文农业命名实体识别数据集，涵盖农业与水文、气象多类别高质量实体，经验证优于现有资源，并具挑战性与研究价值。


<details>
  <summary>Details</summary>
Motivation: 农业领域的命名实体识别缺乏高质量、特别是中文的数据集，导致主流方法表现不佳。同时，现有工作忽视了农业与水文和气象领域的密切关联。

Method: 提出并构建了AgriCHN，一个全面的开源中文农业命名实体识别数据集。该数据集包含4040个句子，涵盖15799个农业实体，涉及27个类别，并囊括了与水文和气象相关的实体。用多种当前主流神经网络NER模型进行了基准实验。

Result: 数据验证表明，AgriCHN在数据质量上优于相关资源，包括更丰富的农业实体类型和更细致的实体划分。实验表明AgriCHN数据集具备较大挑战性和研究潜力。

Conclusion: AgriCHN数据集的提出极大丰富了中文农业命名实体识别资源，拓展了农业实体类型并提高了数据细粒度，为进一步研究和方法改进提供了基础。

Abstract: Agricultural named entity recognition is a specialized task focusing on
identifying distinct agricultural entities within vast bodies of text,
including crops, diseases, pests, and fertilizers. It plays a crucial role in
enhancing information extraction from extensive agricultural text resources.
However, the scarcity of high-quality agricultural datasets, particularly in
Chinese, has resulted in suboptimal performance when employing mainstream
methods for this purpose. Most earlier works only focus on annotating
agricultural entities while overlook the profound correlation of agriculture
with hydrology and meteorology. To fill this blank, we present AgriCHN, a
comprehensive open-source Chinese resource designed to promote the accuracy of
automated agricultural entity annotation. The AgriCHN dataset has been
meticulously curated from a wealth of agricultural articles, comprising a total
of 4,040 sentences and encapsulating 15,799 agricultural entity mentions
spanning 27 diverse entity categories. Furthermore, it encompasses entities
from hydrology to meteorology, thereby enriching the diversity of entities
considered. Data validation reveals that, compared with relevant resources,
AgriCHN demonstrates outstanding data quality, attributable to its richer
agricultural entity types and more fine-grained entity divisions. A benchmark
task has also been constructed using several state-of-the-art neural NER
models. Extensive experimental results highlight the significant challenge
posed by AgriCHN and its potential for further research.

</details>


### [163] [Mind the Gap: Assessing Wiktionary's Crowd-Sourced Linguistic Knowledge on Morphological Gaps in Two Related Languages](https://arxiv.org/abs/2506.17603)
*Jonathan Sakunkoo,Annabella Sakunkoo*

Main category: cs.CL

TL;DR: 本文提出并验证了一种新型神经形态分析器，用以核查拉丁语和意大利语缺损动词的众包数据。结果发现，Wiktionary对意大利语缺损词的标注极为可靠，但拉丁语中有7%的词条存在误判，提醒我们众包数据在低资源语言和稀有语言学现象上的局限。该研究不仅提供了大规模自动化校验众包语言数据的新方法，还提升了形态学缺损现象在多语言背景下的研究深度。


<details>
  <summary>Details</summary>
Motivation: 形态学缺损现象即某些词汇应有的屈折形式缺失，是语言学中一个有趣但研究不足的问题。现有NLP工具在处理这种现象时准确率较低，且主流的语言学资源对缺损的覆盖有限，人工记录和验证难度大。维基百科和Wiktionary虽然可获取，但其数据的可靠性一直存在争议。

Method: 本研究定制了一种新型神经形态分析器，用于标注拉丁语和意大利语语料库，并利用Wiktionary众包的缺损动词列表进行计算机验证分析。

Result: 结果显示，Wiktionary对意大利语形态学缺损现象的记录非常可靠，但在拉丁语中约有7%的所谓缺损词实际上在语料中并不缺损，表明Wiktionary等众包资源在少数语言或现象的权威性有限。

Conclusion: 该研究为众包数据的质量保障提供了可扩展工具，推动了计算形态学发展，并拓展了对非英语、形态丰富语言缺损现象的认识。

Abstract: Morphological defectivity is an intriguing and understudied phenomenon in
linguistics. Addressing defectivity, where expected inflectional forms are
absent, is essential for improving the accuracy of NLP tools in morphologically
rich languages. However, traditional linguistic resources often lack coverage
of morphological gaps as such knowledge requires significant human expertise
and effort to document and verify. For scarce linguistic phenomena in
under-explored languages, Wikipedia and Wiktionary often serve as among the few
accessible resources. Despite their extensive reach, their reliability has been
a subject of controversy. This study customizes a novel neural morphological
analyzer to annotate Latin and Italian corpora. Using the massive annotated
data, crowd-sourced lists of defective verbs compiled from Wiktionary are
validated computationally. Our results indicate that while Wiktionary provides
a highly reliable account of Italian morphological gaps, 7% of Latin lemmata
listed as defective show strong corpus evidence of being non-defective. This
discrepancy highlights potential limitations of crowd-sourced wikis as
definitive sources of linguistic knowledge, particularly for less-studied
phenomena and languages, despite their value as resources for rare linguistic
features. By providing scalable tools and methods for quality assurance of
crowd-sourced data, this work advances computational morphology and expands
linguistic knowledge of defectivity in non-English, morphologically rich
languages.

</details>


### [164] [Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives](https://arxiv.org/abs/2506.18116)
*Batool Haider,Atmika Gorti,Aman Chadha,Manas Gaur*

Main category: cs.CL

TL;DR: 本研究发现，现有大型语言模型在心理健康领域存在复杂的系统性偏见，提出的多跳问答框架可以更有效地检测并量化这些偏见，通过创新去偏方法可显著减小偏见影响，为构建公平的AI医疗系统提供了方法和参考。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在心理健康领域中的应用可能会传播偏见，强化对边缘群体的负面刻板印象和伤害。虽然早期研究发现了这种问题的趋势，但目前系统性检测交叉偏见（如种族、性别、年龄、社会经济地位等交叉影响）的有效方法仍很有限。

Method: 提出了一种多跳问答（MHQA）框架，系统性地分析LLM在心理健康话语中的回应是否存在偏见。具体方法是利用Interpretable Mental Health Instruction（IMHI）数据集中的内容，涵盖症状表现、应对机制和治疗方式，并结合年龄、种族、性别、社会经济地位等系统标签，在人口群体交叉点探查偏见格局。同时对Claude 3.5 Sonnet、Jamba 1.6、Gemma 3和Llama 4四种LLM进行评估，并比较多跳问答与常规检测方法的有效性。此外，实验采用角色扮演模拟和显式偏见消减两种去偏技巧，通过BBQ数据集的few-shot提示进行优化。

Result: 四种主流LLM在情感倾向、人口统计特征和心理健康状态方面都存在系统性偏见。多跳问答方法比传统检测手段更好地发现偏见的放大节点（即推理链条中偏见被放大的环节）。实施的两种去偏方法在偏见检测实验中达到了66-94%的偏见消减效果。

Conclusion: 当前主流LLM在心理健康场景下存在危险的系统性和交叉偏见。多跳问答技术能有效挖掘这些问题，并通过角色扮演和显式偏见消减指令能大幅降低相关偏见，对未来更公平的AI医疗系统设计提供了实证依据。

Abstract: Large Language Models (LLMs) in mental healthcare risk propagating biases
that reinforce stigma and harm marginalized groups. While previous research
identified concerning trends, systematic methods for detecting intersectional
biases remain limited. This work introduces a multi-hop question answering
(MHQA) framework to explore LLM response biases in mental health discourse. We
analyze content from the Interpretable Mental Health Instruction (IMHI) dataset
across symptom presentation, coping mechanisms, and treatment approaches. Using
systematic tagging across age, race, gender, and socioeconomic status, we
investigate bias patterns at demographic intersections. We evaluate four LLMs:
Claude 3.5 Sonnet, Jamba 1.6, Gemma 3, and Llama 4, revealing systematic
disparities across sentiment, demographics, and mental health conditions. Our
MHQA approach demonstrates superior detection compared to conventional methods,
identifying amplification points where biases magnify through sequential
reasoning. We implement two debiasing techniques: Roleplay Simulation and
Explicit Bias Reduction, achieving 66-94% bias reductions through few-shot
prompting with BBQ dataset examples. These findings highlight critical areas
where LLMs reproduce mental healthcare biases, providing actionable insights
for equitable AI development.

</details>


### [165] [TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting](https://arxiv.org/abs/2506.17609)
*Lincan Li,Eren Erman Ozguven,Yue Zhao,Guang Wang,Yiqun Xie,Yushun Dong*

Main category: cs.CL

TL;DR: TyphoFormer利用大语言模型生成的自然语言提示，显著提升了台风路径预测的准确性，优于目前主流方法。


<details>
  <summary>Details</summary>
Motivation: 台风路径预测对于早期预警和灾害响应至关重要。以往基于Transformer的模型表现良好，但在处理稀疏气象轨迹如台风路径时，缺乏更广泛的上下文知识，难以提升预测可靠性。

Method: 提出TyphoFormer框架，在每个时间步利用大语言模型（LLM）基于北大西洋飓风数据库的数值属性生成凝练的自然语言描述，将其作为辅助提示，通过特殊token加到时序数值输入前。这样联合文本和序列信息输入到Transformer编码器。

Result: 在HURDAT2基准上进行大量实验，TyphoFormer在具有非线性路径变化和历史观测稀少的严峻场景下，预测表现优于其他最新基线方法。

Conclusion: TyphoFormer有效融合了自然语言与数值时序信息，为气象轨迹（如台风路径）预测提供了更强的上下文感知能力，显著提升了预测精度，尤其在困难场景下具有优势。

Abstract: Accurate typhoon track forecasting is crucial for early system warning and
disaster response. While Transformer-based models have demonstrated strong
performance in modeling the temporal dynamics of dense trajectories of humans
and vehicles in smart cities, they usually lack access to broader contextual
knowledge that enhances the forecasting reliability of sparse meteorological
trajectories, such as typhoon tracks. To address this challenge, we propose
TyphoFormer, a novel framework that incorporates natural language descriptions
as auxiliary prompts to improve typhoon trajectory forecasting. For each time
step, we use Large Language Model (LLM) to generate concise textual
descriptions based on the numerical attributes recorded in the North Atlantic
hurricane database. The language descriptions capture high-level meteorological
semantics and are embedded as auxiliary special tokens prepended to the
numerical time series input. By integrating both textual and sequential
information within a unified Transformer encoder, TyphoFormer enables the model
to leverage contextual cues that are otherwise inaccessible through numerical
features alone. Extensive experiments are conducted on HURDAT2 benchmark,
results show that TyphoFormer consistently outperforms other state-of-the-art
baseline methods, particularly under challenging scenarios involving nonlinear
path shifts and limited historical observations.

</details>


### [166] [Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review](https://arxiv.org/abs/2506.18199)
*Bushra Asseri,Estabrag Abdelaziz,Areej Al-Wabil*

Main category: cs.CL

TL;DR: 本综述系统评估了用于阿拉伯和穆斯林文化偏见缓解的prompt工程方法，发现结构化多步流程最有效，但需要更深入的、文化特异性研究和资源支持。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多个领域展现出卓越能力，但存在对阿拉伯人和穆斯林文化偏见，这引发了伦理担忧，容易加剧刻板印象和边缘化问题。尽管LLMs偏见问题备受关注，但针对阿拉伯和穆斯林群体的prompt工程方法尚少有系统性研究。

Method: 采用混合方法的系统综述，遵循PRISMA指南和Kitchenham的系统综述方法，分析了2021-2024年间8项实证研究，评估用于减轻偏见的prompt工程策略。

Result: 研究发现五种主要的prompt工程方法：文化引导、情感启动、自去偏、结构化多步流程和参数优化连续prompt。各种方法均有减少偏见的潜力，但对不同偏见类型效果差异较大。结构化多步流程效果最佳，偏见减少高达87.7%，但技术门槛较高。文化引导方法具有良好可及性和显著效果。

Conclusion: prompt工程可在无需调参的情况下有效缓解文化偏见，但对某些偏见类型的效果有限，特别是阿拉伯和穆斯林相关领域严重缺乏研究，需发展更具文化适应性的prompt和相关资源，将prompt工程与其他去偏方法结合以提升实际应用价值。

Abstract: Large language models have demonstrated remarkable capabilities across
various domains, yet concerns about cultural bias - particularly towards Arabs
and Muslims - pose significant ethical challenges by perpetuating harmful
stereotypes and marginalization. Despite growing recognition of bias in LLMs,
prompt engineering strategies specifically addressing Arab and Muslim
representation remain understudied. This mixed-methods systematic review
examines such techniques, offering evidence-based guidance for researchers and
practitioners. Following PRISMA guidelines and Kitchenham's systematic review
methodology, we analyzed 8 empirical studies published between 2021-2024
investigating bias mitigation strategies. Our findings reveal five primary
prompt engineering approaches: cultural prompting, affective priming,
self-debiasing techniques, structured multi-step pipelines, and
parameter-optimized continuous prompts. Although all approaches show potential
for reducing bias, effectiveness varied substantially across studies and bias
types. Evidence suggests that certain bias types may be more resistant to
prompt-based mitigation than others. Structured multi-step pipelines
demonstrated the highest overall effectiveness, achieving up to 87.7% reduction
in bias, though they require greater technical expertise. Cultural prompting
offers broader accessibility with substantial effectiveness. These results
underscore the accessibility of prompt engineering for mitigating cultural bias
without requiring access to model parameters. The limited number of studies
identified highlights a significant research gap in this critical area. Future
research should focus on developing culturally adaptive prompting techniques,
creating Arab and Muslim-specific evaluation resources, and integrating prompt
engineering with complementary debiasing methods to address deeper stereotypes
while maintaining model utility.

</details>


### [167] [OpusLM: A Family of Open Unified Speech Language Models](https://arxiv.org/abs/2506.17611)
*Jinchuan Tian,William Chen,Yifan Peng,Jiatong Shi,Siddhant Arora,Shikhar Bharadwaj,Takashi Maekaku,Yusuke Shinohara,Keita Goto,Xiang Yue,Huck Yang,Shinji Watanabe*

Main category: cs.CL

TL;DR: 提出并开源了大规模、高性能的语音语言模型OpusLMs，模型及数据全部公开，性能与业界领先模型持平甚至更优，极大促进了开放SpeechLM研究。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏高质量、完全开源且大规模的语音语言模型（SpeechLM），而现存SpeechLMs主要集中在闭源或数据受限制的模型。该论文旨在推动开放领域的语音语言模型研究，提供一个完整可复现、透明且扩展性强的模型系列。

Method: 作者提出了OpusLMs：基于解码器的文本语言模型做初始化，随后在大规模语音-文本对（213,000小时）和文本数据（2920亿tokens）上持续预训练。技术上，文章优化了分词方案、采用多流模型结构及分阶段训练策略，并研究了模型尺度扩展及数据选择退火的影响。

Result: OpusLMs在语音识别、语音合成及文本相关任务上取得了与当前优秀SpeechLMs相媲美甚至更优的性能。此外，所有模型均基于公开数据与代码，极大增强了可复现性和开放性。

Conclusion: OpusLMs系列实现了开放、透明的大规模语音语言建模，不仅性能优越且全面公开，有望推动SpeechLMs社区的开放研究和应用。

Abstract: This paper presents Open Unified Speech Language Models (OpusLMs), a family
of open foundational speech language models (SpeechLMs) up to 7B. Initialized
from decoder-only text language models, the OpusLMs are continuously
pre-trained on 213K hours of speech-text pairs and 292B text-only tokens. We
demonstrate our OpusLMs achieve comparable (or even superior) performance with
existing SpeechLMs in speech recognition, speech synthesis, and text-only
capabilities. Technically, this paper articulates our SpeechLM designs on
tokenization, multi-stream language models, and multi-stage training
strategies. We experimentally demonstrate the importance of model size scaling
and the effect of annealing data selection. The OpusLMs are all built from
publicly available materials and are fully transparent models. We release our
code, data, checkpoints, and training logs to facilitate open SpeechLM research

</details>


### [168] [A Modular Taxonomy for Hate Speech Definitions and Its Impact on Zero-Shot LLM Classification Performance](https://arxiv.org/abs/2506.18576)
*Matteo Melis,Gabriella Lapesa,Dennis Assenmacher*

Main category: cs.CL

TL;DR: 本文分析了仇恨言论定义的多样性，构建了14元素的定义体系，并证明了不同定义会影响大模型检测仇恨言论的效果，但不同模型表现不同，为相关研究和应用提供了参考。


<details>
  <summary>Details</summary>
Motivation: 在NLP领域，检测有害内容（如仇恨言论）是保障社交环境安全的一项重要挑战，但仇恨言论的定义存在模糊，影响模型检测效果。作者希望弄清这一定义歧义带来的影响。

Method: 1. 收集并分析文献中已有的仇恨言论定义，将其整理为包含14个概念元素的分类体系。2. 分别基于不同的定义，对三种大型语言模型（LLM）在三类不同类型的仇恨言论数据集上进行零样本实验评估。

Result: 不同的仇恨言论定义（具体体现在所包含的元素细节数量）会影响模型性能，但这种影响在不同模型架构中表现不一致。

Conclusion: 仇恨言论定义的差异确实对NLP模型的检测能力有影响，因此研究和应用需关注定义选择，并结合具体需求和模型架构进行优化。

Abstract: Detecting harmful content is a crucial task in the landscape of NLP
applications for Social Good, with hate speech being one of its most dangerous
forms. But what do we mean by hate speech, how can we define it, and how does
prompting different definitions of hate speech affect model performance? The
contribution of this work is twofold. At the theoretical level, we address the
ambiguity surrounding hate speech by collecting and analyzing existing
definitions from the literature. We organize these definitions into a taxonomy
of 14 Conceptual Elements-building blocks that capture different aspects of
hate speech definitions, such as references to the target of hate (individual
or groups) or of the potential consequences of it. At the experimental level,
we employ the collection of definitions in a systematic zero-shot evaluation of
three LLMs, on three hate speech datasets representing different types of data
(synthetic, human-in-the-loop, and real-world). We find that choosing different
definitions, i.e., definitions with a different degree of specificity in terms
of encoded elements, impacts model performance, but this effect is not
consistent across all architectures.

</details>


### [169] [Answer-Centric or Reasoning-Driven? Uncovering the Latent Memory Anchor in LLMs](https://arxiv.org/abs/2506.17630)
*Yang Wu,Yifan Zhang,Yiwei Wang,Yujun Cai,Yurong Wu,Yuran Wang,Ning Xu,Jian Cheng*

Main category: cs.CL

TL;DR: 本文通过实验揭示，LLMs的推理很大程度上依赖于显式答案提示，而非真正的逻辑推理，呼吁对其推理能力进行更深入讨论。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）展现出强大的推理能力，但越来越多的证据表明，这种能力更多来源于对答案-推理模式的记忆，而非真实推理。本文旨在探讨LLMs是否真正进行推理，或仅仅依赖已有的答案及其模式。

Method: 提出了一个五级答案可见性提示框架，系统性地操纵答案线索，并通过间接的行为分析来探查模型行为。通过对多种前沿LLM进行实验，考察其对显式答案的依赖性。

Result: 实验显示，当答案线索被隐藏时，即使有完整的推理链，模型性能下降26.90%。这展示了LLMs对显式答案的高度依赖。

Conclusion: LLMs所表现出的许多推理能力更多是事后合理化而非真正的推理推导，说明其推理深度值得质疑。需要对LLMs推理能力的内涵有更细致的认识。

Abstract: While Large Language Models (LLMs) demonstrate impressive reasoning
capabilities, growing evidence suggests much of their success stems from
memorized answer-reasoning patterns rather than genuine inference. In this
work, we investigate a central question: are LLMs primarily anchored to final
answers or to the textual pattern of reasoning chains? We propose a five-level
answer-visibility prompt framework that systematically manipulates answer cues
and probes model behavior through indirect, behavioral analysis. Experiments
across state-of-the-art LLMs reveal a strong and consistent reliance on
explicit answers. The performance drops by 26.90\% when answer cues are masked,
even with complete reasoning chains. These findings suggest that much of the
reasoning exhibited by LLMs may reflect post-hoc rationalization rather than
true inference, calling into question their inferential depth. Our study
uncovers the answer-anchoring phenomenon with rigorous empirical validation and
underscores the need for a more nuanced understanding of what constitutes
reasoning in LLMs.

</details>


### [170] [Step-Opt: Boosting Optimization Modeling in LLMs through Iterative Data Synthesis and Structured Validation](https://arxiv.org/abs/2506.17637)
*Yang Wu,Yifan Zhang,Yurong Wu,Yuran Wang,Junkai Zhang,Jian Cheng*

Main category: cs.CL

TL;DR: 本文提出Step-Opt-Instruct，通过逐步复杂化和验证机制生成高质量微调数据，显著提升了大模型在运筹优化建模任务中的表现，尤其对复杂问题准确率提升显著。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）虽然在多个领域取得了显著进展，但在处理运筹学中的优化建模任务上仍然面临挑战，尤其是在面对复杂问题时。这限制了LLMs自动化决策过程的能力，因此需要新方法来提升其在优化建模中的应用效果。

Method: 提出了Step-Opt-Instruct框架，用于扩充和生成高质量、适用于优化建模的微调数据。该框架采用迭代式问题生成，以逐步增加问题复杂度，并引入逐步验证机制以保证数据质量和防止错误传播。基于此框架对开源大模型（如LLaMA-3-8B和Mistral-7B）进行微调，开发出Step-Opt模型。

Result: Step-Opt模型在多个基准任务（NL4OPT、MAMO、IndustryOR）上取得了最先进的性能，特别是在复杂运筹学任务中表现突出，在难题上的微平均准确率提升了17.01%。

Conclusion: 结合结构化验证和逐步复杂化问题的数据生成流程，能够显著提升大语言模型自动化决策的能力，有效推动运筹优化任务的解决效率。

Abstract: Large Language Models (LLMs) have revolutionized various domains but
encounter substantial challenges in tackling optimization modeling tasks for
Operations Research (OR), particularly when dealing with complex problem. In
this work, we propose Step-Opt-Instruct, a framework that augments existing
datasets and generates high-quality fine-tuning data tailored to optimization
modeling. Step-Opt-Instruct employs iterative problem generation to
systematically increase problem complexity and stepwise validation to
rigorously verify data, preventing error propagation and ensuring the quality
of the generated dataset. Leveraging this framework, we fine-tune open-source
LLMs, including LLaMA-3-8B and Mistral-7B, to develop Step-Opt--a model that
achieves state-of-the-art performance on benchmarks such as NL4OPT, MAMO, and
IndustryOR. Extensive experiments demonstrate the superior performance of
Step-Opt, especially in addressing complex OR tasks, with a notable 17.01\%
improvement in micro average accuracy on difficult problems. These findings
highlight the effectiveness of combining structured validation with gradual
problem refinement to advance the automation of decision-making processes using
LLMs.The code and dataset are available at https://github.com/samwu-learn/Step.

</details>


### [171] [TPTT: Transforming Pretrained Transformer into Titans](https://arxiv.org/abs/2506.17671)
*Fabien Furfaro*

Main category: cs.CL

TL;DR: 本文提出TPTT框架，结合高效注意力机制与内存管理，无需全量重训即可显著提升预训练Transformer模型在长上下文任务的效率与准确性，实验结果表明其性能超过现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）虽然在自然语言处理领域取得了巨大进展，但其在计算和内存消耗上仍面临挑战，尤其是处理长上下文推理任务时。本文希望解决如何提升预训练Transformer模型的效率和可扩展性问题。

Method: 提出了TPTT（Transforming Pretrained Transformer into Titans）框架，通过引入高效的线性化注意力机制和先进的内存管理方法，如Memory as Gate（MaG）和混合线性化注意力（LiZA），并兼容Hugging Face Transformers生态，在不需全部重训练的前提下，以参数高效微调（如LoRA）提升模型能力。

Result: 在MMLU基准测试中，约10亿参数量级的模型使用TPTT后，在效率和准确率上均有显著提升，例如Titans-Llama-3.2-1B模型的Exact Match（EM）指标比基线提升了20%。

Conclusion: TPTT能够显著提升现有LLM在长上下文任务中的效率与准确性，具备良好的扩展性和兼容性，并经过实验证明其优于最新的同类方法。

Abstract: Recent advances in large language models (LLMs) have led to remarkable
progress in natural language processing, but their computational and memory
demands remain a significant challenge, particularly for long-context
inference. We introduce TPTT (Transforming Pretrained Transformer into Titans),
a novel framework for enhancing pretrained Transformer models with efficient
linearized attention mechanisms and advanced memory management. TPTT employs
techniques such as Memory as Gate (MaG) and mixed linearized attention (LiZA).
It is fully compatible with the Hugging Face Transformers library, enabling
seamless adaptation of any causal LLM through parameter-efficient fine-tuning
(LoRA) without full retraining. We show the effectiveness of TPTT on the MMLU
benchmark with models of approximately 1 billion parameters, observing
substantial improvements in both efficiency and accuracy. For instance,
Titans-Llama-3.2-1B achieves a 20% increase in Exact Match (EM) over its
baseline. Statistical analyses and comparisons with recent state-of-the-art
methods confirm the practical scalability and robustness of TPTT. Code is
available at https://github.com/fabienfrfr/tptt . Python package at
https://pypi.org/project/tptt/ .

</details>


### [172] [Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering](https://arxiv.org/abs/2506.17692)
*Binquan Ji,Haibo Luo,Yifei Lu,Lei Hei,Jiaqi Wang,Tingjing Liao,Lingyu Wang,Shichao Wang,Feiliang Ren*

Main category: cs.CL

TL;DR: 本文提出DEC动态增强链框架，通过拆解与重写子问题及高效关键词检索，显著提升轻量级LLM在多跳问答任务中的表现，并兼顾精度与计算效率，取得了新的最优实验结果。


<details>
  <summary>Details</summary>
Motivation: 知识密集型的多跳问答（QA）任务需要整合多个来源的信息以回答复杂问题，而轻量级大语言模型（参数较少的LLMs）在处理大量文档和长上下文时容易出现虚假内容和语义漂移等问题。

Method: 提出了一种动态增强链（DEC）框架：首先将复杂问题分解为逻辑连贯的子问题，避免推理过程中的幻觉；随后通过上下文感知的重写不断优化子问题表述；在检索过程中，基于一个轻量级判别性关键词提取模块，利用关键词高效回忆相关文档，保证精确的检索且计算消耗较低。

Result: 在三个多跳QA数据集上进行实验，DEC框架能达到或超过同类最优水平，同时大幅减少了token消耗。尤其在8B参数模型上达到了新的最优结果，验证了该方法在多种环境下的有效性，尤其适合算力资源受限的场景。

Conclusion: DEC为多跳问答任务中的轻量级LLMs提供了一种高效且能有效控制幻觉问题的解决框架，不但提升了模型性能，同时降低了计算负担。该方法具有良好的通用性和实际应用价值。

Abstract: Knowledge-intensive multi-hop question answering (QA) tasks, which require
integrating evidence from multiple sources to address complex queries, often
necessitate multiple rounds of retrieval and iterative generation by large
language models (LLMs). However, incorporating many documents and extended
contexts poses challenges -such as hallucinations and semantic drift-for
lightweight LLMs with fewer parameters. This work proposes a novel framework
called DEC (Dynamic Enhancement Chain). DEC first decomposes complex questions
into logically coherent subquestions to form a hallucination-free reasoning
chain. It then iteratively refines these subquestions through context-aware
rewriting to generate effective query formulations. For retrieval, we introduce
a lightweight discriminative keyword extraction module that leverages extracted
keywords to achieve targeted, precise document recall with relatively low
computational overhead. Extensive experiments on three multi-hop QA datasets
demonstrate that DEC performs on par with or surpasses state-of-the-art
benchmarks while significantly reducing token consumption. Notably, our
approach attains state-of-the-art results on models with 8B parameters,
showcasing its effectiveness in various scenarios, particularly in
resource-constrained environments.

</details>


### [173] [Zero-Shot Conversational Stance Detection: Dataset and Approaches](https://arxiv.org/abs/2506.17693)
*Yuzhe Ding,Kang He,Bobo Li,Li Zheng,Haijun He,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: 本文提出了大规模零样本对话立场检测数据集（ZS-CSD）和SITPCL模型，推动了该领域发展，但实验结果显示零样本对话立场检测依旧极具挑战。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中针对特定议题的立场检测是一个重要但具有挑战性的任务。随着社交媒体用户在线辩论的增多，基于对话的立场检测逐渐成为研究重点。但现有数据集目标有限，难以适应真实世界中大量未见过的新目标。

Method: 作者人工整理了大规模高质量的零样本对话立场检测数据集（ZS-CSD），涵盖280个目标，并提出了SITPCL模型（结合说话者交互和目标感知的原型对比学习方法），在零样本场景下进行基准测试。

Result: SITPCL模型在零样本对话立场检测任务中取得了当前最优结果，但其F1-macro分数仅为43.81%，说明在该领域仍存在显著挑战。

Conclusion: 提出的ZS-CSD数据集和SITPCL模型提升了零样本对话立场检测的研究水平，但实际性能仍显示该任务的高难度。

Abstract: Stance detection, which aims to identify public opinion towards specific
targets using social media data, is an important yet challenging task. With the
increasing number of online debates among social media users, conversational
stance detection has become a crucial research area. However, existing
conversational stance detection datasets are restricted to a limited set of
specific targets, which constrains the effectiveness of stance detection models
when encountering a large number of unseen targets in real-world applications.
To bridge this gap, we manually curate a large-scale, high-quality zero-shot
conversational stance detection dataset, named ZS-CSD, comprising 280 targets
across two distinct target types. Leveraging the ZS-CSD dataset, we propose
SITPCL, a speaker interaction and target-aware prototypical contrastive
learning model, and establish the benchmark performance in the zero-shot
setting. Experimental results demonstrate that our proposed SITPCL model
achieves state-of-the-art performance in zero-shot conversational stance
detection. Notably, the SITPCL model attains only an F1-macro score of 43.81%,
highlighting the persistent challenges in zero-shot conversational stance
detection.

</details>


### [174] [The Evolution of Natural Language Processing: How Prompt Optimization and Language Models are Shaping the Future](https://arxiv.org/abs/2506.17700)
*Summra Saleem,Muhammad Nabeel Asim,Shaista Zulfiqar,Andreas Dengel*

Main category: cs.CL

TL;DR: 本文系统梳理并分类总结了多种Prompt优化策略及其在NLP任务中的应用，有助于后续相关工作的对比和新方法的发展。


<details>
  <summary>Details</summary>
Motivation: 虽然已有许多综述探讨了Prompt工程，但关于Prompt优化策略的系统性分析仍存在空白，因此需要对这些策略进行深入梳理和分类。

Method: 综合梳理当前多样的Prompt优化方法，对其工作原理进行分析，并依据原理将其归为11个类别。同时，总结这些策略在各类NLP任务、不同LLM模型和常用数据集上的应用情况。

Result: 建立了Prompt优化策略的分类体系，详细罗列了它们在NLP领域中的应用和评测情况，为今后相关方法的比较与发展提供了系统性资料。

Conclusion: 本研究填补了Prompt优化策略系统分析的空白，为未来LLM相关研究和新任务的算法创新提供了理论和方法基础。

Abstract: Large Language Models (LLMs) have revolutionized the field of Natural
Language Processing (NLP) by automating traditional labor-intensive tasks and
consequently accelerated the development of computer-aided applications. As
researchers continue to advance this field with the introduction of novel
language models and more efficient training/finetuning methodologies, the idea
of prompt engineering and subsequent optimization strategies with LLMs has
emerged as a particularly impactful trend to yield a substantial performance
boost across diverse NLP tasks. To best of our knowledge numerous review
articles have explored prompt engineering, however, a critical gap exists in
comprehensive analyses of prompt optimization strategies. To bridge this gap
this paper provides unique and comprehensive insights about the potential of
diverse prompt optimization strategies. It analyzes their underlying working
paradigms and based on these principles, categorizes them into 11 distinct
classes. Moreover, the paper provides details about various NLP tasks where
these prompt optimization strategies have been employed, along with details of
different LLMs and benchmark datasets used for evaluation. This comprehensive
compilation lays a robust foundation for future comparative studies and enables
rigorous assessment of prompt optimization and LLM-based predictive pipelines
under consistent experimental settings: a critical need in the current
landscape. Ultimately, this research will centralize diverse strategic
knowledge to facilitate the adaptation of existing prompt optimization
strategies for development of innovative predictors across unexplored tasks.

</details>


### [175] [Aged to Perfection: Machine-Learning Maps of Age in Conversational English](https://arxiv.org/abs/2506.17708)
*MingZe Tang*

Main category: cs.CL

TL;DR: 本研究利用英国国家语料库和机器学习，揭示不同年龄群体在口语上的显著差异，并实现了年龄群体的有效预测。


<details>
  <summary>Details</summary>
Motivation: 语言随年龄变化，了解不同年龄群体之间的口语差异，有助于丰富社会语言学对现代英语变异和多样性的认知。

Method: 结合计算语言分析和机器学习方法，利用2014年英国国家语料库对不同年龄段说话者的语料进行分析，提取话语时长、词汇多样性和用词选择等特征，并建立年龄群预测模型。

Result: 发现多代群体间存在显著的语言标志，预测模型能够基于语音特征较为准确地估计说话者的年龄段。

Conclusion: 研究揭示了英国当代口语在不同年龄群体间的语言模式存在显著差异，且可以通过语言特征有效预测说话者的年龄群体。

Abstract: The study uses the British National Corpus 2014, a large sample of
contemporary spoken British English, to investigate language patterns across
different age groups. Our research attempts to explore how language patterns
vary between different age groups, exploring the connection between speaker
demographics and linguistic factors such as utterance duration, lexical
diversity, and word choice. By merging computational language analysis and
machine learning methodologies, we attempt to uncover distinctive linguistic
markers characteristic of multiple generations and create prediction models
that can consistently estimate the speaker's age group from various aspects.
This work contributes to our knowledge of sociolinguistic diversity throughout
the life of modern British speech.

</details>


### [176] [Unveiling Factors for Enhanced POS Tagging: A Study of Low-Resource Medieval Romance Languages](https://arxiv.org/abs/2506.17715)
*Matthias Schöffel,Esteban Garces Arias,Marinus Wiedner,Paula Ruppert,Meimingwei Li,Christian Heumann,Matthias Aßenmacher*

Main category: cs.CL

TL;DR: 本研究围绕中古罗曼语POS标注的难题，系统评估了多种技术对大语言模型性能的影响。结果显示：LLMs对于历史文本中的语言变异和拼写不规范适应性有限，但部分方法（如跨语言迁移等）能显著提升标注准确率。


<details>
  <summary>Details</summary>
Motivation: 词性标注（POS tagging）是自然语言处理中的基础任务，对于涉及历史文本分析的领域尤为重要。然而，将现代大语言模型（LLM）应用于中古罗曼语（如中古奥克西唐语、西班牙语、法语）时，会遇到语言演变、拼写变异以及有标注数据稀缺等独特挑战。论文动机在于揭示影响历史少资源语言中POS标注性能的关键因素。

Method: 作者通过系统性实验证明，考察不同微调方法、提示工程、模型架构、解码策略和跨语言迁移学习技术如何影响POS标注准确性。实验涵盖中古奥克西唐语、西班牙语和法语的不同领域文本（如圣经、传记、医学、饮食文献）。

Result: 实验结果揭示了大语言模型在处理历史语言变异和非标准拼写方面的显著局限，也发现了一些能有效应对低资源历史语言挑战的专门技术。

Conclusion: 尽管大语言模型在应对中古罗曼语等历史低资源语言的POS标注任务中存在不足，但针对性策略与技术可带来显著提升，为后续数字人文与历史语言处理研究提供了重要借鉴。

Abstract: Part-of-speech (POS) tagging remains a foundational component in natural
language processing pipelines, particularly critical for historical text
analysis at the intersection of computational linguistics and digital
humanities. Despite significant advancements in modern large language models
(LLMs) for ancient languages, their application to Medieval Romance languages
presents distinctive challenges stemming from diachronic linguistic evolution,
spelling variations, and labeled data scarcity. This study systematically
investigates the central determinants of POS tagging performance across diverse
corpora of Medieval Occitan, Medieval Spanish, and Medieval French texts,
spanning biblical, hagiographical, medical, and dietary domains. Through
rigorous experimentation, we evaluate how fine-tuning approaches, prompt
engineering, model architectures, decoding strategies, and cross-lingual
transfer learning techniques affect tagging accuracy. Our results reveal both
notable limitations in LLMs' ability to process historical language variations
and non-standardized spelling, as well as promising specialized techniques that
effectively address the unique challenges presented by low-resource historical
languages.

</details>


### [177] [KAG-Thinker: Teaching Large Language Models to Think with Human-like Reasoning Process](https://arxiv.org/abs/2506.17728)
*Dalong Zhang,Jun Xu,Jun Zhou,Lei Liang,Lin Yuan,Ling Zhong,Mengshu Sun,Peilong Zhao,QiWei Wang,Xiaorui Wang,Xinkai Du,YangYang Hou,Yu Ao,ZhaoYang Wang,Zhengke Gui,ZhiYing Yi,Zhongpu Bo*

Main category: cs.CL

TL;DR: KAG-Thinker是一种模拟人类认知的推理框架，可提升LLM在专业领域知识问答中的推理逻辑和知识获取能力，通过分解子问题、动态知识选择和有监督训练实现更强推理性能。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型（LLM）在基于领域知识库的问答任务中，缺乏与人类思维过程相仿的逻辑一致性与上下文连续性的推理能力。作者希望提升LLM在人类类推理、复杂问题分解和动态知识源选择等方面的表现。

Method: 提出了KAG-Thinker人类类推理框架，基于参数较少的LLM。采用Logical Form引导的检索与推理技术，首先通过广度分解将复杂问题拆解为可独立求解的子问题，并以自然语言和逻辑函数两种形式进行表达，明确任务依赖和变量传递。对于知识检索与推理分析子任务分别应用不同函数。创新地将LLM和外部知识源作为等价的知识库，通过knowledge boundary模型实现动态知识源选择；深度求解模型提升知识获取全面性。训练时采用多轮对话的有监督微调，配合数据评测与语料迭代。

Result: KAG-Thinker能显著提升LLM在面向领域知识库的问答中，推理链的逻辑性、上下文一致性和知识检索全面性，避免过度反思带来的推理异常，并通过数据框架验证其有效性。

Conclusion: KAG-Thinker通过启发式分解与动态知识边界选择，构建了更贴近人类认知模式的LLM推理方案，为领域知识推理和复杂问答任务提供了有效技术路径。

Abstract: In this paper, we introduce KAG-Thinker, a novel human-like reasoning
framework built upon a parameter-light large language model (LLM). Our approach
enhances the logical coherence and contextual consistency of the thinking
process in question-answering (Q\&A) tasks on domain-specific knowledge bases
(KBs) within LLMs. This framework simulates human cognitive mechanisms for
handling complex problems by establishing a structured thinking process.
Continuing the \textbf{Logical Form} guided retrieval and reasoning technology
route of KAG v0.7, firstly, it decomposes complex questions into independently
solvable sub-problems(also referred to as logical forms) through
\textbf{breadth decomposition}, each represented in two equivalent
forms-natural language and logical function-and further classified as either
Knowledge Retrieval or Reasoning Analysis tasks, with dependencies and
variables passing explicitly modeled via logical function interfaces. In the
solving process, the Retrieval function is used to perform knowledge retrieval
tasks, while the Math and Deduce functions are used to perform reasoning
analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval
sub-problem tasks, LLMs and external knowledge sources are regarded as
equivalent KBs. We use the \textbf{knowledge boundary} model to determine the
optimal source using self-regulatory mechanisms such as confidence calibration
and reflective reasoning, and use the \textbf{depth solving} model to enhance
the comprehensiveness of knowledge acquisition. Finally, instead of utilizing
reinforcement learning, we employ supervised fine-tuning with multi-turn
dialogues to align the model with our structured inference paradigm, thereby
avoiding excessive reflection. This is supported by a data evaluation framework
and iterative corpus synthesis, which facilitate the generation of detailed
reasoning trajectories...

</details>


### [178] [HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations](https://arxiv.org/abs/2506.17748)
*Anwoy Chatterjee,Yash Goel,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练、单遍即可检测大语言模型幻觉的新方法（HIDE），利用模型内部表征解耦性，实验证明其准确性和效率均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LMs）在生成内容时常出现事实错误或与输入上下文不符的问题，即“幻觉”现象。现有检测方法大多依赖多次生成，对每个输入分析多组结果，计算成本和延迟较高。研究动机是提出一种能有效、快速检测幻觉的方法。

Method: 提出了一种基于单遍、无需训练的新方法——HIDE（Hallucination detectIon via Decoupled rEpresentations）。该方法利用Hilbert-Schmidt独立性准则（HSIC）度量生成输出时模型内部输入上下文表示与输出表示的统计“解耦”程度，据此识别幻觉。

Result: 在四个多样化问答数据集和六种开源语言模型上进行了大量实验。结果显示，HIDE在几乎所有设置下都优于其他单遍方法，在各模型及数据集间AUC-ROC平均提升约29%。相较多遍最优方法，HIDE在AUC-ROC平均提升约3%，计算资源消耗减少约51%。

Conclusion: 通过衡量语言模型内部表征的解耦，HIDE方法实现了高效且实用的幻觉检测，在准确性和计算效率之间取得了良好平衡。

Abstract: Contemporary Language Models (LMs), while impressively fluent, often generate
content that is factually incorrect or unfaithful to the input context - a
critical issue commonly referred to as 'hallucination'. This tendency of LMs to
generate hallucinated content undermines their reliability, especially because
these fabrications are often highly convincing and therefore difficult to
detect. While several existing methods attempt to detect hallucinations, most
rely on analyzing multiple generations per input, leading to increased
computational cost and latency. To address this, we propose a single-pass,
training-free approach for effective Hallucination detectIon via Decoupled
rEpresentations (HIDE). Our approach leverages the hypothesis that
hallucinations result from a statistical decoupling between an LM's internal
representations of input context and its generated output. We quantify this
decoupling using the Hilbert-Schmidt Independence Criterion (HSIC) applied to
hidden-state representations extracted while generating the output sequence. We
conduct extensive experiments on four diverse question answering datasets,
evaluating both faithfulness and factuality hallucinations across six
open-source LMs of varying scales and properties. Our results demonstrate that
HIDE outperforms other single-pass methods in almost all settings, achieving an
average relative improvement of ~29% in AUC-ROC over the best-performing
single-pass strategy across various models and datasets. Additionally, HIDE
shows competitive and often superior performance with multi-pass
state-of-the-art methods, obtaining an average relative improvement of ~3% in
AUC-ROC while consuming ~51% less computation time. Our findings highlight the
effectiveness of exploiting internal representation decoupling in LMs for
efficient and practical hallucination detection.

</details>


### [179] [Multilingual Tokenization through the Lens of Indian Languages: Challenges and Insights](https://arxiv.org/abs/2506.17789)
*N J Karthika,Maharaj Brahma,Rohit Saluja,Ganesh Ramakrishnan,Maunendra Sankar Desarkar*

Main category: cs.CL

TL;DR: 本研究系统评估了17种印度语言的分词方法，为多语种NLP分词器设计提供了经验：低资源语言可借助高资源语言分词器，提出了更公平高效的分词方案。


<details>
  <summary>Details</summary>
Motivation: 现有的分词器多针对高资源语言设计，对于印度次大陆等语言多样且形态丰富的语言支持有限。

Method: 对17种印度语言的分词策略进行了全面的内在评估，量化分析了自底向上与自顶向下分词算法（如BPE和Unigram LM）、词汇表规模影响，以及多语种词汇表构建策略（联合与集群训练）的对比。

Result: 发现极低资源语言可以从在相关高资源语言上训练的分词器中获益。

Conclusion: 为多语种NLP构建更公平、高效且语言学更优的分词器提供了实用的见解。

Abstract: Tokenization plays a pivotal role in multilingual NLP. However, existing
tokenizers are often skewed towards high-resource languages, limiting their
effectiveness for linguistically diverse and morphologically rich languages
such as those in the Indian subcontinent. This paper presents a comprehensive
intrinsic evaluation of tokenization strategies across 17 Indian languages. We
quantify the trade-offs between bottom-up and top-down tokenizer algorithms
(BPE and Unigram LM), effects of vocabulary sizes, and compare strategies of
multilingual vocabulary construction such as joint and cluster-based training.
We also show that extremely low-resource languages can benefit from tokenizers
trained on related high-resource languages. Our study provides practical
insights for building more fair, efficient, and linguistically informed
tokenizers for multilingual NLP.

</details>


### [180] [THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction](https://arxiv.org/abs/2506.17844)
*Xin Zhang,Qiyu Wei,Yingjie Zhu,Fanyi Wu,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 本文提出时序-层级因果建模新方法，结合保形置信校准，改进了多模态EHR数据的疾病风险预测效果，在真实数据集上取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）包含结构化诊断代码和非结构化叙述性病历，两者均对临床风险预测至关重要。以往方法常将两种数据分开处理，或通过简单的数据融合，而忽略了实际病情由文本观察引发诊断、导致风险跨次住院传播的因果与层次联动。该文旨在弥补这一缺陷。

Method: 提出THCM-CAL（带保形校准的时序-层级因果模型），利用因果推断生成多模态因果图，将出自病历文本和ICD代码的临床实体建为节点，通过层级因果发现学习三种关键关系：同层同模态序列、同层跨模态触发与跨层风险传播，并将保形预测技术拓展到多标签ICD编码，实现多标签置信区间校准。

Result: 在MIMIC-III和MIMIC-IV数据集上实验显示，THCM-CAL在临床风险预测表现优于现有方法，具备更高预测可靠性和精度。

Conclusion: 针对多模态EHR数据的因果联动与风险传播，THCM-CAL可捕捉病情演变的真实临床机制，并以校准置信提升预测可信度，在复杂场景下具备实际应用潜力。

Abstract: Automated clinical risk prediction from electronic health records (EHRs)
demands modeling both structured diagnostic codes and unstructured narrative
notes. However, most prior approaches either handle these modalities separately
or rely on simplistic fusion strategies that ignore the directional,
hierarchical causal interactions by which narrative observations precipitate
diagnoses and propagate risk across admissions. In this paper, we propose
THCM-CAL, a Temporal-Hierarchical Causal Model with Conformal Calibration. Our
framework constructs a multimodal causal graph where nodes represent clinical
entities from two modalities: Textual propositions extracted from notes and ICD
codes mapped to textual descriptions. Through hierarchical causal discovery,
THCM-CAL infers three clinically grounded interactions: intra-slice
same-modality sequencing, intra-slice cross-modality triggers, and inter-slice
risk propagation. To enhance prediction reliability, we extend conformal
prediction to multi-label ICD coding, calibrating per-code confidence intervals
under complex co-occurrences. Experimental results on MIMIC-III and MIMIC-IV
demonstrate the superiority of THCM-CAL.

</details>


### [181] [LLMs for Customized Marketing Content Generation and Evaluation at Scale](https://arxiv.org/abs/2506.17863)
*Haoran Liu,Amir Tahmasbi,Ehtesham Sam Haque,Purak Jain*

Main category: cs.CL

TL;DR: 本论文提出用于电商站外营销内容生成和自动化评估的新系统，能提升广告效果并降低人工评估成本，但最终部署仍需人工审核。


<details>
  <summary>Details</summary>
Motivation: 现有的电商站外营销内容过于通用、模板化且与落地页匹配度低，导致推广效果受限，需要更智能且高效的内容生成与评估方法。

Method: 提出了MarketingFM系统，利用多数据源和检索增强技术生成针对关键词的广告文案，减少人工干预。同时构建了AutoEval-Main自动化评估系统，结合规则与LLM（大语言模型）评判，并进一步提出AutoEval-Update人机协作框架动态优化评估标准。

Result: MarketingFM生成的针对性广告文案在A/B测试中CTR提升9%，展示量提高12%，CPC降低0.38%。AutoEval-Main系统与人工评审一致率达89.57%。AutoEval-Update能显著提升评估一致性并降低人工成本，但人工把关仍必不可少。

Conclusion: 关键词驱动的广告生成系统与自动化评估体系能提升电商广告投放效果和评估效率，但关键环节仍需人工最终把控。

Abstract: Offsite marketing is essential in e-commerce, enabling businesses to reach
customers through external platforms and drive traffic to retail websites.
However, most current offsite marketing content is overly generic,
template-based, and poorly aligned with landing pages, limiting its
effectiveness. To address these limitations, we propose MarketingFM, a
retrieval-augmented system that integrates multiple data sources to generate
keyword-specific ad copy with minimal human intervention. We validate
MarketingFM via offline human and automated evaluations and large-scale online
A/B tests. In one experiment, keyword-focused ad copy outperformed templates,
achieving up to 9% higher CTR, 12% more impressions, and 0.38% lower CPC,
demonstrating gains in ad ranking and cost efficiency. Despite these gains,
human review of generated ads remains costly. To address this, we propose
AutoEval-Main, an automated evaluation system that combines rule-based metrics
with LLM-as-a-Judge techniques to ensure alignment with marketing principles.
In experiments with large-scale human annotations, AutoEval-Main achieved
89.57% agreement with human reviewers. Building on this, we propose
AutoEval-Update, a cost-efficient LLM-human collaborative framework to
dynamically refine evaluation prompts and adapt to shifting criteria with
minimal human input. By selectively sampling representative ads for human
review and using a critic LLM to generate alignment reports, AutoEval-Update
improves evaluation consistency while reducing manual effort. Experiments show
the critic LLM suggests meaningful refinements, improving LLM-human agreement.
Nonetheless, human oversight remains essential for setting thresholds and
validating refinements before deployment.

</details>


### [182] [QueueEDIT: Structural Self-Correction for Sequential Model Editing in LLMs](https://arxiv.org/abs/2506.17864)
*Taolin Zhang,Haidong Kang,Dongyang Li,Qizhou Chen,Chengyu Wang Xiaofeng He,Richang Hong*

Main category: cs.CL

TL;DR: 本文提出了QueueEDIT框架，通过队列管理与自适应参数对齐，提升大语言模型的多轮编辑能力，并减缓通用能力的下降，在各类实验中效果优于其它方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）尽管表现优异，但仍存在幻觉（事实性错误）问题，模型编辑被用于修正这些错误。然而，现有方法通常只进行一次性编辑，难以应对需要连续多次修正的情景，且频繁编辑可能削弱模型的整体能力。

Method: 提出了一种基于队列的自我纠正框架（QueueEDIT）。该框架首先将知识三元组映射到Transformer层中的知识敏感神经元，并将每次编辑涉及的参数存储在队列中，对相关参数进行动态对齐。每次编辑时，只调整与当前任务相关的参数，冻结无关参数，并将最新参数更新回模型，从而减小对模型通用能力的影响。

Result: 实验结果显示，QueueEDIT在多种连续编辑任务下优于其他主流方法，并且在单次编辑任务中也表现出良好的竞争力。同时，经过多轮编辑后的LLM依然能够保持较高的NLP任务通用能力。

Conclusion: QueueEDIT能够在保障模型编辑有效性的同时，较好地维护大语言模型的整体能力，为解决序贯模型编辑中的能力退化问题提供了一种新思路。

Abstract: Recently, large language models (LLMs) have demonstrated impressive results
but still suffer from hallucinations. Model editing has been proposed to
correct factual inaccuracies in LLMs. A challenging case is sequential model
editing (SME), which aims to rectify errors continuously rather than treating
them as a one-time task. During SME, the general capabilities of LLMs can be
negatively affected due to the introduction of new parameters. In this paper,
we propose a queue-based self-correction framework (QueueEDIT) that not only
enhances SME performance by addressing long-sequence dependency but also
mitigates the impact of parameter bias on the general capabilities of LLMs.
Specifically, we first introduce a structural mapping editing loss to map the
triplets to the knowledge-sensitive neurons within the Transformer layers of
LLMs. We then store the located parameters for each piece of edited knowledge
in a queue and dynamically align previously edited parameters. In each edit, we
select queue parameters most relevant to the currently located parameters to
determine whether previous knowledge needs realignment. Irrelevant parameters
in the queue are frozen, and we update the parameters at the queue head to the
LLM to ensure they do not harm general abilities. Experiments show that our
framework significantly outperforms strong baselines across various SME
settings and maintains competitiveness in single-turn editing. The resulting
LLMs also preserve high capabilities in general NLP tasks throughout the SME
process.

</details>


### [183] [How Alignment Shrinks the Generative Horizon](https://arxiv.org/abs/2506.17871)
*Chenghao Yang,Ari Holtzman*

Main category: cs.CL

TL;DR: 本文揭示齐平大模型缺乏多样性的根因在于生成分布的收敛与BF显著降低，指出齐平训练实际上是通过语气token引导而非本质改变模型行为，BF可作为诊断与调控输出多样性的有效工具。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型虽然表现优异，但在齐平（aligned）后，其生成的输出往往缺乏多样性。该论文希望探明造成输出稳定、缺乏多样性的内在原因及机制。

Method: 作者引入了分支因子（Branching Factor, BF）作为衡量模型在生成过程中“下一个合理token选择”数量的度量指标，并通过实证分析跟踪BF的变化。此外，作者还进行了“nudging”实验，通过设置特定提示词监测基座模型在输出多样性上的变化。

Result: 实验显示：（1）生成过程中BF普遍降低，说明模型越生成越趋于确定性。（2）齐平调优会极大降低初始的BF（例如从12降至1.2），显著收敛输出分布，有助于解释齐平模型对解码策略的不敏感性。此外，链式推理模型正是通过延长推理链条，将生成推向更为确定性的阶段而实现输出稳定。重要发现还包括，对base模型加入特定的“风格性token”也能实现类似的BF降低。

Conclusion: BF成为理解与调节LLM输出稳定性与多样性的强有力诊断工具。齐平主要通过风格引导token推动模型进入低熵（确定性强）的上下文轨迹，而并非实质改变模型本体行为，为LLM齐平训练和推理生成的理解与优化提供了新思路。

Abstract: Despite their impressive capabilities, aligned large language models (LLMs)
often generate outputs that lack diversity. What drives this stability in the
generation? We investigate this phenomenon through the lens of probability
concentration in the model's output distribution. To quantify this
concentration, we introduce the Branching Factor (BF) -- a token-invariant
measure of the effective number of plausible next steps during generation. Our
empirical analysis reveals two key findings: (1) BF often decreases as
generation progresses, suggesting that LLMs become more predictable as they
generate. (2) alignment tuning substantially sharpens the model's output
distribution from the outset, reducing BF by nearly an order of magnitude
(e.g., from 12 to 1.2) relative to base models. This stark reduction helps
explain why aligned models often appear less sensitive to decoding strategies.
Building on this insight, we find this stability has surprising implications
for complex reasoning. Aligned Chain-of-Thought (CoT) models (e.g.,
DeepSeek-distilled models), for instance, leverage this effect; by generating
longer reasoning chains, they push generation into later, more deterministic
(lower BF) stages, resulting in more stable outputs. We hypothesize that
alignment tuning does not fundamentally change a model's behavior, but instead
steers it toward stylistic tokens (e.g., "Sure") that unlock low-entropy
trajectories already present in the base model. This view is supported by
nudging experiments, which show that prompting base models with such tokens can
similarly reduce BF. Together, our findings establish BF as a powerful
diagnostic for understanding and controlling LLM outputs - clarifying how
alignment reduces variability, how CoT promotes stable generations, and how
base models can be steered away from diversity.

</details>


### [184] [Multi-turn Jailbreaking via Global Refinement and Active Fabrication](https://arxiv.org/abs/2506.17881)
*Hua Tang,Lingyong Yan,Yukun Zhao,Shuaiqiang Wang,Jizhou Huang,Dawei Yin*

Main category: cs.CL

TL;DR: 本文提出了一种全局优化和主动伪造响应的新颖多轮越狱方法，能显著提升主流大模型生成有害内容的风险，需引起安全关注。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然在各种任务中表现出色，但因潜在被恶意滥用而存在安全风险，尤其是“越狱”攻击能引发有害内容输出，目前多为单轮对话攻击，多轮场景研究不足。

Method: 提出一种新的多轮越狱方法，该方法在每次交互时全局优化越狱路径，并主动伪造模型回应以抑制安全警告，从而提升后续问题引发有害输出的概率。

Result: 实验证明，该方法在六个主流LLM上优于现有单轮及多轮越狱技术。

Conclusion: 提出的多轮越狱方法有效提升了模型生成有害内容的概率，显示出较强的攻防能力，对LLM安全防护提出新挑战。

Abstract: Large Language Models (LLMs) have achieved exceptional performance across a
wide range of tasks. However, they still pose significant safety risks due to
the potential misuse for malicious purposes. Jailbreaks, which aim to elicit
models to generate harmful content, play a critical role in identifying the
underlying security threats. Recent jailbreaking primarily focuses on
single-turn scenarios, while the more complicated multi-turn scenarios remain
underexplored. Moreover, existing multi-turn jailbreaking techniques struggle
to adapt to the evolving dynamics of dialogue as the interaction progresses. To
address this limitation, we propose a novel multi-turn jailbreaking method that
refines the jailbreaking path globally at each interaction. We also actively
fabricate model responses to suppress safety-related warnings, thereby
increasing the likelihood of eliciting harmful outputs in subsequent questions.
Experimental results demonstrate the superior performance of our method
compared with existing single-turn and multi-turn jailbreaking techniques
across six state-of-the-art LLMs. Our code is publicly available at
https://github.com/Ytang520/Multi-Turn_jailbreaking_Global-Refinment_and_Active-Fabrication.

</details>


### [185] [Scatter-Based Innovation Propagation in Large Language Models for Multi-Stage Process Adaptation](https://arxiv.org/abs/2506.17949)
*Hong Su*

Main category: cs.CL

TL;DR: 提出了一种创新扩散模型，有效提升LLM将创新推广至多阶段流程的能力，经验证能改进泛化和创新复用。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在预训练中能够很好地再现和扩展已有模式，但在将创新从一个特定阶段推广到其他阶段时常常表现不佳。解决LLM创新泛化局限，是提升模型能力的关键难题。

Method: 提出了一种基于分散（scatter-based）的创新扩散模型。该模型指导LLM按照四步流程：1）比较用户输入和上下文，识别核心创新；2）将创新去除特定阶段、组件的限定，实现泛化；3）判断泛化后的创新是否可适用于更广泛范围；4）用LLM系统性地将创新应用到结构上相似的其他阶段。利用多阶段系统中的结构冗余，提升创新扩散能力。

Result: 验证表明，创新扩散模型让LLM能够将创新推广到结构上相似的不同阶段，实现了创新的更好泛化和复用。

Conclusion: 创新扩散模型能够提升LLM将创新意见从单一阶段推广扩散到多阶段结构中的能力，从而改善其泛化和创新复用表现。

Abstract: Large Language Models (LLMs) exhibit strong capabilities in reproducing and
extending patterns observed during pretraining but often struggle to generalize
novel ideas beyond their original context. This paper addresses the challenge
of applying such localized innovations - introduced at a specific stage or
component - to other parts of a multi-stage process. We propose a scatter-based
innovation expansion model (innovation scatter model) that guides the LLM
through a four-step process: (1) identifying the core innovation by comparing
the user's input with its surrounding context, (2) generalizing the innovation
by removing references to specific stages or components, (3) determining
whether the generalized innovation applies to a broader scope beyond the
original stage, and (4) systematically applying it to other structurally
similar stages using the LLM. This model leverages structural redundancy across
stages to improve the applicability of novel ideas. Verification results
demonstrate that the innovation scatter model enables LLMs to extend
innovations across structurally similar stages, thereby enhancing
generalization and reuse.

</details>


### [186] [A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment](https://arxiv.org/abs/2506.17951)
*Quanwei Tang,Sophia Yat Mei Lee,Junshuang Wu,Dong Zhang,Shoushan Li,Erik Cambria,Guodong Zhou*

Main category: cs.CL

TL;DR: 本文提出GraphMPA，通过图结构模拟人类信息整合过程并加入偏好优化机制，显著提升了大模型问答系统的全局理解和人类对齐水平，在多数据集实验中效果突出。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成（RAG）技术提升了大语言模型在问答任务中的表现，但模型在实现全局理解和对齐人类伦理及质量偏好方面依然面临挑战。

Method: 提出了一种综合性基于图的框架GraphMPA，并配合模式寻优偏好对齐方法。该方法通过一般相似性度量构建分层文档图，模拟人类认知过程进行信息理解与综合，并引入概率匹配约束以优化模型输出与人类偏好的对齐。

Result: 在六个数据集上的大量实验结果证明了GraphMPA方法的有效性。

Conclusion: GraphMPA框架能够提高大语言模型的全局理解能力与与人类偏好的对齐表现，为检索增强生成任务带来更优的答案质量和伦理对齐效果。

Abstract: Recent advancements in retrieval-augmented generation (RAG) have enhanced
large language models in question answering by integrating external knowledge.
However, challenges persist in achieving global understanding and aligning
responses with human ethical and quality preferences. To address these issues,
we propose GraphMPA, a comprehensive graph-based framework with mode-seeking
preference alignment. Our approach constructs a hierarchical document graph
using a general similarity measurement, mimicking human cognitive processes for
information understanding and synthesis. Additionally, we introduce
mode-seeking preference optimization to better align model outputs with human
preferences through probability-matching constraints. Extensive experiments on
six datasets demonstrate the effectiveness of our
\href{https://github.com/tangquanwei/GraphMPA}{GraphMPA}.

</details>


### [187] [PDF Retrieval Augmented Question Answering](https://arxiv.org/abs/2506.18027)
*Thi Thu Uyen Hoang,Viet Anh Nguyen*

Main category: cs.CL

TL;DR: 作者基于RAG框架，提出了一种支持PDF多模态内容（如图片、表格等）问答的系统，并通过改进模型和集成技术在实验中获得了良好效果。该工作为多模态数据问答研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 目前大多数问答系统仅针对文本数据设计，而PDF中富含文本、图片、表格、图表等多种类型内容，如何处理这些多模态数据并进行有效问答极具挑战性。

Method: 本研究基于RAG（检索增强生成）框架，专注于改进对PDF文件中的非文本元素的处理与集成，并通过对大语言模型进行针对性的微调，以更好地适应多模态问答的场景。

Result: 通过实验评估，所提出系统在处理PDF多种内容类型时，能够准确提取信息，对复杂多模态问题也能给出有效答案，表现出较强的适应性和可靠性。

Conclusion: 本文推动了检索增强型问答系统在多模态数据整合与处理方面的发展，为未来相关研究提供了技术基础和新思路。

Abstract: This paper presents an advancement in Question-Answering (QA) systems using a
Retrieval Augmented Generation (RAG) framework to enhance information
extraction from PDF files. Recognizing the richness and diversity of data
within PDFs--including text, images, vector diagrams, graphs, and tables--poses
unique challenges for existing QA systems primarily designed for textual
content. We seek to develop a comprehensive RAG-based QA system that will
effectively address complex multimodal questions, where several data types are
combined in the query. This is mainly achieved by refining approaches to
processing and integrating non-textual elements in PDFs into the RAG framework
to derive precise and relevant answers, as well as fine-tuning large language
models to better adapt to our system. We provide an in-depth experimental
evaluation of our solution, demonstrating its capability to extract accurate
information that can be applied to different types of content across PDFs. This
work not only pushes the boundaries of retrieval-augmented QA systems but also
lays a foundation for further research in multimodal data integration and
processing.

</details>


### [188] [Splitformer: An improved early-exit architecture for automatic speech recognition on edge devices](https://arxiv.org/abs/2506.18035)
*Maxence Lasbordes,Daniele Falavigna,Alessio Brutti*

Main category: cs.CL

TL;DR: 针对计算资源有限场景，作者提出在神经网络早期退出模型中增加并行下采样层，有效提升了语音识别性能，实现了模型效率和推理速度的优化。


<details>
  <summary>Details</summary>
Motivation: 神经网络模型在设备端推理面临计算资源有限且波动的问题，需要模型具备动态调整计算负载的能力。早期退出（early-exit）架构通过在中间层提供提前输出，提高了推理灵活性；但一些自动语音识别中的高效架构，如Zipformer，则缺乏引入早期退出分支所需的模块化。论文旨在改进早期退出模型的表现。

Method: 作者提出在早期退出模型中引入处理下采样输入的并行层，这些并行层与标准处理层结合工作，提升性能。这样在保持推理时间基本不变的前提下，有效增强了模型的内存效率和灵活性。

Result: 实验表明，该方法在标准语音识别基准上显著提升了性能，仅带来极小的模型参数增加，同时推理时间不受影响。

Conclusion: 引入并行下采样层的方法能够有效提升早期退出神经网络在自动语音识别任务中的表现，且可控的增加模型复杂度和保持推理高效性。

Abstract: The ability to dynamically adjust the computational load of neural models
during inference in a resource aware manner is crucial for on-device processing
scenarios, characterised by limited and time-varying computational resources.
Early-exit architectures represent an elegant and effective solution, since
they can process the input with a subset of their layers, exiting at
intermediate branches (the upmost layers are hence removed from the model).
  From a different perspective, for automatic speech recognition applications
there are memory-efficient neural architectures that apply variable frame rate
analysis, through downsampling/upsampling operations in the middle layers,
reducing the overall number of operations and improving significantly the
performance on well established benchmarks. One example is the Zipformer.
However, these architectures lack the modularity necessary to inject early-exit
branches.
  With the aim of improving the performance in early-exit models, we propose
introducing parallel layers in the architecture that process downsampled
versions of their inputs. % in conjunction with standard processing layers. We
show that in this way the speech recognition performance on standard benchmarks
significantly improve, at the cost of a small increase in the overall number of
model parameters but without affecting the inference time.

</details>


### [189] [Markov-Enhanced Clustering for Long Document Summarization: Tackling the 'Lost in the Middle' Challenge with Large Language Models](https://arxiv.org/abs/2506.18036)
*Aziz Amari,Mohamed Achref Ben Ammar*

Main category: cs.CL

TL;DR: 本文提出了一种结合提取式和生成式的混合自动文本摘要方法，通过分段、聚类、生成局部摘要并利用马尔可夫链有序整合，实现长文档优质摘要，解决了长文本信息易丢失的难题。


<details>
  <summary>Details</summary>
Motivation: 随着信息量的极大增长，有效的自动文本摘要需求增加。现有摘要方法存在提取式和生成式两种，特别是大语言模型虽然提升了生成式摘要能力，但在处理长文本时容易丢失关键信息。因此，亟需更能保留核心内容的高效摘要方法。

Method: 提出了一种混合摘要方法，将提取式和生成式结合。具体做法为：将文档分割为小片段，对其向量嵌入进行聚类，为每个聚类生成代表该部分核心思想的摘要，最终用马尔可夫链图选择摘要中各思想的语义顺序，构建最终摘要。

Result: 该方法能够更好地整合长文档中的关键信息，避免“丢失中间内容”的问题，同时提升摘要的准确性与连贯性。

Conclusion: 混合摘要方法兼具提取式的精准与生成式的表达优势，能更有效应对长文档内容分散与关键信息遗漏的难题。

Abstract: The rapid expansion of information from diverse sources has heightened the
need for effective automatic text summarization, which condenses documents into
shorter, coherent texts. Summarization methods generally fall into two
categories: extractive, which selects key segments from the original text, and
abstractive, which generates summaries by rephrasing the content coherently.
Large language models have advanced the field of abstractive summarization, but
they are resourceintensive and face significant challenges in retaining key
information across lengthy documents, which we call being "lost in the middle".
To address these issues, we propose a hybrid summarization approach that
combines extractive and abstractive techniques. Our method splits the document
into smaller text chunks, clusters their vector embeddings, generates a summary
for each cluster that represents a key idea in the document, and constructs the
final summary by relying on a Markov chain graph when selecting the semantic
order of ideas.

</details>


### [190] [Statistical Multicriteria Evaluation of LLM-Generated Text](https://arxiv.org/abs/2506.18082)
*Esteban Garces Arias,Hannah Blocher,Julian Rodemann,Matthias Aßenmacher,Christoph Jansen*

Main category: cs.CL

TL;DR: 本文提出并实证了一种基于GSD的多维度文本生成质量评价框架，能够科学兼容多指标和测量尺度，实现可靠的统计推断，解决了现有评价方法的主要不足。


<details>
  <summary>Details</summary>
Motivation: 当前对大语言模型（LLM）生成文本质量的评价方法存在局限，单一指标或简单汇总无法准确反映文本多维度的质量（如连贯性、多样性、流畅性等）之间的权衡。同时，自动评分方法与人工评判的度量方式和尺度常常不一致，且缺乏统计推断保证。

Method: 本文采用基于广义随机优势（GSD）的统计推断框架，以多元、分层次的方式综合评估生成文本的多种质量维度，兼容不同的度量尺度，避免对各指标作出主观加权，支持更科学的推断分析。

Result: 通过该框架，对常见的文本生成解码策略与人工生成文本进行衡量，可以揭示多维质量上的显著性能差异，并实现统计显著性的保证，且能够应对采样设计中可能出现的非独立同分布（non-i.i.d.）情况。

Conclusion: GSD-front评估框架突破了现有的单指标和人为权重设定局限，能实现多维度、可靠且统计显著的LLM文本质量判别，为未来相关文本生成评估提供了一种更科学和实用的方法。

Abstract: Assessing the quality of LLM-generated text remains a fundamental challenge
in natural language processing. Current evaluation approaches often rely on
isolated metrics or simplistic aggregations that fail to capture the nuanced
trade-offs between coherence, diversity, fluency, and other relevant indicators
of text quality. In this work, we adapt a recently proposed framework for
statistical inference based on Generalized Stochastic Dominance (GSD) that
addresses three critical limitations in existing benchmarking methodologies:
the inadequacy of single-metric evaluation, the incompatibility between
cardinal automatic metrics and ordinal human judgments, and the lack of
inferential statistical guarantees. The GSD-front approach enables simultaneous
evaluation across multiple quality dimensions while respecting their different
measurement scales, building upon partial orders of decoding strategies, thus
avoiding arbitrary weighting of the involved metrics. By applying this
framework to evaluate common decoding strategies against human-generated text,
we demonstrate its ability to identify statistically significant performance
differences while accounting for potential deviations from the i.i.d.
assumption of the sampling design.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [191] [Bridging Equilibrium and Kinetics Prediction with a Data-Weighted Neural Network Model of Methane Steam Reforming](https://arxiv.org/abs/2506.17224)
*Zofia Pizoń,Shinji Kimijima,Grzegorz Brus*

Main category: cs.CE

TL;DR: 论文提出了一种训练于多源数据（实验、理论、插值等）的神经网络代理模型，实现了对甲烷蒸汽重整动力学和热力学工况的统一高精度预测，显著提升了过程建模与优化能力，可用于反应器设计和流程优化。


<details>
  <summary>Details</summary>
Motivation: 当前氢气作为能源载体的需求不断增长，甲烷蒸汽重整是最常用的制氢工艺。随着燃料电池等应用推动反应器的小型化和过程优化，对能同时处理动力学和热力学（平衡）两种工况的高效模拟方法的需求日益突出。然而，现有模型多仅适用于某一工况，适用面有限。

Method: 本文开发了一种代理模型，利用人工神经网络，并用包含动力学实验、平衡实验、插值数据和理论数据的综合数据集进行训练。数据增强及不同数据类型赋予不同权重提升了模型训练效果。对比贝叶斯优化和随机采样，选取了最优模型。

Result: 该神经网络模型在不同操作参数下预测反应后混合物组成时表现出极高准确性，均方误差仅为0.000498，Pearson相关系数为0.927。模型输出具有连续导数，适合于过程建模和优化。

Conclusion: 所提代理模型能够统一动力学和平衡两类工况，具有稳定性和较强的泛化能力，为甲烷蒸汽重整反应模拟和优化提供了有力工具。

Abstract: Hydrogen's role is growing as an energy carrier, increasing the need for
efficient production, with methane steam reforming being the most widely used
technique. This process is crucial for applications like fuel cells, where
hydrogen is converted into electricity, pushing for reactor miniaturization and
optimized process control through numerical simulations. Existing models
typically address either kinetic or equilibrium regimes, limiting their
applicability. Here we show a surrogate model capable of unifying both regimes.
An artificial neural network trained on a comprehensive dataset that includes
experimental data from kinetic and equilibrium experiments, interpolated data,
and theoretical data derived from theoretical models for each regime. Data
augmentation and assigning appropriate weights to each data type enhanced
training. After evaluating Bayesian Optimization and Random Sampling, the
optimal model demonstrated high predictive accuracy for the composition of the
post-reaction mixture under varying operating parameters, indicated by a mean
squared error of 0.000498 and strong Pearson correlation coefficients of 0.927.
The network's ability to provide continuous derivatives of its predictions
makes it particularly useful for process modeling and optimization. The results
confirm the surrogate model's robustness for simulating methane steam reforming
in both kinetic and equilibrium regimes, making it a valuable tool for design
and process optimization.

</details>


### [192] [Variational Quantum Latent Encoding for Topology Optimization](https://arxiv.org/abs/2506.17487)
*Alireza Tabarraei*

Main category: cs.CE

TL;DR: 本文提出融合量子和经典潜空间编码的神经结构优化方法，实现无监督、多解拓扑设计。量子潜编码在设计多样性和物理性能上展现优势，显示量子电路在结构优化领域的应用前景。


<details>
  <summary>Details</summary>
Motivation: 希望突破传统拓扑优化只能得到单一解的限制，通过量子与经典潜空间编码提升设计多样性和性能，同时为物理约束的结构优化探索高效方法，并探索量子硬件在结构设计中的应用潜力。

Method: 提出一种变分结构拓扑优化框架，将量子与经典潜编码方法结合到基于坐标的神经解码结构中。使用变分量子电路或高斯分布生成低维潜向量，经可学习投影层映射到高维潜空间，再通过神经网络与傅里叶映射坐标联合解码为高分辨率材料分布，并以有限元分析的物理目标直接优化潜参数。

Result: 实验表明，所提方法无监督下可生成多样且物理有效的结构拓扑。两类编码方式均获得高质量设计，量子编码在多个基准问题中在顺应性和设计多样性上优于经典方法。

Conclusion: 量子电路在结构拓扑优化中展现出有效性和可扩展性，有望在结构设计领域推动近端量子硬件的应用。

Abstract: A variational framework for structural topology optimization is developed,
integrating quantum and classical latent encoding strategies within a
coordinate-based neural decoding architecture. In this approach, a
low-dimensional latent vector, generated either by a variational quantum
circuit or sampled from a Gaussian distribution, is mapped to a
higher-dimensional latent space via a learnable projection layer. This enriched
representation is then decoded into a high-resolution material distribution
using a neural network that takes both the latent vector and Fourier-mapped
spatial coordinates as input. The optimization is performed directly on the
latent parameters, guided solely by physics-based objectives such as compliance
minimization and volume constraints evaluated through finite element analysis,
without requiring any precomputed datasets or supervised training. Quantum
latent vectors are constructed from the expectation values of Pauli observables
measured on parameterized quantum circuits, providing a structured and
entangled encoding of information. The classical baseline uses Gaussian-sampled
latent vectors projected in the same manner. The proposed variational
formulation enables the generation of diverse and physically valid topologies
by exploring the latent space through sampling or perturbation, in contrast to
traditional optimization methods that yield a single deterministic solution.
Numerical experiments show that both classical and quantum encodings produce
high-quality structural designs. However, quantum encodings demonstrate
advantages in several benchmark cases in terms of compliance and design
diversity. These results highlight the potential of quantum circuits as an
effective and scalable tool for physics-constrained topology optimization and
suggest promising directions for applying near-term quantum hardware in
structural design.

</details>


### [193] [A predictor-corrector scheme for approximating signed distances using finite element methods](https://arxiv.org/abs/2506.17830)
*Amina El Bachari,Johann Rannou,Vladislav A. Yastrebov,Pierre Kerfriden,Susanne Claus*

Main category: cs.CE

TL;DR: 本文提出了一种有效且健壮的有限元方法，通过预测-校正策略计算拟有符号距离函数，能很好地应对复杂界面和各种初始情况，适用于各类level set重初始化问题。


<details>
  <summary>Details</summary>
Motivation: 现有计算有符号距离函数的方法在处理复杂界面或初始level set函数有突出或平坦区域时往往不够健壮高效。

Method: 提出了一种有限元方法，结合了基于扩散的线性预测步骤和基于Eikonal方程的非线性最小化校正步骤。

Result: 通过多种典型与复杂几何（如星域、三维环面等）的数值实验，方法具备高精度、高效率和鲁棒性。

Conclusion: 该方法能广泛稳定地应用于各类level set函数的重新初始化，尤其在复杂界面情况下表现出色。

Abstract: In this article, we introduce a finite element method designed for the robust
computation of approximate signed distance functions to arbitrary boundaries in
two and three dimensions. Our method employs a novel prediction-correction
approach, involving first the solution of a linear diffusion-based prediction
problem, followed by a nonlinear minimization-based correction problem
associated with the Eikonal equation. The prediction step efficiently generates
a suitable initial guess, significantly facilitating convergence of the
nonlinear correction step. A key strength of our approach is its ability to
handle complex interfaces and initial level set functions with arbitrary steep
or flat regions, a notable challenge for existing techniques. Through several
representative examples, including classical geometries and more complex shapes
such as star domains and three-dimensional tori, we demonstrate the accuracy,
efficiency, and robustness of the method, validating its broad applicability
for reinitializing diverse level set functions.

</details>


### [194] [Learning from the Storm: A Multivariate Machine Learning Approach to Predicting Hurricane-Induced Economic Losses](https://arxiv.org/abs/2506.17964)
*Bolin Shen,Eren Erman Ozguven,Yue Zhao,Guang Wang,Yiqun Xie,Yushun Dong*

Main category: cs.CE

TL;DR: 本研究构建了一个集成飓风特征、水环境和社会经济要素的机器学习框架，在微观空间尺度上预测佛罗里达州飓风经济损失，并能够量化各项因素的重要性，助力灾害管理和城市规划。


<details>
  <summary>Details</summary>
Motivation: 佛罗里达州经常遭受飓风袭击，导致巨大经济损失。以往研究多关注具体原因，但很少有统一框架能整合各类影响因素，全面评估经济损失的来源。该研究旨在填补这一领域空白。

Method: 提出了一个综合性建模框架，将影响因素分为三类：（1）飓风特征、（2）与水相关的环境因子、（3）受灾地区的社会经济因素。整合多源数据，并将所有变量聚合到更细致的ZCTA（邮政编码区域）空间尺度，利用机器学习模型以保险理赔作为经济损失指标进行预测。

Result: 框架能准确预测经济损失，并系统评估各因素的重要性。为灾害缓解、风险评估和海岸及暴风区城市适应性策略的制定提供了实际指导。相关代码已开源。

Conclusion: 提出并验证了一个整合多维度因素的飓风经济损失预测框架，有效提高了分析全面性和预测准确性，对实际灾害管理有重要参考价值。

Abstract: Florida is particularly vulnerable to hurricanes, which frequently cause
substantial economic losses. While prior studies have explored specific
contributors to hurricane-induced damage, few have developed a unified
framework capable of integrating a broader range of influencing factors to
comprehensively assess the sources of economic loss. In this study, we propose
a comprehensive modeling framework that categorizes contributing factors into
three key components: (1) hurricane characteristics, (2) water-related
environmental factors, and (3) socioeconomic factors of affected areas. By
integrating multi-source data and aggregating all variables at the finer
spatial granularity of the ZIP Code Tabulation Area (ZCTA) level, we employ
machine learning models to predict economic loss, using insurance claims as
indicators of incurred damage. Beyond accurate loss prediction, our approach
facilitates a systematic assessment of the relative importance of each
component, providing practical guidance for disaster mitigation, risk
assessment, and the development of adaptive urban strategies in coastal and
storm-exposed areas. Our code is now available at:
https://github.com/LabRAI/Hurricane-Induced-Economic-Loss-Prediction

</details>


### [195] [A phase field model for hydraulic fracture: Drucker-Prager driving force and a hybrid coupling strategy](https://arxiv.org/abs/2506.18161)
*Y. Navidtehrani,C. Betegón,J. Vallejos,E. Martínez-Pañeda*

Main category: cs.CE

TL;DR: 本文提出了新型通用的相场水力压裂模拟框架，创新性处理流体-裂纹耦合与特殊材料断裂，显著拓展实际工程应用范围，并开源了相关代码。


<details>
  <summary>Details</summary>
Motivation: 近年来，利用相场方法模拟水力压裂受到极大关注，旨在优化关键工业过程（如石油工程、采矿和地热能提取），但现有方法在液体流动与相场耦合、断裂驱动力描述等方面存在局限性。

Method: 提出了一种新颖的理论与计算相场框架，能够更好地处理液体流动与相场的耦合，并普适性地描述断裂驱动力。包括：1）创新性的混合耦合方法，提升裂缝-液体流相互作用的精度与灵活性；2）基于Drucker-Prager准则的应变能分解，扩展到能模拟拉压不对称断裂特性的材料如页岩，并预测断层激活和粘滑行为。

Result: 通过四个案例分析展示该框架的新建模能力，涵盖渗透率耦合、裂纹行为及多轴工况下的水力压裂模拟。相关代码已开源并对外发布。

Conclusion: 提出的通用相场方法拓展了水力压裂模拟的材料和物理范围，并为相关工程领域提供了更强的建模和预测能力。

Abstract: Recent years have seen a significant interest in using phase field approaches
to model hydraulic fracture, so as to optimise a process that is key to
industries such as petroleum engineering, mining and geothermal energy
extraction. Here, we present a novel theoretical and computational phase field
framework to simulate hydraulic fracture. The framework is general and
versatile, in that it allows for improved treatments of the coupling between
fluid flow and the phase field, and encompasses a universal description of the
fracture driving force. Among others, this allows us to bring two innovations
to the phase field hydraulic fracture community: (i) a new hybrid coupling
approach to handle the fracture-fluid flow interplay, offering enhanced
accuracy and flexibility; and (ii) a Drucker-Prager-based strain energy
decomposition, extending the simulation of hydraulic fracture to materials
exhibiting asymmetric tension-compression fracture behaviour (such as shale
rocks) and enabling the prediction of geomechanical phenomena such as fault
reactivation and stick-slip behaviour. Four case studies are addressed to
illustrate these additional modelling capabilities and bring insight into
permeability coupling, cracking behaviour, and multiaxial conditions in
hydraulic fracturing simulations. The codes developed are made freely available
to the community and can be downloaded from {https://mechmat.web.ox.ac.uk/

</details>


### [196] [Measuring Fractal Dimension using Discrete Global Grid Systems](https://arxiv.org/abs/2506.18175)
*Pramit Ghosh*

Main category: cs.CE

TL;DR: 本文提出利用DGGS计算地理空间矢量数据的分形维数，有效消除了传统网格覆盖方法的局限，实验与理论均表现优异，为地理数据分析提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 分形维数和离散全球网格系统（DGGS）是地理信息科学中的两个重要但彼此关联较少的领域，本研究旨在探索将DGGS用作地理矢量数据计算分形维数的覆盖集，以解决现有方法中由网格位置、方向及尺寸进展带来的局限性。

Method: 作者将DGGS用作覆盖集，采用Minkowski-Bouligand方法计算地理矢量数据的分形维数。通过在合成数据和卫星云层数据上进行实验，检验该方法的有效性和准确性。

Result: 新方法在合成数据测试中与理论分形维数的误差小于1%；在真实卫星云场数据中的实验结果与文献中的分形维数值一致。方法在考虑地球曲率以及消除网格任意性方面具有优势。

Conclusion: DGGS作为覆盖集计算地理空间数据分形维数的方法是有效且理论上可行的，能够缓解传统方法中网格选择和尺寸调整的问题，并适用于大范围地理数据。论文还讨论了适合该用途的DGGS的理想特性。

Abstract: This study builds a bridge between two well-studied but distant topics:
fractal dimension and Discrete Global Grid System (DGGS). DGGSs are used as
covering sets for geospatial vector data to calculate the Minkowski-Bouligand
dimension. Using the method on synthetic data yields results within 1% of their
theoretical fractal dimensions. A case study on opaque cloud fields obtained
from satellite images gives fractal dimension in agreement with that available
in the literature. The proposed method alleviates the problems of arbitrary
grid placement and orientation, as well as the progression of cell sizes of the
covering sets for geospatial data. Using DGGSs further ensure that
intersections of the covering sets with the geospatial vector having large
geographic extents are calculated by taking the curvature of the earth into
account. This paper establishes the validity of DGGSs as covering sets
theoretically and discusses desirable properties of DGGSs suitable for this
purpose.

</details>


### [197] [Conservative data-driven finite element formulation](https://arxiv.org/abs/2506.18206)
*Adriana Kuliková,Andrei G. Shvarts,Łukasz Kaczmarczyk,Chris J. Pearce*

Main category: cs.CE

TL;DR: 本文提出一种利用混合有限元理论的数据驱动有限元框架，直接在数值计算中应用实验数据，避免传统材料模型拟合带来的偏差和不确定性，利用后验误差指示器支持自适应加密，并在核石墨非线性热传导算例中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的扩散问题求解方法依赖于简化材料模型来拟合实验数据，这可能导致模型偏差，无法充分利用全部实验数据。作者希望通过数据驱动的方法，直接应用实验数据，避免材料模型参数拟合带来的限制和风险。

Method: 提出了一种基于混合有限元（mixed finite element）数据驱动有限元分析框架。通过混合有限元方法强制满足守恒律和边界条件，并直接在数值计算中采用实验数据，无需拟合材料模型参数。混合有限元方法降低了对逼近空间的正则性要求，确保了法向通量在所有内部边界上的连续性。此外，该方法提供了适用于数据驱动计算的后验误差指示器，支持自适应 hp-加密。

Result: 该方法可以量化数据集变化导致的解的非唯一性并预测结果的不确定性。在非线性热传导（以合成的核石墨材料数据集为例）环境下，验证了所提混合有限元数据驱动框架的有效性和灵活性。

Conclusion: 提出的混合有限元数据驱动框架能够避免材料模型参数拟合，直接利用实验数据，从而减少模型偏差和不确定性，支持精确适应性分析。该框架适用于处理扩散问题，能够量化解的不确定性，其适用性和有效性通过热传导实例得到了验证。

Abstract: This paper presents a new data-driven finite element framework derived with
mixed finite element formulation. The standard approach to diffusion problems
requires the solution of the mathematical equations that describe both the
conservation law and the constitutive relations, where the latter is
traditionally obtained after fitting experimental data to simplified material
models. To exploit all available information and avoid bias in the material
model, we follow a data-driven approach. While the conservation laws and
boundary conditions are satisfied by means of the finite element method, the
experimental data is used directly in the numerical simulations, avoiding the
need of fitting material model parameters. In order to satisfy the conservation
law a priori in the strong sense, we introduce a mixed finite element
formulation. This relaxes the regularity requirements on approximation spaces
while enforcing continuity of the normal flux component across all of the inner
boundaries. This weaker mixed formulation provides a posteriori error
indicators tailored for this data-driven approach, enabling adaptive
hp-refinement. The relaxed regularity of the approximation spaces makes it
easier to observe how the variation in the datasets results in the
non-uniqueness of the solution, which can be quantified to predict the
uncertainty of the results. The capabilities of the formulation are
demonstrated in an example of the nonlinear heat transfer in nuclear graphite
using synthetically generated material datasets.

</details>


### [198] [Exact Conditional Score-Guided Generative Modeling for Amortized Inference in Uncertainty Quantification](https://arxiv.org/abs/2506.18227)
*Zezhong Zhang,Caroline Tatsuoka,Dongbin Xiu,Guannan Zhang*

Main category: cs.CE

TL;DR: 本文提出融合精准条件扩散模型与前馈神经网络的高效条件推断方法，兼具表达力与推断速度，适合复杂后验分布任务。


<details>
  <summary>Details</summary>
Motivation: 目前有条件推断的生成模型存在效率和表达能力的权衡。可逆归一化流需要可逆结构，限制了模型表达力和效率；扩散模型则推断计算成本高。本研究动机在于结合两者优点，实现高效且表达力强的条件生成建模。

Method: 提出一种两阶段方法。第一阶段，通过精确计算由样本构建的高斯混合先验下的条件score，引导无监督扩散模型，无需训练即可生成条件噪声标注样本。第二阶段，利用生成的噪声-标签数据，训练一个前馈神经网络，将噪声和观测直接映射为后验样本，从而避免模型结构可逆性和推断过程迭代采样。

Result: 该方法在高维度、多峰后验分布的条件采样任务中实现了快速、精准、可扩展的推断，在复杂物理系统参数估计等不确定性量化任务上显示了优越性。通过数值实验验证了方法有效性。

Conclusion: 该工作提出了一种结合扩散模型与非可逆神经网络的条件生成方法，提升了条件推断的效率与表达能力，为高复杂度系统的不确定性量化等应用提供了新工具。

Abstract: We propose an efficient framework for amortized conditional inference by
leveraging exact conditional score-guided diffusion models to train a
non-reversible neural network as a conditional generative model. Traditional
normalizing flow methods require reversible architectures, which can limit
their expressiveness and efficiency. Although diffusion models offer greater
flexibility, they often suffer from high computational costs during inference.
To combine the strengths of both approaches, we introduce a two-stage method.
First, we construct a training-free conditional diffusion model by analytically
deriving an exact score function under a Gaussian mixture prior formed from
samples of the underlying joint distribution. This exact conditional score
model allows us to efficiently generate noise-labeled data, consisting of
initial diffusion Gaussian noise and posterior samples conditioned on various
observation values, by solving a reverse-time ordinary differential equation.
Second, we use this noise-labeled data to train a feedforward neural network
that maps noise and observations directly to posterior samples, eliminating the
need for reversibility or iterative sampling at inference time. The resulting
model provides fast, accurate, and scalable conditional sampling for
high-dimensional and multi-modal posterior distributions, making it well-suited
for uncertainty quantification tasks, e.g., parameter estimation of complex
physical systems. We demonstrate the effectiveness of our approach through a
series of numerical experiments.

</details>


### [199] [Neural-operator element method: Efficient and scalable finite element method enabled by reusable neural operators](https://arxiv.org/abs/2506.18427)
*Weihang Ouyang,Yeonjong Shin,Si-Wei Liu,Lu Lu*

Main category: cs.CE

TL;DR: NOEM结合了有限元和神经算子的优点，大幅降低了复杂PDE模拟的计算成本，实验验证了方法的高效、准确与可扩展，适用于多种复杂问题。


<details>
  <summary>Details</summary>
Motivation: 有限元方法（FEM）在解决偏微分方程（PDE）方面非常成熟，但其基于网格的特性导致在复杂多尺度模拟中计算成本高。近年来，基于机器学习的神经算子（neural operators）等方法为PDE提供了数据驱动的解法，但存在高训练成本和模型可复用性低等问题。

Method: 提出了一种神经算子元方法（NOEM），将有限元方法与神经算子结合。在需要大量有限元划分的子域内，采用神经算子构建单个神经算子元（NOE），这些NOE与标准有限元整合，通过变分框架共同表示整体解，不需要密集网格划分。

Result: 通过大量数值实验，展示了NOEM在非线性PDE、多尺度问题、复杂几何及不连续系数场上的准确性、效率和可扩展性。

Conclusion: NOEM方法能够克服传统有限元和神经算子方法的局限，实现了更加高效且可扩展的PDE模拟，在复杂多尺度问题上具有明显优势。

Abstract: The finite element method (FEM) is a well-established numerical method for
solving partial differential equations (PDEs). However, its mesh-based nature
gives rise to substantial computational costs, especially for complex
multiscale simulations. Emerging machine learning-based methods (e.g., neural
operators) provide data-driven solutions to PDEs, yet they present challenges,
including high training cost and low model reusability. Here, we propose the
neural-operator element method (NOEM) by synergistically combining FEM with
operator learning to address these challenges. NOEM leverages neural operators
(NOs) to simulate subdomains where a large number of finite elements would be
required if FEM was used. In each subdomain, an NO is used to build a single
element, namely a neural-operator element (NOE). NOEs are then integrated with
standard finite elements to represent the entire solution through the
variational framework. Thereby, NOEM does not necessitate dense meshing and
offers efficient simulations. We demonstrate the accuracy, efficiency, and
scalability of NOEM by performing extensive and systematic numerical
experiments, including nonlinear PDEs, multiscale problems, PDEs on complex
geometries, and discontinuous coefficient fields.

</details>


### [200] [Virtual failure assessment diagrams for hydrogen transmission pipelines](https://arxiv.org/abs/2506.18554)
*J. Wijnen,J. Parker,M. Gagliano,E. Martínez-Pañeda*

Main category: cs.CE

TL;DR: 本研究提出结合先进工艺建模与相场断裂仿真的新方法，定量分析氢输运管道氢脆失效的关键因素，生成更精准的失效评估图，发现现有标准评估方法存在保守不足，并提出改进的安全系数建议。


<details>
  <summary>Details</summary>
Motivation: 氢气运输管道在使用过程中面临由焊接工艺和材料特性导致的结构脆化和失效风险，现有标准中故障评估方法（FAD）对焊缝微观结构异质性和残余应力的考虑不足，可能导致安全性评估不准确。

Method: 将先进的热-冶金焊接过程建模与相场断裂模拟（包括耦合扩散—弹塑性）结合，定量分析焊缝残余应力、热影响区（HAZ）的脆硬区域作用，并模拟各种缺陷态、材料、焊接工艺和氢纯度条件下的失效情况。进一步，基于广泛仿真结果构建虚拟FAD图表，实现机理驱动的服役安全性评估流程。

Result: 研究发现，模型预测与现有FAD标准吻合良好，但揭示标准FAD未能保守地反映焊缝微观结构异质性对失效压力的影响。提出了可补偿残余应力和脆硬焊缝区域影响的机理化FAD安全系数。

Conclusion: 该方法为氢气管道服役安全评估提供了量化、机理化的手段，能更准确考虑焊缝细节与缺陷情况，优化现有安全标准并提升风险评估可靠性。

Abstract: We combine state-of-the-art thermo-metallurgical welding process modelling
with coupled diffusion-elastic-plastic phase field fracture simulations to
predict the failure states of hydrogen transport pipelines. This enables
quantitatively resolving residual stress states and the role of brittle, hard
regions of the weld such as the heat affected zone (HAZ). Failure pressures can
be efficiently quantified as a function of asset state (existing defects),
materials and weld procedures adopted, and hydrogen purity. Importantly,
simulations spanning numerous relevant conditions (defect size and
orientations) are used to build \emph{Virtual} Failure Assessment Diagrams
(FADs), enabling a straightforward uptake of this mechanistic approach in
fitness-for-service assessment. Model predictions are in very good agreement
with FAD approaches from the standards but show that the latter are not
conservative when resolving the heterogeneous nature of the weld
microstructure. Appropriate, \emph{mechanistic} FAD safety factors are
established that account for the role of residual stresses and hard, brittle
weld regions.

</details>


### [201] [A Physics-Informed Neural Network Framework for Simulating Creep Buckling in Growing Viscoelastic Biological Tissues](https://arxiv.org/abs/2506.18565)
*Zhongya Lin,Jinshuai Bai,Shuang Li,Xindong Chen,Bo Li,Xi-Qiao Feng*

Main category: cs.CE

TL;DR: 提出了一种用能量最小化约束的PINN方法，不需预设缺陷即可模拟材料时变特性与复杂形态变化，对传统方法形成有益补充，适用结构工程、软材料和组织工程等应用。


<details>
  <summary>Details</summary>
Motivation: 传统有限元等数值方法在模拟粘弹性等时变材料变形时需显式建网格、人工扰动或嵌入定制程序，导致计算复杂度高。为突破这些限制，需要一种物理一致、自动触发失稳且简便的新方法。

Method: 提出并开发了一种基于能量的物理信息神经网络（PINN）框架，采用增量式方法，训练神经网络最小化系统的势能泛函，以隐式满足平衡和本构关系，实现对粘弹性蠕变、应力松弛、屈曲及组织生长形态发生的模拟。

Result: 该方法无需输入预设缺陷，即可依靠神经网络训练过程自发捕捉屈曲现象。将其扩展应用到生物组织生长和形态发生，能够准确预测圆柱结构的均匀扩展与差异生长导致的屈曲。实验结果显示此PINN框架对粘弹性失稳、屈曲后演化和组织形态变化均具有优秀的预测能力。

Conclusion: 本文提出的基于能量的PINN方法能够有效预测粘弹性失稳、屈曲后的形态演化及生物组织的形态变化，是传统方法有力的补充，为复杂、时变材料行为建模提供了灵活且鲁棒的新工具。

Abstract: Modeling viscoelastic behavior is crucial in engineering and biomechanics,
where materials undergo time-dependent deformations, including stress
relaxation, creep buckling and biological tissue development. Traditional
numerical methods, like the finite element method, often require explicit
meshing, artificial perturbations or embedding customised programs to capture
these phenomena, adding computational complexity. In this study, we develop an
energy-based physics-informed neural network (PINN) framework using an
incremental approach to model viscoelastic creep, stress relaxation, buckling,
and growth-induced morphogenesis. Physics consistency is ensured by training
neural networks to minimize the systems potential energy functional, implicitly
satisfying equilibrium and constitutive laws. We demonstrate that this
framework can naturally capture creep buckling without pre-imposed
imperfections, leveraging inherent training dynamics to trigger instabilities.
Furthermore, we extend our framework to biological tissue growth and
morphogenesis, predicting both uniform expansion and differential
growth-induced buckling in cylindrical structures. Results show that the
energy-based PINN effectively predicts viscoelastic instabilities,
post-buckling evolution and tissue morphological evolution, offering a
promising alternative to traditional methods. This study demonstrates that PINN
can be a flexible robust tool for modeling complex, time-dependent material
behavior, opening possible applications in structural engineering, soft
materials, and tissue development.

</details>


### [202] [Communication Architecture for Autonomous Power-to-X Platforms: Enhancing Inspection and Operation With Legged Robots and 5G](https://arxiv.org/abs/2506.18572)
*Peter Frank,Falk Dettinger,Daniel Dittler,Pascal Häbig,Nasser Jazdi,Kai Hufendiek,Michael Weyrich*

Main category: cs.CE

TL;DR: 本文提出了一套基于5G网络的通信架构，利用四足机器人自动完成海上Power to X平台的检测和维护，实验证明该方法可有效降低人工成本，提升设施运维的自动化与智能化水平。


<details>
  <summary>Details</summary>
Motivation: 海上平台的检查和维护成本高昂，主要原因是对大量人力的需求和苛刻的作业环境。如何降低人力需求、提升效能是亟需解决的问题。

Method: 首先对Power to X平台进行了分类，然后提出了一套支持监测、控制和远程操作的通信架构。通过集成四足机器人，自动化执行检查和维护工作。机器人在5G独立组网上进行远程监控、控制和遥操作，并记录和评估其可用性与时延。

Result: 实现了四足机器人在Power to X平台上的远程检查与维护。基于5G网络的遥操作的可用性和时延得到了记录与评估，显示了技术可行性和关键性能。

Conclusion: 结合5G通信和四足机器人能够有效减少海上平台对人力的依赖，提高操作安全性与效率。5G网络支持下的远程操作为未来海上设施智能化、自动化维护提供了可行路径。

Abstract: Inspection and maintenance of offshore platforms are associated with high
costs, primarily due to the significant personnel requirements and challenging
operational conditions. This paper first presents a classification of Power to
X platforms. Building upon this foundation, a communication architecture is
proposed to enable monitoring, control, and teleoperation for a Power to X
platform. To reduce the demand for human labor, a robotic system is integrated
to autonomously perform inspection and maintenance tasks. The implementation
utilizes a quadruped robot. Remote monitoring, control, and teleoperation of
the robot are analyzed within the context of a 5G standalone network. As part
of the evaluation, aspects such as availability and latency are recorded,
compared, and critically assessed.

</details>


### [203] [A Study of Dynamic Stock Relationship Modeling and S&P500 Price Forecasting Based on Differential Graph Transformer](https://arxiv.org/abs/2506.18717)
*Linyue Hu,Qi Wang*

Main category: cs.CE

TL;DR: 提出了一种基于差分图变换器的新框架，有效提升了股票价格预测的准确性，结合聚类分析为量化投资策略提供新思路。


<details>
  <summary>Details</summary>
Motivation: 股票价格预测对于投资决策和风险管理至关重要，但由于市场具有非线性动力学和时变的股票间相关性，这一任务极具挑战性。传统的静态相关性模型无法捕捉股票关系的动态演变。

Method: 提出了一种差分图变换器（Differential Graph Transformer, DGT）框架，用于动态关系建模和价格预测。DGT通过差分图机制将序列图结构的变化集成到多头自注意力机制中，有效保留高价值连接并抑制噪声，并采用因果时间注意力捕捉价格序列中的全局和局部依赖。此外，分别评估了多种相关性度量（Pearson, MI, Spearman, Kendall’s Tau）作为空间注意力先验。实验采用历时10年的标准普尔500指数收盘价进行验证。

Result: DGT结合空间先验在预测性能上显著优于GRU基线（RMSE: 0.24 vs. 0.87），以Kendall’s Tau全球矩阵为空间先验时效果最佳（MAE: 0.11）。K-means聚类揭示了高波动成长股与防御型蓝筹股两大类别，后者因相关性更稳定而预测误差更低（RMSE: 0.13）。Kendall’s Tau和互信息在高波动板块表现优秀。

Conclusion: 通过创新性地将差分图结构与Transformer相结合，验证了动态关系建模的有效性和最优相关性度量/范围的选择。聚类分析为定制量化策略提供支持，该框架推进了金融时间序列动态建模和跨资产关系分析。

Abstract: Stock price prediction is vital for investment decisions and risk management,
yet remains challenging due to markets' nonlinear dynamics and time-varying
inter-stock correlations. Traditional static-correlation models fail to capture
evolving stock relationships. To address this, we propose a Differential Graph
Transformer (DGT) framework for dynamic relationship modeling and price
prediction. Our DGT integrates sequential graph structure changes into
multi-head self-attention via a differential graph mechanism, adaptively
preserving high-value connections while suppressing noise. Causal temporal
attention captures global/local dependencies in price sequences. We further
evaluate correlation metrics (Pearson, Mutual Information, Spearman, Kendall's
Tau) across global/local/dual scopes as spatial-attention priors. Using 10
years of S&P 500 closing prices (z-score normalized; 64-day sliding windows),
DGT with spatial priors outperformed GRU baselines (RMSE: 0.24 vs. 0.87).
Kendall's Tau global matrices yielded optimal results (MAE: 0.11). K-means
clustering revealed "high-volatility growth" and "defensive blue-chip" stocks,
with the latter showing lower errors (RMSE: 0.13) due to stable correlations.
Kendall's Tau and Mutual Information excelled in volatile sectors. This study
innovatively combines differential graph structures with Transformers,
validating dynamic relationship modeling and identifying optimal correlation
metrics/scopes. Clustering analysis supports tailored quantitative strategies.
Our framework advances financial time-series prediction through dynamic
modeling and cross-asset interaction analysis.

</details>


### [204] [Towards Real-time Structural Dynamics Simulation with Graph-based Digital Twin Modelling](https://arxiv.org/abs/2506.18724)
*Jun Zhang,Tong Zhang,Ying Wang*

Main category: cs.CE

TL;DR: 提出了一种基于图的数字孪生动力学模拟方法，物理可解释性强，适应多种结构拓扑，精度高、效率极大提升，对结构健康监测应用前景广阔。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在结构动力学模拟中效率低下、计算成本高，而深度学习方法又存在物理可解释性不足与难以适应多样结构的问题。

Method: 提出基于图的数字孪生建模（GDTM）框架，利用邻接矩阵明确表示结构顶点空间关系，从而提升模型物理可解释性，并通过数值与实验研究验证有效性。

Result: 框架能准确模拟不同拓扑结构下的动力响应，数值仿真NMSE低于0.005，实验验证低于0.0015，且较传统有限元法提升超过80倍计算效率。

Conclusion: 基于图的结构动力学建模极大提升了模拟效率与精度，促进了其在结构性能评估和健康监测中的应用潜力。

Abstract: Precise and timely simulation of a structure's dynamic behavior is crucial
for evaluating its performance and assessing its health status. Traditional
numerical methods are often limited by high computational costs and low
efficiency, while deep learning approaches offer a promising alternative.
However, these data-driven methods still face challenges, such as limited
physical interpretability and difficulty in adapting to diverse structural
configurations. To address these issues, this study proposes a graph-based
digital twin modelling (GDTM) framework to simulate structural dynamic
responses across various spatial topologies. In this framework, the adjacency
matrix explicitly represents the spatial relationships between structural
vertices, enhancing the model's physical interpretability. The effectiveness of
the proposed framework was validated through comprehensive numerical and
experimental studies. The results demonstrate that the framework accurately
simulated structural dynamics across different topological configurations, with
Normalized Mean-Squared Error (NMSE) values consistently below 0.005 in
numerical simulations and 0.0015 in experimental validations. Furthermore, the
framework achieved over 80-fold improvements in computational efficiency
compared to traditional finite element methods (FEM). This research promotes
the practical application of graph-based structural dynamics modelling, which
has the potential to significantly advance structural performance evaluation
and health monitoring.

</details>


### [205] [Skeletal Reaction Models for Gasoline Surrogate Combustion](https://arxiv.org/abs/2506.18853)
*Yinmin Liu,Hessam Babaee,Peyman Givi,Daniel Livescu,Arash Nouri*

Main category: cs.CE

TL;DR: 利用新型的隐式TDB-CUR降阶方法，自动化从复杂汽油代理反应模型中提取出骨架反应网络，在保证计算精度的前提下，实现了模型大幅简化，显著提高了工程仿真的效率。


<details>
  <summary>Details</summary>
Motivation: 复杂的汽油代理成分燃烧化学反应模型规模庞大，计算量巨大，限制了其在实际工程中的应用，因此需要通过精简机理来降低模型复杂度，同时保持预测精度。

Method: 采用一种基于CUR矩阵分解并结合隐式时间积分的方法（implicit TDB-CUR）进行局部即时灵敏度分析，通过降阶建模(Reduced-Order Modeling, ROM)技术自动化筛选重要反应路径，从而发展了骨架反应模型。

Result: 从包含1389种组分的LLNL汽油详细机理中，自动化生成了包含679种和494种组分的两个骨架模型。其中679组分的模型在关键燃烧特性预测上与详细模型误差小于1%，494组分模型的误差小于10%。

Conclusion: 提出的隐式TDB-CUR降阶建模方法能够有效从复杂汽油燃烧详细机理中提取出更小、更高效且准确度较高的骨架机理，显著缩减了计算复杂度并保证了预测精度。

Abstract: Skeletal reaction models are derived for a four-component gasoline surrogate
model via an instantaneous local sensitivity analysis technique. The
sensitivities of the species mass fractions and the temperature with respect to
the reaction rates are estimated by a reduced-order modeling (ROM) methodology.
Termed "implicit time-dependent basis CUR (implicit TDB-CUR)," this methodology
is based on the CUR matrix decomposition and incorporates implicit time
integration for evolving the bases. The estimated sensitivities are
subsequently analyzed to develop skeletal reaction models with a fully
automated procedure. The 1389-species gasoline surrogate model developed at
Lawrence Livermore National Laboratory (LLNL) is selected as the detailed
kinetics model. The skeletal reduction procedure is applied to this model in a
zero-dimensional constant-pressure reactor over a wide range of initial
conditions. The performances of the resulting skeletal models are appraised by
comparison against the results via the LLNL detailed model, and also
predictions via other skeletal models. Two new skeletal models are developed
consisting of 679 and 494 species, respectively. The first is an alternative to
an existing model with the same number of species. The predictions with this
model reproduces the detailed models vital flame results with less than 1%
errors. The errors via the second model are less than 10%.

</details>


### [206] [Bridging Equilibrium and Kinetics Prediction with a Data-Weighted Neural Network Model of Methane Steam Reforming](https://arxiv.org/abs/2506.17224)
*Zofia Pizoń,Shinji Kimijima,Grzegorz Brus*

Main category: cs.CE

TL;DR: 本文提出了一种训练有素的神经网络代理模型，首次兼容并精准预测甲烷蒸汽重整的动力学与平衡过程，为制氢反应模拟与优化提供了高效且实用的新方法。


<details>
  <summary>Details</summary>
Motivation: 氢气作为能源载体的作用日益增强，对高效制氢方法的需求也随之增加。甲烷蒸汽重整是目前最广泛使用的制氢技术，其在燃料电池等应用中的反应器小型化和工艺优化尤为关键。以往的数值模拟模型多只能描述动力学或平衡态中的一种，限制了其实用性。本论文旨在开发一种统一处理两种反应机制的新模型。

Method: 本研究开发了一种代理模型（surrogate model），利用人工神经网络对包含动力学实验、平衡实验插值和理论数据的综合数据集进行训练。为提高训练效果，通过数据增强和对不同类型数据赋予合适权重。采用贝叶斯优化和随机采样方法对模型进行比较，并选取最优模型。

Result: 最优神经网络模型在不同操作参数下对反应后混合物组成进行了高精度预测，均方误差为0.000498，Pearson相关系数为0.927。其能对预测结果连续求导，适用于过程建模和优化。最终结果表明，代理模型可稳健仿真甲烷蒸汽重整的动力学和热力学平衡过程。

Conclusion: 所提出的神经网络代理模型可统一描述甲烷蒸汽重整反应的动力学与平衡两种机制，能够为反应器设计和过程优化提供有力工具。

Abstract: Hydrogen's role is growing as an energy carrier, increasing the need for
efficient production, with methane steam reforming being the most widely used
technique. This process is crucial for applications like fuel cells, where
hydrogen is converted into electricity, pushing for reactor miniaturization and
optimized process control through numerical simulations. Existing models
typically address either kinetic or equilibrium regimes, limiting their
applicability. Here we show a surrogate model capable of unifying both regimes.
An artificial neural network trained on a comprehensive dataset that includes
experimental data from kinetic and equilibrium experiments, interpolated data,
and theoretical data derived from theoretical models for each regime. Data
augmentation and assigning appropriate weights to each data type enhanced
training. After evaluating Bayesian Optimization and Random Sampling, the
optimal model demonstrated high predictive accuracy for the composition of the
post-reaction mixture under varying operating parameters, indicated by a mean
squared error of 0.000498 and strong Pearson correlation coefficients of 0.927.
The network's ability to provide continuous derivatives of its predictions
makes it particularly useful for process modeling and optimization. The results
confirm the surrogate model's robustness for simulating methane steam reforming
in both kinetic and equilibrium regimes, making it a valuable tool for design
and process optimization.

</details>


### [207] [Variational Quantum Latent Encoding for Topology Optimization](https://arxiv.org/abs/2506.17487)
*Alireza Tabarraei*

Main category: cs.CE

TL;DR: 本文提出结合量子和经典潜在编码的变分神经结构拓扑优化方法，无需监督数据，可直接进行物理目标驱动的设计优化。实验表明，量子编码可获得更丰富且优质的结构解，显示出量子计算在工程优化领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 结构拓扑优化是工程设计中的关键问题，传统方法通常得到唯一确定解，缺乏多样性，且依赖大规模数据或监督训练。作者希望通过引入变分框架，结合量子与经典方法，提升解的多样性与物理有效性，同时探索量子计算在结构优化中的潜力。

Method: 提出融合量子与经典潜在编码的变分框架，通过坐标基神经网络解码。先用变分量子电路或高斯分布生成低维潜变量，经过可学习投影映射至高维，再与傅里叶映射空间坐标一同输入神经网络解码，生成高分辨率材料分布。优化直接在潜变量参数上进行，仅依赖有限元分析得到的物理目标，无需预先数据集或监督训练。量子潜变量通过量子电路上的参数化泡利算符期望值得到，具备结构化和纠缠特性。

Result: 数值实验表明，经典与量子编码方法均可产生高质量结构设计。量子编码在若干基准测试上，表现出更优的周向性能和设计多样性。

Conclusion: 该框架展现出量子电路作为物理约束拓扑优化工具的有效性和可扩展性，为近期量子硬件在结构设计中应用提供了有前景的方向。

Abstract: A variational framework for structural topology optimization is developed,
integrating quantum and classical latent encoding strategies within a
coordinate-based neural decoding architecture. In this approach, a
low-dimensional latent vector, generated either by a variational quantum
circuit or sampled from a Gaussian distribution, is mapped to a
higher-dimensional latent space via a learnable projection layer. This enriched
representation is then decoded into a high-resolution material distribution
using a neural network that takes both the latent vector and Fourier-mapped
spatial coordinates as input. The optimization is performed directly on the
latent parameters, guided solely by physics-based objectives such as compliance
minimization and volume constraints evaluated through finite element analysis,
without requiring any precomputed datasets or supervised training. Quantum
latent vectors are constructed from the expectation values of Pauli observables
measured on parameterized quantum circuits, providing a structured and
entangled encoding of information. The classical baseline uses Gaussian-sampled
latent vectors projected in the same manner. The proposed variational
formulation enables the generation of diverse and physically valid topologies
by exploring the latent space through sampling or perturbation, in contrast to
traditional optimization methods that yield a single deterministic solution.
Numerical experiments show that both classical and quantum encodings produce
high-quality structural designs. However, quantum encodings demonstrate
advantages in several benchmark cases in terms of compliance and design
diversity. These results highlight the potential of quantum circuits as an
effective and scalable tool for physics-constrained topology optimization and
suggest promising directions for applying near-term quantum hardware in
structural design.

</details>


### [208] [A predictor-corrector scheme for approximating signed distances using finite element methods](https://arxiv.org/abs/2506.17830)
*Amina El Bachari,Johann Rannou,Vladislav A. Yastrebov,Pierre Kerfriden,Susanne Claus*

Main category: cs.CE

TL;DR: 提出了一种结合线性扩散预测与非线性校正的有限元方法，高效准确地逼近任意维复杂边界下的带符号距离函数，显著提升了处理复杂界面和极端初始条件的能力。


<details>
  <summary>Details</summary>
Motivation: 当前有限元方法在逼近任意复杂边界的带符号距离函数时面临数值收敛性和处理复杂界面形状的挑战。尤其是在初始水平集函数包含任意陡峭或平坦区域时，现有技术常常难以获得准确和鲁棒的重初始化结果。

Method: 提出了一种新型有限元方法，包括线性扩散预测步骤和基于非线性极小化的校正步骤。首先通过求解扩散问题得到初始猜测，然后通过与Eikonal方程相关的非线性极小化进一步校正，提高了收敛性和准确性。

Result: 该方法能有效处理复杂界面以及初始水平集函数的极端区域（陡峭/平坦），并在不同代表性示例（如经典几何体、星域、三维环面）中表现出高准确性、高效率和强鲁棒性，验证其适用于多样化水平集函数的重初始化。

Conclusion: 所提出的有限元方法不仅高效鲁棒地逼近任意边界的带符号距离函数，还克服了现有技术难以处理复杂形状和极端初始条件的局限，具有广泛的实际应用前景。

Abstract: In this article, we introduce a finite element method designed for the robust
computation of approximate signed distance functions to arbitrary boundaries in
two and three dimensions. Our method employs a novel prediction-correction
approach, involving first the solution of a linear diffusion-based prediction
problem, followed by a nonlinear minimization-based correction problem
associated with the Eikonal equation. The prediction step efficiently generates
a suitable initial guess, significantly facilitating convergence of the
nonlinear correction step. A key strength of our approach is its ability to
handle complex interfaces and initial level set functions with arbitrary steep
or flat regions, a notable challenge for existing techniques. Through several
representative examples, including classical geometries and more complex shapes
such as star domains and three-dimensional tori, we demonstrate the accuracy,
efficiency, and robustness of the method, validating its broad applicability
for reinitializing diverse level set functions.

</details>


### [209] [Learning from the Storm: A Multivariate Machine Learning Approach to Predicting Hurricane-Induced Economic Losses](https://arxiv.org/abs/2506.17964)
*Bolin Shen,Eren Erman Ozguven,Yue Zhao,Guang Wang,Yiqun Xie,Yushun Dong*

Main category: cs.CE

TL;DR: 作者提出了一种结合飓风特征、水环境和社会经济三大因素的统一框架，利用机器学习模型在小尺度（ZCTA）上预测和分析飓风造成的经济损失，并定量区分各类影响的重要性，从而为灾害管理和城市决策提供具体指导。


<details>
  <summary>Details</summary>
Motivation: 佛罗里达州频繁遭受飓风侵袭，造成巨大的经济损失。尽管已有研究探讨飓风损失的具体影响因素，但很少有研究提出能整合多因素的统一评估框架。本研究的动机在于开发一个能够全面识别和解析经济损失来源的统一建模方法。

Method: 将飓风损失影响因素分为三个主要部分：（1）飓风的自身特性；（2）与水有关的环境因子；（3）受影响区域的社会经济特征。通过整合多源数据，并将所有变量细化到邮政编码区（ZCTA）层级，利用机器学习模型以保险理赔作为经济损失的指标进行预测。同时，该方法支持系统衡量各类因素对损失的相对重要性分析。

Result: 提出了综合建模框架，能够准确预测经济损失，并量化不同因素对损失的贡献，为灾害减缓、风险评估和城市适应性开发提供了实用决策依据。代码已开源。

Conclusion: 本研究建立了多因素一体化的飓风经济损失预测方法，不仅提升了预测精度，还揭示了不同因素在损失中的作用，为飓风多发及沿海城市提供了科学的应对和规划建议。

Abstract: Florida is particularly vulnerable to hurricanes, which frequently cause
substantial economic losses. While prior studies have explored specific
contributors to hurricane-induced damage, few have developed a unified
framework capable of integrating a broader range of influencing factors to
comprehensively assess the sources of economic loss. In this study, we propose
a comprehensive modeling framework that categorizes contributing factors into
three key components: (1) hurricane characteristics, (2) water-related
environmental factors, and (3) socioeconomic factors of affected areas. By
integrating multi-source data and aggregating all variables at the finer
spatial granularity of the ZIP Code Tabulation Area (ZCTA) level, we employ
machine learning models to predict economic loss, using insurance claims as
indicators of incurred damage. Beyond accurate loss prediction, our approach
facilitates a systematic assessment of the relative importance of each
component, providing practical guidance for disaster mitigation, risk
assessment, and the development of adaptive urban strategies in coastal and
storm-exposed areas. Our code is now available at:
https://github.com/LabRAI/Hurricane-Induced-Economic-Loss-Prediction

</details>


### [210] [A phase field model for hydraulic fracture: Drucker-Prager driving force and a hybrid coupling strategy](https://arxiv.org/abs/2506.18161)
*Y. Navidtehrani,C. Betegón,J. Vallejos,E. Martínez-Pañeda*

Main category: cs.CE

TL;DR: 作者提出了一套通用且灵活的相场水力压裂建模方法，能更好耦合流体与断裂、适用更多材料，案例验证创新有效，代码已开放下载。


<details>
  <summary>Details</summary>
Motivation: 近年来，水力压裂作为石油工程、采矿和地热能等行业的关键过程，急需优化模拟方法。传统方法在流体-断裂耦合及对复杂材料行为建模方面存在局限，因此需要新的理论与数值框架提升建模能力。

Method: 本文提出了一种新颖的理论与计算相场框架，能够普适性地描述流体与相场之间的耦合过程，并对断裂驱动力进行统一建模。具体创新包括：一是提出了混合耦合方法，提升流体-断裂相互作用的精度和灵活性；二是基于Drucker-Prager准则的应变能分解方法，适用于具张拉-压缩非对称断裂行为的材料。通过四个案例验证了该方法的多方面建模能力。

Result: 该方法能够模拟具有非对称张拉-压缩断裂行为的材料（如页岩岩石），并预测包括断层再活化、粘滑行为等地质力学现象。案例展示了渗透率耦合、裂缝行为和多轴工况下的建模能力。开发的代码已免费公开。

Conclusion: 该文提出的相场框架提升了水力压裂建模的普适性、准确性和适用材料范围，为相关行业提供了更强大、灵活的模拟工具。

Abstract: Recent years have seen a significant interest in using phase field approaches
to model hydraulic fracture, so as to optimise a process that is key to
industries such as petroleum engineering, mining and geothermal energy
extraction. Here, we present a novel theoretical and computational phase field
framework to simulate hydraulic fracture. The framework is general and
versatile, in that it allows for improved treatments of the coupling between
fluid flow and the phase field, and encompasses a universal description of the
fracture driving force. Among others, this allows us to bring two innovations
to the phase field hydraulic fracture community: (i) a new hybrid coupling
approach to handle the fracture-fluid flow interplay, offering enhanced
accuracy and flexibility; and (ii) a Drucker-Prager-based strain energy
decomposition, extending the simulation of hydraulic fracture to materials
exhibiting asymmetric tension-compression fracture behaviour (such as shale
rocks) and enabling the prediction of geomechanical phenomena such as fault
reactivation and stick-slip behaviour. Four case studies are addressed to
illustrate these additional modelling capabilities and bring insight into
permeability coupling, cracking behaviour, and multiaxial conditions in
hydraulic fracturing simulations. The codes developed are made freely available
to the community and can be downloaded from {https://mechmat.web.ox.ac.uk/

</details>


### [211] [Measuring Fractal Dimension using Discrete Global Grid Systems](https://arxiv.org/abs/2506.18175)
*Pramit Ghosh*

Main category: cs.CE

TL;DR: 本文将离散全球网格系统(DGGS)应用于地理空间数据的分形维度测算，实验和理论都证明其高精度和实用性，并能克服传统方法的缺陷。


<details>
  <summary>Details</summary>
Motivation: 目前分形维度与离散全球网格系统（DGGS）是两个研究较多但互相独立的领域。文章希望将DGGS应用于分形维度测算，解决地理空间数据分形分析中网格布置随意、大小不统一等实际问题。

Method: 采用DGGS作为对地理空间矢量数据的覆盖集，通过Minkowski-Bouligand方法来测算其分形维度，并在合成数据和实际卫星云图数据集上进行实验。

Result: 在合成数据实验中，所得分形维度结果与理论值误差小于1%；在实际卫星云图上测得分形维度与文献结果一致。提出的方法有效克服了常规网格布置存在的随意性问题，并能处理大尺度地理对象计算时的地球曲率影响。

Conclusion: DGGS作为分形维度计算的覆盖集不仅理论上成立，而且在实践中具有精度高、不受网格布置和尺寸选择影响等优点，适合于地理空间数据的分形分析。文中还讨论了为此任务选择DGGS需具备的性质。

Abstract: This study builds a bridge between two well-studied but distant topics:
fractal dimension and Discrete Global Grid System (DGGS). DGGSs are used as
covering sets for geospatial vector data to calculate the Minkowski-Bouligand
dimension. Using the method on synthetic data yields results within 1% of their
theoretical fractal dimensions. A case study on opaque cloud fields obtained
from satellite images gives fractal dimension in agreement with that available
in the literature. The proposed method alleviates the problems of arbitrary
grid placement and orientation, as well as the progression of cell sizes of the
covering sets for geospatial data. Using DGGSs further ensure that
intersections of the covering sets with the geospatial vector having large
geographic extents are calculated by taking the curvature of the earth into
account. This paper establishes the validity of DGGSs as covering sets
theoretically and discusses desirable properties of DGGSs suitable for this
purpose.

</details>


### [212] [Conservative data-driven finite element formulation](https://arxiv.org/abs/2506.18206)
*Adriana Kuliková,Andrei G. Shvarts,Łukasz Kaczmarczyk,Chris J. Pearce*

Main category: cs.CE

TL;DR: 本文提出一种面向扩散问题的数据驱动混合有限元框架，直接利用实验数据替代本构拟合，弱混合形式更灵活，并能对数据引入的不确定性进行量化，已在核石墨传热问题中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统扩散问题需要对材料本构关系进行拟合建模，这会引入模型偏差，且不能充分利用实验数据。因此亟需一种充分利用数据、避免模型先验偏差的模拟方法。

Method: 采用混合有限元方法，通过弱混合形式保证守恒定律先验满足，同时直接将实验数据用于数值仿真，避免物性参数的显式拟合，并基于该框架进行自适应hp加密与不确定性量化。

Result: 采用该方法后，在核石墨非线性传热的数值测试中验证了该框架的能力，可以量化和预测由数据集变化引起的解的不唯一性和不确定性。

Conclusion: 该论文提出的数据驱动有限元混合方法能够避免物性参数拟合带来的模型偏差，弱混合形式还便于后验误差分析与自适应hp加密，同时可以量化数据不确定性对解的影响。

Abstract: This paper presents a new data-driven finite element framework derived with
mixed finite element formulation. The standard approach to diffusion problems
requires the solution of the mathematical equations that describe both the
conservation law and the constitutive relations, where the latter is
traditionally obtained after fitting experimental data to simplified material
models. To exploit all available information and avoid bias in the material
model, we follow a data-driven approach. While the conservation laws and
boundary conditions are satisfied by means of the finite element method, the
experimental data is used directly in the numerical simulations, avoiding the
need of fitting material model parameters. In order to satisfy the conservation
law a priori in the strong sense, we introduce a mixed finite element
formulation. This relaxes the regularity requirements on approximation spaces
while enforcing continuity of the normal flux component across all of the inner
boundaries. This weaker mixed formulation provides a posteriori error
indicators tailored for this data-driven approach, enabling adaptive
hp-refinement. The relaxed regularity of the approximation spaces makes it
easier to observe how the variation in the datasets results in the
non-uniqueness of the solution, which can be quantified to predict the
uncertainty of the results. The capabilities of the formulation are
demonstrated in an example of the nonlinear heat transfer in nuclear graphite
using synthetically generated material datasets.

</details>


### [213] [Exact Conditional Score-Guided Generative Modeling for Amortized Inference in Uncertainty Quantification](https://arxiv.org/abs/2506.18227)
*Zezhong Zhang,Caroline Tatsuoka,Dongbin Xiu,Guannan Zhang*

Main category: cs.CE

TL;DR: 本文提出一种结合精确条件扩散模型和非可逆神经网络的新方法，实现了高效且可扩展的条件生成采样，在高维和复杂参数估计问题中效果优越。


<details>
  <summary>Details</summary>
Motivation: 现有的条件生成方法存在效率和表达能力的权衡。可逆的流模型效率高但可表达性有限，扩散模型表达性强但推断慢。该工作旨在结合两者的优点，实现快速、高效的条件生成。

Method: 首先，作者通过在高斯混合先验下，解析推导出精确的条件score函数，获得一个无需训练的条件扩散模型，能够通过解反向常微分方程，生成带噪数据。其次，用这些带噪数据训练一个非可逆前馈神经网络，直接从噪声和观测映射到后验采样，实现高效的条件生成。

Result: 所提出的模型能够实现针对高维、多峰后验分布的快速、准确、可扩展的条件采样，非常适合用于不确定性量化等任务。通过数值实验验证了该方法的有效性。

Conclusion: 结合扩散模型和流模型优势的方法可以实现比传统方法更高效和灵活的条件采样，在高维、多峰后验和科学参数估计等应用中表现优异。

Abstract: We propose an efficient framework for amortized conditional inference by
leveraging exact conditional score-guided diffusion models to train a
non-reversible neural network as a conditional generative model. Traditional
normalizing flow methods require reversible architectures, which can limit
their expressiveness and efficiency. Although diffusion models offer greater
flexibility, they often suffer from high computational costs during inference.
To combine the strengths of both approaches, we introduce a two-stage method.
First, we construct a training-free conditional diffusion model by analytically
deriving an exact score function under a Gaussian mixture prior formed from
samples of the underlying joint distribution. This exact conditional score
model allows us to efficiently generate noise-labeled data, consisting of
initial diffusion Gaussian noise and posterior samples conditioned on various
observation values, by solving a reverse-time ordinary differential equation.
Second, we use this noise-labeled data to train a feedforward neural network
that maps noise and observations directly to posterior samples, eliminating the
need for reversibility or iterative sampling at inference time. The resulting
model provides fast, accurate, and scalable conditional sampling for
high-dimensional and multi-modal posterior distributions, making it well-suited
for uncertainty quantification tasks, e.g., parameter estimation of complex
physical systems. We demonstrate the effectiveness of our approach through a
series of numerical experiments.

</details>


### [214] [Neural-operator element method: Efficient and scalable finite element method enabled by reusable neural operators](https://arxiv.org/abs/2506.18427)
*Weihang Ouyang,Yeonjong Shin,Si-Wei Liu,Lu Lu*

Main category: cs.CE

TL;DR: 提出NOEM方法，将有限元与神经算子结合，有效减少网格需求，大幅提高PDE仿真效率并保证精度，适用于多类型复杂问题。


<details>
  <summary>Details</summary>
Motivation: 有限元方法（FEM）虽然有效，但在处理复杂多尺度问题时计算成本高昂。机器学习方法如神经算子能提供数据驱动的PDE求解，但训练成本高、模型复用性低。解决这些问题是本研究的出发点。

Method: 提出神经算子元方法（NOEM），将有限元方法与神经算子结合。在需要大量有限元的子域中，用单个神经算子元（NOE）代替多个有限元。NOE与标准有限元通过变分框架整合，模拟整体解，无需高密度网格。

Result: 通过大量系统的数值实验（处理非线性PDE、多尺度问题、复杂几何和不连续系数场）展示了NOEM在准确性、效率和可扩展性方面的优势。

Conclusion: NOEM兼顾了有限元的物理通用性与神经算子的效率，显著提升了复杂PDE模拟的计算效率和适应性，是解决高性能计算PDE问题的有效方案。

Abstract: The finite element method (FEM) is a well-established numerical method for
solving partial differential equations (PDEs). However, its mesh-based nature
gives rise to substantial computational costs, especially for complex
multiscale simulations. Emerging machine learning-based methods (e.g., neural
operators) provide data-driven solutions to PDEs, yet they present challenges,
including high training cost and low model reusability. Here, we propose the
neural-operator element method (NOEM) by synergistically combining FEM with
operator learning to address these challenges. NOEM leverages neural operators
(NOs) to simulate subdomains where a large number of finite elements would be
required if FEM was used. In each subdomain, an NO is used to build a single
element, namely a neural-operator element (NOE). NOEs are then integrated with
standard finite elements to represent the entire solution through the
variational framework. Thereby, NOEM does not necessitate dense meshing and
offers efficient simulations. We demonstrate the accuracy, efficiency, and
scalability of NOEM by performing extensive and systematic numerical
experiments, including nonlinear PDEs, multiscale problems, PDEs on complex
geometries, and discontinuous coefficient fields.

</details>


### [215] [Virtual failure assessment diagrams for hydrogen transmission pipelines](https://arxiv.org/abs/2506.18554)
*J. Wijnen,J. Parker,M. Gagliano,E. Martínez-Pañeda*

Main category: cs.CE

TL;DR: 作者通过多物理场耦合模拟系统评估氢气管道焊缝缺陷的失效行为，提出虚拟失效评估图，证明标准方法对复杂焊缝微观结构低估了风险，并给出更合理的机制性安全系数。


<details>
  <summary>Details</summary>
Motivation: 随着氢能源的兴起，氢气运输管道的结构安全逐渐成为业界关注的焦点。传统失效评估方法难以准确反映焊接工艺产生的残余应力及热影响区（HAZ）硬脆区域对失效的影响，因此亟需一种更具物理机制的失效预测方法。

Method: 本文将最先进的热-冶金焊接工艺建模与耦合扩散-弹塑性相场断裂模拟相结合，系统分析管道结构中的残余应力分布和局部硬脆区域带来的安全风险。通过模拟不同缺陷尺寸与取向、多种材料与焊接工艺及氢气纯度情景，构建虚拟失效评估图（Virtual Failure Assessment Diagrams，FADs），为服役适应性评估（Fitness-for-service assessment）提供直观工具。

Result: 模拟结果与标准中的FAD方法高度吻合，但揭示出传统标准无法对焊接微观结构异质性进行保守性评估。研究进一步提出了能够量化残余应力及硬脆焊缝区域影响的机制性FAD安全系数，更好保障氢气管道的结构安全。

Conclusion: 本研究提出的耦合模拟方法和虚拟FAD工具为氢气运输管道的失效评估提供了更具物理意义且更具保守性的技术支撑，可为相关标准的修订和工业应用提供理论依据。

Abstract: We combine state-of-the-art thermo-metallurgical welding process modelling
with coupled diffusion-elastic-plastic phase field fracture simulations to
predict the failure states of hydrogen transport pipelines. This enables
quantitatively resolving residual stress states and the role of brittle, hard
regions of the weld such as the heat affected zone (HAZ). Failure pressures can
be efficiently quantified as a function of asset state (existing defects),
materials and weld procedures adopted, and hydrogen purity. Importantly,
simulations spanning numerous relevant conditions (defect size and
orientations) are used to build \emph{Virtual} Failure Assessment Diagrams
(FADs), enabling a straightforward uptake of this mechanistic approach in
fitness-for-service assessment. Model predictions are in very good agreement
with FAD approaches from the standards but show that the latter are not
conservative when resolving the heterogeneous nature of the weld
microstructure. Appropriate, \emph{mechanistic} FAD safety factors are
established that account for the role of residual stresses and hard, brittle
weld regions.

</details>


### [216] [A Physics-Informed Neural Network Framework for Simulating Creep Buckling in Growing Viscoelastic Biological Tissues](https://arxiv.org/abs/2506.18565)
*Zhongya Lin,Jinshuai Bai,Shuang Li,Xindong Chen,Bo Li,Xi-Qiao Feng*

Main category: cs.CE

TL;DR: 本文提出了一种能量驱动的物理信息神经网络（PINN）新方法，有效、自动地模拟黏弹性材料的时变行为（如屈曲、应力松弛和生物组织生长），为传统有限元提供了高效替代，尤其适用于无需预设缺陷的屈曲和复杂组织形貌演化问题。


<details>
  <summary>Details</summary>
Motivation: 传统研究材料的黏弹性行为多依赖于有限元等数值方法，这些方法常常需要显式建模、人工扰动或自定义代码，导致计算复杂度高。而黏弹性行为广泛存在于工程和生物力学中，因此亟需一种更高效、自动化的建模方法。

Method: 提出了一种基于能量函数的物理信息神经网络（PINN）方法，通过最小化系统的势能泛函来保证物理一致性，并采用增量法模拟黏弹性蠕变、应力松弛、屈曲及生物组织生长形变。网络训练过程中系统可自发产生不稳定性，无需人工预置缺陷。

Result: 该PINN框架能够自然捕捉材料的蠕变屈曲、后屈曲行为、生物组织的形态变化。同样可准确预测圆柱结构下均匀膨胀与差异生长导致的屈曲现象。结果表明该框架胜任传统方法需要复杂处理的时间相关材料行为建模任务。

Conclusion: 能量型PINN可作为建模复杂、时变材料行为的灵活且稳健工具，在结构工程、软材料及组织生长研究中具有广阔应用前景。

Abstract: Modeling viscoelastic behavior is crucial in engineering and biomechanics,
where materials undergo time-dependent deformations, including stress
relaxation, creep buckling and biological tissue development. Traditional
numerical methods, like the finite element method, often require explicit
meshing, artificial perturbations or embedding customised programs to capture
these phenomena, adding computational complexity. In this study, we develop an
energy-based physics-informed neural network (PINN) framework using an
incremental approach to model viscoelastic creep, stress relaxation, buckling,
and growth-induced morphogenesis. Physics consistency is ensured by training
neural networks to minimize the systems potential energy functional, implicitly
satisfying equilibrium and constitutive laws. We demonstrate that this
framework can naturally capture creep buckling without pre-imposed
imperfections, leveraging inherent training dynamics to trigger instabilities.
Furthermore, we extend our framework to biological tissue growth and
morphogenesis, predicting both uniform expansion and differential
growth-induced buckling in cylindrical structures. Results show that the
energy-based PINN effectively predicts viscoelastic instabilities,
post-buckling evolution and tissue morphological evolution, offering a
promising alternative to traditional methods. This study demonstrates that PINN
can be a flexible robust tool for modeling complex, time-dependent material
behavior, opening possible applications in structural engineering, soft
materials, and tissue development.

</details>


### [217] [Communication Architecture for Autonomous Power-to-X Platforms: Enhancing Inspection and Operation With Legged Robots and 5G](https://arxiv.org/abs/2506.18572)
*Peter Frank,Falk Dettinger,Daniel Dittler,Pascal Häbig,Nasser Jazdi,Kai Hufendiek,Michael Weyrich*

Main category: cs.CE

TL;DR: 本文提出并实现了一种基于5G的四足机器人系统，能够替代人工对Power to X离岸平台进行远程监控和维护，并对其通信性能进行了评估，证明该方案可行，能显著减轻运维压力。


<details>
  <summary>Details</summary>
Motivation: 离岸平台的检查与维护受到高人力需求和操作环境艰难的制约，成本很高，急需降低人工干预并提高作业效率。

Method: 本文首先对Power to X平台进行分类，并构建通信架构，实现对平台的监控、控制与远程操作。集成四足机器人以自动完成检查与维护任务，并在5G独立组网环境下远程监控、控制和操作机器人，同时记录并评估通信的可用性和时延等指标。

Result: 成功集成了四足机器人，实现了在5G网络下对机器人系统的远程监控、控制及操作；并对通信架构的可用性与时延进行了对比与评估。

Conclusion: 通过搭建基于5G通信架构的机器人系统，可以有效降低离岸平台的人力需求，提高运维自动化水平，对高效安全运行具有促进作用。

Abstract: Inspection and maintenance of offshore platforms are associated with high
costs, primarily due to the significant personnel requirements and challenging
operational conditions. This paper first presents a classification of Power to
X platforms. Building upon this foundation, a communication architecture is
proposed to enable monitoring, control, and teleoperation for a Power to X
platform. To reduce the demand for human labor, a robotic system is integrated
to autonomously perform inspection and maintenance tasks. The implementation
utilizes a quadruped robot. Remote monitoring, control, and teleoperation of
the robot are analyzed within the context of a 5G standalone network. As part
of the evaluation, aspects such as availability and latency are recorded,
compared, and critically assessed.

</details>


### [218] [A Study of Dynamic Stock Relationship Modeling and S&P500 Price Forecasting Based on Differential Graph Transformer](https://arxiv.org/abs/2506.18717)
*Linyue Hu,Qi Wang*

Main category: cs.CE

TL;DR: 提出了一种创新的差分图Transformer用于动态建模和股票价格预测，比传统模型表现更优，能自适应处理股票间变化相关性，结果显示尤其适合波动性较高行业，支持量化投资策略优化。


<details>
  <summary>Details</summary>
Motivation: 由于股票市场具有非线性动态和时间变化的相关性，股票价格预测极具挑战性。传统的静态相关性模型无法有效捕捉不断演变的股票关系，因此需要有新的方法来实现动态关系建模和更准确的价格预测。

Method: 提出了一种差分图神经网络Transformer（Differential Graph Transformer, DGT）框架。该方法将时序性下的图结构变化融入多头自注意力机制，并通过差分图机制自适应地保留高价值连接、抑制噪声。引入因果时序注意力捕获价格序列中的全局和局部依赖关系，并在空间注意力中比较了不同相关性指标和范围作为先验。

Result: 在标准化后的10年S&P 500收盘价（以64日滑窗处理）上，DGT结合空间先验在RMSE、MAE等指标上均优于GRU等基线模型。以Kendall's Tau相关性为全局空间先验时取得最佳表现。聚类分析发现高波动成长股和防御型蓝筹股，其中蓝筹股因相关性更稳定预测误差更低。并且Kendall's Tau、互信息在高波动行业表现尤佳。

Conclusion: 差分图结构与Transformer的结合能有效提升动态关系建模和价格预测能力。实验证实该框架能根据不同股票相关性稳定性和波动性，制定更有针对性的量化策略，并在金融时间序列预测领域具有先进性和应用前景。

Abstract: Stock price prediction is vital for investment decisions and risk management,
yet remains challenging due to markets' nonlinear dynamics and time-varying
inter-stock correlations. Traditional static-correlation models fail to capture
evolving stock relationships. To address this, we propose a Differential Graph
Transformer (DGT) framework for dynamic relationship modeling and price
prediction. Our DGT integrates sequential graph structure changes into
multi-head self-attention via a differential graph mechanism, adaptively
preserving high-value connections while suppressing noise. Causal temporal
attention captures global/local dependencies in price sequences. We further
evaluate correlation metrics (Pearson, Mutual Information, Spearman, Kendall's
Tau) across global/local/dual scopes as spatial-attention priors. Using 10
years of S&P 500 closing prices (z-score normalized; 64-day sliding windows),
DGT with spatial priors outperformed GRU baselines (RMSE: 0.24 vs. 0.87).
Kendall's Tau global matrices yielded optimal results (MAE: 0.11). K-means
clustering revealed "high-volatility growth" and "defensive blue-chip" stocks,
with the latter showing lower errors (RMSE: 0.13) due to stable correlations.
Kendall's Tau and Mutual Information excelled in volatile sectors. This study
innovatively combines differential graph structures with Transformers,
validating dynamic relationship modeling and identifying optimal correlation
metrics/scopes. Clustering analysis supports tailored quantitative strategies.
Our framework advances financial time-series prediction through dynamic
modeling and cross-asset interaction analysis.

</details>


### [219] [Towards Real-time Structural Dynamics Simulation with Graph-based Digital Twin Modelling](https://arxiv.org/abs/2506.18724)
*Jun Zhang,Tong Zhang,Ying Wang*

Main category: cs.CE

TL;DR: 作者提出了基于图的数字孪生模型，通过提升物理可解释性和适应不同结构，显著提升了结构动力模拟的精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 结构动态行为的精确及时模拟对于评估其性能和健康状态至关重要。传统数值方法计算成本高、效率低，而深度学习虽具备前景，但存在物理可解释性差及难以适应多样结构的挑战。

Method: 提出了一种基于图的数字孪生建模(GDTM)框架，利用邻接矩阵显式表达结构节点间的空间关系，从而提升模型的物理可解释性。该方法通过数值及实验两方面进行全面验证。

Result: 框架在各种拓扑结构的动态响应模拟中均获得很高准确度，数值仿真NMSE低于0.005，实验验证低于0.0015。与传统有限元法(FEM)相比，计算效率提升超过80倍。

Conclusion: 基于图的数字孪生动态建模能显著提升结构动力响应模拟的效率和准确性，有助于结构性能评估和健康监测的实际应用。

Abstract: Precise and timely simulation of a structure's dynamic behavior is crucial
for evaluating its performance and assessing its health status. Traditional
numerical methods are often limited by high computational costs and low
efficiency, while deep learning approaches offer a promising alternative.
However, these data-driven methods still face challenges, such as limited
physical interpretability and difficulty in adapting to diverse structural
configurations. To address these issues, this study proposes a graph-based
digital twin modelling (GDTM) framework to simulate structural dynamic
responses across various spatial topologies. In this framework, the adjacency
matrix explicitly represents the spatial relationships between structural
vertices, enhancing the model's physical interpretability. The effectiveness of
the proposed framework was validated through comprehensive numerical and
experimental studies. The results demonstrate that the framework accurately
simulated structural dynamics across different topological configurations, with
Normalized Mean-Squared Error (NMSE) values consistently below 0.005 in
numerical simulations and 0.0015 in experimental validations. Furthermore, the
framework achieved over 80-fold improvements in computational efficiency
compared to traditional finite element methods (FEM). This research promotes
the practical application of graph-based structural dynamics modelling, which
has the potential to significantly advance structural performance evaluation
and health monitoring.

</details>


### [220] [Skeletal Reaction Models for Gasoline Surrogate Combustion](https://arxiv.org/abs/2506.18853)
*Yinmin Liu,Hessam Babaee,Peyman Givi,Daniel Livescu,Arash Nouri*

Main category: cs.CE

TL;DR: 本文提出了一种基于隐式TDB-CUR的自动化汽油动力学骨架化方法，能显著压缩动力学模型规模（最多减少至原来1/3），且保证预测误差极小（<1%），为复杂燃料模拟提供了高效工具。


<details>
  <summary>Details</summary>
Motivation: 现有的汽油替代燃料动力学模型因物种数量庞大（如1389种），导致数值计算极为复杂和低效。为了便于工程应用和数值模拟，需要将复杂详细模型简化成反应物种更少但仍保留动力学行为的骨架模型。目前，自动化和高效的骨架模型构建方法依然是动力学研究的难点。

Method: 本文提出了一种基于隐式时间相关基CUR分解（implicit TDB-CUR）的降阶方法，通过对反应速率的局部瞬时灵敏度分析，自动构建骨架反应动力学模型。该方法结合CUR矩阵分解与隐式时间积分，通过分析物种和温度对反应速率的灵敏度，筛选重要反应通道，自动进行骨架化处理。

Result: 将所提出方法应用于LLNL的1389物种汽油代理模型，并在零维定压反应器中进行广泛条件测试，最终获得两个分别包含679个与494个物种的骨架模型。其中679物种模型与已有同规模骨架模型精度相当，关键火焰参数预测误差低于1%；494物种模型误差也控制在10%以内。

Conclusion: 提出的implicit TDB-CUR方法可以自动且高效地对大型燃料动力学机制进行骨架化，在显著减少物种数量的同时保证了动力学预测准确性。该方法为复杂燃料化学模型的工程应用与数值模拟提供了新思路。

Abstract: Skeletal reaction models are derived for a four-component gasoline surrogate
model via an instantaneous local sensitivity analysis technique. The
sensitivities of the species mass fractions and the temperature with respect to
the reaction rates are estimated by a reduced-order modeling (ROM) methodology.
Termed "implicit time-dependent basis CUR (implicit TDB-CUR)," this methodology
is based on the CUR matrix decomposition and incorporates implicit time
integration for evolving the bases. The estimated sensitivities are
subsequently analyzed to develop skeletal reaction models with a fully
automated procedure. The 1389-species gasoline surrogate model developed at
Lawrence Livermore National Laboratory (LLNL) is selected as the detailed
kinetics model. The skeletal reduction procedure is applied to this model in a
zero-dimensional constant-pressure reactor over a wide range of initial
conditions. The performances of the resulting skeletal models are appraised by
comparison against the results via the LLNL detailed model, and also
predictions via other skeletal models. Two new skeletal models are developed
consisting of 679 and 494 species, respectively. The first is an alternative to
an existing model with the same number of species. The predictions with this
model reproduces the detailed models vital flame results with less than 1%
errors. The errors via the second model are less than 10%.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [221] [The California Report on Frontier AI Policy](https://arxiv.org/abs/2506.17303)
*Rishi Bommasani,Scott R. Singer,Ruth E. Appel,Sarah Cen,A. Feder Cooper,Elena Cryst,Lindsey A. Gailmard,Ian Klaus,Meredith M. Lee,Inioluwa Deborah Raji,Anka Reuel,Drew Spence,Alexander Wan,Angelina Wang,Daniel Zhang,Daniel E. Ho,Percy Liang,Dawn Song,Joseph E. Gonzalez,Jonathan Zittrain,Jennifer Tour Chayes,Mariano-Florentino Cuellar,Li Fei-Fei*

Main category: cs.CY

TL;DR: 本报告分析了前沿AI在带来巨大机遇的同时所伴随的政策挑战，通过多学科研究提出了‘信任但需验证’的政策原则，帮助加州平衡AI创新和风险治理。


<details>
  <summary>Details</summary>
Motivation: 面对前沿AI带来的历史性机遇与复杂政策挑战，特别是其对科学、经济和社会的深远影响，加州作为全球AI创新中心需要制定既支持创新又能有效防控风险的政策框架。

Method: 报告采用了广泛证据，包括实证研究、历史分析、建模与模拟，基于多学科的方法建立研究框架并推导政策原则。

Result: 报告为加州制定和实施前沿AI政策提供了理论框架与核心原则，强调创新与风险降低策略需并重。

Conclusion: 本报告提出了一套以“信任但需验证”为核心的政策原则，指导加州如何在推动前沿AI发展的同时，妥善评估与治理其风险。

Abstract: The innovations emerging at the frontier of artificial intelligence (AI) are
poised to create historic opportunities for humanity but also raise complex
policy challenges. Continued progress in frontier AI carries the potential for
profound advances in scientific discovery, economic productivity, and broader
social well-being. As the epicenter of global AI innovation, California has a
unique opportunity to continue supporting developments in frontier AI while
addressing substantial risks that could have far reaching consequences for the
state and beyond. This report leverages broad evidence, including empirical
research, historical analysis, and modeling and simulations, to provide a
framework for policymaking on the frontier of AI development. Building on this
multidisciplinary approach, this report derives policy principles that can
inform how California approaches the use, assessment, and governance of
frontier AI: principles rooted in an ethos of trust but verify. This approach
takes into account the importance of innovation while establishing appropriate
strategies to reduce material risks.

</details>


### [222] [Can Large Language Models Be Trusted Paper Reviewers? A Feasibility Study](https://arxiv.org/abs/2506.17311)
*Chuanlei Li,Xu Hu,Minghui Xu,Kun Li,Yue Zhang,Xiuzhen Cheng*

Main category: cs.CY

TL;DR: 大语言模型可以降低论文评审的时间和成本，但在独立判断和准确性上仍有明显不足，适合作为人工辅助工具，而不能完全取代人类评审员。


<details>
  <summary>Details</summary>
Motivation: 学术论文评审通常需要大量时间、专业知识和人力资源，研究动机是探索如何通过自动化手段提升评审效率、降低成本。

Method: 提出了一套自动化论文评审系统，将RAG（检索增强生成）、AutoGen多智能体系统和Chain-of-Thought提示方法整合在一起，支持格式检查、标准化评价、意见生成和打分等任务。

Result: 对290篇WASA 2024会议投稿进行实验，证明LLM基础的评审可大幅减少评审时间（平均2.48小时）与成本（平均104.28美元），但与实际录用文章的相似度较低（平均38.6%），暴露出幻觉、判断独立性不足和检索偏好等问题。

Conclusion: LLM可用作辅助工具帮助人类评审员，但现阶段不宜完全替代人工评审。

Abstract: Academic paper review typically requires substantial time, expertise, and
human resources. Large Language Models (LLMs) present a promising method for
automating the review process due to their extensive training data, broad
knowledge base, and relatively low usage cost. This work explores the
feasibility of using LLMs for academic paper review by proposing an automated
review system. The system integrates Retrieval Augmented Generation (RAG), the
AutoGen multi-agent system, and Chain-of-Thought prompting to support tasks
such as format checking, standardized evaluation, comment generation, and
scoring. Experiments conducted on 290 submissions from the WASA 2024 conference
using GPT-4o show that LLM-based review significantly reduces review time
(average 2.48 hours) and cost (average \$104.28 USD). However, the similarity
between LLM-selected papers and actual accepted papers remains low (average
38.6\%), indicating issues such as hallucination, lack of independent judgment,
and retrieval preferences. Therefore, it is recommended to use LLMs as
assistive tools to support human reviewers, rather than to replace them.

</details>


### [223] [Using Machine Learning in Analyzing Air Quality Discrepancies of Environmental Impact](https://arxiv.org/abs/2506.17319)
*Shuangbao Paul Wang,Lucas Yang,Rahouane Chouchane,Jin Guo,Michael Bailey*

Main category: cs.CY

TL;DR: 本研究利用机器学习和多源数据，揭示了巴尔的摩有色人种及低收入群体因历史政策遗留，面对更高空气污染的不公现实。


<details>
  <summary>Details</summary>
Motivation: 研究巴尔的摩市空气污染与历史上有偏见的保险风险评估方法、居民人口结构以及人口普查中的空气污染物（NO2和PM2.5）浓度之间的关系。探讨长期政策对居民，特别是有色人种生活质量的影响。

Method: 结合机器学习和软件工程方法，利用三个主要数据源（住房贷款公司的有偏估算方法、巴尔的摩人口统计数据、NO2和PM2.5浓度的普查数据）对城市空气污染进行建模和分析。

Result: 发现空气污染水平与有偏见的保险风险评估方法存在明显联系。高收入和低收入居住区之间的NO2水平存在巨大差异，不同种族间空气污染暴露水平同样不均。

Conclusion: 历史有偏见的政策和风险估算方法，导致了今日巴尔的摩市不同种族、收入阶层在空气污染暴露上的严重不平等问题，这些政策持续影响居民的生活质量，特别是有色人种群体。

Abstract: In this study, we apply machine learning and software engineering in
analyzing air pollution levels in City of Baltimore. The data model was fed
with three primary data sources: 1) a biased method of estimating insurance
risk used by homeowners loan corporation, 2) demographics of Baltimore
residents, and 3) census data estimate of NO2 and PM2.5 concentrations. The
dataset covers 650,643 Baltimore residents in 44.7 million residents in 202
major cities in US. The results show that air pollution levels have a clear
association with the biased insurance estimating method. Great disparities
present in NO2 level between more desirable and low income blocks. Similar
disparities exist in air pollution level between residents' ethnicity. As
Baltimore population consists of a greater proportion of people of color, the
finding reveals how decades old policies has continued to discriminate and
affect quality of life of Baltimore citizens today.

</details>


### [224] [MAARTA:Multi-Agentic Adaptive Radiology Teaching Assistant](https://arxiv.org/abs/2506.17320)
*Akash Awasthi,Brandon V. Chang,Anh M. Vu,Ngan Le,Rishi Agrawal,Zhigang Deng,Carol Wu,Hien Van Nguyen*

Main category: cs.CY

TL;DR: 提出MAARTA系统，通过分析视线和诊断报告，为放射科学生提供个性化的错误分析和改正建议，提升了AI在医学教育中的实用性和教学效果。


<details>
  <summary>Details</summary>
Motivation: 放射科学生由于缺乏专家指导时间，难以培养知觉专业能力，导致视觉搜索和诊断解释出错。目前的AI主要关注诊断准确性，无法解释错误发生的原因和过程。

Method: 提出了MAARTA（多智能体自适应放射学助教）系统，通过分析学员的视线轨迹和报告，比较专家与学生的行为，利用结构化图谱检测遗漏和错误，并由专门的智能体分析和反馈。系统可根据错误复杂性动态选择适当的智能体，分步引导学生理解和改正错误。

Result: MAARTA能够有效发现学生在影像判读中的具体知觉错误，通过个性化反馈促进其诊断推理能力提升，从而推动基于AI的放射科教育发展。

Conclusion: MAARTA弥补了现有AI在放射学教育中只关注结果不解释过程的不足，通过结构化且个性化的差错反馈，引导学生改进，提高了放射学生的培养效率。

Abstract: Radiology students often struggle to develop perceptual expertise due to
limited expert mentorship time, leading to errors in visual search and
diagnostic interpretation. These perceptual errors, such as missed fixations,
short dwell times, or misinterpretations, are not adequately addressed by
current AI systems, which focus on diagnostic accuracy but fail to explain how
and why errors occur. To address this gap, we introduce MAARTA (Multi-Agentic
Adaptive Radiology Teaching Assistant), a multi-agent framework that analyzes
gaze patterns and radiology reports to provide personalized feedback. Unlike
single-agent models, MAARTA dynamically selects agents based on error
complexity, enabling adaptive and efficient reasoning. By comparing expert and
student gaze behavior through structured graphs, the system identifies missed
findings and assigns Perceptual Error Teacher agents to analyze discrepancies.
MAARTA then uses step-by-step prompting to help students understand their
errors and improve diagnostic reasoning, advancing AI-driven radiology
education.

</details>


### [225] [AI is the Strategy: From Agentic AI to Autonomous Business Models onto Strategy in the Age of AI](https://arxiv.org/abs/2506.17339)
*René Bohnsack,Mickie de Wet*

Main category: cs.CY

TL;DR: 本研究提出自主型商业模式（ABMs），认为代理性AI将成为企业战略和运营的核心。从AI增强向AI自主商业模式转型，将重构企业竞争和管理逻辑。


<details>
  <summary>Details</summary>
Motivation: 当前大多数企业仍以人为主导或AI增强为主，但随着代理性AI的发展，AI不仅是辅助工具，而可以成为执行企业价值创造、传递与获取的核心。因此有必要重新探讨AI主导的商业模式。

Method: 本文提出自主型商业模式（ABMs）概念，通过两个案例——以autonomy by design为目标的以色列初创公司getswam.ai，以及假设的AI主导瑞安航空改造案例——说明从AI增强到AI自主商业模式的演变过程。

Result: ABMs能够通过AI自主执行、持续适应和逐步卸载人类决策，重塑企业竞争优势，引发“合成竞争”（synthetic competition），带来决策速度和规模的巨大变化，对战略、组织设计和治理产生深远影响。

Conclusion: 随着代理性AI日益主导企业运作，我们需要重新理解和设计企业战略管理，因为企业将越来越多实现自动化自运行。

Abstract: This article develops the concept of Autonomous Business Models (ABMs) as a
distinct managerial and strategic logic in the age of agentic AI. While most
firms still operate within human-driven or AI-augmented models, we argue that
we are now entering a phase where agentic AI (systems capable of initiating,
coordinating, and adapting actions autonomously) can increasingly execute the
core mechanisms of value creation, delivery, and capture. This shift reframes
AI not as a tool to support strategy, but as the strategy itself. Using two
illustrative cases, getswan.ai, an Israeli startup pursuing autonomy by design,
and a hypothetical reconfiguration of Ryanair as an AI-driven incumbent, we
depict the evolution from augmented to autonomous business models. We show how
ABMs reshape competitive advantage through agentic execution, continuous
adaptation, and the gradual offloading of human decision-making. This
transition introduces new forms of competition between AI-led firms, which we
term synthetic competition, where strategic interactions occur at rapid,
machine-level speed and scale. It also challenges foundational assumptions in
strategy, organizational design, and governance. By positioning agentic AI as
the central actor in business model execution, the article invites us to
rethink strategic management in an era where firms increasingly run themselves.

</details>


### [226] [Distinguishing Predictive and Generative AI in Regulation](https://arxiv.org/abs/2506.17347)
*Jennifer Wang,Andrew Selbst,Solon Barocas,Suresh Venkatasubramanian*

Main category: cs.CY

TL;DR: 生成式AI与预测式AI有本质区别，现有监管工具难以完全适用。本文分析了生成式AI的四大特性及带来的挑战，提出三项政策建议，助力制定更有效的AI监管政策。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的出现，现有的AI监管工具基于对预测式AI的假设，已经难以涵盖新型AI带来的独特挑战，亟需重新审视和调整政策响应。

Method: 本文通过分析生成式AI的四个关键特征，探讨其对政策制定带来的新需求和挑战，并提出针对性的改进建议。

Result: 研究明确了生成式AI在通用性与适应性、评估难度、新的法律问题以及价值链分布结构方面与预测式AI的根本不同，强调现有监管政策部分失效，需要新的政策工具，并给出三项具体建议来改进监管目标识别和治理手段。

Conclusion: 为有效治理生成式AI，政策制定者应区分两类AI的核心差异，借鉴以往政策中仍有效的部分，同时针对生成式AI独有的风险制定新政策。本文为监管目标与生态系统约束的识别、利用提供了方向。

Abstract: Over the past decade, policymakers have developed a set of regulatory tools
to ensure AI development aligns with key societal goals. Many of these tools
were initially developed in response to concerns with predictive AI and
therefore encode certain assumptions about the nature of AI systems and the
utility of certain regulatory approaches. With the advent of generative AI,
however, some of these assumptions no longer hold, even as policymakers attempt
to maintain a single regulatory target that covers both types of AI.
  In this paper, we identify four distinct aspects of generative AI that call
for meaningfully different policy responses. These are the generality and
adaptability of generative AI that make it a poor regulatory target, the
difficulty of designing effective evaluations, new legal concerns that change
the ecosystem of stakeholders and sources of expertise, and the distributed
structure of the generative AI value chain.
  In light of these distinctions, policymakers will need to evaluate where the
past decade of policy work remains relevant and where new policies, designed to
address the unique risks posed by generative AI, are necessary. We outline
three recommendations for policymakers to more effectively identify regulatory
targets and leverage constraints across the broader ecosystem to govern
generative AI.

</details>


### [227] [Evaluating the Impact of Lean and Green Practices on Operational Performance: A Real Data-Driven Simulation Case Study](https://arxiv.org/abs/2506.17354)
*Farah Altarazi*

Main category: cs.CY

TL;DR: 本研究提出以Lean和Green理念结合OEEE新指标评估与改进企业生产绩效。仿真结果显示，相关措施能有效缩短生产周期和提升可持续表现，建议聚焦相关改进以增强企业竞争优势。


<details>
  <summary>Details</summary>
Motivation: 全球市场驱动和客户需求持续变化，以盈利和效率为主的企业目标已不足以应对竞争，可持续表现成为新的竞争优势，促使企业整合传统目标与绿色创新。

Method: 应用系统分析与建模，结合仿真模拟和能耗价值流图，计算OEEE值衡量质量、可用性、生产力及可持续性。提出并模拟两种改进方案，评估其对OEEE和生产周期的影响。

Result: 现状下生产周期为329.1分钟，OEEE为13.1%，环节存在较大改进空间。改进一（合并、重排检测工位）后，周期降至158.23分钟，OEEE升至35%；改进二（使用紫外线烘干）后，周期降至292分钟，OEEE升至24%。两种方案均提升了绩效与可持续性。

Conclusion: 采用Lean和Green方法结合整体环境设备效能（OEEE）指标，有助于企业提升生产绩效和可持续能力。针对现状的改进措施能明显提高OEEE值和缩短生产周期，建议将管理和技术创新努力集中于绩效与可持续性提升。

Abstract: Global market-driven forces and customer needs are continuously changing. In
the past, profitability and efficiency were the primary objectives of most
companies. However, in recent decades, sustainable performance has emerged as a
new competitive advantage. Companies have been compelled to adopt a concept
that combines these evolving global interests with traditional goals resulting
in the innovation of the lean and green approach.
  In this study, a research methodology that includes system analysis and
modeling procedures to apply the lean and green concept, combined with a new
evaluation metric, the Overall Environmental Equipment Effectiveness (OEEE) was
used to investigate the effects of adopting lean and green practices on overall
performance.
  A simulation model and energy value stream mapping were implemented, and the
OEEE value was calculated to assess the current performance in terms of
quality, availability, productivity, and sustainability. The current state
production lead time was 329.1 minutes per batch, and the OEEE value was 13.1%.
This result indicates existing issues in performance and sustainability,
suggesting that improvement efforts should focus on enhancing these two aspects
to increase the overall OEEE value.
  Several improvement scenarios were proposed, including combining and
rearranging the inspection workstations as the first scenario, and using UV
lighting for drying purposes at the framing workstation as the second. After
applying these improvements, both scenarios showed increased OEEE values and
reduced lead times compared to the current state. In the first scenario, the
lead time decreased to 158.23 minutes, and the OEEE increased to 35%. In the
second scenario, the lead time was reduced to 292 minutes, with the OEEE
increasing to 24%.

</details>


### [228] [PasteTrace: A Single Source Plagiarism Detection Tool For Introductory Programming Courses](https://arxiv.org/abs/2506.17355)
*Jesse McDonald,Scott Robertson,Anthony Peruma*

Main category: cs.CY

TL;DR: 本文提出并验证了PasteTrace：一款可在IDE内实时检测初学者编程课程抄袭的新工具，效果优于传统检测方法。


<details>
  <summary>Details</summary>
Motivation: 初学者在计算机科学入门课程中，因缺乏编程经验，常对课程内容感到吃力，并可能因难以理解导致学术不端行为（如抄袭）。现有抄袭检测工具不完全适合入门编程教学情境。

Method: 提出了PasteTrace，这是一个专为编程入门课程设计的开源抄袭检测工具，它能在IDE内实时跟踪学生的编程活动，以发现潜在的抄袭行为。作者还将PasteTrace与现有工具进行了对比评估。

Result: PasteTrace能提供学生行为的洞见，并能检测多种抄袭类型。实验结果显示，该工具在两门入门课程中优于现有知名工具。

Conclusion: PasteTrace为初级编程课程提供了更有效的抄袭检测方式，有助于维护学术诚信并帮助教师理解学生学习行为。

Abstract: Introductory Computer Science classes are important for laying the foundation
for advanced programming courses. However, students without prior programming
experience may find these courses challenging, leading to difficulties in
understanding concepts and engaging in academic dishonesty such as plagiarism.
While there exists plagiarism detection techniques and tools, not all of them
are suitable for academic settings, especially in introductory programming
courses. This paper introduces PasteTrace, a novel open-source plagiarism
detection tool designed specifically for introductory programming courses.
Unlike traditional methods, PasteTrace operates within an Integrated
Development Environment that tracks the student's coding activities in
real-time for evidence of plagiarism. Our evaluation of PasteTrace in two
introductory programming courses demonstrates the tool's ability to provide
insights into student behavior and detect various forms of plagiarism,
outperforming an existing well-established tool.
  A video demonstration of PasteTrace and its source code, and case study data
are made available at https://doi.org/10.6084/m9.figshare.27115852

</details>


### [229] [Automatic Large Language Models Creation of Interactive Learning Lessons](https://arxiv.org/abs/2506.17356)
*Jionghao Lin,Jiarui Rao,Yiyang Zhao,Yuting Wang,Ashish Gurung,Amanda Barany,Jaclyn Ocumpaugh,Ryan S. Baker,Kenneth R. Koedinger*

Main category: cs.CY

TL;DR: 本文提出并验证了一种基于GPT-4o和任务分解的课程自动生成系统，可有效产出用于导师培训的高质量课程。


<details>
  <summary>Details</summary>
Motivation: 提升初学者线上数学教学能力，自动化生成互动场景式培训课程以降低成本、提高效率。

Method: 采用基于GPT-4o的检索增强生成（RAG）方法，通过任务分解（task decomposition）的提示工程，自动生成结构化的导师培训课程，并由两位人工评审结合定量和定性指标进行评价。

Result: 采用任务分解策略生成的课程质量优于单步生成；课程结构合理，节省准备时间，但存在反馈内容泛化和局部教学环节不清晰的不足。

Conclusion: 任务分解和人机协作生成的课程在导师培训中具有较大应用潜力，未来应进一步优化反馈和细节清晰度。

Abstract: We explore the automatic generation of interactive, scenario-based lessons
designed to train novice human tutors who teach middle school mathematics
online. Employing prompt engineering through a Retrieval-Augmented Generation
approach with GPT-4o, we developed a system capable of creating structured
tutor training lessons. Our study generated lessons in English for three key
topics: Encouraging Students' Independence, Encouraging Help-Seeking Behavior,
and Turning on Cameras, using a task decomposition prompting strategy that
breaks lesson generation into sub-tasks. The generated lessons were evaluated
by two human evaluators, who provided both quantitative and qualitative
evaluations using a comprehensive rubric informed by lesson design research.
Results demonstrate that the task decomposition strategy led to higher-rated
lessons compared to single-step generation. Human evaluators identified several
strengths in the LLM-generated lessons, including well-structured content and
time-saving potential, while also noting limitations such as generic feedback
and a lack of clarity in some instructional sections. These findings underscore
the potential of hybrid human-AI approaches for generating effective lessons in
tutor training.

</details>


### [230] [A Large-Scale Real-World Evaluation of LLM-Based Virtual Teaching Assistant](https://arxiv.org/abs/2506.17363)
*Sunjun Kweon,Sooyohn Nam,Hyunseung Lim,Hwajung Hong,Edward Choi*

Main category: cs.CY

TL;DR: 作者在AI课程中部署了一个基于大语言模型的虚拟助教，通过学生调查和交互数据，系统评估了其在现实课堂中的作用、优势与挑战，并开源了该系统。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM驱动的虚拟助教有望通过即时反馈和多轮互动提升学生学习效果，但其在真实课堂的效果和接受度尚缺乏实证数据，实际影响不明，因此需要在现实场景下进行系统性评估。

Method: 在477名研究生参加的AI编程课程中部署基于大模型的虚拟助教，并在课程不同阶段进行三轮学生问卷调查，同时分析3869组学生与虚拟助教的交互记录，并与传统学生-人工教师的交互进行对比分析。

Result: 学生对VTA表现的看法会随时间变化，分析显示VTA能够覆盖多种提问类型并展现独特的参与模式。但与人类教师相比仍有不足，实际应用中存在型关键挑战。同时开源了VTA系统。

Conclusion: 本文通过大规模实证研究和交互分析，评估了LLM驱动的虚拟助教在真实课堂中的可行性，并指出了其广泛应用所面临的关键挑战。作者还开源了虚拟助教系统，以促进未来AI教育的发展。

Abstract: Virtual Teaching Assistants (VTAs) powered by Large Language Models (LLMs)
have the potential to enhance student learning by providing instant feedback
and facilitating multi-turn interactions. However, empirical studies on their
effectiveness and acceptance in real-world classrooms are limited, leaving
their practical impact uncertain. In this study, we develop an LLM-based VTA
and deploy it in an introductory AI programming course with 477 graduate
students. To assess how student perceptions of the VTA's performance evolve
over time, we conduct three rounds of comprehensive surveys at different stages
of the course. Additionally, we analyze 3,869 student--VTA interaction pairs to
identify common question types and engagement patterns. We then compare these
interactions with traditional student--human instructor interactions to
evaluate the VTA's role in the learning process. Through a large-scale
empirical study and interaction analysis, we assess the feasibility of
deploying VTAs in real-world classrooms and identify key challenges for broader
adoption. Finally, we release the source code of our VTA system, fostering
future advancements in AI-driven education:
\texttt{https://github.com/sean0042/VTA}.

</details>


### [231] [AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning](https://arxiv.org/abs/2506.17364)
*Alvaro Becerra,Roberto Daza,Ruth Cobos,Aythami Morales,Mutlu Cukurova,Julian Fierrez*

Main category: cs.CY

TL;DR: 本研究提出基于多模态生物识别手段监测在线学习过程中的分心行为，融合多种生理与行为信号，检测手机使用分心的准确率提升至91%，为在线教育平台的实时监控与干预提供了新方案。


<details>
  <summary>Details</summary>
Motivation: 在需要持续专注的任务（如在线学习）中，智能手机使用导致的分心是一个重要问题。传统学习平台缺乏对学习者行为的精细数据分析，因此需要新的方法来监测并理解学习者的注意力状态。

Method: 提出了一种基于AI的方法，结合生理信号（如脑电和心跳）及头部姿态数据，检测用户在电脑端学习时是否使用手机。通过多模态学习分析与生物传感器采集数据，设计并评估单模态与多模态的识别模型。

Result: 单一生物识别信号（如脑波、心率）检测手机使用的准确率有限；单独使用头部姿态能够达到87%的准确率；将所有信号融合的多模态模型准确率高达91%。

Conclusion: 多模态生物识别技术能够更有效地检测学习期间的分心行为，尤其是在智能手机使用方面。实际部署时还需考虑模型的实时性及应用限制。

Abstract: This work investigates the use of multimodal biometrics to detect
distractions caused by smartphone use during tasks that require sustained
attention, with a focus on computer-based online learning. Although the methods
are applicable to various domains, such as autonomous driving, we concentrate
on the challenges learners face in maintaining engagement amid internal (e.g.,
motivation), system-related (e.g., course design) and contextual (e.g.,
smartphone use) factors. Traditional learning platforms often lack detailed
behavioral data, but Multimodal Learning Analytics (MMLA) and biosensors
provide new insights into learner attention. We propose an AI-based approach
that leverages physiological signals and head pose data to detect phone use.
Our results show that single biometric signals, such as brain waves or heart
rate, offer limited accuracy, while head pose alone achieves 87%. A multimodal
model combining all signals reaches 91% accuracy, highlighting the benefits of
integration. We conclude by discussing the implications and limitations of
deploying these models for real-time support in online learning environments.

</details>


### [232] [AI based Content Creation and Product Recommendation Applications in E-commerce: An Ethical overview](https://arxiv.org/abs/2506.17370)
*Aditi Madhusudan Jain,Ayush Jain*

Main category: cs.CY

TL;DR: 本文分析了电商中AI内容生成与推荐的伦理风险，提出了消除算法偏见和强化伦理标准的措施，为行业提供了具体的合规操作建议。


<details>
  <summary>Details</summary>
Motivation: 随着AI在电商的快速普及，对内容生成及推荐的高效个性化带来好处，但也引发了如数据隐私、算法偏见和用户自主权等严重伦理问题，迫切需要更完善的伦理标准。

Method: 分析并总结AI用于电商内容和推荐系统的伦理风险，归纳企业应采纳的最佳实践，如算法定期审计、多元化训练数据和引入公平性指标。同时探讨了保障数据隐私和消费者自主权的符合伦理的框架。

Result: 归纳了AI在电商领域的主要伦理风险，并提出了减缓偏见、保障公平和隐私的实践性建议，对增强AI系统的包容性和伦理性具有指导作用。

Conclusion: 提出应通过多项举措来提升AI在电商内容生成和产品推荐中的公平性、透明度和合规性，并为行业提供了实际的道德规范和建议。

Abstract: As e-commerce rapidly integrates artificial intelligence for content creation
and product recommendations, these technologies offer significant benefits in
personalization and efficiency. AI-driven systems automate product
descriptions, generate dynamic advertisements, and deliver tailored
recommendations based on consumer behavior, as seen in major platforms like
Amazon and Shopify. However, the widespread use of AI in e-commerce raises
crucial ethical challenges, particularly around data privacy, algorithmic bias,
and consumer autonomy. Bias -- whether cultural, gender-based, or socioeconomic
-- can be inadvertently embedded in AI models, leading to inequitable product
recommendations and reinforcing harmful stereotypes. This paper examines the
ethical implications of AI-driven content creation and product recommendations,
emphasizing the need for frameworks to ensure fairness, transparency, and need
for more established and robust ethical standards. We propose actionable best
practices to remove bias and ensure inclusivity, such as conducting regular
audits of algorithms, diversifying training data, and incorporating fairness
metrics into AI models. Additionally, we discuss frameworks for ethical
conformance that focus on safeguarding consumer data privacy, promoting
transparency in decision-making processes, and enhancing consumer autonomy. By
addressing these issues, we provide guidelines for responsibly utilizing AI in
e-commerce applications for content creation and product recommendations,
ensuring that these technologies are both effective and ethically sound.

</details>


### [233] [Multimodal Political Bias Identification and Neutralization](https://arxiv.org/abs/2506.17372)
*Cedric Bernard,Xavier Pleimling,Amun Kharel,Chase Vickery*

Main category: cs.CY

TL;DR: 本文提出了一个综合文本与图像偏见检测与去除的模型，初步实验效果良好，但还需提高训练力度与资源投入，人工评估确保新内容语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有关于政治回音室的问题要求对政治文章中的主观偏见和情绪化语言进行检测与去除，但以往的研究只关注文本部分，忽视了图像部分，而图像同样是重要的信息传递媒介。

Method: 提出了一个结合文本与图像偏见的模型，包括四个步骤：1）图像文本对齐（通过CLIP对模型偏见进行语义对齐）；2）图像偏见评分（利用ViT分类器为图像打分）；3）文本去偏见（用BERT检测并中和偏见词句）；4）最终去偏见（用低偏见的文本及图像替换原内容）。还设计了人工评估，新生成的文本和图像的语义一致性。

Result: 文本去偏见方法可以识别大量潜在的偏见词和偏见短语，ViT图像偏见模型训练效果也较好，语义对齐模块效率高。但实现更好结果还需更多训练时间与资源。

Conclusion: 本文联合利用文本和图像信息进行去偏见，方法效果初步验证有效，未来需进一步训练和资源投入提升性能；人工评估确保生成内容语义一致性。

Abstract: Due to the presence of political echo chambers, it becomes imperative to
detect and remove subjective bias and emotionally charged language from both
the text and images of political articles. However, prior work has focused on
solely the text portion of the bias rather than both the text and image
portions. This is a problem because the images are just as powerful of a medium
to communicate information as text is. To that end, we present a model that
leverages both text and image bias which consists of four different steps.
Image Text Alignment focuses on semantically aligning images based on their
bias through CLIP models. Image Bias Scoring determines the appropriate bias
score of images via a ViT classifier. Text De-Biasing focuses on detecting
biased words and phrases and neutralizing them through BERT models. These three
steps all culminate to the final step of debiasing, which replaces the text and
the image with neutralized or reduced counterparts, which for images is done by
comparing the bias scores. The results so far indicate that this approach is
promising, with the text debiasing strategy being able to identify many
potential biased words and phrases, and the ViT model showcasing effective
training. The semantic alignment model also is efficient. However, more time,
particularly in training, and resources are needed to obtain better results. A
human evaluation portion was also proposed to ensure semantic consistency of
the newly generated text and images.

</details>


### [234] [A Grassroots Network and Community Roadmap for Interconnected Autonomous Science Laboratories for Accelerated Discovery](https://arxiv.org/abs/2506.17510)
*Rafael Ferreira da Silva,Milad Abolhasani,Dionysios A. Antonopoulos,Laura Biven,Ryan Coffee,Ian T. Foster,Leslie Hamilton,Shantenu Jha,Theresa Mayer,Benjamin Mintz,Robert G. Moore,Salahudin Nimer,Noah Paulson,Woong Shin,Frederic Suter,Mitra Taheri,Michela Taufer,Newell R. Washburn*

Main category: cs.CY

TL;DR: AISLE打破自主实验室孤岛，实现跨机构协作与资源整合，以AI驱动科学研究创新并提升教育，助力多个科学领域的重大突破。


<details>
  <summary>Details</summary>
Motivation: 现有的AI自主实验室多为孤立系统，缺乏跨机构协作，制约了科学发现的效率及创新生态。

Method: 提出了AISLE系统，通过五个关键维度（跨机构设备协同、智能数据管理、AI驱动编排、可互操作通信接口、AI/ML赋能的科学教育）实现自治实验室的互联。

Result: AISLE不仅促进了多机构自动化研究协作，还为可持续能源、材料开发和公共健康等领域带来重大创新潜力。

Conclusion: AISLE实现跨机构自主实验室的协作，推动以AI为驱动的科学研究突破传统，缩短创新周期，且促进科研民主化。

Abstract: Scientific discovery is being revolutionized by AI and autonomous systems,
yet current autonomous laboratories remain isolated islands unable to
collaborate across institutions. We present the Autonomous Interconnected
Science Lab Ecosystem (AISLE), a grassroots network transforming fragmented
capabilities into a unified system that shorten the path from ideation to
innovation to impact and accelerates discovery from decades to months. AISLE
addresses five critical dimensions: (1) cross-institutional equipment
orchestration, (2) intelligent data management with FAIR compliance, (3)
AI-agent driven orchestration grounded in scientific principles, (4)
interoperable agent communication interfaces, and (5) AI/ML-integrated
scientific education. By connecting autonomous agents across institutional
boundaries, autonomous science can unlock research spaces inaccessible to
traditional approaches while democratizing cutting-edge technologies. This
paradigm shift toward collaborative autonomous science promises breakthroughs
in sustainable energy, materials development, and public health.

</details>


### [235] [Public Perceptions of Autonomous Vehicles: A Survey of Pedestrians and Cyclists in Pittsburgh](https://arxiv.org/abs/2506.17513)
*Rudra Y. Bedekar*

Main category: cs.CY

TL;DR: 通过调查匹兹堡1200多名居民，发现人群特征、基础设施与沟通教育共同影响公众对自动驾驶汽车的认知与采纳。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶汽车（AV）技术的发展，行人与骑行者作为道路使用者与AV的互动日益增多，但他们对该技术的认知、信任和安全感尚不清晰。本研究旨在阐明不同人群对AV的看法及其影响因素，推动更好城市交通规划与技术普及。

Method: 本研究通过面向匹兹堡地区超过1200名受访者进行问卷调查，收集行人与骑行者对自动驾驶汽车的看法和体验数据，并分析人口统计特征、互动经历、基础设施准备状况、安全感和信任度之间的关系。

Result: 结果显示，人口统计因素（如年龄、性别等）影响人们对AV的看法，基础设施存在差距。安全沟通和相关知识教育在推动AV接受和信任中起着关键作用。

Conclusion: 不同人群对自动驾驶汽车技术的认知和接受度存在差异，加强基础设施建设及提升公众沟通与教育对于推动AV技术的普及具有重要意义。

Abstract: This study investigates how autonomous vehicle(AV) technology is perceived by
pedestrians and bicyclists in Pittsburgh. Using survey data from over 1200
respondents, the research explores the interplay between demographics, AV
interactions, infrastructural readiness, safety perceptions, and trust.
Findings highlight demographic divides, infrastructure gaps, and the crucial
role of communication and education in AV adoption.

</details>


### [236] [Optimizing Mastery Learning by Fast-Forwarding Over-Practice Steps](https://arxiv.org/abs/2506.17577)
*Meng Xia,Robin Schmucker,Conrad Borchers,Vincent Aleven*

Main category: cs.CY

TL;DR: 提出并验证了一种题目步骤级的快进技术，能显著减少学生对已掌握技能的过度练习，提升学习效率。该方法易于集成到现有算法，但实际效果受学生难题挑战中的参与度影响。


<details>
  <summary>Details</summary>
Motivation: 尽管精熟学习能提升学习效率和效果，但学生过度练习已掌握技能的问题依旧是辅导系统的核心难题，现有方法主要通过改进题目选择算法和设计针对性练习任务来减少过度练习，很少关注题目步骤级的自适应。

Method: 提出了一种名为“快进（Fast-Forwarding）”的新技术作为现有问题选择算法的增强，基于真实学生数据建立的学习者模型与解题路径进行仿真研究，实现了在学生完全掌握之后可跳过剩余的解题步骤。

Result: 仿真结果表明，快进技术最多能将过度练习减少三分之一，特别是当与优先选择难题的问题选择算法结合时效果更佳。

Conclusion: 快进是一种灵活的方法，可以增强任何问题选择算法，提高学生练习的效率，但实际效果还依赖于学生在高难度练习中的动机和专注度。

Abstract: Mastery learning improves learning proficiency and efficiency. However, the
overpractice of skills--students spending time on skills they have already
mastered--remains a fundamental challenge for tutoring systems. Previous
research has reduced overpractice through the development of better problem
selection algorithms and the authoring of focused practice tasks. However, few
efforts have concentrated on reducing overpractice through step-level
adaptivity, which can avoid resource-intensive curriculum redesign. We propose
and evaluate Fast-Forwarding as a technique that enhances existing problem
selection algorithms. Based on simulation studies informed by learner models
and problem-solving pathways derived from real student data, Fast-Forwarding
can reduce overpractice by up to one-third, as it does not require students to
complete problem-solving steps if all remaining pathways are fully mastered.
Fast-Forwarding is a flexible method that enhances any problem selection
algorithm, though its effectiveness is highest for algorithms that
preferentially select difficult problems. Therefore, our findings suggest that
while Fast-Forwarding may improve student practice efficiency, the size of its
practical impact may also depend on students' ability to stay motivated and
engaged at higher levels of difficulty.

</details>


### [237] [Experimental Evidence for the Propagation and Preservation of Machine Discoveries in Human Populations](https://arxiv.org/abs/2506.17741)
*Levin Brinkmann,Thomas F. Eisenmann,Anne-Marie Nussberger,Maxim Derex,Sara Bonati,Valerii Chirkov,Iyad Rahwan*

Main category: cs.CY

TL;DR: 本论文提出，AI若能发现创新且具明显优势并易于学习的策略，便能持续推动人类文化和认知演进。这一机制通过实验和模拟得到验证，对理解AI时代的文化变迁具有深刻启示。


<details>
  <summary>Details</summary>
Motivation: 当前的AI系统不仅超越人类能力，还可能带来新的问题解决策略，这对人类文化和认知发展具有重要意义。然而，我们尚不明确AI从工具角色跃升为推动文化持久变革的具体条件。

Method: 作者使用了文化传递实验和基于模拟的智能体实验，系统性地分析和验证AI发现的策略在人群中的传递、理解与保留过程。

Result: 研究发现，若AI发现的策略具有非平凡性、可学习性及显著优势，这些策略便可被人类吸收并代际传承，最终引起持久的文化变迁。

Conclusion: 机器只要创造出具有实际优势且易于被人理解和学习的新策略，就能成为推动人类文化和认知持续扩展的新动力。这为理解AI对人类文化演化的深远影响提供了理论框架。

Abstract: Intelligent machines with superhuman capabilities have the potential to
uncover problem-solving strategies beyond human discovery. Emerging evidence
from competitive gameplay, such as Go, demonstrates that AI systems are
evolving from mere tools to sources of cultural innovation adopted by humans.
However, the conditions under which intelligent machines transition from tools
to drivers of persistent cultural change remain unclear. We identify three key
conditions for machines to fundamentally influence human problem-solving: the
discovered strategies must be non-trivial, learnable, and offer a clear
advantage. Using a cultural transmission experiment and an agent-based
simulation, we demonstrate that when these conditions are met,
machine-discovered strategies can be transmitted, understood, and preserved by
human populations, leading to enduring cultural shifts. These findings provide
a framework for understanding how machines can persistently expand human
cognitive skills and underscore the need to consider their broader implications
for human cognition and cultural evolution.

</details>


### [238] [The value of human and machine in machine-generated creative contents](https://arxiv.org/abs/2506.17808)
*Weina Jin*

Main category: cs.CY

TL;DR: 机器生成的内容如果没有人类解读，就无法与现实和经验建立联系，所谓的“创造力”其实是人机共同作用的结果。


<details>
  <summary>Details</summary>
Motivation: 当前机器生成内容表现出高度的“想象力”和“创造力”，但这些是否真正属于机器本身引发争议。该文旨在厘清人类与机器在内容生成中的实际作用和关系。

Method: 本文采用哲学性分析的方法，探讨机器生成内容与人类主观解读之间的关系。通过理论阐述说明为何人机协同是创造力的来源。

Result: 分析得出：机器生成内容的创造性本质上依赖于人类的解释，没有人类的参与，这些内容无法自动获得现实意义和经验基础。

Conclusion: 机器生成内容中的“想象力”和“创造力”并不能完全归功于机器本身。这种成就是人类与机器共同的结果。没有人类的解读，机器生成的内容无法自动与现实和人的经验建立联系。

Abstract: The seemingly "imagination" and "creativity" from machine-generated contents
should not be misattributed to the accomplishment of machine. They are
accomplishments of both human and machine. Without human interpretation, the
machine-generated contents remain in the imaginary space of the large language
models, and cannot automatically establish grounding in the reality and human
experience.

</details>


### [239] [The Democratic Paradox in Large Language Models' Underestimation of Press Freedom](https://arxiv.org/abs/2506.18045)
*I. Loaiza,R. Vestrelli,A. Fronzetti Colladon,R. Rigobon*

Main category: cs.CY

TL;DR: 主流大语言模型在评估各国新闻自由方面与专家评估存在系统性偏差，普遍低估多数国家的新闻自由，且对本国产生正向偏见。这种失真或影响公众对全球民主状况的理解，亟需改进模型的客观性和准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在全球范围内影响大量用户获取信息。由于其对信息的引导与偏见，可能影响公众对如新闻自由等重要民主制度的认知和信任。作者关注这些模型对新闻自由状态评价的准确性和潜在失真。

Method: 对六个主流LLMs进行实验，分析它们对180个国家新闻自由状况的评价，并与世界新闻自由指数（WPFI）专家评估结果进行系统对比，考察失真与偏见现象。

Result: 六个LLMs普遍低估新闻自由，全模型在71%-93%的国家中低于专家评价。发现“差异性失调”，即在新闻自由最强的国家被低估最严重。大多数模型对本国存在正向偏见，对本国新闻自由的评价比实际高7%-260%。

Conclusion: 当前热门LLMs在新闻自由这种关键民主议题上存在系统性偏见与失调，可能误导全球用户。随着LLMs在信息获取领域地位提升，需确保其对全球公民权益的客观准确表达。

Abstract: As Large Language Models (LLMs) increasingly mediate global information
access for millions of users worldwide, their alignment and biases have the
potential to shape public understanding and trust in fundamental democratic
institutions, such as press freedom. In this study, we uncover three systematic
distortions in the way six popular LLMs evaluate press freedom in 180 countries
compared to expert assessments of the World Press Freedom Index (WPFI). The six
LLMs exhibit a negative misalignment, consistently underestimating press
freedom, with individual models rating between 71% to 93% of countries as less
free. We also identify a paradoxical pattern we term differential misalignment:
LLMs disproportionately underestimate press freedom in countries where it is
strongest. Additionally, five of the six LLMs exhibit positive home bias,
rating their home countries' press freedoms more favorably than would be
expected given their negative misalignment with the human benchmark. In some
cases, LLMs rate their home countries between 7% to 260% more positively than
expected. If LLMs are set to become the next search engines and some of the
most important cultural tools of our time, they must ensure accurate
representations of the state of our human and civic rights globally.

</details>


### [240] [Aggregated Individual Reporting for Post-Deployment Evaluation](https://arxiv.org/abs/2506.18133)
*Jessica Dai,Inioluwa Deborah Raji,Benjamin Recht,Irene Y. Chen*

Main category: cs.CY

TL;DR: 本文提出AIR机制，让用户报告AI系统使用中的问题并聚合分析，实现更细致、民主的后部署评估；强调该方式有助发现新问题并推动AI系统改进，补足传统评估模式的不足，并给出实践路径和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统部署后的评估局限于静态基准测试，无法反映真实使用中的问题，同时人们对于AI系统权力集中的担忧，推动了对“民主”或“公众”AI的兴趣。科学有效地引入公众参与AI系统评估成为一个重要需求。

Method: 提出聚合个人报告（AIR）的机制，作为一种新的部署后评估框架。该机制允许用户在与AI系统交互遇到问题时进行个人报告，随后将这些报告进行汇总分析，从而实现更加细致的后期评估。本工作还详述了AIR机制的设计流程及未来进一步研究需要关注的问题。

Result: AIR机制能够发现以往静态测评难以捕捉的安全性和性能新问题，聚合分析为后续改进行动提供依据，也为民主化AI现实路径和理论提出了支持。本文明确阐释了实践中的设计要点和后续研究方向。

Conclusion: 个人体验报告应成为AI系统部署后评估的重要组成部分。聚合报告机制不仅拓宽了对AI系统性能和安全性的认识方式，也为实现‘民主’AI增添了可实施路径，并呼吁后续深入完善相关流程和方法。

Abstract: The need for developing model evaluations beyond static benchmarking,
especially in the post-deployment phase, is now well-understood. At the same
time, concerns about the concentration of power in deployed AI systems have
sparked a keen interest in 'democratic' or 'public' AI. In this work, we bring
these two ideas together by proposing mechanisms for aggregated individual
reporting (AIR), a framework for post-deployment evaluation that relies on
individual reports from the public. An AIR mechanism allows those who interact
with a specific, deployed (AI) system to report when they feel that they may
have experienced something problematic; these reports are then aggregated over
time, with the goal of evaluating the relevant system in a fine-grained manner.
This position paper argues that individual experiences should be understood as
an integral part of post-deployment evaluation, and that the scope of our
proposed aggregated individual reporting mechanism is a practical path to that
end. On the one hand, individual reporting can identify substantively novel
insights about safety and performance; on the other, aggregation can be
uniquely useful for informing action. From a normative perspective, the
post-deployment phase completes a missing piece in the conversation about
'democratic' AI. As a pathway to implementation, we provide a workflow of
concrete design decisions and pointers to areas requiring further research and
methodological development.

</details>


### [241] [The California Report on Frontier AI Policy](https://arxiv.org/abs/2506.17303)
*Rishi Bommasani,Scott R. Singer,Ruth E. Appel,Sarah Cen,A. Feder Cooper,Elena Cryst,Lindsey A. Gailmard,Ian Klaus,Meredith M. Lee,Inioluwa Deborah Raji,Anka Reuel,Drew Spence,Alexander Wan,Angelina Wang,Daniel Zhang,Daniel E. Ho,Percy Liang,Dawn Song,Joseph E. Gonzalez,Jonathan Zittrain,Jennifer Tour Chayes,Mariano-Florentino Cuellar,Li Fei-Fei*

Main category: cs.CY

TL;DR: 本报告为加州如何平衡AI创新与风险治理提出了多元化、可操作的政策原则与框架。


<details>
  <summary>Details</summary>
Motivation: 人工智能前沿创新带来巨大机遇，但也引发复杂政策挑战，特别是在推动创新与防范风险之间如何取得平衡。作为全球AI创新中心，加州需要应对与AI发展相关的潜在风险，并制定适应前沿AI发展的政策框架。

Method: 本报告采用多学科方法，结合实证研究、历史分析、建模与仿真等多种证据，提出了前沿AI政策制定框架，并据此提炼出可为加州AI政策提供指导的原则。

Result: 报告提出了基于“信任但验证”理念的AI治理政策原则，强调在支持AI创新的同时，建立适当风险管控措施，从而减少实质风险。

Conclusion: 加州可通过本报告提出的多元证据和理念指导，既促进前沿AI创新，又有效管理与之相关的重大风险，实现创新与治理的平衡。

Abstract: The innovations emerging at the frontier of artificial intelligence (AI) are
poised to create historic opportunities for humanity but also raise complex
policy challenges. Continued progress in frontier AI carries the potential for
profound advances in scientific discovery, economic productivity, and broader
social well-being. As the epicenter of global AI innovation, California has a
unique opportunity to continue supporting developments in frontier AI while
addressing substantial risks that could have far reaching consequences for the
state and beyond. This report leverages broad evidence, including empirical
research, historical analysis, and modeling and simulations, to provide a
framework for policymaking on the frontier of AI development. Building on this
multidisciplinary approach, this report derives policy principles that can
inform how California approaches the use, assessment, and governance of
frontier AI: principles rooted in an ethos of trust but verify. This approach
takes into account the importance of innovation while establishing appropriate
strategies to reduce material risks.

</details>


### [242] [Can Large Language Models Be Trusted Paper Reviewers? A Feasibility Study](https://arxiv.org/abs/2506.17311)
*Chuanlei Li,Xu Hu,Minghui Xu,Kun Li,Yue Zhang,Xiuzhen Cheng*

Main category: cs.CY

TL;DR: 利用LLMs自动论文评审可显著提高效率、降低成本，但评审结果与实际录用差异较大，目前适合辅助人工而非取代人工评审。


<details>
  <summary>Details</summary>
Motivation: 学术论文评审耗时、要求高的专业性且需要大量人力资源，因此希望用LLMs自动化评审流程以降低成本并提升效率。

Method: 提出了一个集成了检索增强生成（RAG）、AutoGen多智能体系统和链式思维提示的自动评审系统，用于论文格式检查、标准化评估、评论生成以及打分。对290篇WASA 2024投稿进行了实验。

Result: LLM自动评审平均耗时2.48小时、平均成本104.28美元，大大低于人工。但LLM选择的论文与实际录用论文的一致性仅为38.6%，存在幻觉、判断力不足和偏好检索信息等问题。

Conclusion: LLMs在学术论文评审中能够显著降低时间和费用，但与实际评审结果的一致性较低，目前不宜完全替代人工评审，应作为辅助工具使用。

Abstract: Academic paper review typically requires substantial time, expertise, and
human resources. Large Language Models (LLMs) present a promising method for
automating the review process due to their extensive training data, broad
knowledge base, and relatively low usage cost. This work explores the
feasibility of using LLMs for academic paper review by proposing an automated
review system. The system integrates Retrieval Augmented Generation (RAG), the
AutoGen multi-agent system, and Chain-of-Thought prompting to support tasks
such as format checking, standardized evaluation, comment generation, and
scoring. Experiments conducted on 290 submissions from the WASA 2024 conference
using GPT-4o show that LLM-based review significantly reduces review time
(average 2.48 hours) and cost (average \$104.28 USD). However, the similarity
between LLM-selected papers and actual accepted papers remains low (average
38.6\%), indicating issues such as hallucination, lack of independent judgment,
and retrieval preferences. Therefore, it is recommended to use LLMs as
assistive tools to support human reviewers, rather than to replace them.

</details>


### [243] [Using Machine Learning in Analyzing Air Quality Discrepancies of Environmental Impact](https://arxiv.org/abs/2506.17319)
*Shuangbao Paul Wang,Lucas Yang,Rahouane Chouchane,Jin Guo,Michael Bailey*

Main category: cs.CY

TL;DR: 本研究通过机器学习分析发现，巴尔的摩市的空气污染与带有偏见的保险风险评估历史政策存在密切关系，低收入和有色人种社区面临更严重的污染问题，这反映了制度性不公对当代居民生活的深远影响。


<details>
  <summary>Details</summary>
Motivation: 研究团队希望揭示巴尔的摩（Baltimore）城市中空气污染水平与历史上存在偏见的保险风险评估方法之间的关系，探究环境污染与社会经济、种族因素之间的联系。

Method: 采用机器学习和软件工程方法，整合三大数据源：有偏见的保险风险评估法、居民人口统计信息以及NO2和PM2.5的污染数据，对覆盖整个巴尔的摩市及美国主要城市居民的数据进行分析。

Result: 发现空气污染水平与存在偏见的保险评估方法密切相关。高收入与低收入区间NO2污染水平存在明显差异，居民种族因素也与空气污染分布密切关联。

Conclusion: 历史性的政策偏见持续影响着巴尔的摩现今的环境公平与居民生活质量，对有色人种的影响尤为突出。

Abstract: In this study, we apply machine learning and software engineering in
analyzing air pollution levels in City of Baltimore. The data model was fed
with three primary data sources: 1) a biased method of estimating insurance
risk used by homeowners loan corporation, 2) demographics of Baltimore
residents, and 3) census data estimate of NO2 and PM2.5 concentrations. The
dataset covers 650,643 Baltimore residents in 44.7 million residents in 202
major cities in US. The results show that air pollution levels have a clear
association with the biased insurance estimating method. Great disparities
present in NO2 level between more desirable and low income blocks. Similar
disparities exist in air pollution level between residents' ethnicity. As
Baltimore population consists of a greater proportion of people of color, the
finding reveals how decades old policies has continued to discriminate and
affect quality of life of Baltimore citizens today.

</details>


### [244] [MAARTA:Multi-Agentic Adaptive Radiology Teaching Assistant](https://arxiv.org/abs/2506.17320)
*Akash Awasthi,Brandon V. Chang,Anh M. Vu,Ngan Le,Rishi Agrawal,Zhigang Deng,Carol Wu,Hien Van Nguyen*

Main category: cs.CY

TL;DR: 本文提出一种多智能体放射学教学助手MAARTA，能够动态分析学生与专家的注视行为和诊断报告，对学生视觉与诊断错误进行个性化分析和反馈，有助于提升放射学学生的诊断能力，弥补现有AI系统在错误解释上的不足。


<details>
  <summary>Details</summary>
Motivation: 放射学学生在视觉搜索和诊断解释方面常出现错误，主要由于缺乏专家导师的时间和指导。目前的AI系统仅注重最终诊断准确率，无法解释错误产生的过程与原因，无法有效帮助学生理解和改进感知错误。

Method: 提出了MAARTA（多智能体自适应放射学教学助手），它通过多智能体架构，分析学生与专家的视线轨迹和放射学报告，对学生进行个性化反馈。系统利用结构化图比较专家与学生的注视行为，动态选择智能体，分析感知错误，并用分步提示方式帮助学生理解并改进诊断逻辑。

Result: MAARTA能够智能、动态地帮助放射学学生发现并理解感知错误，如漏看、注视时间过短、误解释等，从而提升其诊断推理能力。系统相比单智能体模型更具适应性与高效性。

Conclusion: MAARTA通过多智能体机制精准分析和反馈学生的感知错误，填补了现有AI辅导系统无法解释错误如何发生的空白，推动了AI在放射学教育中的智能化和个性化发展。

Abstract: Radiology students often struggle to develop perceptual expertise due to
limited expert mentorship time, leading to errors in visual search and
diagnostic interpretation. These perceptual errors, such as missed fixations,
short dwell times, or misinterpretations, are not adequately addressed by
current AI systems, which focus on diagnostic accuracy but fail to explain how
and why errors occur. To address this gap, we introduce MAARTA (Multi-Agentic
Adaptive Radiology Teaching Assistant), a multi-agent framework that analyzes
gaze patterns and radiology reports to provide personalized feedback. Unlike
single-agent models, MAARTA dynamically selects agents based on error
complexity, enabling adaptive and efficient reasoning. By comparing expert and
student gaze behavior through structured graphs, the system identifies missed
findings and assigns Perceptual Error Teacher agents to analyze discrepancies.
MAARTA then uses step-by-step prompting to help students understand their
errors and improve diagnostic reasoning, advancing AI-driven radiology
education.

</details>


### [245] [AI is the Strategy: From Agentic AI to Autonomous Business Models onto Strategy in the Age of AI](https://arxiv.org/abs/2506.17339)
*René Bohnsack,Mickie de Wet*

Main category: cs.CY

TL;DR: 本文提出企业正在从由人主导或AI辅助的模式，向AI自主决策和执行的自主型商业模式（ABM）转变。通过案例分析，作者指出AI将成为企业竞争和战略的核心，推动行业进入机器主导的“合成竞争”阶段。这一变革对战略管理和组织设计提出了巨大挑战。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力提升，AI不再仅作为辅助工具进入企业，而有潜力成为企业战略和运营的核心，驱动商业模式根本性变革。作者希望探讨和框定这种转型，并引发对未来企业战略与组织设计的思考。

Method: 通过分析两个案例：以自主设计为目标的以色列初创公司getswan.ai，以及假设将Ryanair重构为AI驱动企业，展示了企业从AI辅助向AI自主演化的过程和动态。

Result: ABM使企业获得通过AI决策执行的新型竞争优势，实现持续适应和决策自动化，重塑行业竞争格局并挑战传统管理和治理范式。

Conclusion: 本文提出了自主型商业模式（Autonomous Business Models, ABMs）的概念，认为随着智能体AI能力的增强，企业战略和管理正进入由AI主导的新阶段，人类的决策和管理将逐步被AI取代，企业运作将更高效且具适应性，未来的竞争将转变为AI之间的“合成竞争”。

Abstract: This article develops the concept of Autonomous Business Models (ABMs) as a
distinct managerial and strategic logic in the age of agentic AI. While most
firms still operate within human-driven or AI-augmented models, we argue that
we are now entering a phase where agentic AI (systems capable of initiating,
coordinating, and adapting actions autonomously) can increasingly execute the
core mechanisms of value creation, delivery, and capture. This shift reframes
AI not as a tool to support strategy, but as the strategy itself. Using two
illustrative cases, getswan.ai, an Israeli startup pursuing autonomy by design,
and a hypothetical reconfiguration of Ryanair as an AI-driven incumbent, we
depict the evolution from augmented to autonomous business models. We show how
ABMs reshape competitive advantage through agentic execution, continuous
adaptation, and the gradual offloading of human decision-making. This
transition introduces new forms of competition between AI-led firms, which we
term synthetic competition, where strategic interactions occur at rapid,
machine-level speed and scale. It also challenges foundational assumptions in
strategy, organizational design, and governance. By positioning agentic AI as
the central actor in business model execution, the article invites us to
rethink strategic management in an era where firms increasingly run themselves.

</details>


### [246] [Distinguishing Predictive and Generative AI in Regulation](https://arxiv.org/abs/2506.17347)
*Jennifer Wang,Andrew Selbst,Solon Barocas,Suresh Venkatasubramanian*

Main category: cs.CY

TL;DR: 随着生成式AI兴起，传统AI监管工具不再完全适用，本文分析了生成式AI的四大特性和相应政策挑战，呼吁制定新的监管政策，并提出三项具体建议以更好地管理生成式AI发展。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的出现，现有针对预测型AI制定的监管工具与假设可能已不再适用于新型风险与特性，有必要重新审视和调整政策。

Method: 分析生成式AI相较于预测性AI的四个不同特性及其带来的政策挑战，并对比现有政策的适用性，进一步提出针对生成式AI的政策建议。

Result: 提出生成式AI具备四个关键特征：普遍性和适应性强难以精准监管、评估有效性难度增大、新的法律及利益相关方变化、价值链分布广泛。这些都要求政策制定者重新衡量和调整原有监管策略，并给出相应的三条政策建议。

Conclusion: 现有AI监管方案需针对生成式AI独有的风险与挑战进行调整，政策制定者必须结合生态系统约束和新的监管目标，制定更有效的政策。

Abstract: Over the past decade, policymakers have developed a set of regulatory tools
to ensure AI development aligns with key societal goals. Many of these tools
were initially developed in response to concerns with predictive AI and
therefore encode certain assumptions about the nature of AI systems and the
utility of certain regulatory approaches. With the advent of generative AI,
however, some of these assumptions no longer hold, even as policymakers attempt
to maintain a single regulatory target that covers both types of AI.
  In this paper, we identify four distinct aspects of generative AI that call
for meaningfully different policy responses. These are the generality and
adaptability of generative AI that make it a poor regulatory target, the
difficulty of designing effective evaluations, new legal concerns that change
the ecosystem of stakeholders and sources of expertise, and the distributed
structure of the generative AI value chain.
  In light of these distinctions, policymakers will need to evaluate where the
past decade of policy work remains relevant and where new policies, designed to
address the unique risks posed by generative AI, are necessary. We outline
three recommendations for policymakers to more effectively identify regulatory
targets and leverage constraints across the broader ecosystem to govern
generative AI.

</details>


### [247] [Evaluating the Impact of Lean and Green Practices on Operational Performance: A Real Data-Driven Simulation Case Study](https://arxiv.org/abs/2506.17354)
*Farah Altarazi*

Main category: cs.CY

TL;DR: 本文结合精益与绿色生产理念，通过系统建模和OEEE指标评估，提出并验证了一系列生产优化措施。结果显示，这些改进显著提升了设备整体环境效率和生产效率，强调了综合可持续管理的重要性。


<details>
  <summary>Details</summary>
Motivation: 在全球市场驱动和客户需求不断变化的背景下，可持续发展成为新的竞争优势，驱使企业将传统的盈利与效率目标与可持续目标结合，创新精益与绿色管理理念。

Method: 采用系统分析和建模方法，引入并计算整体环境设备效率（OEEE），利用仿真建模和能耗价值流程图，评估和优化生产流程，并提出改进方案进行情境分析。

Result: 现有系统OEEE值仅为13.1%，生产周期较长。通过优化工序和采用新技术，两种改进方案将OEEE提升至24%和35%，生产周期分别降至292分钟和158.23分钟。

Conclusion: 研究表明，将精益与绿色生产方法结合，并应用OEEE指标可以显著提升生产系统的可持续性和整体绩效。提出的改进措施在模拟中均表现出更高的OEEE值和更短的生产周期，验证了这些方法的有效性。

Abstract: Global market-driven forces and customer needs are continuously changing. In
the past, profitability and efficiency were the primary objectives of most
companies. However, in recent decades, sustainable performance has emerged as a
new competitive advantage. Companies have been compelled to adopt a concept
that combines these evolving global interests with traditional goals resulting
in the innovation of the lean and green approach.
  In this study, a research methodology that includes system analysis and
modeling procedures to apply the lean and green concept, combined with a new
evaluation metric, the Overall Environmental Equipment Effectiveness (OEEE) was
used to investigate the effects of adopting lean and green practices on overall
performance.
  A simulation model and energy value stream mapping were implemented, and the
OEEE value was calculated to assess the current performance in terms of
quality, availability, productivity, and sustainability. The current state
production lead time was 329.1 minutes per batch, and the OEEE value was 13.1%.
This result indicates existing issues in performance and sustainability,
suggesting that improvement efforts should focus on enhancing these two aspects
to increase the overall OEEE value.
  Several improvement scenarios were proposed, including combining and
rearranging the inspection workstations as the first scenario, and using UV
lighting for drying purposes at the framing workstation as the second. After
applying these improvements, both scenarios showed increased OEEE values and
reduced lead times compared to the current state. In the first scenario, the
lead time decreased to 158.23 minutes, and the OEEE increased to 35%. In the
second scenario, the lead time was reduced to 292 minutes, with the OEEE
increasing to 24%.

</details>


### [248] [PasteTrace: A Single Source Plagiarism Detection Tool For Introductory Programming Courses](https://arxiv.org/abs/2506.17355)
*Jesse McDonald,Scott Robertson,Anthony Peruma*

Main category: cs.CY

TL;DR: 本文提出并验证了针对编程入门课程的实时抄袭检测工具PasteTrace，在实际教学中效果显著，优于传统工具。


<details>
  <summary>Details</summary>
Motivation: 在计算机科学入门课程中，零基础学生经常会因课程难度大而出现理解困难甚至学术不端（如抄袭）行为，现有的抄袭检测工具并不完全适用于此类课程。

Method: 本文提出PasteTrace，一种专为编程入门课设计的开源抄袭检测工具。PasteTrace集成于IDE中，实时跟踪学生编码行为，识别学术不端证据。

Result: 在两门编程入门课程中的评估表明，PasteTrace能够有效洞察学生行为、检测多种抄袭方式，并且优于现有主流工具。

Conclusion: PasteTrace作为新型代码抄袭检测工具，为编程入门教学的学术诚信管理提供了更专业和高效的手段。

Abstract: Introductory Computer Science classes are important for laying the foundation
for advanced programming courses. However, students without prior programming
experience may find these courses challenging, leading to difficulties in
understanding concepts and engaging in academic dishonesty such as plagiarism.
While there exists plagiarism detection techniques and tools, not all of them
are suitable for academic settings, especially in introductory programming
courses. This paper introduces PasteTrace, a novel open-source plagiarism
detection tool designed specifically for introductory programming courses.
Unlike traditional methods, PasteTrace operates within an Integrated
Development Environment that tracks the student's coding activities in
real-time for evidence of plagiarism. Our evaluation of PasteTrace in two
introductory programming courses demonstrates the tool's ability to provide
insights into student behavior and detect various forms of plagiarism,
outperforming an existing well-established tool.
  A video demonstration of PasteTrace and its source code, and case study data
are made available at https://doi.org/10.6084/m9.figshare.27115852

</details>


### [249] [Automatic Large Language Models Creation of Interactive Learning Lessons](https://arxiv.org/abs/2506.17356)
*Jionghao Lin,Jiarui Rao,Yiyang Zhao,Yuting Wang,Ashish Gurung,Amanda Barany,Jaclyn Ocumpaugh,Ryan S. Baker,Kenneth R. Koedinger*

Main category: cs.CY

TL;DR: 通过RAG与GPT-4o结合任务分解提示工程，自动为新手在线数学教师生成高质量培训课程，经人工评估显示课程结构优秀且节约时间，但存在些许内容泛化和说明不清。人机协作生成教学内容展现了较大应用前景。


<details>
  <summary>Details</summary>
Motivation: 现有的在线数学教师培训存在效率低下、成本高昂的问题，需要自动化、高质量的互动式课程生成方法，辅助新手教师在线培训。

Method: 提出采用基于检索增强生成（RAG）的GPT-4o，通过任务分解的提示工程，自动生成结构化的教学场景课程。针对三个关键主题进行课程生成，并由两名人工评审使用基于教学设计的评分细则进行定量与定性评价。

Result: 任务分解策略生成的课程结构更好、得分更高，节省时间。人工评审指出课程内容结构合理且有效，但也存在反馈泛化和部分教学说明不清晰的缺点。

Conclusion: 提出的AI和人类混合方法能高效生成高质量教师培训课程，显示在人机联合设计互动课程方面具有潜力。

Abstract: We explore the automatic generation of interactive, scenario-based lessons
designed to train novice human tutors who teach middle school mathematics
online. Employing prompt engineering through a Retrieval-Augmented Generation
approach with GPT-4o, we developed a system capable of creating structured
tutor training lessons. Our study generated lessons in English for three key
topics: Encouraging Students' Independence, Encouraging Help-Seeking Behavior,
and Turning on Cameras, using a task decomposition prompting strategy that
breaks lesson generation into sub-tasks. The generated lessons were evaluated
by two human evaluators, who provided both quantitative and qualitative
evaluations using a comprehensive rubric informed by lesson design research.
Results demonstrate that the task decomposition strategy led to higher-rated
lessons compared to single-step generation. Human evaluators identified several
strengths in the LLM-generated lessons, including well-structured content and
time-saving potential, while also noting limitations such as generic feedback
and a lack of clarity in some instructional sections. These findings underscore
the potential of hybrid human-AI approaches for generating effective lessons in
tutor training.

</details>


### [250] [A Large-Scale Real-World Evaluation of LLM-Based Virtual Teaching Assistant](https://arxiv.org/abs/2506.17363)
*Sunjun Kweon,Sooyohn Nam,Hyunseung Lim,Hwajung Hong,Edward Choi*

Main category: cs.CY

TL;DR: 本文开发并实地部署了一个基于大型语言模型的虚拟助教（VTA），在大规模课程中系统评估了其效果和学生反馈，分析了实际交互模式，并提出了未来改进和推广的关键难点。


<details>
  <summary>Details</summary>
Motivation: 当前关于LLM驱动的虚拟助教在实际课堂中的效果和学生接受度的实证研究有限，实际影响尚不明朗，需要通过真实场景评估其可行性和潜在价值。

Method: 开发了一个基于LLM的VTA系统，并在477名研究生的AI编程课程中部署。通过在课程的不同阶段进行三轮问卷调查，收集学生对VTA表现的感知变化；同时，分析3,869条学生与VTA的交互记录，比较VTA和人类教师在交互中的异同。

Result: 学生对VTA的感知随着课程推进有所变化。交互分析揭示了学生常见提问类型和参与模式，同时指出与人类教师相比，VTA在支持学习过程上发挥了一定作用，但也面临一些挑战。

Conclusion: 通过大规模实证研究和交互分析，评估了基于大型语言模型的虚拟助教（VTA）在真实课堂中的可行性，并指出了其更广泛应用面临的关键挑战。

Abstract: Virtual Teaching Assistants (VTAs) powered by Large Language Models (LLMs)
have the potential to enhance student learning by providing instant feedback
and facilitating multi-turn interactions. However, empirical studies on their
effectiveness and acceptance in real-world classrooms are limited, leaving
their practical impact uncertain. In this study, we develop an LLM-based VTA
and deploy it in an introductory AI programming course with 477 graduate
students. To assess how student perceptions of the VTA's performance evolve
over time, we conduct three rounds of comprehensive surveys at different stages
of the course. Additionally, we analyze 3,869 student--VTA interaction pairs to
identify common question types and engagement patterns. We then compare these
interactions with traditional student--human instructor interactions to
evaluate the VTA's role in the learning process. Through a large-scale
empirical study and interaction analysis, we assess the feasibility of
deploying VTAs in real-world classrooms and identify key challenges for broader
adoption. Finally, we release the source code of our VTA system, fostering
future advancements in AI-driven education:
\texttt{https://github.com/sean0042/VTA}.

</details>


### [251] [AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning](https://arxiv.org/abs/2506.17364)
*Alvaro Becerra,Roberto Daza,Ruth Cobos,Aythami Morales,Mutlu Cukurova,Julian Fierrez*

Main category: cs.CY

TL;DR: 研究通过AI和多模态生物识别（生理信号+头部姿态），有效检测线上学习中因手机使用引发的分心，多模态方法准确率高达91%，优于单一信号，对提升在线学习支持具有参考价值。


<details>
  <summary>Details</summary>
Motivation: 在持续注意力任务（特别是线上学习）中，手机使用会导致分心，现有学习平台缺乏细粒度的行为数据，因此需要新的方法提高对学习分心情况的检测和理解。

Method: 提出了一种基于人工智能的方法，利用多模态生物识别信号（如生理信号和头部姿态数据）检测学习者使用手机导致的分心行为。通过比较单一生物信号与多模态整合模型的检测准确率。

Result: 头部姿态单一信号检测手机使用的准确率为87%，多模态模型（结合所有信号）的准确率提升到91%。

Conclusion: 多模态信号的整合明显优于单一信号，有助于更准确地检测学习过程中的分心行为。此外，提出了模型在在线学习环境中实时支持的可行性和局限性。

Abstract: This work investigates the use of multimodal biometrics to detect
distractions caused by smartphone use during tasks that require sustained
attention, with a focus on computer-based online learning. Although the methods
are applicable to various domains, such as autonomous driving, we concentrate
on the challenges learners face in maintaining engagement amid internal (e.g.,
motivation), system-related (e.g., course design) and contextual (e.g.,
smartphone use) factors. Traditional learning platforms often lack detailed
behavioral data, but Multimodal Learning Analytics (MMLA) and biosensors
provide new insights into learner attention. We propose an AI-based approach
that leverages physiological signals and head pose data to detect phone use.
Our results show that single biometric signals, such as brain waves or heart
rate, offer limited accuracy, while head pose alone achieves 87%. A multimodal
model combining all signals reaches 91% accuracy, highlighting the benefits of
integration. We conclude by discussing the implications and limitations of
deploying these models for real-time support in online learning environments.

</details>


### [252] [AI based Content Creation and Product Recommendation Applications in E-commerce: An Ethical overview](https://arxiv.org/abs/2506.17370)
*Aditi Madhusudan Jain,Ayush Jain*

Main category: cs.CY

TL;DR: AI在电商内容生成和产品推荐中带来效率和个性化提升，但伴随数据隐私和算法偏见等伦理问题。本文提出审计算法、丰富训练数据、多维公平性考量等解决策略，并针对数据隐私和透明度提供框架建议，为电商AI应用指明了合乎道德的发展路径。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在电商内容生成和产品推荐中的快速应用，尽管带来了个性化和效率提升，但相应的伦理挑战也日益凸显，尤其是在数据隐私、算法偏见和消费者自主权方面。

Method: 本文系统性地分析了AI驱动的内容生成和产品推荐中的伦理问题，并提出了通过算法常规审计、多样化训练数据和引入公平性指标等方法消除偏见和促进包容性。此外，还探讨了关注数据隐私、透明度和消费者自主权的伦理合规框架。

Result: 提出了可操作的最佳实践方法，包括定期审计算法、丰富数据多样性和融合公平性指标等，同时针对数据隐私保护和决策透明度提供了具体框架建议。

Conclusion: 通过实践这些建议，可以确保电商在采用AI进行内容生成和产品推荐时，技术既有效又合乎伦理。

Abstract: As e-commerce rapidly integrates artificial intelligence for content creation
and product recommendations, these technologies offer significant benefits in
personalization and efficiency. AI-driven systems automate product
descriptions, generate dynamic advertisements, and deliver tailored
recommendations based on consumer behavior, as seen in major platforms like
Amazon and Shopify. However, the widespread use of AI in e-commerce raises
crucial ethical challenges, particularly around data privacy, algorithmic bias,
and consumer autonomy. Bias -- whether cultural, gender-based, or socioeconomic
-- can be inadvertently embedded in AI models, leading to inequitable product
recommendations and reinforcing harmful stereotypes. This paper examines the
ethical implications of AI-driven content creation and product recommendations,
emphasizing the need for frameworks to ensure fairness, transparency, and need
for more established and robust ethical standards. We propose actionable best
practices to remove bias and ensure inclusivity, such as conducting regular
audits of algorithms, diversifying training data, and incorporating fairness
metrics into AI models. Additionally, we discuss frameworks for ethical
conformance that focus on safeguarding consumer data privacy, promoting
transparency in decision-making processes, and enhancing consumer autonomy. By
addressing these issues, we provide guidelines for responsibly utilizing AI in
e-commerce applications for content creation and product recommendations,
ensuring that these technologies are both effective and ethically sound.

</details>


### [253] [Multimodal Political Bias Identification and Neutralization](https://arxiv.org/abs/2506.17372)
*Cedric Bernard,Xavier Pleimling,Amun Kharel,Chase Vickery*

Main category: cs.CY

TL;DR: 提出了一个结合文本和图片的政治文章去偏见方法，能较好识别和减少文本及图片中的偏见，但模型还需更多训练和资源以进一步提升效果。


<details>
  <summary>Details</summary>
Motivation: 现有的偏见检测方法仅关注文本，忽视了图片部分，而图片在传播信息时同样重要。由于政治回音室现象，有必要同时针对政治文章中的文本与图片去除主观偏见和情绪化语言。

Method: 提出一种结合文本和图片偏见分析的新模型，包含四步：（1）利用CLIP模型进行图文偏见的语义对齐；（2）用ViT分类器为图片评分偏见度；（3）用BERT模型检测与消解文本中的偏见词汇与短语；（4）将原文与图片替换为经过中和或偏见减弱的版本。同时建议引入人工评估以保证生成内容的语义一致性。

Result: 文本去偏见方法能识别许多潜在的偏见词句，ViT模型对图片偏见检测效果良好，语义对齐模型高效。但为获得更好结果，还需更多训练和资源。

Conclusion: 结合文本与图片偏见检测和去偏见处理的方案具备前景，初步实验有效，但模型需进一步优化并强化训练。

Abstract: Due to the presence of political echo chambers, it becomes imperative to
detect and remove subjective bias and emotionally charged language from both
the text and images of political articles. However, prior work has focused on
solely the text portion of the bias rather than both the text and image
portions. This is a problem because the images are just as powerful of a medium
to communicate information as text is. To that end, we present a model that
leverages both text and image bias which consists of four different steps.
Image Text Alignment focuses on semantically aligning images based on their
bias through CLIP models. Image Bias Scoring determines the appropriate bias
score of images via a ViT classifier. Text De-Biasing focuses on detecting
biased words and phrases and neutralizing them through BERT models. These three
steps all culminate to the final step of debiasing, which replaces the text and
the image with neutralized or reduced counterparts, which for images is done by
comparing the bias scores. The results so far indicate that this approach is
promising, with the text debiasing strategy being able to identify many
potential biased words and phrases, and the ViT model showcasing effective
training. The semantic alignment model also is efficient. However, more time,
particularly in training, and resources are needed to obtain better results. A
human evaluation portion was also proposed to ensure semantic consistency of
the newly generated text and images.

</details>


### [254] [A Grassroots Network and Community Roadmap for Interconnected Autonomous Science Laboratories for Accelerated Discovery](https://arxiv.org/abs/2506.17510)
*Rafael Ferreira da Silva,Milad Abolhasani,Dionysios A. Antonopoulos,Laura Biven,Ryan Coffee,Ian T. Foster,Leslie Hamilton,Shantenu Jha,Theresa Mayer,Benjamin Mintz,Robert G. Moore,Salahudin Nimer,Noah Paulson,Woong Shin,Frederic Suter,Mitra Taheri,Michela Taufer,Newell R. Washburn*

Main category: cs.CY

TL;DR: 本文提出AISLE生态系统，打破自主实验室孤岛，推动跨机构协作和数据共享，加速科学发现，并拓宽研究与技术应用边界。


<details>
  <summary>Details</summary>
Motivation: 目前的自主实验室在AI和自动化推动下已有巨大进展，但不同机构之间仍缺乏有效协作，导致能力碎片化，影响科学创新速度和影响力。

Method: 提出了AISLE（Autonomous Interconnected Science Lab Ecosystem），实现跨机构实验设备编排、智能数据管理（FAIR合规）、基于科学原理的AI编排、可互操作的智能体通信接口以及融合AI/ML的科学教育。通过互连自主智能体，实现跨机构协同创新。

Result: AISLE能够打破传统孤岛模式，实现从想法到创新再到成果的周期缩短，从而明显加快科学发现进程。连接自主智能体，可拓展研究领域范围并促进技术普及。

Conclusion: AISLE代表了自主科学研究转向协作新范式，有望在可持续能源、材料开发和公共健康领域带来突破。

Abstract: Scientific discovery is being revolutionized by AI and autonomous systems,
yet current autonomous laboratories remain isolated islands unable to
collaborate across institutions. We present the Autonomous Interconnected
Science Lab Ecosystem (AISLE), a grassroots network transforming fragmented
capabilities into a unified system that shorten the path from ideation to
innovation to impact and accelerates discovery from decades to months. AISLE
addresses five critical dimensions: (1) cross-institutional equipment
orchestration, (2) intelligent data management with FAIR compliance, (3)
AI-agent driven orchestration grounded in scientific principles, (4)
interoperable agent communication interfaces, and (5) AI/ML-integrated
scientific education. By connecting autonomous agents across institutional
boundaries, autonomous science can unlock research spaces inaccessible to
traditional approaches while democratizing cutting-edge technologies. This
paradigm shift toward collaborative autonomous science promises breakthroughs
in sustainable energy, materials development, and public health.

</details>


### [255] [Public Perceptions of Autonomous Vehicles: A Survey of Pedestrians and Cyclists in Pittsburgh](https://arxiv.org/abs/2506.17513)
*Rudra Y. Bedekar*

Main category: cs.CY

TL;DR: 通过匹兹堡1200余份问卷分析，发现人口特征、基础设施及沟通教育对行人和骑行者对自动驾驶汽车的态度和信任度影响显著。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车（AV）逐渐进入现实生活，了解行人和骑行者的态度对于其推广应用至关重要。本文旨在揭示不同群体如何看待AV，并分析他们的信任与安全感。

Method: 采用问卷调查方法，收集了1200多位匹兹堡行人和自行车骑行者的数据，对其与AV技术的互动体验、人口统计特征、基础设施准备度、安全感知和信任进行了分析。

Result: 结果显示，不同人口群体对自动驾驶汽车的接受程度存在显著差异，当前基础设施存在不足，这在一定程度上影响了使用者的安全感和信任度。沟通和相关知识普及能够有效促进社会对AV的接受。

Conclusion: 推动自动驾驶汽车落地不仅需要技术进步，还必须重视行人与骑行者的身份差异和感受，通过改善基础设施及强化宣传教育来提升公众信任与安全感。

Abstract: This study investigates how autonomous vehicle(AV) technology is perceived by
pedestrians and bicyclists in Pittsburgh. Using survey data from over 1200
respondents, the research explores the interplay between demographics, AV
interactions, infrastructural readiness, safety perceptions, and trust.
Findings highlight demographic divides, infrastructure gaps, and the crucial
role of communication and education in AV adoption.

</details>


### [256] [Optimizing Mastery Learning by Fast-Forwarding Over-Practice Steps](https://arxiv.org/abs/2506.17577)
*Meng Xia,Robin Schmucker,Conrad Borchers,Vincent Aleven*

Main category: cs.CY

TL;DR: 提出Fast-Forwarding技术，用于减少掌握式学习中的过度练习，通过仿真最高可降低过度练习三分之一，能集成到多种题目选择算法中，对高难度题目成效更好，但成效与学生动力相关。


<details>
  <summary>Details</summary>
Motivation: 掌握式学习能提升学习效率，但过度练习，即学生在已掌握技能上花费过多时间，成为教学系统的挑战。以往研究多通过优化题目选择算法和精心设计的练习内容来减少过度练习，较少关注通过更细粒度的“步骤级自适应”来实现。

Method: 提出并评估了一种名为Fast-Forwarding的新技术，该技术可增强现有题目选择算法。通过基于真实学生数据的学习者模型与解题路径，利用仿真研究考察其效果。该方法允许学生已完全掌握路径的情况下跳过部分步骤，减少无效练习。

Result: 仿真结果表明，Fast-Forwarding能将过度练习减少至原来的三分之二。其本身可与任意题目选择算法结合使用，但在偏好选择高难度题目的算法中效果最明显。实际影响还依赖于学生在高难度任务时的动力和参与度。

Conclusion: Fast-Forwarding是一种灵活且效果显著的减少过度练习的方法，能提升掌握式学习的实践效率，但最佳成效需考虑学生的学习动力。

Abstract: Mastery learning improves learning proficiency and efficiency. However, the
overpractice of skills--students spending time on skills they have already
mastered--remains a fundamental challenge for tutoring systems. Previous
research has reduced overpractice through the development of better problem
selection algorithms and the authoring of focused practice tasks. However, few
efforts have concentrated on reducing overpractice through step-level
adaptivity, which can avoid resource-intensive curriculum redesign. We propose
and evaluate Fast-Forwarding as a technique that enhances existing problem
selection algorithms. Based on simulation studies informed by learner models
and problem-solving pathways derived from real student data, Fast-Forwarding
can reduce overpractice by up to one-third, as it does not require students to
complete problem-solving steps if all remaining pathways are fully mastered.
Fast-Forwarding is a flexible method that enhances any problem selection
algorithm, though its effectiveness is highest for algorithms that
preferentially select difficult problems. Therefore, our findings suggest that
while Fast-Forwarding may improve student practice efficiency, the size of its
practical impact may also depend on students' ability to stay motivated and
engaged at higher levels of difficulty.

</details>


### [257] [Experimental Evidence for the Propagation and Preservation of Machine Discoveries in Human Populations](https://arxiv.org/abs/2506.17741)
*Levin Brinkmann,Thomas F. Eisenmann,Anne-Marie Nussberger,Maxim Derex,Sara Bonati,Valerii Chirkov,Iyad Rahwan*

Main category: cs.CY

TL;DR: 本文指出，机器提出的非同凡响、易于学习且有明显优势的策略，能够被持久地传递和采纳，促进人类认知和文化的长期进步。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能在诸如围棋等领域已展现超越人类的能力，并逐渐从工具发展为人类文化创新的源泉，但尚不清楚哪些条件促使机器从简单工具转为持续文化变革的驱动力。

Method: 本文采用文化传递实验以及基于代理(agent-based)的模拟，研究了智能机器对人类问题解决能力和文化演变的影响。

Result: 验证了只有当机器发现的新策略具备非平凡性、可学习性和明显优势这三大条件时，才能在人群中实现传承和影响，从而引发持久的文化变化。

Conclusion: 当机器发现的策略具备非平凡性、可学习性和明显优势时，这些策略能够在人类群体中被传递、理解和保留，从而带来持续的文化转变。

Abstract: Intelligent machines with superhuman capabilities have the potential to
uncover problem-solving strategies beyond human discovery. Emerging evidence
from competitive gameplay, such as Go, demonstrates that AI systems are
evolving from mere tools to sources of cultural innovation adopted by humans.
However, the conditions under which intelligent machines transition from tools
to drivers of persistent cultural change remain unclear. We identify three key
conditions for machines to fundamentally influence human problem-solving: the
discovered strategies must be non-trivial, learnable, and offer a clear
advantage. Using a cultural transmission experiment and an agent-based
simulation, we demonstrate that when these conditions are met,
machine-discovered strategies can be transmitted, understood, and preserved by
human populations, leading to enduring cultural shifts. These findings provide
a framework for understanding how machines can persistently expand human
cognitive skills and underscore the need to consider their broader implications
for human cognition and cultural evolution.

</details>


### [258] [The value of human and machine in machine-generated creative contents](https://arxiv.org/abs/2506.17808)
*Weina Jin*

Main category: cs.CY

TL;DR: 机器生成内容的创造性离不开人的解释，人和机器共同完成有意义的内容创造。


<details>
  <summary>Details</summary>
Motivation: 当前对机器生成内容的“想象力”和“创造力”常被误归因于机器本身，忽视了人的作用。作者希望澄清人机在内容创造中的关系。

Method: 理论探讨与哲学分析，澄清人类解释在机器生成内容中的作用。

Result: 机器生成内容本身无法独立建立与现实和人类经验的连接，必须经过人的解释与认知才能成为有意义的创造。

Conclusion: 机器产生的“想象力”和“创造力”不是单方面成就，而是人机共同作用的产物。人类解释赋予了机器生成内容现实基础和意义。

Abstract: The seemingly "imagination" and "creativity" from machine-generated contents
should not be misattributed to the accomplishment of machine. They are
accomplishments of both human and machine. Without human interpretation, the
machine-generated contents remain in the imaginary space of the large language
models, and cannot automatically establish grounding in the reality and human
experience.

</details>


### [259] [The Democratic Paradox in Large Language Models' Underestimation of Press Freedom](https://arxiv.org/abs/2506.18045)
*I. Loaiza,R. Vestrelli,A. Fronzetti Colladon,R. Rigobon*

Main category: cs.CY

TL;DR: 主流大型语言模型普遍低估全球新闻自由状况，且对本国新闻自由有明显高估倾向。研究揭示了三种系统性偏差，说明LLMs在成为主流信息工具前需改进其公正性和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）正在成为全球数以百万计用户的信息获取中介，其在新闻自由等基础民主机构上的价值观和偏见会影响全球舆论与公众信任。该研究意在揭示LLMs在评估新闻自由时与人类专家存在的偏差，以及这些偏差对社会可能产生的影响。

Method: 作者分析了六款主流LLM，对于180个国家的新闻自由状况进行了评估，并与世界新闻自由指数（WPFI）专家评判进行了系统对比，识别模型中的系统性失真和偏见模式。

Result: 六款LLM全部存在负面错位，即普遍低估新闻自由；具体表现为这些模型将71%至93%的国家评为“新闻不自由”或低于专家评价。作者还发现“差异性错位”，即在新闻自由度高的国家，LLMs往往低估更严重。此外，大多数LLM对其“母国”表现出积极本土偏见，给母国打分高于全球基准，部分模型甚至高出7%至260%。

Conclusion: 如LLMs发展成为主流信息搜索和文化工具，其表现的人权与公民权利评判失真问题亟需关注并改进，否则将误导公众对新闻自由和民主制度的认知。

Abstract: As Large Language Models (LLMs) increasingly mediate global information
access for millions of users worldwide, their alignment and biases have the
potential to shape public understanding and trust in fundamental democratic
institutions, such as press freedom. In this study, we uncover three systematic
distortions in the way six popular LLMs evaluate press freedom in 180 countries
compared to expert assessments of the World Press Freedom Index (WPFI). The six
LLMs exhibit a negative misalignment, consistently underestimating press
freedom, with individual models rating between 71% to 93% of countries as less
free. We also identify a paradoxical pattern we term differential misalignment:
LLMs disproportionately underestimate press freedom in countries where it is
strongest. Additionally, five of the six LLMs exhibit positive home bias,
rating their home countries' press freedoms more favorably than would be
expected given their negative misalignment with the human benchmark. In some
cases, LLMs rate their home countries between 7% to 260% more positively than
expected. If LLMs are set to become the next search engines and some of the
most important cultural tools of our time, they must ensure accurate
representations of the state of our human and civic rights globally.

</details>


### [260] [Aggregated Individual Reporting for Post-Deployment Evaluation](https://arxiv.org/abs/2506.18133)
*Jessica Dai,Inioluwa Deborah Raji,Benjamin Recht,Irene Y. Chen*

Main category: cs.CY

TL;DR: 本文提出，将公众用户的个体报告聚合作为AI系统部署后动态评估的新机制（AIR），既提升AI安全和性能发现，也推动了“民主化”AI监管，提供有实践路径和研究指引。


<details>
  <summary>Details</summary>
Motivation: 近年来人们对AI系统部署后如何进行评估以及如何实现“民主”或“公众参与”的AI提出了更高要求。现有静态基准评测无法满足真实环境下复杂变化和个体体验的反馈需求。作者希望弥补这一评估盲区。

Method: 本文提出了一种基于个体公众报告汇总的后部署评估机制（Aggregated Individual Reporting, AIR），具体做法是让使用过某AI系统的用户直接报告他们遇到的问题，再将这些个体报告长期汇总分析，以细致评估系统表现，并提出具体设计流程和后续方法学发展的需求。

Result: 个体报告能带来对AI安全与性能具有重要价值的新发现，而报告的汇总又能有效指导实际操作。此框架为“民主化”AI提供了切实可行的解决路径，并有助于完善AI系统监管和评估的理论与实践体系。

Conclusion: 作者认为，个体体验应成为AI后部署阶段评估的重要组成部分，AIR机制既能丰富评估信息来源，也有助于实现更加‘民主’和负责任的AI发展。论文还提出了具体的实施思路和未来研究方向。

Abstract: The need for developing model evaluations beyond static benchmarking,
especially in the post-deployment phase, is now well-understood. At the same
time, concerns about the concentration of power in deployed AI systems have
sparked a keen interest in 'democratic' or 'public' AI. In this work, we bring
these two ideas together by proposing mechanisms for aggregated individual
reporting (AIR), a framework for post-deployment evaluation that relies on
individual reports from the public. An AIR mechanism allows those who interact
with a specific, deployed (AI) system to report when they feel that they may
have experienced something problematic; these reports are then aggregated over
time, with the goal of evaluating the relevant system in a fine-grained manner.
This position paper argues that individual experiences should be understood as
an integral part of post-deployment evaluation, and that the scope of our
proposed aggregated individual reporting mechanism is a practical path to that
end. On the one hand, individual reporting can identify substantively novel
insights about safety and performance; on the other, aggregation can be
uniquely useful for informing action. From a normative perspective, the
post-deployment phase completes a missing piece in the conversation about
'democratic' AI. As a pathway to implementation, we provide a workflow of
concrete design decisions and pointers to areas requiring further research and
methodological development.

</details>


<div id='q-fin.TR'></div>

# q-fin.TR [[Back]](#toc)

### [261] [Causal Interventions in Bond Multi-Dealer-to-Client Platforms](https://arxiv.org/abs/2506.18147)
*Paloma Marín,Sergio Ardanza-Trevijano,Javier Sabio*

Main category: q-fin.TR

TL;DR: 本文提出了一套用于多交易商对客户平台（MD2C）谈判分析的概率与机器学习模型框架，并通过实验展示其对定价与收益优化的实际效果，强调理解谈判机制的重要性。


<details>
  <summary>Details</summary>
Motivation: 金融市场数字化导致交易模式从语音转向电子化，多交易商对客户（MD2C）平台让客户可以同时向多个交易商请求报价（RfQ）。在此高度竞争但价格彼此不可见的环境下，交易商需要严谨地分析谈判过程以保持盈利。本文旨在为这一问题建立分析框架。

Method: 本文提出一种基于概率图模型与因果推断的通用分析框架，探讨RfQ流程中交易商的最优定价、潜在收益估算和客户识别等推断问题。同时，分析了两类模型：基于生成式模型（Fermanian, Guéant & Pu, 2017工作）和利用机器学习的判别式模型，并通过定价场景下的预测指标进行评估。

Result: 实验结果显示，不同模型在最优定价方面有不同表现，能够对实际MD2C平台交易商的定价策略与收益预测提供有效支持，并突出了理解谈判过程内部机制模型的优势。

Conclusion: 基于概率图模型和因果推断的分析框架能有效评估MD2C平台环境中交易商的多策略，帮助优化定价和提升收益，对实务具有应用价值。

Abstract: The digitalization of financial markets has shifted trading from voice to
electronic channels, with Multi-Dealer-to-Client (MD2C) platforms now enabling
clients to request quotes (RfQs) for financial instruments like bonds from
multiple dealers simultaneously. In this competitive landscape, dealers cannot
see each other's prices, making a rigorous analysis of the negotiation process
crucial to ensure their profitability. This article introduces a novel general
framework for analyzing the RfQ process using probabilistic graphical models
and causal inference. Within this framework, we explore different inferential
questions that are relevant for dealers participating in MD2C platforms, such
as the computation of optimal prices, estimating potential revenues and the
identification of clients that might be interested in trading the dealer's
axes. We then move into analyzing two different approaches for model
specification: a generative model built on the work of (Fermanian, Gu\'eant &
Pu, 2017); and discriminative models utilizing machine learning techniques. We
evaluate these methodologies using predictive metrics designed to assess their
effectiveness in the context of optimal pricing, highlighting the relative
benefits of using models that take into account the internal mechanisms of the
negotiation process.

</details>


### [262] [Causal Interventions in Bond Multi-Dealer-to-Client Platforms](https://arxiv.org/abs/2506.18147)
*Paloma Marín,Sergio Ardanza-Trevijano,Javier Sabio*

Main category: q-fin.TR

TL;DR: 本文针对多交易商到客户平台的报价竞争问题，提出基于概率图与因果推断的新分析框架，结合生成和判别模型，并评估了其在最优定价等任务中的有效性，为交易商实用价格策略制定提供理论与实证支持。


<details>
  <summary>Details</summary>
Motivation: 随着金融市场数字化发展，交易逐步从人工语音转向电子化渠道。多交易商到客户（MD2C）平台让客户能同时向多个交易商请求金融工具报价，令交易商间竞争加剧却又无法了解对方报价。因此，如何严谨分析议价过程、确保交易商盈利变得尤为紧迫和重要。

Method: 文中提出一种新颖的通用框架，采用概率图模型与因果推断分析MD2C平台上的RfQ过程。框架内同时探讨生成模型（如Fermanian等2017年工作基础上构建）与判别模型（利用机器学习技术）；并设计预测性评估指标衡量模型在最优定价等场景的效果。

Result: 通过实际评估，作者比较了生成模型与判别模型在最优定价及收益预测等任务中的表现，指出考虑议价内部机制的模型具有一定优势。框架能有效识别感兴趣客户并帮助交易商设定更优价格策略。

Conclusion: 文献展示了概率图模型和机器学习方法在MD2C平台报价分析和优化中的应用前景，为交易商利润最大化及客户挖掘提供了数据驱动的定量支持。

Abstract: The digitalization of financial markets has shifted trading from voice to
electronic channels, with Multi-Dealer-to-Client (MD2C) platforms now enabling
clients to request quotes (RfQs) for financial instruments like bonds from
multiple dealers simultaneously. In this competitive landscape, dealers cannot
see each other's prices, making a rigorous analysis of the negotiation process
crucial to ensure their profitability. This article introduces a novel general
framework for analyzing the RfQ process using probabilistic graphical models
and causal inference. Within this framework, we explore different inferential
questions that are relevant for dealers participating in MD2C platforms, such
as the computation of optimal prices, estimating potential revenues and the
identification of clients that might be interested in trading the dealer's
axes. We then move into analyzing two different approaches for model
specification: a generative model built on the work of (Fermanian, Gu\'eant &
Pu, 2017); and discriminative models utilizing machine learning techniques. We
evaluate these methodologies using predictive metrics designed to assess their
effectiveness in the context of optimal pricing, highlighting the relative
benefits of using models that take into account the internal mechanisms of the
negotiation process.

</details>
