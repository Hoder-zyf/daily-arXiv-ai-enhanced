{"id": "2507.05503", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2507.05503", "abs": "https://arxiv.org/abs/2507.05503", "authors": ["Jie Huang", "Daiheng Zhang"], "title": "MolFORM: Multi-modal Flow Matching for Structure-Based Drug Design", "comment": "Accepted to ICML 2025 genbio workshop", "summary": "Structure-based drug design (SBDD) seeks to generate molecules that bind\neffectively to protein targets by leveraging their 3D structural information.\nWhile diffusion-based generative models have become the predominant approach\nfor SBDD, alternative non-autoregressive frameworks remain relatively\nunderexplored. In this work, we introduce MolFORM, a novel generative framework\nthat jointly models discrete (atom types) and continuous (3D coordinates)\nmolecular modalities using multi-flow matching. To further enhance generation\nquality, we incorporate a preference-guided fine-tuning stage based on\n\\textit{Direct Preference Optimization} (DPO), using Vina score as a reward\nsignal. We propose a multi-modal flow DPO co-modeling strategy that\nsimultaneously aligns discrete and continuous modalities, leading to consistent\nimprovements across multiple evaluation metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u5206\u5b50\u751f\u6210\u6a21\u578bMolFORM\uff0c\u901a\u8fc7\u201c\u591a\u6d41\u5339\u914d+\u504f\u597d\u5f15\u5bfc\u4f18\u5316\u201d\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u5206\u5b50\u7c7b\u578b\u4e0e\u4e09\u7ef4\u7a7a\u95f4\u8054\u5408\u9ad8\u6548\u5efa\u6a21\uff0c\u5728\u7ed3\u6784\u836f\u7269\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u6bd4\u4e3b\u6d41\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u7ed3\u6784\u57fa\u7840\u836f\u7269\u8bbe\u8ba1\uff08SBDD\uff09\u901a\u8fc7\u5229\u7528\u86cb\u767d\u8d28\u9776\u6807\u7684\u4e09\u7ef4\u7ed3\u6784\u4fe1\u606f\uff0c\u751f\u6210\u4e0e\u4e4b\u6709\u6548\u7ed3\u5408\u7684\u5206\u5b50\u3002\u7136\u800c\uff0c\u76ee\u524d\u4e3b\u6d41\u65b9\u6cd5\u4ee5\u6269\u6563\u751f\u6210\u6a21\u578b\u4e3a\u4e3b\uff0c\u975e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u65b9\u6cd5\u4ecd\u7136\u8f83\u5c11\u88ab\u7814\u7a76\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u6846\u67b6MolFORM\uff0c\u901a\u8fc7\u591a\u6d41\u5339\u914d\u540c\u65f6\u5efa\u6a21\u5206\u5b50\u7684\u79bb\u6563\uff08\u539f\u5b50\u7c7b\u578b\uff09\u548c\u8fde\u7eed\uff08\u4e09\u7ef4\u5750\u6807\uff09\u6a21\u6001\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u7684\u504f\u597d\u5f15\u5bfc\u5fae\u8c03\u65b9\u6cd5\uff0c\u5e76\u4ee5Vina\u8bc4\u5206\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u3002\u63d0\u51fa\u7684\u591a\u6a21\u6001\u6d41DPO\u534f\u540c\u5efa\u6a21\u7b56\u7565\u53ef\u4ee5\u540c\u65f6\u5bf9\u9f50\u79bb\u6563\u548c\u8fde\u7eed\u6a21\u6001\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u5747\u53d6\u5f97\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0c\u751f\u6210\u5206\u5b50\u7684\u8d28\u91cf\u6709\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "MolFORM\u80fd\u591f\u6709\u6548\u63d0\u5347\u5206\u5b50\u751f\u6210\u8d28\u91cf\uff0c\u5b9e\u73b0\u4e86\u79bb\u6563\u548c\u8fde\u7eed\u6a21\u6001\u7684\u534f\u540c\u4f18\u5316\uff0c\u4e3a\u7ed3\u6784\u57fa\u7840\u836f\u7269\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u9ad8\u6548\u65b9\u6cd5\u3002"}}
{"id": "2507.05659", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2507.05659", "abs": "https://arxiv.org/abs/2507.05659", "authors": ["Alexandre Friou"], "title": "MCNP-GO: A python package for assembling MCNP input files with a systems engineering approach", "comment": "Submitted to Nuclear Engineering and Technology", "summary": "This article introduces MCNP-GO (https://github.com/afriou/mcnpgo), a Python\npackage designed to manipulate and assemble MCNP input files, allowing users to\nassemble a set of independent objects, each described by a valid MCNP file,\ninto a single cohesive file. This tool is particularly useful for applications\nwhere precise modeling and positioning of equipment are crucial. The package\naddresses the challenges of managing large databases of MCNP input files,\nensuring reliability and traceability through configuration management systems.\nMCNP-GO provides functionalities such as renumbering, extracting subsets of\nfiles, transforming files, and assembling files while managing collisions and\nmaterials. It also keeps track of the operations performed on files, enhancing\ntraceability and ease of modification. The article demonstrates the package's\ncapabilities through a practical example of assembling an MCNP input file for a\ntomographic experiment, highlighting its efficiency and user-friendliness.\nMCNP-GO is designed for users with minimal Python knowledge.", "AI": {"tldr": "MCNP-GO\u662f\u4e00\u4e2a\u4fbf\u6377\u9ad8\u6548\u7684Python\u5305\uff0c\u53ef\u81ea\u52a8\u5316\u5730\u7ec4\u88c5\u4e0e\u7ba1\u7406MCNP\u8f93\u5165\u6587\u4ef6\uff0c\u652f\u6301\u8ffd\u8e2a\u4e0e\u64cd\u4f5c\u5386\u53f2\uff0c\u5927\u5e45\u63d0\u5347\u6a21\u578b\u6784\u5efa\u6548\u7387\uff0c\u5bf9\u975e\u7f16\u7a0b\u7528\u6237\u53cb\u597d\u3002", "motivation": "MCNP\u8f93\u5165\u6587\u4ef6\u7684\u7ba1\u7406\u548c\u7ec4\u88c5\u5728\u7cbe\u786e\u5efa\u6a21\u548c\u8bbe\u5907\u5b9a\u4f4d\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u5927\u578b\u6587\u4ef6\u5e93\u3001\u4fdd\u6301\u53ef\u9760\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u7b49\u65b9\u9762\u5b58\u5728\u96be\u9898\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f00\u53d1\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u5347\u6548\u7387\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "method": "\u5f00\u53d1\u4e86MCNP-GO\uff0c\u4e00\u4e2aPython\u5305\uff0c\u652f\u6301\u72ec\u7acbMCNP\u5bf9\u8c61\u8f93\u5165\u6587\u4ef6\u7684\u81ea\u52a8\u7ec4\u88c5\uff0c\u5305\u62ec\u91cd\u7f16\u53f7\u3001\u6587\u4ef6\u63d0\u53d6\u3001\u53d8\u6362\u3001\u78b0\u649e\u53ca\u6750\u6599\u7ba1\u7406\uff0c\u5e76\u8bb0\u5f55\u6240\u6709\u64cd\u4f5c\u6d41\u7a0b\uff0c\u4ee5\u5b9e\u73b0\u6613\u4fee\u6539\u548c\u53ef\u8ffd\u6eaf\u3002\u529f\u80fd\u901a\u8fc7\u65ad\u5c42\u5b9e\u9a8c\u7684MCNP\u8f93\u5165\u7ec4\u88c5\u8303\u4f8b\u8fdb\u884c\u6f14\u793a\u3002", "result": "MCNP-GO\u5b9e\u73b0\u4e86MCNP\u8f93\u5165\u6587\u4ef6\u7684\u9ad8\u6548\u7ec4\u88c5\u3001\u81ea\u52a8\u53d8\u6362\u4e0e\u7ba1\u7406\uff0c\u6709\u6548\u7b80\u5316\u4e86\u6d41\u7a0b\uff0c\u63d0\u9ad8\u4e86\u5927\u578bMCNP\u6570\u636e\u5e93\u7684\u7ba1\u7406\u6548\u7387\u4e0e\u53ef\u9760\u6027\uff0c\u7528\u6237\u53ea\u9700\u6781\u5c11\u7684Python\u77e5\u8bc6\u5373\u53ef\u4f7f\u7528\u3002", "conclusion": "MCNP-GO\u4e3a\u9700\u8981\u7cbe\u786e\u5efa\u6a21\u4e0e\u5b9a\u4f4d\u7684\u5e94\u7528\u573a\u5408\u63d0\u4f9b\u4e86\u5b9e\u7528\u9ad8\u6548\u7684\u81ea\u52a8\u5316MCNP\u8f93\u5165\u6587\u4ef6\u7ba1\u7406\u5de5\u5177\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u5de5\u4f5c\u6548\u7387\u548c\u6587\u4ef6\u7ba1\u7406\u7684\u53ef\u8ffd\u6eaf\u6027\uff0c\u9002\u7528\u4e8e\u975e\u7a0b\u5e8f\u5458\u7528\u6237\u3002"}}
{"id": "2507.06133", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2507.06133", "abs": "https://arxiv.org/abs/2507.06133", "authors": ["Jaewan Park", "Farid Ahmed", "Kazuma Kobayashi", "Seid Koric", "Syed Bahauddin Alam", "Iwona Jasiuk", "Diab Abueidda"], "title": "Bridging Sequential Deep Operator Network and Video Diffusion: Residual Refinement of Spatio-Temporal PDE Solutions", "comment": null, "summary": "Video-diffusion models have recently set the standard in video generation,\ninpainting, and domain translation thanks to their training stability and high\nperceptual fidelity. Building on these strengths, we repurpose conditional\nvideo diffusion as a physics surrogate for spatio-temporal fields governed by\npartial differential equations (PDEs). Our two-stage surrogate first applies a\nSequential Deep Operator Network (S-DeepONet) to produce a coarse,\nphysics-consistent prior from the prescribed boundary or loading conditions.\nThe prior is then passed to a conditional video diffusion model that learns\nonly the residual: the point-wise difference between the ground truth and the\nS-DeepONet prediction. By shifting the learning burden from the full solution\nto its much smaller residual space, diffusion can focus on sharpening\nhigh-frequency structures without sacrificing global coherence. The framework\nis assessed on two disparate benchmarks: (i) vortex-dominated lid-driven cavity\nflow and (ii) tensile plastic deformation of dogbone specimens. Across these\ndata sets the hybrid surrogate consistently outperforms its single-stage\ncounterpart, cutting the mean relative L2 error from 4.57% to 0.83% for the\nflow problem and from 4.42% to 2.94% for plasticity, a relative improvements of\n81.8% and 33.5% respectively. The hybrid approach not only lowers quantitative\nerrors but also improves visual quality, visibly recovering fine spatial\ndetails. These results show that (i) conditioning diffusion on a physics-aware\nprior enables faithful reconstruction of localized features, (ii) residual\nlearning reduces the problem, accelerating convergence and enhancing accuracy,\nand (iii) the same architecture transfers seamlessly from incompressible flow\nto nonlinear elasto-plasticity without problem-specific architectural\nmodifications, highlighting its broad applicability to nonlinear,\ntime-dependent continua.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7269\u7406\u5148\u9a8c\u7684\u6761\u4ef6\u89c6\u9891\u6269\u6563\u6b8b\u5dee\u5b66\u4e60\u65b0\u6846\u67b6\uff0c\u5728\u590d\u6742\u591a\u7269\u7406\u573a\u65f6\u7a7a\u5efa\u6a21\u4efb\u52a1\u4e0a\u53d6\u5f97\u5927\u5e45\u7cbe\u5ea6\u548c\u7ec6\u8282\u63d0\u5347\uff0c\u4e14\u5177\u6709\u5f88\u5f3a\u7684\u901a\u7528\u6027\u548c\u9ad8\u6548\u6027\u3002", "motivation": "\u89c6\u9891\u6269\u6563\u6a21\u578b\u5728\u9ad8\u611f\u77e5\u4fdd\u771f\u5ea6\u548c\u7a33\u5b9a\u8bad\u7ec3\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5728\u7a7a\u95f4-\u65f6\u95f4\u8fde\u7eed\u4ecb\u8d28\u7269\u7406\u5efa\u6a21\u4e0a\u7684\u6f5c\u529b\u5c1a\u672a\u88ab\u5145\u5206\u6316\u6398\u3002\u73b0\u6709\u76f4\u63a5\u5efa\u6a21\u5168\u89e3\u7684\u65b9\u5f0f\u5b66\u4e60\u96be\u5ea6\u5927\uff0c\u96be\u4ee5\u51c6\u786e\u6355\u6349\u9ad8\u9891\u5c40\u90e8\u7ed3\u6784\u3002\u8be5\u6587\u5e0c\u671b\u901a\u8fc7\u7ed3\u5408\u7269\u7406\u5148\u9a8c\u548c\u6b8b\u5dee\u5b66\u4e60\uff0c\u63d0\u5347\u6a21\u578b\u5728\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u95ee\u9898\u4e0a\u7684\u7cbe\u5ea6\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u9636\u6bb5\u6df7\u5408\u7269\u7406\u66ff\u4ee3\u5efa\u6a21\u6846\u67b6\u3002\u7b2c\u4e00\u9636\u6bb5\u7531\u987a\u5e8f\u6df1\u7b97\u5b50\u7f51\u7edc\uff08S-DeepONet\uff09\u6839\u636e\u8fb9\u754c\u6216\u8f7d\u8377\u6761\u4ef6\u5feb\u901f\u9884\u6d4b\u7269\u7406\u4e00\u81f4\u6027\u7684\u7c97\u7565\u89e3\u4f5c\u4e3a\u5148\u9a8c\u3002\u7b2c\u4e8c\u9636\u6bb5\uff0c\u5c06\u5148\u9a8c\u8f93\u5165\u5230\u6761\u4ef6\u89c6\u9891\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u4ec5\u5b66\u4e60\u6b8b\u5dee\u2014\u2014\u5373\u9884\u6d4b\u4e0e\u771f\u5b9e\u89e3\u7684\u9010\u70b9\u5dee\u5f02\uff0c\u7531\u6b64\u8ba9\u6269\u6563\u6a21\u578b\u4e13\u6ce8\u4e8e\u9ad8\u9891\u7ec6\u8282\u91cd\u5efa\uff0c\u63d0\u9ad8\u6574\u4f53\u7cbe\u5ea6\u4e0e\u89c6\u89c9\u8d28\u91cf\u3002\u65b9\u6cd5\u5728\u4e24\u7c7b\u57fa\u51c6\u4efb\u52a1\u4e0a\u9a8c\u8bc1\uff1a\u6709\u6da1\u8154\u6d41\u548c\u6750\u6599\u7684\u62c9\u4f38\u5851\u6027\u53d8\u5f62\u3002", "result": "\u4e0e\u4ec5\u7528\u5355\u4e00\u6a21\u578b\u76f8\u6bd4\uff0c\u6df7\u5408\u6a21\u578b\u5728\u4e24\u4e2a\u4efb\u52a1\u4e0a\u5747\u5927\u5e45\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002\u8154\u6d41\u95ee\u9898\u7684\u5e73\u5747\u76f8\u5bf9L2\u8bef\u5dee\u75314.57%\u964d\u81f30.83%\uff0c\u5851\u6027\u95ee\u9898\u75314.42%\u964d\u81f32.94%\uff0c\u76f8\u5bf9\u63d0\u5347\u5206\u522b\u4e3a81.8%\u548c33.5%\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u80fd\u66f4\u597d\u4fdd\u7559\u9ad8\u9891\u5c40\u90e8\u7ec6\u8282\uff0c\u89c6\u89c9\u6548\u679c\u663e\u8457\u6539\u5584\uff0c\u5e76\u4e14\u65e0\u9700\u9488\u5bf9\u4e0d\u540c\u7269\u7406\u95ee\u9898\u505a\u6a21\u578b\u7ed3\u6784\u8c03\u6574\uff0c\u6cdb\u5316\u80fd\u529b\u5f3a\u3002", "conclusion": "\u5c06\u6761\u4ef6\u89c6\u9891\u6269\u6563\u6a21\u578b\u8026\u5408\u7269\u7406\u5148\u9a8c\u5e76\u8fdb\u884c\u6b8b\u5dee\u5b66\u4e60\uff0c\u6781\u5927\u63d0\u5347\u4e86\u975e\u7ebf\u6027\u65f6\u95f4\u76f8\u5173PDE\u95ee\u9898\u7684\u5efa\u6a21\u7cbe\u5ea6\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u7ec6\u8282\u91cd\u5efa\u80fd\u529b\u548c\u65b9\u6cd5\u7684\u901a\u7528\u6027\u3002\u8be5\u67b6\u6784\u8868\u73b0\u51fa\u826f\u597d\u7684\u8de8\u7269\u7406\u573a\u6cdb\u5316\u80fd\u529b\u548c\u9ad8\u6548\u6536\u655b\u7279\u6027\u3002"}}
{"id": "2507.05816", "categories": ["cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05816", "abs": "https://arxiv.org/abs/2507.05816", "authors": ["Shuai Zhao", "Yulin Zhang", "Luwei Xiao", "Xinyi Wu", "Yanhao Jia", "Zhongliang Guo", "Xiaobao Wu", "Cong-Duy Nguyen", "Guoming Zhang", "Anh Tuan Luu"], "title": "Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy of Prematurity", "comment": null, "summary": "Despite the remarkable progress of large language models (LLMs) across\nvarious domains, their capacity to predict retinopathy of prematurity (ROP)\nrisk remains largely unexplored. To address this gap, we introduce a novel\nChinese benchmark dataset, termed CROP, comprising 993 admission records\nannotated with low, medium, and high-risk labels. To systematically examine the\npredictive capabilities and affective biases of LLMs in ROP risk\nstratification, we propose Affective-ROPTester, an automated evaluation\nframework incorporating three prompting strategies: Instruction-based,\nChain-of-Thought (CoT), and In-Context Learning (ICL). The Instruction scheme\nassesses LLMs' intrinsic knowledge and associated biases, whereas the CoT and\nICL schemes leverage external medical knowledge to enhance predictive accuracy.\nCrucially, we integrate emotional elements at the prompt level to investigate\nhow different affective framings influence the model's ability to predict ROP\nand its bias patterns. Empirical results derived from the CROP dataset yield\ntwo principal observations. First, LLMs demonstrate limited efficacy in ROP\nrisk prediction when operating solely on intrinsic knowledge, yet exhibit\nmarked performance gains when augmented with structured external inputs.\nSecond, affective biases are evident in the model outputs, with a consistent\ninclination toward overestimating medium- and high-risk cases. Third, compared\nto negative emotions, positive emotional framing contributes to mitigating\npredictive bias in model outputs. These findings highlight the critical role of\naffect-sensitive prompt engineering in enhancing diagnostic reliability and\nemphasize the utility of Affective-ROPTester as a framework for evaluating and\nmitigating affective bias in clinical language modeling systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCROP\u6570\u636e\u96c6\u548cAffective-ROPTester\u8bc4\u6d4b\u6846\u67b6\uff0c\u53d1\u73b0\u5927\u6a21\u578b\u9700\u5916\u90e8\u77e5\u8bc6\u8f85\u52a9\u624d\u80fd\u63d0\u9ad8\u65e9\u4ea7\u513f\u89c6\u7f51\u819c\u75c5\u53d8\u98ce\u9669\u9884\u6d4b\u80fd\u529b\uff0c\u4e14\u901a\u8fc7\u6b63\u9762\u60c5\u611f\u63d0\u793a\u53ef\u6709\u6548\u7f13\u89e3\u6a21\u578b\u504f\u5dee\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bb8\u591a\u9886\u57df\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5176\u5bf9\u65e9\u4ea7\u513f\u89c6\u7f51\u819c\u75c5\u53d8\u98ce\u9669\u9884\u6d4b\u7684\u80fd\u529b\u5c1a\u672a\u88ab\u7cfb\u7edf\u7814\u7a76\uff0c\u9700\u8981\u5efa\u7acb\u57fa\u51c6\u6570\u636e\u96c6\u53ca\u8bc4\u6d4b\u6846\u67b6\u6765\u586b\u8865\u8be5\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u4e86CROP\u4e2d\u6587\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1Affective-ROPTester\u81ea\u52a8\u8bc4\u6d4b\u6846\u67b6\uff0c\u91c7\u7528\u4e09\u79cd\u63d0\u793a\u7b56\u7565\uff08\u76f4\u63a5\u6307\u4ee4\u3001\u94fe\u5f0f\u601d\u7ef4\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\uff09\uff0c\u7ed3\u5408\u60c5\u611f\u8c03\u63a7\uff0c\u4ece\u4e0d\u540c\u89d2\u5ea6\u8003\u5bdf\u5927\u6a21\u578b\u9884\u6d4b\u65e9\u4ea7\u513f\u89c6\u7f51\u819c\u75c5\u53d8\u98ce\u9669\u7684\u80fd\u529b\u4e0e\u504f\u501a\u3002", "result": "1) \u5927\u6a21\u578b\u4f9d\u8d56\u81ea\u8eab\u77e5\u8bc6\u65f6\u5bf9ROP\u98ce\u9669\u9884\u6d4b\u6548\u679c\u6709\u9650\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u5916\u90e8\u8f93\u5165\u540e\u6027\u80fd\u663e\u8457\u63d0\u5347\uff1b2) \u6a21\u578b\u5bf9\u4e2d\u9ad8\u98ce\u9669\u6709\u9ad8\u4f30\u503e\u5411\uff0c\u5b58\u5728\u60c5\u611f\u504f\u5dee\uff1b3) \u6b63\u9762\u60c5\u611f\u5316\u63d0\u793a\u6709\u52a9\u4e8e\u7f13\u89e3\u9884\u6d4b\u504f\u5dee\u3002", "conclusion": "\u60c5\u611f\u654f\u611f\u6027\u63d0\u793a\u5de5\u7a0b\u53ef\u4ee5\u63d0\u5347\u8bca\u65ad\u53ef\u9760\u6027\uff0cAffective-ROPTester\u4e3a\u8bc4\u4f30\u548c\u7f13\u89e3\u4e34\u5e8a\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u60c5\u611f\u504f\u5dee\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2507.05275", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LO", "cs.MA", "D.2.4; K.3.1; C.3; I.2.6"], "pdf": "https://arxiv.org/pdf/2507.05275", "abs": "https://arxiv.org/abs/2507.05275", "authors": ["Weibing Zheng", "Laurah Turner", "Jess Kropczynski", "Murat Ozer", "Seth Overla", "Shane Halse"], "title": "A Fuzzy Supervisor Agent Design for Clinical Reasoning Assistance in a Multi-Agent Educational Clinical Scenario Simulation", "comment": "6 pages, 3 figures, 1 table. 2025 IFSA World Congress NAFIPS Annual\n  Meeting", "summary": "Assisting medical students with clinical reasoning (CR) during clinical\nscenario training remains a persistent challenge in medical education. This\npaper presents the design and architecture of the Fuzzy Supervisor Agent (FSA),\na novel component for the Multi-Agent Educational Clinical Scenario Simulation\n(MAECSS) platform. The FSA leverages a Fuzzy Inference System (FIS) to\ncontinuously interpret student interactions with specialized clinical agents\n(e.g., patient, physical exam, diagnostic, intervention) using pre-defined\nfuzzy rule bases for professionalism, medical relevance, ethical behavior, and\ncontextual distraction. By analyzing student decision-making processes in\nreal-time, the FSA is designed to deliver adaptive, context-aware feedback and\nprovides assistance precisely when students encounter difficulties. This work\nfocuses on the technical framework and rationale of the FSA, highlighting its\npotential to provide scalable, flexible, and human-like supervision in\nsimulation-based medical education. Future work will include empirical\nevaluation and integration into broader educational settings. More detailed\ndesign and implementation is~\\href{https://github.com/2sigmaEdTech/MAS/}{open\nsourced here}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u7684\u667a\u80fd\u76d1\u7763\u4ee3\u7406FSA\uff0c\u53ef\u5728\u533b\u5b66\u6559\u80b2\u6a21\u62df\u4e2d\u5b9e\u65f6\u8f85\u52a9\u5b66\u751f\u4e34\u5e8a\u63a8\u7406\uff0c\u5177\u5907\u53ef\u6269\u5c55\u6027\u548c\u7075\u6d3b\u6027\uff0c\u9884\u8ba1\u5c06\u663e\u8457\u63d0\u5347\u6559\u5b66\u6548\u679c\uff0c\u5177\u4f53\u5b9e\u73b0\u5df2\u5f00\u6e90\uff0c\u540e\u7eed\u5c06\u9a8c\u8bc1\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u5728\u533b\u5b66\u6559\u80b2\u4e2d\uff0c\u5982\u4f55\u5728\u4e34\u5e8a\u573a\u666f\u8bad\u7ec3\u4e2d\u6709\u6548\u8f85\u52a9\u533b\u5b66\u751f\u8fdb\u884c\u4e34\u5e8a\u63a8\u7406\u4e00\u76f4\u662f\u4e00\u4e2a\u96be\u9898\u3002\u73b0\u6709\u6559\u5b66\u7cfb\u7edf\u5bf9\u4e8e\u5b9e\u65f6\u3001\u4e2a\u6027\u5316\u548c\u573a\u666f\u76f8\u5173\u7684\u5f15\u5bfc\u5b58\u5728\u4e0d\u8db3\uff0c\u96be\u4ee5\u6ee1\u8db3\u5927\u89c4\u6a21\u9ad8\u6548\u6307\u5bfc\u7684\u9700\u6c42\u3002", "method": "\u672c\u6587\u63d0\u51fa\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6a21\u7cca\u76d1\u7763\u4ee3\u7406\uff08FSA\uff09\uff0c\u96c6\u6210\u4e8e\u591a\u4ee3\u7406\u6559\u80b2\u4e34\u5e8a\u573a\u666f\u4eff\u771f\uff08MAECSS\uff09\u5e73\u53f0\u4e2d\u3002FSA\u5229\u7528\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\uff08FIS\uff09\uff0c\u57fa\u4e8e\u4e13\u4e1a\u6027\u3001\u533b\u5b66\u76f8\u5173\u6027\u3001\u4f26\u7406\u884c\u4e3a\u548c\u60c5\u5883\u5e72\u6270\u7b49\u9884\u5b9a\u4e49\u6a21\u7cca\u89c4\u5219\uff0c\u5b9e\u65f6\u89e3\u6790\u5b66\u751f\u4e0e\u5404\u7c7b\u4e34\u5e8a\u4ee3\u7406\uff08\u5982\u75c5\u4eba\u3001\u4f53\u68c0\u3001\u8bca\u65ad\u3001\u5e72\u9884\uff09\u7684\u4ea4\u4e92\uff0c\u5206\u6790\u5176\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4ece\u800c\u63d0\u4f9b\u81ea\u9002\u5e94\u3001\u60c5\u5883\u611f\u77e5\u7684\u53cd\u9988\u548c\u5e2e\u52a9\u3002", "result": "\u76ee\u524d\u5de5\u4f5c\u4fa7\u91cd\u4e8eFSA\u6280\u672f\u6846\u67b6\u548c\u8bbe\u8ba1\u539f\u7406\u7684\u8bba\u8ff0\uff0c\u7a81\u51fa\u5176\u53ef\u80fd\u4e3a\u6a21\u62df\u533b\u5b66\u6559\u80b2\u5e26\u6765\u53ef\u6269\u5c55\u3001\u7075\u6d3b\u53ca\u7c7b\u4eba\u5316\u76d1\u7763\u7684\u6f5c\u529b\u3002\u5177\u4f53\u5b9e\u73b0\u7ec6\u8282\u5df2\u5f00\u6e90\uff0c\u540e\u7eed\u5c06\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u548c\u66f4\u5e7f\u6cdb\u7684\u96c6\u6210\u5e94\u7528\u3002", "conclusion": "FSA\u7cfb\u7edf\u6709\u671b\u4e3a\u533b\u5b66\u6559\u80b2\u4e2d\u7684\u4e34\u5e8a\u573a\u666f\u6a21\u62df\u63d0\u4f9b\u667a\u80fd\u5316\u3001\u53ca\u65f6\u548c\u4e2a\u6027\u5316\u7684\u8f85\u52a9\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5b66\u751f\u7684\u4e34\u5e8a\u63a8\u7406\u80fd\u529b\u548c\u573a\u666f\u9002\u5e94\u529b\u3002\u7136\u800c\u5b9e\u9645\u6548\u679c\u8fd8\u6709\u5f85\u540e\u7eed\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u548c\u63a8\u5e7f\u3002"}}
{"id": "2507.05261", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05261", "abs": "https://arxiv.org/abs/2507.05261", "authors": ["Yingtai Xiao", "Yuqing Zhu", "Sirat Samyoun", "Wanrong Zhang", "Jiachen T. Wang", "Jian Du"], "title": "TokenShapley: Token Level Context Attribution with Shapley Value", "comment": null, "summary": "Large language models (LLMs) demonstrate strong capabilities in in-context\nlearning, but verifying the correctness of their generated responses remains a\nchallenge. Prior work has explored attribution at the sentence level, but these\nmethods fall short when users seek attribution for specific keywords within the\nresponse, such as numbers, years, or names. To address this limitation, we\npropose TokenShapley, a novel token-level attribution method that combines\nShapley value-based data attribution with KNN-based retrieval techniques\ninspired by recent advances in KNN-augmented LLMs. By leveraging a precomputed\ndatastore for contextual retrieval and computing Shapley values to quantify\ntoken importance, TokenShapley provides a fine-grained data attribution\napproach. Extensive evaluations on four benchmarks show that TokenShapley\noutperforms state-of-the-art baselines in token-level attribution, achieving an\n11-23% improvement in accuracy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86TokenShapley\uff0c\u4e00\u79cd\u7ed3\u5408Shapley\u503c\u4e0eKNN\u68c0\u7d22\u7684token\u7ea7\u522b\u6eaf\u6e90\u65b9\u6cd5\uff0c\u5728\u56db\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5927\u6a21\u578b\u8f93\u51fa\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u4e0a\u4e0b\u6587\u548c\u751f\u6210\u5185\u5bb9\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u8f93\u51fa\u7ed3\u679c\u7684\u6b63\u786e\u6027\u9a8c\u8bc1\u5b58\u5728\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5728\u7528\u6237\u9700\u8981\u5bf9\u5177\u4f53\u5173\u952e\u8bcd\uff08\u5982\u6570\u5b57\u3001\u5e74\u4efd\u6216\u59d3\u540d\uff09\u8fdb\u884c\u6eaf\u6e90\u65f6\uff0c\u73b0\u6709\u7684\u53e5\u5b50\u7ea7\u5f52\u56e0\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u7cbe\u7ec6\u5316\u9700\u6c42\u3002", "method": "\u63d0\u51faTokenShapley\u65b9\u6cd5\uff0c\u5c06\u57fa\u4e8eShapley\u503c\u7684\u6570\u636e\u5f52\u56e0\u4e0eKNN\u68c0\u7d22\u6280\u672f\u7ed3\u5408\uff0c\u901a\u8fc7\u4f7f\u7528\u9884\u5148\u8ba1\u7b97\u7684\u6570\u636e\u5b58\u50a8\u8fdb\u884c\u4e0a\u4e0b\u6587\u68c0\u7d22\uff0c\u5e76\u8ba1\u7b97Shapley\u503c\u4ee5\u91cf\u5316\u6bcf\u4e2atoken\u7684\u91cd\u8981\u6027\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u6570\u636e\u5f52\u56e0\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cTokenShapley\u5728token\u7ea7\u522b\u5f52\u56e0\u51c6\u786e\u7387\u65b9\u9762\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u6709\u6240\u63d0\u5347\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e8611-23%\u3002", "conclusion": "TokenShapley\u80fd\u591f\u66f4\u7cbe\u7ec6\u51c6\u786e\u5730\u4e3aLLM\u8f93\u51fa\u7ed3\u679c\u4e2d\u7684\u5173\u952e\u8bcd\u63d0\u4f9b\u51fa\u5904\u5f52\u56e0\uff0c\u4e3a\u63d0\u9ad8\u5927\u6a21\u578b\u8f93\u51fa\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.05267", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05267", "abs": "https://arxiv.org/abs/2507.05267", "authors": ["Markus B\u00f6ck"], "title": "Strongly Solving $7 \\times 6$ Connect-Four on Consumer Grade Hardware", "comment": null, "summary": "While the game Connect-Four has been solved mathematically and the best move\ncan be effectively computed with search based methods, a strong solution in the\nform of a look-up table was believed to be infeasible. In this paper, we\nrevisit a symbolic search method based on binary decision diagrams to produce\nstrong solutions. With our efficient implementation we were able to produce a\n89.6 GB large look-up table in 47 hours on a single CPU core with 128 GB main\nmemory for the standard $7 \\times 6$ board size. In addition to this\nwin-draw-loss evaluation, we include an alpha-beta search in our open source\nartifact to find the move which achieves the fastest win or slowest loss.", "AI": {"tldr": "\u4f5c\u8005\u5229\u7528\u9ad8\u6548\u7684\u7b26\u53f7\u641c\u7d22\uff0c\u9996\u6b21\u5728\u5355\u6838\u5927\u5185\u5b58\u673a\u5668\u4e0a\u5b9e\u73b0\u4e86Connect-Four\u7684\u5f3a\u89e3\u67e5\u8be2\u8868\u751f\u6210\uff0c\u5e76\u5f00\u6e90\u4e86\u53ef\u7528\u4e8e\u6700\u4f18\u8def\u5f84\u641c\u7d22\u7684\u5de5\u5177\u3002", "motivation": "\u5c3d\u7ba1Connect-Four\u6e38\u620f\u5df2\u7ecf\u901a\u8fc7\u6570\u5b66\u65b9\u6cd5\u88ab\u89e3\u51b3\uff0c\u5e76\u4e14\u53ef\u4ee5\u4f7f\u7528\u57fa\u4e8e\u641c\u7d22\u7684\u65b9\u6cd5\u6709\u6548\u5730\u8ba1\u7b97\u6700\u4f73\u8d70\u6cd5\uff0c\u4f46\u5236\u4f5c\u4e00\u4e2a\u67e5\u8be2\u8868\uff08look-up table\uff09\u5f62\u5f0f\u7684\u5f3a\u89e3\u4e00\u76f4\u88ab\u8ba4\u4e3a\u662f\u96be\u4ee5\u5b9e\u73b0\u7684\u3002\u4f5c\u8005\u5e0c\u671b\u7a81\u7834\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u4f5c\u8005\u5229\u7528\u57fa\u4e8e\u4e8c\u5143\u51b3\u7b56\u56fe\uff08binary decision diagrams, BDD\uff09\u7684\u7b26\u53f7\u641c\u7d22\u65b9\u6cd5\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u5728\u4e00\u53f0\u914d\u6709128GB\u5185\u5b58\u7684\u5355\u6838CPU\u4e0a\u8fdb\u884c\u4e86\u8ba1\u7b97\u3002", "result": "\u4f5c\u8005\u6210\u529f\u4e3a\u6807\u51c67\u00d76\u68cb\u76d8\u89c4\u6a21\u751f\u6210\u4e86\u4e00\u4e2a89.6GB\u7684\u5927\u578b\u67e5\u8be2\u8868\uff0c\u4ec5\u752847\u5c0f\u65f6\u5b8c\u6210\uff0c\u5bf9\u6bcf\u79cd\u5c40\u9762\u53ef\u4ee5\u5b9e\u73b0\u80dc-\u548c-\u8d1f\u7684\u8bc4\u4f30\u3002\u6b64\u5916\uff0c\u5f00\u6e90\u4ee3\u7801\u8fd8\u96c6\u6210\u4e86alpha-beta\u641c\u7d22\uff0c\u53ef\u627e\u5230\u6700\u5feb\u80dc\u6216\u6700\u6162\u8d25\u7684\u8d70\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u7b26\u53f7\u641c\u7d22\u4e0e\u9ad8\u6548\u5b9e\u73b0\uff0c\u6210\u529f\u4e3aConnect-Four\u751f\u6210\u4e86\u5f3a\u89e3\u67e5\u8be2\u8868\uff0c\u63d0\u5347\u4e86\u5bf9\u8be5\u6e38\u620f\u89e3\u7a7a\u95f4\u7684\u5b9e\u7528\u8bbf\u95ee\u80fd\u529b\uff0c\u4e5f\u4e3a\u76f8\u5173\u95ee\u9898\u63d0\u4f9b\u4e86\u53c2\u8003\u65b9\u6cd5\u3002"}}
{"id": "2507.05280", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05280", "abs": "https://arxiv.org/abs/2507.05280", "authors": ["Andr\u00e1s Ferenczy"], "title": "Hungary and AI: efforts and opportunities in comparison with Singapore", "comment": "39 pages", "summary": "The study assesses Hungary's National AI Strategy and its implementation\nthrough the analysis of strategic documents, publicly available financial\nrecords, and expert interviews with the Hungarian AI Coalition President and\nChief Strategic Advisor to the Government Commissioner for AI. 22 goals from\nHungary's strategy were evaluated through conceptual, governance, temporal, and\nfinancial dimensions before being benchmarked against Singapore's National AI\nStrategies (NAIS 1.0 and NAIS 2.0). Key findings include an estimated total of\nEUR 4.65 billion in AI-related public investment in Hungary. Openly available\nfinancial data was found for only half of the evaluated goals, and just three\nprojects made up 98\\% of all documented funding. The research also reveals\nHungary's implementation challenges, including fragmented execution following\nministerial reorganizations and the absence of designated biennial reviews\nsince 2020. Furthermore, the paper provides targeted recommendations for\nHungary's forthcoming AI strategy, drawing on Singapore's framework as a\nreference point. These include adapting to the era of large language models,\nrestructuring the existing triple helix network to foster more effective\ndialogue and advocacy, and positioning the country as an East-West bridge for\nautomotive AI experimentation.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5308\u7259\u5229\u56fd\u5bb6AI\u6218\u7565\u7684\u76ee\u6807\u843d\u5b9e\u4e0e\u8d44\u91d1\u5206\u914d\uff0c\u63ed\u793a\u4e86\u5176\u5728\u6570\u636e\u516c\u5f00\u3001\u6267\u884c\u534f\u540c\u548c\u5b9a\u671f\u8bc4\u4f30\u65b9\u9762\u5b58\u5728\u7684\u95ee\u9898\uff0c\u5e76\u501f\u9274\u65b0\u52a0\u5761\u7ecf\u9a8c\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\uff0c\u5c24\u5176\u662f\u5e94\u5bf9AI\u6280\u672f\u53d8\u9769\u3001\u4f18\u5316\u591a\u65b9\u5408\u4f5c\u3001\u63d0\u5347\u56fd\u9645\u5b9a\u4f4d\u7b49\u65b9\u9762\u3002", "motivation": "\u5206\u6790\u548c\u8bc4\u4f30\u5308\u7259\u5229\u56fd\u5bb6AI\u6218\u7565\u7684\u5236\u5b9a\u53ca\u6267\u884c\u60c5\u51b5\uff0c\u5f25\u8865\u5f53\u524d\u5bf9\u5176\u6218\u7565\u5b9e\u65bd\u7ec6\u8282\u548c\u6210\u6548\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u501f\u9274\u65b0\u52a0\u5761AI\u6218\u7565\u5bf9\u5308\u7259\u5229\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6218\u7565\u6587\u4ef6\u3001\u516c\u5f00\u8d22\u52a1\u8bb0\u5f55\uff0c\u4ee5\u53ca\u5bf9\u5308\u7259\u5229AI\u8054\u76df\u4e3b\u5e2d\u548c\u653f\u5e9cAI\u4e13\u5458\u9996\u5e2d\u6218\u7565\u987e\u95ee\u7684\u4e13\u5bb6\u8bbf\u8c08\uff0c\u5bf9\u5308\u7259\u5229\u6218\u7565\u76ee\u6807\u4ece\u6982\u5ff5\u3001\u6cbb\u7406\u3001\u65f6\u95f4\u548c\u8d22\u52a1\u56db\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e0e\u65b0\u52a0\u5761AI\u6218\u7565\u8fdb\u884c\u5bf9\u6807\u3002", "result": "\u5308\u7259\u5229AI\u76f8\u5173\u516c\u5171\u6295\u8d44\u603b\u989d\u7ea6\u4e3a46.5\u4ebf\u6b27\u5143\uff0c\u4ec5\u534a\u6570\u76ee\u6807\u53ef\u627e\u5230\u516c\u5f00\u8d22\u52a1\u6570\u636e\uff0c\u4e09\u5927\u9879\u76ee\u5360\u636e\u5df2\u8bb0\u5f55\u8d44\u91d1\u768498%\u3002\u6267\u884c\u4e0a\u5b58\u5728\u788e\u7247\u5316\u3001\u673a\u6784\u8c03\u6574\u5f71\u54cd\u548c\u7f3a\u4e4f\u5b9a\u671f\u8bc4\u4f30\u7b49\u95ee\u9898\u3002", "conclusion": "\u5308\u7259\u5229\u56fd\u5bb6AI\u6218\u7565\u5728\u6267\u884c\u548c\u76d1\u6d4b\u4e0a\u5b58\u5728\u91cd\u5927\u4e0d\u8db3\uff0c\u5e94\u501f\u9274\u65b0\u52a0\u5761\u7ecf\u9a8c\uff0c\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u52a0\u5f3a\u7b56\u7565\u66f4\u65b0\uff0c\u4f18\u5316\u653f\u4ea7\u5b66\u4e09\u87ba\u65cb\u5408\u4f5c\u6846\u67b6\uff0c\u6253\u9020\u6c7d\u8f66\u9886\u57dfAI\u8bd5\u9a8c\u4e1c\u897f\u65b9\u6865\u6881\u5730\u4f4d\uff0c\u5e76\u5236\u5b9a\u66f4\u5b8c\u5584\u7684\u76ee\u6807\u8ffd\u8e2a\u548c\u4fe1\u606f\u62ab\u9732\u673a\u5236\u3002"}}
{"id": "2507.05266", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05266", "abs": "https://arxiv.org/abs/2507.05266", "authors": ["Sougata Saha", "Monojit Choudhury"], "title": "User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs", "comment": null, "summary": "Measuring the generalization ability of Large Language Models (LLMs) is\nchallenging due to data contamination. As models grow and computation becomes\ncheaper, ensuring tasks and test cases are unseen during training phases will\nbecome nearly impossible. We argue that knowledge-retrieval and reasoning tasks\nare not ideal for measuring generalization, as LLMs are not trained for\nspecific tasks. Instead, we propose user behavior prediction, also a key aspect\nof personalization, as a theoretically sound, scalable, and robust alternative.\nWe introduce a novel framework for this approach and test it on movie and music\nrecommendation datasets for GPT-4o, GPT-4o-mini, and Llama-3.1-8B-Instruct.\nResults align with our framework's predictions, showing GPT-4o outperforms\nGPT-4o-mini and Llama, though all models have much room for improvement,\nespecially Llama.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u7528\u6237\u884c\u4e3a\u9884\u6d4b\u4efb\u52a1\u8861\u91cfLLM\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002GPT-4o\u8868\u73b0\u6700\u4f18\uff0cLlama\u4ecd\u6709\u5f88\u5927\u63d0\u5347\u7a7a\u95f4\uff0c\u8be5\u65b9\u6cd5\u662f\u672a\u6765\u6cdb\u5316\u80fd\u529b\u8bc4\u4f30\u7684\u6709\u529b\u8865\u5145\u3002", "motivation": "\u76ee\u524dLLM\u6cdb\u5316\u80fd\u529b\u7684\u5ea6\u91cf\u9762\u4e34\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u4e14\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u5927\u548c\u7b97\u529b\u6210\u672c\u964d\u4f4e\uff0c\u786e\u4fdd\u8bc4\u6d4b\u4efb\u52a1\u5728\u8bad\u7ec3\u9636\u6bb5\u5b8c\u5168\u201c\u770b\u4e0d\u89c1\u201d\u53d8\u5f97\u51e0\u4e4e\u4e0d\u53ef\u80fd\u3002\u56e0\u6b64\uff0c\u5bfb\u627e\u4e00\u79cd\u65b0\u7684\u3001\u66f4\u5065\u5168\u7684\u6cdb\u5316\u80fd\u529b\u8bc4\u4f30\u65b9\u5f0f\u5341\u5206\u5fc5\u8981\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u7528\u201c\u7528\u6237\u884c\u4e3a\u9884\u6d4b\u201d\u4efb\u52a1\uff0c\u6765\u4ee3\u66ff\u4f20\u7edf\u7684\u77e5\u8bc6\u68c0\u7d22\u548c\u63a8\u7406\u4efb\u52a1\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u7684\u6cdb\u5316\u80fd\u529b\u3002\u4ed6\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5168\u65b0\u8bc4\u6d4b\u6846\u67b6\uff0c\u5e76\u5728\u7535\u5f71\u548c\u97f3\u4e50\u63a8\u8350\u7684\u6570\u636e\u96c6\u4e0a\u5bf9GPT-4o\u3001GPT-4o-mini\u53caLlama-3.1-8B-Instruct\u6a21\u578b\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cGPT-4o\u5728\u7528\u6237\u884c\u4e3a\u9884\u6d4b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4f18\u4e8eGPT-4o-mini\u548cLlama-3.1-8B-Instruct\u3002\u5176\u4e2d\uff0cLlama\u7cfb\u5217\u6a21\u578b\u8868\u73b0\u63d0\u5347\u7a7a\u95f4\u8f83\u5927\u3002", "conclusion": "\u7528\u6237\u884c\u4e3a\u9884\u6d4b\u4efb\u52a1\u53ef\u4f5c\u4e3a\u6cdb\u5316\u80fd\u529b\u8bc4\u4f30\u7684\u65b0\u65b9\u6cd5\uff0c\u5177\u5907\u7406\u8bba\u5408\u7406\u6027\u3001\u53ef\u6269\u5c55\u6027\u4e0e\u9c81\u68d2\u6027\uff0c\u5e76\u6709\u6548\u63ed\u793a\u4e3b\u6d41LLM\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u5f02\u3002\u8be5\u65b9\u6cd5\u4e3a\u8bc4\u6d4bLLM\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2507.05283", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05283", "abs": "https://arxiv.org/abs/2507.05283", "authors": ["Yue Wang", "Miao Zhou", "Guijing Huang", "Rui Zhuo", "Chao Yi", "Zhenliang Ma"], "title": "Chat2SPaT: A Large Language Model Based Tool for Automating Traffic Signal Control Plan Management", "comment": null, "summary": "Pre-timed traffic signal control, commonly used for operating signalized\nintersections and coordinated arterials, requires tedious manual work for\nsignaling plan creating and updating. When the time-of-day or day-of-week plans\nare utilized, one intersection is often associated with multiple plans, leading\nto further repetitive manual plan parameter inputting. To enable a\nuser-friendly traffic signal control plan management process, this study\nproposes Chat2SPaT, a method to convert users' semi-structured and ambiguous\ndescriptions on the signal control plan to exact signal phase and timing (SPaT)\nresults, which could further be transformed into structured stage-based or\nring-based plans to interact with intelligent transportation system (ITS)\nsoftware and traffic signal controllers. With curated prompts, Chat2SPaT first\nleverages large language models' (LLMs) capability of understanding users' plan\ndescriptions and reformulate the plan as a combination of phase sequence and\nphase attribute results in the json format. Based on LLM outputs, python\nscripts are designed to locate phases in a cycle, address nuances of traffic\nsignal control, and finally assemble the complete traffic signal control plan.\nWithin a chat, the pipeline can be utilized iteratively to conduct further plan\nediting. Experiments show that Chat2SPaT can generate plans with an accuracy of\nover 94% for both English and Chinese cases, using a test dataset with over 300\nplan descriptions. As the first benchmark for evaluating LLMs' capability of\nunderstanding traffic signal control plan descriptions, Chat2SPaT provides an\neasy-to-use plan management pipeline for traffic practitioners and researchers,\nserving as a potential new building block for a more accurate and versatile\napplication of LLMs in the field of ITS. The source codes, prompts and test\ndataset are openly accessible at https://github.com/yuewangits/Chat2SPaT.", "AI": {"tldr": "Chat2SPaT\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u65b9\u6848\u7684\u81ea\u52a8\u5316\u751f\u6210\uff0c\u663e\u8457\u7b80\u5316\u4e86\u4eba\u5de5\u8f93\u5165\u6d41\u7a0b\uff0c\u5728\u4e2d\u82f1\u6587\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u7387\uff0c\u5bf9\u4e8e\u667a\u80fd\u4ea4\u901a\u9886\u57df\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u4f20\u7edf\u9884\u8bbe\u65f6\u6bb5\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u65b9\u6848\u5728\u5236\u5b9a\u548c\u66f4\u65b0\u65f6\u9700\u8981\u5927\u91cf\u4eba\u5de5\u8f93\u5165\uff0c\u5c24\u5176\u5f53\u4e00\u4e2a\u8def\u53e3\u9700\u8981\u591a\u4e2a\u4e0d\u540c\u65f6\u95f4\u6bb5\u7684\u4fe1\u53f7\u65b9\u6848\u65f6\uff0c\u8fd9\u79cd\u91cd\u590d\u5de5\u4f5c\u5c24\u4e3a\u7e41\u7410\uff0c\u6548\u7387\u4f4e\u4e0b\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u7b80\u5316\u4fe1\u53f7\u63a7\u5236\u65b9\u6848\u7684\u7ba1\u7406\u6d41\u7a0b\uff0c\u51cf\u8f7b\u4eba\u5de5\u8d1f\u62c5\uff0c\u63d0\u9ad8\u51c6\u786e\u7387\uff0c\u6210\u4e3a\u4e00\u4e2a\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aChat2SPaT\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7406\u89e3\u7528\u6237\u5bf9\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u65b9\u6848\u7684\u534a\u7ed3\u6784\u5316\u3001\u6a21\u7cca\u63cf\u8ff0\uff0c\u5e76\u5c06\u5176\u81ea\u52a8\u8f6c\u6362\u4e3a\u7cbe\u786e\u7684\u4fe1\u53f7\u76f8\u4f4d\u4e0e\u65f6\u5e8f\uff08SPaT\uff09\u7ed3\u679c\u3002\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u8bcd\uff0cLLM\u751f\u6210json\u683c\u5f0f\u7684\u76f8\u4f4d\u5e8f\u5217\u53ca\u5c5e\u6027\uff0c\u540e\u7eed\u5229\u7528python\u811a\u672c\u5b9a\u4f4d\u5404\u5468\u671f\u76f8\u4f4d\u3001\u5904\u7406\u5b9e\u9645\u4fe1\u53f7\u63a7\u5236\u4e2d\u7684\u7ec6\u8282\uff0c\u6700\u7ec8\u7ec4\u88c5\u6210\u5b8c\u6574\u7684\u4fe1\u53f7\u63a7\u5236\u65b9\u6848\u3002\u8be5\u7ba1\u9053\u652f\u6301\u591a\u8f6e\u4ea4\u4e92\u548c\u7f16\u8f91\u3002", "result": "Chat2SPaT\u80fd\u591f\u5b9e\u73b0\u82f1\u6587\u548c\u4e2d\u6587\u4fe1\u53f7\u65b9\u6848\u63cf\u8ff0\u5230\u7ed3\u6784\u5316\u8ba1\u5212\u7684\u9ad8\u7cbe\u5ea6\u8f6c\u6362\uff0c\u5728\u5305\u542b300\u4f59\u6761\u65b9\u6848\u63cf\u8ff0\u7684\u6d4b\u8bd5\u96c6\u4e2d\uff0c\u751f\u6210\u8ba1\u5212\u7684\u51c6\u786e\u7387\u8d85\u8fc794%\u3002", "conclusion": "Chat2SPaT\u5c55\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u65b9\u6848\u7406\u89e3\u4e0e\u751f\u6210\u65b9\u9762\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u65b9\u6848\u7ba1\u7406\u7684\u4fbf\u6377\u6027\u4e0e\u6548\u7387\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u672a\u6765ITS\uff08\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\uff09\u4e2d\u4fe1\u53f7\u63a7\u5236\u5e94\u7528\u7684\u91cd\u8981\u6a21\u5757\u3002\u540c\u65f6\u8fd8\u9996\u6b21\u6784\u5efa\u4e86\u8bc4\u4f30\u6b64\u7c7b\u4efb\u52a1\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002"}}
{"id": "2507.05292", "categories": ["cs.CY", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.05292", "abs": "https://arxiv.org/abs/2507.05292", "authors": ["Kaiqi Yang", "Hang Li", "Yucheng Chu", "Ahreum Han", "Yasemin Copur-Gencturk", "Jiliang Tang", "Hui Liu"], "title": "A LLM-Driven Multi-Agent Systems for Professional Development of Mathematics Teachers", "comment": null, "summary": "Professional development (PD) serves as the cornerstone for teacher tutors to\ngrasp content knowledge. However, providing equitable and timely PD\nopportunities for teachers poses significant challenges. To address this issue,\nwe introduce I-VIP (Intelligent Virtual Interactive Program), an intelligent\ntutoring platform for teacher professional development, driven by large\nlanguage models (LLMs) and supported by multi-agent frameworks. This platform\noffers a user-friendly conversational interface and allows users to employ a\nvariety of interactive tools to facilitate question answering, knowledge\ncomprehension, and reflective summarization while engaging in dialogue. To\nunderpin the functionality of this platform, including knowledge expectation\nanalysis, response scoring and classification, and feedback generation, the\nmulti-agent frameworks are leveraged to enhance the accuracy of judgments and\nmitigate the issue of missing key points.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u67b6\u6784\u7684\u6559\u5e08\u4e13\u4e1a\u53d1\u5c55\u667a\u80fd\u5e73\u53f0I-VIP\uff0c\u63d0\u5347\u4e86\u6559\u5e08PD\u7684\u516c\u5e73\u6027\u3001\u4e92\u52a8\u6027\u548c\u5b9e\u65f6\u53cd\u9988\u80fd\u529b\u3002", "motivation": "\u6559\u5e08\u4e13\u4e1a\u53d1\u5c55\uff08PD\uff09\u5bf9\u4e8e\u638c\u63e1\u5b66\u79d1\u77e5\u8bc6\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f53\u524d\u5728\u4e3a\u6559\u5e08\u63d0\u4f9b\u516c\u5e73\u4e14\u53ca\u65f6\u7684PD\u673a\u4f1a\u65f6\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u5982\u8d44\u6e90\u6709\u9650\u3001\u65f6\u95f4\u5206\u914d\u96be\u3001\u96be\u4ee5\u53ca\u65f6\u6ee1\u8db3\u4e2a\u6027\u5316\u9700\u6c42\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86I-VIP\uff08\u667a\u80fd\u865a\u62df\u4ea4\u4e92\u5f0f\u5e73\u53f0\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u591a\u667a\u80fd\u4f53\u6846\u67b6\u9a71\u52a8\u7684\u6559\u5e08\u4e13\u4e1a\u53d1\u5c55\u667a\u80fd\u8f85\u5bfc\u5e73\u53f0\u3002\u5e73\u53f0\u901a\u8fc7\u7528\u6237\u53cb\u597d\u7684\u5bf9\u8bdd\u754c\u9762\u548c\u591a\u79cd\u4ea4\u4e92\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u4e92\u52a8\u5f0f\u7b54\u7591\u3001\u77e5\u8bc6\u7406\u89e3\u548c\u53cd\u601d\u603b\u7ed3\u7b49\u529f\u80fd\u3002\u591a\u667a\u80fd\u4f53\u6846\u67b6\u652f\u6301\u77e5\u8bc6\u9884\u671f\u5206\u6790\u3001\u7b54\u590d\u6253\u5206\u4e0e\u5206\u7c7b\u3001\u53cd\u9988\u751f\u6210\u7b49\u6838\u5fc3\u6a21\u5757\uff0c\u4ece\u800c\u63d0\u5347\u5e73\u53f0\u5224\u65ad\u7684\u51c6\u786e\u6027\uff0c\u5e76\u964d\u4f4e\u9057\u6f0f\u5173\u952e\u70b9\u7684\u98ce\u9669\u3002", "result": "I-VIP\u5e73\u53f0\u80fd\u591f\u6709\u6548\u8d4b\u80fd\u6559\u5e08\u5b9e\u73b0\u66f4\u516c\u5e73\u3001\u53ca\u65f6\u548c\u9ad8\u6548\u7684\u4e13\u4e1a\u53d1\u5c55\uff0c\u5e76\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6a21\u5757\u63d0\u5347\u4e92\u52a8\u8d28\u91cf\u548c\u77e5\u8bc6\u8986\u76d6\u5ea6\uff0c\u4f18\u5316\u53cd\u9988\u8d28\u91cf\u3002", "conclusion": "I-VIP\u5e73\u53f0\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u4e3a\u6559\u5e08\u4e13\u4e1a\u53d1\u5c55\u63d0\u4f9b\u4e86\u521b\u65b0\u7684\u6280\u672f\u652f\u6301\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u4f20\u7edfPD\u673a\u4f1a\u5206\u914d\u4e0d\u5747\u3001\u4e92\u52a8\u5355\u4e00\u7b49\u95ee\u9898\u3002"}}
{"id": "2507.05271", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05271", "abs": "https://arxiv.org/abs/2507.05271", "authors": ["Mohammad Zia Ur Rehman", "Aditya Shah", "Nagendra Kumar"], "title": "An Adaptive Supervised Contrastive Learning Framework for Implicit Sexism Detection in Digital Social Networks", "comment": null, "summary": "The global reach of social media has amplified the spread of hateful content,\nincluding implicit sexism, which is often overlooked by conventional detection\nmethods. In this work, we introduce an Adaptive Supervised Contrastive lEarning\nframework for implicit sexism detectioN (ASCEND). A key innovation of our\nmethod is the incorporation of threshold-based contrastive learning: by\ncomputing cosine similarities between embeddings, we selectively treat only\nthose sample pairs as positive if their similarity exceeds a learnable\nthreshold. This mechanism refines the embedding space by robustly pulling\ntogether representations of semantically similar texts while pushing apart\ndissimilar ones, thus reducing false positives and negatives. The final\nclassification is achieved by jointly optimizing a contrastive loss with a\ncross-entropy loss. Textual features are enhanced through a word-level\nattention module. Additionally, we employ sentiment, emotion, and toxicity\nfeatures. Evaluations on the EXIST2021 and MLSC datasets demonstrate that\nASCEND significantly outperforms existing methods, with average Macro F1\nimprovements of 9.86%, 29.63%, and 32.51% across multiple tasks, highlighting\nits efficacy in capturing the subtle cues of implicit sexist language.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7ed3\u5408\u81ea\u9002\u5e94\u9608\u503c\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u591a\u7279\u5f81\u589e\u5f3a\u7684 ASCEND \u6846\u67b6\uff0c\u5728\u9690\u6027\u6027\u522b\u6b67\u89c6\u68c0\u6d4b\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u7684\u5168\u7403\u666e\u53ca\u52a0\u5267\u4e86\u4ec7\u6068\u5185\u5bb9\u7684\u4f20\u64ad\uff0c\u5c24\u5176\u662f\u9690\u6027\u6027\u522b\u6b67\u89c6\uff0c\u8fd9\u7c7b\u5185\u5bb9\u5e38\u5e38\u88ab\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u5ffd\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u6709\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6 ASCEND\uff0c\u901a\u8fc7\u8ba1\u7b97\u6587\u672c\u5d4c\u5165\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u5e76\u8bbe\u5b9a\u53ef\u5b66\u4e60\u7684\u9608\u503c\uff0c\u4ec5\u5c06\u9ad8\u4e8e\u8be5\u9608\u503c\u7684\u6837\u672c\u5bf9\u4f5c\u4e3a\u6b63\u4f8b\uff0c\u5b9e\u73b0\u7cbe\u7ec6\u7684\u8868\u793a\u5b66\u4e60\u3002\u540c\u65f6\u7ed3\u5408\u5bf9\u6bd4\u635f\u5931\u548c\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u5e76\u5f15\u5165\u8bcd\u7ea7\u6ce8\u610f\u529b\u673a\u5236\u3001\u60c5\u611f\u3001\u60c5\u7eea\u548c\u6bd2\u6027\u7279\u5f81\u589e\u5f3a\u6587\u672c\u8868\u793a\u3002", "result": "\u5728 EXIST2021 \u548c MLSC \u6570\u636e\u96c6\u4e0a\uff0cASCEND \u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a Macro F1 \u5206\u522b\u63d0\u9ad8\u4e86 9.86%\u300129.63%\u300132.51%\u3002", "conclusion": "ASCEND \u6846\u67b6\u80fd\u6709\u6548\u6355\u6349\u9690\u85cf\u6027\u522b\u6b67\u89c6\u8bed\u8a00\u7684\u7ec6\u5fae\u7279\u5f81\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u9690\u6027\u6027\u522b\u6b67\u89c6\u5185\u5bb9\u7684\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2507.05297", "categories": ["cs.AI", "econ.TH"], "pdf": "https://arxiv.org/pdf/2507.05297", "abs": "https://arxiv.org/abs/2507.05297", "authors": ["Zijun Meng"], "title": "Fuzzy Classification Aggregation for a Continuum of Agents", "comment": null, "summary": "We prove that any optimal, independent, and zero unanimous fuzzy\nclassification aggregation function of a continuum of individual\nclassifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted\narithmetic mean.", "AI": {"tldr": "\u6ee1\u8db3\u6700\u4f18\u3001\u72ec\u7acb\u548c\u96f6\u4e00\u81f4\u6027\u7684\u6a21\u7cca\u5206\u7c7b\u805a\u5408\u51fd\u6570\uff0c\u5fc5\u7136\u662f\u52a0\u6743\u7b97\u672f\u5e73\u5747\u3002", "motivation": "\u7814\u7a76\u6a21\u7cca\u5206\u7c7b\u60c5\u5883\u4e0b\uff0c\u5982\u4f55\u5c06\u5927\u91cf\u4e2a\u4f53\u5bf9\u591a\u4e2a\u5bf9\u8c61\u7684\u5206\u7c7b\u7ed3\u679c\u5408\u7406\u3001\u6700\u4f18\u5730\u805a\u5408\uff0c\u7279\u522b\u662f\u5728\u6ee1\u8db3\u6700\u4f18\u6027\u3001\u72ec\u7acb\u6027\u548c\u96f6\u4e00\u81f4\u6027\u7b49\u516c\u7406\u65f6\uff0c\u805a\u5408\u51fd\u6570\u5e94\u5177\u6709\u4ec0\u4e48\u7ed3\u6784\u3002", "method": "\u5728\u516c\u7406\u5316\u6846\u67b6\u4e0b\uff0c\u9488\u5bf9\u65e0\u9650\u591a\u4e2a\u4e2a\u4f53\u5bf9\u591a\u4e2a\u5bf9\u8c61\u7684\u6a21\u7cca\u5206\u7c7b\uff0c\u5229\u7528\u51fd\u6570\u6027\u8d28\u5206\u6790\u4e0e\u4e25\u683c\u7684\u6570\u5b66\u8bc1\u660e\uff0c\u523b\u753b\u51fa\u6240\u6709\u6ee1\u8db3\u7279\u5b9a\u516c\u7406\u7684\u805a\u5408\u51fd\u6570\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u7ed9\u5b9a\u7684\u516c\u7406\u6761\u4ef6\u4e0b\uff0c\u552f\u4e00\u6ee1\u8db3\u8981\u6c42\u7684\u805a\u5408\u51fd\u6570\u5f62\u5f0f\u662f\u52a0\u6743\u7b97\u672f\u5e73\u5747\u3002", "conclusion": "\u5bf9\u4e8e\u65e0\u9650\u591a\u4e2a\u4e2a\u4f53\u5bf9\u591a\u4e2a\u5bf9\u8c61\u8fdb\u884c\u7684\u6a21\u7cca\u5206\u7c7b\uff0c\u53ea\u8981\u805a\u5408\u51fd\u6570\u6ee1\u8db3\u6700\u4f18\u3001\u72ec\u7acb\u4e0e\u96f6\u4e00\u81f4\u6027\u8fd9\u4e09\u6761\u516c\u7406\uff0c\u5176\u7ed3\u6784\u5fc5\u7136\u662f\u52a0\u6743\u7b97\u672f\u5e73\u5747\u3002"}}
{"id": "2507.05296", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05296", "abs": "https://arxiv.org/abs/2507.05296", "authors": ["Islem Sahraoui", "Kinam Kim", "Lu Gao", "Zia Din", "Ahmed Senouci"], "title": "Integrating Generative AI in BIM Education: Insights from Classroom Implementation", "comment": null, "summary": "This study evaluates the implementation of a Generative AI-powered rule\nchecking workflow within a graduate-level Building Information Modeling (BIM)\ncourse at a U.S. university. Over two semesters, 55 students participated in a\nclassroom-based pilot exploring the use of GenAI for BIM compliance tasks, an\narea with limited prior research. The instructional design included lectures on\nprompt engineering and AI-driven rule checking, followed by an assignment where\nstudents used a large language model (LLM) to identify code violations in\ndesigns using Autodesk Revit. Surveys and interviews were conducted to assess\nstudent workload, learning effectiveness, and overall experience, using the\nNASA-TLX scale and regression analysis. Findings indicate students generally\nachieved learning objectives but faced challenges such as difficulties\ndebugging AI-generated code and inconsistent tool performance, probably due to\ntheir limited prompt engineering experience. These issues increased cognitive\nand emotional strain, especially among students with minimal programming\nbackgrounds. Despite these challenges, students expressed strong interest in\nfuture GenAI applications, particularly with clear instructional support.", "AI": {"tldr": "\u672c\u7814\u7a76\u5728\u7f8e\u56fd\u9ad8\u6821BIM\u8bfe\u7a0b\u5f15\u5165\u751f\u6210\u5f0fAI\u89c4\u5219\u68c0\u67e5\u5b9e\u8df5\uff0c\u53d1\u73b0\u5176\u6709\u52a9\u4e8e\u8fbe\u6210\u5b66\u4e60\u76ee\u6807\uff0c\u4f46\u8c03\u8bd5\u96be\u3001\u5de5\u5177\u4e0d\u7a33\u53ca\u7ecf\u9a8c\u4e0d\u8db3\u5bfc\u81f4\u5b66\u751f\u538b\u529b\u589e\u5927\u3002\u603b\u4f53\u4e0a\uff0c\u5b66\u751f\u79ef\u6781\u770b\u5f85\u5c06\u6765\u5728\u6559\u5b66\u4e2d\u7ee7\u7eed\u5e94\u7528\u6b64\u6280\u672f\uff0c\u5c24\u5176\u662f\u5728\u6709\u6e05\u6670\u6307\u5bfc\u7684\u524d\u63d0\u4e0b\u3002", "motivation": "\u76ee\u524d\u5173\u4e8e\u5728BIM\u8bfe\u7a0b\u4e2d\u5e94\u7528\u751f\u6210\u5f0fAI\u8fdb\u884c\u5408\u89c4\u68c0\u67e5\u7684\u7814\u7a76\u5f88\u6709\u9650\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u5e0c\u671b\u8bc4\u4f30\u8fd9\u79cd\u65b0\u6280\u672f\u7684\u6559\u5b66\u6709\u6548\u6027\u3001\u5b66\u751f\u4f53\u9a8c\u53ca\u5b58\u5728\u7684\u95ee\u9898\uff0c\u4e3a\u540e\u7eed\u6559\u80b2\u5e94\u7528\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u91c7\u7528\u8bfe\u5802\u6559\u5b66\u3001\u5b9e\u9645\u64cd\u4f5c\u4f5c\u4e1a\u3001\u8c03\u67e5\u95ee\u5377\uff08\u5305\u542bNASA-TLX\u91cf\u8868\uff09\u548c\u8bbf\u8c08\u65b9\u5f0f\uff0c\u7ed3\u5408\u56de\u5f52\u5206\u6790\u8bc4\u4f30\u5b66\u751f\u7684\u5de5\u4f5c\u8d1f\u8377\u3001\u5b66\u4e60\u6210\u6548\u53ca\u6574\u4f53\u4f53\u9a8c\u3002", "result": "\u5b66\u751f\u5728\u5b66\u4e60\u76ee\u6807\u5b9e\u73b0\u4e0a\u603b\u4f53\u8868\u73b0\u826f\u597d\uff0c\u4f46\u56e0\u7f3a\u4e4f\u63d0\u793a\u5de5\u7a0b\u7ecf\u9a8c\uff0c\u8c03\u8bd5AI\u751f\u6210\u4ee3\u7801\u548c\u5de5\u5177\u7a33\u5b9a\u6027\u4e0a\u9047\u5230\u56f0\u96be\uff0c\u8fd9\u589e\u52a0\u4e86\u4ed6\u4eec\u7684\u8ba4\u77e5\u4e0e\u60c5\u611f\u8d1f\u62c5\u3002\u65e0\u7f16\u7a0b\u57fa\u7840\u7684\u5b66\u751f\u5c24\u4e3a\u660e\u663e\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u5b66\u751f\u666e\u904d\u5bf9\u672a\u6765\u6709\u6559\u5b66\u652f\u6301\u7684GenAI\u5e94\u7528\u6301\u79ef\u6781\u6001\u5ea6\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u5b66\u751f\u5728\u4f7f\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u8fdb\u884c\u5efa\u7b51\u4fe1\u606f\u5efa\u6a21\uff08BIM\uff09\u89c4\u5219\u68c0\u67e5\u65f6\u9762\u4e34\u5982\u8c03\u8bd5\u56f0\u96be\u548c\u5de5\u5177\u8868\u73b0\u4e0d\u7a33\u5b9a\u7b49\u6311\u6218\uff0c\u4f46\u5927\u591a\u6570\u5b66\u751f\u80fd\u591f\u5b9e\u73b0\u5b66\u4e60\u76ee\u6807\uff0c\u5e76\u5bf9\u672a\u6765\u4f7f\u7528\u8be5\u7c7b\u6280\u672f\u8868\u73b0\u51fa\u8f83\u5f3a\u5174\u8da3\uff0c\u524d\u63d0\u662f\u6709\u660e\u786e\u7684\u6559\u5b66\u652f\u6301\u3002"}}
{"id": "2507.05285", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.IR", "I.2.7; I.2.1; K.3.1"], "pdf": "https://arxiv.org/pdf/2507.05285", "abs": "https://arxiv.org/abs/2507.05285", "authors": ["Miloud Mihoubi", "Meriem Zerkouk", "Belkacem Chikhaoui"], "title": "Beyond classical and contemporary models: a transformative ai framework for student dropout prediction in distance learning using rag, prompt engineering, and cross-modal fusion", "comment": "10 pages, 5 figures, 5 tables. Submitted to the 38th Canadian\n  Conference on Artificial Intelligence (Canadian AI 2025)", "summary": "Student dropout in distance learning remains a critical challenge, with\nprofound societal and economic consequences. While classical machine learning\nmodels leverage structured socio-demographic and behavioral data, they often\nfail to capture the nuanced emotional and contextual factors embedded in\nunstructured student interactions. This paper introduces a transformative AI\nframework that redefines dropout prediction through three synergistic\ninnovations: Retrieval-Augmented Generation (RAG) for domain-specific sentiment\nanalysis, prompt engineering to decode academic stressors, and cross-modal\nattention fusion to dynamically align textual, behavioral, and\nsocio-demographic insights. By grounding sentiment analysis in a curated\nknowledge base of pedagogical content, our RAG-enhanced BERT model interprets\nstudent comments with unprecedented contextual relevance, while optimized\nprompts isolate indicators of academic distress (e.g., \"isolation,\" \"workload\nanxiety\"). A cross-modal attention layer then fuses these insights with\ntemporal engagement patterns, creating holistic risk profiles. Evaluated on a\nlongitudinal dataset of 4 423 students, the framework achieves 89% accuracy and\nan F1-score of 0.88, outperforming conventional models by 7% and reducing false\nnegatives by 21%. Beyond prediction, the system generates interpretable\ninterventions by retrieving contextually aligned strategies (e.g., mentorship\nprograms for isolated learners). This work bridges the gap between predictive\nanalytics and actionable pedagogy, offering a scalable solution to mitigate\ndropout risks in global education systems", "AI": {"tldr": "\u672c\u6587\u521b\u65b0\u6027\u5730\u7ed3\u5408\u4e86\u77e5\u8bc6\u589e\u5f3a\u60c5\u611f\u5206\u6790\u3001Prompt\u5de5\u7a0b\u548c\u591a\u6a21\u6001\u878d\u5408\uff0c\u6781\u5927\u63d0\u5347\u4e86\u8fdc\u7a0b\u5b66\u4e60\u4e2d\u5b66\u751f\u8f8d\u5b66\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u80fd\u81ea\u52a8\u63a8\u8350\u4e2a\u6027\u5316\u5e72\u9884\u7b56\u7565\u3002", "motivation": "\u8fdc\u7a0b\u5b66\u4e60\u4e2d\u7684\u5b66\u751f\u8f8d\u5b66\u7387\u5c45\u9ad8\u4e0d\u4e0b\uff0c\u5bf9\u793e\u4f1a\u548c\u7ecf\u6d4e\u5e26\u6765\u5de8\u5927\u5f71\u54cd\u3002\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u5229\u7528\u4e86\u7ed3\u6784\u5316\u6570\u636e\uff0c\u4f46\u96be\u4ee5\u6355\u6349\u5b66\u751f\u4e92\u52a8\u4e2d\u60c5\u611f\u548c\u60c5\u5883\u7b49\u975e\u7ed3\u6784\u5316\u56e0\u7d20\u3002\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63d0\u5347\u5bf9\u5b66\u751f\u8f8d\u5b66\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\uff0c\u8fdb\u800c\u63a8\u52a8\u65e9\u671f\u5e72\u9884\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e09\u9879\u521b\u65b0\u7684\u4eba\u5de5\u667a\u80fd\u6846\u67b6\uff1a\uff081\uff09\u57fa\u4e8eRAG\u6280\u672f\u7684\u9886\u57df\u7279\u5b9a\u60c5\u611f\u5206\u6790\uff0c\u501f\u52a9\u77e5\u8bc6\u5e93\u63d0\u5347\u8bc4\u8bba\u89e3\u91ca\u80fd\u529b\uff1b\uff082\uff09\u901a\u8fc7\u4f18\u5316Prompt Engineering\u8bc6\u522b\u5b66\u4e1a\u538b\u529b\u76f8\u5173\u7279\u5f81\u8bcd\uff1b\uff083\uff09\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u878d\u5408\u5c42\uff0c\u5b9e\u73b0\u6587\u672c\u3001\u884c\u4e3a\u548c\u793e\u4f1a\u7ecf\u6d4e\u591a\u6e90\u6570\u636e\u7684\u5bf9\u9f50\u548c\u878d\u5408\u3002\u6a21\u578b\u4e3b\u8981\u57fa\u4e8eBERT\u8fdb\u884c\u60c5\u611f\u5206\u6790\uff0c\u91c7\u7528\u957f\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u57284,423\u540d\u5b66\u751f\u7684\u957f\u671f\u6570\u636e\u96c6\u4e0a\uff0c\u6846\u67b6\u53d6\u5f97\u4e8689%\u7684\u51c6\u786e\u7387\u548c0.88\u7684F1\u5206\u6570\uff0c\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b7%\uff0c\u5c06\u5047\u9634\u6027\u964d\u4f4e\u4e8621%\u3002\u8fd8\u80fd\u57fa\u4e8e\u5206\u6790\u7ed3\u679c\u81ea\u52a8\u63a8\u8350\u4e2a\u6027\u5316\u5e72\u9884\u63aa\u65bd\uff08\u5982\u5bf9\u5b64\u7acb\u5b66\u751f\u5339\u914d\u5bfc\u5e08\u9879\u76ee\uff09\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u591a\u6a21\u6001AI\u6846\u67b6\uff0c\u5728\u8fdc\u7a0b\u6559\u80b2\u8f8d\u5b66\u9884\u6d4b\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\uff0c\u53ef\u6269\u5c55\u5e94\u7528\u4e8e\u5168\u7403\u6559\u80b2\u7cfb\u7edf\uff0c\u5e76\u80fd\u4e3a\u6559\u80b2\u5e72\u9884\u63aa\u65bd\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u652f\u6301\u3002"}}
{"id": "2507.05488", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.05488", "abs": "https://arxiv.org/abs/2507.05488", "authors": ["Subhasis Dasgupta", "Jon Stephens", "Amarnath Gupta"], "title": "OLG++: A Semantic Extension of Obligation Logic Graph", "comment": null, "summary": "We present OLG++, a semantic extension of the Obligation Logic Graph (OLG)\nfor modeling regulatory and legal rules in municipal and interjurisdictional\ncontexts. OLG++ introduces richer node and edge types, including spatial,\ntemporal, party group, defeasibility, and logical grouping constructs, enabling\nnuanced representations of legal obligations, exceptions, and hierarchies. The\nmodel supports structured reasoning over rules with contextual conditions,\nprecedence, and complex triggers. We demonstrate its expressiveness through\nexamples from food business regulations, showing how OLG++ supports legal\nquestion answering using property graph queries. OLG++ also improves over\nLegalRuleML by providing native support for subClassOf, spatial constraints,\nand reified exception structures. Our examples show that OLG++ is more\nexpressive than prior graph-based models for legal knowledge representation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faOLG++\uff0c\u6269\u5c55\u73b0\u6709\u6cd5\u5f8b\u77e5\u8bc6\u56fe\u8c31\u6a21\u578b\uff0c\u5b9e\u73b0\u66f4\u590d\u6742\u6cd5\u5f8b\u89c4\u5219\u7684\u8868\u8fbe\u4e0e\u63a8\u7406\uff0c\u7279\u522b\u5728\u7a7a\u95f4\u3001\u65f6\u95f4\u3001\u4f8b\u5916\u5904\u7406\u53ca\u7c7b\u7ee7\u627f\u7b49\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u5bf9\u5b9e\u9645\u6cd5\u89c4\u573a\u666f\u5177\u5907\u66f4\u5f3a\u9002\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6cd5\u5f8b\u77e5\u8bc6\u56fe\u8c31\u5982OLG\u548cLegalRuleML\u5728\u8868\u8fbe\u590d\u6742\u6cd5\u5f8b\u89c4\u5219\u3001\u4e0a\u4e0b\u6587\u53ca\u4f8b\u5916\u7b49\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u96be\u4ee5\u6ee1\u8db3\u5e02\u653f\u53ca\u8de8\u5730\u57df\u573a\u666f\u4e0b\u6cd5\u5f8b\u89c4\u5219\u5efa\u6a21\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51faOLG++\uff0c\u5bf9\u539f\u6709Obligation Logic Graph\u8fdb\u884c\u8bed\u4e49\u6269\u5c55\uff0c\u5f15\u5165\u66f4\u4e30\u5bcc\u7684\u8282\u70b9\u548c\u8fb9\u7c7b\u578b\uff08\u5982\u7a7a\u95f4\u3001\u65f6\u95f4\u3001\u56e2\u4f53\u3001\u591a\u5c42\u4f8b\u5916\u7ed3\u6784\u7b49\uff09\uff0c\u652f\u6301\u4e0a\u4e0b\u6587\u6761\u4ef6\u3001\u4f18\u5148\u7ea7\u3001\u89e6\u53d1\u6761\u4ef6\u7b49\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u98df\u54c1\u884c\u4e1a\u6cd5\u89c4\u6848\u4f8b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "OLG++\u80fd\u591f\u901a\u8fc7\u5c5e\u6027\u56fe\u67e5\u8be2\u5b9e\u73b0\u6cd5\u5f8b\u95ee\u7b54\uff0c\u5e76\u5bf9subClassOf\u3001\u7a7a\u95f4\u7ea6\u675f\u3001\u4f8b\u5916\u7b49\u63d0\u4f9b\u539f\u751f\u652f\u6301\uff0c\u76f8\u8f83LegalRuleML\u548c\u5176\u4ed6\u56fe\u8c31\u6a21\u578b\u62e5\u6709\u66f4\u5f3a\u8868\u8fbe\u80fd\u529b\u3002", "conclusion": "OLG++\u5728\u6cd5\u5f8b\u89c4\u5219\u8868\u793a\u4e0e\u63a8\u7406\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u9700\u8981\u8868\u8fbe\u590d\u6742\u4e0a\u4e0b\u6587\u4e0e\u4f8b\u5916\u60c5\u51b5\u7684\u573a\u666f\u3002"}}
{"id": "2507.05305", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05305", "abs": "https://arxiv.org/abs/2507.05305", "authors": ["Lorenzo Lee Solano", "Charles Koutcheme", "Juho Leinonen", "Alexandra Vassar", "Jake Renzella"], "title": "Narrowing the Gap: Supervised Fine-Tuning of Open-Source LLMs as a Viable Alternative to Proprietary Models for Pedagogical Tools", "comment": "7 pages, 3 tables, 1 figure", "summary": "Frontier Large language models (LLMs) like ChatGPT and Gemini can decipher\ncryptic compiler errors for novice programmers, but their computational scale,\ncost, and tendency to over-assist make them problematic for widespread\npedagogical adoption. This work demonstrates that smaller, specialised language\nmodels, enhanced via Supervised Fine-Tuning (SFT), present a more viable\nalternative for educational tools. We utilise a new dataset of 40,000 C\ncompiler error explanations, derived from real introductory programming (CS1/2)\nstudent-generated programming errors, which we used to fine-tune three\nopen-source models: Qwen3-4B, Llama-3.1-8B, and Qwen3-32B. We performed a dual\nevaluation, combining expert human reviews with a large-scale automated\nanalysis of 8,000 responses using a validated LLM-as-judge ensemble. Our\nresults show that SFT significantly boosts the pedagogical quality of smaller\nmodels, achieving performance comparable to much larger models. We analyse the\ntrade-offs between model size and quality, confirming that fine-tuning compact,\nefficient models on high-quality, domain-specific data is a potent strategy for\ncreating specialised models to drive educational tools. We provide a replicable\nmethodology to foster broader access to generative AI capabilities in\neducational contexts.", "AI": {"tldr": "\u672c\u7814\u7a76\u7528\u5305\u542b4\u4e07\u6761\u5b66\u751f\u7f16\u8bd1\u9519\u8bef\u7684\u65b0\u6570\u636e\u96c6\u5fae\u8c03\u4e09\u79cd\u5c0f\u578b\u5f00\u6e90\u5927\u6a21\u578b\uff0c\u8bc4\u6d4b\u663e\u793a\uff1a\u5fae\u8c03\u5927\u5e45\u63d0\u5347\u5c0f\u6a21\u578b\u8bb2\u89e3\u80fd\u529b\uff0c\u8fbe\u5230\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u7684\u6559\u5b66\u8f85\u52a9\u6548\u679c\uff0c\u4e14\u6210\u672c\u4f4e\u3001\u6613\u63a8\u5e7f\uff0c\u9002\u5408\u6559\u80b2\u573a\u666f\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u590d\u73b0\u65b9\u6cd5\u3002", "motivation": "\u5927\u578bLLM\uff08\u5982ChatGPT\u3001Gemini\uff09\u867d\u80fd\u5e2e\u52a9\u65b0\u624b\u7f16\u7a0b\u5b66\u4e60\u8005\u7406\u89e3\u7f16\u8bd1\u62a5\u9519\uff0c\u4f46\u56e0\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u5927\u53ca\u8fc7\u5ea6\u8f85\u52a9\u95ee\u9898\uff0c\u4e0d\u9002\u5408\u5927\u89c4\u6a21\u6559\u80b2\u63a8\u5e7f\u3002\u6545\u9700\u63a2\u7d22\u9ad8\u6548\u3001\u4e13\u7528\u7684\u5c0f\u6a21\u578b\u5728\u6559\u80b2\u9886\u57df\u7684\u53ef\u884c\u6027\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u6db5\u76d64\u4e07\u6761\u771f\u5b9e\u5b66\u751f\u7f16\u8bd1\u5668\u9519\u8bef\u89e3\u91ca\u7684\u6570\u636e\u96c6\uff0c\u5bf9\u4e09\u79cd\u5f00\u6e90\u5c0f\u6a21\u578b\u8fdb\u884c\u4e86\u6709\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u3002\u8bc4\u4f30\u65b9\u6cd5\u5305\u542b\u4e13\u5bb6\u4eba\u5de5\u8bc4\u5ba1\u548c\u5927\u89c4\u6a21\u81ea\u52a8\u5316LLM\u6253\u5206\uff0c\u53cc\u91cd\u5b9a\u91cf\u4e0e\u5b9a\u6027\u8bc4\u4f30\u6a21\u578b\u8868\u73b0\u3002", "result": "\u5fae\u8c03\u540e\u7684\u5c0f\u578b\u6a21\u578b\u5728\u89e3\u91ca\u7f16\u8bd1\u9519\u8bef\u65f6\uff0c\u6559\u80b2\u8f85\u52a9\u8d28\u91cf\u663e\u8457\u63d0\u5347\uff0c\u8868\u73b0\u4e0e\u5927\u578b\u6a21\u578b\u63a5\u8fd1\u3002\u7814\u7a76\u8fd8\u5206\u6790\u4e86\u6a21\u578b\u89c4\u6a21\u4e0e\u8868\u73b0\u7684\u6743\u8861\uff0c\u63a8\u8350\u901a\u8fc7\u9ad8\u8d28\u91cf\u57df\u4e13\u6570\u636e\u5fae\u8c03\u5c0f\u6a21\u578b\uff0c\u7528\u4ee5\u6784\u5efa\u6613\u63a8\u5e7f\u7684\u6559\u80b2AI\u5de5\u5177\u3002", "conclusion": "\u901a\u8fc7SFT\u5fae\u8c03\u7684\u5c0f\u578b\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\uff08\u5982Qwen3-4B\u3001Llama-3.1-8B\u3001Qwen3-32B\uff09\uff0c\u5728\u7f16\u8bd1\u5668\u9519\u8bef\u89e3\u91ca\u65b9\u9762\u80fd\u8fbe\u5230\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u7684\u6559\u80b2\u8f85\u52a9\u6548\u679c\uff0c\u4e14\u66f4\u5177\u6210\u672c\u548c\u8d44\u6e90\u6548\u7387\uff0c\u4e3a\u6559\u80b2\u573a\u666f\u4e0b\u751f\u6210\u5f0fAI\u7684\u91c7\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.05319", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05319", "abs": "https://arxiv.org/abs/2507.05319", "authors": ["Cheng Yuan", "Xinkai Rui", "Yongqi Fan", "Yawei Fan", "Boyang Zhong", "Jiacheng Wang", "Weiyan Zhang", "Tong Ruan"], "title": "LCDS: A Logic-Controlled Discharge Summary Generation System Supporting Source Attribution and Expert Review", "comment": "ACL Demo 2025", "summary": "Despite the remarkable performance of Large Language Models (LLMs) in\nautomated discharge summary generation, they still suffer from hallucination\nissues, such as generating inaccurate content or fabricating information\nwithout valid sources. In addition, electronic medical records (EMRs) typically\nconsist of long-form data, making it challenging for LLMs to attribute the\ngenerated content to the sources. To address these challenges, we propose LCDS,\na Logic-Controlled Discharge Summary generation system. LCDS constructs a\nsource mapping table by calculating textual similarity between EMRs and\ndischarge summaries to constrain the scope of summarized content. Moreover,\nLCDS incorporates a comprehensive set of logical rules, enabling it to generate\nmore reliable silver discharge summaries tailored to different clinical fields.\nFurthermore, LCDS supports source attribution for generated content, allowing\nexperts to efficiently review, provide feedback, and rectify errors. The\nresulting golden discharge summaries are subsequently recorded for incremental\nfine-tuning of LLMs. Our project and demo video are in the GitHub repository\nhttps://github.com/ycycyc02/LCDS.", "AI": {"tldr": "\u63d0\u51fa\u4e86LCDS\u7cfb\u7edf\uff0c\u901a\u8fc7\u6587\u672c\u76f8\u4f3c\u6027\u6620\u5c04\u548c\u903b\u8f91\u89c4\u5219\u7ea6\u675f\uff0c\u63d0\u5347\u4e86LLM\u751f\u6210\u51fa\u9662\u5c0f\u7ed3\u7684\u51c6\u786e\u6027\u548c\u53ef\u6eaf\u6027\uff0c\u5e76\u4e3a\u540e\u7eed\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u52a8\u751f\u6210\u51fa\u9662\u5c0f\u7ed3\u65f6\u867d\u7136\u8868\u73b0\u5353\u8d8a\uff0c\u4f46\u4ecd\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u5982\u751f\u6210\u4e0d\u51c6\u786e\u5185\u5bb9\u6216\u634f\u9020\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u7535\u5b50\u75c5\u5386\uff08EMRs\uff09\u901a\u5e38\u4e3a\u957f\u6587\u672c\u6570\u636e\uff0c\u5bfc\u81f4LLMs\u96be\u4ee5\u5c06\u751f\u6210\u5185\u5bb9\u5f52\u56e0\u4e8e\u539f\u59cb\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86LCDS\uff08Logic-Controlled Discharge Summary\uff09\u7cfb\u7edf\u3002LCDS\u901a\u8fc7\u8ba1\u7b97EMR\u4e0e\u51fa\u9662\u5c0f\u7ed3\u95f4\u7684\u6587\u672c\u76f8\u4f3c\u6027\u5efa\u7acb\u6e90\u6620\u5c04\u8868\uff0c\u9650\u5236\u603b\u7ed3\u5185\u5bb9\u7684\u6765\u6e90\u8303\u56f4\uff0c\u5e76\u7ed3\u5408\u4e00\u5957\u903b\u8f91\u89c4\u5219\u751f\u6210\u66f4\u53ef\u9760\u7684\u94f6\u8d28\u51fa\u9662\u5c0f\u7ed3\u3002\u6b64\u5916\uff0cLCDS\u652f\u6301\u751f\u6210\u5185\u5bb9\u7684\u6eaf\u6e90\uff0c\u4fbf\u4e8e\u4e13\u5bb6\u5ba1\u6838\u548c\u4fee\u6b63\u3002\u6700\u7ec8\u901a\u8fc7\u4eba\u5de5\u4fee\u6b63\u4ea7\u751f\u91d1\u8d28\u51fa\u9662\u5c0f\u7ed3\u5e76\u7528\u4e8eLLM\u589e\u91cf\u5fae\u8c03\u3002", "result": "\u7cfb\u7edf\u63d0\u9ad8\u4e86\u51fa\u9662\u5c0f\u7ed3\u7684\u771f\u5b9e\u6027\u548c\u53ef\u9a8c\u6027\uff0c\u4e3a\u4e13\u5bb6\u9ad8\u6548\u5ba1\u6838\u53ca\u6a21\u578b\u8fed\u4ee3\u4f18\u5316\u63d0\u4f9b\u652f\u6301\u3002\u6700\u7ec8\u6210\u679c\u53ef\u589e\u5f3aLLM\u5728\u533b\u7597\u603b\u7ed3\u751f\u6210\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u901a\u8fc7\u6e90\u6620\u5c04\u548c\u903b\u8f91\u63a7\u5236\uff0cLCDS\u6709\u6548\u7f13\u89e3\u4e86LLM\u751f\u6210\u533b\u7597\u51fa\u9662\u5c0f\u7ed3\u65f6\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5185\u5bb9\u7684\u53ef\u4fe1\u5ea6\u548c\u8ffd\u6eaf\u6027\u3002\u8be5\u7cfb\u7edf\u80fd\u591f\u4fc3\u8fdb\u533b\u7597NLP\u6a21\u578b\u7684\u6301\u7eed\u4f18\u5316\u3002"}}
{"id": "2507.05495", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05495", "abs": "https://arxiv.org/abs/2507.05495", "authors": ["Prahaladh Chandrahasan", "Jiahe Jin", "Zhihan Zhang", "Tevin Wang", "Andy Tang", "Lucy Mo", "Morteza Ziyadi", "Leonardo F. R. Ribeiro", "Zimeng Qiu", "Markus Dreyer", "Akari Asai", "Chenyan Xiong"], "title": "Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents", "comment": null, "summary": "Effectively evaluating deep research agents that autonomously search the web,\nanalyze information, and generate reports remains a major challenge,\nparticularly when it comes to assessing long reports and giving detailed\nfeedback on their intermediate steps. To address these gaps, we introduce Deep\nResearch Comparator, a platform that offers a holistic framework for deep\nresearch agent hosting, side-by-side comparison, fine-grained human feedback\ncollection, and ranking calculation. Given a user query, our platform displays\nthe final reports from two different agents along with their intermediate steps\nduring generation. Annotators can evaluate the overall quality of final reports\nbased on side-by-side comparison, and also provide detailed feedback separately\nby assessing intermediate steps or specific text spans within the final report.\nFurthermore, we develop Simple Deepresearch, an end-to-end agent scaffold. This\nscaffold serves as a baseline that facilitates the easy integration of various\nlarge language models to transform them into deep research agents for\nevaluation. To demonstrate the platform's utility for deep research agent\ndevelopment, we have collected real user preference data from 17 annotators on\nthree deep research agents. A demo video of our platform can be found at\nhttps://www.youtube.com/watch?v=g4d2dnbdseg.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aDeep Research Comparator\u7684\u5e73\u53f0\uff0c\u7528\u4e8e\u6258\u7ba1\u3001\u5e76\u884c\u5bf9\u6bd4\u548c\u8bc4\u4f30\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\uff0c\u5305\u62ec\u6700\u7ec8\u62a5\u544a\u53ca\u5176\u4e2d\u95f4\u6b65\u9aa4\u7684\u8be6\u7ec6\u4eba\u5de5\u53cd\u9988\u3002\u4f5c\u8005\u540c\u65f6\u63d0\u4f9b\u4e86\u53ef\u4f5c\u4e3a\u57fa\u7ebf\u7684\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u5b9e\u73b0\uff0c\u5e76\u516c\u5f00\u4e86\u5b9e\u9645\u7528\u6237\u504f\u597d\u8bc4\u4ef7\u6570\u636e\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u548c\u5f00\u53d1\u63d0\u4f9b\u4e86\u652f\u6301\u3002", "motivation": "\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u53ef\u4ee5\u81ea\u4e3b\u8fdb\u884c\u7f51\u9875\u68c0\u7d22\u3001\u5206\u6790\u4fe1\u606f\u5e76\u751f\u6210\u62a5\u544a\uff0c\u4f46\u5176\u8bc4\u4f30\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u5bf9\u957f\u62a5\u544a\u53ca\u5176\u4e2d\u95f4\u6b65\u9aa4\u8fdb\u884c\u7ec6\u81f4\u53cd\u9988\u65b9\u9762\u5c1a\u65e0\u5b8c\u5584\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Deep Research Comparator\u5e73\u53f0\u3002\u8be5\u5e73\u53f0\u652f\u6301\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u7684\u6258\u7ba1\u3001\u5e76\u884c\u5bf9\u6bd4\u3001\u7ec6\u7c92\u5ea6\u4eba\u5de5\u53cd\u9988\u6536\u96c6\u4e0e\u6392\u540d\u7b97\u6cd5\u3002\u5e73\u53f0\u4f1a\u5c55\u793a\u4e24\u4e2a\u667a\u80fd\u4f53\u9488\u5bf9\u540c\u4e00\u67e5\u8be2\u7684\u6700\u7ec8\u62a5\u544a\u53ca\u5176\u4e2d\u95f4\u751f\u6210\u6b65\u9aa4\uff0c\u4eba\u5de5\u6ce8\u91ca\u5458\u53ef\u5e76\u6392\u6bd4\u8f83\u3001\u7ed9\u51fa\u603b\u4f53\u73b0\u7ed3\u679c\u53cd\u9988\uff0c\u5e76\u5bf9\u4e2d\u95f4\u6b65\u9aa4\u6216\u7279\u5b9a\u62a5\u544a\u6bb5\u843d\u505a\u7ec6\u81f4\u8bc4\u4ef7\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u5f00\u53d1\u4e86Simple Deepresearch\u57fa\u7ebf\u7cfb\u7edf\uff0c\u4fbf\u4e8e\u96c6\u6210\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u53ef\u8bc4\u6d4b\u7684\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u3002", "result": "\u901a\u8fc7\u8be5\u5e73\u53f0\uff0c\u4f5c\u8005\u4ece17\u4f4d\u6ce8\u91ca\u5458\u6536\u96c6\u4e86\u4e09\u79cd\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u7684\u5b9e\u9645\u7528\u6237\u504f\u597d\u6570\u636e\u3002\u5e73\u53f0\u652f\u6301\u7075\u6d3b\u3001\u7cbe\u7ec6\u7684\u8bc4\u4ef7\u548c\u5f00\u53d1\uff0c\u6f14\u793a\u89c6\u9891\u5df2\u53d1\u5e03\u3002", "conclusion": "Deep Research Comparator\u5e73\u53f0\u6709\u6548\u4fc3\u8fdb\u4e86\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u7684\u8bc4\u6d4b\u3001\u5bf9\u6bd4\u53ca\u5f00\u53d1\uff0c\u586b\u8865\u4e86\u957f\u62a5\u544a\u548c\u4e2d\u95f4\u6b65\u9aa4\u7ec6\u81f4\u53cd\u9988\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u5e76\u4e3a\u8be5\u65b9\u5411\u63d0\u4f9b\u4e86\u6570\u636e\u548c\u5de5\u5177\u652f\u6301\u3002"}}
{"id": "2507.05320", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2507.05320", "abs": "https://arxiv.org/abs/2507.05320", "authors": ["Chelsea Thompto"], "title": "Teaching Sustainable Creative Technologies", "comment": "LOCO 2024, December 3, 2024, Glasgow/Online", "summary": "Artists and especially new media artists contribute to public perceptions and\nadoption of new technologies through their own use of emerging media\ntechnologies such as augmented and virtual reality, generative image systems,\nand high-resolution displays in the production of their work. In this way, art\nand media production can be understood as part of the larger issue of\nunsustainable computational consumption. As such, it is critical for artists to\ndevelop, share, and promote new and more sustainable methods of engaging with\ntechnology, especially within the context of higher education. This paper will\nexplore how artists might implement more sustainable methods by considering the\nrelationship between the technical approaches of compute reuse, sustainable web\ndevelopment, and frugal computing, and the concepts of material specificity ,\nfuturity, and media archaeology . Proposing three methods of less\ncarbon-intensive artistic production and a set of guidelines for introducing\nsustainable methods into arts and technology curriculum, this paper will\noutline not only the technical viability of these approaches but also the rich\nconceptual opportunities these approaches might offer to artists and viewers\nalike. For each method, models for pedagogical implementation will be explored\nwith an emphasis on how local resources and sustainability contexts should play\na role.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u65b0\u5a92\u4f53\u827a\u672f\u5bb6\u5728\u63a8\u52a8\u79d1\u6280\u5e94\u7528\u65f6\u9762\u4e34\u7684\u53ef\u6301\u7eed\u6027\u6311\u6218\uff0c\u63d0\u51fa\u4e09\u79cd\u4f4e\u78b3\u827a\u672f\u521b\u4f5c\u53ca\u5176\u8bfe\u7a0b\u63a8\u5e7f\u65b9\u6cd5\uff0c\u65e8\u5728\u517c\u987e\u6280\u672f\u8282\u80fd\u4e0e\u827a\u672f\u521b\u65b0\uff0c\u52a9\u529b\u827a\u672f\u79d1\u6280\u6559\u80b2\u5411\u73af\u4fdd\u65b9\u5411\u53d1\u5c55\u3002", "motivation": "\u65b0\u5a92\u4f53\u827a\u672f\u5bb6\u901a\u8fc7\u5e94\u7528\u589e\u5f3a\u73b0\u5b9e\u3001\u865a\u62df\u73b0\u5b9e\u3001\u751f\u6210\u5f0f\u56fe\u50cf\u7cfb\u7edf\u3001\u9ad8\u5206\u8fa8\u7387\u663e\u793a\u7b49\u524d\u6cbf\u5a92\u4f53\u6280\u672f\uff0c\u5728\u63a8\u52a8\u6280\u672f\u666e\u53ca\u7684\u540c\u65f6\u4e5f\u52a0\u5267\u4e86\u5bf9\u8ba1\u7b97\u8d44\u6e90\u7684\u6d88\u8017\uff0c\u8fd9\u5e26\u6765\u4e86\u4e0d\u53ef\u6301\u7eed\u7684\u8ba1\u7b97\u4f7f\u7528\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u827a\u672f\u5bb6\u6709\u5fc5\u8981\u63a2\u7d22\u4e0e\u63a8\u5e7f\u66f4\u53ef\u6301\u7eed\u7684\u6280\u672f\u5e94\u7528\u65b9\u5f0f\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u7b49\u6559\u80b2\u73af\u5883\u4e2d\u3002", "method": "\u672c\u6587\u63a2\u8ba8\u4e86\u827a\u672f\u5bb6\u91c7\u53d6\u66f4\u53ef\u6301\u7eed\u65b9\u6cd5\u7684\u53ef\u80fd\u6027\uff0c\u5177\u4f53\u7ed3\u5408\u4e86\u8ba1\u7b97\u91cd\u7528\u3001\u53ef\u6301\u7eed\u7f51\u9875\u5f00\u53d1\u4e0e\u8282\u4fed\u8ba1\u7b97\u7b49\u6280\u672f\u624b\u6bb5\uff0c\u5e76\u4e0e\u6750\u6599\u7279\u5f02\u6027\u3001\u672a\u6765\u6027\u548c\u5a92\u4ecb\u8003\u53e4\u7b49\u6982\u5ff5\u7ed3\u5408\u3002\u6587\u7ae0\u63d0\u51fa\u4e86\u4e09\u79cd\u4f4e\u78b3\u827a\u672f\u521b\u4f5c\u65b9\u6cd5\uff0c\u5e76\u5236\u5b9a\u4e86\u4e00\u5957\u5c06\u53ef\u6301\u7eed\u65b9\u6cd5\u5f15\u5165\u827a\u672f\u4e0e\u79d1\u6280\u8bfe\u7a0b\u7684\u6307\u5bfc\u65b9\u9488\u3002\u540c\u65f6\uff0c\u4e3a\u6bcf\u79cd\u65b9\u6cd5\u8bbe\u8ba1\u4e86\u6559\u5b66\u5b9e\u73b0\u6a21\u578b\uff0c\u5f3a\u8c03\u672c\u5730\u8d44\u6e90\u4e0e\u53ef\u6301\u7eed\u60c5\u5883\u7684\u4f5c\u7528\u3002", "result": "\u672c\u6587\u4e0d\u4ec5\u9610\u8ff0\u4e86\u8fd9\u4e9b\u4f4e\u78b3\u827a\u672f\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u8fd8\u5c55\u793a\u4e86\u5176\u4e3a\u827a\u672f\u5bb6\u548c\u89c2\u4f17\u5e26\u6765\u4e30\u5bcc\u6982\u5ff5\u63a2\u7d22\u7684\u6f5c\u529b\u3002\u6b64\u5916\uff0c\u9488\u5bf9\u5982\u4f55\u5728\u827a\u672f\u4e0e\u79d1\u6280\u6559\u80b2\u4e2d\u63a8\u52a8\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u5177\u4f53\u7684\u6559\u5b66\u5b9e\u65bd\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u827a\u672f\u5bb6\u5728\u5a92\u4ecb\u4e0e\u6280\u672f\u521b\u4f5c\u4e2d\u5e94\u91c7\u7528\u66f4\u53ef\u6301\u7eed\u7684\u6280\u672f\u624b\u6bb5\uff0c\u5e76\u9f13\u52b1\u9ad8\u7b49\u6559\u80b2\u4e2d\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u7eb3\u5165\u8bfe\u7a0b\uff0c\u540c\u65f6\u517c\u987e\u6280\u672f\u53ef\u884c\u6027\u4e0e\u827a\u672f\u6982\u5ff5\u63a2\u7d22\uff0c\u4e3a\u63a8\u52a8\u73af\u4fdd\u548c\u521b\u65b0\u505a\u51fa\u8d21\u732e\u3002"}}
{"id": "2507.05330", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05330", "abs": "https://arxiv.org/abs/2507.05330", "authors": ["Ming Gong", "Xucheng Huang", "Chenghan Yang", "Xianhan Peng", "Haoxin Wang", "Yang Liu", "Ling Jiang"], "title": "MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents", "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled new applications\nin e-commerce customer service. However, their capabilities remain constrained\nin complex, multimodal scenarios. We present MindFlow, the first open-source\nmultimodal LLM agent tailored for e-commerce. Built on the CoALA framework, it\nintegrates memory, decision-making, and action modules, and adopts a modular\n\"MLLM-as-Tool\" strategy for effect visual-textual reasoning. Evaluated via\nonline A/B testing and simulation-based ablation, MindFlow demonstrates\nsubstantial gains in handling complex queries, improving user satisfaction, and\nreducing operational costs, with a 93.53% relative improvement observed in\nreal-world deployments.", "AI": {"tldr": "MindFlow\u662f\u4e13\u4e3a\u7535\u5546\u6253\u9020\u7684\u5f00\u6e90\u591a\u6a21\u6001\u5927\u6a21\u578b\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u5927\u5e45\u63d0\u5347\u4e86\u590d\u6742\u573a\u666f\u4e0b\u7684\u5ba2\u670d\u8868\u73b0\uff0c\u5b9e\u73b0\u4e86\u8fd194%\u7684\u73b0\u5b9e\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u7535\u5546\u5ba2\u670d\u9886\u57df\u6709\u65b0\u5e94\u7528\uff0c\u4f46\u5728\u590d\u6742\u3001\u591a\u6a21\u6001\u573a\u666f\u4e0b\u80fd\u529b\u53d7\u9650\u3002\u672c\u6587\u65e8\u5728\u7a81\u7834\u6b64\u74f6\u9888\u3002", "method": "\u63d0\u51faMindFlow\uff0c\u662f\u9996\u4e2a\u4e13\u4e3a\u7535\u5546\u8bbe\u8ba1\u7684\u5f00\u6e90\u591a\u6a21\u6001LLM\u667a\u80fd\u4f53\uff0c\u57fa\u4e8eCoALA\u6846\u67b6\uff0c\u6574\u5408\u8bb0\u5fc6\u3001\u51b3\u7b56\u548c\u884c\u52a8\u7b49\u6a21\u5757\uff0c\u91c7\u7528\u6a21\u5757\u5316\u201cMLLM-as-Tool\u201d\u7b56\u7565\u5b9e\u73b0\u6709\u6548\u7684\u89c6\u89c9-\u6587\u672c\u63a8\u7406\u3002", "result": "\u901a\u8fc7\u5728\u7ebfA/B\u6d4b\u8bd5\u548c\u4eff\u771f\u6d88\u878d\u5b9e\u9a8c\u8bc4\u4f30\uff0cMindFlow\u5728\u771f\u5b9e\u90e8\u7f72\u4e2d\u5904\u7406\u590d\u6742\u67e5\u8be2\u3001\u63d0\u5347\u7528\u6237\u6ee1\u610f\u5ea6\u3001\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u76f8\u5bf9\u63d0\u5347\u8fbe93.53%\u3002", "conclusion": "MindFlow\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u3001\u591a\u6a21\u6001\u7535\u5546\u573a\u666f\u4e2d\u667a\u80fd\u4f53\u7684\u5904\u7406\u80fd\u529b\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.05515", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.05515", "abs": "https://arxiv.org/abs/2507.05515", "authors": ["Haochen Huang", "Jiahuan Pei", "Mohammad Aliannejadi", "Xin Sun", "Moonisa Ahsan", "Pablo Cesar", "Chuang Yu", "Zhaochun Ren", "Junxiao Wang"], "title": "Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality", "comment": "20 pages", "summary": "Vision-language models (VLMs) are essential for enabling AI-powered smart\nassistants to interpret and reason in multimodal environments. However, their\napplication in augmented reality (AR) training remains largely unexplored. In\nthis work, we introduce a comprehensive dataset tailored for AR training,\nfeaturing systematized vision-language tasks, and evaluate nine\nstate-of-the-art VLMs on it. Our results reveal that even advanced models,\nincluding GPT-4o, struggle with fine-grained assembly tasks, achieving a\nmaximum F1 score of just 40.54% on state detection. These findings highlight\nthe demand for enhanced datasets, benchmarks, and further research to improve\nfine-grained vision-language alignment. Beyond technical contributions, our\nwork has broader social implications, particularly in empowering blind and\nvisually impaired users with equitable access to AI-driven learning\nopportunities. We provide all related resources, including the dataset, source\ncode, and evaluation results, to support the research community.", "AI": {"tldr": "\u8bba\u6587\u9996\u6b21\u63d0\u51fa\u9002\u7528\u4e8eAR\u57f9\u8bad\u7684\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u73b0\u6709\u4e3b\u6d41\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5927\u529b\u547c\u5401\u6539\u8fdb\u6570\u636e\u4e0e\u65b9\u6cd5\uff0c\u5c24\u5176\u5173\u6ce8\u5f31\u52bf\u7fa4\u4f53\u53d7\u76ca\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b(VLMs)\u5728\u591a\u6a21\u6001\u73af\u5883\u4e0b\u7684\u89e3\u91ca\u4e0e\u63a8\u7406\u80fd\u529b\u5df2\u8f83\u4e3a\u6210\u719f\uff0c\u4f46\u5176\u5728\u589e\u5f3a\u73b0\u5b9e(AR)\u57f9\u8bad\u4e2d\u7684\u5e94\u7528\u51e0\u4e4e\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u672c\u5de5\u4f5c\u6784\u5efa\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9AR\u57f9\u8bad\u7684\u7cfb\u7edf\u5316\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\u6570\u636e\u96c6\uff0c\u5e76\u7528\u5b83\u5bf9\u4e5d\u4e2a\u6700\u65b0\u7684VLMs\u8fdb\u884c\u8bc4\u6d4b\u3002", "result": "\u6700\u65b0\u7684VLMs\uff0c\u5305\u62ecGPT-4o\uff0c\u5728\u7cbe\u7ec6\u88c5\u914d\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4f9d\u7136\u6709\u9650\uff0c\u72b6\u6001\u68c0\u6d4b\u7684F1\u6700\u9ad8\u4ec5\u4e3a40.54%\u3002", "conclusion": "VLMs\u5728AR\u57f9\u8bad\u4e2d\u5e94\u5bf9\u7ec6\u7c92\u5ea6\u89c6\u89c9-\u8bed\u8a00\u5bf9\u9f50\u8fd8\u6709\u5f88\u957f\u7684\u8def\u8981\u8d70\uff0c\u4e9f\u9700\u66f4\u4e30\u5bcc\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\uff0c\u76f8\u5173\u7814\u7a76\u4e9f\u5f85\u52a0\u5f3a\u3002"}}
{"id": "2507.05321", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05321", "abs": "https://arxiv.org/abs/2507.05321", "authors": ["Kwangsuk Park", "Jiwoong Yang"], "title": "AGACCI : Affiliated Grading Agents for Criteria-Centric Interface in Educational Coding Contexts", "comment": "Accepted at ICML 2025 Workshop on Multi-Agent Systems in the Era of\n  Foundation Models: Opportunities, Challenges and Futures (MAS)", "summary": "Recent advances in AI-assisted education have encouraged the integration of\nvision-language models (VLMs) into academic assessment, particularly for tasks\nthat require both quantitative and qualitative evaluation. However, existing\nVLM based approaches struggle with complex educational artifacts, such as\nprogramming tasks with executable components and measurable outputs, that\nrequire structured reasoning and alignment with clearly defined evaluation\ncriteria. We introduce AGACCI, a multi-agent system that distributes\nspecialized evaluation roles across collaborative agents to improve accuracy,\ninterpretability, and consistency in code-oriented assessment. To evaluate the\nframework, we collected 360 graduate-level code-based assignments from 60\nparticipants, each annotated by domain experts with binary rubric scores and\nqualitative feedback. Experimental results demonstrate that AGACCI outperforms\na single GPT-based baseline in terms of rubric and feedback accuracy,\nrelevance, consistency, and coherence, while preserving the instructional\nintent and evaluative depth of expert assessments. Although performance varies\nacross task types, AGACCI highlights the potential of multi-agent systems for\nscalable and context-aware educational evaluation.", "AI": {"tldr": "AGACCI\u591a\u4ee3\u7406\u7cfb\u7edf\u901a\u8fc7\u89d2\u8272\u5206\u5de5\u63d0\u5347\u4e86\u9488\u5bf9\u4ee3\u7801\u7c7b\u5b66\u672f\u4efb\u52a1\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u8868\u73b0\uff0c\u5728\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u548c\u8bc4\u5224\u6df1\u5ea6\u4e0a\u660e\u663e\u4f18\u4e8e\u5355\u4e00VLM\uff0c\u5c55\u73b0\u4e86AI\u8f85\u52a9\u6559\u80b2\u8bc4\u4f30\u7684\u5e7f\u9614\u524d\u666f\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eVLM\u7684\u5b66\u672f\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u590d\u6742\u3001\u7ed3\u6784\u5316\u7684\u4ee3\u7801\u4efb\u52a1\uff0c\u7f3a\u5c11\u5bf9\u5177\u4f53\u8bc4\u4ef7\u6807\u51c6\u548c\u6df1\u5c42\u7ed3\u6784\u63a8\u7406\u7684\u517c\u5bb9\uff0c\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u8bc4\u4ef7\u7cfb\u7edf\u63d0\u5347\u51c6\u786e\u6027\u4e0e\u89e3\u91ca\u6027\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51faAGACCI\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u5c06\u590d\u6742\u7684\u8bc4\u4f30\u4efb\u52a1\u5206\u914d\u7ed9\u534f\u4f5c\u7684\u5404\u4e2a\u4e13\u95e8\u4ee3\u7406\uff0c\u5e76\u901a\u8fc7\u6536\u96c660\u540d\u53c2\u4e0e\u8005\u7684360\u4efd\u7814\u7a76\u751f\u7ea7\u4ee3\u7801\u4f5c\u4e1a\uff0c\u7ed3\u5408\u4e13\u5bb6\u4e8c\u503c\u8bc4\u5206\u548c\u5b9a\u6027\u53cd\u9988\uff0c\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAGACCI\u5728\u8bc4\u5206\u548c\u53cd\u9988\u7684\u51c6\u786e\u6027\u3001\u76f8\u5173\u6027\u3001\u4e00\u81f4\u6027\u548c\u8fde\u8d2f\u6027\u65b9\u9762\u5747\u4f18\u4e8eGPT\u57fa\u7ebf\u7cfb\u7edf\uff0c\u540c\u65f6\u53ef\u4ee5\u66f4\u597d\u5730\u4f53\u73b0\u4e13\u5bb6\u8bc4\u5ba1\u7684\u6559\u5b66\u610f\u56fe\u548c\u8bc4\u4ef7\u6df1\u5ea6\uff0c\u5c3d\u7ba1\u5728\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u95f4\u8868\u73b0\u6709\u6240\u6ce2\u52a8\u3002", "conclusion": "AGACCI\u591a\u4ee3\u7406\u7cfb\u7edf\u7528\u4e8e\u4ee3\u7801\u5bfc\u5411\u6027\u5b66\u672f\u8bc4\u4f30\uff0c\u5728\u8bc4\u5206\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u548c\u6df1\u5ea6\u7b49\u591a\u65b9\u9762\u4f18\u4e8e\u5355\u4e00GPT\u57fa\u7ebf\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\u5728\u6559\u80b2\u8bc4\u4f30\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.05346", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05346", "abs": "https://arxiv.org/abs/2507.05346", "authors": ["William Fleshman", "Benjamin Van Durme"], "title": "LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks", "comment": null, "summary": "The proliferation of fine-tuned language model experts for specific tasks and\ndomains signals the need for efficient selection and combination methods. We\npropose LoRA-Augmented Generation (LAG) for leveraging large libraries of\nknowledge and task-specific LoRA adapters. LAG requires no additional training\nor access to data, and efficiently filters, retrieves, and applies experts on a\nper-token and layer basis. We evaluate LAG on various knowledge-intensive\ntasks, achieving superior performance over existing data-free methods. We\nexplore scenarios where additional data is available, demonstrating LAG's\ncompatibility with alternative solutions such as retrieval-augmented generation\n(RAG).", "AI": {"tldr": "LAG\u901a\u8fc7\u52a8\u6001\u8c03\u7528LoRA\u4e13\u5bb6\u6a21\u578b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u548c\u6570\u636e\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u4efb\u52a1\u77e5\u8bc6\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e14\u9002\u7528\u4e8e\u591a\u79cd\u73b0\u5b9e\u573a\u666f\u3002", "motivation": "\u968f\u7740\u4e13\u7528\u4efb\u52a1\u548c\u9886\u57df\u7684\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u4e13\u5bb6\u7684\u5927\u91cf\u51fa\u73b0\uff0c\u5982\u4f55\u9ad8\u6548\u9009\u62e9\u548c\u7ec4\u5408\u8fd9\u4e9b\u4e13\u5bb6\u6210\u4e3a\u4e00\u4e2a\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5LoRA-Augmented Generation (LAG)\uff0c\u80fd\u591f\u5229\u7528\u5305\u542b\u4e30\u5bcc\u77e5\u8bc6\u548c\u4efb\u52a1\u5b9a\u5236LoRA\u9002\u914d\u5668\u7684\u5927\u578b\u6a21\u578b\u5e93\u3002LAG\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u548c\u6570\u636e\uff0c\u80fd\u591f\u5728\u6bcf\u4e2atoken\u548c\u5c42\u7ea7\u4e0a\u9ad8\u6548\u7b5b\u9009\u3001\u68c0\u7d22\u548c\u5e94\u7528\u4e13\u5bb6\u6a21\u578b\u3002", "result": "\u5728\u591a\u79cd\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\uff0cLAG\u76f8\u6bd4\u73b0\u6709\u65e0\u6570\u636e\u7684\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002\u540c\u65f6\u63a2\u8ba8\u4e86\u5728\u5b58\u5728\u989d\u5916\u6570\u636e\u65f6\uff0cLAG\u53ef\u4ee5\u4e0eRAG\u7b49\u5176\u4ed6\u65b9\u6848\u517c\u5bb9\u3002", "conclusion": "LAG\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u517c\u5bb9\u7684\u6570\u636e\u65e0\u5173\u4e13\u5bb6\u9009\u62e9\u4e0e\u7ec4\u5408\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u5347\u77e5\u8bc6\u4efb\u52a1\u8868\u73b0\uff0c\u5e76\u6613\u4e8e\u4e0e\u6570\u636e\u589e\u5f3a\u65b9\u6848\u7ed3\u5408\u3002"}}
{"id": "2507.05519", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.05519", "abs": "https://arxiv.org/abs/2507.05519", "authors": ["Gopal Gupta", "Abhiramon Rajasekharan", "Alexis R. Tudor", "Elmer Salazar", "Joaqu\u00edn Arias"], "title": "Modeling (Deontic) Modal Operators With the s(CASP) Goal-directed Predicated Answer Set Programming System", "comment": null, "summary": "We consider the problem of implementing deontic modal logic. We show how\n(deontic) modal operators can be expressed elegantly using default negation\n(negation-as-failure) and strong negation present in answer set programming\n(ASP). We propose using global constraints of ASP to represent obligations and\nimpermissibilities of deontic modal logic. We show that our proposed\nrepresentation results in the various paradoxes of deontic modal logic being\nelegantly resolved.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528ASP\u7684\u9ed8\u8ba4\u5426\u5b9a\u548c\u5168\u5c40\u7ea6\u675f\u6765\u4f18\u96c5\u8868\u8fbe\u548c\u5b9e\u73b0\u89c4\u8303\u6a21\u6001\u903b\u8f91\u7b97\u5b50\uff0c\u4ece\u800c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e0b\u4ea7\u751f\u7684\u89c4\u8303\u6096\u8bba\u95ee\u9898\u3002", "motivation": "\u89c4\u8303\u6a21\u6001\u903b\u8f91\u5e7f\u6cdb\u5e94\u7528\u4e8e\u9053\u5fb7\u3001\u6cd5\u5f8b\u3001\u4eba\u5de5\u667a\u80fd\u7b49\u9886\u57df\uff0c\u4f46\u7ecf\u5178\u8868\u8fbe\u5e38\u5e38\u4ea7\u751f\u6096\u8bba\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u5b9e\u73b0\u65b9\u6cd5\u4ee5\u66f4\u597d\u5730\u8868\u8fbe\u89c4\u8303\u6027\u547d\u9898\u3002", "method": "\u5c06\uff08\u89c4\u8303\uff09\u6a21\u6001\u7b97\u5b50\u4ee5\u9ed8\u8ba4\u5426\u5b9a\uff08\u5373\u201c\u4f5c\u4e3a\u5931\u8d25\u7684\u5426\u5b9a\u201d\uff09\u548c\u5f3a\u5426\u5b9a\u7ed3\u5408\u5728ASP\u4e2d\u5b9e\u73b0\uff0c\u5229\u7528ASP\u7684\u5168\u5c40\u7ea6\u675f\u523b\u753b\u4e49\u52a1\u4e0e\u7981\u6b62\u3002", "result": "\u8bc1\u660e\u4e86ASP\u4e2d\u5229\u7528\u9ed8\u8ba4\u5426\u5b9a\u548c\u5f3a\u5426\u5b9a\u53ef\u4ee5\u4f18\u96c5\u5730\u8868\u8fbe\u89c4\u8303\u6a21\u6001\u7b97\u5b50\uff0c\u5e76\u7528\u5168\u5c40\u7ea6\u675f\u5b9e\u73b0\u4e49\u52a1\u548c\u7981\u6b62\uff0c\u89e3\u51b3\u4e86\u8bb8\u591a\u89c4\u8303\u6a21\u6001\u903b\u8f91\u4e2d\u7684\u8457\u540d\u6096\u8bba\u3002", "conclusion": "\u901a\u8fc7\u5c06\u4e49\u52a1\u548c\u7981\u6b62\u7b49\u89c4\u8303\u6027\u547d\u9898\u7528ASP\u7684\u5168\u5c40\u7ea6\u675f\u8fdb\u884c\u8868\u793a\uff0c\u8bb8\u591a\u89c4\u8303\u6a21\u6001\u903b\u8f91\u7684\u6096\u8bba\u80fd\u591f\u5f97\u5230\u4f18\u96c5\u7684\u89e3\u51b3\u3002"}}
{"id": "2507.05400", "categories": ["cs.CY", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2507.05400", "abs": "https://arxiv.org/abs/2507.05400", "authors": ["Mohammad Hossein Azin", "Hessam Zandhessami"], "title": "Strategic Alignment Patterns in National AI Policies", "comment": null, "summary": "This paper introduces a novel visual mapping methodology for assessing\nstrategic alignment in national artificial intelligence policies. The\nproliferation of AI strategies across countries has created an urgent need for\nanalytical frameworks that can evaluate policy coherence between strategic\nobjectives, foresight methods, and implementation instruments. Drawing on data\nfrom the OECD AI Policy Observatory, we analyze 15-20 national AI strategies\nusing a combination of matrix-based visualization and network analysis to\nidentify patterns of alignment and misalignment. Our findings reveal distinct\nalignment archetypes across governance models, with notable variations in how\ncountries integrate foresight methodologies with implementation planning.\nHigh-coherence strategies demonstrate strong interconnections between economic\ncompetitiveness objectives and robust innovation funding instruments, while\ncommon vulnerabilities include misalignment between ethical AI objectives and\ncorresponding regulatory frameworks. The proposed visual mapping approach\noffers both methodological contributions to policy analysis and practical\ninsights for enhancing strategic coherence in AI governance. This research\naddresses significant gaps in policy evaluation methodology and provides\nactionable guidance for policymakers seeking to strengthen alignment in\ntechnological governance frameworks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u53ef\u89c6\u5316\u65b9\u6cd5\u8bc4\u4f30\u56fd\u5bb6AI\u653f\u7b56\u6218\u7565\u534f\u540c\uff0c\u7528\u77e9\u9635\u548c\u7f51\u7edc\u5206\u6790\u5bf9\u6bd4\u4e0d\u540c\u56fd\u5bb6\u653f\u7b56\uff0c\u63ed\u793a\u7ecf\u6d4e\u76ee\u6807\u4e0e\u521b\u65b0\u8d44\u91d1\u534f\u540c\u826f\u597d\uff0c\u4f26\u7406\u76ee\u6807\u4e0e\u76d1\u7ba1\u5b58\u5728\u8131\u8282\uff0c\u5e76\u4e3a\u653f\u7b56\u6539\u8fdb\u63d0\u4f9b\u65b9\u6cd5\u548c\u5efa\u8bae\u3002", "motivation": "\u5f53\u524d\u5404\u56fd\u7eb7\u7eb7\u51fa\u53f0\u4eba\u5de5\u667a\u80fd\u56fd\u5bb6\u6218\u7565\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u7684\u5206\u6790\u6846\u67b6\u4ee5\u8bc4\u4f30\u6218\u7565\u76ee\u6807\u3001\u524d\u77bb\u65b9\u6cd5\u4e0e\u5b9e\u65bd\u5de5\u5177\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u6709\u6548\u5206\u6790\u548c\u8bc4\u4f30\u653f\u7b56\u534f\u540c\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u7ecf\u5408\u7ec4\u7ec7\uff08OECD\uff09AI\u653f\u7b56\u6570\u636e\u5e93\uff0c\u9009\u53d615-20\u4e2a\u56fd\u5bb6\u7684AI\u6218\u7565\uff0c\u8fd0\u7528\u77e9\u9635\u53ef\u89c6\u5316\u548c\u7f51\u7edc\u5206\u6790\u5de5\u5177\uff0c\u5bf9\u8fd9\u4e9b\u56fd\u5bb6AI\u653f\u7b56\u4e2d\u7684\u6218\u7565\u4e00\u81f4\u6027\u8fdb\u884c\u5206\u6790\u548c\u56fe\u793a\u5316\u5c55\u793a\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u6cbb\u7406\u6a21\u5f0f\u4e0b\u5b58\u5728\u5404\u81ea\u7684\u6218\u7565\u534f\u540c\u7c7b\u578b\uff0c\u9ad8\u4e00\u81f4\u6027\u7684\u7b56\u7565\u901a\u5e38\u8868\u73b0\u4e3a\u7ecf\u6d4e\u7ade\u4e89\u529b\u76ee\u6807\u548c\u521b\u65b0\u8d44\u91d1\u5de5\u5177\u4e4b\u95f4\u6709\u7d27\u5bc6\u8054\u7cfb\uff0c\u5e38\u89c1\u7684\u95ee\u9898\u5219\u662f\u4f26\u7406AI\u76ee\u6807\u4e0e\u76f8\u5e94\u76d1\u7ba1\u6846\u67b6\u4e4b\u95f4\u534f\u540c\u4e0d\u8db3\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u7684\u53ef\u89c6\u5316\u6620\u5c04\u65b9\u6cd5\u4e0d\u4ec5\u4e30\u5bcc\u4e86\u653f\u7b56\u5206\u6790\u5de5\u5177\uff0c\u8fd8\u4e3a\u52a0\u5f3aAI\u6cbb\u7406\u653f\u7b56\u6218\u7565\u534f\u540c\u63d0\u4f9b\u4e86\u5b9e\u8df5\u53c2\u8003\uff0c\u5bf9\u653f\u7b56\u5236\u5b9a\u8005\u5177\u6709\u5b9e\u9645\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2507.05362", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05362", "abs": "https://arxiv.org/abs/2507.05362", "authors": ["Riccardo Alberghi", "Elizaveta Demyanenko", "Luca Biggio", "Luca Saglietti"], "title": "On the Bias of Next-Token Predictors Toward Systematically Inefficient Reasoning: A Shortest-Path Case Study", "comment": null, "summary": "Recent advances in natural language processing highlight two key factors for\nimproving reasoning in large language models (LLMs): (i) allocating more\ntest-time compute tends to help on harder problems but often introduces\nredundancy in the reasoning trace, and (ii) compute is most effective when\nreasoning is systematic and incremental, forming structured chains of thought\n(CoTs) akin to human problem-solving. To study these factors in isolation, we\nintroduce a controlled setting based on shortest-path tasks in layered graphs.\nWe train decoder-only transformers on question-trace-answer triples using a\ncustom tokenizer, comparing models trained on optimal bottom-up dynamic\nprogramming traces with those trained on longer, valid traces involving\nbacktracking. Surprisingly, with the same training-token budget, models trained\non inefficient traces generalize better to unseen graphs. This benefit is not\ndue to length alone-injecting arbitrary redundancy into reasoning traces fails\nto help and can even hurt performance. Instead, we find that generalization\ncorrelates with the model's confidence in next-token prediction, suggesting\nthat long, coherent, and locally incremental traces make the training signal\neasier to optimize.", "AI": {"tldr": "\u4f5c\u8005\u901a\u8fc7\u6700\u77ed\u8def\u5f84\u4efb\u52a1\u53d1\u73b0\uff1a\u8bad\u7ec3\u65f6\u4ee5\u8f83\u957f\u4f46\u7ed3\u6784\u5316\u7684\u63a8\u7406\u8f68\u8ff9\uff08\u5305\u62ec\u56de\u6eaf\uff09\u5582\u7ed9\u5927\u6a21\u578b\uff0c\u80fd\u663e\u8457\u63d0\u5347\u5176\u6cdb\u5316\u80fd\u529b\uff0c\u800c\u7b80\u5355\u5ef6\u957f\u63a8\u7406\u8f68\u8ff9\u65e0\u76ca\u3002\u63d0\u5347\u6cdb\u5316\u4f9d\u8d56\u63a8\u7406\u7684\u8fde\u8d2f\u6027\u4e0e\u9012\u8fdb\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u53d1\u73b0\uff1a\u589e\u52a0\u63a8\u7406\u9636\u6bb5\u7684\u8ba1\u7b97\u91cf\u6709\u52a9\u4e8e\u63d0\u5347LLM\u89e3\u51b3\u590d\u6742\u95ee\u9898\u7684\u80fd\u529b\uff0c\u7ed3\u6784\u5316\u5e76\u9012\u8fdb\u7684\u63a8\u7406\u8f68\u8ff9\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5982\u4f55\u6700\u5927\u5316\u8fd9\u4e24\u8005\u7684\u534f\u540c\u6548\u679c\u3002\u4f5c\u8005\u63d0\u51fa\u901a\u8fc7\u53d7\u63a7\u5b9e\u9a8c\u5206\u6790\u5197\u4f59\u63a8\u7406\u3001\u7cfb\u7edf\u6027\u63a8\u7406\u548c\u6cdb\u5316\u6027\u80fd\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u4f5c\u8005\u4ee5\u5206\u5c42\u56fe\u7684\u6700\u77ed\u8def\u5f84\u4efb\u52a1\u4e3a\u7814\u7a76\u573a\u666f\uff0c\u4f7f\u7528\u81ea\u5b9a\u4e49\u5206\u8bcd\u5668\u548cdecoder-only transformer\uff0c\u5bf9\u6bd4\u4e24\u7c7b\u8bad\u7ec3\u6570\u636e\uff1a\u4e00\u79cd\u662f\u6700\u4f18\u4e14\u81ea\u5e95\u5411\u4e0a\u7684\u52a8\u6001\u89c4\u5212\u63a8\u7406\u8f68\u8ff9\uff0c\u53e6\u4e00\u79cd\u662f\u5305\u62ec\u56de\u6eaf\u7684\u4f46\u4ecd\u6709\u6548\u7684\u8f83\u957f\u63a8\u7406\u8f68\u8ff9\u3002\u901a\u8fc7\u76f8\u540c\u8bad\u7ec3token\u9884\u7b97\u4e0b\uff0c\u5bf9\u6bd4\u6a21\u578b\u5728\u672a\u89c1\u56fe\u7684\u6cdb\u5316\u8868\u73b0\u3002", "result": "\u4f7f\u7528\u5305\u542b\u56de\u6eaf\u3001\u5197\u4f59\u4f46\u903b\u8f91\u81ea\u6d3d\u7684\u957f\u63a8\u7406\u8f68\u8ff9\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u6bd4\u7528\u6700\u4f18\u63a8\u7406\u8f68\u8ff9\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u5176\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\uff08\u5728\u65b0\u56fe\u4e0a\u8868\u73b0\u66f4\u597d\uff09\u3002\u5355\u7eaf\u589e\u52a0\u63a8\u7406\u8f68\u8ff9\u957f\u5ea6\u3001\u5f15\u5165\u968f\u673a\u5197\u4f59\u5e76\u4e0d\u63d0\u5347\u6027\u80fd\uff0c\u90e8\u5206\u60c5\u51b5\u4e0b\u8fd8\u4f1a\u5bfc\u81f4\u6548\u679c\u4e0b\u964d\u3002\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0e\u4e0b\u4e00\u4e2atoken\u7684\u7f6e\u4fe1\u5ea6\u76f8\u5173\uff0c\u9ad8\u7f6e\u4fe1\u5ea6\u4f34\u968f\u8fde\u8d2f\u9010\u6b65\u7684\u63a8\u7406\u8f68\u8ff9\u3002", "conclusion": "\u957f\u4f46\u4f4e\u6548\u7684\u63a8\u7406\u8fc7\u7a0b\uff08\u5982\u5305\u542b\u56de\u6eaf\u7684\u63a8\u7406\u8f68\u8ff9\uff09\u80fd\u591f\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7c7b\u4f3c\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5176\u6548\u679c\u8d85\u8fc7\u4ec5\u4ec5\u589e\u52a0\u63a8\u7406\u957f\u5ea6\u3002\u63d0\u5347\u6cdb\u5316\u4e3b\u8981\u4e0e\u63a8\u7406\u8f68\u8ff9\u7684\u7ed3\u6784\u548c\u8fde\u8d2f\u6027\u6709\u5173\u3002"}}
{"id": "2507.05520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05520", "abs": "https://arxiv.org/abs/2507.05520", "authors": ["Karishma Thakrar", "Shreyas Basavatia", "Akshay Daftardar"], "title": "Cultivating Multimodal Intelligence: Interpretive Reasoning and Agentic RAG Approaches to Dermatological Diagnosis", "comment": "2025 ImageCLEF MEDIQA-MAGIC Challenge", "summary": "The second edition of the 2025 ImageCLEF MEDIQA-MAGIC challenge, co-organized\nby researchers from Microsoft, Stanford University, and the Hospital Clinic of\nBarcelona, focuses on multimodal dermatology question answering and\nsegmentation, using real-world patient queries and images. This work addresses\nthe Closed Visual Question Answering (CVQA) task, where the goal is to select\nthe correct answer to multiple-choice clinical questions based on both\nuser-submitted images and accompanying symptom descriptions. The proposed\napproach combines three core components: (1) fine-tuning open-source multimodal\nmodels from the Qwen, Gemma, and LLaMA families on the competition dataset, (2)\nintroducing a structured reasoning layer that reconciles and adjudicates\nbetween candidate model outputs, and (3) incorporating agentic\nretrieval-augmented generation (agentic RAG), which adds relevant information\nfrom the American Academy of Dermatology's symptom and condition database to\nfill in gaps in patient context. The team achieved second place with a\nsubmission that scored sixth, demonstrating competitive performance and high\naccuracy. Beyond competitive benchmarks, this research addresses a practical\nchallenge in telemedicine: diagnostic decisions must often be made\nasynchronously, with limited input and with high accuracy and interpretability.\nBy emulating the systematic reasoning patterns employed by dermatologists when\nevaluating skin conditions, this architecture provided a pathway toward more\nreliable automated diagnostic support systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u7ed3\u5408\u591a\u6a21\u6001\u5927\u6a21\u578b\u5fae\u8c03\u3001\u7ed3\u6784\u5316\u63a8\u7406\u548c\u77e5\u8bc6\u589e\u5f3a\u673a\u5236\u7684\u76ae\u80a4\u79d1\u591a\u6a21\u6001\u95ee\u7b54\u7cfb\u7edf\uff0c\u5728\u56fd\u9645\u6311\u6218\u8d5b\u4e2d\u53d6\u5f97\u4f73\u7ee9\uff0c\u5e76\u4e3a\u8fdc\u7a0b\u533b\u5b66\u81ea\u52a8\u5316\u8bca\u65ad\u63d0\u4f9b\u53ef\u884c\u8def\u5f84\u3002", "motivation": "\u8be5\u7814\u7a76\u5173\u6ce8\u76ae\u80a4\u75c5\u8fdc\u7a0b\u8bca\u65ad\u4e2d\u7684\u96be\u9898\uff1a\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\uff0c\u533b\u751f\u9700\u8981\u57fa\u4e8e\u6709\u9650\u7684\u56fe\u7247\u548c\u75c7\u72b6\u63cf\u8ff0\u4f5c\u51fa\u9ad8\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u7684\u8bca\u65ad\u51b3\u7b56\u3002\u672c\u9879\u76ee\u5e0c\u671b\u63d0\u9ad8\u81ea\u52a8\u5316\u76ae\u80a4\u75c5\u8bca\u65ad\u7cfb\u7edf\u5728\u8fd9\u79cd\u5e94\u7528\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u65b9\u6cd5\u4e0a\uff0c\u56e2\u961f\u5bf9\u5f00\u6e90\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08Qwen\u3001Gemma\u3001LLaMA\u7cfb\u5217\uff09\u8fdb\u884c\u5fae\u8c03\uff0c\u7ed3\u5408\u6bd4\u8d5b\u6570\u636e\u96c6\u3002\u521b\u65b0\u5730\u5f15\u5165\u7ed3\u6784\u5316\u63a8\u7406\u5c42\uff0c\u7528\u4e8e\u88c1\u51b3\u548c\u6574\u5408\u5019\u9009\u6a21\u578b\u7ed3\u679c\u3002\u540c\u65f6\uff0c\u901a\u8fc7Agentic RAG\u673a\u5236\uff0c\u4ece\u6743\u5a01\u6570\u636e\u5e93\u52a8\u6001\u8865\u5145\u76f8\u5173\u75c7\u72b6/\u75be\u75c5\u4fe1\u606f\uff0c\u589e\u5f3a\u60a3\u8005\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u63d0\u5347\u6a21\u578b\u7406\u89e3\u80fd\u529b\u3002\u6574\u5408\u4ee5\u4e0a\u4e09\u8005\uff0c\u5f62\u6210\u95ed\u96c6\u89c6\u89c9\u95ee\u7b54\uff08CVQA\uff09\u7cfb\u7edf\u3002", "result": "\u56e2\u961f\u7684\u65b9\u6848\u5728ImageCLEF MEDIQA-MAGIC 2025\u6311\u6218\u8d5b\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u53d6\u5f97\u7b2c\u4e8c\u540d\uff08\u63d0\u4ea4\u6392\u540d\u7b2c\u516d\uff09\uff0c\u5c55\u793a\u4e86\u7cfb\u7edf\u7684\u9ad8\u51c6\u786e\u7387\u548c\u7ade\u4e89\u529b\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u5b9e\u9645\u8bca\u65ad\u652f\u6301\u80fd\u529b\u3002", "conclusion": "\u8be5\u67b6\u6784\u901a\u8fc7\u6a21\u62df\u76ae\u80a4\u79d1\u533b\u751f\u7cfb\u7edf\u5316\u63a8\u7406\u6d41\u7a0b\uff0c\u4e3a\u76ae\u80a4\u75c5\u8fdc\u7a0b\u8bca\u65ad\u4e2d\u7684\u81ea\u52a8\u5316\u8f85\u52a9\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5bf9\u5b9e\u9645\u5e94\u7528\u6709\u91cd\u8981\u63a8\u52a8\u610f\u4e49\u3002"}}
{"id": "2507.05549", "categories": ["cs.CY", "cs.AI", "cs.HC", "I.2.0"], "pdf": "https://arxiv.org/pdf/2507.05549", "abs": "https://arxiv.org/abs/2507.05549", "authors": ["Prerana Khatiwada", "Joshua Washington", "Tyler Walsh", "Ahmed Saif Hamed", "Lokesh Bhatta"], "title": "The Ethical Implications of AI in Creative Industries: A Focus on AI-Generated Art", "comment": "7 pages", "summary": "As Artificial Intelligence (AI) continues to grow daily, more exciting (and\nsomewhat controversial) technology emerges every other day. As we see the\nadvancements in AI, we see more and more people becoming skeptical of it. This\npaper explores the complications and confusion around the ethics of generative\nAI art. We delve deep into the ethical side of AI, specifically generative art.\nWe step back from the excitement and observe the impossible conundrums that\nthis impressive technology produces. Covering environmental consequences,\ncelebrity representation, intellectual property, deep fakes, and artist\ndisplacement. Our research found that generative AI art is responsible for\nincreased carbon emissions, spreading misinformation, copyright infringement,\nunlawful depiction, and job displacement. In light of this, we propose multiple\npossible solutions for these problems. We address each situation's history,\ncause, and consequences and offer different viewpoints. At the root of it all,\nthough, the central theme is that generative AI Art needs to be correctly\nlegislated and regulated.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u751f\u6210\u5f0fAI\u827a\u672f\u5f15\u53d1\u7684\u4f26\u7406\u96be\u9898\uff0c\u5305\u62ec\u73af\u5883\u3001\u7248\u6743\u3001\u865a\u5047\u4fe1\u606f\u548c\u827a\u672f\u5bb6\u751f\u8ba1\u7b49\uff0c\u63d0\u51fa\u9700\u52a0\u5f3a\u7acb\u6cd5\u76d1\u7ba1\u4ee5\u51cf\u5c11\u8d1f\u9762\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u751f\u6210\u5f0fAI\u827a\u672f\u5f15\u53d1\u4e86\u8bf8\u591a\u4f26\u7406\u4e0a\u7684\u4e89\u8bae\u548c\u56f0\u60d1\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u5176\u5e26\u6765\u7684\u591a\u91cd\u5f71\u54cd\u3002", "method": "\u8bba\u6587\u4ece\u591a\u4e2a\u89d2\u5ea6\u63a2\u8ba8\u751f\u6210\u5f0fAI\u827a\u672f\u7684\u4f26\u7406\u95ee\u9898\uff0c\u5305\u62ec\u5bf9\u73af\u5883\u5f71\u54cd\u3001\u540d\u4eba\u8096\u50cf\u3001\u77e5\u8bc6\u4ea7\u6743\u3001\u6df1\u5ea6\u4f2a\u9020\u548c\u827a\u672f\u5bb6\u751f\u8ba1\u7684\u5f71\u54cd\uff0c\u7ed3\u5408\u6848\u4f8b\u7814\u7a76\u548c\u5404\u65b9\u89c2\u70b9\uff0c\u5206\u6790\u95ee\u9898\u7684\u6210\u56e0\u3001\u5386\u53f2\u548c\u540e\u679c\uff0c\u5e76\u63d0\u51fa\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u751f\u6210\u5f0fAI\u827a\u672f\u5bfc\u81f4\u4e86\u78b3\u6392\u653e\u589e\u52a0\u3001\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u3001\u7248\u6743\u4fb5\u72af\u3001\u975e\u6cd5\u8096\u50cf\u4f7f\u7528\u548c\u827a\u672f\u5de5\u4f5c\u5c97\u4f4d\u51cf\u5c11\u7b49\u95ee\u9898\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u827a\u672f\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u4e25\u91cd\u7684\u4f26\u7406\u4e0e\u793e\u4f1a\u95ee\u9898\uff0c\u4e9f\u9700\u51fa\u53f0\u5408\u7406\u7684\u7acb\u6cd5\u548c\u76d1\u7ba1\u63aa\u65bd\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002"}}
