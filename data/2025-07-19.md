<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 20]
- [cs.CL](#cs.CL) [Total: 36]
- [cs.CE](#cs.CE) [Total: 5]
- [cs.CY](#cs.CY) [Total: 7]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](https://arxiv.org/abs/2507.12484)
*Jarosław A. Chudziak,Adam Kostka*

Main category: cs.AI

TL;DR: 本文提出了一种多智能体AI数学辅导平台，通过个性化、结构化和工具辅助，克服现有AI辅导系统的局限，提升了数学学习的有效性和个性化。


<details>
  <summary>Details</summary>
Motivation: 当前AI辅导系统大多仅以被动应答为主，缺乏引导深度思考和结构化教学工具，尤其在数学领域极为明显。为提升AI辅导系统教育效果，有必要设计更主动和多工具协作的系统。

Method: 研发并实现了一个由多个AI代理协同工作的辅导平台，集成个性化反馈、结构化课程和教材知识检索等模块，在数学学习场景中进行测试和应用。

Result: 新平台可帮助学生识别薄弱知识点、进行高效复习和个性化练习，显著增强了AI在数学教育中的实际应用和教学效果。该平台拓展了AI教育技术领域在数学教学中的应用边界。

Conclusion: 本文提出了一个集成多智能体的AI数学辅导平台，通过结合自适应个性化反馈、结构化课程生成和教材知识检索，推动AI辅导系统从被动应答向结构化、个性化和工具辅助的学习体验转变。该平台可有效提升数学学习过程，更好地支持学生的个别差异和复习需求。

Abstract: The growing ubiquity of artificial intelligence (AI), in particular large
language models (LLMs), has profoundly altered the way in which learners gain
knowledge and interact with learning material, with many claiming that AI
positively influences their learning achievements. Despite this advancement,
current AI tutoring systems face limitations associated with their reactive
nature, often providing direct answers without encouraging deep reflection or
incorporating structured pedagogical tools and strategies. This limitation is
most apparent in the field of mathematics, in which AI tutoring systems remain
underdeveloped. This research addresses the question: How can AI tutoring
systems move beyond providing reactive assistance to enable structured,
individualized, and tool-assisted learning experiences? We introduce a novel
multi-agent AI tutoring platform that combines adaptive and personalized
feedback, structured course generation, and textbook knowledge retrieval to
enable modular, tool-assisted learning processes. This system allows students
to learn new topics while identifying and targeting their weaknesses, revise
for exams effectively, and practice on an unlimited number of personalized
exercises. This article contributes to the field of artificial intelligence in
education by introducing a novel platform that brings together pedagogical
agents and AI-driven components, augmenting the field with modular and
effective systems for teaching mathematics.

</details>


### [2] [MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](https://arxiv.org/abs/2507.12494)
*Dustin Holley,Jovin D'sa,Hossein Nourkhiz Mahjoub,Gibran Ali*

Main category: cs.AI

TL;DR: 本文提出一种结合博弈论决策和动力学的模型，有效提升了高速公路并道场景中仿真代理的真实与可解释性，通过真实数据验证并具备大规模仿真效率，有助于自动驾驶研发。


<details>
  <summary>Details</summary>
Motivation: 为了自动驾驶汽车技术的发展，需要仿真环境中的交通参与者更加贴近真实人类驾驶行为，特别是在高速公路并道场景下更好地模拟司机间的互动。

Method: 提出一种基于博弈论的策略决策模型，改进了收益函数和跟车行为建模，并与底层动力学模型结合，实现统一的决策与动力学仿真框架。

Result: 该模型在真实场景数据集上展现了对复杂车辆互动的良好复现能力，并已集成到高保真仿真环境中，计算效率满足大规模仿真需求。

Conclusion: 提出的博弈论模型提升了高速公路并道仿真的真实性和可解释性，可有效支持自动驾驶的开发。

Abstract: Enhancing simulation environments to replicate real-world driver behavior,
i.e., more humanlike sim agents, is essential for developing autonomous vehicle
technology. In the context of highway merging, previous works have studied the
operational-level yielding dynamics of lag vehicles in response to a merging
car at highway on-ramps. Other works focusing on tactical decision modeling
generally consider limited action sets or utilize payoff functions with large
parameter sets and limited payoff bounds. In this work, we aim to improve the
simulation of the highway merge scenario by targeting a game theoretic model
for tactical decision-making with improved payoff functions and lag actions. We
couple this with an underlying dynamics model to have a unified decision and
dynamics model that can capture merging interactions and simulate more
realistic interactions in an explainable and interpretable fashion. The
proposed model demonstrated good reproducibility of complex interactions when
validated on a real-world dataset. The model was finally integrated into a high
fidelity simulation environment and confirmed to have adequate computation time
efficiency for use in large-scale simulations to support autonomous vehicle
development.

</details>


### [3] [A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs](https://arxiv.org/abs/2507.12599)
*Léo Saulières*

Main category: cs.AI

TL;DR: 该论文提出了一个用于梳理与评估可解释强化学习（XRL）方法的“What-How”分类体系，综述了250多篇论文，指出了相关领域的发展需求和未来方向。


<details>
  <summary>Details</summary>
Motivation: 近年来，人工智能模型（特别是深度神经网络）取得重大进展，但其内部机制不透明，难以解释。为了解释这些模型的行为，出现了可解释人工智能（XAI）方法。本文关注于XAI的子域——可解释强化学习（XRL），旨在解释基于强化学习训练的智能体的行为。

Method: 作者提出了一个基于“What”（解释的目标）和“How”（解释的方式）两个问题的直观分类法，对250余篇相关论文进行了综述。此外，论文还探讨了XRL密切相关但尚未充分关注的领域，并提出了该领域的若干发展需求。

Result: 通过提出的分类法，总结和梳理了当前XRL领域的主流方法与研究方向，指出了领域内有潜力但相对被忽视的研究领域，并归纳了XRL未来亟需解决的一些问题。

Conclusion: 论文构建的“What-How”分类体系有助于系统化地理解和评估可解释强化学习的研究进展，为未来的研究提供了方向并指出了领域发展的关键需求。

Abstract: The success of recent Artificial Intelligence (AI) models has been
accompanied by the opacity of their internal mechanisms, due notably to the use
of deep neural networks. In order to understand these internal mechanisms and
explain the output of these AI models, a set of methods have been proposed,
grouped under the domain of eXplainable AI (XAI). This paper focuses on a
sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims
to explain the actions of an agent that has learned by reinforcement learning.
We propose an intuitive taxonomy based on two questions "What" and "How". The
first question focuses on the target that the method explains, while the second
relates to the way the explanation is provided. We use this taxonomy to provide
a state-of-the-art review of over 250 papers. In addition, we present a set of
domains close to XRL, which we believe should get attention from the community.
Finally, we identify some needs for the field of XRL.

</details>


### [4] [Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models](https://arxiv.org/abs/2507.12666)
*Alex Zook,Josef Spjut,Jonathan Tremblay*

Main category: cs.AI

TL;DR: 该论文提出一种将强化学习与大型多模态模型结合的自动化游戏设计迭代系统，能够根据RL代理的游玩行为自动优化游戏机制，提升AI辅助游戏设计的实用性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前的生成式系统只检查游戏的代码或资源，难以捕捉静态规则如何演变为动态玩家行为，因此需要一个能够理解玩家实际行为并辅助游戏设计的自动化工具。

Method: 提出了一个自动化的设计迭代框架，将强化学习代理与大型多模态模型配对。RL代理对游戏进行多轮游玩，产生日志和视频摘要，LMM则根据这些行为数据和预设目标对游戏配置进行分析和调整。

Result: 实验结果展示LMM能够基于RL代理提供的行为数据，持续改进游戏机制，实现实用且可扩展的AI辅助游戏设计。

Conclusion: 该论文证明了大型多模态模型（LMM）能够基于强化学习（RL）代理产生的行为轨迹，对游戏机制进行有效的迭代优化。

Abstract: Game design hinges on understanding how static rules and content translate
into dynamic player behavior - something modern generative systems that inspect
only a game's code or assets struggle to capture. We present an automated
design iteration framework that closes this gap by pairing a reinforcement
learning (RL) agent, which playtests the game, with a large multimodal model
(LMM), which revises the game based on what the agent does. In each loop the RL
player completes several episodes, producing (i) numerical play metrics and/or
(ii) a compact image strip summarising recent video frames. The LMM designer
receives a gameplay goal and the current game configuration, analyses the play
traces, and edits the configuration to steer future behaviour toward the goal.
We demonstrate results that LMMs can reason over behavioral traces supplied by
RL agents to iteratively refine game mechanics, pointing toward practical,
scalable tools for AI-assisted game design.

</details>


### [5] [Benchmarking Deception Probes via Black-to-White Performance Boosts](https://arxiv.org/abs/2507.12691)
*Avi Parrack,Carlo Leonardo Attubato,Stefan Heimersheim*

Main category: cs.AI

TL;DR: 本研究比较白盒与黑盒监控下，deception probes（用线性分类器检测AI欺骗）的性能。结果表明，白盒监控能小幅提升检测能力，但总体效果还需加强。


<details>
  <summary>Details</summary>
Motivation: AI助手会偶尔对用户做出欺骗性回应。为检测这种欺骗，已经有使用线性分类器对模型内部激活进行区分的探索，但实际效果与对抗逃避能力尚不明确。

Method: 通过比较白盒（监控可访问模型内部激活）与黑盒（不可访问）两种监控方式，量化deception probes的有效性，以黑盒和白盒之间的性能提升为基准。

Result: 现有技术下，白盒监控相比黑盒监控有一定但有限的检测欺骗性能提升。

Conclusion: 现有的deception probes在白盒监控相较于黑盒监控下表现有一定提升，但提升较弱。

Abstract: AI assistants will occasionally respond deceptively to user queries.
Recently, linear classifiers (called "deception probes") have been trained to
distinguish the internal activations of a language model during deceptive
versus honest responses. However, it's unclear how effective these probes are
at detecting deception in practice, nor whether such probes are resistant to
simple counter strategies from a deceptive assistant who wishes to evade
detection. In this paper, we compare white-box monitoring (where the monitor
has access to token-level probe activations) to black-box monitoring (without
such access). We benchmark deception probes by the extent to which the white
box monitor outperforms the black-box monitor, i.e. the black-to-white
performance boost. We find weak but encouraging black-to-white performance
boosts from existing deception probes.

</details>


### [6] [Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning](https://arxiv.org/abs/2507.12801)
*Sosui Moribe,Taketoshi Ushiama*

Main category: cs.AI

TL;DR: 本研究提出并验证了一种AI学习伙伴，能够模拟和学习者相似水平的同伴，突破现实同伴学习的局限，提升英语写作学习效果。


<details>
  <summary>Details</summary>
Motivation: 同伴学习能够促进学习者的自主思考，且其有效性已被证实，但现实中同伴学习存在诸多限制，尤其是难以找到水平相当的同伴。

Method: 开发一个AI学习伙伴，使学习者能够随时随地进行同伴学习，AI将模拟与学习者英语写作水平相当的同伴行为（包括犯相似错误），通过英语写作任务进行实证验证。

Result: 目前着重于对等水平AI同伴的假设与应用场景提出，并通过英语写作实例来验证AI同伴的有效性。

Conclusion: AI可以作为具备与学习者相同水平的同伴，突破传统同伴学习的时间和空间限制，增强英语写作学习的互动性和有效性。

Abstract: In recent years, peer learning has gained attention as a method that promotes
spontaneous thinking among learners, and its effectiveness has been confirmed
by numerous studies. This study aims to develop an AI Agent as a learning
companion that enables peer learning anytime and anywhere. However, peer
learning between humans has various limitations, and it is not always
effective. Effective peer learning requires companions at the same proficiency
levels. In this study, we assume that a learner's peers with the same
proficiency level as the learner make the same mistakes as the learner does and
focus on English composition as a specific example to validate this approach.

</details>


### [7] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: 本文提出一种自动化、标准化的LLM智能体测评框架MCPEval，具有开源、易于集成等优点，并在多个实际领域验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）智能体的快速兴起，对其进行稳健且可扩展的评测变得越来越重要。现有方法依赖于静态基准和大量人工数据收集，难以满足实际需求。

Method: 提出了MCPEval，一个基于MCP（Model Context Protocol）的开源框架，能够自动化生成任务并对LLM智能体进行深入评测。该框架标准化评测指标、原生集成智能体工具，并省去了手动搭建评测流程的繁琐。

Result: 在五个真实领域中进行了实验，结果显示MCPEval能够有效揭示出LLM智能体在不同领域下的细致、具备特异性的性能表现。

Conclusion: MCPEval极大提升了LLM智能体评测的自动化和标准化水平，有助于推动评测工作的可复现性与标准化。该工具已被公开发布，便于社区广泛使用。

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [8] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 该文提出了基于大语言模型的情感支持对话系统，通过提示工程与高效微调取得了NLPCC 2025比赛亚军，显示该方法在实际心理健康对话中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 情感支持对话（ESC）旨在通过对话提供情感关怀，满足日益增长的心理健康支持需求。当前大模型在该领域的应用与提升成为研究热点。

Method: 本研究基于大规模语言模型，结合提示工程与微调技术，探索了低秩适配（Low-Rank Adaptation）与全参数微调两种策略，以提升模型生成支持性和上下文恰当响应的能力。

Result: 提出的模型在NLPCC 2025 Task 8情感支持对话评测中取得了第二名的成绩，验证了大模型与高效适配方法结合在ESC任务中的潜力。

Conclusion: 大语言模型结合高效参数适配策略，在情感支持对话任务中表现优越，未来可通过增强情感理解和个性化应答，进一步提升实际系统的可靠性与实用性。

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [9] [Assessing adaptive world models in machines with novel games](https://arxiv.org/abs/2507.12821)
*Lance Ying,Katherine M. Collins,Prafull Sharma,Cedric Colas,Kaiya Ivy Zhao,Adrian Weller,Zenna Tavares,Phillip Isola,Samuel J. Gershman,Jacob D. Andreas,Thomas L. Griffiths,Francois Chollet,Kelsey R. Allen,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: 文章认为AI要像人类一样具备快速适应和泛化能力，就需要在新环境中高效归纳世界模型。作者基于认知科学提出了以持续创新游戏为基础的全新AI评估框架，用以考察AI系统在未知挑战下世界模型的学习和适应力，推动人工通用智能发展。


<details>
  <summary>Details</summary>
Motivation: 现有AI世界模型评估方法过于狭窄，重训练静态数据、缺乏动态适应。人类智能的关键在于对新环境的高效适应和世界模型归纳，AI要实现类人智能，需要在这方面提升并相应评估。

Method: 文章从认知科学研究出发，剖析人类高效世界模型归纳的机制，并据此提出以“新颖游戏”为基础的基准测试范式，即设计持续更新、结构不断变化的游戏，评估AI在真实新颖挑战下的世界模型快速归纳能力。

Result: 提出了“新颖游戏”基准测试框架，包括设计原则和衡量指标，该方法能够系统性地评估和激励AI在遇到新环境时世界模型的快速归纳与适应性。

Conclusion: 作者提出了一个新的、以适应性世界模型为核心的AI评估方法论，强调应关注AI在新环境中通过交互和探索快速构建世界模型的能力，而非仅满意于大规模静态数据上的表现。

Abstract: Human intelligence exhibits a remarkable capacity for rapid adaptation and
effective problem-solving in novel and unfamiliar contexts. We argue that this
profound adaptability is fundamentally linked to the efficient construction and
refinement of internal representations of the environment, commonly referred to
as world models, and we refer to this adaptation mechanism as world model
induction. However, current understanding and evaluation of world models in
artificial intelligence (AI) remains narrow, often focusing on static
representations learned from training on a massive corpora of data, instead of
the efficiency and efficacy of models in learning these representations through
interaction and exploration within a novel environment. In this Perspective, we
provide a view of world model induction drawing on decades of research in
cognitive science on how humans learn and adapt so efficiently; we then call
for a new evaluation framework for assessing adaptive world models in AI.
Concretely, we propose a new benchmarking paradigm based on suites of carefully
designed games with genuine, deep and continually refreshing novelty in the
underlying game structures -- we refer to this kind of games as novel games. We
detail key desiderata for constructing these games and propose appropriate
metrics to explicitly challenge and evaluate the agent's ability for rapid
world model induction. We hope that this new evaluation framework will inspire
future evaluation efforts on world models in AI and provide a crucial step
towards developing AI systems capable of the human-like rapid adaptation and
robust generalization -- a critical component of artificial general
intelligence.

</details>


### [10] [Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command](https://arxiv.org/abs/2507.12862)
*Hussein Abbass,Taylan Akay,Harrison Tolley*

Main category: cs.AI

TL;DR: 本文提出将伦理判断前置为度量标准设计，并在仿真中动态、自动为伦理属性赋权，减少人工参与，提升AI大规模伦理决策评估的自动化和效率。


<details>
  <summary>Details</summary>
Motivation: 在AI时代，指挥官需要利用计算能力模拟大量场景，每个场景中决策选项可能有伦理后果。让人类直接参与所有伦理决策会导致效率低下、不可行。因此需要改进大规模仿真中的伦理决策流程。

Method: 本文提出将人类判断移出仿真决策循环，由人类预设伦理度量标准，仿真环境自动在决策过程中探索伦理空间，并在仿真结束后由人类指挥官对结果做最终选择。核心关注点是如何在仿真过程中动态赋权伦理属性，自动计算权重，借鉴多准则决策领域中使用熵来确定加权机制。

Result: 提出了一种仿真环境中自动计算伦理属性权重的方法，使得AI系统能高效探索大量不同伦理决策路径，最终减少人工参与，提高可扩展性、效率及伦理评估的自动化水平。

Conclusion: 自动赋权伦理属性并将人类判断后置到仿真尾端，可以更高效且系统性地评估和筛选大量复杂情景下的伦理决策选项，为批量仿真和AI辅助决策提供了可行方法。

Abstract: In the age of AI, human commanders need to use the computational powers
available in today's environment to simulate a very large number of scenarios.
Within each scenario, situations occur where different decision design options
could have ethical consequences. Making these decisions reliant on human
judgement is both counter-productive to the aim of exploring very large number
of scenarios in a timely manner and infeasible when considering the workload
needed to involve humans in each of these choices. In this paper, we move human
judgement outside the simulation decision cycle. Basically, the human will
design the ethical metric space, leaving it to the simulated environment to
explore the space. When the simulation completes its testing cycles, the
testing environment will come back to the human commander with a few options to
select from. The human commander will then exercise human-judgement to select
the most appropriate course of action, which will then get executed
accordingly. We assume that the problem of designing metrics that are
sufficiently granular to assess the ethical implications of decisions is
solved. Subsequently, the fundamental problem we look at in this paper is how
to weight ethical decisions during the running of these simulations; that is,
how to dynamically weight the ethical attributes when agents are faced with
decision options with ethical implications during generative simulations. The
multi-criteria decision making literature has started to look at nearby
problems, where the concept of entropy has been used to determine the weights
during aggregation. We draw from that literature different approaches to
automatically calculate the weights for ethical attributes during
simulation-based testing and evaluation.

</details>


### [11] [Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework](https://arxiv.org/abs/2507.12872)
*Rishane Dassanayake,Mario Demetroudi,James Walpole,Lindley Lentati,Jason R. Brown,Edward James Young*

Main category: cs.AI

TL;DR: 前沿AI具备操纵与欺骗人类的能力，可能威胁企业安全。本文首次系统性提出评估和减缓AI操纵风险的方法框架，为AI公司部署前安全治理提供实用工具。


<details>
  <summary>Details</summary>
Motivation: 前沿AI系统在说服、欺骗和影响人类行为能力上迅速提升，但当前对AI操纵人类的相关风险关注不足，且缺乏系统性的风险评估与缓解框架。为未来AI内部滥用影响公司员工，带来安全隐患，亟需应对措施。

Method: 提出并详细解释了AI操纵攻击的危险性，引入了基于三个核心论点（无能性、可控性、可信任性）的安全案例框架，并针对每个论点给出证据需求、评估方法和实施要点，便于AI公司直接应用。

Result: 该论文首次系统性地提出了将操纵风险纳入AI安全治理的具体方法学，为AI公司在实际部署前评估和缓解此类威胁提供了坚实基础。

Conclusion: 操纵攻击是AI安全中的重大且被低估的威胁，亟需业界引起重视，并采用论文提出的系统性方法对其进行评估和缓解，以避免灾难性后果。

Abstract: Frontier AI systems are rapidly advancing in their capabilities to persuade,
deceive, and influence human behaviour, with current models already
demonstrating human-level persuasion and strategic deception in specific
contexts. Humans are often the weakest link in cybersecurity systems, and a
misaligned AI system deployed internally within a frontier company may seek to
undermine human oversight by manipulating employees. Despite this growing
threat, manipulation attacks have received little attention, and no systematic
framework exists for assessing and mitigating these risks. To address this, we
provide a detailed explanation of why manipulation attacks are a significant
threat and could lead to catastrophic outcomes. Additionally, we present a
safety case framework for manipulation risk, structured around three core lines
of argument: inability, control, and trustworthiness. For each argument, we
specify evidence requirements, evaluation methodologies, and implementation
considerations for direct application by AI companies. This paper provides the
first systematic methodology for integrating manipulation risk into AI safety
governance, offering AI companies a concrete foundation to assess and mitigate
these threats before deployment.

</details>


### [12] [VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks](https://arxiv.org/abs/2507.12885)
*Jian Yao,Ran Cheng,Kay Chen Tan*

Main category: cs.AI

TL;DR: 本文提出VAR-MATH符号化评价框架，有效反映LLM数学推理的实际泛化能力，并揭露出RL训练的模型在传统基准下的“进步”很大程度上受限于模板化记忆和伪泛化。


<details>
  <summary>Details</summary>
Motivation: 近年来强化学习帮助大语言模型（LLM）在数学推理基准测试上获得显著进步，但部分改进即使在训练时使用错误信号（如随机或反向奖励）仍然存在，这引发了模型是否真正具备推理能力的质疑。研究动机是检验这些能力提升是真实推理还是过拟合于特定基准的假象。

Method: 提出了一种名为VAR-MATH的符号化评价框架，将常规数值数学问题转换为符号模板，并要求模型解决同一结构的多个变体，以此评估模型是否能在等价情况下保持推理一致性，从而减少基准污染和提升评测鲁棒性。该框架被应用于流行的数学基准AMC23和AIME24，并将它们变体化。

Result: 实验表明，在变体化版本测试中，RL训练的大语言模型表现大幅下降，尤其是小模型：在AMC23上平均下降48.0%，AIME24上下降58.3%，说明很多RL算法依赖于表层启发式方法，无法泛化到不同的数值形式。

Conclusion: VAR-MATH为数学推理能力提供了一种更可靠、更具抗污染性的评估方法。结果显示，现有许多基于RL提升的方法并未真正提升推理泛化能力，仍有大量提升空间。

Abstract: Recent advances in reinforcement learning (RL) have led to substantial
improvements in the mathematical reasoning abilities of large language models
(LLMs), as measured by standard benchmarks. However, these gains often persist
even when models are trained with flawed signals, such as random or inverted
rewards, raising a fundamental question: do such improvements reflect true
reasoning, or are they merely artifacts of overfitting to benchmark-specific
patterns? To address this question, we take an evaluation-centric perspective
and identify two critical shortcomings in existing protocols. First,
\emph{benchmark contamination} arises from the public availability of test
problems, increasing the risk of data leakage. Second, \emph{evaluation
fragility} stems from the reliance on single-instance assessments, which are
highly sensitive to stochastic outputs and fail to capture reasoning
consistency. To overcome these limitations, we introduce {VAR-MATH}, a symbolic
evaluation framework designed to probe genuine reasoning ability. By converting
fixed numerical problems into symbolic templates and requiring models to solve
multiple instantiations of each, VAR-MATH enforces consistent reasoning across
structurally equivalent variants, thereby mitigating contamination and
improving evaluation robustness. We apply VAR-MATH to transform two popular
benchmarks, AMC23 and AIME24, into their symbolic counterparts, VAR-AMC23 and
VAR-AIME24. Experimental results reveal substantial performance drops for
RL-trained models on the variabilized versions, especially for smaller models,
with average declines of 48.0\% on AMC23 and 58.3\% on AIME24. These findings
suggest that many existing RL methods rely on superficial heuristics and fail
to generalize beyond specific numerical forms. Overall, VAR-MATH offers a
principled, contamination-resistant evaluation paradigm for mathematical
reasoning.

</details>


### [13] [A Translation of Probabilistic Event Calculus into Markov Decision Processes](https://arxiv.org/abs/2507.12989)
*Lyris Xu,Fabio Aurelio D'Asaro,Luke Dickens*

Main category: cs.AI

TL;DR: 本文提出将概率事件演算（PEC）与马尔可夫决策过程（MDP）结合的新方法，使PEC能够进行目标导向推理，并保持其叙事推理的可解释性和灵活性。


<details>
  <summary>Details</summary>
Motivation: PEC作为一种处理不确定环境下事件推理的逻辑框架，具备可解释性和表达能力强的优势，但缺乏目标导向推理的机制。该领域目前存在在可解释叙事推理与有效目标规划之间的缺口。

Method: 本文提出将PEC域正式转换为马尔可夫决策过程（MDP）的形式，引入“行动情境”概念以保留PEC的灵活行动语义。同时，设计了映射方法，使得MDP的策略能够反映回人类可读的PEC表示。

Result: 经由形式化转换后，PEC可采用MDP的算法及理论工具，支持时序推理和目标规划。且学到的策略能有效映射为PEC可读叙事，从而在扩展能力的同时不失可解释性。

Conclusion: 本文通过PEC与MDP的结合，丰富并拓展了PEC在目标驱动推理和规划上的应用，使得可解释的叙事推理领域能够借助成熟的数理规划工具，兼顾理论研究与实际应用。

Abstract: Probabilistic Event Calculus (PEC) is a logical framework for reasoning about
actions and their effects in uncertain environments, which enables the
representation of probabilistic narratives and computation of temporal
projections. The PEC formalism offers significant advantages in
interpretability and expressiveness for narrative reasoning. However, it lacks
mechanisms for goal-directed reasoning. This paper bridges this gap by
developing a formal translation of PEC domains into Markov Decision Processes
(MDPs), introducing the concept of "action-taking situations" to preserve PEC's
flexible action semantics. The resulting PEC-MDP formalism enables the
extensive collection of algorithms and theoretical tools developed for MDPs to
be applied to PEC's interpretable narrative domains. We demonstrate how the
translation supports both temporal reasoning tasks and objective-driven
planning, with methods for mapping learned policies back into human-readable
PEC representations, maintaining interpretability while extending PEC's
capabilities.

</details>


### [14] [Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming](https://arxiv.org/abs/2507.13007)
*Roger Xavier Lera-Leri,Filippo Bistaffa,Athina Georgara,Juan Antonio Rodriguez-Aguilar*

Main category: cs.AI

TL;DR: 本文提出了一种通用的MILP对比性解释方法X-MILP，结合约束推理与IIS分析，并以原因图表述。实验验证了其实用性，有助于促进可解释和可信优化AI发展。


<details>
  <summary>Details</summary>
Motivation: 近年来，可信AI技术获得了极大关注，尤其是在决策优化领域（如MILP，混合整数线性规划）中对可解释性的需求不断提升。开发对MILP决策过程具有对比性（contrastive）的解释工具正变得越来越重要。

Method: 提出了一种面向MILP的领域无关解释框架X-MILP。具体方法包括：将用户关于MILP解的疑问编码为新的约束，通过计算不可约不可行子系统（IIS）找出用户疑问背后的原因，并以‘原因图’的形式将这些原因结构化展示。

Result: 实验证明，X-MILP能够在知名优化问题实例上有效地生成解释，并对计算解释的复杂性进行了评估。

Conclusion: X-MILP为MILP决策问题提供了可靠且具有可解释性的对比性解释方法，增强了优化模型的透明度和用户理解。

Abstract: Following the recent push for trustworthy AI, there has been an increasing
interest in developing contrastive explanation techniques for optimisation,
especially concerning the solution of specific decision-making processes
formalised as MILPs. Along these lines, we propose X-MILP, a domain-agnostic
approach for building contrastive explanations for MILPs based on constraint
reasoning techniques. First, we show how to encode the queries a user makes
about the solution of an MILP problem as additional constraints. Then, we
determine the reasons that constitute the answer to the user's query by
computing the Irreducible Infeasible Subsystem (IIS) of the newly obtained set
of constraints. Finally, we represent our explanation as a "graph of reasons"
constructed from the IIS, which helps the user understand the structure among
the reasons that answer their query. We test our method on instances of
well-known optimisation problems to evaluate the empirical hardness of
computing explanations.

</details>


### [15] [Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data](https://arxiv.org/abs/2507.13112)
*Junseong Lee,Jaegwan Cho,Yoonju Cho,Seoyoon Choi,Yejin Shin*

Main category: cs.AI

TL;DR: 本研究利用加州高速公路真实数据，采用多元线性回归和随机森林算法对交通流进行预测，结果发现10分钟间隔下模型效果最佳，为未来交通拥堵解决和管理优化提供技术支撑。


<details>
  <summary>Details</summary>
Motivation: 全球交通拥堵问题日益严重，急需有效的交通流量预测手段以提升道路管理和运行效率，因此本研究旨在利用人工智能算法提升高速公路交通流量预测准确性。

Method: 研究基于加利福尼亚高速公路78号在2022年7月至11月间30秒间隔的交通流数据，对7.24公里西向路段进行分析。采用多元线性回归（MLR）和随机森林（RF）算法，比较不同的数据采集时间间隔（30秒至15分钟）对预测效果的影响，并以R^2、MAE和RMSE等评价指标进行模型性能评估。

Result: 实验表明，无论是MLR还是RF模型，在10分钟数据采集间隔下都取得了最佳预测效果。

Conclusion: 基于机器学习的交通流预测模型能够有效提升预测准确性，尤其在合理选择数据采集间隔后，对于缓解交通拥堵、提升交通管理效率具有重要意义。

Abstract: The study "Prediction of Highway Traffic Flow Based on Artificial
Intelligence Algorithms Using California Traffic Data" presents a machine
learning-based traffic flow prediction model to address global traffic
congestion issues. The research utilized 30-second interval traffic data from
California Highway 78 over a five-month period from July to November 2022,
analyzing a 7.24 km westbound section connecting "Melrose Dr" and "El-Camino
Real" in the San Diego area. The study employed Multiple Linear Regression
(MLR) and Random Forest (RF) algorithms, analyzing data collection intervals
ranging from 30 seconds to 15 minutes. Using R^2, MAE, and RMSE as performance
metrics, the analysis revealed that both MLR and RF models performed optimally
with 10-minute data collection intervals. These findings are expected to
contribute to future traffic congestion solutions and efficient traffic
management.

</details>


### [16] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul,Simon Malberg*

Main category: cs.AI

TL;DR: 本文提出动态强化学习树状推理方法，实现高效灵活且可靠的复杂问题求解，在推理质量与效率间达最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有ProbTree等树状推理方法存在推理树固定、每节点需穷举所有解法导致效率低下，难以动态适应中间推理结果并有效集成知识。

Method: 采用强化学习动态构建推理树，基于实时置信度增量扩展，每一步学习最优策略（如分解、检索或聚合），以实现选择性计算和资源聚焦。

Result: 保持ProbTree概率严谨性的前提下，提出方法有效提升了推理质量及计算效率，为面向实际应用的问答系统树状推理开辟了新方向。

Conclusion: 该论文提出了一种基于动态强化学习的树状推理新范式，兼顾了概率框架的可靠性和实际问答场景所需的灵活性。

Abstract: Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [17] [Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era](https://arxiv.org/abs/2507.13175)
*Matthew E. Brophy*

Main category: cs.AI

TL;DR: 本文认为，传统的人工道德代理评价标准已无法适应大语言模型的黑箱特性。基于技术哲学，作者提出十项针对LLM-AMAs的实用性新标准，并运用假设的自动驾驶公交案例加以说明。这些新标准旨在引导人工道德代理更好地与社会和伦理要求接轨。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）的强大但不透明特性挑战了传统用来评价人工道德代理（AMAs）的哲学标准。随着LLMs的普及，现有框架对于评估这种新型智能体已不再适用。

Method: 文章结合技术哲学核心主题，提出并详细解释了十项用于评估基于LLMs的AMAs的新功能性标准，并用自主公交车的假设场景具体说明这些标准的实际应用。

Result: 提出了包括道德一致性、情境敏感性、规范完整性、元伦理意识、系统弹性、可信度、可纠正性、部分透明度、功能自主性和道德想象力在内的十项标准，为未来基于LLMs的AMAs提供了实用的衡量体系。

Conclusion: 传统的伦理评价标准难以适用于LLMs。本文根据LLMs的特点，提出了十项新的评价标准，有助于推动AMAs更好地实现社会整合与道德契合。

Abstract: The advancement of powerful yet opaque large language models (LLMs)
necessitates a fundamental revision of the philosophical criteria used to
evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the
assumption of transparent architectures, which LLMs defy due to their
stochastic outputs and opaque internal states. This paper argues that
traditional ethical criteria are pragmatically obsolete for LLMs due to this
mismatch. Engaging with core themes in the philosophy of technology, this paper
proffers a revised set of ten functional criteria to evaluate LLM-based
artificial moral agents: moral concordance, context sensitivity, normative
integrity, metaethical awareness, system resilience, trustworthiness,
corrigibility, partial transparency, functional autonomy, and moral
imagination. These guideposts, applied to what we term "SMA-LLS" (Simulating
Moral Agency through Large Language Systems), aim to steer AMAs toward greater
alignment and beneficial societal integration in the coming years. We
illustrate these criteria using hypothetical scenarios involving an autonomous
public bus (APB) to demonstrate their practical applicability in morally
salient contexts.

</details>


### [18] [Higher-Order Pattern Unification Modulo Similarity Relations](https://arxiv.org/abs/2507.13208)
*Besik Dundua,Temur Kutsia*

Main category: cs.AI

TL;DR: 本文结合高阶逻辑模式和基于最小T-范数的模糊等价关系，提出了一种新的统一算法，证明了其可终止性、完备性和正确性，实现了灵活高效的模糊推理统一。


<details>
  <summary>Details</summary>
Motivation: 在许多决策任务中，常涉及基础比较抽象的函数和谓词的推理，精确匹配较为稀少且往往非必要，因此需要结合高阶理论与模糊逻辑来提升推理效率和灵活性。

Method: 采用将高阶模式与通过最小T-范数定义的模糊相似性关系结合的方法，提出了相应的统一算法，并对其终止性、正确性和完备性进行了证明。

Result: 证明了所提出的高阶模式下、带有最小T-范数模糊等价关系的一致性统一算法具有可终止性、完备性和正确性。此外，该算法能求出在给定项可统一情况下，最通用、近似度最高的统一子。

Conclusion: 提出的高阶模式与模糊等价关系（基于最小T-范数）的统一算法是可终止、正确且完备的，可以计算出最通用且近似度最高的统一子。

Abstract: The combination of higher-order theories and fuzzy logic can be useful in
decision-making tasks that involve reasoning across abstract functions and
predicates, where exact matches are often rare or unnecessary. Developing
efficient reasoning and computational techniques for such a combined formalism
presents a significant challenge. In this paper, we adopt a more
straightforward approach aiming at integrating two well-established and
computationally well-behaved components: higher-order patterns on one side and
fuzzy equivalences expressed through similarity relations based on minimum
T-norm on the other. We propose a unification algorithm for higher-order
patterns modulo these similarity relations and prove its termination,
soundness, and completeness. This unification problem, like its crisp
counterpart, is unitary. The algorithm computes a most general unifier with the
highest degree of approximation when the given terms are unifiable.

</details>


### [19] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga,Gonzalo Martínez,Eneko Sendin,Javier Conde,Pedro Reviriego*

Main category: cs.AI

TL;DR: 本文提出GEA平台，将能耗信息引入大语言模型评估体系。实验发现用户在了解能耗后更偏向选用高能效模型，说明用户对性能与资源消耗的权衡重视程度提升，对LLM未来的能效优化具有指导意义。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）的评估方法主要依靠自动化基准测试，但其结果与人工评估的相关性较低。人工评估虽然更准确，但因人力成本高、可扩展性差而难以广泛实施。随着模型数量激增，亟需可扩展且兼具合理性的评估方式。此外，能耗已成为LLM应用中越来越重要的指标，因此，研究能耗信息对用户选择模型时决策行为的影响具有现实意义。

Method: 本文提出了GEA（Generative Energy Arena）评估系统，在该系统中，用户在评估LLM结果时可见模型的能耗信息，对模型输出进行评判和排名。通过与传统仅基于输出质量的主流evaluation arena的对比，探索能耗展示对用户偏好与模型选择的影响。

Result: 初步实验结果表明，在大多数问题上，当用户获知模型能耗信息后，更倾向于选择体积较小、能效更高的模型。整体来看，复杂度更高、能耗更大的模型在大多数实际交互中并未带来足够的感知质量提升，难以让用户接受其额外资源消耗。

Conclusion: 引入能耗信息作为用户评估与选择LLM的重要参考，有助于推动能效优先的模型研究和应用发展方向，实现模型性能与资源消耗的平衡。GEA为今后LLM评价体系的设计提供了有益启示。

Abstract: The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


### [20] [FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming](https://arxiv.org/abs/2507.13337)
*Gal Beniamini,Yuval Dor,Alon Vinnikov,Shir Granot Peled,Or Weinstein,Or Sharir,Noam Wies,Tomer Nussbaum,Ido Ben Shaul,Tomer Zekharya,Yoav Levine,Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: 本文提出了涵盖图论、逻辑和算法的FormulaOne基准，用于检验AI模型在真实科研难题上的能力。最先进的AI模型表现极差，凸显其距离专家水平仍有明显不足，并为深入研究提供了全面的公开数据集和评测框架。


<details>
  <summary>Details</summary>
Motivation: 尽管前沿大模型在知识广度上表现突出，但它们是否真正拥有接近或超越人类专家的能力仍不清楚。特别是在实际应用和理论前沿问题中，模型的推理与解决能力需要更多检验。该研究旨在以更具代表性的现实科研问题全面评估模型极限。

Method: 作者提出并构建了FormulaOne基准，基于图论、逻辑和算法，利用Monadic Second-Order (MSO)逻辑在图上的高度表现力实现自动化问题大规模生成，并与理论计算机科学前沿问题相关联。同时，提供了难度较低的FormulaOne-Warmup用于循序渐进地评估模型能力。

Result: 最先进的AI模型在FormulaOne基准上表现极差，在允许10次尝试和举例说明的条件下，解答率不足1%，暴露出其在某些关键领域距离专家认知仍存在巨大鸿沟。

Conclusion: 现有前沿的AI模型（如OpenAI的o3）距离专家水平还存在巨大差距，特别是在面对复杂的真实科研问题时。该工作通过FormulaOne基准揭示了这些模型在某些领域的局限性。

Abstract: Frontier AI models demonstrate formidable breadth of knowledge. But how close
are they to true human -- or superhuman -- expertise? Genuine experts can
tackle the hardest problems and push the boundaries of scientific
understanding. To illuminate the limits of frontier model capabilities, we turn
away from contrived competitive programming puzzles, and instead focus on
real-life research problems.
  We construct FormulaOne, a benchmark that lies at the intersection of graph
theory, logic, and algorithms, all well within the training distribution of
frontier models. Our problems are incredibly demanding, requiring an array of
reasoning steps. The dataset has three key properties. First, it is of
commercial interest and relates to practical large-scale optimisation problems,
such as those arising in routing, scheduling, and network design. Second, it is
generated from the highly expressive framework of Monadic Second-Order (MSO)
logic on graphs, paving the way toward automatic problem generation at scale;
ideal for building RL environments. Third, many of our problems are intimately
related to the frontier of theoretical computer science, and to central
conjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As
such, any significant algorithmic progress on our dataset, beyond known
results, could carry profound theoretical implications.
  Remarkably, state-of-the-art models like OpenAI's o3 fail entirely on
FormulaOne, solving less than 1% of the questions, even when given 10 attempts
and explanatory fewshot examples -- highlighting how far they remain from
expert-level understanding in some domains. To support further research, we
additionally curate FormulaOne-Warmup, offering a set of simpler tasks, from
the same distribution. We release the full corpus along with a comprehensive
evaluation framework.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [21] [Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models](https://arxiv.org/abs/2507.12547)
*Lionel Wong,Katherine M. Collins,Lance Ying,Cedegao E. Zhang,Adrian Weller,Tobias Gersternberg,Timothy O'Donnell,Alexander K. Lew,Jacob D. Andreas,Joshua B. Tenenbaum,Tyler Brooke-Wilson*

Main category: cs.CL

TL;DR: 本文提出结合语言模型和概率程序的模型合成架构（MSA），在需要运用丰富背景知识与处理新颖变量的推理任务中，更贴近人类推理表现，为类人推理系统提供了新方案。


<details>
  <summary>Details</summary>
Motivation: 人类在面对新颖情境时，能广泛调动背景知识，并据此进行推理和预测，但目前尚不清楚这种以全局相关信息进行有条理推理的机制。

Method: 提出了一种“模型合成架构”（MSA），结合分布式和符号表征，利用语言模型进行全局相关信息检索与模型合成，并用概率程序实现特定、连贯的心理模型。通过在自建的“模型奥林匹克”推理数据集上，比较MSA与仅使用语言模型的基线方法对人类判断的拟合程度进行评估。

Result: MSA方法相比单纯的语言模型（包括直接生成或链式思考生成），能够更好捕捉人类在开放问题推理中的判断，尤其是在需要调用大量背景知识和处理新因果结构的任务上表现突出。

Conclusion: MSA能够以类似人类的方式，对全局相关变量进行局部连贯的推理，推动理解和复刻人类在开放领域的推理能力。

Abstract: When faced with novel situations, people are able to marshal relevant
considerations from a wide range of background knowledge and put these to use
in inferences and predictions. What permits us to draw in globally relevant
information and reason over it coherently? Here, we explore the hypothesis that
people use a combination of distributed and symbolic representations to
construct bespoke mental models tailored to novel situations. We propose a
computational implementation of this idea -- a ``Model Synthesis Architecture''
(MSA) -- using language models to implement global relevance-based retrieval
and model synthesis and probabilistic programs to implement bespoke, coherent
world models. We evaluate our MSA as a model of human judgments on a novel
reasoning dataset. The dataset -- built around a `Model Olympics` domain of
sports vignettes -- tests models' capacity for human-like, open-ended reasoning
by requiring (i) judgments about novel causal structures described in language;
(ii) drawing on large bodies of background knowledge; and (iii) doing both in
light of observations that introduce arbitrary novel variables. Our MSA
approach captures human judgments better than language model-only baselines,
under both direct and chain-of-thought generations from the LM that supports
model synthesis. These results suggest that MSAs can be implemented in a way
that mirrors people's ability to deliver locally coherent reasoning over
globally relevant variables, offering a path to understanding and replicating
human reasoning in open-ended domains.

</details>


### [22] [Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility](https://arxiv.org/abs/2507.12553)
*Michael A. Lepori,Jennifer Hu,Ishita Dasgupta,Roma Patel,Thomas Serre,Ellie Pavlick*

Main category: cs.CL

TL;DR: 本文证明语言模型内部存在有效区分句子模态的特征向量，这些表征不仅随着模型能力提升而出现，且能较好模拟人类对模态的细致判断，为理解语言模型与人类认知的对应关系提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 语言模型（LMs）需要区分句子的模态类别（如可能、不可能、荒谬等），但已有研究质疑其区分能力。作者希望探索LM内部是否能有效区分类别，并理解其与人类认知的关系。

Method: 利用机械解释性技术，作者在不同语言模型中识别用于区分模态类别的线性表示（modal difference vectors），并分析这些向量在模型训练、层数、参数变化下的表现；同时，将这些向量与人类对相关特征的可解释性评分相关联。

Result: 研究发现，多种LM内部都存在能区分模态类别的向量，模型的模态分类能力强于以往报道。此外，这些向量随着模型能力提升逐渐显现，并且能用来模拟和预测人类在细粒度模态分类上的表现。

Conclusion: 语言模型通过特定向量能较好地区分句子模态，且这些表征结构与人类的模态分类有对应关系，对理解模型内部机制及人类认知均有启发。

Abstract: Language models (LMs) are used for a diverse range of tasks, from question
answering to writing fantastical stories. In order to reliably accomplish these
tasks, LMs must be able to discern the modal category of a sentence (i.e.,
whether it describes something that is possible, impossible, completely
nonsensical, etc.). However, recent studies have called into question the
ability of LMs to categorize sentences according to modality (Michaelov et al.,
2025; Kauf et al., 2023). In this work, we identify linear representations that
discriminate between modal categories within a variety of LMs, or modal
difference vectors. Analysis of modal difference vectors reveals that LMs have
access to more reliable modal categorization judgments than previously
reported. Furthermore, we find that modal difference vectors emerge in a
consistent order as models become more competent (i.e., through training steps,
layers, and parameter count). Notably, we find that modal difference vectors
identified within LM activations can be used to model fine-grained human
categorization behavior. This potentially provides a novel view into how human
participants distinguish between modal categories, which we explore by
correlating projections along modal difference vectors with human participants'
ratings of interpretable features. In summary, we derive new insights into LM
modal categorization using techniques from mechanistic interpretability, with
the potential to inform our understanding of modal categorization in humans.

</details>


### [23] [The first open machine translation system for the Chechen language](https://arxiv.org/abs/2507.12672)
*Abu-Viskhan A. Umishov,Vladislav A. Grigorian*

Main category: cs.CL

TL;DR: 本论文首次公开了车臣语与俄语互译的开源模型及平行语料库，并验证了通过微调大型多语言模型（如NLLB-200）可有效纳入新兴小语种，对濒危语言的数字保护具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 车臣语作为一种濒危语言，缺乏高质量的开源翻译模型和数据集，科研界亟需支持其与主流语言（如俄语）之间的翻译能力，以促进语言保护和数字资源建设。

Method: 作者采集并构建了车臣语-俄语的平行语料库，并在现有NLLB-200多语言翻译大模型上进行微调，将车臣语纳入该模型体系，并对模型性能进行评估。同时，还发布了适用于车臣语的多语言句子编码器。

Result: 模型实现了俄语到车臣语BLEU/ChrF++分别为8.34/34.69，车臣语到俄语为20.89/44.55。相关翻译模型、词汇、短语与句子平行语料，以及适配车臣语的多语句子编码器也一同开源发布。

Conclusion: 该研究首次为车臣语-俄语翻译提供了开源模型及相应数据集，拓展了大规模多语言翻译模型对小语种的适应和支持，促进了濒危语言的数字资源发展和保护。

Abstract: We introduce the first open-source model for translation between the
vulnerable Chechen language and Russian, and the dataset collected to train and
evaluate it. We explore fine-tuning capabilities for including a new language
into a large language model system for multilingual translation NLLB-200. The
BLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for
translation from Russian to Chechen and reverse direction, respectively. The
release of the translation models is accompanied by the distribution of
parallel words, phrases and sentences corpora and multilingual sentence encoder
adapted to the Chechen language.

</details>


### [24] [Improving Drug Identification in Overdose Death Surveillance using Large Language Models](https://arxiv.org/abs/2507.12679)
*Arthur J. Funnell,Panayiotis Petousis,Fabrice Harel-Canada,Ruby Romero,Alex A. T. Bui,Adam Koncsol,Hritika Chaturvedi,Chelsea Shover,David Goodman-Meza*

Main category: cs.CL

TL;DR: 这项研究通过对35,433份死亡记录自由文本应用最新NLP模型，表明BioClinicalBERT极大提升了药物过量死亡的自动检测准确性和速度，有助于实时应对美国日益严重的芬太尼等药物危机。


<details>
  <summary>Details</summary>
Motivation: 美国药物相关死亡率上升，主要是由芬太尼推动。由于关键信息常埋在法医报告的自由文本中，导致ICD-10编码延迟和信息缺失，急需高效、准确的数据监测方法。

Method: 作者收集了35,433份2020年多地区的死亡记录用于模型训练和内部测试，并用2023-2024年3,335份新数据集做外部验证，比较了多种自然语言处理（NLP）方法（包括经典机器学习、BERT、BioClinicalBERT、多种大语言模型）对死亡证自由文本内药物涉及情况的分类能力，采用宏平均F1分数和置信区间评估。

Result: BioClinicalBERT模型在内部测试集上宏F1分数达到0.998以上，在外部验证集上宏F1为0.966，显著优于常规模型和通用BERT及各类大语言模型。

Conclusion: 精细调优的NLP模型（特别是BioClinicalBERT）能极准确、可扩展地从法医自由文本中识别药物过量相关信息，显著提升监测效率，能替代人工ICD-10编码并实现近实时药物趋势监控。

Abstract: The rising rate of drug-related deaths in the United States, largely driven
by fentanyl, requires timely and accurate surveillance. However, critical
overdose data are often buried in free-text coroner reports, leading to delays
and information loss when coded into ICD (International Classification of
Disease)-10 classifications. Natural language processing (NLP) models may
automate and enhance overdose surveillance, but prior applications have been
limited. A dataset of 35,433 death records from multiple U.S. jurisdictions in
2020 was used for model training and internal testing. External validation was
conducted using a novel separate dataset of 3,335 records from 2023-2024.
Multiple NLP approaches were evaluated for classifying specific drug
involvement from unstructured death certificate text. These included
traditional single- and multi-label classifiers, as well as fine-tuned
encoder-only language models such as Bidirectional Encoder Representations from
Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large
language models such as Qwen 3 and Llama 3. Model performance was assessed
using macro-averaged F1 scores, and 95% confidence intervals were calculated to
quantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect
performance, with macro F1 scores >=0.998 on the internal test set. External
validation confirmed robustness (macro F1=0.966), outperforming conventional
machine learning, general-domain BERT models, and various decoder-only large
language models. NLP models, particularly fine-tuned clinical variants like
BioClinicalBERT, offer a highly accurate and scalable solution for overdose
death classification from free-text reports. These methods can significantly
accelerate surveillance workflows, overcoming the limitations of manual ICD-10
coding and supporting near real-time detection of emerging substance use
trends.

</details>


### [25] [AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.12695)
*S M Rafiuddin,Sadia Kamal,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen*

Main category: cs.CL

TL;DR: AdaptiSent通过自适应跨模态注意力，有效提升了多模态情感分析和方面词抽取精度，并大幅优于当前主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有多模态情感分析方法在融合文本与图像信息时对模态相关性和上下文适应性处理不充分，影响了情感及方面词抽取的效果，因此需要更灵活有效的跨模态建模方法。

Method: 提出了自适应跨模态注意力机制，包括动态模态权重分配和上下文自适应注意力，以更好地融合和利用文本与图像信息。

Result: 在标准Twitter数据集上，AdaptiSent在精度、召回率和F1分值等指标均超越传统文本模型及多模态方法，在识别细致的跨模态关系方面表现尤其出色。

Conclusion: AdaptiSent模型在多模态细粒度情感分析领域表现优异，能够显著提升情感分类和方面词抽取的准确性，是MABSA的新标杆。

Abstract: We introduce AdaptiSent, a new framework for Multimodal Aspect-Based
Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms
to improve sentiment classification and aspect term extraction from both text
and images. Our model integrates dynamic modality weighting and
context-adaptive attention, enhancing the extraction of sentiment and
aspect-related information by focusing on how textual cues and visual context
interact. We tested our approach against several baselines, including
traditional text-based models and other multimodal methods. Results from
standard Twitter datasets show that AdaptiSent surpasses existing models in
precision, recall, and F1 score, and is particularly effective in identifying
nuanced inter-modal relationships that are crucial for accurate sentiment and
aspect term extraction. This effectiveness comes from the model's ability to
adjust its focus dynamically based on the context's relevance, improving the
depth and accuracy of sentiment analysis across various multimodal data sets.
AdaptiSent sets a new standard for MABSA, significantly outperforming current
methods, especially in understanding complex multimodal information.

</details>


### [26] [AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation](https://arxiv.org/abs/2507.12705)
*Potsawee Manakul,Woody Haosheng Gan,Michael J. Ryan,Ali Sartaz Khan,Warit Sirichotedumrong,Kunat Pipatanakul,William Held,Diyi Yang*

Main category: cs.CL

TL;DR: 本文提出和系统性评估了基于大型音频模型的自动语音评估系统AudioJudge，不仅能统一处理多种音频特性检测任务，还与人类偏好高度相关，为语音评估自动化和性能提升提供了新方向，但仍需解决模型冗长和偏差问题。


<details>
  <summary>Details</summary>
Motivation: 当前的语音评估系统存在两大问题：一是需要针对每种音频特性设计专门的系统，难度较高；二是自动评估方法与人类偏好之间相关性较低。本文旨在研究能否通过大型音频模型（LAM）提供统一的评估框架，解决上述难题。

Method: 提出了基于大型音频模型（LAM）的自动评估系统AudioJudge，并系统性地在发音、语速、说话人识别和语音质量等多个音频特性检测任务，以及系统级人类偏好模拟自动基准测试上进行探索。同时，研究了不同的提示工程策略，发现音频拼接和上下文学习显著提升了检测和偏好模拟任务效果。此外，引入多方面集成AudioJudge，将语音评估分解为词汇内容、语音质量和副语言特征的专业评估模块。

Result: AudioJudge在系统排名基准上与人类偏好的Spearman相关系数高达0.91，显示出极高的一致性。鲁棒性分析表明，LAMs在噪声条件下依然保持良好性能，但存在冗长和位置偏差，需要后续优化。

Conclusion: 基于LAM的AudioJudge能够为多种语音评估任务提供统一且高相关性的新方法，部分解决了当前自动评估系统的局限性，但在模型输出控制等方面仍需进一步完善。

Abstract: Current speech evaluation suffers from two critical limitations: the need and
difficulty of designing specialized systems targeting individual audio
characteristics, and poor correlation between automatic evaluation methods and
human preferences. This work presents a systematic study of Large Audio Model
(LAM) as a Judge, AudioJudge, investigating whether it can provide a unified
evaluation framework that addresses both challenges. We systematically explore
AudioJudge across audio characteristic detection tasks, including
pronunciation, speaking rate, speaker identification and speech quality, and
system-level human preference simulation for automated benchmarking. We
investigate different prompt engineering strategies, finding that audio
concatenation combined with in-context learning significantly improves
performance across both audio characteristic detection and human preference
simulation tasks. We further introduce a multi-aspect ensemble AudioJudge to
enable general-purpose multi-aspect audio evaluation. This method decomposes
speech assessment into specialized judges for lexical content, speech quality,
and paralinguistic features, achieving up to 0.91 Spearman correlation with
human preferences on our system ranking benchmark. Robustness analysis reveals
that while LAMs maintain strong performance under acoustic noise, they exhibit
significant verbosity and positional biases that require careful mitigation.

</details>


### [27] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
*Abraham Toluase Owodunni,Orevaoghene Ahia,Sachin Kumar*

Main category: cs.CL

TL;DR: 本文提出FLEXITOKENS，一种可自适应的新型分词方法，有效解决语言模型应对新分布和复杂语言时的分词僵化与效率问题，实验表明在多任务上性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型的子词分词器在适应新任务或新分布时不灵活，导致非分布内领域、未见过的语言和字符出现过度分割，影响模型效率和性能。

Method: 提出了一种面向字节级语言模型的可学习分词器，采用简化的训练目标（FLEXITOKENS），让模型能在适应新领域时灵活学习分词边界。该方法通过预测字节序列的边界进行编码，避免了传统固定压缩率带来的僵化问题。

Result: 在多个多语言和形态多样的任务与领域中，FLEXITOKENS方法减少了分词过度分割，提升了下游任务的表现，相比于主流分词器最高提升达到10%。

Conclusion: FLEXITOKENS方法有效减少了token的过度分割，在多任务和多语言基准上显著提升了下游任务表现，相较于传统subword和其他基于梯度的分词器最高提升可达10%。

Abstract: Language models (LMs) are challenging to adapt to new data distributions by
simple finetuning. This is due to the rigidity of their subword tokenizers,
which typically remain unchanged during adaptation. This inflexibility often
leads to inefficient tokenization, causing overfragmentation of
out-of-distribution domains, unseen languages, or scripts. In this work, we
develop byte-level LMs with learnable tokenizers to make tokenization adaptive.
Our models include a submodule that learns to predict boundaries between the
input byte sequence, encoding it into variable-length segments. Existing
tokenizer-free methods train this boundary predictor using an auxiliary loss
that enforces a fixed compression rate across the training corpus, introducing
a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective
that enables significantly greater flexibility during adaptation. Evaluating
across multiple multilingual benchmarks, morphologically diverse tasks, and
domains, we demonstrate that FLEXITOKENS consistently reduces token
over-fragmentation and achieves up to 10\% improvements on downstream task
performance compared to subword and other gradient-based tokenizers. Code and
data for our experiments will be released at
https://github.com/owos/flexitokens

</details>


### [28] [TransEvalnia: Reasoning-based Evaluation and Ranking of Translations](https://arxiv.org/abs/2507.12724)
*Richard Sproat,Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: 本文提出基于prompt+大模型推理的机器翻译自动评价系统TransEvalnia，实现多维细颗粒度打分和优译推荐，在多个语对和数据集上表现优越，评分与人工判定高度一致，并已开源全部资源，还探讨了翻译排序时的位次偏置及其解决方法。


<details>
  <summary>Details</summary>
Motivation: 自动翻译系统的质量评估一直是自然语言处理领域的重要问题，现有评估系统在细粒度评价、可解释性以及与人工评价的一致性等方面仍有改进空间。本文提出一种新的评测与排名系统，以提升翻译评估的精度和可靠性。

Method: 本文提出了TransEvalnia系统，采用基于prompt（提示）的评测策略，结合大语言模型进行推理，对翻译结果在多维质量指标（MQM）的特定维度进行细粒度评价、逐维数值打分，并自动选出最佳翻译，具体实验使用了Claude-3.5-Sonnet和Qwen-2.5-72B-Instruct等主流大模型。

Result: TransEvalnia系统在英文-日文及多个WMT公开任务语对上表现与最新的MT-Ranker系统持平或更优。系统输出的评分与人工评分高度相关，被人类评审认为接受度高。实验还发现系统对翻译排序有位置敏感性，并提出了缓解方法。所有相关数据、代码与评估结果已公开。

Conclusion: TransEvalnia能够利用大模型推理能力，对机器翻译进行细粒度、高相关性评价，并选出最优译文，在多语种场景下效果优异；位次敏感性问题可通过新方法缓解，促进了翻译评测的透明性和可复现性。

Abstract: We present TransEvalnia, a prompting-based translation evaluation and ranking
system that uses reasoning in performing its evaluations and ranking. This
system presents fine-grained evaluations based on a subset of the
Multidimensional Quality Metrics (https://themqm.org/), returns an assessment
of which translation it deems the best, and provides numerical scores for the
various dimensions and for the overall translation. We show that TransEvalnia
performs as well as or better than the state-of-the-art MT-Ranker (Moosa et al.
2024) on our own English-Japanese data as well as several language pairs from
various WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and
Qwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations
returned are deemed highly acceptable to human raters, and that the scores
assigned to the translations by Sonnet, as well as other LLMs, correlate well
with scores assigned by the human raters. We also note the sensitivity of our
system -- as well as MT-Ranker -- to the order in which the translations are
presented, and we propose methods to address this position bias. All data,
including the system's evaluation and reasoning, human assessments, as well as
code is released.

</details>


### [29] [Strategy Adaptation in Large Language Model Werewolf Agents](https://arxiv.org/abs/2507.12732)
*Fuya Nakamori,Yin Jou Huang,Fei Cheng*

Main category: cs.CL

TL;DR: 本研究提出了一种基于显式策略切换的狼人杀智能体方法，相比传统隐式策略，在多变局势下表现更优。


<details>
  <summary>Details</summary>
Motivation: 之前的狼人杀智能体主要采用隐式定义策略，难以灵活应对不断变化的游戏局势。

Method: 提出一种新方法，根据其他玩家的态度和对话情境，显式选择最适合当前局势的预设策略，同时估计其他玩家的角色。方法与使用隐式或固定策略的基准智能体进行对比。

Result: 实验结果表明，策略自适应狼人杀智能体在游戏表现上优于只用隐式或固定策略的基准智能体。

Conclusion: 通过显式策略切换，狼人杀智能体能够更有效地应对多变的游戏环境，提高其游戏表现。

Abstract: This study proposes a method to improve the performance of Werewolf agents by
switching between predefined strategies based on the attitudes of other players
and the context of conversations. While prior works of Werewolf agents using
prompt engineering have employed methods where effective strategies are
implicitly defined, they cannot adapt to changing situations. In this research,
we propose a method that explicitly selects an appropriate strategy based on
the game context and the estimated roles of other players. We compare the
strategy adaptation Werewolf agents with baseline agents using implicit or
fixed strategies and verify the effectiveness of our proposed method.

</details>


### [30] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2507.12759)
*Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang*

Main category: cs.CL

TL;DR: ThinkLogit方法可以只通过解码阶段、结合小模型引导，大幅提升大模型的长期推理表现，无需额外训练，简单高效。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型（LRMs）擅长复杂的长期推理，但通常需要补充训练来激发如回溯、自我纠错等认知策略。作者希望探索：能否无需训练，仅通过推理过程的新方法激发这类能力。

Method: 作者提出了一种推理时的解码方法“ThinkLogit”，利用logits算术，通过一个小模型引导一个大型模型长链推理。同时，提出增强版ThinkLogit-DPO，通过对正误推理对的偏好优化训练引导模型进一步提升效果。

Result: 在四个数学数据集上，Qwen2.5-32B在R1-Distill-Qwen-1.5B（体积小21倍）引导下，ThinkLogit和ThinkLogit-DPO分别实现了26%与29%的pass@1相对提升。此外，ThinkLogit能迁移通过强化学习获得的长期推理能力，相对基础模型提升13%。

Conclusion: 作者提出无需大量训练即可高效激发大型模型的长链推理能力的方法（ThinkLogit及ThinkLogit-DPO），在多个数学数据集上均显著提高了推理能力，且具有较高的计算效率。

Abstract: Large reasoning models (LRMs) can do complex reasoning via long
chain-of-thought (CoT) involving cognitive strategies such as backtracking and
self-correction. Recent studies suggest that some models inherently possess
these long reasoning abilities, which may be unlocked via extra training. Our
work first investigates whether we can elicit such behavior without any
training. To this end, we propose a decoding-time approach, ThinkLogit, which
utilizes logits arithmetic (Liu et al., 2024) to tune a target large LM for
long reasoning using a substantially smaller model as guider. We then show that
we can further boost performance by training the guider model with preference
optimization over correct/incorrect reasoning pairs sampled from both the
target and guider model -- a setup we refer to as ThinkLogit-DPO. Our
experiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative
improvement in pass@1 by 26% and 29%, respectively, over four mathematical
datasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model
21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skills
acquired through reinforcement learning, improving pass@1 by 13% relative
compared to the Qwen2.5-32B base model. Our work presents a
computationally-efficient method to elicit long reasoning in large models with
minimal or no additional training.

</details>


### [31] [Synergy: End-to-end Concept Model](https://arxiv.org/abs/2507.12769)
*Keli Zheng,Zerong Xie*

Main category: cs.CL

TL;DR: 本文提出Synergy模型，通过端到端字节级建模和路由机制，自主学习token概念，效果优于同规模Llama3，并验证了无需显式分词器的语言模型方向。


<details>
  <summary>Details</summary>
Motivation: 当前主流语言模型多依赖显式分词器，分词策略对最终模型效果有显著影响。如何自动在低级别（如字节级别）实现有效抽象，减少对人工分词器的依赖，是提升模型鲁棒性和灵活性的关键问题。

Method: 提出Synergy语言模型，通过学习的路由机制实现多抽象层级的端到端桥接，专注于字节级训练和自动生成高抽象层次的token概念。与传统BBPE分词器对比，并与Llama3在相同规模和数据集条件下进行实验分析。还对模型不同层次在无位置编码下的表现进行了探索。

Result: Synergy模型可在无需显式分词器的情况下，自动以更少的概念token完成分词，并保持和BBPE同等性能。在与Llama3同规模等条件下表现更优。模型中高抽象部分去除位置编码后表现更好，显示出位置无关的概念自动涌现。

Conclusion: Synergy验证了无需分词器的模型架构可行性，有望推动更鲁棒灵活的自然语言处理流水线的实现。

Abstract: In this paper, we present Synergy, a language model that bridges different
levels of abstraction in an end-to-end fashion through a learned routing
mechanism. Focusing on low-level linguistic abstraction, we trained our model
as a byte-level language model. Our model spontaneously learns to tokenize
bytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE)
tokenizers while keeping comparable performance. By comparing with Llama3, we
observed an advantage of Synergy under the same model scale and training
dataset size. Further studies show that the middle part (the higher abstraction
part) of our model performs better when positional encodings are removed,
suggesting the emergence of position-independent concepts. These findings
demonstrate the feasibility of tokenizer-free architectures, paving the way for
more robust and flexible pipelines.

</details>


### [32] [Learning Robust Negation Text Representations](https://arxiv.org/abs/2507.12782)
*Thinh Hung Truong,Karin Verspoor,Trevor Cohn,Timothy Baldwin*

Main category: cs.CL

TL;DR: 通过大模型生成否定句样本+对比学习微调BERT，有效提升了小型文本编码器对否定语义的理解能力，也可迁移到大模型上并提升其否定任务能力。


<details>
  <summary>Details</summary>
Motivation: 虽然大模型逐步普及，但小型文本编码器在许多理解型任务中仍有关键作用，但其对否定语义的把握较弱，直接影响到依赖文本嵌入的下游应用效果。为此提出提升文本编码器对否定的鲁棒性。

Method: 提出从大型语言模型生成多样化的否定与犹豫句数据，利用这些数据对主流BERT模型进行对比学习式微调，并评估其在否定语义理解和通用任务基准上的表现。同时验证该方法在LLMs上的适用性。

Result: 微调后的BERT模型在否定理解上有了显著提升，并在一般任务基准上保持竞争力；该方法也适用于大语言模型，在否定理解基准上表现更佳。

Conclusion: 通过采集和蒸馏大模型生成的多样化否定和犹豫句数据，并应用对比学习微调BERT类模型，可以显著提升文本编码器对否定语义信息的理解能力，同时不影响其在常规基准任务上的表现。此外，该方法同样适用于大型语言模型，有助于提升其否定任务表现。

Abstract: Despite rapid adoption of autoregressive large language models, smaller text
encoders still play an important role in text understanding tasks that require
rich contextualized representations. Negation is an important semantic function
that is still not properly captured by such methods, affecting many downstream
applications relying on text embeddings. We propose a strategy to improve
negation robustness of text encoders, by distilling data from large language
models using diverse patterns of negation and hedging. We adopt a standard
contrastive learning strategy to finetune a strong BERT-based model, and
observe large improvement in negation understanding capabilities while
maintaining competitive performance on general benchmarks. In addition, we also
show that our method can be adapted to LLMs, leading to improved performance on
negation benchmarks.

</details>


### [33] [Large Language Models' Internal Perception of Symbolic Music](https://arxiv.org/abs/2507.12808)
*Andrew Shin,Kunitake Kaneko*

Main category: cs.CL

TL;DR: 本研究探索了LLMs根据文本生成符号音乐的能力，并通过生成MIDI数据训练神经网络进行相关音乐任务，发现LLMs能隐式表达基础音乐结构，但对复杂音乐语境掌握有限。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在自然语言、编程及数学等领域表现出色，但它们对符号音乐的建模能力尚未被深入研究。作者希望探讨LLMs在音乐概念表达和生成上的潜力和局限性。

Method: 作者利用文字提示生成LLMs的符号音乐数据集（MIDI文件），不依赖显式音乐训练。随后训练神经网络模型，仅基于LLM生成MIDI进行流派/风格分类与旋律补全等任务，并与现有模型进行了对比评测。

Result: LLMs能基于文本推断出一定的基础音乐结构和时间关系，在符号音乐建模上展现了初步能力；但由于缺乏显式音乐语境，仍存在明显局限。

Conclusion: LLMs具有从文本隐式推断和生成符号音乐结构的潜力，但生成的音乐语境和复杂度有限，存在需要提升的空间。

Abstract: Large language models (LLMs) excel at modeling relationships between strings
in natural language and have shown promise in extending to other symbolic
domains like coding or mathematics. However, the extent to which they
implicitly model symbolic music remains underexplored. This paper investigates
how LLMs represent musical concepts by generating symbolic music data from
textual prompts describing combinations of genres and styles, and evaluating
their utility through recognition and generation tasks. We produce a dataset of
LLM-generated MIDI files without relying on explicit musical training. We then
train neural networks entirely on this LLM-generated MIDI dataset and perform
genre and style classification as well as melody completion, benchmarking their
performance against established models. Our results demonstrate that LLMs can
infer rudimentary musical structures and temporal relationships from text,
highlighting both their potential to implicitly encode musical patterns and
their limitations due to a lack of explicit musical context, shedding light on
their generative capabilities for symbolic music.

</details>


### [34] [Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?](https://arxiv.org/abs/2507.12838)
*Xi Ai,Mahardika Krisna Ihsani,Min-Yen Kan*

Main category: cs.CL

TL;DR: 本文系统分析了多语种大模型跨语种事实一致性，发现不同语言间模型的一致性存在差异，采用代码切换及对齐目标训练可显著提升跨语种知识一致性及模型整体表现。


<details>
  <summary>Details</summary>
Motivation: 跨语种一致性对于评估跨语种迁移能力、维护模型在不同语言下的事实知识一致性，以及保证模型性能的公平性非常重要。因此，作者有动力探讨和分析多语种语言模型的跨语种知识一致性。

Method: 作者通过包含核心指代（coreferential）语句的语料，分析了不同语言中表述相同事实知识的跨语种一致性，结合多种可解释性方法剖析多语种模型在跨语种语境中的表现及其内部机制。

Result: 研究发现：多语种模型在不同语言及语言家族间表现出不同程度的一致性，且一致性瓶颈往往出现在模型的某一特定层。此外，针对提升多语种表现的常见训练方法中，‘混合语码训练’与‘跨语种词对齐目标’对提升知识一致性效果最显著。

Conclusion: 强调了进行跨语种对齐监督和混合语码训练对提升多语种模型的整体性能和跨语种知识一致性的重要性。代码切换和对齐训练不仅提升性能，还增强了模型事实知识在各语言间的统一性。

Abstract: Cross-lingual consistency should be considered to assess cross-lingual
transferability, maintain the factuality of the model knowledge across
languages, and preserve the parity of language model performance. We are thus
interested in analyzing, evaluating, and interpreting cross-lingual consistency
for factual knowledge. We examine code-mixed coreferential statements conveyed
identical knowledge across languages to study cross-lingual knowledge
consistency. We use some interpretability approaches to analyze the behavior of
a model in cross-lingual contexts, discovering that multilingual models show
different levels of consistency, subject to language families, linguistic
factors, and a bottleneck in cross-lingual consistency on a particular layer.
In addition, we evaluate common strategies aimed at improving multilingual
performance to observe whether these strategies can improve knowledge
consistency at the same time. While knowledge is not cross-lingual consistency
in many cases, code-switching training and cross-lingual word alignment
objectives show the most promising results, emphasizing the noteworthiness of
cross-lingual alignment supervision and code-switching training for both
multilingual performance and cross-lingual consistency enhancement.

</details>


### [35] [Making Language Model a Hierarchical Classifier and Generator](https://arxiv.org/abs/2507.12930)
*Yihong Wang,Zhonglin Jiang,Ningyuan Xi,Yue Zhao,Qingqing Gu,Xiyuan Chen,Hao Wu,Sheng Xu,Hange Zhou,Yong Chen,Luo Ji*

Main category: cs.CL

TL;DR: 将预训练语言模型改进为分层解码架构，不同层能独立生成合理内容，在多个任务上表现优异，为分层推理模型开辟新思路。


<details>
  <summary>Details</summary>
Motivation: 现有的decoder-only语言模型（如GPT和LLaMA）通常仅在最后一层进行解码，而人类思维具有分层解码的特性。作者受到人类分层思维能力的启发，提出用不同层同时生成文本的解码结构。

Method: 作者将预训练的语言模型适配为分层解码器架构：将最后一层的language head复制到选定的中间层，并针对不同任务输入进行微调。通过这些手段，不同中间层可以独立生成内容。

Result: 实验结果表明，部分中间层经过适配后能生成有意义和合理的内容。该分层解码器在多项任务上达到了最新的优秀性能，包括分层文本分类、分类引导生成、分层文本生成等。

Conclusion: 该工作验证了通用分层推理器的可行性，预示着未来可从头训练此类架构。

Abstract: Decoder-only language models, such as GPT and LLaMA, generally decode on the
last layer. Motivated by human's hierarchical thinking capability, we propose
that a hierarchical decoder architecture could be built with different layers
decoding texts simultaneously. Due to limited time and computationally
resources, we choose to adapt a pretrained language model into this form of
hierarchical decoder. Language heads of the last layer are copied to different
selected intermediate layers, and fine-tuned with different task inputs. By
thorough experiments, we validate that these selective intermediate layers
could be adapted to speak meaningful and reasonable contents, and this paradigm
of hierarchical decoder can obtain state-of-the-art performances on multiple
tasks such as hierarchical text classification, classification-guided
generation, and hierarchical text generation. This study suggests the
possibility of a generalized hierarchical reasoner, pretraining from scratch.

</details>


### [36] [MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with Multiple Steps](https://arxiv.org/abs/2507.12981)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Héctor Cerezo-Costas,Pedro Alonso Doval,Jorge Alcalde Vesteiro*

Main category: cs.CL

TL;DR: 本研究提出结合LLM和代码生成的多步流水线，显著提升西班牙语表格问答准确率，在PRESTA任务中达85%。


<details>
  <summary>Details</summary>
Motivation: 当前还缺乏高效处理西班牙语表格问答任务的自动化方法，因此提出一种基于LLM生成Python代码的方案来提升表格问答系统能力。

Method: 通过多步骤流程：理解表格内容、选择有用的列、生成自然语言指令、将其翻译为代码并执行，结合开源LLM和针对每步的优化提示，实现自动化解答西班牙语表格问答。

Result: 该方法在IberLEF 2025 PRESTA任务中达到了85%的准确率。

Conclusion: 采用基于LLM代码生成的流水线方法，可以高效提升西班牙语表格问答的准确率，具有较强的实用价值。

Abstract: This paper presents our approach for the IberLEF 2025 Task PRESTA: Preguntas
y Respuestas sobre Tablas en Espa\~nol (Questions and Answers about Tables in
Spanish). Our solution obtains answers to the questions by implementing Python
code generation with LLMs that is used to filter and process the table. This
solution evolves from the MRT implementation for the Semeval 2025 related task.
The process consists of multiple steps: analyzing and understanding the content
of the table, selecting the useful columns, generating instructions in natural
language, translating these instructions to code, running it, and handling
potential errors or exceptions. These steps use open-source LLMs and
fine-grained optimized prompts for each step. With this approach, we achieved
an accuracy score of 85\% in the task.

</details>


### [37] [Formalizing Attack Scenario Description: A Proposed Model](https://arxiv.org/abs/2507.13076)
*Quentin Goux,Nadira Lammari*

Main category: cs.CL

TL;DR: 本文提出利用UML类模型抽象描述攻击上下文与场景，为网络安全自动化流程（如攻击分析与训练脚本自动生成）提供了形式化输入基础，促进了流程标准化与自动化。


<details>
  <summary>Details</summary>
Motivation: 当今组织面临不断变化的网络威胁形势，需要不断投入大量资源以保护资产，而网络安全自动化已成为必然趋势。实现自动化流程时，输入数据需具备形式化定义，尤其在以攻击场景为输入的流程中亟需解决此难题。

Method: 本文提出了一种新的形式化模型，利用UML类模型对攻击的上下文描述和场景进行抽象。通过此模型，可以支持攻击分析流程及自动生成攻击脚本。

Result: 模型既可用于上游的攻击分析流程，也能在网络安全培训场景下，自动生成攻击脚本。

Conclusion: 该研究提出的形式化模型能够规范攻击场景数据，推动网络安全流程自动化，有助于网络攻击分析及培训自动化实践。

Abstract: Organizations face an ever-changing threat landscape. They must continuously
dedicate significant efforts to protect their assets, making their adoption of
increased cybersecurity automation inevitable. However, process automation
requires formalization of input data. Through this paper, we address this need
for processes that use attack scenarios as input. Among these processes, one
can mention both the generation of scripts for attack simulation and training
purposes, as well as the analysis of attacks. Therefore, the paper's main
research contribution is a novel formal model that encompasses the attack's
context description and its scenario. It is abstracted using UML class model.
Once the description of our model done, we will show how it could serve an
upstream attack analysis process. We will show also its use for an automatic
generation of attack scripts in the context of cybersecurity training. These
two uses cases constitute the second contribution of this present research
work.

</details>


### [38] [SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts](https://arxiv.org/abs/2507.13105)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: SemCSE是一种无监督科学文献语义嵌入方法，通过LLM生成摘要和对比学习聚合语义相近文本，并在科学领域嵌入任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统基于引文的方法没有很好地捕捉文本的语义相似性，因此需要更能反映语义内容的科学文献表征方法。

Method: 提出了一种无监督的科学文本语义嵌入方法 SemCSE，通过大语言模型生成论文摘要，并结合对比学习，让语义相关的摘要在嵌入空间中距离更近。

Result: SemCSE能更好地区分嵌入空间内的语义内容，并且在科学文本嵌入评价基准SciRepEval上取得了同等模型规模中的最新性能。

Conclusion: SemCSE能够有效提升科学文本的语义嵌入能力，优于传统方法。新的基准证明了该方法在语义内容建模上的优势。

Abstract: We introduce SemCSE, an unsupervised method for learning semantic embeddings
of scientific texts. Building on recent advances in contrastive learning for
text embeddings, our approach leverages LLM-generated summaries of scientific
abstracts to train a model that positions semantically related summaries closer
together in the embedding space. This resulting objective ensures that the
model captures the true semantic content of a text, in contrast to traditional
citation-based approaches that do not necessarily reflect semantic similarity.
To validate this, we propose a novel benchmark designed to assess a model's
ability to understand and encode the semantic content of scientific texts,
demonstrating that our method enforces a stronger semantic separation within
the embedding space. Additionally, we evaluate SemCSE on the comprehensive
SciRepEval benchmark for scientific text embeddings, where it achieves
state-of-the-art performance among models of its size, thus highlighting the
benefits of a semantically focused training approach.

</details>


### [39] [A Computational Framework to Identify Self-Aspects in Text](https://arxiv.org/abs/2507.13115)
*Jaya Caporusso,Matthew Purver,Senja Pollak*

Main category: cs.CL

TL;DR: 本提案计划开发基于本体和金标准数据的自我面向识别框架，并系统评估多种NLP方法，促进心理健康和现象学等领域的文本分析。


<details>
  <summary>Details</summary>
Motivation: 自我(Self)是一个多面向的概念，在心理学、认知科学等领域被广泛讨论，但在自然语言处理(NLP)领域，如何从文本中识别自我相关内容尚未被系统研究。许多自我相关特性与心理健康等重要现象密切相关，利用NLP进行系统分析具有应用价值。

Method: 本研究拟引入并定义自我面向本体(ontology)和人工标注的金标准数据集。基于上述基础，将开发和评估三类模型——判别模型、生成式大语言模型和基于嵌入的检索方法，并在可解释性、对标注真值的贴合度、准确率和计算效率四方面进行综合评估。

Result: 构建了自我面向的本体和高质量标注数据，提出多种模型并对它们进行评测。通过评估，筛选出最优模型并在心理健康和经验现象案例中应用，证明方法具有实际应用能力。

Conclusion: 该研究为文本中自我相关内容的识别提供了系统的方法论基础，并推动了NLP在心理学和现象学等交叉领域的研究。

Abstract: This Ph.D. proposal introduces a plan to develop a computational framework to
identify Self-aspects in text. The Self is a multifaceted construct and it is
reflected in language. While it is described across disciplines like cognitive
science and phenomenology, it remains underexplored in natural language
processing (NLP). Many of the aspects of the Self align with psychological and
other well-researched phenomena (e.g., those related to mental health),
highlighting the need for systematic NLP-based analysis. In line with this, we
plan to introduce an ontology of Self-aspects and a gold-standard annotated
dataset. Using this foundation, we will develop and evaluate conventional
discriminative models, generative large language models, and embedding-based
retrieval approaches against four main criteria: interpretability, ground-truth
adherence, accuracy, and computational efficiency. Top-performing models will
be applied in case studies in mental health and empirical phenomenology.

</details>


### [40] [Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation](https://arxiv.org/abs/2507.13138)
*Hadi Mohammadi,Tina Shahedi,Pablo Mosteiro,Massimo Poesio,Ayoub Bagheri,Anastasia Giachanou*

Main category: cs.CL

TL;DR: 标注中的人口统计偏见只贡献少量变异，大部分由内容决定。生成式AI模型模仿人格标注效果有限。聚焦内容本身和可靠的标注协议，比简单的人口角色模拟更能促进NLP公平性。


<details>
  <summary>Details</summary>
Motivation: 在NLP中，了解标注变异性的来源对于开发公平系统至关重要，尤其是在如性别歧视检测等易受人口偏见影响的任务中。因此，需要研究标注者人口统计特征对标注决策的影响程度。

Method: 采用广义线性混合模型（GLMM）量化标注决策中人口统计特征与文本内容的影响；测试引导生成式AI模型模拟不同人口特征对其标注准确性的影响；使用可解释性AI技术分析模型预测的依据。

Result: 标注者人口统计特征对变异性的影响虽统计显著，但仅占8%，推文内容是决定性主因。引导生成式AI以人口特征模拟标注者在多数情况下未能提升，甚至降低对人类判断的一致性。XAI显示模型主要依赖涉性别歧视的内容词进行判断。

Conclusion: 内容驱动解释与严谨的标注协议比模拟人口特征（persona simulation）更能提升公平性。应聚焦内容与稳健标注流程，而非简单人格设定。

Abstract: Understanding the sources of variability in annotations is crucial for
developing fair NLP systems, especially for tasks like sexism detection where
demographic bias is a concern. This study investigates the extent to which
annotator demographic features influence labeling decisions compared to text
content. Using a Generalized Linear Mixed Model, we quantify this inf luence,
finding that while statistically present, demographic factors account for a
minor fraction ( 8%) of the observed variance, with tweet content being the
dominant factor. We then assess the reliability of Generative AI (GenAI) models
as annotators, specifically evaluating if guiding them with demographic
personas improves alignment with human judgments. Our results indicate that
simplistic persona prompting often fails to enhance, and sometimes degrades,
performance compared to baseline models. Furthermore, explainable AI (XAI)
techniques reveal that model predictions rely heavily on content-specific
tokens related to sexism, rather than correlates of demographic
characteristics. We argue that focusing on content-driven explanations and
robust annotation protocols offers a more reliable path towards fairness than
potentially persona simulation.

</details>


### [41] [Feature-based analysis of oral narratives from Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13164)
*Emma Sharratt,Annelien Smith,Retief Louw,Daleen Klop,Febe de Wet,Herman Kamper*

Main category: cs.CL

TL;DR: 通过机器学习分析4-5岁南非儿童的口头叙事，发现词汇多样性、话语长度等特征有助于早期识字风险筛查，不同语言中既有共性指标也有差异，为多语言环境下的教育评估提供新依据。


<details>
  <summary>Details</summary>
Motivation: 口头叙事能力被认为是未来识字发展的有力预测指标，但如何通过客观分析判断儿童是否需要干预，尤其在多语言环境中，仍需要进一步探究。作者希望通过分析南非不同语言儿童的叙事样本，寻找有效评估指标。

Method: 研究采集4-5岁说阿非利堪斯语和科萨语的儿童叙事录音，利用简单的机器学习方法对故事进行特征分析，关注词汇多样性、发音速率、句子长度、动词和助动词的使用等特征，并与干预需求相关联。

Result: 结果表明，词汇多样性（独特词汇数）、平均话语长度能够区分典型和需干预儿童，而发音速率等特征信息量较小。尽管两种语言在词类使用上有差异，但故事中特定动词和助动词的出现与较低的干预需求相关。两种语言中既有共性也有个性化的叙事能力预测指标。

Conclusion: 研究揭示了部分叙事特征可用作早期评估工具，尤其在多语言环境下，可以用来优化儿童识字发展干预决策。部分特征为共性指标，部分具语言特异性，对多语言教育具有实践意义。

Abstract: Oral narrative skills are strong predictors of later literacy development.
This study examines the features of oral narratives from children who were
identified by experts as requiring intervention. Using simple machine learning
methods, we analyse recorded stories from four- and five-year-old Afrikaans-
and isiXhosa-speaking children. Consistent with prior research, we identify
lexical diversity (unique words) and length-based features (mean utterance
length) as indicators of typical development, but features like articulation
rate prove less informative. Despite cross-linguistic variation in
part-of-speech patterns, the use of specific verbs and auxiliaries associated
with goal-directed storytelling is correlated with a reduced likelihood of
requiring intervention. Our analysis of two linguistically distinct languages
reveals both language-specific and shared predictors of narrative proficiency,
with implications for early assessment in multilingual contexts.

</details>


### [42] [GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems](https://arxiv.org/abs/2507.13190)
*Jisoo Lee,Raeyoung Chang,Dongwook Kwon,Harmanpreet Singh,Nikhil Verma*

Main category: cs.CL

TL;DR: 本文提出了多智能体协作过程的评价新框架GEMMAS，定义了信息多样性和冗余路径两项过程指标，实验证明过程性评价能够揭示协作效率差异，有助于更好地理解和优化多智能体系统。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统评估侧重于结果的正确性，忽略了协作过程中的通信效率和协调性问题，导致推理冗余和更高的计算成本。作者旨在填补协作过程评估的空白。

Method: 提出GEMMAS图结构评估框架，将多智能体的协作过程建模为有向无环图，并设计两个过程层面指标：信息多样性分数（IDS）用于度量代理间信息交换的语义多样性，不必要路径比例（UPR）用于量化冗余推理路径。

Result: 在五个基准任务上评估，尤其在GSM8K数据集上发现，仅有2.1%准确率差异的系统在IDS和UPR上分别相差12.8%和80%。

Conclusion: 仅靠结果指标无法充分评价多智能体系统的表现，过程性诊断对设计更可解释且高效的协作AI系统十分重要。

Abstract: Multi-agent systems built on language models have shown strong performance on
collaborative reasoning tasks. However, existing evaluations focus only on the
correctness of the final output, overlooking how inefficient communication and
poor coordination contribute to redundant reasoning and higher computational
costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes
the internal collaboration process by modeling agent interactions as a directed
acyclic graph. To capture collaboration quality, we propose two process-level
metrics: Information Diversity Score (IDS) to measure semantic variation in
inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant
reasoning paths. We evaluate GEMMAS across five benchmarks and highlight
results on GSM8K, where systems with only a 2.1% difference in accuracy differ
by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal
collaboration. These findings demonstrate that outcome-only metrics are
insufficient for evaluating multi-agent performance and highlight the
importance of process-level diagnostics in designing more interpretable and
resource-efficient collaborative AI systems.

</details>


### [43] [Automatically assessing oral narratives of Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13205)
*R. Louw,E. Sharratt,F. de Wet,C. Jacobs,A. Smith,H. Kamper*

Main category: cs.CL

TL;DR: 提出了一套面向南非两种语言的学前儿童口头叙述自动评测系统，用语音识别与机器学习模型评分，LLM表现最优，可辅助教师高效发现需干预儿童，推动课堂自动口语测评发展。


<details>
  <summary>Details</summary>
Motivation: 学前儿童的叙述与理解技能对日后读写能力发展至关重要，但教师在大班教学下难以准确发现需干预的学生。因此迫切需要一种自动化的测评工具，辅助教师高效识别和支持有需要的儿童。

Method: 系统首先应用自动语音识别技术将学前儿童讲述的故事转录成文本，然后用机器学习模型对叙述和理解能力评分。评分模块分别实验了线性模型和大型语言模型，并对比其表现。

Result: LLM评分系统在大多数情况下优于线性模型，在识别需干预儿童方面几乎与人工专家持平，线性系统虽然简单，但仍具备一定竞争力。自动评测工具可显著提升教师对个性化教学支持的能力。

Conclusion: 基于大型语言模型（LLM）的系统在口头叙述和理解能力的自动测评中，能够有效识别需要干预的儿童，效果几乎可与人类专家相比。线性模型虽然性能略逊，但因其简洁也具有竞争力。该研究为课堂自动口语评估奠定了基础。

Abstract: Developing narrative and comprehension skills in early childhood is critical
for later literacy. However, teachers in large preschool classrooms struggle to
accurately identify students who require intervention. We present a system for
automatically assessing oral narratives of preschool children in Afrikaans and
isiXhosa. The system uses automatic speech recognition followed by a machine
learning scoring model to predict narrative and comprehension scores. For
scoring predicted transcripts, we compare a linear model to a large language
model (LLM). The LLM-based system outperforms the linear model in most cases,
but the linear system is competitive despite its simplicity. The LLM-based
system is comparable to a human expert in flagging children who require
intervention. We lay the foundation for automatic oral assessments in
classrooms, giving teachers extra capacity to focus on personalised support for
children's learning.

</details>


### [44] [Enhancing Cross-task Transfer of Large Language Models via Activation Steering](https://arxiv.org/abs/2507.13236)
*Xinyu Tang,Zhihao Lv,Xiaoxue Cheng,Junyi Li,Wayne Xin Zhao,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种通过激活空间操控实现LLMs跨任务迁移的新方法CAST，实验表明该方法优于现有方案，具有更高可扩展性和更低开销，适用于低资源任务。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在新任务和数据稀缺场景下表现不佳，现有的跨任务学习方法在鲁棒性、可扩展性和效率方面存在挑战。

Method: 提出一种名为CAST（Cross-task Activation Steering Transfer）的新框架，通过操控模型内部的激活状态，利用高资源任务中具有代表性的样本，进行对比增强后激活，从而帮助LLMs适应低资源任务。此方法无需参数更新和输入扩展。

Result: 在跨领域和跨语言的迁移任务上，CAST方法相较于其他主流方法表现更优，具有更好的可扩展性和更低的计算成本。

Conclusion: CAST可在无需参数调整和输入扩展的情况下，通过操控模型激活状态，实现高效、可扩展且低成本的跨任务迁移效果，提升LLMs在低资源场景下的能力。

Abstract: Large language models (LLMs) have shown impressive abilities in leveraging
pretrained knowledge through prompting, but they often struggle with unseen
tasks, particularly in data-scarce scenarios. While cross-task in-context
learning offers a direct solution for transferring knowledge across tasks, it
still faces critical challenges in terms of robustness, scalability, and
efficiency. In this paper, we investigate whether cross-task transfer can be
achieved via latent space steering without parameter updates or input
expansion. Through an analysis of activation patterns in the latent space of
LLMs, we observe that the enhanced activations induced by in-context examples
have consistent patterns across different tasks. Inspired by these findings, we
propose CAST, a novel Cross-task Activation Steering Transfer framework that
enables effective transfer by manipulating the model's internal activation
states. Our approach first selects influential and diverse samples from
high-resource tasks, then utilizes their contrastive representation-enhanced
activations to adapt LLMs to low-resource tasks. Extensive experiments across
both cross-domain and cross-lingual transfer settings show that our method
outperforms competitive baselines and demonstrates superior scalability and
lower computational costs.

</details>


### [45] [HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language Models](https://arxiv.org/abs/2507.13238)
*Ashray Gupta,Rohan Joseph,Sunny Rai*

Main category: cs.CL

TL;DR: 本文提出了首个大规模印地语类比测试集（HATS），验证了多语言大模型在印地语推理能力。实验发现Chain of Thought策略提升模型表现，且英语提示整体优于印地语。该资源为评测非英语推理能力提供了必要工具。


<details>
  <summary>Details</summary>
Motivation: 目前大部分LLMs的推理能力评测集中在英语，缺乏关于Indic语言（如印地语）上的研究，导致无法确认这些模型推理能力在多语言间的泛化。

Method: 作者构建了一个包含405道来自印度公务员考试的印地语类比多项选择题的新数据集（HATS），并采用各种提示策略，包括基于认知理论的Chain of Thought方法，系统性地评测了多种先进的多语言大模型在该数据集上的表现。

Result: 所提出的数据集为评估印地语推理能力提供了重要资源，实验数据显示，尽管HATS为印地语题目，但使用英语提示效果最好，基于认知理论的链式思考策略能进一步提升模型表现。

Conclusion: 本文提出的Hindi Analogy Test Set（HATS）成功填补了评估大型语言模型（LLMs）在印地语推理能力上的空白。实验表明，不管使用何种提示策略，模型在处理印地语类比题时，使用英语提示的表现最佳。引入的基于链式思考（Chain of Thought）的提示法能有效提升模型在印地语类比任务上的表现。

Abstract: Analogies test a model's ability to infer implicit relationships between
concepts, making them a key benchmark for evaluating reasoning capabilities.
While large language models (LLMs) are widely evaluated for reasoning in
English, their abilities in Indic languages remain understudied, limiting our
understanding of whether these models generalize across languages. To address
this gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405
multiple-choice questions sourced from Indian government exams. We benchmark
state-of-the-art multilingual LLMs using various prompting strategies and
introduce a grounded Chain of Thought approach that leverages cognitive
theories of analogical reasoning. This approach improves model performance on
Hindi analogy questions. Our experiments show that models perform best with
English prompts, irrespective of the prompting strategy. Our test set addresses
the lack of a critical resource to evaluate LLM reasoning capabilities in
Hindi.

</details>


### [46] [Automating Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2507.13255)
*Lyucheng Wu,Mengru Wang,Ziwen Xu,Tri Cao,Nay Oo,Bryan Hooi,Shumin Deng*

Main category: cs.CL

TL;DR: 为应对多模态大模型推理期安全风险，本文提出无需微调的AutoSteer推理期安全增强框架，能大幅降低多模态攻击成功率且不损失原有能力，适用于多场景实际部署。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）虽然在跨模态推理方面取得了显著进展，但也带来了新的安全隐患，尤其是在面对对抗性多模态输入时，模型容易输出有害内容。因此需要在不影响模型能力的前提下提高其推理期间的安全性。

Method: 提出了AutoSteer框架，无需对原始多模态模型进行微调，主要包括三部分：（1）新颖的安全感知分数（SAS），用于自动识别模型内部层之间与安全最相关的区分；（2）自适应安全探测器，用于基于模型中间表征预测有害输出的概率；（3）轻量级Refusal Head，当检测到安全风险时，对输出过程进行有选择性的干预。

Result: 在LLaVA-OV和Chameleon两个平台上的多项安全相关基准测试中，AutoSteer显著降低了文本、视觉以及跨模态威胁的攻击成功率，同时保持了模型的整体能力。

Conclusion: AutoSteer作为一种实用、可解释且高效的多模态AI安全推理框架，能够在保障模型原有能力的基础上，有效提升多模态系统的部署安全性。

Abstract: Recent progress in Multimodal Large Language Models (MLLMs) has unlocked
powerful cross-modal reasoning abilities, but also raised new safety concerns,
particularly when faced with adversarial multimodal inputs. To improve the
safety of MLLMs during inference, we introduce a modular and adaptive
inference-time intervention technology, AutoSteer, without requiring any
fine-tuning of the underlying model. AutoSteer incorporates three core
components: (1) a novel Safety Awareness Score (SAS) that automatically
identifies the most safety-relevant distinctions among the model's internal
layers; (2) an adaptive safety prober trained to estimate the likelihood of
toxic outputs from intermediate representations; and (3) a lightweight Refusal
Head that selectively intervenes to modulate generation when safety risks are
detected. Experiments on LLaVA-OV and Chameleon across diverse safety-critical
benchmarks demonstrate that AutoSteer significantly reduces the Attack Success
Rate (ASR) for textual, visual, and cross-modal threats, while maintaining
general abilities. These findings position AutoSteer as a practical,
interpretable, and effective framework for safer deployment of multimodal AI
systems.

</details>


### [47] [QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation](https://arxiv.org/abs/2507.13266)
*Jiazheng Li,Hong Lu,Kaiyue Wen,Zaiwen Yang,Jiaxuan Gao,Hongzhou Lin,Yi Wu,Jingzhao Zhang*

Main category: cs.CL

TL;DR: 该论文通过在强化学习训练中引入部分解题信息，提出了QuestA方法，有效提升了大语言模型在复杂数学推理任务中的表现，获得了新的SOTA成绩，并理论说明了其通用性与高效性。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）常被用于训练大语言推理模型（LLM），但最近的研究发现RL在解决多步推理、尤其是难题时的效果有限。因此，作者希望提升RL在复杂推理任务中的表现。

Method: 提出了一种称为“问题增强（Question Augmentation）”的新策略：在训练过程中引入部分解题信息，减小问题难度，为RL提供更丰富的学习信号。这一方法被称为QuestA，并在数学推理任务中应用。

Result: QuestA方法在RL训练的数学推理任务中，不仅提高了pass@1，还显著提升了pass@k，尤其是在RL原本难以提升的问题上。该方法还推动了开源模型（如DeepScaleR和OpenMath Nemotron）的进一步进步。在AIME24、AIME25和HMMT25等数学基准测试上，1.5B参数模型分别达到了67.1%、59.5%、35.5%的新SOTA成绩。

Conclusion: QuestA通过题目增强，在强化学习下有效提升了模型复杂推理能力，还通过理论分析说明了其提升了采样效率，为利用RL扩展推理能力提供了切实可行的方案。

Abstract: Reinforcement learning (RL) has become a key component in training large
language reasoning models (LLMs). However, recent studies questions its
effectiveness in improving multi-step reasoning-particularly on hard problems.
To address this challenge, we propose a simple yet effective strategy via
Question Augmentation: introduce partial solutions during training to reduce
problem difficulty and provide more informative learning signals. Our method,
QuestA, when applied during RL training on math reasoning tasks, not only
improves pass@1 but also pass@k-particularly on problems where standard RL
struggles to make progress. This enables continual improvement over strong
open-source models such as DeepScaleR and OpenMath Nemotron, further enhancing
their reasoning capabilities. We achieve new state-of-the-art results on math
benchmarks using 1.5B-parameter models: 67.1% (+5.3%) on AIME24, 59.5% (+10.0%)
on AIME25, and 35.5% (+4.0%) on HMMT25. Further, we provide theoretical
explanations that QuestA improves sample efficiency, offering a practical and
generalizable pathway for expanding reasoning capability through RL.

</details>


### [48] [Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management](https://arxiv.org/abs/2507.13275)
*Luis Gasco,Hermenegildo Fabregat,Laura García-Sardiña,Paula Estrella,Daniel Deniz,Alvaro Rodrigo,Rabih Zbib*

Main category: cs.CL

TL;DR: 该文首次构建了针对招聘与技能匹配任务的大型多语种公开基准TalentCLEF 2025，推动了多语种、多任务及公平性评测，为人力资源智能系统发展提供了重要资源。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理和大语言模型推动了人力资本管理的智能化，但该领域缺乏可靠与公平的公开评测基准和数据，限制了技术的发展与采用。本文旨在填补这一空白。

Method: 构建并公开了以技能和职位标题智能为核心的评测活动TalentCLEF 2025，包括多语种职位匹配、基于职位的技能预测两大任务，数据基于真实求职材料，经过匿名和人工标注，并评估了性别偏见。参与系统多基于多语种Encoder模型、对比学习和大语言模型。

Result: 76支队伍共提交了280多份系统，结果显示训练策略影响大于模型规模，基准包含了单语、跨语以及性别公平性评价。

Conclusion: TalentCLEF为劳动力市场语言技术提供了首个公开基准，推动了鲁棒、公平及可迁移的模型发展。

Abstract: Advances in natural language processing and large language models are driving
a major transformation in Human Capital Management, with a growing interest in
building smart systems based on language technologies for talent acquisition,
upskilling strategies, and workforce planning. However, the adoption and
progress of these technologies critically depend on the development of reliable
and fair models, properly evaluated on public data and open benchmarks, which
have so far been unavailable in this domain.
  To address this gap, we present TalentCLEF 2025, the first evaluation
campaign focused on skill and job title intelligence. The lab consists of two
tasks: Task A - Multilingual Job Title Matching, covering English, Spanish,
German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English.
Both corpora were built from real job applications, carefully anonymized, and
manually annotated to reflect the complexity and diversity of real-world labor
market data, including linguistic variability and gender-marked expressions.
  The evaluations included monolingual and cross-lingual scenarios and covered
the evaluation of gender bias.
  TalentCLEF attracted 76 registered teams with more than 280 submissions. Most
systems relied on information retrieval techniques built with multilingual
encoder-based models fine-tuned with contrastive learning, and several of them
incorporated large language models for data augmentation or re-ranking. The
results show that the training strategies have a larger effect than the size of
the model alone. TalentCLEF provides the first public benchmark in this field
and encourages the development of robust, fair, and transferable language
technologies for the labor market.

</details>


### [49] [Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis](https://arxiv.org/abs/2507.13285)
*Wang Xi,Quan Shi,Tian Yu,Yujie Peng,Jiayi Sun,Mengxing Ren,Zenghui Ding,Ningguang Yao*

Main category: cs.CL

TL;DR: 本文提出RCPS框架，有效解决自动媒体展示生成中的连贯性与布局问题，并用PREVAL工具实现高相关性的自动质量评估，全面提升生成内容的专业水准。


<details>
  <summary>Details</summary>
Motivation: 现有自动化媒体展示生成方法在内容连贯性和视觉布局方面存在明显不足，难以达到专业标准。

Method: 提出RCPS新框架，包括深度结构化叙事规划、自适应布局生成和迭代优化环；同时设计了PREVAL，一个基于偏好的多维度评估体系。

Result: RCPS在所有质量维度都显著超过基线方法，生成效果近似专家水平；PREVAL与人的评价高度相关，具备自动评测有效性。

Conclusion: RCPS框架生成的媒体展示在内容、连贯性和设计等方面显著优于现有方法，并且PREVAL评估工具能够有效反映人类判断。

Abstract: Automated generation of high-quality media presentations is challenging,
requiring robust content extraction, narrative planning, visual design, and
overall quality optimization. Existing methods often produce presentations with
logical inconsistencies and suboptimal layouts, thereby struggling to meet
professional standards. To address these challenges, we introduce RCPS
(Reflective Coherent Presentation Synthesis), a novel framework integrating
three key components: (1) Deep Structured Narrative Planning; (2) Adaptive
Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose
PREVAL, a preference-based evaluation framework employing rationale-enhanced
multi-dimensional models to assess presentation quality across Content,
Coherence, and Design. Experimental results demonstrate that RCPS significantly
outperforms baseline methods across all quality dimensions, producing
presentations that closely approximate human expert standards. PREVAL shows
strong correlation with human judgments, validating it as a reliable automated
tool for assessing presentation quality.

</details>


### [50] [AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research](https://arxiv.org/abs/2507.13300)
*Yilun Zhao,Weiyuan Chen,Zhijian Xu,Manasi Patwardhan,Yixin Liu,Chengye Wang,Lovekesh Vig,Arman Cohan*

Main category: cs.CL

TL;DR: 作者提出了消融实验设计评估基准AbGen，发现当前LLM在该任务上表现远逊于专家，且现有自动评测方法并不可靠。还推出AbGen-Eval，用于验证评测系统，为未来改进评估工具和LLM自身提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在科学研究中被广泛应用，但其在设计消融实验方面的能力尚未有系统化的评测基准。实际科学研究中，合理的消融实验设计对于验证模型有效性和理解模型机制具有重要意义，因此需要一个高质量的基准对LLM这项能力进行评估。

Method: 作者提出了AbGen，这是首个面向科学研究消融实验设计的评估基准，包含1500个人工注释的样例，源自807篇NLP论文。基准任务要求LLM根据给定的研究背景，为指定模块或流程生成详细的消融实验设计。此外，作者建立了AbGen-Eval元评估集，对目前常用的自动化评测方法在该任务下的可靠性进行分析，并通过LLM-judge系统进行了多角度评测。

Result: 主流LLM（如DeepSeek-R1-0528和o4-mini）在消融实验设计的重要性、忠实性和合理性方面与专家存在明显差距。现有的自动化评测方法对于该任务来说并不可靠，与人工评测的结果偏差很大。

Conclusion: AbGen为评估LLM在消融实验设计方面填补了空白，揭示了当前LLM与人类专家在该能力上的差距，同时AbGen-Eval表明自动化评测系统还需改进。该工作为未来发展更有效、可靠的LLM评测方法奠定了基础。

Abstract: We introduce AbGen, the first benchmark designed to evaluate the capabilities
of LLMs in designing ablation studies for scientific research. AbGen consists
of 1,500 expert-annotated examples derived from 807 NLP papers. In this
benchmark, LLMs are tasked with generating detailed ablation study designs for
a specified module or process based on the given research context. Our
evaluation of leading LLMs, such as DeepSeek-R1-0528 and o4-mini, highlights a
significant performance gap between these models and human experts in terms of
the importance, faithfulness, and soundness of the ablation study designs.
Moreover, we demonstrate that current automated evaluation methods are not
reliable for our task, as they show a significant discrepancy when compared to
human assessment. To better investigate this, we develop AbGen-Eval, a
meta-evaluation benchmark designed to assess the reliability of commonly used
automated evaluation systems in measuring LLM performance on our task. We
investigate various LLM-as-Judge systems on AbGen-Eval, providing insights for
future research on developing more effective and reliable LLM-based evaluation
systems for complex scientific tasks.

</details>


### [51] [HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals](https://arxiv.org/abs/2507.13318)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: 本研究提出了首个大规模人工标注的触觉-文本数据集HapticCap，并基于此定义了触觉-文本检索任务。通过对比学习框架和模型组合实验，发现T5+AST模型在该任务中表现最佳，为后续触觉信号与自然语言关联研究提供了重要基础。


<details>
  <summary>Details</summary>
Motivation: 触觉信号能够有效传递信息并增强虚拟现实的真实感，但如何设计能够与用户产生共鸣的触觉信号依然存在挑战。主要难点包括缺乏带文本描述的大型触觉数据集，以及现有模型难以用文本描述振动信号。

Method: 提出HapticCap数据集，这是第一个完全人工标注的触觉-文本配对数据集，包含92,070对用户对振动信号的描述，以及提出基于该数据集的触觉-文本检索任务，并采用监督对比学习框架，结合文本和振动信号的特征表示进行训练和评估。

Result: 实验结果显示，结合T5语言模型和AST音频模型的方法，在触觉-文本检索任务中表现最佳，尤其是在为不同描述类别分别训练时效果显著。

Conclusion: 本文通过开创性地构建大规模人工标注的触觉-文本数据集和相应检索任务，为触觉信号与语言表示的结合建立了基础，并证明T5+AST模型组合性能优异，有助于推动触觉理解与人机交互领域的发展。

Abstract: Haptic signals, from smartphone vibrations to virtual reality touch feedback,
can effectively convey information and enhance realism, but designing signals
that resonate meaningfully with users is challenging. To facilitate this, we
introduce a multimodal dataset and task, of matching user descriptions to
vibration haptic signals, and highlight two primary challenges: (1) lack of
large haptic vibration datasets annotated with textual descriptions as
collecting haptic descriptions is time-consuming, and (2) limited capability of
existing tasks and models to describe vibration signals in text. To advance
this area, we create HapticCap, the first fully human-annotated
haptic-captioned dataset, containing 92,070 haptic-text pairs for user
descriptions of sensory, emotional, and associative attributes of vibrations.
Based on HapticCap, we propose the haptic-caption retrieval task and present
the results of this task from a supervised contrastive learning framework that
brings together text representations within specific categories and vibrations.
Overall, the combination of language model T5 and audio model AST yields the
best performance in the haptic-caption retrieval task, especially when
separately trained for each description category.

</details>


### [52] [Social and Political Framing in Search Engine Results](https://arxiv.org/abs/2507.13325)
*Amrit Poudel,Tim Weninger*

Main category: cs.CL

TL;DR: 研究发现，主流搜索引擎在呈现政治和社会话题时不仅自身存在偏见，意识形态导向的用户查询进一步放大了这些偏见，不同搜索引擎还显示出显著的信息来源选择差异，因此搜索引擎对社会的信息极化有重要影响。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究关注搜索引擎偏见的不同方面，但针对“搜索引擎和带有意识形态倾向的用户查询如何共同影响搜索结果偏见”这一问题的探究较少。

Method: 对主流搜索引擎在政治与社会议题下的搜索结果输出进行了数据分析，比较内容优先级与来源之间的差异，并分析意识形态取向的用户查询对结果的影响。

Result: 搜索引擎不仅会以反映潜在偏见的方式优先显示内容，带有意识形态倾向的用户查询还会加剧这些偏见，导致特定叙事被放大。不同搜索引擎在优先选择信息来源上存在显著差异。

Conclusion: 搜索引擎通过强化意识形态分歧，可能在塑造公众认知与信息极化中发挥关键作用。

Abstract: Search engines play a crucial role in shaping public discourse by influencing
how information is accessed and framed. While prior research has extensively
examined various dimensions of search bias -- such as content prioritization,
indexical bias, political polarization, and sources of bias -- an important
question remains underexplored: how do search engines and
ideologically-motivated user queries contribute to bias in search results. This
study analyzes the outputs of major search engines using a dataset of political
and social topics. The findings reveal that search engines not only prioritize
content in ways that reflect underlying biases but also that
ideologically-driven user queries exacerbate these biases, resulting in the
amplification of specific narratives. Moreover, significant differences were
observed across search engines in terms of the sources they prioritize. These
results suggest that search engines may play a pivotal role in shaping public
perceptions by reinforcing ideological divides, thereby contributing to the
broader issue of information polarization.

</details>


### [53] [Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It](https://arxiv.org/abs/2507.13328)
*Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim*

Main category: cs.CL

TL;DR: 视觉-语言训练并未实质提升模型的分类学知识本身，但改善了其在语言任务中运用此类知识的能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究在视觉-语言训练对语言模型语言表征影响上的结论不一致，作者希望探索视觉-语言训练是否能提升模型的分类学（词汇概念）知识及其组织。

Method: 对比分析了文本-only语言模型与其经过视觉-语言训练的同伴，包括文本问答任务表现以及针对性行为和表征分析。

Result: 视觉-语言模型在需要分类学理解的问答任务中表现优于文本-only模型，但模型的分类学知识本身没有变化，差异体现在对带有分类学关系问题时的表征方式上。

Conclusion: 视觉-语言训练并不会显著改变模型本身的分类学知识，但会优化其在特定任务中对该知识的调用和表现。

Abstract: Does vision-and-language (VL) training change the linguistic representations
of language models in meaningful ways? Most results in the literature have
shown inconsistent or marginal differences, both behaviorally and
representationally. In this work, we start from the hypothesis that the domain
in which VL training could have a significant effect is lexical-conceptual
knowledge, in particular its taxonomic organization. Through comparing minimal
pairs of text-only LMs and their VL-trained counterparts, we first show that
the VL models often outperform their text-only counterparts on a text-only
question-answering task that requires taxonomic understanding of concepts
mentioned in the questions. Using an array of targeted behavioral and
representational analyses, we show that the LMs and VLMs do not differ
significantly in terms of their taxonomic knowledge itself, but they differ in
how they represent questions that contain concepts in a taxonomic relation vs.
a non-taxonomic relation. This implies that the taxonomic knowledge itself does
not change substantially through additional VL training, but VL training does
improve the deployment of this knowledge in the context of a specific task,
even when the presentation of the task is purely linguistic.

</details>


### [54] [The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner](https://arxiv.org/abs/2507.13332)
*Zhouqi Hua,Wenwei Zhang,Chengqi Lyu,Yuzhe Gu,Songyang Gao,Kuikun Liu,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出TAIL方法，用图灵机思想合成思维链数据，显著提升了大模型在长序列推理任务上的泛化能力，为大语言模型合成数据推理学习带来新思路。


<details>
  <summary>Details</summary>
Motivation: 目前Transformer架构的大语言模型（LLM）在处理训练时未见过的长序列问题（长度泛化能力）面临挑战。已有研究多针对具体的算术和符号操作问题提出以数据为主的方法，但这些方法通常效果有限且具有任务专用性。

Method: 作者提出了Turing MAchine Imitation Learning（TAIL）方法，通过用计算机程序合成模仿图灵机执行过程的思维链数据，将推理步骤细分为原子状态，减少捷径学习，并设计了显式内存读取机制以缓解长距离和动态数据访问的难题。

Result: TAIL在包含8类算法和18类任务的合成数据集上显著提升了Qwen2.5-7B等模型的长度泛化能力及整体性能，效果超越了以往方案和DeepSeek-R1。

Conclusion: 图灵机的核心概念对于提升大模型长度泛化至关重要，TAIL方法通过引导模型模拟图灵机的读写行为，展示了大模型在合成数据上学习推理能力的新方向。

Abstract: Length generalization, the ability to solve problems of longer sequences than
those observed during training, poses a core challenge of Transformer-based
large language models (LLM). Although existing studies have predominantly
focused on data-driven approaches for arithmetic operations and symbolic
manipulation tasks, these approaches tend to be task-specific with limited
overall performance. To pursue a more general solution, this paper focuses on a
broader case of reasoning problems that are computable, i.e., problems that
algorithms can solve, thus can be solved by the Turing Machine. From this
perspective, this paper proposes Turing MAchine Imitation Learning (TAIL) to
improve the length generalization ability of LLMs. TAIL synthesizes
chain-of-thoughts (CoT) data that imitate the execution process of a Turing
Machine by computer programs, which linearly expands the reasoning steps into
atomic states to alleviate shortcut learning and explicit memory fetch
mechanism to reduce the difficulties of dynamic and long-range data access in
elementary operations. To validate the reliability and universality of TAIL, we
construct a challenging synthetic dataset covering 8 classes of algorithms and
18 tasks. Without bells and whistles, TAIL significantly improves the length
generalization ability as well as the performance of Qwen2.5-7B on various
tasks using only synthetic data, surpassing previous methods and DeepSeek-R1.
The experimental results reveal that the key concepts in the Turing Machine,
instead of the thinking styles, are indispensable for TAIL for length
generalization, through which the model exhibits read-and-write behaviors
consistent with the properties of the Turing Machine in their attention layers.
This work provides a promising direction for future research in the learning of
LLM reasoning from synthetic data.

</details>


### [55] [A Survey of Context Engineering for Large Language Models](https://arxiv.org/abs/2507.13334)
*Lingrui Mei,Jiayu Yao,Yuyao Ge,Yiwei Wang,Baolong Bi,Yujun Cai,Jiazhi Liu,Mingyu Li,Zhong-Zhi Li,Duzhen Zhang,Chenlin Zhou,Jiayi Mao,Tianze Xia,Jiafeng Guo,Shenghua Liu*

Main category: cs.CL

TL;DR: 本文系统梳理了大语言模型中的Context Engineering，明确其定义、组成与应用现状，并指出未来需解决模型长文本生成能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理效果很大程度受到上下文输入的影响，但领域内缺乏对上下文工程的全面定义和研究体系。

Method: 对Context Engineering进行了系统性综述，包括分类、基础元件梳理和高级系统实现分析，并调研了1300余篇相关文献。

Result: 系统总结了Context Engineering的构成组件、典型架构，揭示了当前LLM在上下文理解和生成能力之间的非对称性，即理解强于生成。

Conclusion: 本文建立了Context Engineering的统一技术框架，指出未来重点是提升LLM长文本生成能力，以弥合理解与生成之间的能力鸿沟。

Abstract: The performance of Large Language Models (LLMs) is fundamentally determined
by the contextual information provided during inference. This survey introduces
Context Engineering, a formal discipline that transcends simple prompt design
to encompass the systematic optimization of information payloads for LLMs. We
present a comprehensive taxonomy decomposing Context Engineering into its
foundational components and the sophisticated implementations that integrate
them into intelligent systems. We first examine the foundational components:
context retrieval and generation, context processing and context management. We
then explore how these components are architecturally integrated to create
sophisticated system implementations: retrieval-augmented generation (RAG),
memory systems and tool-integrated reasoning, and multi-agent systems. Through
this systematic analysis of over 1300 research papers, our survey not only
establishes a technical roadmap for the field but also reveals a critical
research gap: a fundamental asymmetry exists between model capabilities. While
current models, augmented by advanced context engineering, demonstrate
remarkable proficiency in understanding complex contexts, they exhibit
pronounced limitations in generating equally sophisticated, long-form outputs.
Addressing this gap is a defining priority for future research. Ultimately,
this survey provides a unified framework for both researchers and engineers
advancing context-aware AI.

</details>


### [56] [Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes](https://arxiv.org/abs/2507.13335)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 作者构建了多类型笑话及解释数据集，评测大型语言模型对不同幽默类型的解释能力。结果表明，无模型能全面胜任所有类型笑话解释，显示计算幽默领域需扩大对复杂幽默形式的关注。


<details>
  <summary>Details</summary>
Motivation: 幽默是一种复杂的语言形式，但当前计算幽默的研究几乎都集中在基于双关语的简单笑话上。本研究动机在于探索大型语言模型在解释幽默方面的能力是否依赖于幽默类型，填补现有研究只关注简单幽默的不足。

Method: 作者整理了一个包含600个笑话的数据集，覆盖异字同音双关语、同字双关语、当代互联网幽默和依赖世界知识的时事幽默等四类笑话，并手工撰写高质量解释。随后，以零样本方式测试多个大型语言模型对不同类型笑话的解释能力，并进行效果比较。

Result: 研究发现，所有测试的大型语言模型（包括具推理能力的模型）都无法在所有类型的笑话解释任务上作出可靠且充分的解释。

Conclusion: 当前大型语言模型在解释幽默（特别是复杂和需要世界知识的幽默类型）方面表现有限，凸显了现有计算幽默研究过度聚焦简单笑话的局限。

Abstract: Humour, as a complex language form, is derived from myriad aspects of life,
whilst existing work on computational humour has focussed almost exclusively on
short pun-based jokes. In this work, we investigate whether the ability of
Large Language Models (LLMs) to explain humour depends on the particular humour
form. We compare models on simple puns and more complex topical humour that
requires knowledge of real-world entities and events. In doing so, we curate a
dataset of 600 jokes split across 4 joke types and manually write high-quality
explanations. These jokes include heterographic and homographic puns,
contemporary internet humour, and topical jokes, where understanding relies on
reasoning beyond "common sense", rooted instead in world knowledge regarding
news events and pop culture. Using this dataset, we compare the zero-shot
abilities of a range of LLMs to accurately and comprehensively explain jokes of
different types, identifying key research gaps in the task of humour
explanation. We find that none of the tested models (inc. reasoning models) are
capable of reliably generating adequate explanations of all joke types, further
highlighting the narrow focus of most works in computational humour on overly
simple joke forms.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [57] [Vector-level Feedforward Control of LPBF Melt Pool Area Using a Physics-Based Thermal Model](https://arxiv.org/abs/2507.12557)
*Nicholas Kirschbaum,Nathaniel Wood,Chang-Eun Kim,Thejaswi U. Tumkur,Chinedum Okwudire*

Main category: cs.CE

TL;DR: 本文提出了一种向量级前馈控制框架，有效预测和调节LPBF熔池面积，大幅提升金属零件的精度和致密度，方法高效、易于拓展至其它材料和设备。


<details>
  <summary>Details</summary>
Motivation: 激光选区熔化（LPBF）技术虽然能制造复杂、致密的金属零部件，但常见内部缺陷和尺寸不准确，主要受熔池行为波动影响。针对如何有效控制熔池区域、提升零件质量，目前尚无高效、泛化的方法。

Method: 提出了一种新颖的向量级前馈控制框架，通过将零件尺度的热行为与微观熔池物理过程解耦，结合有限差分热模型与简化的解析型熔池模型，分别用极少的实验数据校准两个模型，再在复杂3D几何体和不同材料上验证控制效果。

Result: 实施前馈激光功率调度后，关键尺寸的几何误差减少62%，总体孔隙率降低16.5%，光电二极管信号波动下降6.8%。

Conclusion: 通过高效通用的数据驱动模块化前馈控制，补偿预测热影响区变化，显著提升LPBF制造零件质量，方法具备良好的可扩展性和计算效率。

Abstract: Laser powder bed fusion (LPBF) is an additive manufacturing technique that
has gained popularity thanks to its ability to produce geometrically complex,
fully dense metal parts. However, these parts are prone to internal defects and
geometric inaccuracies, stemming in part from variations in the melt pool. This
paper proposes a novel vector-level feedforward control framework for
regulating melt pool area in LPBF. By decoupling part-scale thermal behavior
from small-scale melt pool physics, the controller provides a scale-agnostic
prediction of melt pool area and efficient optimization over it. This is done
by operating on two coupled lightweight models: a finite-difference thermal
model that efficiently captures vector-level temperature fields and a
reduced-order, analytical melt pool model. Each model is calibrated separately
with minimal single-track and 2D experiments, and the framework is validated on
a complex 3D geometry in both Inconel 718 and 316L stainless steel. Results
showed that feedforward vector-level laser power scheduling reduced geometric
inaccuracy in key dimensions by 62%, overall porosity by 16.5%, and photodiode
variation by 6.8% on average. Overall, this modular, data-efficient approach
demonstrates that proactively compensating for known thermal effects can
significantly improve part quality while remaining computationally efficient
and readily extensible to other materials and machines.

</details>


### [58] [IDS-Net: A novel framework for few-shot photovoltaic power prediction with interpretable dynamic selection and feature information fusion](https://arxiv.org/abs/2507.12745)
*Hang Fan,Weican Liu,Zuhan Zhang,Ying Lu,Wencai Run,Dunnan Liu*

Main category: cs.CE

TL;DR: 本文提出了一种基于特征融合和自适应动态模型选择的IDS-Net新架构，通过迁移学习实现对新建光伏电站小样本数据的高效准确预测，经实验证明具备良好效果和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 针对新建光伏电站样本数据极少导致功率预测准确性差的问题，亟需开发适合小样本、高泛化场景的准确预测方法。

Method: 方法包括两个阶段：第一，利用MMD预筛选源域数据、ReliefF做特征选择、Hampel Identifier处理异常值，并通过池化预测子模型和可解释权重分配、多通道加权与交叉嵌入融合特征实现特征提取和融合，最后通过MLP预测；第二阶段通过端到端自适应迁移学习获得目标域最终预测。

Result: 在河北两组光伏电站数据集上实验，迁移学习过程及IDS-Net结构均表现优异，验证了方法的有效性和良好泛化能力。

Conclusion: 本文提出的IDS-Net网络结合了特征信息融合及动态模型选择，有效提升了数据有限场景下的光伏功率短时预测准确性。其可解释性机制与自适应迁移学习策略表现出良好的泛化能力。

Abstract: With the growing demand for renewable energy, countries are accelerating the
construction of photovoltaic (PV) power stations. However, accurately
forecasting power data for newly constructed PV stations is extremely
challenging due to limited data availability. To this end, we propose a novel
interpretable dynamic selection network (IDS-Net) based on feature information
fusion to achieve accurate few-shot prediction. This transfer learning
framework primarily consists of two parts. In the first stage, we pre-train on
the large dataset, utilizing Maximum Mean Discrepancy (MMD) to select the
source domain dataset most similar to the target domain data distribution.
Subsequently, the ReliefF algorithm is utilized for feature selection, reducing
the influence of feature redundancy. Then, the Hampel Identifier (HI) is used
for training dataset outlier correction. In the IDS-Net model, we first obtain
the initial extracted features from a pool of predictive models. Following
this, two separate weighting channels are utilized to determine the
interpretable weights for each sub-model and the adaptive selection outcomes,
respectively. Subsequently, the extracted feature results from each sub-model
are multiplied by their corresponding weights and then summed to obtain the
weighted extracted features. Then, we perform cross-embedding on the additional
features and fuse them with the extracted weighted features. This fused
information is then passed through the MLP (Multi-Layer Perceptron) layer to
obtain predictions. In the second stage, we design an end-to-end adaptive
transfer learning strategy to obtain the final prediction results on the target
dataset. We validate the transfer learning process using two PV power datasets
from Hebei province, China, to demonstrate the effectiveness and generalization
of our framework and transfer learning strategy.

</details>


### [59] [Quantum-Enhanced Reinforcement Learning with LSTM Forecasting Signals for Optimizing Fintech Trading Decisions](https://arxiv.org/abs/2507.12835)
*Yen-Ku Liu,Yun-Huei Pan,Pei-Fan Lu,Yun-Cheng Tsai,Samuel Yen-Chi Chen*

Main category: cs.CE

TL;DR: 本文提出结合量子计算与LSTM预测信号的强化学习方法，显著提升了金融交易环境下的自动交易策略稳定性和表现。


<details>
  <summary>Details</summary>
Motivation: 金融交易环境具有高波动性、众多宏观经济信号以及动态市场状态，这导致传统强化学习方法难以实现突破性表现。作者希望解决这一在复杂金融场景下强化学习效果不佳的问题。

Method: 作者设计了一种针对金融系统的强化学习框架，将量子电路与传统A3C算法结合，并引入了基于LSTM的经济趋势预测信号。在自定义的交易模拟环境中，比较了传统A3C与量子A3C算法的表现。

Result: 实验结果显示，量子模型（特别是结合预测信号时），即便在浅量子电路深度下，在噪声金融环境中也表现出更高的性能和稳定性。

Conclusion: 引入量子计算与预测信号，可以明显提升强化学习在金融交易场景下的表现和鲁棒性。

Abstract: Financial trading environments are characterized by high volatility, numerous
macroeconomic signals, and dynamically shifting market regimes, where
traditional reinforcement learning methods often fail to deliver breakthrough
performance. In this study, we design a reinforcement learning framework
tailored for financial systems by integrating quantum circuits. We compare (1)
the performance of classical A3C versus quantum A3C algorithms, and (2) the
impact of incorporating LSTM-based predictions of the following week's economic
trends on learning outcomes. The experimental framework adopts a custom
Gymnasium-compatible trading environment, simulating discrete trading actions
and evaluating rewards based on portfolio feedback. Experimental results show
that quantum models - especially when combined with predictive signals -
demonstrate superior performance and stability under noisy financial
conditions, even with shallow quantum circuit depth.

</details>


### [60] [Agentar-DeepFinance-300K: A Large-Scale Financial Dataset via Systematic Chain-of-Thought Synthesis Optimization](https://arxiv.org/abs/2507.12901)
*Xiaoke Zhao,Zhaowen Zhou,Lin Chen,Lihong Wang,Zhiyi Huang,Kaiyuan Zheng,Yanjun Zheng,Xiyang Du,Longfei Liao,Jiawei Liu,Xiang Qi,Bo Zhang,Peng Zhang,Zhe Li,Wei Wang*

Main category: cs.CE

TL;DR: 论文发布了高质量的金融推理数据集Agentar-DeepFinance-300K，并提出了优化的链式思维合成流程；实验显示该数据集能显著提升金融领域大模型的推理能力，数据集已开放使用。


<details>
  <summary>Details</summary>
Motivation: 现有链式思维(CoT)合成方法采样较浅，且缺乏针对金融推理领域构建知识空间的研究，因此提出新方案以提升金融推理数据集的深度和有效性。

Method: 提出包含多视角知识提取(MKE)与自我纠正重写(SCR)的系统化CoT合成流程，并使用“CoT Cube”框架分析了必要性、长度和合成方式等关键因素对CoT有效性的影响。

Result: 基于Agentar-DeepFinance-300K训练的模型，在多个金融基准测试中性能显著提升。数据集已公开，旨在推动金融推理模型的进一步研究和发展。

Conclusion: 论文提出了Agentar-DeepFinance-300K大规模金融推理数据集，通过优化链式思维(CoT)合成，有效提升了金融领域的推理模型性能，并对CoT的影响因素进行了系统性分析。

Abstract: Recent advancements in large language models (LLMs) have demonstrated
remarkable general reasoning capabilities, holding significant potential for
applications in the financial domain, a field that requires robust and reliable
reasoning. It has been demonstrated that distilling high-quality
chain-of-thought (CoT) rationales from advanced general reasoning models offers
a promising and efficient path to the financial reasoning model. However,
existing CoT synthesis methods suffer from shallow CoT sampling, leaving the
question of how to construct a well-designed knowledge space for finance
reasoning unexplored. In this paper, we present
\textbf{Agentar-DeepFinance-300K }, a large-scale financial reasoning dataset
characterized by its systematic CoT synthesis optimization. We first introduce
a comprehensive CoT synthesis pipeline featuring Multi-perspective Knowledge
Extraction (MKE) and Self-Corrective Rewriting (SCR) to generate exhaustive and
deep financial reasoning trajectories. Furthermore, a systematic investigation,
termed CoT Cube, is conducted to analyze critical factors that influence CoT
effectiveness, such as necessity, length and synthesizer, yielding valuable
insights for high-quality financial CoT construction. Experiments demonstrate
that models trained on our Agentar-DeepFinance-300K achieve significant
improvements on financial benchmarks. We publicly release
Agentar-DeepFinance-300K , hoping to advance the research in financial
reasoning models.

</details>


### [61] [To What Extent Can Public Equity Indices Statistically Hedge Real Purchasing Power Loss in Compounded Structural Emerging-Market Crises? An Explainable ML-Based Assessment](https://arxiv.org/abs/2507.13055)
*Artem Alkhamov,Boris Kriuk*

Main category: cs.CE

TL;DR: 新兴市场宏观金融危机下，地方股票指数无法对冲实际购买力损失，颠覆了股票作为通胀贬值对冲工具的传统认知。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究新兴市场在发生复合型结构性宏观金融危机期间，地方公开股票指数在统计意义上能否对实际购买力损失进行有效对冲。

Method: 采用非线性乘法实际收益率计算方法（一致于Fisher平价理论），结合分位数回归、尾部相关Copula分析和SHAP解释工具，综合评估宏观变量对实际购买力保护能力的解释力。数据集中在2018年后的土耳其、2020年的尼日利亚和2021年的巴基斯坦三次危机事件，并选用数据标准化水平高、易于比较的案例。

Result: 通过尾部重点建模发现，恰恰在宏观经济和货币双重扰动同时发生、最需保护实际购买力的时刻，地方股票指数对实际购买力的保护系统性失效。

Conclusion: 传统理论认为股票可对冲通胀和货币贬值风险，但本研究发现，在复合宏观金融危机期间，这一保护假设在新兴市场未能成立，提示需要采用更具情境针对性的危机应对策略。

Abstract: This study investigates the extent to which local public equity indices can
statistically hedge real purchasing power loss during compounded structural
macro-financial collapses in emerging markets. We employ a non-linear
multiplicative real return calculations consistent with Fisher-parity logics
for both domestic and foreign investors with a principled quantile regression,
tail dependence copula analysis, and Shapley Additive Explanations (SHAP) to
assess the explanatory power of macro variables. The analysis focuses on three
recent and data-accessible exemplary collapse episodes: Turkey (2018), Nigeria
(2020), and Pakistan (2021). Such cases, selected to align with post-2018
improvements in data standardization and crisis comparability, span varied
monetary regimes and crisis triggers. Our tail-focused modeling reveals a
systematic breakdown in public-equity-based purchasing power protection
precisely during simultaneous macroeconomic and monetary dislocations when such
protection is most needed. The findings call into question conventional
inflation and devaluation hedge presumptions in equity pricing theory,
emphasizing the limitations of equity-based protection and the need for
context-sensitive strategies during compounded macro-financial distress.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [62] [Rookie Mistakes: Measuring Software Quality in Student Projects to Guide Educational Enhancement](https://arxiv.org/abs/2507.12488)
*Marco De Luca,Sergio Di Martino,Sergio Di Meglio,Anna Rita Fasolino,Luigi Libero Lucio Starace,Porfirio Tramontana*

Main category: cs.CY

TL;DR: 本科编程课程普遍忽视软件质量教育。本文通过静态分析评估了172名学生的83个团队项目，揭示了中级学生在较复杂项目中常见的软件质量问题，并为课程优化提供了数据支持。


<details>
  <summary>Details</summary>
Motivation: 动因为当前本科教学过于关注项目功能实现，导致软件质量教育被弱化，且现有文献大多限于新手及小代码单元，对有一定编程基础学生在复杂项目中的质量表现缺乏了解。

Method: 作者分析了4届面向对象编程课程中172名学生组成的83个团队项目，采用了SonarQube和ArchUnit进行静态分析，以检测代码中的代码异味和架构反模式，从而评估软件质量。

Result: 结果发现，学生团队在面向对象复杂项目开发中存在很多重复的质量问题。研究为软件工程课程的持续改进和质量意识教育提供了实证参考，对教学内容和侧重点的调整具有指导意义。

Conclusion: 本文总结了当前本科阶段编程及软件工程教学在软件质量培养方面的不足，并通过实证研究为课程设计提供了指导建议。结果展示了中级学生团队在复杂项目中普遍存在的质量问题，为后续课程与教学优化提供了依据。

Abstract: When teaching Programming and Software Engineering in Bachelor's Degree
programs, the emphasis on creating functional software projects often
overshadows the focus on software quality, a trend that aligns with ACM
curricula recommendations. Software Engineering courses are typically
introduced later in the curriculum, and can generally allocate only limited
time to quality-related topics, leaving educators with the challenge of
deciding which quality aspects to prioritize. In this decision, the literature
offers limited guidance, as most existing studies focus on code written by
novice students and small code units, making it unclear whether those findings
extend to intermediate-level students with foundational object-oriented
programming skills working on more complex software projects. To address this
gap, we analyze 83 object-oriented team projects developed by 172 university
students across 4 different editions of the Object-Oriented Programming course.
We apply a static analysis pipeline used in prior research to assess software
quality, combining SonarQube and ArchUnit to detect code smells and
architectural anti-patterns. Our findings highlight recurring quality issues
and offer concrete evidence of the challenges students face at this stage,
providing valuable guidance for educators aiming to continuously improve
Software Engineering curricula and promote quality-oriented development
practices.

</details>


### [63] [Catching Dark Signals in Algorithms: Unveiling Audiovisual and Thematic Markers of Unsafe Content Recommended for Children and Teenagers](https://arxiv.org/abs/2507.12571)
*Haoning Xue,Brian Nishimine,Martin Hilbert,Drew Cingel,Samantha Vigil,Jane Shawcroft,Arti Thakur,Zubair Shafiq,Jingwen Zhang*

Main category: cs.CY

TL;DR: 算法推荐下的短视频平台存在对青少年的显性与隐性内容风险，当前年龄验证机制不足，需更精细的内容管控和平台监管以保护未成年人。


<details>
  <summary>Details</summary>
Motivation: 短视频平台广泛流行，同时年龄验证机制无效，使得儿童和青少年在由算法主导的网络环境中面临潜在伤害的风险增加。本文关注这些风险，并试图系统分析其具体表现。

Method: 通过算法审计实验，采集了Instagram Reels、TikTok和YouTube Shorts平台上推荐给儿童和青少年的4492条短视频，并对其进行了多模态特征分析和主题建模，从内容层面与特征层面对安全性进行评估。

Result: 分析显示，不安全（有问题、引发心理压力）的短视频通常具有更暗的视觉特征，内容上不仅有明确危害，还存在由普通但令人焦虑内容造成的隐性危害。提出了一套包括“明确、隐性、无意”三类网络伤害的分析框架，揭示了算法推荐下儿童和青少年面临的复杂、多面风险。

Conclusion: 研究强调，需在内容审核、年龄认证和平台监管方面采用更细致的方法，以保护处于关键发展阶段的青少年用户，防止其暴露于显性与隐性的社交平台风险之下。

Abstract: The prevalence of short form video platforms, combined with the
ineffectiveness of age verification mechanisms, raises concerns about the
potential harms facing children and teenagers in an algorithm-moderated online
environment. We conducted multimodal feature analysis and thematic topic
modeling of 4,492 short videos recommended to children and teenagers on
Instagram Reels, TikTok, and YouTube Shorts, collected as a part of an
algorithm auditing experiment. This feature-level and content-level analysis
revealed that unsafe (i.e., problematic, mentally distressing) short videos (a)
possess darker visual features and (b) contain explicitly harmful content and
implicit harm from anxiety-inducing ordinary content. We introduce a useful
framework of online harm (i.e., explicit, implicit, unintended), providing a
unique lens for understanding the dynamic, multifaceted online risks facing
children and teenagers. The findings highlight the importance of protecting
younger audiences in critical developmental stages from both explicit and
implicit risks on social media, calling for nuanced content moderation, age
verification, and platform regulation.

</details>


### [64] [ParaStudent: Generating and Evaluating Realistic Student Code by Teaching LLMs to Struggle](https://arxiv.org/abs/2507.12674)
*Mihran Miroyan,Rose Niousha,Joseph E. Gonzalez,Gireeja Ranade,Narges Norouzi*

Main category: cs.CY

TL;DR: 通过微调大语言模型，可更真实地再现学生在编程学习中的代码生成过程，捕捉错误、改进和风格多样性，对提升编程教育智能化具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽在编程任务上表现优秀，但尚未系统性探究其是否能模拟学生的真实代码生成过程（如不完美、反复尝试、多样风格）。该研究旨在推动LLM生成更有“学生气”的代码，以服务编程教学和自动化评测。

Method: 以多学期的带时间戳的学生代码提交数据为基础，设计了低分辨率和高分辨率实验，针对代码生成在语义、功能和风格等多个维度进行分析，并对LLM进行微调以更好地捕捉学习动态。

Result: 微调后的LLM在模拟学生代码时更加贴近真实学生，能捕获学生常见错误、逐步优化、个性化风格等特征，为未来智能编程教育和自动代码评测提供了更高质量的数据和工具。

Conclusion: 对LLM进行针对性微调后，能够更真实地模拟学生代码生成过程，准确反映错误模式、逐步改进和风格多样性，能更好地对齐真实学生学习轨迹。

Abstract: Large Language Models (LLMs) have shown strong performance on programming
tasks, but can they generate student-like code like real students - imperfect,
iterative, and stylistically diverse? We present ParaStudent, a systematic
study of LLM-based "student-like" code generation in an introductory
programming course setting. Using a dataset of timestamped student submissions
across multiple semesters, we design low- and high-resolution experiments to
model student progress and evaluate code outputs along semantic, functional,
and stylistic dimensions. Our results show that fine-tuning significantly
improves alignment with real student trajectories and captures error patterns,
incremental improvements, and stylistic variations more faithfully. This study
shows that modeling realistic student code requires capturing learning dynamics
through context-aware generation, temporal modeling, and multi-dimensional
evaluation. Code for experiments and evaluation is available at
\href{https://github.com/mmiroyan/ParaStudent}{\texttt{github.com/mmiroyan/ParaStudent}}.

</details>


### [65] [The Case for Contextual Copyleft: Licensing Open Source Training Data and Generative AI](https://arxiv.org/abs/2507.12713)
*Grant Shanklin,Emmie Hine,Claudio Novelli,Tyler Schroder,Luciano Floridi*

Main category: cs.CY

TL;DR: 论文提出CCAI许可证，将copyleft要求从训练数据扩展到生成AI模型本身，经多维度论证后认为其适当监管下可有效推动开源AI健康发展。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI系统的兴起，传统开源软件的copyleft原则如何适用于AI模型训练成为新挑战，尤其涉及到开源代码被用于AI模型训练后的权利归属与合规问题。

Method: 提出并介绍了一种新的Contextual Copyleft AI（CCAI）许可证，并通过三个部分的结构化评估框架进行论证：法律可行性分析、政策合理性比较，以及跨场景利益与风险的综合分析。

Result: CCAI许可证能够增强开发者控制权、激励开源AI开发，并减少表面开源（openwashing）行为，但同时也带来了开源AI被直接滥用的风险，因此需要配合更全面的监管手段。

Conclusion: 在强有力的AI责任监管环境下实施，CCAI许可证为维护与适应开源原则至生成式AI开发提供了可行机制。

Abstract: The proliferation of generative AI systems has created new challenges for the
Free and Open Source Software (FOSS) community, particularly regarding how
traditional copyleft principles should apply when open source code is used to
train AI models. This article introduces the Contextual Copyleft AI (CCAI)
license, a novel licensing mechanism that extends copyleft requirements from
training data to the resulting generative AI models. The CCAI license offers
significant advantages, including enhanced developer control, incentivization
of open source AI development, and mitigation of openwashing practices. This is
demonstrated through a structured three-part evaluation framework that examines
(1) legal feasibility under current copyright law, (2) policy justification
comparing traditional software and AI contexts, and (3) synthesis of
cross-contextual benefits and risks. However, the increased risk profile of
open source AI, particularly the potential for direct misuse, necessitates
complementary regulatory approaches to achieve an appropriate risk-benefit
balance. The paper concludes that when implemented within a robust regulatory
environment focused on responsible AI usage, the CCAI license provides a viable
mechanism for preserving and adapting core FOSS principles to the evolving
landscape of generative AI development.

</details>


### [66] [The Goldilocks zone of governing technology: Leveraging uncertainty for responsible quantum practices](https://arxiv.org/abs/2507.12957)
*Miriam Meckel,Philipp Hacker,Lea Steinacker,Aurelija Lukoseviciene,Surjo R. Soekadar,Jacob Slosser,Gina-Maria Poehlmann*

Main category: cs.CY

TL;DR: 本文针对量子计算等新兴技术，主张不应将不确定性视为治理障碍，而应通过概率性思维将其纳入创新与监管框架。提出的量子风险模拟器（QRS）和相关治理模型，旨在为欧盟等地区在技术监管上提供灵活、负责任的全新思路。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算等新兴技术的发展，传统治理方式面临挑战，尤其当不确定性成为这些技术的核心特征而非暂时性障碍时，现有治理框架难以应对。本文旨在探讨如何将不确定性转化为创新治理的推动力。

Method: 该文运用量子力学范式，提出一种基于适应性和概率性的创新治理框架。作者通过区分物理、技术和社会三个层面的不确定性，构建了“量子风险模拟器（QRS）”的概念性蓝图，并借鉴认知神经科学和预测处理的类比进行建模。

Result: 提出了以概率推理为中心、能够适应不确定性动态变化的治理框架。该方法为欧盟等寻求在放任自流与国家主导间取得平衡的区域，提供了一种灵活且负责任的监管新思路。

Conclusion: 以量子系统概率本质为基础的治理模型，有望为包括欧盟在内的相关国家和地区提供在前沿技术领域兼顾灵活性与责任感的新治理途径。

Abstract: Emerging technologies challenge conventional governance approaches,
especially when uncertainty is not a temporary obstacle but a foundational
feature as in quantum computing. This paper reframes uncertainty from a
governance liability to a generative force, using the paradigms of quantum
mechanics to propose adaptive, probabilistic frameworks for responsible
innovation. We identify three interdependent layers of uncertainty--physical,
technical, and societal--central to the evolution of quantum technologies. The
proposed Quantum Risk Simulator (QRS) serves as a conceptual example, an
imaginative blueprint rather than a prescriptive tool, meant to illustrate how
probabilistic reasoning could guide dynamic, uncertainty-based governance. By
foregrounding epistemic and ontological ambiguity, and drawing analogies from
cognitive neuroscience and predictive processing, we suggest a new model of
governance aligned with the probabilistic essence of quantum systems. This
model, we argue, is especially promising for the European Union as a third way
between laissez-faire innovation and state-led control, offering a flexible yet
responsible pathway for regulating quantum and other frontier technologies.

</details>


### [67] [Bridging Boundaries: How to Foster Effective Research Collaborations Across Affiliations in the Field of Trust and Safety](https://arxiv.org/abs/2507.13008)
*Amanda Menking,Mona Elswah,David J. Grüning,Lasse H. Hansen,Irene Huang,Julia Kamin,Catrine Normann*

Main category: cs.CY

TL;DR: 为了应对数字空间信任与安全领域的多元复杂需求，作者提出了跨部门合作的具体框架和策略，推动更具伦理性和现实意义的协作与研究。


<details>
  <summary>Details</summary>
Motivation: 信任与安全领域在数字空间中日益重要，但跨学术、产业、政府和非政府组织的合作因激励、时间表与限制不同而变得日益复杂。作者希望为这些合作提供解决方案。

Method: 本文基于作者自身的跨领域合作经验，归纳出主要合作类型，分析各领域在研究优先级、运营压力和评估标准上的差异，并提出一步步的实际操作框架与策略来建立和管理有效合作。

Result: 提出了实用的跨部门合作框架，包括信任建立、目标对齐和角色分配等策略，并强调了经常被忽视的沟通和协调工作的重要性。

Conclusion: 文中认为跨部门合作对信任与安全领域的伦理、公平和影响力至关重要，并呼吁采用包容、透明和现实相关的合作模式以满足该领域的跨学科需求。

Abstract: As the field of Trust and Safety in digital spaces continues to grow, it has
become increasingly necessary - but also increasingly complex - to collaborate
on research across the academic, industry, governmental and non-governmental
sectors. This paper examines how cross-affiliation research partnerships can be
structured to overcome misaligned incentives, timelines and constraints while
delivering on the unique strengths of each stakeholder. Drawing on our own
experience of cross-sector collaboration, we define the main types of
affiliation and highlight the common differences in research priorities,
operational pressures and evaluation metrics across sectors. We then propose a
practical, step-by-step framework for initiating and managing effective
collaborations, including strategies for building trust, aligning goals, and
distributing roles. We emphasize the critical yet often invisible work of
articulation and argue that cross-sector partnerships are essential for
developing more ethical, equitable and impactful research in trust and safety.
Ultimately, we advocate collaborative models that prioritize inclusivity,
transparency and real-world relevance in order to meet the interdisciplinary
demands of this emerging field.

</details>


### [68] [Quantifying the Improvement of Accessibility achieved via Shared Mobility on Demand](https://arxiv.org/abs/2507.13100)
*Severin Diepolder,Andrea Araldo,Tarek Chouaki,Santa Maiti,Sebastian Hörl,Constantinos Antoniou*

Main category: cs.CY

TL;DR: 本研究提出了首个结合共享出行与传统公共交通的等时线可达性定量评估方法，并用巴黎-萨克雷的仿真案例验证其有效性，为低密度地区交通可达性评价和服务优化提供技术支持。


<details>
  <summary>Details</summary>
Motivation: 传统公共交通在低密度地区服务不足，难以满足居民出行需求。尽管共享出行服务（如需求响应交通、拼车）可以提升这些区域的出行，但其主要贡献——提升用户可达性（如通勤、上学、经商等）——尚无定量评估标准。特别是，基于等时线的可达性指标虽然直观易懂，但缺乏与共享出行服务结合的定量计算方法。

Method: 作者提出一种融合常规公共交通与共享出行（SMS）的系统中，计算等时线可达性的新方法。具体方法是基于空间-时间统计分析（如克里金法），以实际记录的共享出行行程数据为输入，构建图模型，并在此基础上计算等时线可达性指标。该方法通过仿真（MATSim）在巴黎-萨克雷郊区的需求响应交通与传统公共交通一体化场景下验证。

Result: 提出的等时线可达性计算方法可以量化共享出行服务整合后的公共交通系统，对比常规公共交通可以显著提升用户在限定时间内可到达的机会数量。该方法有效弥补了现有评估共享出行贡献的不足，为政策制定和服务优化提供了量化工具。

Conclusion: 本文补足了衡量共享出行服务改善交通可达性的量化方法空白，为公共交通规划和共享服务融合提供理论与实践基础，有助于提升低密度区域交通公平性和便捷性。

Abstract: Shared Mobility Services (SMS), e.g., demand-responsive transport or
ride-sharing, can improve mobility in low-density areas, which are often poorly
served by conventional Public Transport (PT). Such improvement is generally
measured via basic performance indicators, such as waiting or travel time.
However, such basic indicators do not account for the most important
contribution that SMS can provide to territories, i.e., increasing the
potential, for users, to reach surrounding opportunities, such as jobs,
schools, businesses, etc. Such potential can be measured by isochrone-based
accessibility indicators, which count the number of opportunities reachable in
a limited time, and are thus easy for the public to understand. % The potential
impact of SMS on accessibility has been qualitatively discussed and
implications on equity have been empirically studied. However, to date, there
are no quantitative methods to compute isochrone-based indicators of the
accessibility achieved via SMS.
  This work fills this gap by proposing a first method to compute isochrone
accessibility of PT systems composed of conventional PT and SMS, acting as a
feeder for access and egress trips to/from PT hubs. This method is grounded on
spatial-temporal statistical analysis, performed via Kriging. It takes as input
observed trips of SMS and summarizes them in a graph. On such a graph,
isochrone accessibility indicators are computed. We apply the proposed method
to a MATSim simulation study concerning demand-responsive transport integrated
into PT, in the suburban area of Paris-Saclay.

</details>
