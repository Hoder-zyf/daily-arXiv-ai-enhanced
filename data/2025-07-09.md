<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 9]
- [cs.CL](#cs.CL) [Total: 8]
- [cs.CE](#cs.CE) [Total: 3]
- [cs.CY](#cs.CY) [Total: 9]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy of Prematurity](https://arxiv.org/abs/2507.05816)
*Shuai Zhao,Yulin Zhang,Luwei Xiao,Xinyi Wu,Yanhao Jia,Zhongliang Guo,Xiaobao Wu,Cong-Duy Nguyen,Guoming Zhang,Anh Tuan Luu*

Main category: cs.AI

TL;DR: 本文提出CROP数据集和Affective-ROPTester评测框架，发现大模型需外部知识辅助才能提高早产儿视网膜病变风险预测能力，且通过正面情感提示可有效缓解模型偏差。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在许多领域取得进展，但其对早产儿视网膜病变风险预测的能力尚未被系统研究，需要建立基准数据集及评测框架来填补该空白。

Method: 构建了CROP中文数据集，并设计Affective-ROPTester自动评测框架，采用三种提示策略（直接指令、链式思维、上下文学习），结合情感调控，从不同角度考察大模型预测早产儿视网膜病变风险的能力与偏倚。

Result: 1) 大模型依赖自身知识时对ROP风险预测效果有限，结合结构化外部输入后性能显著提升；2) 模型对中高风险有高估倾向，存在情感偏差；3) 正面情感化提示有助于缓解预测偏差。

Conclusion: 情感敏感性提示工程可以提升诊断可靠性，Affective-ROPTester为评估和缓解临床语言模型中的情感偏差提供了有效框架。

Abstract: Despite the remarkable progress of large language models (LLMs) across
various domains, their capacity to predict retinopathy of prematurity (ROP)
risk remains largely unexplored. To address this gap, we introduce a novel
Chinese benchmark dataset, termed CROP, comprising 993 admission records
annotated with low, medium, and high-risk labels. To systematically examine the
predictive capabilities and affective biases of LLMs in ROP risk
stratification, we propose Affective-ROPTester, an automated evaluation
framework incorporating three prompting strategies: Instruction-based,
Chain-of-Thought (CoT), and In-Context Learning (ICL). The Instruction scheme
assesses LLMs' intrinsic knowledge and associated biases, whereas the CoT and
ICL schemes leverage external medical knowledge to enhance predictive accuracy.
Crucially, we integrate emotional elements at the prompt level to investigate
how different affective framings influence the model's ability to predict ROP
and its bias patterns. Empirical results derived from the CROP dataset yield
two principal observations. First, LLMs demonstrate limited efficacy in ROP
risk prediction when operating solely on intrinsic knowledge, yet exhibit
marked performance gains when augmented with structured external inputs.
Second, affective biases are evident in the model outputs, with a consistent
inclination toward overestimating medium- and high-risk cases. Third, compared
to negative emotions, positive emotional framing contributes to mitigating
predictive bias in model outputs. These findings highlight the critical role of
affect-sensitive prompt engineering in enhancing diagnostic reliability and
emphasize the utility of Affective-ROPTester as a framework for evaluating and
mitigating affective bias in clinical language modeling systems.

</details>


### [2] [Strongly Solving $7 \times 6$ Connect-Four on Consumer Grade Hardware](https://arxiv.org/abs/2507.05267)
*Markus Böck*

Main category: cs.AI

TL;DR: 作者利用高效的符号搜索，首次在单核大内存机器上实现了Connect-Four的强解查询表生成，并开源了可用于最优路径搜索的工具。


<details>
  <summary>Details</summary>
Motivation: 尽管Connect-Four游戏已经通过数学方法被解决，并且可以使用基于搜索的方法有效地计算最佳走法，但制作一个查询表（look-up table）形式的强解一直被认为是难以实现的。作者希望突破这一限制。

Method: 作者利用基于二元决策图（binary decision diagrams, BDD）的符号搜索方法，并实现了高效的算法，在一台配有128GB内存的单核CPU上进行了计算。

Result: 作者成功为标准7×6棋盘规模生成了一个89.6GB的大型查询表，仅用47小时完成，对每种局面可以实现胜-和-负的评估。此外，开源代码还集成了alpha-beta搜索，可找到最快胜或最慢败的走法。

Conclusion: 通过符号搜索与高效实现，成功为Connect-Four生成了强解查询表，提升了对该游戏解空间的实用访问能力，也为相关问题提供了参考方法。

Abstract: While the game Connect-Four has been solved mathematically and the best move
can be effectively computed with search based methods, a strong solution in the
form of a look-up table was believed to be infeasible. In this paper, we
revisit a symbolic search method based on binary decision diagrams to produce
strong solutions. With our efficient implementation we were able to produce a
89.6 GB large look-up table in 47 hours on a single CPU core with 128 GB main
memory for the standard $7 \times 6$ board size. In addition to this
win-draw-loss evaluation, we include an alpha-beta search in our open source
artifact to find the move which achieves the fastest win or slowest loss.

</details>


### [3] [Chat2SPaT: A Large Language Model Based Tool for Automating Traffic Signal Control Plan Management](https://arxiv.org/abs/2507.05283)
*Yue Wang,Miao Zhou,Guijing Huang,Rui Zhuo,Chao Yi,Zhenliang Ma*

Main category: cs.AI

TL;DR: Chat2SPaT利用大语言模型实现交通信号控制方案的自动化生成，显著简化了人工输入流程，在中英文任务中均表现出高准确率，对于智能交通领域具有实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 传统预设时段交通信号控制方案在制定和更新时需要大量人工输入，尤其当一个路口需要多个不同时间段的信号方案时，这种重复工作尤为繁琐，效率低下。因此，如何简化信号控制方案的管理流程，减轻人工负担，提高准确率，成为一个亟需解决的问题。

Method: 提出了一种名为Chat2SPaT的方法，通过大语言模型(LLM)理解用户对交通信号控制方案的半结构化、模糊描述，并将其自动转换为精确的信号相位与时序（SPaT）结果。通过精心设计的提示词，LLM生成json格式的相位序列及属性，后续利用python脚本定位各周期相位、处理实际信号控制中的细节，最终组装成完整的信号控制方案。该管道支持多轮交互和编辑。

Result: Chat2SPaT能够实现英文和中文信号方案描述到结构化计划的高精度转换，在包含300余条方案描述的测试集中，生成计划的准确率超过94%。

Conclusion: Chat2SPaT展示了大语言模型在交通信号控制方案理解与生成方面的实际应用价值，大幅提升了方案管理的便捷性与效率，可以作为未来ITS（智能交通系统）中信号控制应用的重要模块。同时还首次构建了评估此类任务的基准数据集。

Abstract: Pre-timed traffic signal control, commonly used for operating signalized
intersections and coordinated arterials, requires tedious manual work for
signaling plan creating and updating. When the time-of-day or day-of-week plans
are utilized, one intersection is often associated with multiple plans, leading
to further repetitive manual plan parameter inputting. To enable a
user-friendly traffic signal control plan management process, this study
proposes Chat2SPaT, a method to convert users' semi-structured and ambiguous
descriptions on the signal control plan to exact signal phase and timing (SPaT)
results, which could further be transformed into structured stage-based or
ring-based plans to interact with intelligent transportation system (ITS)
software and traffic signal controllers. With curated prompts, Chat2SPaT first
leverages large language models' (LLMs) capability of understanding users' plan
descriptions and reformulate the plan as a combination of phase sequence and
phase attribute results in the json format. Based on LLM outputs, python
scripts are designed to locate phases in a cycle, address nuances of traffic
signal control, and finally assemble the complete traffic signal control plan.
Within a chat, the pipeline can be utilized iteratively to conduct further plan
editing. Experiments show that Chat2SPaT can generate plans with an accuracy of
over 94% for both English and Chinese cases, using a test dataset with over 300
plan descriptions. As the first benchmark for evaluating LLMs' capability of
understanding traffic signal control plan descriptions, Chat2SPaT provides an
easy-to-use plan management pipeline for traffic practitioners and researchers,
serving as a potential new building block for a more accurate and versatile
application of LLMs in the field of ITS. The source codes, prompts and test
dataset are openly accessible at https://github.com/yuewangits/Chat2SPaT.

</details>


### [4] [Fuzzy Classification Aggregation for a Continuum of Agents](https://arxiv.org/abs/2507.05297)
*Zijun Meng*

Main category: cs.AI

TL;DR: 满足最优、独立和零一致性的模糊分类聚合函数，必然是加权算术平均。


<details>
  <summary>Details</summary>
Motivation: 研究模糊分类情境下，如何将大量个体对多个对象的分类结果合理、最优地聚合，特别是在满足最优性、独立性和零一致性等公理时，聚合函数应具有什么结构。

Method: 在公理化框架下，针对无限多个个体对多个对象的模糊分类，利用函数性质分析与严格的数学证明，刻画出所有满足特定公理的聚合函数。

Result: 证明了在给定的公理条件下，唯一满足要求的聚合函数形式是加权算术平均。

Conclusion: 对于无限多个个体对多个对象进行的模糊分类，只要聚合函数满足最优、独立与零一致性这三条公理，其结构必然是加权算术平均。

Abstract: We prove that any optimal, independent, and zero unanimous fuzzy
classification aggregation function of a continuum of individual
classifications of $m\ge 3$ objects into $2\le p\le m$ types must be a weighted
arithmetic mean.

</details>


### [5] [OLG++: A Semantic Extension of Obligation Logic Graph](https://arxiv.org/abs/2507.05488)
*Subhasis Dasgupta,Jon Stephens,Amarnath Gupta*

Main category: cs.AI

TL;DR: 本文提出OLG++，扩展现有法律知识图谱模型，实现更复杂法律规则的表达与推理，特别在空间、时间、例外处理及类继承等方面表现更优，对实际法规场景具备更强适用性。


<details>
  <summary>Details</summary>
Motivation: 现有的法律知识图谱如OLG和LegalRuleML在表达复杂法律规则、上下文及例外等方面存在局限，难以满足市政及跨地域场景下法律规则建模的需求。

Method: 提出OLG++，对原有Obligation Logic Graph进行语义扩展，引入更丰富的节点和边类型（如空间、时间、团体、多层例外结构等），支持上下文条件、优先级、触发条件等结构化推理，并通过实际食品行业法规案例进行验证。

Result: OLG++能够通过属性图查询实现法律问答，并对subClassOf、空间约束、例外等提供原生支持，相较LegalRuleML和其他图谱模型拥有更强表达能力。

Conclusion: OLG++在法律规则表示与推理方面优于现有模型，尤其适用于需要表达复杂上下文与例外情况的场景。

Abstract: We present OLG++, a semantic extension of the Obligation Logic Graph (OLG)
for modeling regulatory and legal rules in municipal and interjurisdictional
contexts. OLG++ introduces richer node and edge types, including spatial,
temporal, party group, defeasibility, and logical grouping constructs, enabling
nuanced representations of legal obligations, exceptions, and hierarchies. The
model supports structured reasoning over rules with contextual conditions,
precedence, and complex triggers. We demonstrate its expressiveness through
examples from food business regulations, showing how OLG++ supports legal
question answering using property graph queries. OLG++ also improves over
LegalRuleML by providing native support for subClassOf, spatial constraints,
and reified exception structures. Our examples show that OLG++ is more
expressive than prior graph-based models for legal knowledge representation.

</details>


### [6] [Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents](https://arxiv.org/abs/2507.05495)
*Prahaladh Chandrahasan,Jiahe Jin,Zhihan Zhang,Tevin Wang,Andy Tang,Lucy Mo,Morteza Ziyadi,Leonardo F. R. Ribeiro,Zimeng Qiu,Markus Dreyer,Akari Asai,Chenyan Xiong*

Main category: cs.AI

TL;DR: 本论文提出了一个名为Deep Research Comparator的平台，用于托管、并行对比和评估深度研究智能体，包括最终报告及其中间步骤的详细人工反馈。作者同时提供了可作为基线的深度研究智能体实现，并公开了实际用户偏好评价数据，为相关研究和开发提供了支持。


<details>
  <summary>Details</summary>
Motivation: 深度研究智能体可以自主进行网页检索、分析信息并生成报告，但其评估面临重大挑战，尤其是在对长报告及其中间步骤进行细致反馈方面尚无完善方法。

Method: 作者提出了Deep Research Comparator平台。该平台支持深度研究智能体的托管、并行对比、细粒度人工反馈收集与排名算法。平台会展示两个智能体针对同一查询的最终报告及其中间生成步骤，人工注释员可并排比较、给出总体现结果反馈，并对中间步骤或特定报告段落做细致评价。此外，作者还开发了Simple Deepresearch基线系统，便于集成多种大语言模型，将其转化为可评测的深度研究智能体。

Result: 通过该平台，作者从17位注释员收集了三种深度研究智能体的实际用户偏好数据。平台支持灵活、精细的评价和开发，演示视频已发布。

Conclusion: Deep Research Comparator平台有效促进了深度研究智能体的评测、对比及开发，填补了长报告和中间步骤细致反馈评估的空白，并为该方向提供了数据和工具支持。

Abstract: Effectively evaluating deep research agents that autonomously search the web,
analyze information, and generate reports remains a major challenge,
particularly when it comes to assessing long reports and giving detailed
feedback on their intermediate steps. To address these gaps, we introduce Deep
Research Comparator, a platform that offers a holistic framework for deep
research agent hosting, side-by-side comparison, fine-grained human feedback
collection, and ranking calculation. Given a user query, our platform displays
the final reports from two different agents along with their intermediate steps
during generation. Annotators can evaluate the overall quality of final reports
based on side-by-side comparison, and also provide detailed feedback separately
by assessing intermediate steps or specific text spans within the final report.
Furthermore, we develop Simple Deepresearch, an end-to-end agent scaffold. This
scaffold serves as a baseline that facilitates the easy integration of various
large language models to transform them into deep research agents for
evaluation. To demonstrate the platform's utility for deep research agent
development, we have collected real user preference data from 17 annotators on
three deep research agents. A demo video of our platform can be found at
https://www.youtube.com/watch?v=g4d2dnbdseg.

</details>


### [7] [Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality](https://arxiv.org/abs/2507.05515)
*Haochen Huang,Jiahuan Pei,Mohammad Aliannejadi,Xin Sun,Moonisa Ahsan,Pablo Cesar,Chuang Yu,Zhaochun Ren,Junxiao Wang*

Main category: cs.AI

TL;DR: 论文首次提出适用于AR培训的视觉-语言任务数据集，实验证明现有主流模型在细粒度任务上表现不佳，大力呼吁改进数据与方法，尤其关注弱势群体受益。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型(VLMs)在多模态环境下的解释与推理能力已较为成熟，但其在增强现实(AR)培训中的应用几乎未被探索。

Method: 本工作构建了一个专门针对AR培训的系统化视觉-语言任务数据集，并用它对九个最新的VLMs进行评测。

Result: 最新的VLMs，包括GPT-4o，在精细装配任务上的表现依然有限，状态检测的F1最高仅为40.54%。

Conclusion: VLMs在AR培训中应对细粒度视觉-语言对齐还有很长的路要走，亟需更丰富的数据集和基准，相关研究亟待加强。

Abstract: Vision-language models (VLMs) are essential for enabling AI-powered smart
assistants to interpret and reason in multimodal environments. However, their
application in augmented reality (AR) training remains largely unexplored. In
this work, we introduce a comprehensive dataset tailored for AR training,
featuring systematized vision-language tasks, and evaluate nine
state-of-the-art VLMs on it. Our results reveal that even advanced models,
including GPT-4o, struggle with fine-grained assembly tasks, achieving a
maximum F1 score of just 40.54% on state detection. These findings highlight
the demand for enhanced datasets, benchmarks, and further research to improve
fine-grained vision-language alignment. Beyond technical contributions, our
work has broader social implications, particularly in empowering blind and
visually impaired users with equitable access to AI-driven learning
opportunities. We provide all related resources, including the dataset, source
code, and evaluation results, to support the research community.

</details>


### [8] [Modeling (Deontic) Modal Operators With the s(CASP) Goal-directed Predicated Answer Set Programming System](https://arxiv.org/abs/2507.05519)
*Gopal Gupta,Abhiramon Rajasekharan,Alexis R. Tudor,Elmer Salazar,Joaquín Arias*

Main category: cs.AI

TL;DR: 本文使用ASP的默认否定和全局约束来优雅表达和实现规范模态逻辑算子，从而有效解决了传统方法下产生的规范悖论问题。


<details>
  <summary>Details</summary>
Motivation: 规范模态逻辑广泛应用于道德、法律、人工智能等领域，但经典表达常常产生悖论，因此需要新的实现方法以更好地表达规范性命题。

Method: 将（规范）模态算子以默认否定（即“作为失败的否定”）和强否定结合在ASP中实现，利用ASP的全局约束刻画义务与禁止。

Result: 证明了ASP中利用默认否定和强否定可以优雅地表达规范模态算子，并用全局约束实现义务和禁止，解决了许多规范模态逻辑中的著名悖论。

Conclusion: 通过将义务和禁止等规范性命题用ASP的全局约束进行表示，许多规范模态逻辑的悖论能够得到优雅的解决。

Abstract: We consider the problem of implementing deontic modal logic. We show how
(deontic) modal operators can be expressed elegantly using default negation
(negation-as-failure) and strong negation present in answer set programming
(ASP). We propose using global constraints of ASP to represent obligations and
impermissibilities of deontic modal logic. We show that our proposed
representation results in the various paradoxes of deontic modal logic being
elegantly resolved.

</details>


### [9] [Cultivating Multimodal Intelligence: Interpretive Reasoning and Agentic RAG Approaches to Dermatological Diagnosis](https://arxiv.org/abs/2507.05520)
*Karishma Thakrar,Shreyas Basavatia,Akshay Daftardar*

Main category: cs.AI

TL;DR: 本研究提出结合多模态大模型微调、结构化推理和知识增强机制的皮肤科多模态问答系统，在国际挑战赛中取得佳绩，并为远程医学自动化诊断提供可行路径。


<details>
  <summary>Details</summary>
Motivation: 该研究关注皮肤病远程诊断中的难题：在真实世界中，医生需要基于有限的图片和症状描述作出高准确性、可解释性的诊断决策。本项目希望提高自动化皮肤病诊断系统在这种应用场景下的表现。

Method: 方法上，团队对开源多模态大模型（Qwen、Gemma、LLaMA系列）进行微调，结合比赛数据集。创新地引入结构化推理层，用于裁决和整合候选模型结果。同时，通过Agentic RAG机制，从权威数据库动态补充相关症状/疾病信息，增强患者上下文信息，提升模型理解能力。整合以上三者，形成闭集视觉问答（CVQA）系统。

Result: 团队的方案在ImageCLEF MEDIQA-MAGIC 2025挑战赛中表现突出，取得第二名（提交排名第六），展示了系统的高准确率和竞争力。实验验证了系统的实际诊断支持能力。

Conclusion: 该架构通过模拟皮肤科医生系统化推理流程，为皮肤病远程诊断中的自动化辅助提供了更可靠、可解释的解决方案，对实际应用有重要推动意义。

Abstract: The second edition of the 2025 ImageCLEF MEDIQA-MAGIC challenge, co-organized
by researchers from Microsoft, Stanford University, and the Hospital Clinic of
Barcelona, focuses on multimodal dermatology question answering and
segmentation, using real-world patient queries and images. This work addresses
the Closed Visual Question Answering (CVQA) task, where the goal is to select
the correct answer to multiple-choice clinical questions based on both
user-submitted images and accompanying symptom descriptions. The proposed
approach combines three core components: (1) fine-tuning open-source multimodal
models from the Qwen, Gemma, and LLaMA families on the competition dataset, (2)
introducing a structured reasoning layer that reconciles and adjudicates
between candidate model outputs, and (3) incorporating agentic
retrieval-augmented generation (agentic RAG), which adds relevant information
from the American Academy of Dermatology's symptom and condition database to
fill in gaps in patient context. The team achieved second place with a
submission that scored sixth, demonstrating competitive performance and high
accuracy. Beyond competitive benchmarks, this research addresses a practical
challenge in telemedicine: diagnostic decisions must often be made
asynchronously, with limited input and with high accuracy and interpretability.
By emulating the systematic reasoning patterns employed by dermatologists when
evaluating skin conditions, this architecture provided a pathway toward more
reliable automated diagnostic support systems.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [10] [TokenShapley: Token Level Context Attribution with Shapley Value](https://arxiv.org/abs/2507.05261)
*Yingtai Xiao,Yuqing Zhu,Sirat Samyoun,Wanrong Zhang,Jiachen T. Wang,Jian Du*

Main category: cs.CL

TL;DR: 该论文提出了TokenShapley，一种结合Shapley值与KNN检索的token级别溯源方法，在四项基准测试上显著优于现有方法，有助于提升大模型输出准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在理解上下文和生成内容方面表现优异，但其输出结果的正确性验证存在困难，尤其是在用户需要对具体关键词（如数字、年份或姓名）进行溯源时，现有的句子级归因方法难以满足精细化需求。

Method: 提出TokenShapley方法，将基于Shapley值的数据归因与KNN检索技术结合，通过使用预先计算的数据存储进行上下文检索，并计算Shapley值以量化每个token的重要性，实现细粒度的数据归因。

Result: 在四个基准测试上，TokenShapley在token级别归因准确率方面比最先进方法有所提升，准确率提高了11-23%。

Conclusion: TokenShapley能够更精细准确地为LLM输出结果中的关键词提供出处归因，为提高大模型输出的可解释性和可信度提供了有效工具。

Abstract: Large language models (LLMs) demonstrate strong capabilities in in-context
learning, but verifying the correctness of their generated responses remains a
challenge. Prior work has explored attribution at the sentence level, but these
methods fall short when users seek attribution for specific keywords within the
response, such as numbers, years, or names. To address this limitation, we
propose TokenShapley, a novel token-level attribution method that combines
Shapley value-based data attribution with KNN-based retrieval techniques
inspired by recent advances in KNN-augmented LLMs. By leveraging a precomputed
datastore for contextual retrieval and computing Shapley values to quantify
token importance, TokenShapley provides a fine-grained data attribution
approach. Extensive evaluations on four benchmarks show that TokenShapley
outperforms state-of-the-art baselines in token-level attribution, achieving an
11-23% improvement in accuracy.

</details>


### [11] [User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs](https://arxiv.org/abs/2507.05266)
*Sougata Saha,Monojit Choudhury*

Main category: cs.CL

TL;DR: 本文提出用用户行为预测任务衡量LLM泛化能力，并通过实验验证了其有效性。GPT-4o表现最优，Llama仍有很大提升空间，该方法是未来泛化能力评估的有力补充。


<details>
  <summary>Details</summary>
Motivation: 目前LLM泛化能力的度量面临数据污染问题，且随着模型规模增大和算力成本降低，确保评测任务在训练阶段完全“看不见”变得几乎不可能。因此，寻找一种新的、更健全的泛化能力评估方式十分必要。

Method: 作者提出用“用户行为预测”任务，来代替传统的知识检索和推理任务，用于评估LLM的泛化能力。他们设计了一个全新评测框架，并在电影和音乐推荐的数据集上对GPT-4o、GPT-4o-mini及Llama-3.1-8B-Instruct模型进行了测试。

Result: 实验结果显示，GPT-4o在用户行为预测任务上的表现优于GPT-4o-mini和Llama-3.1-8B-Instruct。其中，Llama系列模型表现提升空间较大。

Conclusion: 用户行为预测任务可作为泛化能力评估的新方法，具备理论合理性、可扩展性与鲁棒性，并有效揭示主流LLM之间的性能差异。该方法为评测LLM泛化能力提供新的方向。

Abstract: Measuring the generalization ability of Large Language Models (LLMs) is
challenging due to data contamination. As models grow and computation becomes
cheaper, ensuring tasks and test cases are unseen during training phases will
become nearly impossible. We argue that knowledge-retrieval and reasoning tasks
are not ideal for measuring generalization, as LLMs are not trained for
specific tasks. Instead, we propose user behavior prediction, also a key aspect
of personalization, as a theoretically sound, scalable, and robust alternative.
We introduce a novel framework for this approach and test it on movie and music
recommendation datasets for GPT-4o, GPT-4o-mini, and Llama-3.1-8B-Instruct.
Results align with our framework's predictions, showing GPT-4o outperforms
GPT-4o-mini and Llama, though all models have much room for improvement,
especially Llama.

</details>


### [12] [An Adaptive Supervised Contrastive Learning Framework for Implicit Sexism Detection in Digital Social Networks](https://arxiv.org/abs/2507.05271)
*Mohammad Zia Ur Rehman,Aditya Shah,Nagendra Kumar*

Main category: cs.CL

TL;DR: 本文提出了结合自适应阈值对比学习与多特征增强的 ASCEND 框架，在隐性性别歧视检测上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 社交媒体的全球普及加剧了仇恨内容的传播，尤其是隐性性别歧视，这类内容常常被传统检测方法忽略。

Method: 提出了一种自适应有监督对比学习框架 ASCEND，通过计算文本嵌入的余弦相似度，并设定可学习的阈值，仅将高于该阈值的样本对作为正例，实现精细的表示学习。同时结合对比损失和交叉熵损失，并引入词级注意力机制、情感、情绪和毒性特征增强文本表示。

Result: 在 EXIST2021 和 MLSC 数据集上，ASCEND 显著优于现有方法，在多个任务上 Macro F1 分别提高了 9.86%、29.63%、32.51%。

Conclusion: ASCEND 框架能有效捕捉隐藏性别歧视语言的细微特征，大幅提升了隐性性别歧视内容的检测能力。

Abstract: The global reach of social media has amplified the spread of hateful content,
including implicit sexism, which is often overlooked by conventional detection
methods. In this work, we introduce an Adaptive Supervised Contrastive lEarning
framework for implicit sexism detectioN (ASCEND). A key innovation of our
method is the incorporation of threshold-based contrastive learning: by
computing cosine similarities between embeddings, we selectively treat only
those sample pairs as positive if their similarity exceeds a learnable
threshold. This mechanism refines the embedding space by robustly pulling
together representations of semantically similar texts while pushing apart
dissimilar ones, thus reducing false positives and negatives. The final
classification is achieved by jointly optimizing a contrastive loss with a
cross-entropy loss. Textual features are enhanced through a word-level
attention module. Additionally, we employ sentiment, emotion, and toxicity
features. Evaluations on the EXIST2021 and MLSC datasets demonstrate that
ASCEND significantly outperforms existing methods, with average Macro F1
improvements of 9.86%, 29.63%, and 32.51% across multiple tasks, highlighting
its efficacy in capturing the subtle cues of implicit sexist language.

</details>


### [13] [Beyond classical and contemporary models: a transformative ai framework for student dropout prediction in distance learning using rag, prompt engineering, and cross-modal fusion](https://arxiv.org/abs/2507.05285)
*Miloud Mihoubi,Meriem Zerkouk,Belkacem Chikhaoui*

Main category: cs.CL

TL;DR: 本文创新性地结合了知识增强情感分析、Prompt工程和多模态融合，极大提升了远程学习中学生辍学预测的准确性，并能自动推荐个性化干预策略。


<details>
  <summary>Details</summary>
Motivation: 远程学习中的学生辍学率居高不下，对社会和经济带来巨大影响。传统的机器学习方法虽然利用了结构化数据，但难以捕捉学生互动中情感和情境等非结构化因素。研究动机在于提升对学生辍学的预测准确性和实用性，进而推动早期干预。

Method: 提出了一种结合三项创新的人工智能框架：（1）基于RAG技术的领域特定情感分析，借助知识库提升评论解释能力；（2）通过优化Prompt Engineering识别学业压力相关特征词；（3）跨模态注意力融合层，实现文本、行为和社会经济多源数据的对齐和融合。模型主要基于BERT进行情感分析，采用长时间序列数据进行验证。

Result: 在4,423名学生的长期数据集上，框架取得了89%的准确率和0.88的F1分数，优于传统模型7%，将假阴性降低了21%。还能基于分析结果自动推荐个性化干预措施（如对孤立学生匹配导师项目）。

Conclusion: 本文提出的多模态AI框架，在远程教育辍学预测上取得了显著效果，可扩展应用于全球教育系统，并能为教育干预措施提供可解释性支持。

Abstract: Student dropout in distance learning remains a critical challenge, with
profound societal and economic consequences. While classical machine learning
models leverage structured socio-demographic and behavioral data, they often
fail to capture the nuanced emotional and contextual factors embedded in
unstructured student interactions. This paper introduces a transformative AI
framework that redefines dropout prediction through three synergistic
innovations: Retrieval-Augmented Generation (RAG) for domain-specific sentiment
analysis, prompt engineering to decode academic stressors, and cross-modal
attention fusion to dynamically align textual, behavioral, and
socio-demographic insights. By grounding sentiment analysis in a curated
knowledge base of pedagogical content, our RAG-enhanced BERT model interprets
student comments with unprecedented contextual relevance, while optimized
prompts isolate indicators of academic distress (e.g., "isolation," "workload
anxiety"). A cross-modal attention layer then fuses these insights with
temporal engagement patterns, creating holistic risk profiles. Evaluated on a
longitudinal dataset of 4 423 students, the framework achieves 89% accuracy and
an F1-score of 0.88, outperforming conventional models by 7% and reducing false
negatives by 21%. Beyond prediction, the system generates interpretable
interventions by retrieving contextually aligned strategies (e.g., mentorship
programs for isolated learners). This work bridges the gap between predictive
analytics and actionable pedagogy, offering a scalable solution to mitigate
dropout risks in global education systems

</details>


### [14] [LCDS: A Logic-Controlled Discharge Summary Generation System Supporting Source Attribution and Expert Review](https://arxiv.org/abs/2507.05319)
*Cheng Yuan,Xinkai Rui,Yongqi Fan,Yawei Fan,Boyang Zhong,Jiacheng Wang,Weiyan Zhang,Tong Ruan*

Main category: cs.CL

TL;DR: 提出了LCDS系统，通过文本相似性映射和逻辑规则约束，提升了LLM生成出院小结的准确性和可溯性，并为后续模型优化提供支持。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在自动生成出院小结时虽然表现卓越，但仍存在幻觉问题，如生成不准确内容或捏造信息。此外，电子病历（EMRs）通常为长文本数据，导致LLMs难以将生成内容归因于原始数据。

Method: 提出了LCDS（Logic-Controlled Discharge Summary）系统。LCDS通过计算EMR与出院小结间的文本相似性建立源映射表，限制总结内容的来源范围，并结合一套逻辑规则生成更可靠的银质出院小结。此外，LCDS支持生成内容的溯源，便于专家审核和修正。最终通过人工修正产生金质出院小结并用于LLM增量微调。

Result: 系统提高了出院小结的真实性和可验性，为专家高效审核及模型迭代优化提供支持。最终成果可增强LLM在医疗总结生成的实际应用价值。

Conclusion: 通过源映射和逻辑控制，LCDS有效缓解了LLM生成医疗出院小结时的幻觉问题，提升了内容的可信度和追溯性。该系统能够促进医疗NLP模型的持续优化。

Abstract: Despite the remarkable performance of Large Language Models (LLMs) in
automated discharge summary generation, they still suffer from hallucination
issues, such as generating inaccurate content or fabricating information
without valid sources. In addition, electronic medical records (EMRs) typically
consist of long-form data, making it challenging for LLMs to attribute the
generated content to the sources. To address these challenges, we propose LCDS,
a Logic-Controlled Discharge Summary generation system. LCDS constructs a
source mapping table by calculating textual similarity between EMRs and
discharge summaries to constrain the scope of summarized content. Moreover,
LCDS incorporates a comprehensive set of logical rules, enabling it to generate
more reliable silver discharge summaries tailored to different clinical fields.
Furthermore, LCDS supports source attribution for generated content, allowing
experts to efficiently review, provide feedback, and rectify errors. The
resulting golden discharge summaries are subsequently recorded for incremental
fine-tuning of LLMs. Our project and demo video are in the GitHub repository
https://github.com/ycycyc02/LCDS.

</details>


### [15] [MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents](https://arxiv.org/abs/2507.05330)
*Ming Gong,Xucheng Huang,Chenghan Yang,Xianhan Peng,Haoxin Wang,Yang Liu,Ling Jiang*

Main category: cs.CL

TL;DR: MindFlow是专为电商打造的开源多模态大模型智能体，通过模块化设计大幅提升了复杂场景下的客服表现，实现了近94%的现实性能提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在电商客服领域有新应用，但在复杂、多模态场景下能力受限。本文旨在突破此瓶颈。

Method: 提出MindFlow，是首个专为电商设计的开源多模态LLM智能体，基于CoALA框架，整合记忆、决策和行动等模块，采用模块化“MLLM-as-Tool”策略实现有效的视觉-文本推理。

Result: 通过在线A/B测试和仿真消融实验评估，MindFlow在真实部署中处理复杂查询、提升用户满意度、降低运营成本方面表现优异，相对提升达93.53%。

Conclusion: MindFlow显著提升了复杂、多模态电商场景中智能体的处理能力，为相关领域提供了高效、可扩展的解决方案。

Abstract: Recent advances in large language models (LLMs) have enabled new applications
in e-commerce customer service. However, their capabilities remain constrained
in complex, multimodal scenarios. We present MindFlow, the first open-source
multimodal LLM agent tailored for e-commerce. Built on the CoALA framework, it
integrates memory, decision-making, and action modules, and adopts a modular
"MLLM-as-Tool" strategy for effect visual-textual reasoning. Evaluated via
online A/B testing and simulation-based ablation, MindFlow demonstrates
substantial gains in handling complex queries, improving user satisfaction, and
reducing operational costs, with a 93.53% relative improvement observed in
real-world deployments.

</details>


### [16] [LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks](https://arxiv.org/abs/2507.05346)
*William Fleshman,Benjamin Van Durme*

Main category: cs.CL

TL;DR: LAG通过动态调用LoRA专家模型，无需额外训练和数据，有效提升了多任务知识推理能力，并且适用于多种现实场景。


<details>
  <summary>Details</summary>
Motivation: 随着专用任务和领域的微调语言模型专家的大量出现，如何高效选择和组合这些专家成为一个亟需解决的问题。

Method: 提出了一种新的方法LoRA-Augmented Generation (LAG)，能够利用包含丰富知识和任务定制LoRA适配器的大型模型库。LAG无需额外训练和数据，能够在每个token和层级上高效筛选、检索和应用专家模型。

Result: 在多种知识密集型任务上，LAG相比现有无数据的方法表现更优。同时探讨了在存在额外数据时，LAG可以与RAG等其他方案兼容。

Conclusion: LAG是一种高效、兼容的数据无关专家选择与组合方法，能够提升知识任务表现，并易于与数据增强方案结合。

Abstract: The proliferation of fine-tuned language model experts for specific tasks and
domains signals the need for efficient selection and combination methods. We
propose LoRA-Augmented Generation (LAG) for leveraging large libraries of
knowledge and task-specific LoRA adapters. LAG requires no additional training
or access to data, and efficiently filters, retrieves, and applies experts on a
per-token and layer basis. We evaluate LAG on various knowledge-intensive
tasks, achieving superior performance over existing data-free methods. We
explore scenarios where additional data is available, demonstrating LAG's
compatibility with alternative solutions such as retrieval-augmented generation
(RAG).

</details>


### [17] [On the Bias of Next-Token Predictors Toward Systematically Inefficient Reasoning: A Shortest-Path Case Study](https://arxiv.org/abs/2507.05362)
*Riccardo Alberghi,Elizaveta Demyanenko,Luca Biggio,Luca Saglietti*

Main category: cs.CL

TL;DR: 作者通过最短路径任务发现：训练时以较长但结构化的推理轨迹（包括回溯）喂给大模型，能显著提升其泛化能力，而简单延长推理轨迹无益。提升泛化依赖推理的连贯性与递进性。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现：增加推理阶段的计算量有助于提升LLM解决复杂问题的能力，结构化并递进的推理轨迹表现更好，但尚不清楚如何最大化这两者的协同效果。作者提出通过受控实验分析冗余推理、系统性推理和泛化性能间的关系。

Method: 作者以分层图的最短路径任务为研究场景，使用自定义分词器和decoder-only transformer，对比两类训练数据：一种是最优且自底向上的动态规划推理轨迹，另一种是包括回溯的但仍有效的较长推理轨迹。通过相同训练token预算下，对比模型在未见图的泛化表现。

Result: 使用包含回溯、冗余但逻辑自洽的长推理轨迹训练的模型，比用最优推理轨迹训练的模型，其泛化能力更强（在新图上表现更好）。单纯增加推理轨迹长度、引入随机冗余并不提升性能，部分情况下还会导致效果下降。模型泛化能力与下一个token的置信度相关，高置信度伴随连贯逐步的推理轨迹。

Conclusion: 长但低效的推理过程（如包含回溯的推理轨迹）能够提升大语言模型在类似任务上的泛化能力，其效果超过仅仅增加推理长度。提升泛化主要与推理轨迹的结构和连贯性有关。

Abstract: Recent advances in natural language processing highlight two key factors for
improving reasoning in large language models (LLMs): (i) allocating more
test-time compute tends to help on harder problems but often introduces
redundancy in the reasoning trace, and (ii) compute is most effective when
reasoning is systematic and incremental, forming structured chains of thought
(CoTs) akin to human problem-solving. To study these factors in isolation, we
introduce a controlled setting based on shortest-path tasks in layered graphs.
We train decoder-only transformers on question-trace-answer triples using a
custom tokenizer, comparing models trained on optimal bottom-up dynamic
programming traces with those trained on longer, valid traces involving
backtracking. Surprisingly, with the same training-token budget, models trained
on inefficient traces generalize better to unseen graphs. This benefit is not
due to length alone-injecting arbitrary redundancy into reasoning traces fails
to help and can even hurt performance. Instead, we find that generalization
correlates with the model's confidence in next-token prediction, suggesting
that long, coherent, and locally incremental traces make the training signal
easier to optimize.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [18] [MolFORM: Multi-modal Flow Matching for Structure-Based Drug Design](https://arxiv.org/abs/2507.05503)
*Jie Huang,Daiheng Zhang*

Main category: cs.CE

TL;DR: 本文提出了一种全新分子生成模型MolFORM，通过“多流匹配+偏好引导优化”策略，实现了分子类型与三维空间联合高效建模，在结构药物设计任务中比主流方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 结构基础药物设计（SBDD）通过利用蛋白质靶标的三维结构信息，生成与之有效结合的分子。然而，目前主流方法以扩散生成模型为主，非自回归模型的方法仍然较少被研究。

Method: 本文提出了一种新的生成框架MolFORM，通过多流匹配同时建模分子的离散（原子类型）和连续（三维坐标）模态。此外，提出了基于直接偏好优化（DPO）的偏好引导微调方法，并以Vina评分作为奖励信号。提出的多模态流DPO协同建模策略可以同时对齐离散和连续模态。

Result: 该方法在多个评估指标上均取得了一致的性能提升，生成分子的质量有了显著改进。

Conclusion: MolFORM能够有效提升分子生成质量，实现了离散和连续模态的协同优化，为结构基础药物设计提供了一种新的高效方法。

Abstract: Structure-based drug design (SBDD) seeks to generate molecules that bind
effectively to protein targets by leveraging their 3D structural information.
While diffusion-based generative models have become the predominant approach
for SBDD, alternative non-autoregressive frameworks remain relatively
underexplored. In this work, we introduce MolFORM, a novel generative framework
that jointly models discrete (atom types) and continuous (3D coordinates)
molecular modalities using multi-flow matching. To further enhance generation
quality, we incorporate a preference-guided fine-tuning stage based on
\textit{Direct Preference Optimization} (DPO), using Vina score as a reward
signal. We propose a multi-modal flow DPO co-modeling strategy that
simultaneously aligns discrete and continuous modalities, leading to consistent
improvements across multiple evaluation metrics.

</details>


### [19] [MCNP-GO: A python package for assembling MCNP input files with a systems engineering approach](https://arxiv.org/abs/2507.05659)
*Alexandre Friou*

Main category: cs.CE

TL;DR: MCNP-GO是一个便捷高效的Python包，可自动化地组装与管理MCNP输入文件，支持追踪与操作历史，大幅提升模型构建效率，对非编程用户友好。


<details>
  <summary>Details</summary>
Motivation: MCNP输入文件的管理和组装在精确建模和设备定位中至关重要，但传统方法在处理大型文件库、保持可靠性和可追溯性等方面存在难题。本文旨在通过开发自动化工具提升效率和可追溯性。

Method: 开发了MCNP-GO，一个Python包，支持独立MCNP对象输入文件的自动组装，包括重编号、文件提取、变换、碰撞及材料管理，并记录所有操作流程，以实现易修改和可追溯。功能通过断层实验的MCNP输入组装范例进行演示。

Result: MCNP-GO实现了MCNP输入文件的高效组装、自动变换与管理，有效简化了流程，提高了大型MCNP数据库的管理效率与可靠性，用户只需极少的Python知识即可使用。

Conclusion: MCNP-GO为需要精确建模与定位的应用场合提供了实用高效的自动化MCNP输入文件管理工具，大幅提升了工作效率和文件管理的可追溯性，适用于非程序员用户。

Abstract: This article introduces MCNP-GO (https://github.com/afriou/mcnpgo), a Python
package designed to manipulate and assemble MCNP input files, allowing users to
assemble a set of independent objects, each described by a valid MCNP file,
into a single cohesive file. This tool is particularly useful for applications
where precise modeling and positioning of equipment are crucial. The package
addresses the challenges of managing large databases of MCNP input files,
ensuring reliability and traceability through configuration management systems.
MCNP-GO provides functionalities such as renumbering, extracting subsets of
files, transforming files, and assembling files while managing collisions and
materials. It also keeps track of the operations performed on files, enhancing
traceability and ease of modification. The article demonstrates the package's
capabilities through a practical example of assembling an MCNP input file for a
tomographic experiment, highlighting its efficiency and user-friendliness.
MCNP-GO is designed for users with minimal Python knowledge.

</details>


### [20] [Bridging Sequential Deep Operator Network and Video Diffusion: Residual Refinement of Spatio-Temporal PDE Solutions](https://arxiv.org/abs/2507.06133)
*Jaewan Park,Farid Ahmed,Kazuma Kobayashi,Seid Koric,Syed Bahauddin Alam,Iwona Jasiuk,Diab Abueidda*

Main category: cs.CE

TL;DR: 本文提出了一种结合物理先验的条件视频扩散残差学习新框架，在复杂多物理场时空建模任务上取得大幅精度和细节提升，且具有很强的通用性和高效性。


<details>
  <summary>Details</summary>
Motivation: 视频扩散模型在高感知保真度和稳定训练方面表现优异，但其在空间-时间连续介质物理建模上的潜力尚未被充分挖掘。现有直接建模全解的方式学习难度大，难以准确捕捉高频局部结构。该文希望通过结合物理先验和残差学习，提升模型在非线性动力学问题上的精度与泛化能力。

Method: 本文提出了两阶段混合物理替代建模框架。第一阶段由顺序深算子网络（S-DeepONet）根据边界或载荷条件快速预测物理一致性的粗略解作为先验。第二阶段，将先验输入到条件视频扩散模型中，仅学习残差——即预测与真实解的逐点差异，由此让扩散模型专注于高频细节重建，提高整体精度与视觉质量。方法在两类基准任务上验证：有涡腔流和材料的拉伸塑性变形。

Result: 与仅用单一模型相比，混合模型在两个任务上均大幅提升了预测精度。腔流问题的平均相对L2误差由4.57%降至0.83%，塑性问题由4.42%降至2.94%，相对提升分别为81.8%和33.5%。此外，该方法能更好保留高频局部细节，视觉效果显著改善，并且无需针对不同物理问题做模型结构调整，泛化能力强。

Conclusion: 将条件视频扩散模型耦合物理先验并进行残差学习，极大提升了非线性时间相关PDE问题的建模精度，同时提升了细节重建能力和方法的通用性。该架构表现出良好的跨物理场泛化能力和高效收敛特性。

Abstract: Video-diffusion models have recently set the standard in video generation,
inpainting, and domain translation thanks to their training stability and high
perceptual fidelity. Building on these strengths, we repurpose conditional
video diffusion as a physics surrogate for spatio-temporal fields governed by
partial differential equations (PDEs). Our two-stage surrogate first applies a
Sequential Deep Operator Network (S-DeepONet) to produce a coarse,
physics-consistent prior from the prescribed boundary or loading conditions.
The prior is then passed to a conditional video diffusion model that learns
only the residual: the point-wise difference between the ground truth and the
S-DeepONet prediction. By shifting the learning burden from the full solution
to its much smaller residual space, diffusion can focus on sharpening
high-frequency structures without sacrificing global coherence. The framework
is assessed on two disparate benchmarks: (i) vortex-dominated lid-driven cavity
flow and (ii) tensile plastic deformation of dogbone specimens. Across these
data sets the hybrid surrogate consistently outperforms its single-stage
counterpart, cutting the mean relative L2 error from 4.57% to 0.83% for the
flow problem and from 4.42% to 2.94% for plasticity, a relative improvements of
81.8% and 33.5% respectively. The hybrid approach not only lowers quantitative
errors but also improves visual quality, visibly recovering fine spatial
details. These results show that (i) conditioning diffusion on a physics-aware
prior enables faithful reconstruction of localized features, (ii) residual
learning reduces the problem, accelerating convergence and enhancing accuracy,
and (iii) the same architecture transfers seamlessly from incompressible flow
to nonlinear elasto-plasticity without problem-specific architectural
modifications, highlighting its broad applicability to nonlinear,
time-dependent continua.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [21] [A Fuzzy Supervisor Agent Design for Clinical Reasoning Assistance in a Multi-Agent Educational Clinical Scenario Simulation](https://arxiv.org/abs/2507.05275)
*Weibing Zheng,Laurah Turner,Jess Kropczynski,Murat Ozer,Seth Overla,Shane Halse*

Main category: cs.CY

TL;DR: 本文提出了一种基于模糊推理系统的智能监督代理FSA，可在医学教育模拟中实时辅助学生临床推理，具备可扩展性和灵活性，预计将显著提升教学效果，具体实现已开源，后续将验证其实用性。


<details>
  <summary>Details</summary>
Motivation: 在医学教育中，如何在临床场景训练中有效辅助医学生进行临床推理一直是一个难题。现有教学系统对于实时、个性化和场景相关的引导存在不足，难以满足大规模高效指导的需求。

Method: 本文提出并设计了一种新颖的模糊监督代理（FSA），集成于多代理教育临床场景仿真（MAECSS）平台中。FSA利用模糊推理系统（FIS），基于专业性、医学相关性、伦理行为和情境干扰等预定义模糊规则，实时解析学生与各类临床代理（如病人、体检、诊断、干预）的交互，分析其决策过程，从而提供自适应、情境感知的反馈和帮助。

Result: 目前工作侧重于FSA技术框架和设计原理的论述，突出其可能为模拟医学教育带来可扩展、灵活及类人化监督的潜力。具体实现细节已开源，后续将进行实证评估和更广泛的集成应用。

Conclusion: FSA系统有望为医学教育中的临床场景模拟提供智能化、及时和个性化的辅助，有助于提升学生的临床推理能力和场景适应力。然而实际效果还有待后续的实证验证和推广。

Abstract: Assisting medical students with clinical reasoning (CR) during clinical
scenario training remains a persistent challenge in medical education. This
paper presents the design and architecture of the Fuzzy Supervisor Agent (FSA),
a novel component for the Multi-Agent Educational Clinical Scenario Simulation
(MAECSS) platform. The FSA leverages a Fuzzy Inference System (FIS) to
continuously interpret student interactions with specialized clinical agents
(e.g., patient, physical exam, diagnostic, intervention) using pre-defined
fuzzy rule bases for professionalism, medical relevance, ethical behavior, and
contextual distraction. By analyzing student decision-making processes in
real-time, the FSA is designed to deliver adaptive, context-aware feedback and
provides assistance precisely when students encounter difficulties. This work
focuses on the technical framework and rationale of the FSA, highlighting its
potential to provide scalable, flexible, and human-like supervision in
simulation-based medical education. Future work will include empirical
evaluation and integration into broader educational settings. More detailed
design and implementation is~\href{https://github.com/2sigmaEdTech/MAS/}{open
sourced here}.

</details>


### [22] [Hungary and AI: efforts and opportunities in comparison with Singapore](https://arxiv.org/abs/2507.05280)
*András Ferenczy*

Main category: cs.CY

TL;DR: 本文系统评估了匈牙利国家AI战略的目标落实与资金分配，揭示了其在数据公开、执行协同和定期评估方面存在的问题，并借鉴新加坡经验提出了改进建议，尤其是应对AI技术变革、优化多方合作、提升国际定位等方面。


<details>
  <summary>Details</summary>
Motivation: 分析和评估匈牙利国家AI战略的制定及执行情况，弥补当前对其战略实施细节和成效的研究空白，并借鉴新加坡AI战略对匈牙利提出改进建议。

Method: 通过分析战略文件、公开财务记录，以及对匈牙利AI联盟主席和政府AI专员首席战略顾问的专家访谈，对匈牙利战略目标从概念、治理、时间和财务四个维度进行评估，并与新加坡AI战略进行对标。

Result: 匈牙利AI相关公共投资总额约为46.5亿欧元，仅半数目标可找到公开财务数据，三大项目占据已记录资金的98%。执行上存在碎片化、机构调整影响和缺乏定期评估等问题。

Conclusion: 匈牙利国家AI战略在执行和监测上存在重大不足，应借鉴新加坡经验，针对大语言模型加强策略更新，优化政产学三螺旋合作框架，打造汽车领域AI试验东西方桥梁地位，并制定更完善的目标追踪和信息披露机制。

Abstract: The study assesses Hungary's National AI Strategy and its implementation
through the analysis of strategic documents, publicly available financial
records, and expert interviews with the Hungarian AI Coalition President and
Chief Strategic Advisor to the Government Commissioner for AI. 22 goals from
Hungary's strategy were evaluated through conceptual, governance, temporal, and
financial dimensions before being benchmarked against Singapore's National AI
Strategies (NAIS 1.0 and NAIS 2.0). Key findings include an estimated total of
EUR 4.65 billion in AI-related public investment in Hungary. Openly available
financial data was found for only half of the evaluated goals, and just three
projects made up 98\% of all documented funding. The research also reveals
Hungary's implementation challenges, including fragmented execution following
ministerial reorganizations and the absence of designated biennial reviews
since 2020. Furthermore, the paper provides targeted recommendations for
Hungary's forthcoming AI strategy, drawing on Singapore's framework as a
reference point. These include adapting to the era of large language models,
restructuring the existing triple helix network to foster more effective
dialogue and advocacy, and positioning the country as an East-West bridge for
automotive AI experimentation.

</details>


### [23] [A LLM-Driven Multi-Agent Systems for Professional Development of Mathematics Teachers](https://arxiv.org/abs/2507.05292)
*Kaiqi Yang,Hang Li,Yucheng Chu,Ahreum Han,Yasemin Copur-Gencturk,Jiliang Tang,Hui Liu*

Main category: cs.CY

TL;DR: 本文提出了一个基于大语言模型和多智能体架构的教师专业发展智能平台I-VIP，提升了教师PD的公平性、互动性和实时反馈能力。


<details>
  <summary>Details</summary>
Motivation: 教师专业发展（PD）对于掌握学科知识至关重要，但当前在为教师提供公平且及时的PD机会时面临诸多挑战，如资源有限、时间分配难、难以及时满足个性化需求。

Method: 作者提出了I-VIP（智能虚拟交互式平台），这是一个基于大语言模型（LLMs）和多智能体框架驱动的教师专业发展智能辅导平台。平台通过用户友好的对话界面和多种交互工具，实现了互动式答疑、知识理解和反思总结等功能。多智能体框架支持知识预期分析、答复打分与分类、反馈生成等核心模块，从而提升平台判断的准确性，并降低遗漏关键点的风险。

Result: I-VIP平台能够有效赋能教师实现更公平、及时和高效的专业发展，并通过多智能体模块提升互动质量和知识覆盖度，优化反馈质量。

Conclusion: I-VIP平台利用大语言模型和多智能体架构，为教师专业发展提供了创新的技术支持，有效缓解了传统PD机会分配不均、互动单一等问题。

Abstract: Professional development (PD) serves as the cornerstone for teacher tutors to
grasp content knowledge. However, providing equitable and timely PD
opportunities for teachers poses significant challenges. To address this issue,
we introduce I-VIP (Intelligent Virtual Interactive Program), an intelligent
tutoring platform for teacher professional development, driven by large
language models (LLMs) and supported by multi-agent frameworks. This platform
offers a user-friendly conversational interface and allows users to employ a
variety of interactive tools to facilitate question answering, knowledge
comprehension, and reflective summarization while engaging in dialogue. To
underpin the functionality of this platform, including knowledge expectation
analysis, response scoring and classification, and feedback generation, the
multi-agent frameworks are leveraged to enhance the accuracy of judgments and
mitigate the issue of missing key points.

</details>


### [24] [Integrating Generative AI in BIM Education: Insights from Classroom Implementation](https://arxiv.org/abs/2507.05296)
*Islem Sahraoui,Kinam Kim,Lu Gao,Zia Din,Ahmed Senouci*

Main category: cs.CY

TL;DR: 本研究在美国高校BIM课程引入生成式AI规则检查实践，发现其有助于达成学习目标，但调试难、工具不稳及经验不足导致学生压力增大。总体上，学生积极看待将来在教学中继续应用此技术，尤其是在有清晰指导的前提下。


<details>
  <summary>Details</summary>
Motivation: 目前关于在BIM课程中应用生成式AI进行合规检查的研究很有限，因此本研究希望评估这种新技术的教学有效性、学生体验及存在的问题，为后续教育应用提供参考。

Method: 采用课堂教学、实际操作作业、调查问卷（包含NASA-TLX量表）和访谈方式，结合回归分析评估学生的工作负荷、学习成效及整体体验。

Result: 学生在学习目标实现上总体表现良好，但因缺乏提示工程经验，调试AI生成代码和工具稳定性上遇到困难，这增加了他们的认知与情感负担。无编程基础的学生尤为明显。尽管如此，学生普遍对未来有教学支持的GenAI应用持积极态度。

Conclusion: 研究发现，尽管学生在使用生成式人工智能进行建筑信息建模（BIM）规则检查时面临如调试困难和工具表现不稳定等挑战，但大多数学生能够实现学习目标，并对未来使用该类技术表现出较强兴趣，前提是有明确的教学支持。

Abstract: This study evaluates the implementation of a Generative AI-powered rule
checking workflow within a graduate-level Building Information Modeling (BIM)
course at a U.S. university. Over two semesters, 55 students participated in a
classroom-based pilot exploring the use of GenAI for BIM compliance tasks, an
area with limited prior research. The instructional design included lectures on
prompt engineering and AI-driven rule checking, followed by an assignment where
students used a large language model (LLM) to identify code violations in
designs using Autodesk Revit. Surveys and interviews were conducted to assess
student workload, learning effectiveness, and overall experience, using the
NASA-TLX scale and regression analysis. Findings indicate students generally
achieved learning objectives but faced challenges such as difficulties
debugging AI-generated code and inconsistent tool performance, probably due to
their limited prompt engineering experience. These issues increased cognitive
and emotional strain, especially among students with minimal programming
backgrounds. Despite these challenges, students expressed strong interest in
future GenAI applications, particularly with clear instructional support.

</details>


### [25] [Narrowing the Gap: Supervised Fine-Tuning of Open-Source LLMs as a Viable Alternative to Proprietary Models for Pedagogical Tools](https://arxiv.org/abs/2507.05305)
*Lorenzo Lee Solano,Charles Koutcheme,Juho Leinonen,Alexandra Vassar,Jake Renzella*

Main category: cs.CY

TL;DR: 本研究用包含4万条学生编译错误的新数据集微调三种小型开源大模型，评测显示：微调大幅提升小模型讲解能力，达到与大型模型相当的教学辅助效果，且成本低、易推广，适合教育场景，提供了一种可复现方法。


<details>
  <summary>Details</summary>
Motivation: 大型LLM（如ChatGPT、Gemini）虽能帮助新手编程学习者理解编译报错，但因计算资源需求大及过度辅助问题，不适合大规模教育推广。故需探索高效、专用的小模型在教育领域的可行性。

Method: 作者构建了一个涵盖4万条真实学生编译器错误解释的数据集，对三种开源小模型进行了有监督微调（SFT）。评估方法包含专家人工评审和大规模自动化LLM打分，双重定量与定性评估模型表现。

Result: 微调后的小型模型在解释编译错误时，教育辅助质量显著提升，表现与大型模型接近。研究还分析了模型规模与表现的权衡，推荐通过高质量域专数据微调小模型，用以构建易推广的教育AI工具。

Conclusion: 通过SFT微调的小型开源语言模型（如Qwen3-4B、Llama-3.1-8B、Qwen3-32B），在编译器错误解释方面能达到与大型模型相当的教育辅助效果，且更具成本和资源效率，为教育场景下生成式AI的采用提供了可扩展且高效的解决方案。

Abstract: Frontier Large language models (LLMs) like ChatGPT and Gemini can decipher
cryptic compiler errors for novice programmers, but their computational scale,
cost, and tendency to over-assist make them problematic for widespread
pedagogical adoption. This work demonstrates that smaller, specialised language
models, enhanced via Supervised Fine-Tuning (SFT), present a more viable
alternative for educational tools. We utilise a new dataset of 40,000 C
compiler error explanations, derived from real introductory programming (CS1/2)
student-generated programming errors, which we used to fine-tune three
open-source models: Qwen3-4B, Llama-3.1-8B, and Qwen3-32B. We performed a dual
evaluation, combining expert human reviews with a large-scale automated
analysis of 8,000 responses using a validated LLM-as-judge ensemble. Our
results show that SFT significantly boosts the pedagogical quality of smaller
models, achieving performance comparable to much larger models. We analyse the
trade-offs between model size and quality, confirming that fine-tuning compact,
efficient models on high-quality, domain-specific data is a potent strategy for
creating specialised models to drive educational tools. We provide a replicable
methodology to foster broader access to generative AI capabilities in
educational contexts.

</details>


### [26] [Teaching Sustainable Creative Technologies](https://arxiv.org/abs/2507.05320)
*Chelsea Thompto*

Main category: cs.CY

TL;DR: 本文分析了新媒体艺术家在推动科技应用时面临的可持续性挑战，提出三种低碳艺术创作及其课程推广方法，旨在兼顾技术节能与艺术创新，助力艺术科技教育向环保方向发展。


<details>
  <summary>Details</summary>
Motivation: 新媒体艺术家通过应用增强现实、虚拟现实、生成式图像系统、高分辨率显示等前沿媒体技术，在推动技术普及的同时也加剧了对计算资源的消耗，这带来了不可持续的计算使用问题。因此，艺术家有必要探索与推广更可持续的技术应用方式，尤其是在高等教育环境中。

Method: 本文探讨了艺术家采取更可持续方法的可能性，具体结合了计算重用、可持续网页开发与节俭计算等技术手段，并与材料特异性、未来性和媒介考古等概念结合。文章提出了三种低碳艺术创作方法，并制定了一套将可持续方法引入艺术与科技课程的指导方针。同时，为每种方法设计了教学实现模型，强调本地资源与可持续情境的作用。

Result: 本文不仅阐述了这些低碳艺术方法的可行性，还展示了其为艺术家和观众带来丰富概念探索的潜力。此外，针对如何在艺术与科技教育中推动这些方法，提出了具体的教学实施模型。

Conclusion: 提出艺术家在媒介与技术创作中应采用更可持续的技术手段，并鼓励高等教育中将这些方法纳入课程，同时兼顾技术可行性与艺术概念探索，为推动环保和创新做出贡献。

Abstract: Artists and especially new media artists contribute to public perceptions and
adoption of new technologies through their own use of emerging media
technologies such as augmented and virtual reality, generative image systems,
and high-resolution displays in the production of their work. In this way, art
and media production can be understood as part of the larger issue of
unsustainable computational consumption. As such, it is critical for artists to
develop, share, and promote new and more sustainable methods of engaging with
technology, especially within the context of higher education. This paper will
explore how artists might implement more sustainable methods by considering the
relationship between the technical approaches of compute reuse, sustainable web
development, and frugal computing, and the concepts of material specificity ,
futurity, and media archaeology . Proposing three methods of less
carbon-intensive artistic production and a set of guidelines for introducing
sustainable methods into arts and technology curriculum, this paper will
outline not only the technical viability of these approaches but also the rich
conceptual opportunities these approaches might offer to artists and viewers
alike. For each method, models for pedagogical implementation will be explored
with an emphasis on how local resources and sustainability contexts should play
a role.

</details>


### [27] [AGACCI : Affiliated Grading Agents for Criteria-Centric Interface in Educational Coding Contexts](https://arxiv.org/abs/2507.05321)
*Kwangsuk Park,Jiwoong Yang*

Main category: cs.CY

TL;DR: AGACCI多代理系统通过角色分工提升了针对代码类学术任务的自动化评估表现，在准确性、一致性和评判深度上明显优于单一VLM，展现了AI辅助教育评估的广阔前景。


<details>
  <summary>Details</summary>
Motivation: 现有基于VLM的学术评估方法难以处理复杂、结构化的代码任务，缺少对具体评价标准和深层结构推理的兼容，因此需要设计更有效的评价系统提升准确性与解释性。

Method: 该研究提出AGACCI多代理系统，将复杂的评估任务分配给协作的各个专门代理，并通过收集60名参与者的360份研究生级代码作业，结合专家二值评分和定性反馈，进行实验评估。

Result: 实验表明AGACCI在评分和反馈的准确性、相关性、一致性和连贯性方面均优于GPT基线系统，同时可以更好地体现专家评审的教学意图和评价深度，尽管在不同任务类型间表现有所波动。

Conclusion: AGACCI多代理系统用于代码导向性学术评估，在评分准确性、一致性和深度等多方面优于单一GPT基线模型，展示了多代理系统在教育评估中的巨大潜力。

Abstract: Recent advances in AI-assisted education have encouraged the integration of
vision-language models (VLMs) into academic assessment, particularly for tasks
that require both quantitative and qualitative evaluation. However, existing
VLM based approaches struggle with complex educational artifacts, such as
programming tasks with executable components and measurable outputs, that
require structured reasoning and alignment with clearly defined evaluation
criteria. We introduce AGACCI, a multi-agent system that distributes
specialized evaluation roles across collaborative agents to improve accuracy,
interpretability, and consistency in code-oriented assessment. To evaluate the
framework, we collected 360 graduate-level code-based assignments from 60
participants, each annotated by domain experts with binary rubric scores and
qualitative feedback. Experimental results demonstrate that AGACCI outperforms
a single GPT-based baseline in terms of rubric and feedback accuracy,
relevance, consistency, and coherence, while preserving the instructional
intent and evaluative depth of expert assessments. Although performance varies
across task types, AGACCI highlights the potential of multi-agent systems for
scalable and context-aware educational evaluation.

</details>


### [28] [Strategic Alignment Patterns in National AI Policies](https://arxiv.org/abs/2507.05400)
*Mohammad Hossein Azin,Hessam Zandhessami*

Main category: cs.CY

TL;DR: 本文提出一种可视化方法评估国家AI政策战略协同，用矩阵和网络分析对比不同国家政策，揭示经济目标与创新资金协同良好，伦理目标与监管存在脱节，并为政策改进提供方法和建议。


<details>
  <summary>Details</summary>
Motivation: 当前各国纷纷出台人工智能国家战略，但缺乏系统的分析框架以评估战略目标、前瞻方法与实施工具之间的一致性，因此亟需一种有效分析和评估政策协同的方法。

Method: 基于经合组织（OECD）AI政策数据库，选取15-20个国家的AI战略，运用矩阵可视化和网络分析工具，对这些国家AI政策中的战略一致性进行分析和图示化展示。

Result: 发现不同治理模式下存在各自的战略协同类型，高一致性的策略通常表现为经济竞争力目标和创新资金工具之间有紧密联系，常见的问题则是伦理AI目标与相应监管框架之间协同不足。

Conclusion: 作者提出的可视化映射方法不仅丰富了政策分析工具，还为加强AI治理政策战略协同提供了实践参考，对政策制定者具有实际指导意义。

Abstract: This paper introduces a novel visual mapping methodology for assessing
strategic alignment in national artificial intelligence policies. The
proliferation of AI strategies across countries has created an urgent need for
analytical frameworks that can evaluate policy coherence between strategic
objectives, foresight methods, and implementation instruments. Drawing on data
from the OECD AI Policy Observatory, we analyze 15-20 national AI strategies
using a combination of matrix-based visualization and network analysis to
identify patterns of alignment and misalignment. Our findings reveal distinct
alignment archetypes across governance models, with notable variations in how
countries integrate foresight methodologies with implementation planning.
High-coherence strategies demonstrate strong interconnections between economic
competitiveness objectives and robust innovation funding instruments, while
common vulnerabilities include misalignment between ethical AI objectives and
corresponding regulatory frameworks. The proposed visual mapping approach
offers both methodological contributions to policy analysis and practical
insights for enhancing strategic coherence in AI governance. This research
addresses significant gaps in policy evaluation methodology and provides
actionable guidance for policymakers seeking to strengthen alignment in
technological governance frameworks.

</details>


### [29] [The Ethical Implications of AI in Creative Industries: A Focus on AI-Generated Art](https://arxiv.org/abs/2507.05549)
*Prerana Khatiwada,Joshua Washington,Tyler Walsh,Ahmed Saif Hamed,Lokesh Bhatta*

Main category: cs.CY

TL;DR: 论文系统分析了生成式AI艺术引发的伦理难题，包括环境、版权、虚假信息和艺术家生计等，提出需加强立法监管以减少负面影响。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能技术的快速发展，生成式AI艺术引发了诸多伦理上的争议和困惑，需要系统研究其带来的多重影响。

Method: 论文从多个角度探讨生成式AI艺术的伦理问题，包括对环境影响、名人肖像、知识产权、深度伪造和艺术家生计的影响，结合案例研究和各方观点，分析问题的成因、历史和后果，并提出潜在解决方案。

Result: 研究发现，生成式AI艺术导致了碳排放增加、虚假信息传播、版权侵犯、非法肖像使用和艺术工作岗位减少等问题。

Conclusion: 生成式AI艺术的快速发展带来了严重的伦理与社会问题，亟需出台合理的立法和监管措施以应对这些挑战。

Abstract: As Artificial Intelligence (AI) continues to grow daily, more exciting (and
somewhat controversial) technology emerges every other day. As we see the
advancements in AI, we see more and more people becoming skeptical of it. This
paper explores the complications and confusion around the ethics of generative
AI art. We delve deep into the ethical side of AI, specifically generative art.
We step back from the excitement and observe the impossible conundrums that
this impressive technology produces. Covering environmental consequences,
celebrity representation, intellectual property, deep fakes, and artist
displacement. Our research found that generative AI art is responsible for
increased carbon emissions, spreading misinformation, copyright infringement,
unlawful depiction, and job displacement. In light of this, we propose multiple
possible solutions for these problems. We address each situation's history,
cause, and consequences and offer different viewpoints. At the root of it all,
though, the central theme is that generative AI Art needs to be correctly
legislated and regulated.

</details>
