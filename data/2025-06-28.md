<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 13]
- [cs.CL](#cs.CL) [Total: 37]
- [cs.CE](#cs.CE) [Total: 3]
- [cs.CY](#cs.CY) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [The Singapore Consensus on Global AI Safety Research Priorities](https://arxiv.org/abs/2506.20702)
*Yoshua Bengio,Tegan Maharaj,Luke Ong,Stuart Russell,Dawn Song,Max Tegmark,Lan Xue,Ya-Qin Zhang,Stephen Casper,Wan Sie Lee,Sören Mindermann,Vanessa Wilfred,Vidhisha Balachandran,Fazl Barez,Michael Belinsky,Imane Bello,Malo Bourgon,Mark Brakel,Siméon Campos,Duncan Cass-Beggs,Jiahao Chen,Rumman Chowdhury,Kuan Chua Seah,Jeff Clune,Juntao Dai,Agnes Delaborde,Nouha Dziri,Francisco Eiras,Joshua Engels,Jinyu Fan,Adam Gleave,Noah Goodman,Fynn Heide,Dan Hendrycks,Cyrus Hodes,Bryan Low Kian Hsiang,Minlie Huang,Sami Jawhar,Wang Jingyu,Adam Tauman Kalai,Meindert Kamphuis,Mohan Kankanhalli,Subhash Kantamneni,Mathias Bonde Kirk,Thomas Kwa,Jeffrey Ladish,Kwok-Yan Lam,Wan Lee Sie,Taewhi Lee,Xiaojian Li,Jiajun Liu,Chaochao Lu,Yifan Mai,Richard Mallah,Julian Michael,Nick Moës,Simon Möller,Kihyuk Nam,Kwan Yee Ng,Mark Nitzberg,Besmira Nushi,Seán O hÉigeartaigh,Alejandro Ortega,Pierre Peigné,James Petrie,Benjamin Prud'Homme,Reihaneh Rabbany,Nayat Sanchez-Pi,Sarah Schwettmann,Buck Shlegeris,Saad Siddiqui,Aradhana Sinha,Martín Soto,Cheston Tan,Dong Ting,Robert Trager,Brian Tse,Anthony Tung K. H.,Vanessa Wilfred,John Willes,Denise Wong,Wei Xu,Rongwu Xu,Yi Zeng,HongJiang Zhang,Djordje Žikelić*

Main category: cs.AI

TL;DR: 该报告围绕AI安全三大核心环节——开发、评估、部署后控制——系统梳理了研究重点和挑战，为国际AI安全研究合作和生态构建提供了指导。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力和自主性的大幅提升，AI带来的变革潜力巨大，但与此同时，AI如何安全、可靠、可信成为热议话题。因此，建立值得信赖的AI生态体系已经变得至关重要，以增强公众信心并避免创新遭到抵制。

Method: 通过2025年新加坡AI大会，国际科学家集会，确定并整合了AI安全领域的研究重点。本报告借鉴了由Yoshua Bengio主持、33国支持的国际AI安全报告，并采用分层防御（defence-in-depth）模型，将AI安全研究分为开发、评估和控制三个维度。

Result: 报告明确了AI安全研究的三大核心领域：（1）开发阶段的可信系统构建挑战；（2）评估阶段的风险评估挑战；（3）部署后的监测与干预挑战。

Conclusion: 本报告推动跨国AI安全研究协作，为未来AI安全研究和政策规划奠定了基础。建立可信AI生态系统对于释放AI潜力并避免社会反弹至关重要。

Abstract: Rapidly improving AI capabilities and autonomy hold significant promise of
transformation, but are also driving vigorous debate on how to ensure that AI
is safe, i.e., trustworthy, reliable, and secure. Building a trusted ecosystem
is therefore essential -- it helps people embrace AI with confidence and gives
maximal space for innovation while avoiding backlash.
  The "2025 Singapore Conference on AI (SCAI): International Scientific
Exchange on AI Safety" aimed to support research in this space by bringing
together AI scientists across geographies to identify and synthesise research
priorities in AI safety. This resulting report builds on the International AI
Safety Report chaired by Yoshua Bengio and backed by 33 governments. By
adopting a defence-in-depth model, this report organises AI safety research
domains into three types: challenges with creating trustworthy AI systems
(Development), challenges with evaluating their risks (Assessment), and
challenges with monitoring and intervening after deployment (Control).

</details>


### [2] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
*Gurusha Juneja,Alon Albalak,Wenyue Hua,William Yang Wang*

Main category: cs.AI

TL;DR: 现有最先进的大模型Agent在多Agent协作场景下，缺乏对情境隐私的理解和保护能力，常常错误共享敏感信息，且合作完成任务的能力也不理想。


<details>
  <summary>Details</summary>
Motivation: LLM（大语言模型）驱动的AI Agent越来越多地承担如排程、协商、资源分配等多智能体协作任务。在这些系统中，代理通常访问专有工具和数据库，因而保护隐私变得极为关键。然而，目前尚不清楚这些LLM代理是否具备对情境隐私的理解能力，以及在多轮对话协作中是否能在推断时保护用户隐私。

Method: 作者提出了MAGPIE基准集，包含158个来自15个实际高风险领域的任务场景，这些情境下完全排除隐私信息将导致任务难以完成，但无差别共享又会带来重大损失。利用该基准，实证评估了当前主流LLM（如GPT-4o与Claude-2.7-Sonnet）对情境隐私的理解及协作中保护隐私的表现。

Result: 实验结果显示，当前主流模型对情境隐私理解不足，GPT-4o与Claude-2.7-Sonnet分别有25.2%和43.6%的误判率（把私人数据当作可共享），多轮对话中，即使明确告诉保护隐私，这些模型仍分别有59.9%和50.5%的案例会泄露私人信息。此外，多智能体系统有高达71%的案例无法完成任务。

Conclusion: 当前主流LLM代理对情境隐私的理解与保护能力薄弱，在完成协作任务的同时难以做到有效保密，现有模型在隐私保护和多Agent协作任务完成度两方面均存在明显不足。

Abstract: The proliferation of LLM-based agents has led to increasing deployment of
inter-agent collaboration for tasks like scheduling, negotiation, resource
allocation etc. In such systems, privacy is critical, as agents often access
proprietary tools and domain-specific databases requiring strict
confidentiality. This paper examines whether LLM-based agents demonstrate an
understanding of contextual privacy. And, if instructed, do these systems
preserve inference time user privacy in non-adversarial multi-turn
conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents
primarily assess single-turn, low-complexity tasks where private information
can be easily excluded. We first present a benchmark - MAGPIE comprising 158
real-life high-stakes scenarios across 15 domains. These scenarios are designed
such that complete exclusion of private data impedes task completion yet
unrestricted information sharing could lead to substantial losses. We then
evaluate the current state-of-the-art LLMs on (a) their understanding of
contextually private data and (b) their ability to collaborate without
violating user privacy. Empirical experiments demonstrate that current models,
including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual
privacy, misclassifying private data as shareable 25.2\% and 43.6\% of the
time. In multi-turn conversations, these models disclose private information in
59.9\% and 50.5\% of cases even under explicit privacy instructions.
Furthermore, multi-agent systems fail to complete tasks in 71\% of scenarios.
These results underscore that current models are not aligned towards both
contextual privacy preservation and collaborative task-solving.

</details>


### [3] [Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications](https://arxiv.org/abs/2506.20815)
*Xinye Tang,Haijun Zhai,Chaitanya Belwal,Vineeth Thayanithi,Philip Baumann,Yogesh K Roy*

Main category: cs.AI

TL;DR: 该文提出一种面向领域应用的动态prompt推荐系统，可自动分析上下文并生成优质建议，有效提升LLM应用中的prompt质量，经实验证明推荐效果优异。


<details>
  <summary>Details</summary>
Motivation: LLM应用的效果高度依赖于用户输入的prompt质量，而领域特定的高质量prompt撰写颇具挑战性。

Method: 提出了一种动态、上下文感知的prompt推荐系统，结合了上下文查询分析、检索增强知识支撑、分层技能组织和自适应技能排序。系统通过行为遥测和两阶段分层推理动态选择并排序相关技能，利用预定义与自适应模板及少样本学习生成高相关和可用的prompt建议。

Result: 在真实数据集上的实验显示，该方法的prompt建议在实用性与相关性上表现出色，获得自动化和专家评价的双重验证。

Conclusion: 该系统能为领域特定的AI应用动态生成高质量prompt，有效提升应用表现。

Abstract: LLM-powered applications are highly susceptible to the quality of user
prompts, and crafting high-quality prompts can often be challenging especially
for domain-specific applications. This paper presents a novel dynamic
context-aware prompt recommendation system for domain-specific AI applications.
Our solution combines contextual query analysis, retrieval-augmented knowledge
grounding, hierarchical skill organization, and adaptive skill ranking to
generate relevant and actionable prompt suggestions.
  The system leverages behavioral telemetry and a two-stage hierarchical
reasoning process to dynamically select and rank relevant skills, and
synthesizes prompts using both predefined and adaptive templates enhanced with
few-shot learning. Experiments on real-world datasets demonstrate that our
approach achieves high usefulness and relevance, as validated by both automated
and expert evaluations.

</details>


### [4] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
*Chenkai Sun,Denghui Zhang,ChengXiang Zhai,Heng Ji*

Main category: cs.AI

TL;DR: 该论文提出了预测语言模型建议在社会系统长期影响的框架，并通过新数据集测试安全意识，方法显著提升了模型对间接风险的识别能力，在多个基准测试中表现优秀，推动安全AI研究。


<details>
  <summary>Details</summary>
Motivation: 语言模型已在公共政策、医疗等高风险社会决策中广泛应用，因此需要理解模型建议在社会系统中的长期影响，以确保其正面作用和安全性。

Method: 提出了一个概念性框架，用于预测模型生成建议在社会系统中的长期、大规模传导效应。同时，构建了含100个间接伤害场景的数据集，测试模型对非显性负面后果的预判能力。

Result: 新方法在新数据集上的表现提升20%以上，并在现有安全基准（如AdvBench、SafeRLHF、WildGuardMix）上取得超过70%的平均胜率，优于强基线。

Conclusion: 所提框架和方法在提升语言模型长期安全意识和对复杂社会风险的预判能力方面具有前景，为构建更安全的AI智能体指出了新方向。

Abstract: Given the growing influence of language model-based agents on high-stakes
societal decisions, from public policy to healthcare, ensuring their beneficial
impact requires understanding the far-reaching implications of their
suggestions. We propose a proof-of-concept framework that projects how
model-generated advice could propagate through societal systems on a
macroscopic scale over time, enabling more robust alignment. To assess the
long-term safety awareness of language models, we also introduce a dataset of
100 indirect harm scenarios, testing models' ability to foresee adverse,
non-obvious outcomes from seemingly harmless user prompts. Our approach
achieves not only over 20% improvement on the new dataset but also an average
win rate exceeding 70% against strong baselines on existing safety benchmarks
(AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer
agents.

</details>


### [5] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
*Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han*

Main category: cs.AI

TL;DR: 本文表明，当前主流LLMs在新颖因果推理任务中的表现有限，仅能实现浅层因果推理。通过引入结合通用知识与目标导向的G^2-Reasoner方法，可以有效提升LLMs的因果推理水平，朝向更深层次的推理能力迈进。


<details>
  <summary>Details</summary>
Motivation: 目前尚不清楚大型语言模型（LLMs）是否真正具备类似人类的因果推理能力。已有证据表明，现有LLMs仅能完成较浅层的因果推理（level-1），而缺乏更高级别（level-2）的能力。为此，作者进一步探索LLMs在因果推理方面的局限性及其提升路径。

Method: 作者首先从理论上分析transformer-based LLMs自回归机制，指出其本质上并不具备因果推理能力。随后，作者提出了一个全新的因果问答基准集CausalProbe-2024，用于实证LLMs的因果推理能力表现。最后，借鉴人类推理依赖通用知识与目标导向的特点，提出G^2-Reasoner，将通用知识及目标导向提示结合到LLMs的推理过程中。

Result: 在CausalProbe-2024基准测试中，主流LLMs的因果推理能力较以往基准测试大幅下降，确认其主要还是level-1推理。应用G^2-Reasoner后，LLMs在新颖、反事实等复杂语境中的因果推理能力得到明显提升。

Conclusion: 当前LLMs主要停留在浅层因果推理水平，缺乏类人深层因果推理能力。CausalProbe-2024基准和G^2-Reasoner方法为推动LLMs向更高层次因果推理能力发展提供了新的方向。

Abstract: Causal reasoning capability is critical in advancing large language models
(LLMs) toward strong artificial intelligence. While versatile LLMs appear to
have demonstrated capabilities in understanding contextual causality and
providing responses that obey the laws of causality, it remains unclear whether
they perform genuine causal reasoning akin to humans. However, current evidence
indicates the contrary. Specifically, LLMs are only capable of performing
shallow (level-1) causal reasoning, primarily attributed to the causal
knowledge embedded in their parameters, but they lack the capacity for genuine
human-like (level-2) causal reasoning. To support this hypothesis,
methodologically, we delve into the autoregression mechanism of
transformer-based LLMs, revealing that it is not inherently causal.
Empirically, we introduce a new causal Q&A benchmark called CausalProbe-2024,
whose corpora are fresh and nearly unseen for the studied LLMs. The LLMs
exhibit a significant performance drop on CausalProbe-2024 compared to earlier
benchmarks, indicating the fact that they primarily engage in level-1 causal
reasoning. To bridge the gap towards level-2 causal reasoning, we draw
inspiration from the fact that human reasoning is usually facilitated by
general knowledge and intended goals. We propose G^2-Reasoner, a method that
incorporates general knowledge and goal-oriented prompts into LLMs' causal
reasoning processes. Experiments demonstrate that G^2-Reasoner significantly
enhances LLMs' causal reasoning capability, particularly in fresh and
counterfactual contexts. This work sheds light on a new path for LLMs to
advance towards genuine causal reasoning, going beyond level-1 and making
strides towards level-2.

</details>


### [6] [World-aware Planning Narratives Enhance Large Vision-Language Model Planner](https://arxiv.org/abs/2506.21230)
*Junhao Shi,Zhaoye Fei,Siyin Wang,Qipeng Guo,Jingjing Gong,Xipeng QIu*

Main category: cs.AI

TL;DR: 本文提出WAP框架，通过增强大型视觉-语言模型的环境感知和多种认知能力，实现对复杂规划任务的突破性提升，尤其在长时和常识推理场景下，开源模型显著超越主流闭源系统。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型（LVLMs）在体感规划任务中具有潜力，但遇到不熟悉环境和多步骤目标的复杂场景时表现不足。现有方法主要依赖与环境无关的模仿学习，导致模型难以处理与环境紧密相关的指令，且过度依赖补充线索而非视觉推理，尤其在长时序任务中更为明显。

Method: 提出了世界感知规划叙事增强（WAP）框架，通过视觉外观建模、空间推理、功能抽象和句法基础四项认知能力，将全面的环境理解引入LVLMs。模型仅通过原始视觉观察，并结合课程学习进行训练与评估。

Result: 在EB-ALFRED基准测试中，带WAP的LVLM表现大幅提升，尤其是在常识推理和长时规划任务上，Qwen2.5-VL模型的任务成功率绝对提升60.7，分别在常识推理和长时规划上提升60.0和70.0，优于GPT-4o和Claude-3.5-Sonnet等专有系统。

Conclusion: WAP方法大幅提升了LVLM在复杂体感规划任务中的环境理解和执行能力，尤其是在需要常识推理和长时任务规划场景下，增强后的开源模型超过了目前最强的闭源系统。

Abstract: Large Vision-Language Models (LVLMs) show promise for embodied planning tasks
but struggle with complex scenarios involving unfamiliar environments and
multi-step goals. Current approaches rely on environment-agnostic imitation
learning that disconnects instructions from environmental contexts, causing
models to struggle with context-sensitive instructions and rely on
supplementary cues rather than visual reasoning during long-horizon
interactions. In this work, we propose World-Aware Planning Narrative
Enhancement (WAP), a framework that infuses LVLMs with comprehensive
environmental understanding through four cognitive capabilities (visual
appearance modeling, spatial reasoning, functional abstraction, and syntactic
grounding) while developing and evaluating models using only raw visual
observations through curriculum learning. Evaluations on the EB-ALFRED
benchmark demonstrate substantial improvements, with Qwen2.5-VL achieving a
60.7 absolute improvement in task success rates, particularly in commonsense
reasoning (+60.0) and long-horizon planning (+70.0). Notably, our enhanced
open-source models outperform proprietary systems like GPT-4o and
Claude-3.5-Sonnet by a large margin.

</details>


### [7] [IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems](https://arxiv.org/abs/2506.21310)
*Pauline Speckmann,Mario Nadj,Christian Janiesch*

Main category: cs.AI

TL;DR: 该文提出了交互式可解释AI系统IXAII，支持多XAI方法和多用户群定制，实验证明能有效增强AI模型透明度和用户理解，推动了XAI实用化进程。


<details>
  <summary>Details</summary>
Motivation: 当前主流可解释人工智能（XAI）方法大多为静态，且忽略了用户视角，导致其对目标受众的实际效用有限。

Method: 开发了一个交互式可解释智能系统（IXAII），整合了四种XAI技术（LIME、SHAP、Anchors、DiCE），并针对五类用户群体提供定制化展示，让用户能够主动选择解释内容及其呈现方式。通过与专家和普通用户进行访谈，对IXAII进行了评估。

Result: IXAII能够为不同用户提供多样化的解释与可视化选项，显著提升了AI模型的透明度，受访者普遍认为该系统对理解AI决策有帮助。

Conclusion: 通过将多种XAI方法、交互性及实际落地结合，IXAII为AI决策解释和人机交互探索出新的实践路径，有助于提升XAI系统的用户可用性和信任度。

Abstract: Although several post-hoc methods for explainable AI have been developed,
most are static and neglect the user perspective, limiting their effectiveness
for the target audience. In response, we developed the interactive explainable
intelligent system called IXAII that offers explanations from four explainable
AI methods: LIME, SHAP, Anchors, and DiCE. Our prototype provides tailored
views for five user groups and gives users agency over the explanations'
content and their format. We evaluated IXAII through interviews with experts
and lay users. Our results indicate that IXAII, which provides different
explanations with multiple visualization options, is perceived as helpful to
increase transparency. By bridging the gaps between explainable AI methods,
interactivity, and practical implementation, we provide a novel perspective on
AI explanation practices and human-AI interaction.

</details>


### [8] [Active Inference AI Systems for Scientific Discovery](https://arxiv.org/abs/2506.21329)
*Karthik Duraisamy*

Main category: cs.AI

TL;DR: 本文认为AI在科学重大突破中受制于推理与现实反哺等根本性差距，而非模型规模。作者提出主动推断型AI系统的新框架，强调因果推理、闭环互动与人类判断长久并存，以实现AI驱动的科学创新。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能飞速发展并被寄予推动科学发现的厚望，但现有AI系统因架构、推理和与实验现实的割裂，难以实现高水平科学推理。作者认为，仅靠模型规模、数据或计算能力提升难以突破瓶颈，必须解决AI在科学发现中的抽象、推理和现实融合三大根本性差距。

Method: 提出“主动推断AI系统”新方法，具体包括：（1）基于因果自监督基础模型、能长期保存并成长的科学发现记忆；（2）配备贝叶斯安全约束的符号/神经符号推理规划器；（3）构建和动态优化知识图谱，通过推理和与现实互动持续生成、验证和修正知识；（4）通过闭环操作，结合高保真模拟器与自动化实验室，不断校正内部表征，并实现思维模拟与现实行动的相互作用。

Result: 提出了一种科学发现型AI系统的结构性框架。该框架强调因果推理、知识持续成长和与现实实验的交互闭环。同时，论证了人类判断将在AI系统中长期保持不可或缺的角色，以弥补模拟和实验反馈的固有不确定性。

Conclusion: 要实现AI驱动的科学重大发现，必须通过主动推断型AI系统，弥合抽象、推理与现实三大差距，采用因果推理、知识自生长与与现实互动的闭环架构，在不确定性与模糊反馈下，始终保留人类判断为核心组件。

Abstract: The rapid evolution of artificial intelligence has led to expectations of
transformative scientific discovery, yet current systems remain fundamentally
limited by their operational architectures, brittle reasoning mechanisms, and
their separation from experimental reality. Building on earlier work, we
contend that progress in AI-driven science now depends on closing three
fundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap
-- rather than on model size/data/test time compute. Scientific reasoning
demands internal representations that support simulation of actions and
response, causal structures that distinguish correlation from mechanism, and
continuous calibration. We define active inference AI systems for scientific
discovery as those that (i) maintain long-lived research memories grounded in
causal self-supervised foundation models, (ii) symbolic or neuro-symbolic
planners equipped with Bayesian guardrails, (iii) grow persistent knowledge
graphs where thinking generates novel conceptual nodes, reasoning establishes
causal edges, and real-world interaction prunes false connections while
strengthening verified pathways, and (iv) refine their internal representations
through closed-loop interaction with both high-fidelity simulators and
automated laboratories - an operational loop where mental simulation guides
action and empirical surprise reshapes understanding. In essence, we outline an
architecture where discovery arises from the interplay between internal models
that enable counterfactual reasoning and external validation that grounds
hypotheses in reality. It is also argued that the inherent ambiguity in
feedback from simulations and experiments, and underlying uncertainties makes
human judgment indispensable, not as a temporary scaffold but as a permanent
architectural component.

</details>


### [9] [TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding](https://arxiv.org/abs/2506.21393)
*Junwen Zhang,Pu Chen,Yin Zhang*

Main category: cs.AI

TL;DR: 本文提出了TableMoE，一种针对真实复杂多模态表格理解的神经-符号混合专家模型，通过创新路由机制和大规模预训练，实现在多个高难基准上大幅领先，为实际场景下表格分析带来新突破。


<details>
  <summary>Details</summary>
Motivation: 现实场景中的多模态表格理解非常具有挑战性，主要由于表格结构复杂、符号密集、以及视觉退化（如模糊、倾斜、水印、不完整结构或字体、多跨度或嵌套布局）。现有多模态大语言模型（MLLMs）在此类复杂环境下表现不佳，泛化能力有限。

Method: 提出TableMoE，这是一种神经符号混合专家模型（Mixture-of-Connector-Experts, MoCE）架构，专为鲁棒的多模态表格结构化推理设计。TableMoE包含创新的神经符号路由机制，能够预测潜在语义token角色，并通过基于符号推理图的置信门控，将表格单元动态分配给不同领域专家（如Table-to-HTML，Table-to-JSON，Table-to-Code）。此外，引入了大规模预训练数据集TableMoE-Align（包含120万table-HTML-JSON-code四元组），覆盖金融、科学、生物医学、工业等领域。

Result: 实验证明TableMoE在四个专为复杂表格设计的WildStruct基准（WMMFinQA、WMMTatQA、WMMTabDialog、WMMFinanceMath）上大幅超越现有最先进模型。消融实验验证了模型各核心组件的有效性，特别是神经符号路由和结构专家对齐的重要性。定性分析还展示了该模型的可解释性和鲁棒性提升。

Conclusion: TableMoE通过结合神经-符号推理和专家动态路由机制，显著提高了复杂、多模态表格的理解和推理能力，为实际应用场景下的表格分析提供了更强鲁棒性、可解释性和通用性。

Abstract: Multimodal understanding of tables in real-world contexts is challenging due
to the complexity of structure, symbolic density, and visual degradation (blur,
skew, watermarking, incomplete structures or fonts, multi-span or
hierarchically nested layouts). Existing multimodal large language models
(MLLMs) struggle with such WildStruct conditions, resulting in limited
performance and poor generalization. To address these challenges, we propose
TableMoE, a neuro-symbolic Mixture-of-Connector-Experts (MoCE) architecture
specifically designed for robust, structured reasoning over multimodal table
data. TableMoE features an innovative Neuro-Symbolic Routing mechanism, which
predicts latent semantic token roles (e.g., header, data cell, axis, formula)
and dynamically routes table elements to specialized experts (Table-to-HTML,
Table-to-JSON, Table-to-Code) using a confidence-aware gating strategy informed
by symbolic reasoning graphs. To facilitate effective alignment-driven
pretraining, we introduce the large-scale TableMoE-Align dataset, consisting of
1.2M table-HTML-JSON-code quadruples across finance, science, biomedicine and
industry, utilized exclusively for model pretraining. For evaluation, we curate
and release four challenging WildStruct benchmarks: WMMFinQA, WMMTatQA,
WMMTabDialog, and WMMFinanceMath, designed specifically to stress-test models
under real-world multimodal degradation and structural complexity. Experimental
results demonstrate that TableMoE significantly surpasses existing
state-of-the-art models. Extensive ablation studies validate each core
component, emphasizing the critical role of Neuro-Symbolic Routing and
structured expert alignment. Through qualitative analyses, we further showcase
TableMoE's interpretability and enhanced robustness, underscoring the
effectiveness of integrating neuro-symbolic reasoning for multimodal table
understanding.

</details>


### [10] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
*Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei*

Main category: cs.AI

TL;DR: 本文通过MindCube新基准系统评估VLMs对空间心理模型的构建能力，大幅改进方法（map-then-reason+强化学习）将准确率提升至70.7%，揭示了构建和利用空间内部结构对理解不可见空间的重要性。


<details>
  <summary>Details</summary>
Motivation: 人类能够通过有限视角想象完整场景，依靠内部空间模型来进行推理和想象。相比之下，当前视觉语言模型（VLMs）对此能力极为有限，近似随机表现。该工作旨在探究VLMs在空间心理模型构建上的短板并寻找改进方法。

Method: 本文提出了MindCube基准数据集，通过3,268张图片和21,154个问题系统性评估VLMs在位置认知、视角转换和运动模拟（what-if推理）上的能力。研究还探索了三种提升VLMs空间心理模型的方法：补充未见中间视角、自然语言推理链和认知地图，并进一步提出“map-then-reason”为核心的联合训练方法，以及引入强化学习。

Result: 采用“map-then-reason”的思路将模型准确率从37.8%提升到60.8%，联合强化学习进一步提升到70.7%，相比原始能力提升32.9%。

Conclusion: 通过主动构建和利用内部结构化空间表征，并结合灵活推理流程，视觉语言模型对不可见空间的理解能力获得大幅提升。该工作为VLMs融入空间心理模型开辟了新思路。

Abstract: Can Vision Language Models (VLMs) imagine the full scene from just a few
views, like humans do? Humans form spatial mental models, internal
representations of unseen space, to reason about layout, perspective, and
motion. Our new MindCube benchmark with 21,154 questions across 3,268 images
exposes this critical gap, where existing VLMs exhibit near-random performance.
Using MindCube, we systematically evaluate how well VLMs build robust spatial
mental models through representing positions (cognitive mapping), orientations
(perspective-taking), and dynamics (mental simulation for "what-if" movements).
We then explore three approaches to help VLMs approximate spatial mental
models, including unseen intermediate views, natural language reasoning chains,
and cognitive maps. The significant improvement comes from a synergistic
approach, "map-then-reason", that jointly trains the model to first generate a
cognitive map and then reason upon it. By training models to reason over these
internal maps, we boosted accuracy from 37.8% to 60.8% (+23.0%). Adding
reinforcement learning pushed performance even further to 70.7% (+32.9%). Our
key insight is that such scaffolding of spatial mental models, actively
constructing and utilizing internal structured spatial representations with
flexible reasoning processes, significantly improves understanding of
unobservable space.

</details>


### [11] [Ad-Hoc Human-AI Coordination Challenge](https://arxiv.org/abs/2506.21490)
*Tin Dizdarević,Ravi Hammond,Tobias Gessler,Anisoara Calinescu,Jonathan Cook,Matteo Gallici,Andrei Lupu,Jakob Nicolaus Foerster*

Main category: cs.AI

TL;DR: 本文提出Ad-Hoc Human-AI Coordination Challenge (AH2AC2)，利用仿人代理进行可复现、低成本的人机协作评测，并开源3,079局人类对局数据，支持Hanabi两人及三人场景，推动数据高效的人机协作方法发展。


<details>
  <summary>Details</summary>
Motivation: 实现AI代理和人类之间的无缝协作对现实应用至关重要，但仍面临重大挑战。Hanabi游戏由于信息不完全、交流受限和理论心智等特性，是人机协作研究的理想平台。人类评测昂贵且难以复现，制约了该领域的发展。

Method: 1. 提出Ad-Hoc Human-AI Coordination Challenge (AH2AC2)，旨在减少对传统人类测试的依赖。
2. 基于大规模人类数据集开发“人类代理体”（human proxy agents），可作为仿人评价对象，进行大规模、低成本、易复现实验。
3. 开源3,079局Hanabi对局数据集，推动数据高效方法的开发，且故意限制可用人类数据量。
4. 提供了两人和三人游戏的基线结果，并通过受控评测系统托管人类代理体以保证公平。

Result: 人类代理体作为评价工具能模拟真实人类伙伴，允许大规模、低成本且可复现的AI-human协作实验。基线实验已覆盖两人和三人游戏场景。开源的数据和平台将推动该领域的方法开发和标准化评测。

Conclusion: 通过引入AH2AC2挑战和“人类代理体”概念，有效降低了人类评测障碍，提升了AI与人类协作方法的开发效率，有望成为未来人机协作研究的重要标准平台。

Abstract: Achieving seamless coordination between AI agents and humans is crucial for
real-world applications, yet it remains a significant open challenge. Hanabi is
a cooperative card game featuring imperfect information, constrained
communication, theory of mind requirements, and coordinated action -- making it
an ideal testbed for human-AI coordination. However, its use for human-AI
interaction has been limited by the challenges of human evaluation. In this
work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to
overcome the constraints of costly and difficult-to-reproduce human
evaluations. We develop \textit{human proxy agents} on a large-scale human
dataset that serve as robust, cheap, and reproducible human-like evaluation
partners in AH2AC2. To encourage the development of data-efficient methods, we
open-source a dataset of 3,079 games, deliberately limiting the amount of
available human gameplay data. We present baseline results for both two- and
three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy
agents through a controlled evaluation system rather than releasing them
publicly. The code is available at
\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.

</details>


### [12] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
*Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su*

Main category: cs.AI

TL;DR: 此论文提出了更全面评测先进智能体搜索系统的新基准和评测框架，并表明现有技术已接近于高效的人类水平，为未来发展奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大模型的类自主智能体（agentic）搜索系统如Deep Research正不断扩展其能力，能自动浏览网页、整合信息并输出带有引用的复杂答案，但评测体系滞后，无法覆盖其复杂性和多变性，造成评测与实际应用脱节。

Method: 提出了Mind2Web 2基准集，包括130个真实、复杂、长流程、多信息综合任务，用1000小时人工构建。为应对复杂、多变答案的评测难题，创新性引入了“Agent-as-a-Judge”评测框架，通过树状评分标准构造任务特定的评判智能体，自动衡量答案的正确性和信息源引用。

Result: 对九个前沿agentic搜索系统及人工真实表现进行了系统评测及误差分析。最佳系统（OpenAI Deep Research）已实现人类表现的50-70%，且用时仅为人工一半，显示出巨大发展潜力。

Conclusion: Mind2Web 2为复杂agentic搜索任务的研究和评测提供了系统性的方法论基础，有力推动了下一代智能搜索系统的研发。

Abstract: Agentic search such as Deep Research systems, where large language models
autonomously browse the web, synthesize information, and return comprehensive
citation-backed answers, represents a major shift in how users interact with
web-scale information. While promising greater efficiency and cognitive
offloading, the growing complexity and open-endedness of agentic search have
outpaced existing evaluation benchmarks and methodologies, which largely assume
short search horizons and static answers. In this paper, we introduce Mind2Web
2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that
require real-time web browsing and extensive information synthesis, constructed
with over 1,000 hours of human labor. To address the challenge of evaluating
time-varying and complex answers, we propose a novel Agent-as-a-Judge
framework. Our method constructs task-specific judge agents based on a
tree-structured rubric design to automatically assess both answer correctness
and source attribution. We conduct a comprehensive evaluation of nine frontier
agentic search systems and human performance, along with a detailed error
analysis to draw insights for future development. The best-performing system,
OpenAI Deep Research, can already achieve 50-70% of human performance while
spending half the time, showing a great potential. Altogether, Mind2Web 2
provides a rigorous foundation for developing and benchmarking the next
generation of agentic search systems.

</details>


### [13] [PsyLite Technical Report](https://arxiv.org/abs/2506.21536)
*Fangjun Ding,Renyu Zhang,Xinyu Feng,Chengye Xie,Zheng Zhang,Yanting Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型的轻量级心理咨询智能体PsyLite，通过创新训练和安全机制，大幅提升了心理咨询专业性与对话安全性，并支持低硬件环境部署。


<details>
  <summary>Details</summary>
Motivation: 随着数字技术的迅速发展，AI驱动的心理咨询成为心理健康领域的重要研究方向。但现有模型在对话安全性、细致场景处理和轻量化部署方面仍存在不足。

Method: 提出了PsyLite，一款基于InternLM2.5-7B-chat的大语言模型心理咨询智能体。采用两阶段训练策略：混合蒸馏数据微调和ORPO偏好优化，增强模型的深度推理、心理咨询和安全对话能力。在部署端使用Ollama与Open WebUI，并通过Pipelines创建定制工作流；设计了创新的条件RAG，在必要时引入趣味元素提升体验，同时拒绝危险请求提升安全性。通过量化技术，模型仅需5GB内存即可运行，适合资源受限场景。

Result: PsyLite在中文通用评测（CEval）、心理咨询专业评测（CPsyCounE）、对话安全评测（SafeDialBench）中均优于基线模型，特别是在心理咨询专业性和对话安全性上分别提升了47.6%和2.4%。

Conclusion: PsyLite兼顾专业性、对话安全性和轻量化部署，为资源受限环境下的心理咨询应用提供了可行方案。

Abstract: With the rapid development of digital technology, AI-driven psychological
counseling has gradually become an important research direction in the field of
mental health. However, existing models still have deficiencies in dialogue
safety, detailed scenario handling, and lightweight deployment. To address
these issues, this study proposes PsyLite, a lightweight psychological
counseling large language model agent developed based on the base model
InternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation
data fine-tuning and ORPO preference optimization), PsyLite enhances the
model's deep-reasoning ability, psychological counseling ability, and safe
dialogue ability. After deployment using Ollama and Open WebUI, a custom
workflow is created with Pipelines. An innovative conditional RAG is designed
to introduce crosstalk humor elements at appropriate times during psychological
counseling to enhance user experience and decline dangerous requests to
strengthen dialogue safety. Evaluations show that PsyLite outperforms the
baseline models in the Chinese general evaluation (CEval), psychological
counseling professional evaluation (CPsyCounE), and dialogue safety evaluation
(SafeDialBench), particularly in psychological counseling professionalism
(CPsyCounE score improvement of 47.6\%) and dialogue safety (\safe{} score
improvement of 2.4\%). Additionally, the model uses quantization technology
(GGUF q4\_k\_m) to achieve low hardware deployment (5GB memory is sufficient
for operation), providing a feasible solution for psychological counseling
applications in resource-constrained environments.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [Towards Probabilistic Question Answering Over Tabular Data](https://arxiv.org/abs/2506.20747)
*Chen Shen,Sajjadur Rahman,Estevam Hruschka*

Main category: cs.CL

TL;DR: 本文提出了面向表格数据概率性问答的新基准与推理框架，结合贝叶斯网络与大语言模型，有效提升了概率性问题的问答效果，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于表格数据的问答方法（如NL2SQL）可以很好地处理事实性问题，但面对需要不确定性推理的概率性问题时表现不佳。为了解决这个局限性，作者提出了新的研究方法和基准。

Method: 提出了LUCARIO新基准，并设计了一个概率性问答框架：先从数据表中归纳生成贝叶斯网络，将自然语言问题转化为概率性查询，再使用大语言模型（LLM）生成最终答案。通过符号推理与神经网络结合的方法来提升性能。

Result: 实验结果表明，所提出的方法在概率性问答任务上显著优于现有基线方法，验证了混合符号-神经推理的有效性。

Conclusion: 通过引入LUCARIO基准和一种新的混合推理方法，能够更有效地处理关于表格数据的不确定性推理任务，在概率性问答上取得了突破性进展。

Abstract: Current approaches for question answering (QA) over tabular data, such as
NL2SQL systems, perform well for factual questions where answers are directly
retrieved from tables. However, they fall short on probabilistic questions
requiring reasoning under uncertainty. In this paper, we introduce a new
benchmark LUCARIO and a framework for probabilistic QA over large tabular data.
Our method induces Bayesian Networks from tables, translates natural language
queries into probabilistic queries, and uses large language models (LLMs) to
generate final answers. Empirical results demonstrate significant improvements
over baselines, highlighting the benefits of hybrid symbolic-neural reasoning.

</details>


### [15] [Multi-lingual Functional Evaluation for Large Language Models](https://arxiv.org/abs/2506.20793)
*Victor Ojewale,Inioluwa Deborah Raji,Suresh Venkatasubramanian*

Main category: cs.CL

TL;DR: 论文提出并构建了两项多语言功能性评测任务，发现现有静态多语言基准难以全面衡量模型的实际多语言表现和鲁棒性，且不同语言之间的评测表现差异明显。


<details>
  <summary>Details</summary>
Motivation: 当前多语言大模型的能力评估主要基于静态数据基准（如Belebele、M-MMLU和M-GSM），但这些评测无法充分反映模型在实际多语言环境下的表现及鲁棒性。因此，作者提出需要更能考察实际能力的多语言功能性基准。

Method: 作者将既有的功能性评测模板从英文翻译为五种其他语言（法语、西班牙语、印地语、阿拉伯语、约鲁巴语），构建了跨语言小学数学符号推理（CL-GSM Symbolic）和跨语言指令跟随评测（CL-IFEval），以此衡量模型的多语言实际能力和鲁棒性。

Result: 实验证明：不同静态基准对功能性能力的反映有显著差异，如M-GSM与CL-GSM Symbolic在英语、法语和西班牙语中的表现分别下降24%、17%、18%；Belebele与CL-IFEval之间各语言的性能下降在15-24%，而M-MMLU与CL-IFEval之间下降仅有0.5%-3%。此外，不同语言模型的鲁棒性也差异显著，部分语言（如阿拉伯语、英语）表现更为稳定和优越。

Conclusion: 现有静态多语言基准不能充分反映模型的实际能力表现，通过功能性多语言基准可以更精准评估模型的实际应用能力和跨语言鲁棒性。模型在不同语言间表现及鲁棒性存在较大差异，提示未来多语言模型评测应更加关注实际功能任务。

Abstract: Multi-lingual competence in large language models is often evaluated via
static data benchmarks such as Belebele, M-MMLU and M-GSM. However, these
evaluations often fail to provide an adequate understanding of the practical
performance and robustness of models across multi-lingual settings. In
response, we create multi-lingual functional benchmarks -- Cross-Lingual Grade
School Math Symbolic (CL-GSM Symbolic) and Cross-Lingual Instruction-Following
Eval (CL-IFEval)-- by translating existing functional benchmark templates from
English to five additional languages that span the range of resources available
for NLP: French, Spanish, Hindi, Arabic and Yoruba. Our results reveal that
some static multi-lingual benchmarks capture functional performance much more
closely than others (i.e. across models, there is a 24%, 17% and 18% decrease
in performance between M-GSM and CL-GSM Symbolic in English, French and Spanish
respectively; similarly there's a 15 - 24% performance drop across languages
between Belebele and CL-IFEval, and only a 0.5% to 3% performance drop between
M-MMLU and CL-IFEval). Similarly, we find that model robustness across
languages varies significantly, with certain languages (eg. Arabic, English)
being the most consistently well performing across evaluation iterations.

</details>


### [16] [The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas](https://arxiv.org/abs/2506.20803)
*Chenglei Si,Tatsunori Hashimoto,Diyi Yang*

Main category: cs.CL

TL;DR: LLM能生成新颖研究点子，但实际执行效果逊于人类专家，显示现有模型在科研创新上仍有限制，仅靠新颖性评判不可靠。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在科研流程中表现出推动创新的潜力，尤其是在生成新颖研究想法方面优于人类专家，但仅具备新颖性并不能保证研究成果质量。该文希望探究：LLM生成的点子是否真的能带来更好的实际研究成果。

Method: 作者组织了43名NLP领域专家，随机抽取由LLM和人类专家编写的研究点子，每位专家投入100小时以上实施该点子，并以4页论文记录实验过程，最终由另一批专家盲审评价不同来源点子的执行成果，对比其在各项指标（新颖性、激动性、有效性、总体评分）上的表现和排序。

Result: 虽然LLM生成的点子在最初的新颖性评价阶段有优势，但被执行后，它们的各项评审分数明显下滑，跌幅显著大于人类专家点子，甚至在人类专家得分高于LLM的现象下实现排名反转。这表明在实际科研产出方面，LLM点子的优势并未延续，凸显出现有模型在生成“可执行、有效”研究想法上的不足。

Conclusion: 当前LLM虽然在生成看似新颖的科研点子时接近或超过人类专家，但在这些点子实际被实施以后，效用和成果评价显著落后于人类专家。这暴露了评估LLM科研能力时单靠“想法”本身而非实践结果的局限性。需警惕LLM新颖性假象，推动对其生成研究点子实际可执行性的进一步评估和改进。

Abstract: Large Language Models (LLMs) have shown promise in accelerating the
scientific research pipeline. A key capability for this process is the ability
to generate novel research ideas, and prior studies have found settings in
which LLM-generated research ideas were judged as more novel than human-expert
ideas. However, a good idea should not simply appear to be novel, it should
also result in better research after being executed. To test whether
AI-generated ideas lead to better research outcomes, we conduct an execution
study by recruiting 43 expert researchers to execute randomly-assigned ideas,
either written by experts or generated by an LLM. Each expert spent over 100
hours implementing the idea and wrote a 4-page short paper to document the
experiments. All the executed projects are then reviewed blindly by expert NLP
researchers. Comparing the review scores of the same ideas before and after
execution, the scores of the LLM-generated ideas decrease significantly more
than expert-written ideas on all evaluation metrics (novelty, excitement,
effectiveness, and overall; p < 0.05), closing the gap between LLM and human
ideas observed at the ideation stage. When comparing the aggregated review
scores from the execution study, we even observe that for many metrics there is
a flip in rankings where human ideas score higher than LLM ideas. This
ideation-execution gap highlights the limitations of current LLMs in generating
truly effective research ideas and the challenge of evaluating research ideas
in the absence of execution outcomes.

</details>


### [17] [MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering](https://arxiv.org/abs/2506.20821)
*Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh*

Main category: cs.CL

TL;DR: 通过多模态LLM分层回退，MultiFinRAG能更高效、准确地处理复杂金融文件问答，在常规硬件上实现比免费版ChatGPT-4o高19个百分点的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有金融文件如10-K、10-Q等包含大量叙述性文本、结构化表格及复杂图像等多种模态信息。传统的大语言模型（LLMs）和检索增强生成（RAG）方法在处理如此多模态、长跨度内容时，受到token限制、版式信息丢失和跨模态上下文碎片化等问题的影响，难以实现精确和高效的问答推理。

Method: 本文提出了MultiFinRAG，一种专为金融问答设计的多模态检索增强生成框架。MultiFinRAG将表格与图像批量化输入到轻量级多模态LLM，生成结构化JSON和简洁文本摘要，并结合原始文本，通过模态感知的召回策略进行嵌入与索引。采用分层回退机制，根据需要动态从文本扩展到文本+表格+图像，实现高效的跨模态推理并降低无关内容干扰。

Result: MultiFinRAG在无需高端算力环境下，在包含文本、表格、图像及多模态组合的复杂金融问答任务上，准确率比ChatGPT-4o（免费版本）高19个百分点，显示出卓越的多模态金融问答能力。

Conclusion: MultiFinRAG在结合多模态内容进行金融问答方面显著优于现有主流模型，能够突破单一文本或简单RAG方法在实际金融文档场景下的能力瓶颈。

Abstract: Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span
hundreds of pages and combine diverse modalities, including dense narrative
text, structured tables, and complex figures. Answering questions over such
content often requires joint reasoning across modalities, which strains
traditional large language models (LLMs) and retrieval-augmented generation
(RAG) pipelines due to token limitations, layout loss, and fragmented
cross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation
framework purpose-built for financial QA. MultiFinRAG first performs multimodal
extraction by grouping table and figure images into batches and sending them to
a lightweight, quantized open-source multimodal LLM, which produces both
structured JSON outputs and concise textual summaries. These outputs, along
with narrative text, are embedded and indexed with modality-aware similarity
thresholds for precise retrieval. A tiered fallback strategy then dynamically
escalates from text-only to text+table+image contexts when necessary, enabling
cross-modal reasoning while reducing irrelevant context. Despite running on
commodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy
than ChatGPT-4o (free-tier) on complex financial QA tasks involving text,
tables, images, and combined multimodal reasoning.

</details>


### [18] [Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes](https://arxiv.org/abs/2506.20822)
*Quintin Myers,Yanjun Gao*

Main category: cs.CL

TL;DR: 首次利用VBVQ工具系统评估多个LLM在道德冲突和人口统计变异下的响应，发现其对暴力倾向的表征常与传统社会科学结果不符，提示现有LLM在该领域应用存在显著局限。


<details>
  <summary>Details</summary>
Motivation: 当前越来越多地将大语言模型（LLMs）用于暴力内容检测与应对，但其对现实世界中道德模糊情境推理的能力尚缺乏系统验证，尤其是涉及人口统计偏差的情况。

Method: 首次利用经过社会科学验证的Violent Behavior Vignette Questionnaire（VBVQ）来评估LLM对于日常冲突的应对。同时，采用基于人物设定的提示，改变种族、年龄和地理身份等变量，并对六种不同背景下开发的LLM在零样本环境下进行统一评测。

Result: (1) LLM表层生成文本常与其内在对暴力倾向回应的偏好出现分歧；(2) LLM的暴力倾向根据受试人群特征存在变化，且常常与犯罪学、社会科学及心理学的既有研究结果相矛盾。

Conclusion: 现有LLM在处理现实复杂道德冲突及人口统计变异时，存在一致性与准确性问题，对其在暴力检测/干预中的实际可信度需谨慎看待。

Abstract: Large language models (LLMs) are increasingly proposed for detecting and
responding to violent content online, yet their ability to reason about morally
ambiguous, real-world scenarios remains underexamined. We present the first
study to evaluate LLMs using a validated social science instrument designed to
measure human response to everyday conflict, namely the Violent Behavior
Vignette Questionnaire (VBVQ). To assess potential bias, we introduce
persona-based prompting that varies race, age, and geographic identity within
the United States. Six LLMs developed across different geopolitical and
organizational contexts are evaluated under a unified zero-shot setting. Our
study reveals two key findings: (1) LLMs surface-level text generation often
diverges from their internal preference for violent responses; (2) their
violent tendencies vary across demographics, frequently contradicting
established findings in criminology, social science, and psychology.

</details>


### [19] [Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine](https://arxiv.org/abs/2506.20876)
*Sebastian Joseph,Lily Chen,Barry Wei,Michael Mackert,Iain J. Marshall,Paul Pu Liang,Ramez Kouzy,Byron C. Wallace,Junyi Jessy Li*

Main category: cs.CL

TL;DR: 本研究揭示了医学自动事实核查领域存在的关键困境，并建议以交互式沟通思路推动系统设计与评估，而非仅仅追求端到端的核查流程。


<details>
  <summary>Details</summary>
Motivation: 尽管医学事实核查对于公众健康和医学决策至关重要，但现实中自动事实核查系统的应用仍有限。用户医学素养不足和当前医学文献复杂度高也加剧了信息沟通问题，因此亟需研究该领域。

Method: 本研究首次以临床专家为对象，考察他们如何通过综合医学证据对社交媒体中的真实医学主张进行验证，旨在探索医学自动事实核查的可达上限，并揭示其中的根本性挑战。

Result: 研究发现，将事实核查端到端地应用于医学领域面临诸多挑战：如主张与医学实证（临床试验）连接困难、模糊的主张表达与意图不符，以及核查结果标签难以客观化。

Conclusion: 作者认为，医学事实核查应被视为一个交互式沟通问题，而非简单的端到端流程，并建议其在设计与评估时应加强交互性。

Abstract: Technological progress has led to concrete advancements in tasks that were
regarded as challenging, such as automatic fact-checking. Interest in adopting
these systems for public health and medicine has grown due to the high-stakes
nature of medical decisions and challenges in critically appraising a vast and
diverse medical literature. Evidence-based medicine connects to every
individual, and yet the nature of it is highly technical, rendering the medical
literacy of majority users inadequate to sufficiently navigate the domain. Such
problems with medical communication ripens the ground for end-to-end
fact-checking agents: check a claim against current medical literature and
return with an evidence-backed verdict. And yet, such systems remain largely
unused. To understand this, we present the first study examining how clinical
experts verify real claims from social media by synthesizing medical evidence.
In searching for this upper-bound, we reveal fundamental challenges in
end-to-end fact-checking when applied to medicine: Difficulties connecting
claims in the wild to scientific evidence in the form of clinical trials;
ambiguities in underspecified claims mixed with mismatched intentions; and
inherently subjective veracity labels. We argue that fact-checking should be
approached and evaluated as an interactive communication problem, rather than
an end-to-end process.

</details>


### [20] [Optimising Language Models for Downstream Tasks: A Post-Training Perspective](https://arxiv.org/abs/2506.20917)
*Zhengyan Shi*

Main category: cs.CL

TL;DR: 论文针对大语言模型在具体任务适配上的高效性与鲁棒性难题，提出了持续预训练、参数高效微调、改进的有监督微调和新评测基准等方法，提升了模型泛化和应用能力，为通用人工智能发展提供了有力支撑。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LMs）在自然语言处理任务上表现出色，但如何高效、稳健地适应具体下游任务仍存在诸多挑战。现有方法往往无法充分利用无标签数据，容易在小样本任务数据上过拟合，同时计算和存储成本较高。这些问题限制了LMs在实际开放领域任务中的应用。

Method: 1. 提出了从无标签数据中提取任务相关知识的新型持续预训练方法，超越了现有半监督方法。2. 提出了一种参数高效的微调方法，大幅降低内存和计算消耗，同时保持竞争力的性能。3. 优化了有监督微调方式，使模型能在有标注数据稀缺时更好地跟随指令，提升多任务的表现。4. 构建了新的评测方法和基准（如多跳空间推理任务），更全面地评估LM能力。

Result: 本文提出的方法在多种NLP任务上经过大量实验验证，显著提升了LM的鲁棒性、效率和泛化能力，使其适配更广泛实际应用成为可能。

Conclusion: 该论文为大语言模型的高效、稳健适配和推广应用带来了方法突破，对实现更通用的人工智能系统迈出了关键一步。

Abstract: Language models (LMs) have demonstrated remarkable capabilities in NLP, yet
adapting them efficiently and robustly to specific tasks remains challenging.
As their scale and complexity grow, fine-tuning LMs on labelled data often
underutilizes available unlabelled data, leads to overfitting on small
task-specific sets, and imposes significant computational costs. These
limitations hamper their application to the open-ended landscape of real-world
language tasks.
  This thesis proposes a series of methods to better adapt LMs to downstream
applications. First, we explore strategies for extracting task-relevant
knowledge from unlabelled data, introducing a novel continued pre-training
technique that outperforms state-of-the-art semi-supervised approaches. Next,
we present a parameter-efficient fine-tuning method that substantially reduces
memory and compute costs while maintaining competitive performance. We also
introduce improved supervised fine-tuning methods that enable LMs to better
follow instructions, especially when labelled data is scarce, enhancing their
performance across a range of NLP tasks, including open-ended generation.
Finally, we develop new evaluation methods and benchmarks, such as multi-hop
spatial reasoning tasks, to assess LM capabilities and adaptation more
comprehensively.
  Through extensive empirical studies across diverse NLP tasks, our results
demonstrate that these approaches substantially improve LM robustness,
efficiency, and generalization, making them more adaptable to a broad range of
applications. These advances mark a significant step towards more robust and
efficient LMs, bringing us closer to the goal of artificial general
intelligence.

</details>


### [21] ["What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets](https://arxiv.org/abs/2506.21532)
*Akshay Paruchuri,Maryam Aziz,Rohit Vartak,Ayman Ali,Best Uchehara,Xin Liu,Ishan Chatterjee,Monica Agrawal*

Main category: cs.CL

TL;DR: 本文构建了HealthChat-11K医疗健康对话数据集，系统分析了用户与LLM互动时的行为特征和风险，指出LLM在医疗支持应用中的不足，数据集和分析结果已开源。


<details>
  <summary>Details</summary>
Motivation: 越来越多的人通过互动聊天机器人从大型语言模型(LLMs)中寻求医疗健康信息，但这些对话的性质和潜在风险仍未被充分探索。

Method: 作者从大规模对话式AI数据集中筛选并整理出HealthChat-11K数据集，包含11,000个真实世界对话和25,000条用户消息，并使用临床医生主导的用户交互分类体系，系统分析用户在21个健康专业领域与LLM的交互。

Result: 分析揭示了用户寻求健康信息时的互动常见模式、不完整语境、情感性行为，以及用户提问可能诱导模型过度顺从等问题，指出LLM在医疗支持方面仍需改进。

Conclusion: 当前基于LLM的对话式AI在医疗健康支持方面存在很多挑战，需针对用户互动特征和潜在风险进行进一步优化。作者公开了分析结果和数据集。

Abstract: People are increasingly seeking healthcare information from large language
models (LLMs) via interactive chatbots, yet the nature and inherent risks of
these conversations remain largely unexplored. In this paper, we filter
large-scale conversational AI datasets to achieve HealthChat-11K, a curated
dataset of 11K real-world conversations composed of 25K user messages. We use
HealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs
when seeking healthcare information in order to systematically study user
interactions across 21 distinct health specialties. Our analysis reveals
insights into the nature of how and why users seek health information, such as
common interactions, instances of incomplete context, affective behaviors, and
interactions (e.g., leading questions) that can induce sycophancy, underscoring
the need for improvements in the healthcare support capabilities of LLMs
deployed as conversational AI. Code and artifacts to retrieve our analyses and
combine them into a curated dataset can be found here:
https://github.com/yahskapar/HealthChat

</details>


### [22] [FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language](https://arxiv.org/abs/2506.20920)
*Guilherme Penedo,Hynek Kydlíček,Vinko Sabolčec,Bettina Messmer,Negar Foroutan,Amir Hossein Kargaran,Colin Raffel,Martin Jaggi,Leandro Von Werra,Thomas Wolf*

Main category: cs.CL

TL;DR: 提出一种自动适用于多语种的数据集过滤与去重流程，能生成优于现有的多语种预训练数据集，公开了覆盖1000多种语言、5亿文档的FineWeb2大规模语料，显著推动多语种大模型训练。


<details>
  <summary>Details</summary>
Motivation: 当前高质量英文大模型预训练数据集的开放取得了较大进展，但多语种大模型的训练依旧面临挑战，主要源于过滤与去重流程难以适用于多种语言。

Method: 提出基于FineWeb的新型预训练数据集处理流水线，能够自动适用于任何语言，并通过一套基于测量标准精选的评测任务，对不同流水线设计进行详细消融实验。此外，引入支持质量与去重兼顾的简单再平衡方法。

Result: 所提出的流水线可用于构建出优于现有数据集的非英文语料，进一步提升大模型表现。再平衡方法带来性能提升。最终，使用近100个Common Crawl快照，将流水线扩展到1000余种语言，生成FineWeb2这一包含5亿文档、20TB规模的新多语种数据集。相关资源与代码公开。

Conclusion: 本文解决了多语种大模型训练中数据集自动化过滤与去重难题，提出的泛用数据集构建流水线和再平衡方法显著提升了非英文模型表现，推出了大规模多语种数据集FineWeb2，为多语种大模型研究提供重要支持。

Abstract: Pre-training state-of-the-art large language models (LLMs) requires vast
amounts of clean and diverse text data. While the open development of large
high-quality English pre-training datasets has seen substantial recent
progress, training performant multilingual LLMs remains a challenge, in large
part due to the inherent difficulty of tailoring filtering and deduplication
pipelines to a large number of languages. In this work, we introduce a new
pre-training dataset curation pipeline based on FineWeb that can be
automatically adapted to support any language. We extensively ablate our
pipeline design choices on a set of nine diverse languages, guided by a set of
meaningful and informative evaluation tasks that were chosen through a novel
selection process based on measurable criteria. Ultimately, we show that our
pipeline can be used to create non-English corpora that produce more performant
models than prior datasets. We additionally introduce a straightforward and
principled approach to rebalance datasets that takes into consideration both
duplication count and quality, providing an additional performance uplift.
Finally, we scale our pipeline to over 1000 languages using almost 100 Common
Crawl snapshots to produce FineWeb2, a new 20 terabyte (5 billion document)
multilingual dataset which we release along with our pipeline, training, and
evaluation codebases.

</details>


### [23] [KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model](https://arxiv.org/abs/2506.20923)
*Xinping Zhao,Xinshuo Hu,Zifei Shan,Shouzheng Huang,Yao Zhou,Zetian Sun,Zhenyu Liu,Dongfang Li,Xinyuan Wei,Qian Chen,Youcheng Pan,Yang Xiang,Meishan Zhang,Haofen Wang,Jun Yu,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: 本文提出KaLM-Embedding-V2小体积通用嵌入模型，通过架构和训练流程创新，实现了媲美甚至超越多倍大模型的中英文表现，适用于多场景高效文本表示。


<details>
  <summary>Details</summary>
Motivation: 面对通用文本嵌入模型对高效、泛化性能和紧凑模型体积的迫切需求，现有方法在模型结构和训练方式上存在局限，难以兼顾多语种、多任务表现与模型紧凑度，因此需要改进模型架构与训练流程。

Method: 提出KaLM-Embedding-V2模型，采用完全双向Transformer结构，移除因果掩码并结合均值池化生成定长向量。采用多阶段训练：包括大规模预训练、高质量数据微调及模型参数融合，配合焦点式重加权机制和在线难负样本混合，提升模型泛化及区分能力。数据方面收集了20余类预训练、100类微调数据，覆盖广泛场景。

Result: 模型在中英文Massive Text Embedding Benchmark (MTEB)上取得显著优于同体积模型的表现，并能媲美体积分别为自身3至26倍的大模型，树立了小于10亿参数嵌入模型的新标杆。

Conclusion: KaLM-Embedding-V2通过改进结构和训练流程，大幅提升了紧凑型嵌入模型的泛用性能，在不同任务和多语种环境中表现优异，兼具效率和精度，有望成为新一代文本嵌入领域的主流解决方案。

Abstract: In this paper, we propose KaLM-Embedding-V2, a versatile and compact
embedding model, which achieves impressive performance in general-purpose text
embedding tasks by leveraging superior training techniques and data. Our key
innovations include: (1) To better align the architecture with representation
learning, we remove the causal attention mask and adopt a fully bidirectional
transformer with simple yet effective mean-pooling to produce fixed-length
embeddings; (2) We employ a multi-stage training pipeline: (i) pre-training on
large-scale weakly supervised open-source corpora; (ii) fine-tuning on
high-quality retrieval and non-retrieval datasets; and (iii) model-soup
parameter averaging for robust generalization. Besides, we introduce a
focal-style reweighting mechanism that concentrates learning on difficult
samples and an online hard-negative mixing strategy to continuously enrich hard
negatives without expensive offline mining; (3) We collect over 20 categories
of data for pre-training and 100 categories of data for fine-tuning, to boost
both the performance and generalization of the embedding model. Extensive
evaluations on the Massive Text Embedding Benchmark (MTEB) Chinese and English
show that our model significantly outperforms others of comparable size, and
competes with 3x, 14x, 18x, and 26x larger embedding models, setting a new
standard for a versatile and compact embedding model with less than 1B
parameters.

</details>


### [24] [Can Gradient Descent Simulate Prompting?](https://arxiv.org/abs/2506.20989)
*Eric Zhang,Leshem Choshen,Jacob Andreas*

Main category: cs.CL

TL;DR: 本文提出了一种新型元训练方法，使得语言模型通过梯度更新可模拟prompt推理优势，无需真实标签，部分情况下性能与直接prompt相当，为模型泛化和长上下文处理能力开辟新途径。


<details>
  <summary>Details</summary>
Motivation: 当前将新知识融入大模型有两条主要路径：prompt和参数更新。prompt对特定任务表现更好，但参数微调存储成本低。作者探寻是否能让微调过程近似模拟prompt的推理优势。

Method: 提出一种元训练语言模型的方法，使其梯度更新过程能够模拟对新信息的条件化。具体做法是将模型自身prompt预测结果作为训练目标，无需真实标签，通过基于梯度的元学习进行训练。

Result: 所提出方法在“reversal curse”等任务和基于文本单步梯度更新问答方面，有显著改进，部分情况下完全恢复prompt模型的表现。方法对长上下文建模和梯度学习的泛化能力提供了新见解。

Conclusion: 实验表明，通过适当初始化，梯度下降可以很好地模拟基于prompt的推理效果，在部分任务下甚至可以完全恢复prompt模型的性能，表明梯度更新的泛化能力远超预期。

Abstract: There are two primary ways of incorporating new information into a language
model (LM): changing its prompt or changing its parameters, e.g. via
fine-tuning. Parameter updates incur no long-term storage cost for model
changes. However, for many model updates, prompting is significantly more
effective: prompted models can generalize robustly from single examples and
draw logical inferences that do not occur under standard fine-tuning. Can
models be modified so that fine-tuning does emulate prompting? This paper
describes a method for meta-training LMs such that gradient updates emulate the
effects of conditioning on new information. Our approach uses tools from
gradient-based meta-learning but uses an LM's own prompted predictions as
targets, eliminating the need for ground-truth labels. Subsequent gradient
descent training recovers some (and occasionally all) of prompted model
performance -- showing improvement on the ``reversal curse'' tasks, and
answering questions about text passages after a single gradient update. These
results suggest that, with appropriate initialization, gradient descent can be
surprisingly expressive. Our results suggest new avenues for long-context
modeling and offer insight into the generalization capabilities of
gradient-based learning.

</details>


### [25] [SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control](https://arxiv.org/abs/2506.20993)
*Adithya Chittem,Aishna Shrivastava,Sai Tarun Pendela,Jagat Sesh Challa,Dhruv Kumar*

Main category: cs.CL

TL;DR: 本文提出了一种基于16PF模型和特定属性控制（SAC）框架的方法，实现了对大语言模型人格特质及其强度的细致、可控建模。实验验证了方法的有效性及一致性，为实现更自然的人机交互提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 当前大部分大语言模型（LLM）的人格建模主要依靠粗粒度的OCEAN大五人格模型，且缺乏对人格特质强度的控制机制，无法满足对细致、类人互动的需求。

Method: 本文将机器人格量表（MPI）从大五人格模型扩展到16种人格因子的16PF模型，并提出了特定属性控制（SAC）框架。方法包括利用形容词语义锚定来引导特质强度表达，并通过涵盖频率、深度、阈值、努力度和意愿度五种强度因子的行为问题进行评估和动态诱导。

Result: 实验表明，将特质强度建模为连续谱而非二元开关可获得更一致、可控的人格表达。特质强度的变化也会以心理学一致的方式系统性影响相关特质，说明LLM能够内化多维人格结构。

Conclusion: 该研究为LLM实现受控、细致的人格建模开辟了新途径，有助于推动医疗、教育和面试等领域的人机交互，实现更类人的社会化机器。

Abstract: Large language models (LLMs) have gained significant traction across a wide
range of fields in recent years. There is also a growing expectation for them
to display human-like personalities during interactions. To meet this
expectation, numerous studies have proposed methods for modelling LLM
personalities through psychometric evaluations. However, most existing models
face two major limitations: they rely on the Big Five (OCEAN) framework, which
only provides coarse personality dimensions, and they lack mechanisms for
controlling trait intensity. In this paper, we address this gap by extending
the Machine Personality Inventory (MPI), which originally used the Big Five
model, to incorporate the 16 Personality Factor (16PF) model, allowing
expressive control over sixteen distinct traits. We also developed a structured
framework known as Specific Attribute Control (SAC) for evaluating and
dynamically inducing trait intensity in LLMs. Our method introduces
adjective-based semantic anchoring to guide trait intensity expression and
leverages behavioural questions across five intensity factors:
\textit{Frequency}, \textit{Depth}, \textit{Threshold}, \textit{Effort}, and
\textit{Willingness}. Through experimentation, we find that modelling intensity
as a continuous spectrum yields substantially more consistent and controllable
personality expression compared to binary trait toggling. Moreover, we observe
that changes in target trait intensity systematically influence closely related
traits in psychologically coherent directions, suggesting that LLMs internalize
multi-dimensional personality structures rather than treating traits in
isolation. Our work opens new pathways for controlled and nuanced human-machine
interactions in domains such as healthcare, education, and interviewing
processes, bringing us one step closer to truly human-like social machines.

</details>


### [26] [Large Language Models Acing Chartered Accountancy](https://arxiv.org/abs/2506.21031)
*Jatin Gupta,Akhil Sharma,Saransh Singhania,Mohammad Adnan,Sakshi Deo,Ali Imam Abidi,Keshav Gupta*

Main category: cs.CL

TL;DR: 作者提出CA-Ben，首个面向印度注册会计师考试的LLM评测基准，分析了六款主流大模型在财务、法律及定量推理任务下的表现。结果显示，主流模型在概念和法律推理上表现较好，但在数值与复杂法律分析上仍有限，未来提升方向为混合推理及增强检索方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在自然语言处理领域已广泛应用，但它们在金融等专业领域中的实际知识掌握和应用能力仍不明确，特别是在印度复杂的金融语境下。本文致力于填补评估LLM金融领域能力的工具缺口。

Method: 提出CA-Ben基准，即专为印度注册会计师（CA）考试设计的评测数据集，涵盖财务、法律和定量推理能力。数据集来源于ICAI的不同阶段（基础、中级、高级）考试题目。采用标准化协议，对六大主流LLM（GPT-4o、LLAMA 3.3 70B、LLAMA 3.1 405B、MISTRAL Large、Claude 3.5 Sonnet、Microsoft Phi 4）进行系统性评价。

Result: 各模型在CA-Ben基准下表现差异明显，其中Claude 3.5 Sonnet和GPT-4o在概念和法律推理方面表现最优；但在数值计算及法律解释方面存在显著挑战。

Conclusion: 现有LLM在金融和法律推理上有所突破，但在复杂定量分析和精确法律理解上仍有明显短板。未来可通过混合推理及检索增强生成技术提升性能。

Abstract: Advanced intelligent systems, particularly Large Language Models (LLMs), are
significantly reshaping financial practices through advancements in Natural
Language Processing (NLP). However, the extent to which these models
effectively capture and apply domain-specific financial knowledge remains
uncertain. Addressing a critical gap in the expansive Indian financial context,
this paper introduces CA-Ben, a Chartered Accountancy benchmark specifically
designed to evaluate the financial, legal, and quantitative reasoning
capabilities of LLMs. CA-Ben comprises structured question-answer datasets
derived from the rigorous examinations conducted by the Institute of Chartered
Accountants of India (ICAI), spanning foundational, intermediate, and advanced
CA curriculum stages. Six prominent LLMs i.e. GPT 4o, LLAMA 3.3 70B, LLAMA 3.1
405B, MISTRAL Large, Claude 3.5 Sonnet, and Microsoft Phi 4 were evaluated
using standardized protocols. Results indicate variations in performance, with
Claude 3.5 Sonnet and GPT-4o outperforming others, especially in conceptual and
legal reasoning. Notable challenges emerged in numerical computations and legal
interpretations. The findings emphasize the strengths and limitations of
current LLMs, suggesting future improvements through hybrid reasoning and
retrieval-augmented generation methods, particularly for quantitative analysis
and accurate legal interpretation.

</details>


### [27] [A Semi-supervised Scalable Unified Framework for E-commerce Query Classification](https://arxiv.org/abs/2506.21049)
*Chunyuan Yuan,Chong Zhang,Zheng Fang,Ming Pang,Xue Jiang,Changping Peng,Zhangang Lin,Ching Law*

Main category: cs.CL

TL;DR: 该论文提出了一个半监督可扩展统一框架（SSUF），用多种增强模块解决电商查询分类中的信息不足和优化低效问题，在实际实验中效果显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 电商平台中的查询分类任务（如意图和类别预测）很重要，但由于查询短、信息不足及标签间信息不可用，导致建模面临先验信息不足的问题。现有方法依赖用户的点击行为构造训练样本，会陷入“马太效应”恶性循环；同时各子任务缺乏统一框架，算法优化效率低。

Method: 提出了一种新颖的半监督可扩展统一框架（SSUF），包含知识增强、标签增强和结构增强三大模块：知识增强模块利用世界知识提升查询表达能力；标签增强模块结合标签语义和半监督信号，减少对后验标签的依赖；结构增强模块结合标签间复杂关系提升标签表达。所有模块均可灵活插拔，根据具体子任务定制输入特征。

Result: 在大量离线与线上A/B实验中，SSUF在查询分类任务上明显优于当前最先进的方法。

Conclusion: SSUF实现了电商查询分类任务的模块化统一建模，有效缓解了查询信息不足和对用户行为依赖的问题，提升了整体性能。

Abstract: Query classification, including multiple subtasks such as intent and category
prediction, is vital to e-commerce applications. E-commerce queries are usually
short and lack context, and the information between labels cannot be used,
resulting in insufficient prior information for modeling. Most existing
industrial query classification methods rely on users' posterior click behavior
to construct training samples, resulting in a Matthew vicious cycle.
Furthermore, the subtasks of query classification lack a unified framework,
leading to low efficiency for algorithm optimization.
  In this paper, we propose a novel Semi-supervised Scalable Unified Framework
(SSUF), containing multiple enhanced modules to unify the query classification
tasks. The knowledge-enhanced module uses world knowledge to enhance query
representations and solve the problem of insufficient query information. The
label-enhanced module uses label semantics and semi-supervised signals to
reduce the dependence on posterior labels. The structure-enhanced module
enhances the label representation based on the complex label relations. Each
module is highly pluggable, and input features can be added or removed as
needed according to each subtask. We conduct extensive offline and online A/B
experiments, and the results show that SSUF significantly outperforms the
state-of-the-art models.

</details>


### [28] [MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection](https://arxiv.org/abs/2506.21053)
*Fuqiang Niu,Genan Dai,Yisha Lu,Jiayu Liao,Xiang Li,Hu Huang,Bowen Zhang*

Main category: cs.CL

TL;DR: 本文发布了当前最大、最复杂的多轮对话立场检测数据集，并提出结合大模型的新方法LLM-CRAN，在新数据集上明显优于已有方法，有助于推进社交媒体中多方对话立场检测技术。


<details>
  <summary>Details</summary>
Motivation: 现有的立场检测主要针对单条数据，难以处理多方、多轮对话的真实社交媒体场景，主要由于缺少能反映真实社交互动的数据集，限制了对话立场检测的发展。

Method: 提出了MT2-CSD数据集，这是目前最大、对话深度最高的多目标、多轮社交对话立场检测数据集。并提出基于大语言模型增强的对话关系注意力网络（LLM-CRAN），结合LLM推理能力提升对话理解。

Result: LLM-CRAN在MT2-CSD数据集上明显优于各类强基线模型，展现了该方法在对话立场检测任务上的有效性。

Conclusion: 提出的数据集和方法共同推动了多目标、多轮对话立场检测研究的发展。LLM-CRAN很好地利用了大语言模型的优势，为社交媒体中真实复杂情境下的立场检测提供了高性能方案。

Abstract: In the realm of contemporary social media, automatic stance detection is
pivotal for opinion mining, as it synthesizes and examines user perspectives on
contentious topics to uncover prevailing trends and sentiments. Traditional
stance detection research often targets individual instances, thereby limiting
its capacity to model multi-party discussions typical in real social media
scenarios. This shortcoming largely stems from the scarcity of datasets that
authentically capture the dynamics of social media interactions, hindering
advancements in conversational stance detection. In this paper, we introduce
MT2-CSD, a comprehensive dataset for multi-target, multi-turn conversational
stance detection. To the best of our knowledge, MT2-CSD is the largest dataset
available for this purpose, comprising 24,457 annotated instances and
exhibiting the greatest conversational depth, thereby presenting new challenges
for stance detection. To address these challenges, we propose the Large
Language model enhanced Conversational Relational Attention Network (LLM-CRAN),
which exploits the reasoning capabilities of LLMs to improve conversational
understanding. We conduct extensive experiments to evaluate the efficacy of
LLM-CRAN on the MT2-CSD dataset. The experimental results indicate that
LLM-CRAN significantly outperforms strong baseline models in the task of
conversational stance detection.

</details>


### [29] [DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning](https://arxiv.org/abs/2506.21096)
*Kang He,Yuzhe Ding. Haining Wang,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: 本文提出了一种DALR方法，通过细粒度的双重对齐机制，有效提升了多模态句子表示的质量。在各类句子理解任务上表现优异，超过了主流对比方法。


<details>
  <summary>Details</summary>
Motivation: 当前多模态句子表示学习方法多聚焦于粗粒度对齐，忽视了跨模态失配和单模态语义分歧问题，导致句子表示质量下降。该研究旨在细致地解决这两个关键挑战。

Method: 提出了DALR方法，通过双重对齐机制：1）跨模态对齐采用一致性学习模块，利用辅助任务中的语义相似性进行软化负样本，提升细粒度对齐能力；2）单模态对齐结合关系排序蒸馏与全局对齐学习，更好地捕捉句子复杂的语义关系。

Result: 在句子语义相似性和迁移任务上的全面实验验证了DALR方法的有效性，结果显示其在准确率等指标上均超越了现有最优基线。

Conclusion: DALR方法在跨模态与单模态语义对齐方面取得了显著进展，实验表明其在多个任务上均优于现有方法。

Abstract: Previous multimodal sentence representation learning methods have achieved
impressive performance. However, most approaches focus on aligning images and
text at a coarse level, facing two critical challenges:cross-modal misalignment
bias and intra-modal semantic divergence, which significantly degrade sentence
representation quality. To address these challenges, we propose DALR
(Dual-level Alignment Learning for Multimodal Sentence Representation). For
cross-modal alignment, we propose a consistency learning module that softens
negative samples and utilizes semantic similarity from an auxiliary task to
achieve fine-grained cross-modal alignment. Additionally, we contend that
sentence relationships go beyond binary positive-negative labels, exhibiting a
more intricate ranking structure. To better capture these relationships and
enhance representation quality, we integrate ranking distillation with global
intra-modal alignment learning. Comprehensive experiments on semantic textual
similarity (STS) and transfer (TR) tasks validate the effectiveness of our
approach, consistently demonstrating its superiority over state-of-the-art
baselines.

</details>


### [30] [ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry](https://arxiv.org/abs/2506.21098)
*Qinwen Chen,Wenbiao Tao,Zhiwei Zhu,Mingfan Xi,Liangzhong Guo,Yuan Wang,Wei Wang,Yunshi Lan*

Main category: cs.CL

TL;DR: 本工作提出ComRAG框架，通过新颖记忆机制高效整合同步知识与历史问答，实现工业级社区问答平台实时优化，效果明显优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 社区问答平台是重要的知识库，但如何实时高效利用历史交互和外部领域知识仍是难题。现有方法对外部知识利用不足，缺乏动态历史问答的集成或缺少适合工业应用的记忆机制。

Method: 提出了ComRAG，一个检索增强生成框架，通过质心记忆机制整合静态知识与动态历史问答对，支持高效检索、生成及存储。

Result: 在三个工业级CQA数据集上，ComRAG均大幅超过所有基线方法：向量相似度提升最高25.9%，延迟降低8.7%至23.3%，数据块增长率由20.23%降至2.06%。

Conclusion: ComRAG有效整合静态与动态知识，具备优越表现和工业适应性，是社区问答平台实时问答的理想方案。

Abstract: Community Question Answering (CQA) platforms can be deemed as important
knowledge bases in community, but effectively leveraging historical
interactions and domain knowledge in real-time remains a challenge. Existing
methods often underutilize external knowledge, fail to incorporate dynamic
historical QA context, or lack memory mechanisms suited for industrial
deployment. We propose ComRAG, a retrieval-augmented generation framework for
real-time industrial CQA that integrates static knowledge with dynamic
historical QA pairs via a centroid-based memory mechanism designed for
retrieval, generation, and efficient storage. Evaluated on three industrial CQA
datasets, ComRAG consistently outperforms all baselines--achieving up to 25.9%
improvement in vector similarity, reducing latency by 8.7% to 23.3%, and
lowering chunk growth from 20.23% to 2.06% over iterations.

</details>


### [31] [Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models](https://arxiv.org/abs/2506.21119)
*Xiaoshuang Ji,Zhendong Zhao,Xiaojun Chen,Xin Zhao,Zeyao Liu*

Main category: cs.CL

TL;DR: 本文提出的Progtuning方法根据各层贡献逐步降低参与微调的Transformer块数量，能省约25%参数更新量且几乎不损失性能，并兼容现有高效微调技术，提升计算资源利用效率。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型规模不断扩大，传统微调方法需要更新所有参数，计算代价高昂。虽然参数高效微调技术能够减少更新的参数量，但现有方法通常未针对不同块的贡献分配计算资源，导致效率低下。

Method: 提出了Progtuning，这是一种结合渐进式学习的Transformer微调框架。该方法根据各Transformer块的贡献，逐步缩减需要更新的块数量，实现更高效的参数更新。

Result: Progtuning在参数更新量上减少了约25%，但仍保持了竞争力的模型性能。同时，该方法可与现有参数高效微调技术结合，适应多种微调场景，效果出色。

Conclusion: Progtuning能优化Transformer微调时的资源分配，在参数量大幅减少的同时性能不降，为参数高效微调提供了新思路。

Abstract: Fine-tuning is a promising technique for leveraging Transformer-based
language models in downstream tasks. As model sizes continue to grow, updating
all model parameters becomes increasingly costly. Parameter-efficient
fine-tuning methods effectively address this issue by selectively updating a
small subset of parameters. However, fine-tuning and most existing
parameter-efficient fine-tuning methods require updating the same number of
parameters as the initial size, ignoring the unequal contribution across
Transformer blocks and leading to extremely inefficient allocation of computing
resources. In this paper, we propose Progtuning, the novel fine-tuning
framework combined with progressive learning for Transformer-based language
models. Specifically, Progtuning progressively reduces the number of updated
transformer blocks based on the contribution. Remarkably, Progtuning optimizes
resource allocation and reduces the number of updated parameters by
approximately 25\%, while still maintaining competitive performance. And it
also exhibits high adaptability with parameter-efficient fine-tuning methods,
demonstrating excellent performance across various adaptation scenarios.

</details>


### [32] [CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment](https://arxiv.org/abs/2506.20243)
*Papa Séga Wade,Mihai Andries,Ioannis Kanellos,Thierry Moudenc*

Main category: cs.CL

TL;DR: 本文提出一种结合多种自监督语音模型和基于片段的特征融合方法，有效提升了自动口语流利度评估的准确性，尤其适用于复杂停顿与节奏特征的识别，实验结果显著超越传统基线。


<details>
  <summary>Details</summary>
Motivation: 现有自动流利度评估方法难以准确刻画非母语者的语音节奏、停顿和不流利现象，因此需要更能反映这些特征的新方法。

Method: 提出基于呼吸组片段分割和多自监督学习SSL模型（Wav2Vec2、HuBERT、WavLM）特征融合的方法，结合CNN-BiLSTM框架，利用Silero-VAD进行语音切分，特征通过可学习权重机制融合，并在片段中加入流利度标记（如语速、停顿、重复），整体网络捕捉局部与全局依赖。

Result: 在Avalinguo与Speechocean762数据集上，该方法的F1分数和Pearson相关性分别提升了2.8/6.2（Speechocean762）、4.2/4.0（Avalinguo），均超过单一SSL模型与基线方法。未来还需探讨对不规则韵律方言的泛化能力。

Conclusion: 本文提出的基于片段的多SSL特征融合方法显著提升了自动流利度评估的准确性，优于现有的Pyannote.audio分割基线，特别在F1分数和Pearson相关性方面均有较大提升。

Abstract: Automatic fluency assessment (AFA) remains challenging, particularly in
capturing speech rhythm, pauses, and disfluencies in non-native speakers. We
introduce a chunk-based approach integrating self-supervised learning (SSL)
models (Wav2Vec2, HuBERT, and WavLM) selected for their complementary strengths
in phonetic, prosodic, and noisy speech modeling, with a hierarchical
CNN-BiLSTM framework. Speech is segmented into breath-group chunks using Silero
voice activity detection (Silero-VAD), enabling fine-grained temporal analysis
while mitigating over-segmentation artifacts. SSL embeddings are fused via a
learnable weighted mechanism, balancing acoustic and linguistic features, and
enriched with chunk-level fluency markers (e.g., speech rate, pause durations,
n-gram repetitions). The CNN-BiLSTM captures local and long-term dependencies
across chunks. Evaluated on Avalinguo and Speechocean762, our approach improves
F1-score by 2.8 and Pearson correlation by 6.2 points over single SSL baselines
on Speechocean762, with gains of 4.2 F1-score and 4.0 Pearson points on
Avalinguo, surpassing Pyannote.audio-based segmentation baselines. These
findings highlight chunk-based multi-SSL fusion for robust fluency evaluation,
though future work should explore generalization to dialects with irregular
prosody.

</details>


### [33] [Compressed and Smooth Latent Space for Text Diffusion Modeling](https://arxiv.org/abs/2506.21170)
*Viacheslav Meshchaninov,Egor Chimbulatov,Alexander Shabalin,Aleksandr Abramov,Dmitry Vetrov*

Main category: cs.CL

TL;DR: Cosmos通过在压缩潜在空间中应用扩散模型，显著提升文本生成的效率和质量，有望取代传统自回归生成模型。


<details>
  <summary>Details</summary>
Motivation: 当前，自回归语言模型在文本生成领域占主导地位，但它们的顺序性带来了推理速度慢和难以维持整体连贯性的缺点。扩散模型具有并行生成和灵活控制的潜力，但受限于高维的符号级表示，难以直接应用于文本生成。

Method: 提出了一种名为Cosmos的方法，它使用压缩而平滑的潜在空间进行文本生成。该潜在空间通过一个自编码器学习，训练目标包括符号级重建和与预训练语言编码器冻结激活的对齐，从而保证语义基础稳固，并可实现基于扰动的数据增强。

Result: Cosmos方法实现了文本表示的8倍压缩，在生成质量与符号级扩散模型相当的同时，推理速度提升了2倍以上。此外，增加潜在序列长度可进一步提升甚至超越现有扩散和自回归模型的表现。

Conclusion: Cosmos在故事生成、问题生成、摘要和内容净化等多项文本生成任务上取得了可比甚至更优的表现，成为具备高效推理和高生成质量的新一代文本生成范式。

Abstract: Autoregressive language models dominate modern text generation, yet their
sequential nature introduces fundamental limitations: decoding is slow, and
maintaining global coherence remains challenging. Diffusion models offer a
promising alternative by enabling parallel generation and flexible control;
however, their application to text generation is hindered by the high
dimensionality of token-level representations. We introduce Cosmos, a novel
approach to text generation that operates entirely in a compressed, smooth
latent space tailored specifically for diffusion. This space is learned using
an autoencoder trained simultaneously for token-level reconstruction and
alignment with frozen activations from a pretrained language encoder, providing
robust semantic grounding and enabling effective perturbation-based
augmentations. Empirically, we demonstrate that text representations can be
compressed by $8\times$ while maintaining generation quality comparable to
token-level diffusion models. Furthermore, increasing the latent sequence
length allows Cosmos to surpass both diffusion-based and autoregressive
baselines. We evaluate Cosmos on four diverse generative tasks including story
generation, question generation, summarization, and detoxification and compare
it with various generative paradigms. Cosmos achieves comparable or superior
generation quality while offering more than $2\times$ faster inference.

</details>


### [34] [Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks](https://arxiv.org/abs/2506.21182)
*Isaac Chung,Imene Kerboua,Marton Kardos,Roman Solomatin,Kenneth Enevoldsen*

Main category: cs.CL

TL;DR: 本文介绍了如何通过工程化手段保证 MTEB 基准平台的可复现性、扩展性和社区协作经验，为文本嵌入模型评测提供了可持续发展的范例。


<details>
  <summary>Details</summary>
Motivation: MTEB 已成为文本嵌入模型的重要评测标准，但随着社区持续拓展，如何保证其可复现性和可扩展性成为核心工程挑战。本文旨在解决大规模基准测试平台随着任务和数据集的增加，如何保持高质量和相关性的问题，并为其他类似评测平台提供经验。

Method: 作者介绍了如何通过持续集成流水线、自动化测试、数据集完整性校验、基准结果泛化能力评估等一系列工程实践，保障 MTEB 可持续发展、可复现性和可用性。同时，讨论了社区贡献处理机制及如何便捷地扩充新任务与数据集。

Result: 这些工程措施使 MTEB 能够在保证质量的同时持续扩展，提升其在文本嵌入领域的权威性和实用性。平台的经验总结可为其它评测基准的维护者提供参考。

Conclusion: 有效的工程实践（持续集成、自动化测试、社区扩展机制等）是确保大规模基准平台质量、可复现性与扩展性的关键，这对整个机器学习评测社区具有重要借鉴价值。

Abstract: The Massive Text Embedding Benchmark (MTEB) has become a standard evaluation
platform for text embedding models. While previous work has established the
core benchmark methodology, this paper focuses on the engineering aspects that
ensure MTEB's continued reproducibility and extensibility. We present our
approach to maintaining robust continuous integration pipelines that validate
dataset integrity, automate test execution, and assess benchmark results'
generalizability. We detail the design choices that collectively enhance
reproducibility and usability. Furthermore, we discuss our strategies for
handling community contributions and extending the benchmark with new tasks and
datasets. These engineering practices have been instrumental in scaling MTEB to
become more comprehensive while maintaining quality and, ultimately, relevance
to the field. Our experiences offer valuable insights for benchmark maintainers
facing similar challenges in ensuring reproducibility and usability in machine
learning evaluation frameworks. The MTEB repository is available at:
https://github.com/embeddings-benchmark/mteb

</details>


### [35] [Prompt-Guided Turn-Taking Prediction](https://arxiv.org/abs/2506.21191)
*Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Divesh Lala,Keiko Ochi,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 作者提出了一种可通过自然语言提示动态控制轮流预测的transformer模型，既提升了预测准确率，也增强了对会话风格的适应能力。


<details>
  <summary>Details</summary>
Motivation: 对话系统和会话机器人需要精确的轮流预测模型以提升互动体验。现有方法虽然能做到实时预测，但缺乏灵活、直观的人机控制能力，难以根据具体场景或用户需求自如调整。

Method: 作者提出了一种新的基于transformer的模型，在传统VAP（语音活动投影）模型的基础上，加入了文本提示嵌入，并融合到通道内部与跨通道transformer中，实现通过自然语言指令（如“更快”“更冷静”）实时动态调整轮流预测。没有真实的文本提示数据时，利用大语言模型（LLM）生成合成提示句。

Result: 在950小时的真人对话数据上进行了实验，表明该模型不仅提升了预测准确率，还能依据不同文本提示有效调整轮流切换行为。

Conclusion: 将文本提示与transformer结合的新模型为对话系统和机器人带来更直观、灵活的轮流预测调控能力，兼具准确性和适应性的提升。

Abstract: Turn-taking prediction models are essential components in spoken dialogue
systems and conversational robots. Recent approaches leverage transformer-based
architectures to predict speech activity continuously and in real-time. In this
study, we propose a novel model that enables turn-taking prediction to be
dynamically controlled via textual prompts. This approach allows intuitive and
explicit control through instructions such as "faster" or "calmer" adapting
dynamically to conversational partners and contexts. The proposed model builds
upon a transformer-based voice activity projection (VAP) model, incorporating
textual prompt embeddings into both channel-wise transformers and a
cross-channel transformer. We evaluated the feasibility of our approach using
over 950 hours of human-human spoken dialogue data. Since textual prompt data
for the proposed approach was not available in existing datasets, we utilized a
large language model (LLM) to generate synthetic prompt sentences. Experimental
results demonstrated that the proposed model improved prediction accuracy and
effectively varied turn-taking timing behaviors according to the textual
prompts.

</details>


### [36] [Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval](https://arxiv.org/abs/2506.21222)
*Yongchan Chun,Minhyuk Kim,Dongjun Kim,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: 本文提出基于句法相似性检索的prompt，能显著提升大型语言模型在自动术语提取任务中的表现，且方法领域通用。


<details>
  <summary>Details</summary>
Motivation: 自动术语提取（ATE）对许多下游任务（如机器翻译和信息检索）很重要，但现有关于利用大型语言模型（LLM）提升ATE能力的研究很少。

Method: 提出了一种基于检索的提示方法，通过选择‘句法’（而非语义）相似的演示案例，用于few-shot设置。该句法检索方法具有领域无关性，能够更好地指引模型捕捉术语边界。

Result: 在三个专门的ATE基准数据集上进行实验，结果显示句法检索方法提升了F1-score。还分析了查询句与检索示例之间词汇重叠对模型表现的影响。

Conclusion: 句法线索对于适配LLM到术语提取任务非常重要，提出的句法检索法能跨领域、提升ATE表现。

Abstract: Automatic Term Extraction (ATE) identifies domain-specific expressions that
are crucial for downstream tasks such as machine translation and information
retrieval. Although large language models (LLMs) have significantly advanced
various NLP tasks, their potential for ATE has scarcely been examined. We
propose a retrieval-based prompting strategy that, in the few-shot setting,
selects demonstrations according to \emph{syntactic} rather than semantic
similarity. This syntactic retrieval method is domain-agnostic and provides
more reliable guidance for capturing term boundaries. We evaluate the approach
in both in-domain and cross-domain settings, analyzing how lexical overlap
between the query sentence and its retrieved examples affects performance.
Experiments on three specialized ATE benchmarks show that syntactic retrieval
improves F1-score. These findings highlight the importance of syntactic cues
when adapting LLMs to terminology-extraction tasks.

</details>


### [37] [Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](https://arxiv.org/abs/2506.21252)
*Tianyi Men,Zhuoran Jin,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 本工作提出了Agent-RewardBench，一个专为多模态大模型奖励建模能力评估的基准，覆盖多场景和细粒度奖励评估。实验表明，当前模型在奖励建模上表现有限，凸显了专项训练需求。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大模型（MLLMs）的进步，多模态智能体在实际任务中（如网页导航、具身智能）展现出潜力，但由于缺乏外部反馈，这些智能体在自我纠错和泛化方面存在困难。采用奖励模型作为外部反馈是一个有前景的方法，但目前缺乏针对智能体奖励模型的标准评估方法，因此，需要一个专门为智能体构建的奖励基准。

Method: 提出了Agent-RewardBench，这是一套专为评估多模态大模型（MLLMs）奖励建模能力而设计的基准。该基准包含三个特点：（1）多维度且贴近实际的智能体场景评估，涵盖感知、规划与安全等7类场景；（2）步级别奖励评价，能够细致评估智能体在任务各阶段的表现；（3）合适的难度与高质量，通过从10个不同模型中抽样并进行人工验证，确保任务挑战性和数据完整性。

Result: 实验证明，即使是最先进的多模态模型在该基准下的表现也有限，显示现有模型在智能体奖励建模能力上存在不足。

Conclusion: 特别针对智能体的奖励建模具有挑战性，现有多模态大模型缺乏足够的建模能力。为提高智能体系统的表现，需要针对奖励模型的专项训练。

Abstract: As Multimodal Large Language Models (MLLMs) advance, multimodal agents show
promise in real-world tasks like web navigation and embodied intelligence.
However, due to limitations in a lack of external feedback, these agents
struggle with self-correction and generalization. A promising approach is to
use reward models as external feedback, but there is no clear on how to select
reward models for agents. Thus, there is an urgent need to build a reward bench
targeted at agents. To address these challenges, we propose Agent-RewardBench,
a benchmark designed to evaluate reward modeling ability in MLLMs. The
benchmark is characterized by three key features: (1) Multiple dimensions and
real-world agent scenarios evaluation. It covers perception, planning, and
safety with 7 scenarios; (2) Step-level reward evaluation. It allows for the
assessment of agent capabilities at the individual steps of a task, providing a
more granular view of performance during the planning process; and (3)
Appropriately difficulty and high-quality. We carefully sample from 10 diverse
models, difficulty control to maintain task challenges, and manual verification
to ensure the integrity of the data. Experiments demonstrate that even
state-of-the-art multimodal models show limited performance, highlighting the
need for specialized training in agent reward modeling. Code is available at
github.

</details>


### [38] [Cat and Mouse -- Can Fake Text Generation Outpace Detector Systems?](https://arxiv.org/abs/2506.21274)
*Andrea McGlinchey,Peter J Barclay*

Main category: cs.CL

TL;DR: 大模型生成伪文能力增强，但简单分类器依然有检测作用，不是无法应对的“军备竞赛”。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）可以生成具有欺骗性的“伪造文本”，在学术写作、产品评论和政治新闻等领域带来了挑战，因此，需要研究和评估检测人工生成文本的方法。

Method: 本文采用统计分类器，针对经典侦探小说风格的文本，评估其检测“伪造文本”的能力，并比较了不同模型（如Gemini和GPT）生成欺骗性文本的能力随版本变化的情况。

Result: 在0.5版本的升级过程中，Gemini模型生成欺骗性文本的能力有所提升，而GPT模型则没有明显变化。

Conclusion: 尽管LLM体量和能力增强，简单的分类器依然能有效检测伪造文本，但新架构的模型依然可能提升文本的欺骗性。

Abstract: Large language models can produce convincing "fake text" in domains such as
academic writing, product reviews, and political news. Many approaches have
been investigated for the detection of artificially generated text. While this
may seem to presage an endless "arms race", we note that newer LLMs use ever
more parameters, training data, and energy, while relatively simple classifiers
demonstrate a good level of detection accuracy with modest resources. To
approach the question of whether the models' ability to beat the detectors may
therefore reach a plateau, we examine the ability of statistical classifiers to
identify "fake text" in the style of classical detective fiction. Over a 0.5
version increase, we found that Gemini showed an increased ability to generate
deceptive text, while GPT did not. This suggests that reliable detection of
fake text may remain feasible even for ever-larger models, though new model
architectures may improve their deceptiveness

</details>


### [39] [Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning](https://arxiv.org/abs/2506.21285)
*Xin Xu,Tianhao Chen,Fan Zhang,Wanlong Liu,Pengxiang Li,Ajay Kumar Jaiswal,Yuchen Yan,Jishan Hu,Yang Wang,Hao Chen,Shiwei Liu,Shizhe Diao,Can Yang,Lu Yin*

Main category: cs.CL

TL;DR: 本文提出Double-Checker框架，通过自我批评与迭代修正大幅提升LLM推理表现，为构建更可靠高效的语言模型提供新思路。


<details>
  <summary>Details</summary>
Motivation: 目前慢速思考的大型语言模型（LLMs）虽能展现类似“顿悟”式的推理能力，但其生成有价值自我批判与改进之前答案的能力仍有限。因此，希望通过改进机制提升其推理与自我完善的表现。

Method: 提出了Double-Checker框架，通过精心筛选的1730个自我批判实例对长链思考（long-CoT）模型进行微调，使其在推理推断过程中能显式自我批判与多轮迭代自我修正答案，直至输出被自评为正确。

Result: 在多个推理基准测试中，Double-Checker能显著提升长链推理模型的推理能力，特别是在具有挑战性的AIME基准测试中，pass@1指标由4.4%提升到18.2%。

Conclusion: Double-Checker作为结构化自我批判机制，有效提升了LLM推理可信度和能力，是开发更可信赖和高效LLM的一条有前景的路径。

Abstract: While slow-thinking large language models (LLMs) exhibit reflection-like
reasoning, commonly referred to as the "aha moment:, their ability to generate
informative critiques and refine prior solutions remains limited. In this
paper, we introduce Double-Checker, a principled framework designed to enhance
the reasoning capabilities of slow-thinking LLMs by fostering explicit
self-critique and iterative refinement of their previous solutions. By
fine-tuning on our curated 1,730 self-critical instances, Double-Checker
empowers long-CoT LLMs to iteratively critique and refine their outputs during
inference until they evaluate their solutions as correct under self-generated
critiques. We validate the efficacy of Double-Checker across a comprehensive
suite of reasoning benchmarks, demonstrating that iterative self-critique
significantly enhances the reasoning capabilities of long-CoT LLMs. Notably,
our Double-Checker increases the pass@1 performance on challenging AIME
benchmarks from 4.4% to 18.2% compared to the original long-CoT LLMs. These
results highlight a promising direction for developing more trustworthy and
effective LLMs capable of structured self-critique.

</details>


### [40] [Small Encoders Can Rival Large Decoders in Detecting Groundedness](https://arxiv.org/abs/2506.21288)
*Istabrak Abbes,Gabriele Prato,Quentin Fournier,Fernando Rodriguez,Alaa Boukhary,Adam Elwood,Sarath Chandar*

Main category: cs.CL

TL;DR: 本文提出用经过微调的RoBERTa、NomicBERT等轻量级模型预先检测查询是否基于上下文，能以极低延迟实现与大型语言模型类似的准确率，显著减少算力消耗，适用于大模型推理前的高效筛查。


<details>
  <summary>Details</summary>
Motivation: 尽管为大型语言模型（LLMs）提供外部上下文能显著提升其在自然语言处理任务中的表现，但当上下文缺少关键信息时，LLMs 仍常常产生脱离现实的猜测或仅凭自身知识作答。因此，检测模型回答是否真正基于上下文（即“根植性”）成为一个亟待解决的问题。

Method: 本文提出在 LLMs 生成答案前，先利用轻量级、任务专用的编码器模型（如 RoBERTa 和 NomicBERT，经精细微调）检测查询是否根植于提供的文档上下文。

Result: 实验证明，经过精细微调的编码器模型在检测根植性任务上能与当前最先进的大型语言模型（例如 Llama3 8B 和 GPT4o）达到相当的准确度，但推理延迟却大幅降低。

Conclusion: 采用轻量级、专用编码器模型进行根植性检测，不仅可以大幅提升推理效率，还能在保证检测准确性的同时，节约计算资源。此方法为 LLMs 在依赖外部知识进行问答时的可靠性和可用性提供了有效保障。

Abstract: Augmenting large language models (LLMs) with external context significantly
improves their performance in natural language processing (NLP) tasks. However,
LLMs struggle to answer queries reliably when the provided context lacks
information, often resorting to ungrounded speculation or internal knowledge.
Groundedness - generating responses strictly supported by the context - is
essential for ensuring factual consistency and trustworthiness. This study
focuses on detecting whether a given query is grounded in a document provided
in context before the costly answer generation by LLMs. Such a detection
mechanism can significantly reduce both inference time and resource
consumption. We show that lightweight, task specific encoder models such as
RoBERTa and NomicBERT, fine-tuned on curated datasets, can achieve accuracy
comparable to state-of-the-art LLMs, such as Llama3 8B and GPT4o, in
groundedness detection while reducing inference latency by orders of magnitude.
The code is available at : https://github.com/chandarlab/Hallucinate-less

</details>


### [41] [Detecting Referring Expressions in Visually Grounded Dialogue with Autoregressive Language Models](https://arxiv.org/abs/2506.21294)
*Bram Willemsen,Gabriel Skantze*

Main category: cs.CL

TL;DR: 本文表明，纯文本LLM方法能有效抽取视觉语境对话中的指代表达，但由于任务的多模态本质，仍有不可逾越的限制。


<details>
  <summary>Details</summary>
Motivation: 研究纯文本自回归语言模型在从视觉语境对话中抽取指代表达的有效性，探究仅靠语言上下文在多模态任务中的作用。

Method: 将预训练的大型语言模型(LLM)微调应用于对话中的指代表达抽取，仅依赖文本信息，通过下一个token预测方法划定提及边界。

Result: 中等规模LLM、较小数据集和高效参数微调下，纯文本方法能取得较好成效，说明语言上下文对该任务非常重要。

Conclusion: 仅使用文本和自回归语言模型也能在一定程度上有效提取对话中的指代表达，但该任务本质上仍是多模态问题，单一模态有其局限性。

Abstract: In this paper, we explore the use of a text-only, autoregressive language
modeling approach for the extraction of referring expressions from visually
grounded dialogue. More specifically, the aim is to investigate the extent to
which the linguistic context alone can inform the detection of mentions that
have a (visually perceivable) referent in the visual context of the
conversation. To this end, we adapt a pretrained large language model (LLM) to
perform a relatively course-grained annotation of mention spans in unfolding
conversations by demarcating mention span boundaries in text via next-token
prediction. Our findings indicate that even when using a moderately sized LLM,
relatively small datasets, and parameter-efficient fine-tuning, a text-only
approach can be effective, highlighting the relative importance of the
linguistic context for this task. Nevertheless, we argue that the task
represents an inherently multimodal problem and discuss limitations fundamental
to unimodal approaches.

</details>


### [42] [Structuralist Approach to AI Literary Criticism: Leveraging Greimas Semiotic Square for Large Language Models](https://arxiv.org/abs/2506.21360)
*Fangzhou Dong,Yifan Zeng,Yingpeng Sang,Hong Shen*

Main category: cs.CL

TL;DR: 提出GLASS框架，通过结构化方法让大模型也能做出高质量文学批评，并公开首个相关数据集，评测效果优于以往方法，对学界和教学具有应用价值。


<details>
  <summary>Details</summary>
Motivation: 当前大模型虽能理解和生成文本，但难以对思想深邃、叙事复杂的文学作品作出专业批评分析。为提升LLM在深层文学批评场景的能力，作者希望引入结构化分析工具和数据集。

Method: 1. 基于格雷马斯符号学方阵（GSS）提出GLASS结构化分析框架；2. 构建了首个GSS文学批评数据集（包含48部作品的详细分析）；3. 提出基于LLM-as-a-judge范式的量化评测指标；4. 用GLASS分析39部经典作品，并与专家批评结果进行对比评估。

Result: GLASS能帮助LLM快速剖析叙事结构与深层意义，分析结果与专家水平接近，大大弥补了现有LLM在文学批评领域的不足。

Conclusion: 该研究提出的GLASS框架能显著提升大型语言模型在文学批评中的表现，能够生成与专家相媲美的高质量分析，并为文学研究和教育提供了强有力的AI工具。

Abstract: Large Language Models (LLMs) excel in understanding and generating text but
struggle with providing professional literary criticism for works with profound
thoughts and complex narratives. This paper proposes GLASS (Greimas Literary
Analysis via Semiotic Square), a structured analytical framework based on
Greimas Semiotic Square (GSS), to enhance LLMs' ability to conduct in-depth
literary analysis. GLASS facilitates the rapid dissection of narrative
structures and deep meanings in narrative works. We propose the first dataset
for GSS-based literary criticism, featuring detailed analyses of 48 works. Then
we propose quantitative metrics for GSS-based literary criticism using the
LLM-as-a-judge paradigm. Our framework's results, compared with expert
criticism across multiple works and LLMs, show high performance. Finally, we
applied GLASS to 39 classic works, producing original and high-quality analyses
that address existing research gaps. This research provides an AI-based tool
for literary research and education, offering insights into the cognitive
mechanisms underlying literary engagement.

</details>


### [43] [Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21384)
*Guanting Dong,Xiaoxi Li,Yuyao Zhang,Mengjie Deng*

Main category: cs.CL

TL;DR: Omni-RAG是一种新型RAG系统框架，通过三大模块强化对复杂、含噪、多意图查询的处理，有效提升了实际应用场景下的鲁棒性与效果。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG（Retrieval-Augmented Generation）系统在应对真实世界中的用户查询时面临困难，尤其是对于噪声大、歧义重和多意图的复杂查询。这些系统通常只在干净的数据上训练或评估，难以满足实际应用需求。

Method: 提出了Omni-RAG框架，通过LLM辅助的查询理解模块预处理用户输入，包括：1. 深度查询理解与分解，利用LLM和定制化提示纠正拼写等噪声，并将多意图查询拆解为结构化子查询；2. 基于意图的知识检索，对每个子查询执行检索并聚合结果（使用FineWeb与OpenSearch）；3. 重排序与生成，先由重排序器BGE优化结果，再由Falcon-10B大模型通过链式思维提示生成最终回复。

Result: Omni-RAG显著提升了RAG系统在现实开放域场景中处理复杂、多噪声用户查询的鲁棒性和有效性。

Conclusion: Omni-RAG有效弥补了当前RAG系统与现实应用之间的差距，特别是在应对复杂、含噪、多意图查询方面表现出更强的能力，适用于SIGIR 2025 LiveRAG Challenge等实际需求场景。

Abstract: Real-world live retrieval-augmented generation (RAG) systems face significant
challenges when processing user queries that are often noisy, ambiguous, and
contain multiple intents. While RAG enhances large language models (LLMs) with
external knowledge, current systems typically struggle with such complex
inputs, as they are often trained or evaluated on cleaner data. This paper
introduces Omni-RAG, a novel framework designed to improve the robustness and
effectiveness of RAG systems in live, open-domain settings. Omni-RAG employs
LLM-assisted query understanding to preprocess user inputs through three key
modules: (1) Deep Query Understanding and Decomposition, which utilizes LLMs
with tailored prompts to denoise queries (e.g., correcting spelling errors) and
decompose multi-intent queries into structured sub-queries; (2) Intent-Aware
Knowledge Retrieval, which performs retrieval for each sub-query from a corpus
(i.e., FineWeb using OpenSearch) and aggregates the results; and (3) Reranking
and Generation, where a reranker (i.e., BGE) refines document selection before
a final response is generated by an LLM (i.e., Falcon-10B) using a
chain-of-thought prompt. Omni-RAG aims to bridge the gap between current RAG
capabilities and the demands of real-world applications, such as those
highlighted by the SIGIR 2025 LiveRAG Challenge, by robustly handling complex
and noisy queries.

</details>


### [44] [Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](https://arxiv.org/abs/2506.21443)
*Ali Şenol,Garima Agrawal,Huan Liu*

Main category: cs.CL

TL;DR: 该文提出结合领域知识和大型语言模型的新方法，分三个模块检测和分类动态对话中的欺诈及概念漂移。实验证明新方法明显优于传统零样本基线，分类准确率高达98%，特别适合高风险NLP任务。


<details>
  <summary>Details</summary>
Motivation: 在动态平台上检测欺骗性对话变得越来越困难，主要由于语言模式的不断演化和概念漂移（即语义或主题随时间变化），这些变化可能掩盖恶意行为或模仿正常对话，从而让分类更加具有挑战性。

Method: 提出了一个基于领域知识（DK）增强的大语言模型（LLM）框架，将预训练LLM和结构化、任务相关的领域知识相结合，用于欺诈检测和概念漂移检测。框架包括三个主要组成部分：（1）DK-LLM模块用于检测虚假或欺骗性对话；（2）漂移检测单元（OCDD）判断是否发生语义漂移；（3）第二个DK-LLM模块用于将漂移分类为良性或欺诈。

Result: 系统能够高精度地检测虚假对话，有效分类漂移的性质。LLaMA实现版本在分类精度上达到98%。与零样本基线比较，域知识和漂移感知的引入显著提升了系统性能、可解释性和稳健性。

Conclusion: 将领域知识和语义漂移检测融合进LLM，有助于提高检测各类欺骗、漂移行为的准确性和稳健性，特别适用于高风险自然语言处理任务。

Abstract: Detecting deceptive conversations on dynamic platforms is increasingly
difficult due to evolving language patterns and Concept Drift (CD)-i.e.,
semantic or topical shifts that alter the context or intent of interactions
over time. These shifts can obscure malicious intent or mimic normal dialogue,
making accurate classification challenging. While Large Language Models (LLMs)
show strong performance in natural language tasks, they often struggle with
contextual ambiguity and hallucinations in risk-sensitive scenarios. To address
these challenges, we present a Domain Knowledge (DK)-Enhanced LLM framework
that integrates pretrained LLMs with structured, task-specific insights to
perform fraud and concept drift detection. The proposed architecture consists
of three main components: (1) a DK-LLM module to detect fake or deceptive
conversations; (2) a drift detection unit (OCDD) to determine whether a
semantic shift has occurred; and (3) a second DK-LLM module to classify the
drift as either benign or fraudulent. We first validate the value of domain
knowledge using a fake review dataset and then apply our full framework to
SEConvo, a multiturn dialogue dataset that includes various types of fraud and
spam attacks. Results show that our system detects fake conversations with high
accuracy and effectively classifies the nature of drift. Guided by structured
prompts, the LLaMA-based implementation achieves 98% classification accuracy.
Comparative studies against zero-shot baselines demonstrate that incorporating
domain knowledge and drift awareness significantly improves performance,
interpretability, and robustness in high-stakes NLP applications.

</details>


### [45] [Text2Cypher Across Languages: Evaluating Foundational Models Beyond English](https://arxiv.org/abs/2506.21445)
*Makbule Gulcin Ozsoy,William Tai*

Main category: cs.CL

TL;DR: 本文系统评估了大语言模型在Text2Cypher数据库查询生成任务下的多语言表现，发现模型在英语、西班牙语、土耳其语依次下降，提示词本地化作用甚微，强调应推动多语种数据库检索能力的提升。


<details>
  <summary>Details</summary>
Motivation: 现有的自然语言到数据库查询的接口（如Text2SQL、Text2SPARQL、Text2Cypher）极大提升了数据库的可访问性，但大多只关注英语，而其他语言的效果鲜有评估。因此需要更全面评估多语言下模型性能，促进数据库检索方式的多语种普及。

Method: 作者构建了一个多语言的测试集，将英文问题分别翻译为西班牙语和土耳其语，同时保持原始Cypher查询不变。然后用统一的提示词和评测标准，系统地评估了多种主流大语言模型在Text2Cypher任务下的多语言性能，并探讨了将提示词本地化翻译（西班牙语、土耳其语）对模型表现的影响。

Result: 实验结果显示，模型对英文表现最佳，对西班牙语次之，对土耳其语最差。这主要归因为训练数据量和语言本身特性的差异。同时，提示词翻译几乎不影响最终效果。作者由此提出需要更具包容性的多语种数据库检索研究，未来可探索模式本地化与多语种微调。

Conclusion: 多语言环境下，现有大语言模型在数据库查询生成中的表现存在明显“英语优先”现象，而提示词本地化翻译影响甚微。呼吁未来研究加强多语种评估和技术开发，特别关注低资源语言的应用拓展。

Abstract: Recent advances in large language models have enabled natural language
interfaces that translate user questions into database queries, such as
Text2SQL, Text2SPARQL, and Text2Cypher. While these interfaces enhance database
accessibility, most research today focuses solely on English, with limited
evaluation in other languages. This paper investigates the performance of
foundational LLMs on the Text2Cypher task across multiple languages. We create
and release a multilingual test set by translating English questions into
Spanish and Turkish while preserving the original Cypher queries, enabling fair
cross-lingual comparison. We evaluate multiple foundational models using
standardized prompts and metrics. Our results show a consistent performance
pattern: highest on English, then Spanish, and lowest on Turkish. We attribute
this to differences in training data availability and linguistic
characteristics. Additionally, we explore the impact of translating task
prompts into Spanish and Turkish. Results show little to no change in
evaluation metrics, suggesting prompt translation has minor impact. Our
findings highlight the need for more inclusive evaluation and development in
multilingual query generation. Future work includes schema localization and
fine-tuning across diverse languages.

</details>


### [46] [Aligning Spoken Dialogue Models from User Interactions](https://arxiv.org/abs/2506.21463)
*Anne Wu,Laurent Mazaré,Neil Zeghidour,Alexandre Défossez*

Main category: cs.CL

TL;DR: 引入大规模偏好数据和AI反馈，提出并实证了一种适用于实时语音对话的偏好对齐新框架，有效提升系统真实性、安全性和上下文体验。


<details>
  <summary>Details</summary>
Motivation: 现有偏好学习方法主要针对文本语言模型，难以处理具有丰富动态和复杂时序的实时语音交互场景（如打断、插话、缺乏明确说话轮次分割），因此需要新的方法提升语音对话系统在实际应用中的性能。

Method: 1）构建了一个包含15万对偏好配对的大规模多轮语音对话数据集，由AI反馈标注偏好，涵盖语言内容和时序上下文变化；2）采用离线对齐方法，在全双工自回归语音-语音模型上进行微调；3）通过仿真实验和实际部署的人工评测，全面评估方法效果。

Result: 新偏好对齐框架显著提升了语音对话系统多轮交互的真实性、安全性和上下文契合度，人工评测也验证了模型对自然语音对话的加强。

Conclusion: 作者提出了一种新的偏好对齐框架，可以有效提升语音对话模型在实时对话中的表现，综合提升模型的真实性、安全性和上下文契合度。实验证明该方法在多轮对话和实际应用场景中均取得了积极成效。

Abstract: We propose a novel preference alignment framework for improving spoken
dialogue models on real-time conversations from user interactions. Current
preference learning methods primarily focus on text-based language models, and
are not directly suited to the complexities of real-time speech interactions,
with richer dynamics (e.g. interruption, interjection) and no explicit
segmentation between speaker turns.We create a large-scale dataset of more than
150,000 preference pairs from raw multi-turn speech conversations, annotated
with AI feedback, to cover preferences over both linguistic content and
temporal context variations. We leverage offline alignment methods to finetune
a full-duplex autoregressive speech-to-speech model. Extensive experiments
demonstrate that feedback on generic conversations can be consistently
effective in improving spoken dialogue models to produce more factual, safer
and more contextually aligned interactions. We deploy the finetuned model and
conduct holistic human evaluations to assess the impact beyond single-turn
conversations. Our findings shed light on the importance of a well-calibrated
balance among various dynamics, crucial for natural real-time speech dialogue
systems.

</details>


### [47] [TopK Language Models](https://arxiv.org/abs/2506.21468)
*Ryosuke Takahashi,Tatsuro Inaba,Kentaro Inui,Benjamin Heinzerling*

Main category: cs.CL

TL;DR: 本文针对SAE存在的稳定性与可用性问题，提出将TopK激活函数直接整合进transformer，免去了后续训练过程，提升了模型的可解释性和干预可控性，并实现了高效、稳定的稀疏表示。这将助力未来LM解释性与可控性研究。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAEs）在分析和解释基于transformer的语言模型激活空间时具有重要作用，但它们在可用性和内部有效性上存在诸多不足：如SAE是否未能发现某一概念究竟因自身能力限制还是因底层模型本就未表征该概念、受训练条件和结构影响导致不同checkpoint难以比较，特征不稳定等。

Method: 提出在transformer结构中于特定层引入TopK激活函数，使模型的隐藏状态与TopK SAE的潜在特征等效，从而不再需要后验训练，同时直接获得与SAE可比拟的解释性能力。

Result: TopK语言模型保持原有能力的同时，带来更强的解释性和模型稳定性，其稀疏表示有助于通过特定神经元干预进行模型调整与详细神经元分析，在不同checkpoint和层之间具有更强的特征可比性。

Conclusion: TopK LMs是一种稳定、可靠且高效的解释工具，有助于深入理解语言模型如何学习和表征概念，这将显著促进模型可解释性和可控性领域的发展。

Abstract: Sparse autoencoders (SAEs) have become an important tool for analyzing and
interpreting the activation space of transformer-based language models (LMs).
However, SAEs suffer several shortcomings that diminish their utility and
internal validity. Since SAEs are trained post-hoc, it is unclear if the
failure to discover a particular concept is a failure on the SAE's side or due
to the underlying LM not representing this concept. This problem is exacerbated
by training conditions and architecture choices affecting which features an SAE
learns. When tracing how LMs learn concepts during training, the lack of
feature stability also makes it difficult to compare SAEs features across
different checkpoints. To address these limitations, we introduce a
modification to the transformer architecture that incorporates a TopK
activation function at chosen layers, making the model's hidden states
equivalent to the latent features of a TopK SAE. This approach eliminates the
need for post-hoc training while providing interpretability comparable to SAEs.
The resulting TopK LMs offer a favorable trade-off between model size,
computational efficiency, and interpretability. Despite this simple
architectural change, TopK LMs maintain their original capabilities while
providing robust interpretability benefits. Our experiments demonstrate that
the sparse representations learned by TopK LMs enable successful steering
through targeted neuron interventions and facilitate detailed analysis of
neuron formation processes across checkpoints and layers. These features make
TopK LMs stable and reliable tools for understanding how language models learn
and represent concepts, which we believe will significantly advance future
research on model interpretability and controllability.

</details>


### [48] [Bridging Offline and Online Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.21495)
*Jack Lanchantin,Angelica Chen,Janice Lan,Xian Li,Swarnadeep Saha,Tianlu Wang,Jing Xu,Ping Yu,Weizhe Yuan,Jason E Weston,Sainbayar Sukhbaatar,Ilia Kulikov*

Main category: cs.CL

TL;DR: 本文系统比较了LLM在可验证与不可验证任务上从离线到在线多种强化学习微调方法，发现在线、半在线策略整体优于离线，多任务训练进一步提升表现。


<details>
  <summary>Details</summary>
Motivation: 强化学习在LLM微调场景下，多样任务（可验证、不可验证）和多种训练范式下的效果和差异尚不明晰，需要系统比较和分析。

Method: 比较了在线、半在线Direct Preference Optimization和Group Reward Policy Optimization目标函数，并在可验证数学任务与不可验证的指令跟随任务上进行基准测试。对训练动态及超参数选择也做了详细分析。

Result: 在线及半在线方法在所有测试中都优于离线方法；各优化方法间表现相似；多任务微调有助于两类任务的整体提升。

Conclusion: 在线、半在线强化学习方法在微调大型语言模型时，相较于纯离线方法表现更佳，而多任务结合可验证与不可验证任务能进一步提升表现。

Abstract: We investigate the effectiveness of reinforcement learning methods for
finetuning large language models when transitioning from offline to semi-online
to fully online regimes for both verifiable and non-verifiable tasks. Our
experiments cover training on verifiable math as well as non-verifiable
instruction following with a set of benchmark evaluations for both. Across
these settings, we extensively compare online and semi-online Direct Preference
Optimization and Group Reward Policy Optimization objectives, and surprisingly
find similar performance and convergence between these variants, which all
strongly outperform offline methods. We provide a detailed analysis of the
training dynamics and hyperparameter selection strategies to achieve optimal
results. Finally, we show that multi-tasking with verifiable and non-verifiable
rewards jointly yields improved performance across both task types.

</details>


### [49] [skLEP: A Slovak General Language Understanding Benchmark](https://arxiv.org/abs/2506.21508)
*Marek Šuppa,Andrej Ridzik,Daniel Hládek,Tomáš Javůrek,Viktória Ondrejová,Kristína Sásiková,Martin Tamajka,Marián Šimko*

Main category: cs.CL

TL;DR: 本文提出并公开了skLEP——首个专为斯洛伐克语自然语言理解设计的综合性评测基准，并评估多类语言模型表现，为该领域后续研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 目前斯洛伐克语自然语言理解（NLU）领域缺乏专门的评测基准，限制了模型性能的全面评估和研究进展。

Method: 作者构建了一个名为skLEP的全新评测基准，融合了九项涵盖不同层次（Token、句对和文档级别）的任务。数据集包括为斯洛伐克语定制的新数据，同时精心翻译了已有的英文NLU资源。作者还利用skLEP系统性地评估了多种斯洛伐克语、英文及多语言预训练模型。

Result: skLEP基准全面评估了多种语言模型在斯洛伐克语NLU任务上的表现，对各类模型优缺点进行了系统对比分析。基准数据、开源工具包和排行榜全部公开，便于社区复现和进一步研究。

Conclusion: skLEP作为首个斯洛伐克语NLU综合基准，为研究和推动高质量斯洛伐克语自然语言模型提供了重要基础设施，有助于推动本领域未来发展。

Abstract: In this work, we introduce skLEP, the first comprehensive benchmark
specifically designed for evaluating Slovak natural language understanding
(NLU) models. We have compiled skLEP to encompass nine diverse tasks that span
token-level, sentence-pair, and document-level challenges, thereby offering a
thorough assessment of model capabilities. To create this benchmark, we curated
new, original datasets tailored for Slovak and meticulously translated
established English NLU resources. Within this paper, we also present the first
systematic and extensive evaluation of a wide array of Slovak-specific,
multilingual, and English pre-trained language models using the skLEP tasks.
Finally, we also release the complete benchmark data, an open-source toolkit
facilitating both fine-tuning and evaluation of models, and a public
leaderboard at https://github.com/slovak-nlp/sklep in the hopes of fostering
reproducibility and drive future research in Slovak NLU.

</details>


### [50] [Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments](https://arxiv.org/abs/2506.21497)
*Jiashuo Wang,Kaitao Song,Chunpu Xu,Changhe Song,Yang Xiao,Dongsheng Li,Lili Qiu,Wenjie Li*

Main category: cs.CL

TL;DR: 该工作提出利用用户真实后续反应作为训练信号，通过交互模拟和偏好优化提升大模型在社会性对话场景中的用户参与度，并取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 以往工作虽然通过优化知识推理或对话行为促进模型效果，但在社会性对话中，知识或对话行为与用户参与度的关系并不直接，无法保证用户有效参与。因而需要新的方式使交互式大模型能够主动提升和学习用户参与度。

Method: 提出用用户在对话后的真实反应作为用户参与度的直接指标，通过开发用户模拟器与交互式大模型进行互动，并结合交互蒙特卡洛树搜索（i×MCTS）探索用户与大模型之间的互动，采集高、低质量互动体验数据。最后，采用直接偏好优化（DPO）方法来微调交互式大模型，提升其促进用户参与度的能力。

Result: 在情感支持和善意劝说两个社会性对话场景下实验证明，该方法能有效提升交互式大模型的用户参与度。

Conclusion: 通过引入未来用户反应作为奖励信号，结合模拟与偏好优化，在社会性对话中大幅提升了大模型促进用户参与度的表现。

Abstract: Enhancing user engagement through interactions plays an essential role in
socially-driven dialogues. While prior works have optimized models to reason
over relevant knowledge or plan a dialogue act flow, the relationship between
user engagement and knowledge or dialogue acts is subtle and does not guarantee
user engagement in socially-driven dialogues. To this end, we enable
interactive LLMs to learn user engagement by leveraging signals from the future
development of conversations. Specifically, we adopt a more direct and relevant
indicator of user engagement, i.e., the user's reaction related to dialogue
intention after the interaction, as a reward to align interactive LLMs. To
achieve this, we develop a user simulator to interact with target interactive
LLMs and explore interactions between the user and the interactive LLM system
via \textit{i$\times$MCTS} (\textit{M}onte \textit{C}arlo \textit{T}ree
\textit{S}earch for \textit{i}nteraction). In this way, we collect a dataset
containing pairs of higher and lower-quality experiences using
\textit{i$\times$MCTS}, and align interactive LLMs for high-level user
engagement by direct preference optimization (DPO) accordingly. Experiments
conducted on two socially-driven dialogue scenarios (emotional support
conversations and persuasion for good) demonstrate that our method effectively
enhances user engagement in interactive LLMs.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [51] [A generalised framework for phase field-based modelling of coupled problems: application to thermo-mechanical fracture, hydraulic fracture, hydrogen embrittlement and corrosion](https://arxiv.org/abs/2506.20763)
*Y. Navidtehrani,C. Betegón,E. Martínez-Pañeda*

Main category: cs.CE

TL;DR: 作者提出了一种基于相场和多物理场耦合的新方法，能在Abaqus有限元软件中通过简单子程序处理多种结构失效问题，经验证该方法准确且具有普适性，相关代码已公开。


<details>
  <summary>Details</summary>
Motivation: 现有对结构完整性耦合问题的分析方法有限，缺乏一种普适且易于在商业有限元软件中实施的多物理场耦合方法，尤其在处理热-力、流体-结构、化学腐蚀等复杂问题时更显不足。

Method: 通过将相场模型与多物理场建模相结合，利用热传导方程的通用性，仅需在积分点层级进行简单子程序（UMAT和UMATHT）开发，无需广泛修改有限元代码，即可实现复杂耦合多变量现象的模拟。

Result: 方法已在热-力断裂、水力断裂、氢致开裂和金属腐蚀等工程实际与科学相关问题上进行2D、3D数值验证，与实验数据及已有数值、解析解符合良好。用户自编子程序已开源。

Conclusion: 提出的方法能够有效地通过有限元软件Abaqus解决多种与结构完整性相关的耦合问题，具有较好的通用性和准确性。

Abstract: We present a novel, generalised formulation to treat coupled structural
integrity problems by combining phase field and multi-physics modelling. The
approach exploits the versatility of the heat transfer equation and is
therefore well suited to be adopted in commercial finite element packages,
requiring only integration point-level implementation. This aspect is
demonstrated here by implementing coupled, multi-variable phenomena through
simple \texttt{UMAT} and \texttt{UMATHT} subroutines in the finite element
package \texttt{Abaqus}. The generalised theoretical and computational
framework presented is particularised to four problems of engineering and
scientific relevance: thermo-mechanical fracture, hydraulic fracture,
hydrogen-assisted cracking and metallic corrosion. 2D and 3D problems are
considered. The results reveal a very good agreement with experimental data,
and existing numerical and analytical solutions.The user subroutines developed
are made freely available at https://mechmat.web.ox.ac.uk/codes.

</details>


### [52] [A Hereditary Integral, Transient Network Approach to Modeling Permanent Set and Viscoelastic Response in Polymers](https://arxiv.org/abs/2506.20773)
*Stephen T. Castonguay,Joshua B. Fernandes,Michael A. Puso,Sylvie Aubry*

Main category: cs.CE

TL;DR: 本文提出了一种高效的聚合物黏弹性和永久定型数值模拟方法，简化了历史积分过程，适用于多种材料模型，并能准确捕捉复杂加载下的材料行为。


<details>
  <summary>Details</summary>
Motivation: 现有聚合物材料的数值建模方法在处理历史依赖性的黏弹性和永久定型方面计算复杂性高。论文旨在提出一种更高效的数值框架，减少计算量并提高适用性。

Method: 基于瞬态网络理论的遗传积分形式，对聚合物链的不同网络进行建模。通过能量核分解，建立递推关系，从而避免对整个时间历史进行积分。该方法应用于neo-Hookean、Blatz-Ko、Yeoh和Ogden-Hill材料模型，涵盖高可压缩性和近不可压缩性的材料。

Result: 提出的框架能够高效模拟聚合物黏弹性和永久定型，并适应不同材料类型。通过多个案例验证了其对速率相关响应和复杂加载历史下残余应变的预测能力。

Conclusion: 数值框架能够高效地模拟聚合物的黏弹性和永久定型效应，并适用于不同类型的材料模型。该方法能处理加载历史复杂、速率相关的响应和残余应变。

Abstract: An efficient numerical framework is presented for modeling viscoelasticity
and permanent set of polymers. It is based on the hereditary integral form of
transient network theory, in which polymer chains belong to distinct networks
each with different natural equilibrium states. Chains continually detach from
previously formed networks and reattach to new networks in a state of zero
stress. The free energy of these networks is given in terms of the deformation
gradient relative to the configuration at which the network was born. A
decomposition of the kernel for various free energies allows for a recurrence
relationship to be established, bypassing the need to integrate over all time
history. The technique is established for both highly compressible and nearly
incompressible materials through the use of neo-Hookean, Blatz-Ko, Yeoh, and
Ogden-Hill material models. Multiple examples are presented showing the ability
to handle rate-dependent response and residual strains under complex loading
histories.

</details>


### [53] [Counterfactual Voting Adjustment for Quality Assessment and Fairer Voting in Online Platforms with Helpfulness Evaluation](https://arxiv.org/abs/2506.21362)
*Chang Liu,Yixin Wang,Moontae Lee*

Main category: cs.CE

TL;DR: 本文提出CVA因果模型修正网络投票偏见，更准确评估内容质量，在多个平台实验中效果优于传统方法，提升了内容排序的公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 网络平台需要高效获取高质量信息，用户通过发布内容和投票提高信息实用性，但投票受位置偏见和羊群效应影响，影响了内容质量的公正评估。

Method: 提出了Counterfactual Voting Adjustment（CVA）因果推断框架，用于修正用户投票中的位置和羊群偏见，通过实验验证其在内容质量评估中的有效性。

Result: CVA框架能有效建模并修正位置和羊群偏见，准确恢复内容的真实质量。实验显示，基于CVA学习到的内容质量重新排序结果与用户情感和GPT-4o质量评判高度一致，优于仅用投票总数或无因果推断的模型排序。此外，该方法还能洞察不同社区专家用户的行为动态。

Conclusion: CVA提供了一种更公平、有效的内容质量评估方法，在实际应用中显著提升了内容排序结果的公正性和准确性，可推广到多个网络社区平台。

Abstract: Efficient access to high-quality information is vital for online platforms.
To promote more useful information, users not only create new content but also
evaluate existing content, often through helpfulness voting. Although
aggregated votes help service providers rank their user content, these votes
are often biased by disparate accessibility per position and the cascaded
influence of prior votes. For a fairer assessment of information quality, we
propose the Counterfactual Voting Adjustment (CVA), a causal framework that
accounts for the context in which individual votes are cast. Through
preliminary and semi-synthetic experiments, we show that CVA effectively models
the position and herding biases, accurately recovering the predefined content
quality. In a real experiment, we demonstrate that reranking content based on
the learned quality by CVA exhibits stronger alignment with both user sentiment
and quality evaluation assessed by GPT-4o, outperforming system rankings based
on aggregated votes and model-based rerankings without causal inference. Beyond
the individual quality inference, our embeddings offer comparative insights
into the behavioral dynamics of expert user groups across 120 major
StackExchange communities.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [54] [Our Coding Adventure: Using LLMs to Personalise the Narrative of a Tangible Programming Robot for Preschoolers](https://arxiv.org/abs/2506.20982)
*Martin Ruskov*

Main category: cs.CY

TL;DR: 本研究提出用开源LLM为学前儿童编程机器人制定个性化故事，帮助教师教学，不让儿童直接接触LLM，方法验证有效但存在部分AI幻觉等问题，适宜幼教应用。


<details>
  <summary>Details</summary>
Motivation: 当前将大型语言模型（LLM）应用于教育领域存在风险，尤其是针对年幼儿童，他们容易因技术不理解和屏幕时间过长而受影响。该研究旨在寻找平衡的方式安全地利用LLM提升幼儿教育体验。

Method: 采用行动研究法，围绕可编程机器人Cubetto，制定并实现一个正式化流程，利用开源LLM生成用于引导幼儿操作机器人的个性化故事。实验涵盖5种不同的大型语言模型，具体记录了实验流程、素材使用和提示词设计，同时评估了教师和幼儿的实际学习体验及结果。

Result: 通过对4种不同任务场景的测试，发现生成内容用于教师辅助教学基本成功，但也存在一致性和幻觉问题，并尝试了多种方法（部分有效）来解决这些问题。整个过程避免让儿童直接接触LLM，保障其安全性。

Conclusion: 所提出的方法能够帮助教师快速生成个性化故事，适用于学前班教育，有望在真实环境中进一步实验和推广。

Abstract: Finding balanced ways to employ Large Language Models (LLMs) in education is
a challenge due to inherent risks of poor understanding of the technology and
of a susceptible audience. This is particularly so with younger children, who
are known to have difficulties with pervasive screen time. Working with a
tangible programming robot called Cubetto, we propose an approach to benefit
from the capabilities of LLMs by employing such models in the preparation of
personalised storytelling, necessary for preschool children to get accustomed
to the practice of commanding the robot. We engage in action research to
develop an early version of a formalised process to rapidly prototype game
stories for Cubetto. Our approach has both reproducible results, because it
employs open weight models, and is model-agnostic, because we test it with 5
different LLMs. We document on one hand the process, the used materials and
prompts, and on the other the learning experience and outcomes. We deem the
generation successful for the intended purposes of using the results as a
teacher aid. Testing the models on 4 different task scenarios, we encounter
issues of consistency and hallucinations and document the corresponding
evaluation process and attempts (some successful and some not) to overcome
these issues. Importantly, the process does not expose children to LLMs
directly. Rather, the technology is used to help teachers easily develop
personalised narratives on children's preferred topics. We believe our method
is adequate for preschool classes and we are planning to further experiment in
real-world educational settings.

</details>
