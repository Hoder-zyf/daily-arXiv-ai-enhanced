{"id": "2507.12488", "categories": ["cs.CY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.12488", "abs": "https://arxiv.org/abs/2507.12488", "authors": ["Marco De Luca", "Sergio Di Martino", "Sergio Di Meglio", "Anna Rita Fasolino", "Luigi Libero Lucio Starace", "Porfirio Tramontana"], "title": "Rookie Mistakes: Measuring Software Quality in Student Projects to Guide Educational Enhancement", "comment": "Manuscript accepted for the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA)", "summary": "When teaching Programming and Software Engineering in Bachelor's Degree\nprograms, the emphasis on creating functional software projects often\novershadows the focus on software quality, a trend that aligns with ACM\ncurricula recommendations. Software Engineering courses are typically\nintroduced later in the curriculum, and can generally allocate only limited\ntime to quality-related topics, leaving educators with the challenge of\ndeciding which quality aspects to prioritize. In this decision, the literature\noffers limited guidance, as most existing studies focus on code written by\nnovice students and small code units, making it unclear whether those findings\nextend to intermediate-level students with foundational object-oriented\nprogramming skills working on more complex software projects. To address this\ngap, we analyze 83 object-oriented team projects developed by 172 university\nstudents across 4 different editions of the Object-Oriented Programming course.\nWe apply a static analysis pipeline used in prior research to assess software\nquality, combining SonarQube and ArchUnit to detect code smells and\narchitectural anti-patterns. Our findings highlight recurring quality issues\nand offer concrete evidence of the challenges students face at this stage,\nproviding valuable guidance for educators aiming to continuously improve\nSoftware Engineering curricula and promote quality-oriented development\npractices.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86172\u540d\u5927\u5b66\u751f83\u4e2a\u56e2\u961f\u9762\u5411\u5bf9\u8c61\u9879\u76ee\u7684\u8d28\u91cf\uff0c\u501f\u52a9\u9759\u6001\u5206\u6790\u5de5\u5177\u63ed\u793a\u4e86\u4e2d\u7ea7\u5b66\u751f\u5728\u590d\u6742\u9879\u76ee\u4e2d\u5e38\u89c1\u7684\u8f6f\u4ef6\u8d28\u91cf\u95ee\u9898\uff0c\u4e3a\u6539\u8fdb\u8f6f\u4ef6\u5de5\u7a0b\u6559\u5b66\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002", "motivation": "\u5f53\u524d\u8ba1\u7b97\u673a\u672c\u79d1\u6559\u80b2\u5728\u7f16\u7a0b\u548c\u8f6f\u4ef6\u5de5\u7a0b\u8bfe\u7a0b\u4e2d\uff0c\u5f80\u5f80\u66f4\u5f3a\u8c03\u8f6f\u4ef6\u9879\u76ee\u7684\u5b9e\u73b0\u529f\u80fd\uff0c\u5ffd\u89c6\u4e86\u8f6f\u4ef6\u8d28\u91cf\u7684\u57f9\u517b\uff0c\u4e14\u5927\u591a\u6570\u76f8\u5173\u7814\u7a76\u4ec5\u5173\u6ce8\u521d\u5b66\u8005\u4ee3\u7801\u4e0e\u5c0f\u578b\u9879\u76ee\uff0c\u7f3a\u4e4f\u5bf9\u4e2d\u7ea7\u5b66\u751f\u53ca\u8f83\u590d\u6742\u9879\u76ee\u7684\u8f6f\u4ef6\u8d28\u91cf\u7814\u7a76\u3002\u56e0\u6b64\uff0c\u6559\u80b2\u8005\u5728\u6709\u9650\u6559\u5b66\u65f6\u95f4\u5185\u65e0\u6cd5\u83b7\u5f97\u5145\u5206\u6587\u732e\u6307\u5bfc\uff0c\u96be\u4ee5\u5408\u7406\u6743\u8861\u8f6f\u4ef6\u8d28\u91cf\u6559\u5b66\u91cd\u70b9\u3002", "method": "\u672c\u6587\u6536\u96c6\u5e76\u5206\u6790\u4e864\u5c4a\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u8bfe\u7a0b\u4e2d172\u540d\u5927\u5b66\u751f\u7ec4\u6210\u56e2\u961f\u5f00\u53d1\u768483\u4e2a\u9762\u5411\u5bf9\u8c61\u9879\u76ee\uff0c\u5229\u7528SonarQube\u548cArchUnit\u7ec4\u6210\u7684\u9759\u6001\u5206\u6790\u6d41\u7a0b\u68c0\u6d4b\u4ee3\u7801\u5f02\u5473\u548c\u67b6\u6784\u53cd\u6a21\u5f0f\uff0c\u5bf9\u9879\u76ee\u8f6f\u4ef6\u8d28\u91cf\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u5206\u6790\u7ed3\u679c\u53d1\u73b0\uff0c\u4e2d\u7ea7\u7f16\u7a0b\u5b66\u751f\u5728\u5f00\u53d1\u590d\u6742\u9879\u76ee\u65f6\u4ecd\u53cd\u590d\u51fa\u73b0\u4e00\u4e9b\u5178\u578b\u7684\u8f6f\u4ef6\u8d28\u91cf\u95ee\u9898\u3002\u7814\u7a76\u63ed\u793a\u4e86\u4ed6\u4eec\u5728\u5f53\u524d\u8bfe\u7a0b\u9636\u6bb5\u9762\u4e34\u7684\u5177\u4f53\u4e3b\u8981\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u4e3a\u9ad8\u6821\u6559\u5e08\u63d0\u4f9b\u4e86\u5177\u4f53\u6570\u636e\u548c\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u8f6f\u4ef6\u5de5\u7a0b\u8bfe\u7a0b\u8bbe\u7f6e\uff0c\u7279\u522b\u662f\u5982\u4f55\u66f4\u597d\u5730\u57f9\u517b\u5b66\u751f\u7684\u8f6f\u4ef6\u8d28\u91cf\u610f\u8bc6\u548c\u5b9e\u8df5\u3002"}}
{"id": "2507.12571", "categories": ["cs.CY", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.12571", "abs": "https://arxiv.org/abs/2507.12571", "authors": ["Haoning Xue", "Brian Nishimine", "Martin Hilbert", "Drew Cingel", "Samantha Vigil", "Jane Shawcroft", "Arti Thakur", "Zubair Shafiq", "Jingwen Zhang"], "title": "Catching Dark Signals in Algorithms: Unveiling Audiovisual and Thematic Markers of Unsafe Content Recommended for Children and Teenagers", "comment": null, "summary": "The prevalence of short form video platforms, combined with the\nineffectiveness of age verification mechanisms, raises concerns about the\npotential harms facing children and teenagers in an algorithm-moderated online\nenvironment. We conducted multimodal feature analysis and thematic topic\nmodeling of 4,492 short videos recommended to children and teenagers on\nInstagram Reels, TikTok, and YouTube Shorts, collected as a part of an\nalgorithm auditing experiment. This feature-level and content-level analysis\nrevealed that unsafe (i.e., problematic, mentally distressing) short videos (a)\npossess darker visual features and (b) contain explicitly harmful content and\nimplicit harm from anxiety-inducing ordinary content. We introduce a useful\nframework of online harm (i.e., explicit, implicit, unintended), providing a\nunique lens for understanding the dynamic, multifaceted online risks facing\nchildren and teenagers. The findings highlight the importance of protecting\nyounger audiences in critical developmental stages from both explicit and\nimplicit risks on social media, calling for nuanced content moderation, age\nverification, and platform regulation.", "AI": {"tldr": "\u8be5\u6587\u901a\u8fc7\u5bf9\u63a8\u8350\u7ed9\u9752\u5c11\u5e74\u7684\u77ed\u89c6\u9891\u5185\u5bb9\u5206\u6790\uff0c\u53d1\u73b0\u8bb8\u591a\u89c6\u9891\u5b58\u5728\u76f4\u63a5\u6216\u95f4\u63a5\u7684\u5fc3\u7406\u5371\u5bb3\uff0c\u63d0\u51fa\u4e86\u7ebf\u4e0a\u5371\u5bb3\u6846\u67b6\uff0c\u5f3a\u8c03\u9700\u52a0\u5f3a\u5185\u5bb9\u7ba1\u7406\u4e0e\u5e73\u53f0\u76d1\u7ba1\u4ee5\u4fdd\u62a4\u672a\u6210\u5e74\u7528\u6237\u3002", "motivation": "\u968f\u7740\u77ed\u89c6\u9891\u5e73\u53f0\u7684\u6d41\u884c\u4ee5\u53ca\u5e74\u9f84\u9a8c\u8bc1\u673a\u5236\u7684\u4f4e\u6548\uff0c\u513f\u7ae5\u548c\u9752\u5c11\u5e74\u9762\u4e34\u7b97\u6cd5\u63a8\u8350\u73af\u5883\u4e2d\u6f5c\u5728\u5371\u5bb3\u7684\u62c5\u5fe7\u65e5\u76ca\u589e\u52a0\u3002", "method": "\u7814\u7a76\u8005\u5bf9Instagram Reels\u3001TikTok\u3001YouTube Shorts\u4e09\u5927\u5e73\u53f0\u4e0a\u88ab\u63a8\u8350\u7ed9\u513f\u7ae5\u548c\u9752\u5c11\u5e74\u76844,492\u4e2a\u77ed\u89c6\u9891\u8fdb\u884c\u4e86\u591a\u6a21\u6001\u7279\u5f81\u5206\u6790\u548c\u4e3b\u9898\u5185\u5bb9\u5efa\u6a21\uff0c\u5e76\u4f5c\u4e3a\u7b97\u6cd5\u5ba1\u8ba1\u5b9e\u9a8c\u7684\u4e00\u90e8\u5206\u3002", "result": "\u5206\u6790\u663e\u793a\uff0c\u4e0d\u5b89\u5168\uff08\u95ee\u9898\u6027\u6216\u5fc3\u7406\u56f0\u6270\uff09\u77ed\u89c6\u9891\u901a\u5e38\u5177\u6709\u66f4\u6697\u7684\u89c6\u89c9\u7279\u5f81\uff0c\u4e14\u5185\u5bb9\u5305\u542b\u663e\u6027\u6709\u5bb3\u4fe1\u606f\u53ca\u9690\u6027\u7531\u666e\u901a\u5185\u5bb9\u5f15\u53d1\u7126\u8651\u7684\u5371\u5bb3\u3002\u7814\u7a76\u8fd8\u63d0\u51fa\u4e86\u201c\u663e\u6027\u3001\u9690\u6027\u3001\u975e\u9884\u671f\u201d\u4e09\u7c7b\u7ebf\u4e0a\u5371\u5bb3\u6846\u67b6\u3002", "conclusion": "\u7ed3\u679c\u7a81\u663e\u4e86\u4fdd\u62a4\u513f\u7ae5\u548c\u9752\u5c11\u5e74\u53d1\u5c55\u5173\u952e\u9636\u6bb5\u7684\u89c2\u4f17\u514d\u53d7\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u663e\u6027\u4e0e\u9690\u6027\u5371\u5bb3\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u547c\u5401\u5bf9\u5185\u5bb9\u5ba1\u6838\u3001\u5e74\u9f84\u9a8c\u8bc1\u548c\u5e73\u53f0\u76d1\u7ba1\u505a\u51fa\u6539\u8fdb\u3002"}}
{"id": "2507.12674", "categories": ["cs.CY", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.12674", "abs": "https://arxiv.org/abs/2507.12674", "authors": ["Mihran Miroyan", "Rose Niousha", "Joseph E. Gonzalez", "Gireeja Ranade", "Narges Norouzi"], "title": "ParaStudent: Generating and Evaluating Realistic Student Code by Teaching LLMs to Struggle", "comment": null, "summary": "Large Language Models (LLMs) have shown strong performance on programming\ntasks, but can they generate student-like code like real students - imperfect,\niterative, and stylistically diverse? We present ParaStudent, a systematic\nstudy of LLM-based \"student-like\" code generation in an introductory\nprogramming course setting. Using a dataset of timestamped student submissions\nacross multiple semesters, we design low- and high-resolution experiments to\nmodel student progress and evaluate code outputs along semantic, functional,\nand stylistic dimensions. Our results show that fine-tuning significantly\nimproves alignment with real student trajectories and captures error patterns,\nincremental improvements, and stylistic variations more faithfully. This study\nshows that modeling realistic student code requires capturing learning dynamics\nthrough context-aware generation, temporal modeling, and multi-dimensional\nevaluation. Code for experiments and evaluation is available at\n\\href{https://github.com/mmiroyan/ParaStudent}{\\texttt{github.com/mmiroyan/ParaStudent}}.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u591f\u66f4\u52a0\u771f\u5b9e\u5730\u6a21\u62df\u5b66\u751f\u4ee3\u7801\u7684\u98ce\u683c\u548c\u5b66\u4e60\u8f68\u8ff9\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u6355\u6349\u9519\u8bef\u548c\u98ce\u683c\u591a\u6837\u6027\u65b9\u9762\u4f18\u4e8e\u672a\u7ecf\u5fae\u8c03\u7684\u6a21\u578b\u3002", "motivation": "\u5f53\u524dLLM\u5728\u7f16\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u662f\u5426\u80fd\u751f\u6210\u201c\u7c7b\u5b66\u751f\u201d\u7684\u4ee3\u7801\uff0c\u5373\u4e0d\u5b8c\u7f8e\u3001\u5177\u6709\u8fed\u4ee3\u6027\u548c\u98ce\u683c\u591a\u6837\u6027\uff0c\u662f\u4e00\u4e2a\u4e9f\u9700\u63a2\u7d22\u7684\u95ee\u9898\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u6a21\u62df\u5b66\u751f\u7684\u5b66\u4e60\u548c\u7f16\u7a0b\u8fc7\u7a0b\uff0c\u52a0\u5f3a\u6559\u80b2\u9886\u57dfLLM\u7684\u5b9e\u7528\u6027\u548c\u771f\u5b9e\u5ea6\u3002", "method": "\u4f7f\u7528\u5305\u542b\u591a\u4e2a\u5b66\u671f\u5b66\u751f\u4ee3\u7801\u63d0\u4ea4\u7684\u65f6\u95f4\u6233\u6570\u636e\uff0c\u8bbe\u8ba1\u4e86\u4f4e\u5206\u8fa8\u7387\u4e0e\u9ad8\u5206\u8fa8\u7387\u5b9e\u9a8c\uff0c\u5bf9\u5b66\u751f\u5b66\u4e60\u8f68\u8ff9\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u4ece\u8bed\u4e49\u3001\u529f\u80fd\u548c\u98ce\u683c\u591a\u7ef4\u5ea6\u5bf9\u751f\u6210\u4ee3\u7801\u8fdb\u884c\u8bc4\u4f30\u3002\u5bf9LLM\u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u4f7f\u5176\u66f4\u8d34\u8fd1\u771f\u5b9e\u5b66\u751f\u7684\u4ee3\u7801\u6d41\u7a0b\u548c\u9519\u8bef\u7279\u5f81\u3002", "result": "\u5fae\u8c03\u540e\u7684LLM\u5728\u6a21\u62df\u5b66\u751f\u4ee3\u7801\u8f93\u51fa\u65f6\uff0c\u4e0e\u771f\u5b9e\u5b66\u751f\u4ee3\u7801\u5e8f\u5217\u7684\u5bf9\u9f50\u5ea6\u660e\u663e\u63d0\u9ad8\uff0c\u66f4\u597d\u5730\u6355\u6349\u4e86\u5b66\u4e60\u4e2d\u7684\u9519\u8bef\u3001\u6539\u8fdb\u548c\u98ce\u683c\u53d8\u5316\u3002\u591a\u7ef4\u8bc4\u4f30\u8bc1\u660e\u8fd9\u79cd\u65b9\u6cd5\u6548\u679c\u663e\u8457\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u9488\u5bf9\u5b66\u751f\u63d0\u4ea4\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u80fd\u591f\u66f4\u52a0\u771f\u5b9e\u5730\u6a21\u62df\u5b66\u751f\u7684\u4ee3\u7801\u98ce\u683c\uff0c\u6355\u6349\u5176\u9519\u8bef\u6a21\u5f0f\u3001\u589e\u91cf\u6539\u8fdb\u8fc7\u7a0b\u548c\u98ce\u683c\u591a\u6837\u6027\u3002\u6a21\u578b\u80fd\u8f83\u597d\u5730\u91cd\u73b0\u5b66\u751f\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u53d8\u5316\u3002"}}
{"id": "2507.12713", "categories": ["cs.CY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.12713", "abs": "https://arxiv.org/abs/2507.12713", "authors": ["Grant Shanklin", "Emmie Hine", "Claudio Novelli", "Tyler Schroder", "Luciano Floridi"], "title": "The Case for Contextual Copyleft: Licensing Open Source Training Data and Generative AI", "comment": "19 pages", "summary": "The proliferation of generative AI systems has created new challenges for the\nFree and Open Source Software (FOSS) community, particularly regarding how\ntraditional copyleft principles should apply when open source code is used to\ntrain AI models. This article introduces the Contextual Copyleft AI (CCAI)\nlicense, a novel licensing mechanism that extends copyleft requirements from\ntraining data to the resulting generative AI models. The CCAI license offers\nsignificant advantages, including enhanced developer control, incentivization\nof open source AI development, and mitigation of openwashing practices. This is\ndemonstrated through a structured three-part evaluation framework that examines\n(1) legal feasibility under current copyright law, (2) policy justification\ncomparing traditional software and AI contexts, and (3) synthesis of\ncross-contextual benefits and risks. However, the increased risk profile of\nopen source AI, particularly the potential for direct misuse, necessitates\ncomplementary regulatory approaches to achieve an appropriate risk-benefit\nbalance. The paper concludes that when implemented within a robust regulatory\nenvironment focused on responsible AI usage, the CCAI license provides a viable\nmechanism for preserving and adapting core FOSS principles to the evolving\nlandscape of generative AI development.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u751f\u6210\u5f0fAI\u65f6\u4ee3\u5f00\u6e90\u4ee3\u7801\u9762\u4e34\u7684\u65b0\u7248\u6743\u6311\u6218\uff0c\u63d0\u51faCCAI\u8bb8\u53ef\u534f\u8bae\uff0c\u62c9\u5bbdcopyleft\u539f\u5219\u5bf9AI\u6a21\u578b\u7684\u9002\u7528\u8303\u56f4\u3002\u7ecf\u8fc7\u6cd5\u5f8b\u3001\u653f\u7b56\u53ca\u98ce\u9669\u6536\u76ca\u591a\u5c42\u6b21\u8bc4\u4f30\uff0c\u8ba4\u4e3aCCAI\u9700\u914d\u5957\u76d1\u7ba1\uff0c\u53ef\u6210\u4e3a\u4fdd\u969c\u5f00\u6e90AI\u53d1\u5c55\u7684\u6709\u6548\u5de5\u5177\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u7cfb\u7edf\u8fc5\u901f\u53d1\u5c55\uff0c\u5f00\u6e90\u793e\u533a\u9762\u4e34\u7740\u4f20\u7edfcopyleft\uff08\u8457\u4f5c\u6743\u5de6\u8f6c\uff09\u539f\u5219\u5728AI\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u9002\u7528\u6027\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u4ee5\u4fdd\u62a4\u5f00\u6e90\u7cbe\u795e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bb8\u53ef\u534f\u8baeContextual Copyleft AI\uff08CCAI\uff09\uff0c\u5e76\u5229\u7528\u4e09\u5c42\u6b21\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u62ec\u6cd5\u5f8b\u53ef\u884c\u6027\u3001\u653f\u7b56\u6b63\u5f53\u6027\u5206\u6790\u53ca\u8de8\u9886\u57df\u98ce\u9669\u4e0e\u6536\u76ca\u7efc\u5408\u8bc4\u4f30\u3002", "result": "CCAI\u8bb8\u53ef\u534f\u8bae\u80fd\u591f\u63d0\u5347\u5f00\u53d1\u8005\u63a7\u5236\u6743\u3001\u4fc3\u8fdb\u5f00\u6e90AI\u53d1\u5c55\u3001\u51cf\u5c11\u5f00\u6e90\u6f02\u6d17\u98ce\u9669\uff0c\u4f46\u7531\u4e8e\u5f00\u6e90AI\u53ef\u80fd\u88ab\u6ee5\u7528\uff0c\u9700\u914d\u5408\u76d1\u7ba1\u63aa\u65bd\u624d\u80fd\u5b9e\u73b0\u98ce\u9669\u4e0e\u5229\u76ca\u7684\u5e73\u8861\u3002", "conclusion": "\u53ea\u8981\u5728\u6709\u9002\u5f53\u76d1\u7ba1\u7684\u73af\u5883\u4e0b\u5b9e\u65bd\uff0cCCAI\u8bb8\u53ef\u534f\u8bae\u80fd\u6709\u6548\u4fdd\u7559\u5e76\u9002\u5e94FOSS\u539f\u5219\u4e8e\u751f\u6210\u5f0fAI\u9886\u57df\uff0c\u662f\u5e94\u5bf9AI\u65f6\u4ee3\u5f00\u6e90\u6311\u6218\u7684\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2507.12547", "categories": ["cs.CL", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.12547", "abs": "https://arxiv.org/abs/2507.12547", "authors": ["Lionel Wong", "Katherine M. Collins", "Lance Ying", "Cedegao E. Zhang", "Adrian Weller", "Tobias Gersternberg", "Timothy O'Donnell", "Alexander K. Lew", "Jacob D. Andreas", "Joshua B. Tenenbaum", "Tyler Brooke-Wilson"], "title": "Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models", "comment": "Presented at CogSci 2025", "summary": "When faced with novel situations, people are able to marshal relevant\nconsiderations from a wide range of background knowledge and put these to use\nin inferences and predictions. What permits us to draw in globally relevant\ninformation and reason over it coherently? Here, we explore the hypothesis that\npeople use a combination of distributed and symbolic representations to\nconstruct bespoke mental models tailored to novel situations. We propose a\ncomputational implementation of this idea -- a ``Model Synthesis Architecture''\n(MSA) -- using language models to implement global relevance-based retrieval\nand model synthesis and probabilistic programs to implement bespoke, coherent\nworld models. We evaluate our MSA as a model of human judgments on a novel\nreasoning dataset. The dataset -- built around a `Model Olympics` domain of\nsports vignettes -- tests models' capacity for human-like, open-ended reasoning\nby requiring (i) judgments about novel causal structures described in language;\n(ii) drawing on large bodies of background knowledge; and (iii) doing both in\nlight of observations that introduce arbitrary novel variables. Our MSA\napproach captures human judgments better than language model-only baselines,\nunder both direct and chain-of-thought generations from the LM that supports\nmodel synthesis. These results suggest that MSAs can be implemented in a way\nthat mirrors people's ability to deliver locally coherent reasoning over\nglobally relevant variables, offering a path to understanding and replicating\nhuman reasoning in open-ended domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u548c\u6982\u7387\u7a0b\u5e8f\u7684\u6a21\u578b\u5408\u6210\u67b6\u6784\uff08MSA\uff09\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6a21\u62df\u4eba\u7c7b\u5728\u65b0\u9896\u60c5\u5883\u4e0b\u7684\u5f00\u653e\u5f0f\u63a8\u7406\uff0c\u8d85\u8d8a\u4e86\u4ec5\u4f9d\u8d56\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "motivation": "\u4eba\u7c7b\u5728\u9762\u5bf9\u65b0\u9896\u60c5\u5883\u65f6\uff0c\u80fd\u4ece\u4e30\u5bcc\u7684\u80cc\u666f\u77e5\u8bc6\u4e2d\u8c03\u53d6\u76f8\u5173\u4fe1\u606f\u5e76\u52a0\u4ee5\u63a8\u7406\uff0c\u8fd9\u4e00\u80fd\u529b\u80cc\u540e\u7684\u8ba4\u77e5\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u6587\u5c1d\u8bd5\u89e3\u91ca\u4eba\u7c7b\u5982\u4f55\u9ad8\u6548\u6574\u5408\u5e7f\u6cdb\u4fe1\u606f\u5e76\u8fdb\u884c\u8fde\u8d2f\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e86\u201c\u6a21\u578b\u5408\u6210\u67b6\u6784\u201d\uff08MSA\uff09\uff0c\u7ed3\u5408\u5206\u5e03\u5f0f\u548c\u7b26\u53f7\u8868\u793a\uff0c\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u5168\u5c40\u76f8\u5173\u6027\u68c0\u7d22\u548c\u6a21\u578b\u5408\u6210\uff0c\u5e76\u5229\u7528\u6982\u7387\u7a0b\u5e8f\u751f\u6210\u5b9a\u5236\u7684\u4e16\u754c\u6a21\u578b\u3002\u8bbe\u8ba1\u4e86\u4ee5\u201cModel Olympics\u201d\u4e3a\u6838\u5fc3\u7684\u63a8\u7406\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u6d4b\u8bc4\u4eba\u7c7b\u7c7b\u6bd4\u63a8\u7406\u80fd\u529b\uff0c\u6d4b\u8bd5MSA\u6027\u80fd\u3002", "result": "MSA\u5728\u6a21\u62df\u4eba\u7c7b\u5224\u65ad\u65b9\u9762\u4f18\u4e8e\u4ec5\u4f9d\u8d56\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u7ebf\uff0c\u65e0\u8bba\u662f\u5728\u76f4\u63a5\u751f\u6210\u8fd8\u662f\u201c\u601d\u7ef4\u94fe\u201d\u751f\u6210\u4efb\u52a1\u4e0a\uff0c\u5747\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u6a21\u578b\u5408\u6210\u67b6\u6784\u53ef\u4ee5\u6709\u6548\u5730\u6a21\u4eff\u4eba\u7c7b\u5728\u5f00\u653e\u9886\u57df\u4e0b\uff0c\u6574\u5408\u5168\u5c40\u76f8\u5173\u53d8\u91cf\u5e76\u8fdb\u884c\u5c40\u90e8\u8fde\u8d2f\u63a8\u7406\u7684\u80fd\u529b\uff0c\u4e3a\u7406\u89e3\u548c\u590d\u5236\u4eba\u7c7b\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u8def\u5f84\u3002"}}
{"id": "2507.12484", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.12484", "abs": "https://arxiv.org/abs/2507.12484", "authors": ["Jaros\u0142aw A. Chudziak", "Adam Kostka"], "title": "AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education", "comment": "8 pages, 5 figures", "summary": "The growing ubiquity of artificial intelligence (AI), in particular large\nlanguage models (LLMs), has profoundly altered the way in which learners gain\nknowledge and interact with learning material, with many claiming that AI\npositively influences their learning achievements. Despite this advancement,\ncurrent AI tutoring systems face limitations associated with their reactive\nnature, often providing direct answers without encouraging deep reflection or\nincorporating structured pedagogical tools and strategies. This limitation is\nmost apparent in the field of mathematics, in which AI tutoring systems remain\nunderdeveloped. This research addresses the question: How can AI tutoring\nsystems move beyond providing reactive assistance to enable structured,\nindividualized, and tool-assisted learning experiences? We introduce a novel\nmulti-agent AI tutoring platform that combines adaptive and personalized\nfeedback, structured course generation, and textbook knowledge retrieval to\nenable modular, tool-assisted learning processes. This system allows students\nto learn new topics while identifying and targeting their weaknesses, revise\nfor exams effectively, and practice on an unlimited number of personalized\nexercises. This article contributes to the field of artificial intelligence in\neducation by introducing a novel platform that brings together pedagogical\nagents and AI-driven components, augmenting the field with modular and\neffective systems for teaching mathematics.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u73b0\u6709AI\u8f85\u5bfc\u7cfb\u7edf\u7684\u88ab\u52a8\u6027\uff0c\u63d0\u51fa\u4e00\u79cd\u591a\u667a\u80fd\u4f53AI\u6570\u5b66\u8f85\u5bfc\u5e73\u53f0\uff0c\u96c6\u6210\u4e2a\u6027\u5316\u53cd\u9988\u3001\u8bfe\u7a0b\u751f\u6210\u548c\u77e5\u8bc6\u68c0\u7d22\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u548c\u5de5\u5177\u5316\u7684\u5b66\u4e60\u4f53\u9a8c\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6570\u5b66\u5b66\u4e60\u7684\u4e2a\u6027\u5316\u4e0e\u7ed3\u6784\u5316\u6c34\u5e73\u3002", "motivation": "\u5f53\u524dAI\u8f85\u5bfc\u7cfb\u7edf\u5927\u591a\u4e3a\u88ab\u52a8\u54cd\u5e94\u5f0f\uff0c\u53ea\u63d0\u4f9b\u76f4\u63a5\u7b54\u6848\uff0c\u7f3a\u4e4f\u4fc3\u8fdb\u6df1\u5165\u53cd\u601d\u6216\u7ed3\u5408\u7ed3\u6784\u5316\u6559\u5b66\u5de5\u5177\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u6570\u5b66\u9886\u57df\u5c24\u4e3a\u660e\u663e\u3002\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63d0\u5347AI\u8f85\u5bfc\u7cfb\u7edf\u7684\u81ea\u4e3b\u6027\u548c\u6559\u5b66\u6548\u679c\uff0c\u8ba9AI\u4e0d\u4ec5\u4ec5\u662f\u7b54\u9898\u5de5\u5177\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53AI\u8f85\u5bfc\u5e73\u53f0\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u548c\u4e2a\u6027\u5316\u53cd\u9988\u3001\u7ed3\u6784\u5316\u8bfe\u7a0b\u751f\u6210\u53ca\u6559\u79d1\u4e66\u77e5\u8bc6\u68c0\u7d22\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u3001\u5de5\u5177\u8f85\u52a9\u7684\u5b66\u4e60\u8fc7\u7a0b\u3002\u7cfb\u7edf\u7531\u591a\u79cd\u6559\u80b2\u667a\u80fd\u4f53\u4e0eAI\u7ec4\u4ef6\u534f\u4f5c\uff0c\u652f\u6301\u5b9a\u5236\u7ec3\u4e60\u548c\u9488\u5bf9\u6027\u590d\u4e60\u3002", "result": "\u5e73\u53f0\u652f\u6301\u5b66\u751f\u6709\u6548\u5b66\u4e60\u65b0\u77e5\u8bc6\u3001\u8bc6\u522b\u5e76\u5f25\u8865\u5f31\u9879\u3001\u5907\u8003\u590d\u4e60\u53ca\u65e0\u9650\u91cf\u4e2a\u6027\u5316\u7ec3\u4e60\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u7cfb\u7edf\u53ef\u63d0\u4f9b\u66f4\u4e3a\u7ed3\u6784\u5316\u548c\u6709\u6548\u7684\u6570\u5b66\u6559\u5b66\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u548cAI\u9a71\u52a8\u7ec4\u4ef6\u7ed3\u5408\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u7684\u5e73\u53f0\u4e30\u5bcc\u4e86AI\u6559\u80b2\u9886\u57df\uff0c\u4e3a\u6570\u5b66\u6559\u5b66\u63d0\u4f9b\u4e86\u66f4\u6a21\u5757\u5316\u3001\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8eAI\u5bfc\u5e08\u7cfb\u7edf\u4ece\u88ab\u52a8\u7b54\u9898\u8d70\u5411\u4e3b\u52a8\u3001\u5de5\u5177\u5316\u548c\u4e2a\u6027\u5316\u8f85\u5bfc\u3002"}}
{"id": "2507.12557", "categories": ["cs.CE", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2507.12557", "abs": "https://arxiv.org/abs/2507.12557", "authors": ["Nicholas Kirschbaum", "Nathaniel Wood", "Chang-Eun Kim", "Thejaswi U. Tumkur", "Chinedum Okwudire"], "title": "Vector-level Feedforward Control of LPBF Melt Pool Area Using a Physics-Based Thermal Model", "comment": "43 pages, 15 figures", "summary": "Laser powder bed fusion (LPBF) is an additive manufacturing technique that\nhas gained popularity thanks to its ability to produce geometrically complex,\nfully dense metal parts. However, these parts are prone to internal defects and\ngeometric inaccuracies, stemming in part from variations in the melt pool. This\npaper proposes a novel vector-level feedforward control framework for\nregulating melt pool area in LPBF. By decoupling part-scale thermal behavior\nfrom small-scale melt pool physics, the controller provides a scale-agnostic\nprediction of melt pool area and efficient optimization over it. This is done\nby operating on two coupled lightweight models: a finite-difference thermal\nmodel that efficiently captures vector-level temperature fields and a\nreduced-order, analytical melt pool model. Each model is calibrated separately\nwith minimal single-track and 2D experiments, and the framework is validated on\na complex 3D geometry in both Inconel 718 and 316L stainless steel. Results\nshowed that feedforward vector-level laser power scheduling reduced geometric\ninaccuracy in key dimensions by 62%, overall porosity by 16.5%, and photodiode\nvariation by 6.8% on average. Overall, this modular, data-efficient approach\ndemonstrates that proactively compensating for known thermal effects can\nsignificantly improve part quality while remaining computationally efficient\nand readily extensible to other materials and machines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u6570\u636e\u9a71\u52a8\u524d\u9988\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u8026\u5408\u70ed\u6a21\u578b\u548c\u7194\u6c60\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5bf9LPBF\u8fc7\u7a0b\u4e2d\u7194\u6c60\u9762\u79ef\u7684\u7cbe\u51c6\u8c03\u8282\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u96f6\u4ef6\u7684\u51e0\u4f55\u7cbe\u5ea6\u548c\u81f4\u5bc6\u5ea6\uff0c\u5177\u5907\u826f\u597d\u7684\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u6fc0\u5149\u9009\u533a\u7194\u5316\uff08LPBF\uff09\u6280\u672f\u80fd\u591f\u5236\u9020\u590d\u6742\u4e14\u9ad8\u5bc6\u5ea6\u7684\u91d1\u5c5e\u96f6\u4ef6\uff0c\u4f46\u5bb9\u6613\u51fa\u73b0\u5185\u90e8\u7f3a\u9677\u548c\u51e0\u4f55\u504f\u5dee\uff0c\u4e3b\u8981\u539f\u56e0\u4e4b\u4e00\u662f\u7194\u6c60\u7684\u53d8\u5316\u6027\u3002\u5982\u4f55\u6709\u6548\u63a7\u5236\u7194\u6c60\u533a\u57df\uff0c\u63d0\u5347\u5236\u4ef6\u8d28\u91cf\uff0c\u662f\u8be5\u9886\u57df\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u77e2\u91cf\u7ea7\u524d\u9988\u63a7\u5236\u6846\u67b6\u4ee5\u8c03\u8282LPBF\u4e2d\u7684\u7194\u6c60\u9762\u79ef\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u4e24\u4e2a\u8026\u5408\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\uff1a\u6709\u9650\u5dee\u5206\u70ed\u6a21\u578b\u7528\u4e8e\u6355\u6349\u77e2\u91cf\u7ea7\u6e29\u5ea6\u573a\uff0c\u4ee5\u53ca\u4e00\u4e2a\u964d\u9636\u89e3\u6790\u7194\u6c60\u6a21\u578b\u3002\u8fd9\u4e24\u4e2a\u6a21\u578b\u5206\u522b\u901a\u8fc7\u5c11\u91cf\u5355\u9053\u4e0e\u4e8c\u7ef4\u5b9e\u9a8c\u8fdb\u884c\u6821\u51c6\uff0c\u5e76\u5728\u590d\u6742\u4e09\u7ef4\u51e0\u4f55\u4f53\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u91c7\u7528\u8be5\u524d\u9988\u77e2\u91cf\u7ea7\u6fc0\u5149\u529f\u7387\u8c03\u5ea6\u540e\uff0c\u5173\u952e\u5c3a\u5bf8\u7684\u51e0\u4f55\u4e0d\u51c6\u786e\u6027\u964d\u4f4e\u4e8662%\uff0c\u6574\u4f53\u5b54\u9699\u7387\u964d\u4f4e\u4e8616.5%\uff0c\u5149\u7535\u4e8c\u6781\u7ba1\u68c0\u6d4b\u4fe1\u53f7\u7684\u6ce2\u52a8\u5e73\u5747\u964d\u4f4e\u4e866.8%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6709\u6548\u9884\u6d4b\u548c\u4f18\u5316\u7194\u6c60\u884c\u4e3a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u96f6\u4ef6\u8d28\u91cf\uff0c\u540c\u65f6\u5177\u6709\u826f\u597d\u7684\u8ba1\u7b97\u6548\u7387\u548c\u901a\u7528\u6027\uff0c\u6613\u4e8e\u6269\u5c55\u5230\u4e0d\u540c\u6750\u6599\u548c\u8bbe\u5907\u3002"}}
{"id": "2507.12957", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2507.12957", "abs": "https://arxiv.org/abs/2507.12957", "authors": ["Miriam Meckel", "Philipp Hacker", "Lea Steinacker", "Aurelija Lukoseviciene", "Surjo R. Soekadar", "Jacob Slosser", "Gina-Maria Poehlmann"], "title": "The Goldilocks zone of governing technology: Leveraging uncertainty for responsible quantum practices", "comment": "Paper is accepted and will be published", "summary": "Emerging technologies challenge conventional governance approaches,\nespecially when uncertainty is not a temporary obstacle but a foundational\nfeature as in quantum computing. This paper reframes uncertainty from a\ngovernance liability to a generative force, using the paradigms of quantum\nmechanics to propose adaptive, probabilistic frameworks for responsible\ninnovation. We identify three interdependent layers of uncertainty--physical,\ntechnical, and societal--central to the evolution of quantum technologies. The\nproposed Quantum Risk Simulator (QRS) serves as a conceptual example, an\nimaginative blueprint rather than a prescriptive tool, meant to illustrate how\nprobabilistic reasoning could guide dynamic, uncertainty-based governance. By\nforegrounding epistemic and ontological ambiguity, and drawing analogies from\ncognitive neuroscience and predictive processing, we suggest a new model of\ngovernance aligned with the probabilistic essence of quantum systems. This\nmodel, we argue, is especially promising for the European Union as a third way\nbetween laissez-faire innovation and state-led control, offering a flexible yet\nresponsible pathway for regulating quantum and other frontier technologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\uff0c\u9762\u5bf9\u91cf\u5b50\u8ba1\u7b97\u7b49\u9ad8\u4e0d\u786e\u5b9a\u6027\u524d\u6cbf\u6280\u672f\uff0c\u5e94\u6539\u53d8\u6cbb\u7406\u601d\u8def\uff0c\u5c06\u4e0d\u786e\u5b9a\u6027\u89c6\u4e3a\u79ef\u6781\u529b\u91cf\u3002\u901a\u8fc7\u7c7b\u6bd4\u91cf\u5b50\u529b\u5b66\u548c\u8ba4\u77e5\u79d1\u5b66\uff0c\u63d0\u51fa\u4e86\u6982\u7387\u6027\u81ea\u9002\u5e94\u6cbb\u7406\u65b0\u6a21\u5f0f\uff08QRS\u6982\u5ff5\uff09\uff0c\u4e3b\u5f20\u6b27\u76df\u7528\u66f4\u7075\u6d3b\u3001\u8d23\u4efb\u5316\u7684\u65b9\u6cd5\u76d1\u7ba1\u521b\u65b0\u79d1\u6280\u3002", "motivation": "\u65b0\u5174\u6280\u672f\uff08\u5982\u91cf\u5b50\u8ba1\u7b97\uff09\u7684\u4e0d\u786e\u5b9a\u6027\u5df2\u6210\u4e3a\u6cbb\u7406\u4e2d\u7684\u5173\u952e\u96be\u9898\uff0c\u4f20\u7edf\u6cbb\u7406\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u8fd9\u79cd\u672c\u8d28\u4e0a\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u8be5\u7814\u7a76\u65e8\u5728\u5bfb\u627e\u9002\u5e94\u8fd9\u79cd\u6301\u7eed\u548c\u6839\u672c\u6027\u4e0d\u786e\u5b9a\u6027\u7684\u6cbb\u7406\u65b0\u65b9\u5f0f\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u91cf\u5b50\u529b\u5b66\u8303\u5f0f\uff0c\u5c06\u6982\u7387\u6027\u548c\u9002\u5e94\u6027\u6cbb\u7406\u7406\u8bba\u5e94\u7528\u4e8e\u6280\u672f\u521b\u65b0\u6cbb\u7406\uff0c\u63d0\u51fa\u4e86\u5305\u542b\u7269\u7406\u3001\u6280\u672f\u548c\u793e\u4f1a\u4e09\u5c42\u4e0d\u786e\u5b9a\u6027\u7684\u5206\u6790\u6846\u67b6\uff0c\u5e76\u4ee5\u201c\u91cf\u5b50\u98ce\u9669\u6a21\u62df\u5668\uff08QRS\uff09\u201d\u4f5c\u4e3a\u6982\u5ff5\u793a\u4f8b\uff0c\u540c\u65f6\u501f\u9274\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u548c\u9884\u6d4b\u5904\u7406\u7406\u8bba\uff0c\u63d0\u51fa\u4e00\u79cd\u52a8\u6001\u7684\u4e0d\u786e\u5b9a\u6027\u6cbb\u7406\u6a21\u578b\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\u4ee5\u6982\u7387\u63a8\u7406\u4e3a\u6838\u5fc3\u3001\u80fd\u52a8\u6001\u9002\u5e94\u4e0d\u786e\u5b9a\u6027\u7684\u6cbb\u7406\u65b0\u6a21\u5f0f\uff0c\u5f3a\u8c03\u4e09\u5c42\u4e0d\u786e\u5b9a\u6027\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u4ee5QRS\u4e3a\u60f3\u8c61\u6027\u84dd\u56fe\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u8be5\u7406\u8bba\u5e94\u7528\u4e8e\u5b9e\u9645\u6cbb\u7406\u8fc7\u7a0b\u4e2d\u3002", "conclusion": "\u8fd9\u79cd\u4ee5\u4e0d\u786e\u5b9a\u6027\u4e3a\u751f\u6210\u52a8\u529b\u7684\u6cbb\u7406\u6a21\u5f0f\uff0c\u4e3a\u91cf\u5b50\u53ca\u524d\u6cbf\u6280\u672f\u7684\u76d1\u7ba1\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u4e14\u6709\u8d23\u4efb\u611f\u7684\u65b0\u8def\u5f84\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6b27\u76df\uff0c\u5e0c\u671b\u6784\u5efa\u5728\u653e\u4efb\u548c\u56fd\u5bb6\u63a7\u5236\u4e4b\u95f4\u7684\u201c\u7b2c\u4e09\u79cd\u65b9\u5f0f\u201d\u3002"}}
{"id": "2507.12553", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.12553", "abs": "https://arxiv.org/abs/2507.12553", "authors": ["Michael A. Lepori", "Jennifer Hu", "Ishita Dasgupta", "Roma Patel", "Thomas Serre", "Ellie Pavlick"], "title": "Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility", "comment": null, "summary": "Language models (LMs) are used for a diverse range of tasks, from question\nanswering to writing fantastical stories. In order to reliably accomplish these\ntasks, LMs must be able to discern the modal category of a sentence (i.e.,\nwhether it describes something that is possible, impossible, completely\nnonsensical, etc.). However, recent studies have called into question the\nability of LMs to categorize sentences according to modality (Michaelov et al.,\n2025; Kauf et al., 2023). In this work, we identify linear representations that\ndiscriminate between modal categories within a variety of LMs, or modal\ndifference vectors. Analysis of modal difference vectors reveals that LMs have\naccess to more reliable modal categorization judgments than previously\nreported. Furthermore, we find that modal difference vectors emerge in a\nconsistent order as models become more competent (i.e., through training steps,\nlayers, and parameter count). Notably, we find that modal difference vectors\nidentified within LM activations can be used to model fine-grained human\ncategorization behavior. This potentially provides a novel view into how human\nparticipants distinguish between modal categories, which we explore by\ncorrelating projections along modal difference vectors with human participants'\nratings of interpretable features. In summary, we derive new insights into LM\nmodal categorization using techniques from mechanistic interpretability, with\nthe potential to inform our understanding of modal categorization in humans.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u673a\u5236\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u5177\u5907\u6bd4\u6b64\u524d\u8ba4\u4e3a\u66f4\u5f3a\u7684\u6a21\u6001\u7c7b\u522b\u5224\u522b\u80fd\u529b\uff0c\u5e76\u63ed\u793a\u4e86\u5176\u6f14\u53d8\u3001\u8868\u5f81\u65b9\u5f0f\u4e0e\u4eba\u7c7b\u6a21\u6001\u5206\u7c7b\u884c\u4e3a\u7684\u5173\u7cfb\uff0c\u5bf9\u4eba\u673a\u6a21\u6001\u8ba4\u77e5\u7406\u89e3\u6709\u91cd\u8981\u542f\u793a\u3002", "motivation": "\u8fd1\u671f\u6709\u7814\u7a76\u8d28\u7591\u8bed\u8a00\u6a21\u578b\uff08LMs\uff09\u80fd\u591f\u6709\u6548\u8bc6\u522b\u53e5\u5b50\u7684\u6a21\u6001\u7c7b\u522b\uff08\u5982\u53ef\u80fd\u3001\u4e0d\u53ef\u80fd\u3001\u8352\u8c2c\u7b49\uff09\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u73b0\u6709LMs\u5728\u6a21\u6001\u5224\u522b\u65b9\u9762\u7684\u8868\u73b0\u53ca\u5176\u5185\u90e8\u673a\u5236\u3002", "method": "\u672c\u6587\u5206\u6790\u4e86\u5404\u7c7b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6fc0\u6d3b\u6a21\u5f0f\uff0c\u901a\u8fc7\u8bc6\u522b\u80fd\u533a\u5206\u6a21\u6001\u7c7b\u522b\u7684\u7ebf\u6027\u8868\u5f81\uff08\u5373\u201c\u6a21\u6001\u5dee\u5f02\u5411\u91cf\u201d\uff09\uff0c\u5e76\u5229\u7528\u8be5\u8868\u5f81\u4e0e\u4eba\u7c7b\u5224\u522b\u6570\u636e\u8fdb\u884c\u76f8\u5173\u6027\u5206\u6790\uff0c\u91c7\u7528\u4e86\u673a\u5236\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u7ed3\u5408\u8bad\u7ec3\u6b65\u9aa4\u3001\u6a21\u578b\u5c42\u6570\u548c\u53c2\u6570\u91cf\u7b49\u56e0\u7d20\u8fdb\u4e00\u6b65\u5206\u6790\u5176\u6f14\u53d8\u8fc7\u7a0b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5b9e\u9645LMs\u5bf9\u53e5\u5b50\u6a21\u6001\u5206\u7c7b\u7684\u80fd\u529b\u4f18\u4e8e\u6b64\u524d\u62a5\u544a\u3002\u6a21\u6001\u5dee\u5f02\u5411\u91cf\u968f\u7740\u6a21\u578b\u80fd\u529b\u63d0\u5347\uff08\u8bad\u7ec3\u8fdb\u5ea6\u3001\u7ed3\u6784\u590d\u6742\u5ea6\u7b49\uff09\u800c\u4ee5\u4e00\u81f4\u987a\u5e8f\u51fa\u73b0\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u5411\u91cf\u6295\u5f71\u503c\u4e0e\u4eba\u7c7b\u53d7\u8bd5\u8005\u5bf9\u53ef\u89e3\u91ca\u7279\u5f81\u7684\u8bc4\u5206\u5448\u826f\u597d\u76f8\u5173\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u6001\u5224\u522b\u65b9\u9762\u7684\u6f5c\u529b\u548c\u5185\u90e8\u673a\u5236\uff0c\u4e3a\u7406\u89e3\u548c\u63d0\u5347\u6a21\u578b\u53ca\u4eba\u7c7b\u7684\u6a21\u6001\u5206\u7c7b\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u548c\u5de5\u5177\u3002"}}
{"id": "2507.12494", "categories": ["cs.AI", "cs.GT", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.12494", "abs": "https://arxiv.org/abs/2507.12494", "authors": ["Dustin Holley", "Jovin D'sa", "Hossein Nourkhiz Mahjoub", "Gibran Ali"], "title": "MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents", "comment": "8 pages", "summary": "Enhancing simulation environments to replicate real-world driver behavior,\ni.e., more humanlike sim agents, is essential for developing autonomous vehicle\ntechnology. In the context of highway merging, previous works have studied the\noperational-level yielding dynamics of lag vehicles in response to a merging\ncar at highway on-ramps. Other works focusing on tactical decision modeling\ngenerally consider limited action sets or utilize payoff functions with large\nparameter sets and limited payoff bounds. In this work, we aim to improve the\nsimulation of the highway merge scenario by targeting a game theoretic model\nfor tactical decision-making with improved payoff functions and lag actions. We\ncouple this with an underlying dynamics model to have a unified decision and\ndynamics model that can capture merging interactions and simulate more\nrealistic interactions in an explainable and interpretable fashion. The\nproposed model demonstrated good reproducibility of complex interactions when\nvalidated on a real-world dataset. The model was finally integrated into a high\nfidelity simulation environment and confirmed to have adequate computation time\nefficiency for use in large-scale simulations to support autonomous vehicle\ndevelopment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u535a\u5f08\u8bba\u51b3\u7b56\u4e0e\u52a8\u529b\u5b66\u7684\u7edf\u4e00\u6a21\u578b\uff0c\u80fd\u66f4\u771f\u5b9e\u89e3\u91ca\u548c\u6a21\u62df\u9ad8\u901f\u516c\u8def\u5e76\u9053\u573a\u666f\u4e0b\u7684\u590d\u6742\u4eba\u7c7b\u9a7e\u9a76\u884c\u4e3a\uff0c\u5e76\u5df2\u9a8c\u8bc1\u5176\u5728\u771f\u5b9e\u6570\u636e\u548c\u5927\u89c4\u6a21\u4eff\u771f\u4e2d\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "motivation": "\u63d0\u9ad8\u4eff\u771f\u73af\u5883\u5bf9\u73b0\u5b9e\u4e2d\u9a7e\u9a76\u5458\u884c\u4e3a\u7684\u8fd8\u539f\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u9ad8\u901f\u516c\u8def\u5e76\u9053\u573a\u666f\u4e0b\uff0c\u4f7f\u4eff\u771f\u667a\u80fd\u4f53\u66f4\u52a0\u63a5\u8fd1\u4eba\u7c7b\u9a7e\u9a76\u884c\u4e3a\uff0c\u4ece\u800c\u66f4\u597d\u5730\u652f\u6301\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6539\u8fdb\u6536\u76ca\u51fd\u6570\u548c\u6ede\u540e\u52a8\u4f5c\u7684\u535a\u5f08\u8bba\u51b3\u7b56\u6a21\u578b\uff0c\u5e76\u4e0e\u5e95\u5c42\u52a8\u529b\u5b66\u6a21\u578b\u7ed3\u5408\uff0c\u5f62\u6210\u7edf\u4e00\u7684\u51b3\u7b56\u4e0e\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u5bf9\u590d\u6742\u5e76\u9053\u4e92\u52a8\u8fdb\u884c\u5efa\u6a21\u548c\u89e3\u91ca\u3002", "result": "\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u5bf9\u590d\u6742\u4ea4\u4e92\u7684\u9ad8\u5ea6\u590d\u73b0\u80fd\u529b\uff0c\u5e76\u88ab\u96c6\u6210\u81f3\u9ad8\u7cbe\u5ea6\u4eff\u771f\u5e73\u53f0\uff0c\u8ba1\u7b97\u6548\u7387\u4e5f\u8fbe\u5230\u4e86\u5927\u89c4\u6a21\u4eff\u771f\u9700\u6c42\u3002", "conclusion": "\u6240\u63d0\u6a21\u578b\u80fd\u5728\u9ad8\u901f\u516c\u8def\u5e76\u9053\u4eff\u771f\u4e2d\u6709\u6548\u518d\u73b0\u4eba\u7c7b\u9a7e\u9a76\u7684\u590d\u6742\u4ea4\u4e92\uff0c\u4e14\u9002\u7528\u4e8e\u652f\u6301\u81ea\u52a8\u9a7e\u9a76\u7814\u53d1\u7684\u5927\u89c4\u6a21\u4eff\u771f\u73af\u5883\u3002"}}
{"id": "2507.12745", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2507.12745", "abs": "https://arxiv.org/abs/2507.12745", "authors": ["Hang Fan", "Weican Liu", "Zuhan Zhang", "Ying Lu", "Wencai Run", "Dunnan Liu"], "title": "IDS-Net: A novel framework for few-shot photovoltaic power prediction with interpretable dynamic selection and feature information fusion", "comment": null, "summary": "With the growing demand for renewable energy, countries are accelerating the\nconstruction of photovoltaic (PV) power stations. However, accurately\nforecasting power data for newly constructed PV stations is extremely\nchallenging due to limited data availability. To this end, we propose a novel\ninterpretable dynamic selection network (IDS-Net) based on feature information\nfusion to achieve accurate few-shot prediction. This transfer learning\nframework primarily consists of two parts. In the first stage, we pre-train on\nthe large dataset, utilizing Maximum Mean Discrepancy (MMD) to select the\nsource domain dataset most similar to the target domain data distribution.\nSubsequently, the ReliefF algorithm is utilized for feature selection, reducing\nthe influence of feature redundancy. Then, the Hampel Identifier (HI) is used\nfor training dataset outlier correction. In the IDS-Net model, we first obtain\nthe initial extracted features from a pool of predictive models. Following\nthis, two separate weighting channels are utilized to determine the\ninterpretable weights for each sub-model and the adaptive selection outcomes,\nrespectively. Subsequently, the extracted feature results from each sub-model\nare multiplied by their corresponding weights and then summed to obtain the\nweighted extracted features. Then, we perform cross-embedding on the additional\nfeatures and fuse them with the extracted weighted features. This fused\ninformation is then passed through the MLP (Multi-Layer Perceptron) layer to\nobtain predictions. In the second stage, we design an end-to-end adaptive\ntransfer learning strategy to obtain the final prediction results on the target\ndataset. We validate the transfer learning process using two PV power datasets\nfrom Hebei province, China, to demonstrate the effectiveness and generalization\nof our framework and transfer learning strategy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u8fc1\u79fb\u5b66\u4e60\u4e0e\u7279\u5f81\u878d\u5408\u65b9\u6cd5IDS-Net\uff0c\u7528\u4e8e\u89e3\u51b3\u65b0\u5efa\u5149\u4f0f\u7535\u7ad9\u6570\u636e\u7a00\u7f3a\u4e0b\u7684\u7535\u529b\u9884\u6d4b\u96be\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6570\u636e\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6548\u679c\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u7531\u4e8e\u65b0\u5efa\u5149\u4f0f\uff08PV\uff09\u7535\u7ad9\u6570\u636e\u6709\u9650\uff0c\u5bfc\u81f4\u7535\u529b\u9884\u6d4b\u5177\u6709\u5f88\u5927\u6311\u6218\uff0c\u800c\u53ef\u518d\u751f\u80fd\u6e90\u7684\u9700\u6c42\u663e\u8457\u589e\u957f\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u51fa\u9ad8\u6548\u7684\u6570\u636e\u5c11\u91cf\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7279\u5f81\u4fe1\u606f\u878d\u5408\u7684\u53ef\u89e3\u91ca\u52a8\u6001\u9009\u62e9\u7f51\u7edc\uff08IDS-Net\uff09\uff0c\u7ed3\u5408\u8fc1\u79fb\u5b66\u4e60\uff0c\u5305\u62ec\uff081\uff09\u9884\u8bad\u7ec3\u548c\u6570\u636e\u96c6\u76f8\u4f3c\u6027\u9009\u62e9\uff0c\u7279\u5f81\u9009\u62e9\u4e0e\u5f02\u5e38\u503c\u6821\u6b63\uff1b\uff082\uff09IDS-Net\u591a\u6a21\u578b\u7279\u5f81\u63d0\u53d6\u4e0e\u52a0\u6743\uff0c\u7279\u5f81\u878d\u5408\uff0c\u5e76\u901a\u8fc7MLP\u9884\u6d4b\uff1b\uff083\uff09\u7aef\u5230\u7aef\u81ea\u9002\u5e94\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\uff0c\u6700\u7ec8\u5b8c\u6210\u5bf9\u76ee\u6807\u6570\u636e\u96c6\u7684\u9884\u6d4b\u3002", "result": "\u4f7f\u7528\u6cb3\u5317\u7701\u4e24\u4e2a\u5149\u4f0f\u7535\u529b\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u548c\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u5b9e\u73b0\u5bf9\u65b0\u5efa\u5149\u4f0f\u7535\u7ad9\u7684\u5c0f\u6837\u672c\u9ad8\u7cbe\u5ea6\u9884\u6d4b\uff0c\u6709\u5f88\u597d\u7684\u8fc1\u79fb\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.13008", "categories": ["cs.CY", "cs.HC", "J.4; K.4.1; K.4.2"], "pdf": "https://arxiv.org/pdf/2507.13008", "abs": "https://arxiv.org/abs/2507.13008", "authors": ["Amanda Menking", "Mona Elswah", "David J. Gr\u00fcning", "Lasse H. Hansen", "Irene Huang", "Julia Kamin", "Catrine Normann"], "title": "Bridging Boundaries: How to Foster Effective Research Collaborations Across Affiliations in the Field of Trust and Safety", "comment": "19 pages, no figures", "summary": "As the field of Trust and Safety in digital spaces continues to grow, it has\nbecome increasingly necessary - but also increasingly complex - to collaborate\non research across the academic, industry, governmental and non-governmental\nsectors. This paper examines how cross-affiliation research partnerships can be\nstructured to overcome misaligned incentives, timelines and constraints while\ndelivering on the unique strengths of each stakeholder. Drawing on our own\nexperience of cross-sector collaboration, we define the main types of\naffiliation and highlight the common differences in research priorities,\noperational pressures and evaluation metrics across sectors. We then propose a\npractical, step-by-step framework for initiating and managing effective\ncollaborations, including strategies for building trust, aligning goals, and\ndistributing roles. We emphasize the critical yet often invisible work of\narticulation and argue that cross-sector partnerships are essential for\ndeveloping more ethical, equitable and impactful research in trust and safety.\nUltimately, we advocate collaborative models that prioritize inclusivity,\ntransparency and real-world relevance in order to meet the interdisciplinary\ndemands of this emerging field.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u6570\u5b57\u7a7a\u95f4\u4fe1\u4efb\u4e0e\u5b89\u5168\u9886\u57df\u8de8\u90e8\u95e8\u7814\u7a76\u5408\u4f5c\u7684\u6311\u6218\u548c\u91cd\u8981\u6027\uff0c\u63d0\u51fa\u4e86\u5177\u4f53\u6846\u67b6\u548c\u7b56\u7565\uff0c\u5f3a\u8c03\u5305\u5bb9\u548c\u900f\u660e\u7684\u5408\u4f5c\u6a21\u5f0f\u5bf9\u4e8e\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u7531\u4e8e\u6570\u5b57\u7a7a\u95f4\u7684\u4fe1\u4efb\u4e0e\u5b89\u5168\u8bae\u9898\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u5b66\u754c\u3001\u4e1a\u754c\u3001\u653f\u5e9c\u548c\u975e\u653f\u5e9c\u90e8\u95e8\u4e4b\u95f4\u5f00\u5c55\u5408\u4f5c\uff0c\u4f46\u73b0\u5b9e\u4e2d\u5404\u65b9\u6fc0\u52b1\u3001\u5468\u671f\u4e0e\u9650\u5236\u5e38\u5e38\u4e0d\u4e00\u81f4\uff0c\u5f71\u54cd\u5408\u4f5c\u6548\u679c\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u81ea\u8eab\u8de8\u90e8\u95e8\u5408\u4f5c\u7ecf\u9a8c\uff0c\u603b\u7ed3\u4e0d\u540c\u90e8\u95e8\u95f4\u7684\u5dee\u5f02\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u3001\u53ef\u64cd\u4f5c\u7684\u5408\u4f5c\u6846\u67b6\uff0c\u5305\u62ec\u5efa\u7acb\u4fe1\u4efb\u3001\u76ee\u6807\u5bf9\u9f50\u548c\u89d2\u8272\u5206\u914d\u7684\u7b56\u7565\u3002", "result": "\u5b9a\u4e49\u4e86\u4e3b\u8981\u7684\u90e8\u95e8\u7c7b\u578b\uff0c\u5c55\u793a\u4e86\u90e8\u95e8\u95f4\u5728\u7814\u7a76\u4f18\u5148\u7ea7\u3001\u8fd0\u8425\u538b\u529b\u548c\u8bc4\u4f30\u6807\u51c6\u7684\u4e0d\u540c\uff0c\u5e76\u7ed9\u51fa\u4e86\u542f\u52a8\u548c\u7ba1\u7406\u6709\u6548\u5408\u4f5c\u7684\u5b9e\u7528\u6b65\u9aa4\u548c\u5efa\u8bae\u3002\u5f3a\u8c03\u4e86\u5408\u4f5c\u4e2d\u201c\u8868\u8ff0\u6027\u201d\u5de5\u4f5c\u7684\u4ef7\u503c\uff0c\u5e76\u4e3b\u5f20\u5408\u4f5c\u6a21\u5f0f\u9700\u6ce8\u91cd\u5305\u5bb9\u6027\u3001\u900f\u660e\u6027\u548c\u73b0\u5b9e\u610f\u4e49\u3002", "conclusion": "\u8de8\u90e8\u95e8\u5408\u4f5c\u5bf9\u4e8e\u6570\u5b57\u7a7a\u95f4\u4e2d\u7684\u4fe1\u4efb\u4e0e\u5b89\u5168\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u63a8\u52a8\u66f4\u5177\u4f26\u7406\u6027\u3001\u516c\u5e73\u6027\u4e0e\u5f71\u54cd\u529b\u7684\u7814\u7a76\u3002"}}
{"id": "2507.12672", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.12672", "abs": "https://arxiv.org/abs/2507.12672", "authors": ["Abu-Viskhan A. Umishov", "Vladislav A. Grigorian"], "title": "The first open machine translation system for the Chechen language", "comment": "7 pages", "summary": "We introduce the first open-source model for translation between the\nvulnerable Chechen language and Russian, and the dataset collected to train and\nevaluate it. We explore fine-tuning capabilities for including a new language\ninto a large language model system for multilingual translation NLLB-200. The\nBLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for\ntranslation from Russian to Chechen and reverse direction, respectively. The\nrelease of the translation models is accompanied by the distribution of\nparallel words, phrases and sentences corpora and multilingual sentence encoder\nadapted to the Chechen language.", "AI": {"tldr": "\u9996\u6b21\u5b9e\u73b0\u4e86\u8f66\u81e3\u8bed\u4e0e\u4fc4\u8bed\u4e4b\u95f4\u7684\u5f00\u6e90\u673a\u5668\u7ffb\u8bd1\u6a21\u578b\u53ca\u6570\u636e\u96c6\u6784\u5efa\uff0c\u53d6\u5f97\u4e86\u53ef\u7528\u7684\u7ffb\u8bd1\u6548\u679c\uff0c\u5e76\u63a8\u52a8\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u6280\u672f\u7684\u53d1\u5c55\u3002", "motivation": "\u8f66\u81e3\u8bed\u662f\u4e00\u79cd\u6fd2\u5371\u8bed\u8a00\uff0c\u5728\u73b0\u6709\u7684\u591a\u8bed\u79cd\u7ffb\u8bd1\u7cfb\u7edf\u4e2d\u9c9c\u6709\u652f\u6301\u3002\u672c\u7814\u7a76\u65e8\u5728\u4e3a\u8f66\u81e3\u8bed\u4e0e\u4fc4\u8bed\u4e4b\u95f4\u7684\u7ffb\u8bd1\u5efa\u7acb\u7b2c\u4e00\u4e2a\u5f00\u6e90\u6a21\u578b\uff0c\u5e76\u63a8\u52a8\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6280\u672f\u53d1\u5c55\u3002", "method": "\u672c\u7814\u7a76\u6536\u96c6\u5e76\u6784\u5efa\u4e86\u7528\u4e8e\u8f66\u81e3\u8bed\u548c\u4fc4\u8bed\u4e92\u8bd1\u7684\u5e73\u884c\u8bed\u6599\u5e93\uff0c\u5e76\u57fa\u4e8eNLLB-200\u5927\u578b\u591a\u8bed\u79cd\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u63a2\u7d22\u4e86\u901a\u8fc7\u5fae\u8c03\u5c06\u65b0\u8bed\u8a00\u7eb3\u5165\u7cfb\u7edf\u7684\u6280\u672f\u8def\u5f84\u3002\u8fd8\u53d1\u5e03\u4e86\u76f8\u5e94\u7684\u591a\u8bed\u79cd\u53e5\u5b50\u7f16\u7801\u5668\u5e76\u5bf9\u5176\u8fdb\u884c\u4e86\u8f66\u81e3\u8bed\u9002\u914d\u3002", "result": "\u4fc4\u8bed\u5230\u8f66\u81e3\u8bed\u7684\u7ffb\u8bd1\u6a21\u578bBLEU\u5206\u6570\u4e3a8.34\uff0cChrF++\u5206\u6570\u4e3a34.69\uff1b\u8f66\u81e3\u8bed\u5230\u4fc4\u8bed\u65b9\u5411\u5206\u522b\u4e3a20.89\u548c44.55\u3002\u76f8\u5e94\u8bed\u6599\u548c\u6a21\u578b\u5747\u5df2\u5f00\u6e90\u53d1\u5e03\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u4e3a\u8f66\u81e3\u8bed\u4e0e\u4fc4\u8bed\u4e4b\u95f4\u7684\u673a\u5668\u7ffb\u8bd1\u63d0\u4f9b\u4e86\u516c\u5f00\u7684\u6280\u672f\u57fa\u7840\u548c\u6570\u636e\u8d44\u6e90\uff0c\u4e3a\u6fd2\u5371\u8bed\u8a00\u7684\u4fe1\u606f\u5316\u4fdd\u62a4\u548c\u591a\u8bed\u79cd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u652f\u6301\u3002"}}
{"id": "2507.12599", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.12599", "abs": "https://arxiv.org/abs/2507.12599", "authors": ["L\u00e9o Sauli\u00e8res"], "title": "A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs", "comment": "69 pages, 19 figures", "summary": "The success of recent Artificial Intelligence (AI) models has been\naccompanied by the opacity of their internal mechanisms, due notably to the use\nof deep neural networks. In order to understand these internal mechanisms and\nexplain the output of these AI models, a set of methods have been proposed,\ngrouped under the domain of eXplainable AI (XAI). This paper focuses on a\nsub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims\nto explain the actions of an agent that has learned by reinforcement learning.\nWe propose an intuitive taxonomy based on two questions \"What\" and \"How\". The\nfirst question focuses on the target that the method explains, while the second\nrelates to the way the explanation is provided. We use this taxonomy to provide\na state-of-the-art review of over 250 papers. In addition, we present a set of\ndomains close to XRL, which we believe should get attention from the community.\nFinally, we identify some needs for the field of XRL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u2018What-How\u2019\u7684\u5206\u7c7b\u6cd5\uff0c\u5bf9250\u591a\u7bc7\u53ef\u89e3\u91ca\u6027\u5f3a\u5316\u5b66\u4e60\u6587\u732e\u8fdb\u884c\u4e86\u7efc\u8ff0\uff0c\u6307\u51fa\u4e86\u8be5\u9886\u57df\u5c1a\u9700\u5173\u6ce8\u7684\u65b9\u5411\u4e0e\u9700\u6c42\u3002", "motivation": "\u8fd1\u5e74\u6765\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u53d8\u5f97\u8d8a\u6765\u8d8a\u6666\u6da9\uff0c\u5c24\u5176\u662f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5bfc\u81f4\u6a21\u578b\u8f93\u51fa\u96be\u4ee5\u89e3\u91ca\u3002\u4e3a\u6b64\uff0c\u8bde\u751f\u4e86\u4e00\u7cfb\u5217\u53ef\u89e3\u91ca\u6027\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u65b9\u6cd5\u3002\u672c\u6587\u805a\u7126\u4e8eXAI\u7684\u4e00\u4e2a\u7ec6\u5206\u9886\u57df\u2014\u2014\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\uff08XRL\uff09\uff0c\u76ee\u7684\u662f\u89e3\u91ca\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u51fa\u6765\u7684\u667a\u80fd\u4f53\u6240\u505a\u51fa\u7684\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u201c\u662f\u4ec0\u4e48\u201d\uff08What\uff09\u548c\u201c\u5982\u4f55\u505a\u201d\uff08How\uff09\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\u7684\u76f4\u89c2\u5206\u7c7b\u6cd5\u3002\u57fa\u4e8e\u8be5\u5206\u7c7b\u6cd5\uff0c\u4f5c\u8005\u5bf9250\u4f59\u7bc7\u76f8\u5173\u6587\u732e\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0eXRL\u5bc6\u5207\u76f8\u5173\u4f46\u5c1a\u672a\u5f15\u8d77\u8db3\u591f\u91cd\u89c6\u7684\u7814\u7a76\u9886\u57df\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u57fa\u4e8e\u2018What\u2019\u548c\u2018How\u2019\u7684\u5206\u7c7b\u6807\u51c6\uff0c\u603b\u7ed3\u4e86\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u68b3\u7406\u4e86250\u591a\u7bc7\u8bba\u6587\uff0c\u53d1\u73b0\u5e76\u5f3a\u8c03\u4e86\u4e0eXRL\u7d27\u5bc6\u76f8\u5173\u4f46\u53d1\u5c55\u4e0d\u5145\u5206\u7684\u9886\u57df\uff0c\u5e76\u603b\u7ed3\u4e86\u8be5\u9886\u57df\u672a\u6765\u7684\u53d1\u5c55\u9700\u6c42\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u7684\u65b0\u5206\u7c7b\u6cd5\uff0c\u5bf9\u5f53\u524d\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u7684\u7814\u7a76\u6210\u679c\u8fdb\u884c\u4e86\u68b3\u7406\u4e0e\u8bc4\u4ef7\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u8be5\u9886\u57df\u7684\u82e5\u5e72\u9700\u6c42\u548c\u672a\u6765\u5173\u6ce8\u65b9\u5411\u3002"}}
{"id": "2507.12835", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2507.12835", "abs": "https://arxiv.org/abs/2507.12835", "authors": ["Yen-Ku Liu", "Yun-Huei Pan", "Pei-Fan Lu", "Yun-Cheng Tsai", "Samuel Yen-Chi Chen"], "title": "Quantum-Enhanced Reinforcement Learning with LSTM Forecasting Signals for Optimizing Fintech Trading Decisions", "comment": null, "summary": "Financial trading environments are characterized by high volatility, numerous\nmacroeconomic signals, and dynamically shifting market regimes, where\ntraditional reinforcement learning methods often fail to deliver breakthrough\nperformance. In this study, we design a reinforcement learning framework\ntailored for financial systems by integrating quantum circuits. We compare (1)\nthe performance of classical A3C versus quantum A3C algorithms, and (2) the\nimpact of incorporating LSTM-based predictions of the following week's economic\ntrends on learning outcomes. The experimental framework adopts a custom\nGymnasium-compatible trading environment, simulating discrete trading actions\nand evaluating rewards based on portfolio feedback. Experimental results show\nthat quantum models - especially when combined with predictive signals -\ndemonstrate superior performance and stability under noisy financial\nconditions, even with shallow quantum circuit depth.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u5e76\u6d4b\u8bd5\u4e86\u7ed3\u5408\u91cf\u5b50\u7535\u8def\u548cLSTM\u4fe1\u53f7\u7684\u5f3a\u5316\u5b66\u4e60\u4ea4\u6613\u7cfb\u7edf\uff0c\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u8f83\u4f20\u7edf\u65b9\u6cd5\uff0c\u91cf\u5b50\u6a21\u578b\u5728\u4e0d\u7a33\u5b9a\u7684\u91d1\u878d\u73af\u5883\u4e2d\u8868\u73b0\u66f4\u597d\u4e14\u66f4\u7a33\u5b9a\u3002", "motivation": "\u7531\u4e8e\u91d1\u878d\u4ea4\u6613\u73af\u5883\u9ad8\u5ea6\u6ce2\u52a8\u3001\u590d\u6742\u4e14\u5e02\u573a\u72b6\u6001\u4e0d\u65ad\u53d8\u5316\uff0c\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u8fd9\u4e00\u573a\u666f\u4e0b\u8868\u73b0\u6709\u9650\uff0c\u56e0\u6b64\u52a8\u529b\u6765\u6e90\u4e8e\u63a2\u7d22\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60\u662f\u5426\u80fd\u591f\u5e26\u6765\u7a81\u7834\u6027\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u91cf\u5b50\u7535\u8def\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u6bd4\u8f83\u4e86\u7ecf\u5178A3C\u548c\u91cf\u5b50A3C\u7b97\u6cd5\u7684\u6548\u679c\uff0c\u8fd8\u8003\u5bdf\u4e86\u5f15\u5165LSTM\u9884\u6d4b\u7ecf\u6d4e\u8d8b\u52bf\u4fe1\u53f7\u5bf9\u5b66\u4e60\u8868\u73b0\u7684\u5f71\u54cd\u3002\u91c7\u7528\u81ea\u5b9a\u4e49\u7684\u3001\u517c\u5bb9Gymnasium\u7684\u4ea4\u6613\u73af\u5883\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6a21\u62df\u79bb\u6563\u4ea4\u6613\u884c\u4e3a\u5e76\u4ee5\u6295\u8d44\u7ec4\u5408\u53cd\u9988\u4e3a\u5956\u52b1\u3002", "result": "\u91cf\u5b50A3C\u7b97\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u7ed3\u5408LSTM\u9884\u6d4b\u4fe1\u53f7\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u6bd4\u7ecf\u5178A3C\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u4ea4\u6613\u7b56\u7565\u548c\u66f4\u5f3a\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "\u91cf\u5b50\u6a21\u578b\uff0c\u7279\u522b\u662f\u7ed3\u5408LSTM\u7ecf\u6d4e\u8d8b\u52bf\u9884\u6d4b\u4fe1\u53f7\u65f6\uff0c\u5728\u5608\u6742\u91d1\u878d\u73af\u5883\u4e0b\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff0c\u5373\u4fbf\u91cf\u5b50\u7535\u8def\u5c42\u6b21\u8f83\u6d45\u3002"}}
{"id": "2507.13100", "categories": ["cs.CY", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2507.13100", "abs": "https://arxiv.org/abs/2507.13100", "authors": ["Severin Diepolder", "Andrea Araldo", "Tarek Chouaki", "Santa Maiti", "Sebastian H\u00f6rl", "Constantinos Antoniou"], "title": "Quantifying the Improvement of Accessibility achieved via Shared Mobility on Demand", "comment": null, "summary": "Shared Mobility Services (SMS), e.g., demand-responsive transport or\nride-sharing, can improve mobility in low-density areas, which are often poorly\nserved by conventional Public Transport (PT). Such improvement is generally\nmeasured via basic performance indicators, such as waiting or travel time.\nHowever, such basic indicators do not account for the most important\ncontribution that SMS can provide to territories, i.e., increasing the\npotential, for users, to reach surrounding opportunities, such as jobs,\nschools, businesses, etc. Such potential can be measured by isochrone-based\naccessibility indicators, which count the number of opportunities reachable in\na limited time, and are thus easy for the public to understand. % The potential\nimpact of SMS on accessibility has been qualitatively discussed and\nimplications on equity have been empirically studied. However, to date, there\nare no quantitative methods to compute isochrone-based indicators of the\naccessibility achieved via SMS.\n  This work fills this gap by proposing a first method to compute isochrone\naccessibility of PT systems composed of conventional PT and SMS, acting as a\nfeeder for access and egress trips to/from PT hubs. This method is grounded on\nspatial-temporal statistical analysis, performed via Kriging. It takes as input\nobserved trips of SMS and summarizes them in a graph. On such a graph,\nisochrone accessibility indicators are computed. We apply the proposed method\nto a MATSim simulation study concerning demand-responsive transport integrated\ninto PT, in the suburban area of Paris-Saclay.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u7ed3\u5408\u5171\u4eab\u51fa\u884c\u4e0e\u4f20\u7edf\u516c\u5171\u4ea4\u901a\u7684\u53ef\u8fbe\u6027\u5b9a\u91cf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a7a\u95f4\u7edf\u8ba1\u6280\u672f\uff0c\u5c06\u5b9e\u9645SMS\u884c\u7a0b\u8f6c\u5316\u4e3a\u7b49\u65f6\u7ebf\u53ef\u8fbe\u6027\u6307\u6807\uff0c\u5e76\u5728\u5df4\u9ece\u90ca\u533a\u5b9e\u9645\u4eff\u771f\u4e2d\u9a8c\u8bc1\uff0c\u4e3a\u4ea4\u901a\u7cfb\u7edf\u4f18\u5316\u548c\u8861\u91cfSMS\u6548\u76ca\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002", "motivation": "\u5171\u4eab\u51fa\u884c\u670d\u52a1\uff08SMS\uff09\u80fd\u591f\u63d0\u5347\u4f4e\u5bc6\u5ea6\u5730\u533a\u7684\u51fa\u884c\u4fbf\u5229\u6027\uff0c\u8fd9\u4e9b\u5730\u533a\u5e38\u89c4\u516c\u5171\u4ea4\u901a\u8986\u76d6\u8f83\u5dee\u3002\u4f20\u7edf\u8bc4\u4f30\u591a\u4f9d\u8d56\u7b49\u5f85\u6216\u51fa\u884c\u65f6\u95f4\u7b49\u57fa\u7840\u6307\u6807\uff0c\u65e0\u6cd5\u4f53\u73b0SMS\u63d0\u5347\u7528\u6237\u53ef\u8fbe\u6027\u7684\u6838\u5fc3\u4f5c\u7528\uff0c\u5373\u6269\u5927\u7528\u6237\u5728\u6709\u9650\u65f6\u95f4\u5185\u53ef\u5230\u8fbe\u7684\u5de5\u4f5c\u3001\u5b66\u6821\u3001\u5546\u4e1a\u7b49\u673a\u4f1a\u3002", "method": "\u63d0\u51fa\u9996\u4e2a\u57fa\u4e8eIsochrone\uff08\u7b49\u65f6\u7ebf\uff09\u7684\u53ef\u8fbe\u6027\u91cf\u5316\u8ba1\u7b97\u65b9\u6cd5\uff0c\u7ed3\u5408\u4f20\u7edf\u516c\u5171\u4ea4\u901a\u4e0eSMS\uff0cSMS\u4f5c\u4e3a\u8fdb\u51fa\u67a2\u7ebd\u8865\u5145\u65b9\u5f0f\u3002\u65b9\u6cd5\u91c7\u7528\u7a7a\u95f4-\u65f6\u95f4\u7edf\u8ba1\u5206\u6790\uff08Kriging\u5730\u7edf\u8ba1\uff09\uff0c\u4ee5\u89c2\u6d4b\u5230\u7684SMS\u884c\u7a0b\u751f\u6210\u56fe\u7ed3\u6784\uff0c\u518d\u5728\u8be5\u56fe\u4e0a\u8ba1\u7b97\u7b49\u65f6\u7ebf\u53ef\u8fbe\u6027\u6307\u6807\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5df4\u9ece\u90ca\u533aSaclay\u533a\u7684\u9700\u6c42\u54cd\u5e94\u4ea4\u901a\u96c6\u6210\u516c\u5171\u4ea4\u901aMATSim\u4eff\u771f\u6848\u4f8b\u4e2d\u5e94\u7528\uff0c\u80fd\u591f\u91cf\u5316SMS\u4e0ePT\u7ec4\u5408\u7cfb\u7edf\u4e0b\u7684\u4e0d\u540c\u65f6\u57df\u53ef\u8fbe\u6027\u3002", "conclusion": "\u9996\u6b21\u7ed9\u51fa\u4e86SMS\u4e0e\u4f20\u7edfPT\u878d\u5408\u96c6\u6210\u7cfb\u7edf\u53ef\u8fbe\u6027\u53ef\u91cf\u5316\u6d4b\u7b97\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u57fa\u4e8e\u7b49\u65f6\u7ebf\u7684\u53ef\u8fbe\u6027\u91cf\u5316\u8bc4\u4ef7\u7a7a\u767d\uff0c\u5bf9SMS\u63d0\u5347\u4ea4\u901a\u516c\u5e73\u6027\u548c\u51fa\u884c\u673a\u4f1a\u5177\u6709\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2507.12679", "categories": ["cs.CL", "q-bio.QM", "I.2.7; J.3"], "pdf": "https://arxiv.org/pdf/2507.12679", "abs": "https://arxiv.org/abs/2507.12679", "authors": ["Arthur J. Funnell", "Panayiotis Petousis", "Fabrice Harel-Canada", "Ruby Romero", "Alex A. T. Bui", "Adam Koncsol", "Hritika Chaturvedi", "Chelsea Shover", "David Goodman-Meza"], "title": "Improving Drug Identification in Overdose Death Surveillance using Large Language Models", "comment": "30 pages, 1 figure, 4 tables, 2 supplemental figures, 4 supplemental\n  tables, submitted to Journal of Forensic Sciences (JFS)", "summary": "The rising rate of drug-related deaths in the United States, largely driven\nby fentanyl, requires timely and accurate surveillance. However, critical\noverdose data are often buried in free-text coroner reports, leading to delays\nand information loss when coded into ICD (International Classification of\nDisease)-10 classifications. Natural language processing (NLP) models may\nautomate and enhance overdose surveillance, but prior applications have been\nlimited. A dataset of 35,433 death records from multiple U.S. jurisdictions in\n2020 was used for model training and internal testing. External validation was\nconducted using a novel separate dataset of 3,335 records from 2023-2024.\nMultiple NLP approaches were evaluated for classifying specific drug\ninvolvement from unstructured death certificate text. These included\ntraditional single- and multi-label classifiers, as well as fine-tuned\nencoder-only language models such as Bidirectional Encoder Representations from\nTransformers (BERT) and BioClinicalBERT, and contemporary decoder-only large\nlanguage models such as Qwen 3 and Llama 3. Model performance was assessed\nusing macro-averaged F1 scores, and 95% confidence intervals were calculated to\nquantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect\nperformance, with macro F1 scores >=0.998 on the internal test set. External\nvalidation confirmed robustness (macro F1=0.966), outperforming conventional\nmachine learning, general-domain BERT models, and various decoder-only large\nlanguage models. NLP models, particularly fine-tuned clinical variants like\nBioClinicalBERT, offer a highly accurate and scalable solution for overdose\ndeath classification from free-text reports. These methods can significantly\naccelerate surveillance workflows, overcoming the limitations of manual ICD-10\ncoding and supporting near real-time detection of emerging substance use\ntrends.", "AI": {"tldr": "\u901a\u8fc7NLP\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5fae\u8c03\u7684\u4e34\u5e8aBERT\u6a21\u578b\uff0c\u53ef\u9ad8\u5ea6\u51c6\u786e\u4e14\u9ad8\u6548\u5730\u4ece\u9a8c\u5c38\u5b98\u6587\u672c\u62a5\u544a\u4e2d\u8bc6\u522b\u836f\u7269\u8fc7\u91cf\u6b7b\u4ea1\uff0c\u5927\u5927\u52a0\u901f\u4ee3\u7801\u5316\u548c\u76d1\u6d4b\u6d41\u7a0b\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u8868\u73b0\u4f18\u5f02\uff0c\u6709\u52a9\u4e8e\u53d1\u73b0\u6700\u65b0\u6ee5\u7528\u8d8b\u52bf\u3002", "motivation": "\u7f8e\u56fd\u836f\u7269\u76f8\u5173\u6b7b\u4ea1\u7387\u4e0a\u5347\uff0c\u4e3b\u8981\u7531\u82ac\u592a\u5c3c\u9a71\u52a8\uff0c\u4e9f\u9700\u53ca\u65f6\u3001\u51c6\u786e\u7684\u76d1\u6d4b\u3002\u7136\u800c\uff0c\u5173\u952e\u7684\u836f\u7269\u8fc7\u91cf\u6b7b\u4ea1\u6570\u636e\u591a\u9690\u85cf\u5728\u9a8c\u5c38\u5b98\u7684\u81ea\u7531\u6587\u672c\u62a5\u544a\u4e2d\uff0c\u5bfc\u81f4\u901a\u8fc7ICD-10\u7f16\u7801\u65f6\u51fa\u73b0\u5ef6\u8fdf\u548c\u4fe1\u606f\u4e22\u5931\u3002\u73b0\u6709\u4eba\u5de5\u5904\u7406\u65b9\u5f0f\u6548\u7387\u4f4e\u4e0b\uff0c\u96be\u4ee5\u53ca\u65f6\u5e94\u5bf9\u836f\u7269\u6ee5\u7528\u8d8b\u52bf\u53d8\u5316\u3002NLP\uff08\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff09\u6709\u671b\u81ea\u52a8\u5316\u5e76\u63d0\u5347\u8fc7\u91cf\u6b7b\u4ea1\u76d1\u6d4b\u6548\u679c\uff0c\u4f46\u76ee\u524d\u5e94\u7528\u6709\u9650\u3002", "method": "\u6536\u96c6\u4e862020\u5e74\u7f8e\u56fd\u591a\u4e2a\u5730\u533a\u768435,433\u4efd\u6b7b\u4ea1\u8bb0\u5f55\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u4e0e\u5185\u90e8\u6d4b\u8bd5\uff0c\u5916\u90e8\u9a8c\u8bc1\u91c7\u7528\u4e862023-2024\u5e74\u76843,335\u4efd\u5168\u65b0\u8bb0\u5f55\u3002\u6bd4\u8f83\u4e86\u591a\u79cdNLP\u65b9\u6cd5\uff0c\u5305\u62ec\u4f20\u7edf\u7684\u5355\u6807\u7b7e\u548c\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u3001\u5fae\u8c03\u7684\u7f16\u7801\u5668\uff08\u5982BERT\u3001BioClinicalBERT\uff09\u548c\u6700\u65b0\u7684\u89e3\u7801\u5668\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982Qwen 3\u548cLlama 3\uff09\u3002\u4e3b\u8981\u901a\u8fc7macro F1\u5206\u6570\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u8ba1\u7b97\u4e8695%\u7f6e\u4fe1\u533a\u95f4\u3002", "result": "\u5fae\u8c03\u7684BioClinicalBERT\u6a21\u578b\u5728\u5185\u90e8\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u63a5\u8fd1\u5b8c\u7f8e\uff0cmacro F1\u5206\u6570\u22650.998\u3002\u5916\u90e8\u9a8c\u8bc1\u663e\u793a\u5176\u9c81\u68d2\u6027\uff08macro F1=0.966\uff09\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u3001\u901a\u7528BERT\u6a21\u578b\u4ee5\u53ca\u5404\u79cd\u89e3\u7801\u5668\u5927\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u9488\u5bf9\u81ea\u7531\u6587\u672c\u7684\u6b7b\u4ea1\u62a5\u544a\uff0cNLP\u65b9\u6cd5\uff08\u5c24\u5176\u662f\u4e34\u5e8a\u9886\u57df\u5fae\u8c03\u6a21\u578bBioClinicalBERT\uff09\u53ef\u5b9e\u73b0\u6781\u9ad8\u51c6\u786e\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u80fd\u663e\u8457\u63d0\u5347\u836f\u7269\u8fc7\u91cf\u6b7b\u4ea1\u7684\u76d1\u6d4b\u6548\u7387\uff0c\u652f\u6301\u5bf9\u65b0\u5174\u7269\u8d28\u6ee5\u7528\u8d8b\u52bf\u7684\u8fd1\u5b9e\u65f6\u68c0\u6d4b\uff0c\u8d85\u8d8a\u624b\u5de5ICD-10\u7f16\u7801\u5e26\u6765\u7684\u6ede\u540e\u548c\u4fe1\u606f\u635f\u5931\u3002"}}
{"id": "2507.12666", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.12666", "abs": "https://arxiv.org/abs/2507.12666", "authors": ["Alex Zook", "Josef Spjut", "Jonathan Tremblay"], "title": "Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models", "comment": "Published at Reinforcement Learning and Video Games workshop\n  https://sites.google.com/view/rlvg-workshop-2025/home", "summary": "Game design hinges on understanding how static rules and content translate\ninto dynamic player behavior - something modern generative systems that inspect\nonly a game's code or assets struggle to capture. We present an automated\ndesign iteration framework that closes this gap by pairing a reinforcement\nlearning (RL) agent, which playtests the game, with a large multimodal model\n(LMM), which revises the game based on what the agent does. In each loop the RL\nplayer completes several episodes, producing (i) numerical play metrics and/or\n(ii) a compact image strip summarising recent video frames. The LMM designer\nreceives a gameplay goal and the current game configuration, analyses the play\ntraces, and edits the configuration to steer future behaviour toward the goal.\nWe demonstrate results that LMMs can reason over behavioral traces supplied by\nRL agents to iteratively refine game mechanics, pointing toward practical,\nscalable tools for AI-assisted game design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u591a\u6a21\u6001\u5927\u6a21\u578b\u534f\u4f5c\uff0c\u5b9e\u73b0\u4ee5\u73a9\u5bb6\u884c\u4e3a\u4e3a\u4f9d\u636e\u7684\u81ea\u52a8\u5316\u6e38\u620f\u8bbe\u8ba1\u8fed\u4ee3\u6846\u67b6\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u6b64\u65b9\u6cd5\u4f18\u5316\u6e38\u620f\u673a\u5236\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u524d\u666f\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u4ee3\u7801\u6216\u7d20\u6750\u7684\u81ea\u52a8\u751f\u6210\u7cfb\u7edf\uff0c\u96be\u4ee5\u6355\u6349\u9759\u6001\u89c4\u5219\u5230\u73a9\u5bb6\u52a8\u6001\u884c\u4e3a\u7684\u8f6c\u5316\uff0c\u5f71\u54cd\u4e86\u6e38\u620f\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u81ea\u52a8\u5316\u6e38\u620f\u8bbe\u8ba1\u8fed\u4ee3\u6846\u67b6\uff0c\u5c06\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4ee3\u7406\u4f5c\u4e3a\u81ea\u52a8\u6e38\u73a9\u6d4b\u8bd5\u5de5\u5177\uff0c\u4e0e\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMM\uff09\u914d\u5bf9\uff0c\u7531LMM\u6839\u636eRL\u4ee3\u7406\u7684\u884c\u4e3a\u5bf9\u6e38\u620f\u5185\u5bb9\u8fdb\u884c\u4fee\u6539\u3002\u6bcf\u8f6e\u8fed\u4ee3\u4e2d\uff0cRL\u4ee3\u7406\u751f\u6210\u6570\u503c\u6e38\u73a9\u6307\u6807\u548c/\u6216\u89c6\u9891\u5e27\u6458\u8981\uff0c\u7531LMM\u5206\u6790\u4e0e\u7f16\u8f91\u6e38\u620f\u914d\u7f6e\uff0c\u5f15\u5bfc\u884c\u4e3a\u671d\u76ee\u6807\u9760\u8fd1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLMM\u80fd\u57fa\u4e8eRL\u751f\u6210\u7684\u884c\u4e3a\u8f68\u8ff9\u6709\u6548\u63a8\u7406\uff0c\u5e76\u80fd\u8fed\u4ee3\u4f18\u5316\u6e38\u620f\u673a\u5236\uff0c\u5bf9\u5b9e\u9645AI\u8f85\u52a9\u6e38\u620f\u8bbe\u8ba1\u5de5\u5177\u7684\u53ef\u884c\u6027\u548c\u53ef\u6269\u5c55\u6027\u8d77\u5230\u79ef\u6781\u4f5c\u7528\u3002", "conclusion": "\u5c06RL\u4ee3\u7406\u4e0eLMM\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u884c\u4e3a\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u6e38\u620f\u673a\u5236\u4f18\u5316\uff0c\u4e3aAI\u8f85\u52a9\u7684\u6e38\u620f\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u65b0\u65b9\u6848\u3002"}}
{"id": "2507.12901", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2507.12901", "abs": "https://arxiv.org/abs/2507.12901", "authors": ["Xiaoke Zhao", "Zhaowen Zhou", "Lin Chen", "Lihong Wang", "Zhiyi Huang", "Kaiyuan Zheng", "Yanjun Zheng", "Xiyang Du", "Longfei Liao", "Jiawei Liu", "Xiang Qi", "Bo Zhang", "Peng Zhang", "Zhe Li", "Wei Wang"], "title": "Agentar-DeepFinance-300K: A Large-Scale Financial Dataset via Systematic Chain-of-Thought Synthesis Optimization", "comment": null, "summary": "Recent advancements in large language models (LLMs) have demonstrated\nremarkable general reasoning capabilities, holding significant potential for\napplications in the financial domain, a field that requires robust and reliable\nreasoning. It has been demonstrated that distilling high-quality\nchain-of-thought (CoT) rationales from advanced general reasoning models offers\na promising and efficient path to the financial reasoning model. However,\nexisting CoT synthesis methods suffer from shallow CoT sampling, leaving the\nquestion of how to construct a well-designed knowledge space for finance\nreasoning unexplored. In this paper, we present\n\\textbf{Agentar-DeepFinance-300K }, a large-scale financial reasoning dataset\ncharacterized by its systematic CoT synthesis optimization. We first introduce\na comprehensive CoT synthesis pipeline featuring Multi-perspective Knowledge\nExtraction (MKE) and Self-Corrective Rewriting (SCR) to generate exhaustive and\ndeep financial reasoning trajectories. Furthermore, a systematic investigation,\ntermed CoT Cube, is conducted to analyze critical factors that influence CoT\neffectiveness, such as necessity, length and synthesizer, yielding valuable\ninsights for high-quality financial CoT construction. Experiments demonstrate\nthat models trained on our Agentar-DeepFinance-300K achieve significant\nimprovements on financial benchmarks. We publicly release\nAgentar-DeepFinance-300K , hoping to advance the research in financial\nreasoning models.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u5316\u7684CoT\u5408\u6210\u7b56\u7565\uff0c\u6784\u5efa\u4e86\u5927\u578b\u91d1\u878d\u63a8\u7406\u6570\u636e\u96c6Agentar-DeepFinance-300K\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u91d1\u878d\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u91d1\u878d\u9886\u57df\u9700\u8981\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u91d1\u878d\u63a8\u7406\u65b9\u9762\u7684\u94fe\u5f0f\u601d\u8003\uff08CoT\uff09\u91c7\u6837\u8f83\u6d45\uff0c\u7f3a\u4e4f\u6784\u5efa\u7cfb\u7edf\u6027\u91d1\u878d\u63a8\u7406\u77e5\u8bc6\u7a7a\u95f4\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86Agentar-DeepFinance-300K\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u7cfb\u7edf\u5316\u7684CoT\u5408\u6210\u4f18\u5316\u6d41\u7a0b\uff1a\u5305\u62ec\u591a\u89c6\u89d2\u77e5\u8bc6\u63d0\u53d6\uff08MKE\uff09\u548c\u81ea\u6211\u7ea0\u6b63\u91cd\u5199\uff08SCR\uff09\u4ee5\u751f\u6210\u66f4\u6df1\u5c42\u6b21\u3001\u66f4\u5168\u9762\u7684\u91d1\u878d\u63a8\u7406\u8def\u5f84\u3002\u8fd8\u901a\u8fc7CoT Cube\u7cfb\u7edf\u5206\u6790\u5f71\u54cdCoT\u6709\u6548\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5982\u5fc5\u8981\u6027\u3001\u957f\u5ea6\u548c\u5408\u6210\u5668\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728Agentar-DeepFinance-300K\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u91d1\u878d\u57fa\u51c6\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u5927\u89c4\u6a21\u91d1\u878d\u63a8\u7406\u6570\u636e\u96c6\u53ca\u5176\u7cfb\u7edf\u7684\u94fe\u5f0f\u601d\u8003\u5408\u6210\u65b9\u6cd5\uff0c\u4e3a\u8fdb\u4e00\u6b65\u63a8\u52a8\u91d1\u878d\u63a8\u7406\u6a21\u578b\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002\u6570\u636e\u96c6\u5df2\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2507.12695", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.12695", "abs": "https://arxiv.org/abs/2507.12695", "authors": ["S M Rafiuddin", "Sadia Kamal", "Mohammed Rakib", "Arunkumar Bagavathi", "Atriya Sen"], "title": "AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis", "comment": "12 pages (including references), 2 figures (Fig. 1 overview, Fig. 2\n  hyperparameter sensitivity with two subplots), 6 tables (performance,\n  ablation, dataset stats, case studies, etc.), accepted at ASONAM 2025 (Social\n  Network Analysis and Mining)", "summary": "We introduce AdaptiSent, a new framework for Multimodal Aspect-Based\nSentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms\nto improve sentiment classification and aspect term extraction from both text\nand images. Our model integrates dynamic modality weighting and\ncontext-adaptive attention, enhancing the extraction of sentiment and\naspect-related information by focusing on how textual cues and visual context\ninteract. We tested our approach against several baselines, including\ntraditional text-based models and other multimodal methods. Results from\nstandard Twitter datasets show that AdaptiSent surpasses existing models in\nprecision, recall, and F1 score, and is particularly effective in identifying\nnuanced inter-modal relationships that are crucial for accurate sentiment and\naspect term extraction. This effectiveness comes from the model's ability to\nadjust its focus dynamically based on the context's relevance, improving the\ndepth and accuracy of sentiment analysis across various multimodal data sets.\nAdaptiSent sets a new standard for MABSA, significantly outperforming current\nmethods, especially in understanding complex multimodal information.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AdaptiSent\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u6587\u672c\u548c\u56fe\u50cf\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u60c5\u611f\u548c\u65b9\u9762\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u6210\u4e3aMABSA\u9886\u57df\u7684\u65b0\u6807\u6746\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u9762\u5411\u65b9\u9762\u60c5\u611f\u5206\u6790\uff08MABSA\uff09\u5728\u878d\u5408\u6587\u672c\u4e0e\u56fe\u50cf\u4fe1\u606f\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u96be\u4ee5\u5145\u5206\u6355\u6349\u6587\u672c\u4e0e\u89c6\u89c9\u4e4b\u95f4\u7684\u7ec6\u7c92\u5ea6\u4ea4\u4e92\uff0c\u9650\u5236\u4e86\u60c5\u611f\u548c\u65b9\u9762\u5206\u7c7b\u7684\u7cbe\u5ea6\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u6539\u8fdb\u8de8\u6a21\u6001\u5efa\u6a21\u673a\u5236\uff0c\u63d0\u5347\u60c5\u611f\u5206\u6790\u548c\u65b9\u9762\u672f\u8bed\u62bd\u53d6\u8868\u73b0\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u540d\u4e3aAdaptiSent\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\uff0c\u52a8\u6001\u6743\u91cd\u878d\u5408\u6587\u672c\u4e0e\u56fe\u50cf\u4fe1\u606f\uff0c\u5b9e\u73b0\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u6ce8\u610f\u529b\u5206\u914d\u3002\u8be5\u6a21\u578b\u80fd\u591f\u6839\u636e\u5f53\u524d\u60c5\u5883\u7684\u76f8\u5173\u6027\u8c03\u6574\u5173\u6ce8\u91cd\u70b9\uff0c\u66f4\u6709\u6548\u5730\u6574\u5408\u4e24\u79cd\u6a21\u6001\u7684\u4fe1\u606f\u3002", "result": "\u5728\u591a\u4e2a\u6807\u51c6Twitter\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cAdaptiSent\u5728\u7cbe\u51c6\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u6587\u672c\u6a21\u578b\u53ca\u5176\u4ed6\u591a\u6a21\u6001\u65b9\u6cd5\uff0c\u5c24\u5176\u64c5\u957f\u53d1\u73b0\u6587\u672c\u548c\u89c6\u89c9\u95f4\u7684\u590d\u6742\u5173\u7cfb\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u60c5\u611f\u548c\u65b9\u9762\u62bd\u53d6\u3002", "conclusion": "AdaptiSent\u8bbe\u5b9a\u4e86\u591a\u6a21\u6001\u9762\u5411\u65b9\u9762\u60c5\u611f\u5206\u6790\u7684\u65b0\u6807\u51c6\uff0c\u7279\u522b\u64c5\u957f\u7406\u89e3\u590d\u6742\u7684\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u5728\u591a\u9879\u6307\u6807\u4e0a\u5927\u5e45\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.12691", "categories": ["cs.AI", "cs.LG", "I.2.7; K.4.1"], "pdf": "https://arxiv.org/pdf/2507.12691", "abs": "https://arxiv.org/abs/2507.12691", "authors": ["Avi Parrack", "Carlo Leonardo Attubato", "Stefan Heimersheim"], "title": "Benchmarking Deception Probes via Black-to-White Performance Boosts", "comment": "Preprint. 37 pages, 10 figures, 7 tables", "summary": "AI assistants will occasionally respond deceptively to user queries.\nRecently, linear classifiers (called \"deception probes\") have been trained to\ndistinguish the internal activations of a language model during deceptive\nversus honest responses. However, it's unclear how effective these probes are\nat detecting deception in practice, nor whether such probes are resistant to\nsimple counter strategies from a deceptive assistant who wishes to evade\ndetection. In this paper, we compare white-box monitoring (where the monitor\nhas access to token-level probe activations) to black-box monitoring (without\nsuch access). We benchmark deception probes by the extent to which the white\nbox monitor outperforms the black-box monitor, i.e. the black-to-white\nperformance boost. We find weak but encouraging black-to-white performance\nboosts from existing deception probes.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86AI\u52a9\u624b\u6b3a\u9a97\u68c0\u6d4b\u4e2d\u7684\u767d\u76d2\u4e0e\u9ed1\u76d2\u76d1\u63a7\uff0c\u5f53\u524d\u63a2\u9488\u6548\u679c\u4e00\u822c\u4f46\u663e\u793a\u51fa\u4e00\u5b9a\u524d\u666f\u3002", "motivation": "AI\u52a9\u624b\u6709\u65f6\u4f1a\u5bf9\u7528\u6237\u67e5\u8be2\u505a\u51fa\u6b3a\u9a97\u6027\u7684\u56de\u5e94\uff0c\u73b0\u6709\u7684\u201c\u6b3a\u9a97\u63a2\u9488\u201d\u80fd\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u68c0\u6d4b\u5e76\u533a\u5206\u6a21\u578b\u5185\u90e8\u7684\u6b3a\u9a97\u6216\u8bda\u5b9e\u6fc0\u6d3b\u4ecd\u4e0d\u660e\u786e\uff0c\u4e5f\u4e0d\u6e05\u695a\u8fd9\u4e9b\u63a2\u9488\u80fd\u5426\u62b5\u6297\u5177\u6709\u89c4\u907f\u610f\u56fe\u7684AI\u52a9\u624b\u3002", "method": "\u5c06\u767d\u76d2\u76d1\u63a7\uff08\u53ef\u8bbf\u95ee\u63a2\u9488\u6fc0\u6d3b\uff09\u4e0e\u9ed1\u76d2\u76d1\u63a7\uff08\u4e0d\u53ef\u8bbf\u95ee\u6fc0\u6d3b\uff09\u8fdb\u884c\u6bd4\u8f83\uff0c\u901a\u8fc7\u201c\u9ed1\u76d2\u5230\u767d\u76d2\u6027\u80fd\u63d0\u5347\u201d\u6765\u8bc4\u6d4b\u6b3a\u9a97\u63a2\u9488\u7684\u6709\u6548\u6027\u3002", "result": "\u73b0\u6709\u6b3a\u9a97\u63a2\u9488\u5e26\u6765\u4e86\u5fae\u5f31\u4f46\u4ee4\u4eba\u9f13\u821e\u7684\u9ed1\u76d2\u5230\u767d\u76d2\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u76ee\u524d\u7684\u6b3a\u9a97\u63a2\u9488\u5728\u68c0\u6d4bAI\u52a9\u624b\u6b3a\u9a97\u6027\u884c\u4e3a\u4e0a\u6548\u679c\u6709\u9650\u4f46\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u767d\u76d2\u76d1\u63a7\u8868\u73b0\u7565\u4f18\u4e8e\u9ed1\u76d2\u76d1\u63a7\u3002"}}
{"id": "2507.13055", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2507.13055", "abs": "https://arxiv.org/abs/2507.13055", "authors": ["Artem Alkhamov", "Boris Kriuk"], "title": "To What Extent Can Public Equity Indices Statistically Hedge Real Purchasing Power Loss in Compounded Structural Emerging-Market Crises? An Explainable ML-Based Assessment", "comment": "8 pages, 3 figures, 1 table", "summary": "This study investigates the extent to which local public equity indices can\nstatistically hedge real purchasing power loss during compounded structural\nmacro-financial collapses in emerging markets. We employ a non-linear\nmultiplicative real return calculations consistent with Fisher-parity logics\nfor both domestic and foreign investors with a principled quantile regression,\ntail dependence copula analysis, and Shapley Additive Explanations (SHAP) to\nassess the explanatory power of macro variables. The analysis focuses on three\nrecent and data-accessible exemplary collapse episodes: Turkey (2018), Nigeria\n(2020), and Pakistan (2021). Such cases, selected to align with post-2018\nimprovements in data standardization and crisis comparability, span varied\nmonetary regimes and crisis triggers. Our tail-focused modeling reveals a\nsystematic breakdown in public-equity-based purchasing power protection\nprecisely during simultaneous macroeconomic and monetary dislocations when such\nprotection is most needed. The findings call into question conventional\ninflation and devaluation hedge presumptions in equity pricing theory,\nemphasizing the limitations of equity-based protection and the need for\ncontext-sensitive strategies during compounded macro-financial distress.", "AI": {"tldr": "\u65b0\u5174\u5e02\u573a\u91cd\u5927\u91d1\u878d\u4e0e\u8d27\u5e01\u5371\u673a\u65f6\uff0c\u80a1\u7968\u5e02\u573a\u65e0\u6cd5\u6709\u6548\u4fdd\u503c\uff0c\u4f20\u7edf\u7684\u901a\u80c0\u548c\u8d2c\u503c\u5bf9\u51b2\u89c2\u70b9\u503c\u5f97\u91cd\u65b0\u5ba1\u89c6\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u8bc4\u4f30\u65b0\u5174\u5e02\u573a\u91cd\u5927\u5b8f\u89c2\u91d1\u878d\u5371\u673a\u671f\u95f4\uff0c\u672c\u5730\u80a1\u7968\u6307\u6570\u5728\u5bf9\u6297\u5b9e\u9645\u8d2d\u4e70\u529b\u635f\u5931\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u5f53\u524d\u5e02\u573a\u666e\u904d\u8ba4\u4e3a\u80a1\u7968\u662f\u62b5\u5fa1\u901a\u80c0\u548c\u8d27\u5e01\u8d2c\u503c\u7684\u5de5\u5177\uff0c\u4f46\u5b9e\u9645\u5728\u5371\u673a\u671f\u95f4\u662f\u5426\u6210\u7acb\u5c1a\u4e0d\u660e\u6717\u3002", "method": "\u672c\u6587\u91c7\u7528\u975e\u7ebf\u6027\u4e58\u6cd5\u5b9e\u9645\u6536\u76ca\u8ba1\u7b97\uff08\u4e00\u81f4\u4e8e\u8d39\u96ea\u5747\u8861\u7406\u8bba\uff09\uff0c\u5e76\u7ed3\u5408\u5206\u4f4d\u6570\u56de\u5f52\u3001\u5c3e\u90e8\u76f8\u5173Copula\u5206\u6790\u548cSHAP\uff08Shapley\u52a0\u6cd5\u89e3\u91ca\u6cd5\uff09\u6765\u8bc4\u4f30\u5b8f\u89c2\u53d8\u91cf\u7684\u89e3\u91ca\u529b\u3002\u9009\u53d62018\u5e74\u571f\u8033\u5176\u30012020\u5e74\u5c3c\u65e5\u5229\u4e9a\u548c2021\u5e74\u5df4\u57fa\u65af\u5766\u4e09\u6b21\u6570\u636e\u53ef\u5f97\u7684\u5371\u673a\u4e8b\u4ef6\u4f5c\u4e3a\u6837\u672c\u3002", "result": "\u5c3e\u90e8\u805a\u7126\u7684\u5efa\u6a21\u663e\u793a\uff0c\u5728\u5b8f\u89c2\u7ecf\u6d4e\u4e0e\u8d27\u5e01\u53cc\u91cd\u5371\u673a\u5e76\u53d1\u65f6\uff0c\u672c\u5730\u80a1\u5e02\u7684\u8d2d\u4e70\u529b\u4fdd\u62a4\u529f\u80fd\u7cfb\u7edf\u6027\u5931\u6548\uff0c\u6070\u597d\u5728\u6700\u9700\u8981\u4fdd\u62a4\u7684\u65f6\u5019\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8d28\u7591\u4e86\u4f20\u7edf\u80a1\u7968\u5bf9\u6297\u901a\u80c0\u548c\u8d2c\u503c\u7684\u5047\u8bbe\uff0c\u5f3a\u8c03\u4e86\u80a1\u7968\u4fdd\u62a4\u7684\u5c40\u9650\u6027\uff0c\u5e76\u547c\u5401\u5728\u590d\u5408\u578b\u5b8f\u89c2\u91d1\u878d\u5371\u673a\u671f\u95f4\u91c7\u7528\u66f4\u5177\u60c5\u5883\u611f\u77e5\u7684\u6295\u8d44\u7b56\u7565\u3002"}}
{"id": "2507.12705", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.12705", "abs": "https://arxiv.org/abs/2507.12705", "authors": ["Potsawee Manakul", "Woody Haosheng Gan", "Michael J. Ryan", "Ali Sartaz Khan", "Warit Sirichotedumrong", "Kunat Pipatanakul", "William Held", "Diyi Yang"], "title": "AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation", "comment": null, "summary": "Current speech evaluation suffers from two critical limitations: the need and\ndifficulty of designing specialized systems targeting individual audio\ncharacteristics, and poor correlation between automatic evaluation methods and\nhuman preferences. This work presents a systematic study of Large Audio Model\n(LAM) as a Judge, AudioJudge, investigating whether it can provide a unified\nevaluation framework that addresses both challenges. We systematically explore\nAudioJudge across audio characteristic detection tasks, including\npronunciation, speaking rate, speaker identification and speech quality, and\nsystem-level human preference simulation for automated benchmarking. We\ninvestigate different prompt engineering strategies, finding that audio\nconcatenation combined with in-context learning significantly improves\nperformance across both audio characteristic detection and human preference\nsimulation tasks. We further introduce a multi-aspect ensemble AudioJudge to\nenable general-purpose multi-aspect audio evaluation. This method decomposes\nspeech assessment into specialized judges for lexical content, speech quality,\nand paralinguistic features, achieving up to 0.91 Spearman correlation with\nhuman preferences on our system ranking benchmark. Robustness analysis reveals\nthat while LAMs maintain strong performance under acoustic noise, they exhibit\nsignificant verbosity and positional biases that require careful mitigation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5927\u578b\u97f3\u9891\u6a21\u578bAudioJudge\u7edf\u4e00\u8fdb\u884c\u8bed\u97f3\u591a\u7279\u5f81\u548c\u4eba\u7c7b\u504f\u597d\u81ea\u52a8\u5316\u8bc4\u4f30\uff0c\u53d6\u5f97\u4e0e\u4eba\u5de5\u9ad8\u5ea6\u4e00\u81f4\u7684\u7ed3\u679c\uff08Spearman\u76f8\u5173\u8fbe\u52300.91\uff09\uff0c\u4f46\u5b58\u5728\u8f93\u51fa\u5197\u4f59\u548c\u504f\u7f6e\u7b49\u95ee\u9898\u9700\u6539\u8fdb\u3002", "motivation": "\u5f53\u524d\u7684\u8bed\u97f3\u8bc4\u4f30\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u4e00\u662f\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u97f3\u9891\u7279\u5f81\u8bbe\u8ba1\u4e13\u95e8\u7684\u7cfb\u7edf\uff0c\u8fc7\u7a0b\u590d\u6742\uff1b\u4e8c\u662f\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6cd5\u4e0e\u4eba\u7c7b\u4e3b\u89c2\u504f\u597d\u7684\u4e00\u81f4\u6027\u8f83\u5dee\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u5229\u7528\u5927\u578b\u97f3\u9891\u6a21\u578b\uff08LAM\uff09AudioJudge\u4f5c\u4e3a\u7edf\u4e00\u8bc4\u5224\u5de5\u5177\uff0c\u7cfb\u7edf\u6027\u5730\u5728\u53d1\u97f3\u3001\u8bed\u901f\u3001\u8bf4\u8bdd\u4eba\u8bc6\u522b\u3001\u8bed\u97f3\u8d28\u91cf\u7b49\u97f3\u9891\u7279\u5f81\u68c0\u6d4b\u4ee5\u53ca\u81ea\u52a8\u5316\u6a21\u62df\u4eba\u7c7b\u504f\u597d\u7684\u4efb\u52a1\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002\u901a\u8fc7\u4e0d\u540c\u7684\u63d0\u793a\u8bcd\u5de5\u7a0b\uff08prompt engineering\uff09\u7b56\u7565\uff0c\u53d1\u73b0\u97f3\u9891\u4e32\u8054\u4e0e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7ed3\u5408\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u97f3\u9891\u7279\u5f81\u68c0\u6d4b\u548c\u4eba\u7c7b\u504f\u597d\u6a21\u62df\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u591a\u65b9\u9762\u96c6\u6210AudioJudge\uff0c\u5c06\u8bed\u97f3\u8bc4\u4f30\u5206\u4e3a\u8bcd\u6c47\u5185\u5bb9\u3001\u8bed\u97f3\u8d28\u91cf\u548c\u526f\u8bed\u8a00\u7279\u5f81\u4e09\u4e2a\u8bc4\u5224\u5b50\u7cfb\u7edf\u3002", "result": "\u591a\u65b9\u9762\u96c6\u6210AudioJudge\u5728\u7cfb\u7edf\u6392\u540d\u57fa\u51c6\u4e0a\uff0c\u4e0e\u4eba\u7c7b\u504f\u597d\u7684Spearman\u76f8\u5173\u7cfb\u6570\u6700\u9ad8\u8fbe\u52300.91\u3002\u9c81\u68d2\u6027\u5206\u6790\u663e\u793a\uff0cLAM\u5728\u6709\u566a\u58f0\u7684\u6761\u4ef6\u4e0b\u4f9d\u7136\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5b58\u5728\u8f93\u51fa\u5197\u957f\u53ca\u4f4d\u7f6e\u504f\u7f6e\u95ee\u9898\uff0c\u6709\u5f85\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "conclusion": "AudioJudge\u80fd\u591f\u4f5c\u4e3a\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\uff0c\u89e3\u51b3\u8bed\u97f3\u8bc4\u4f30\u573a\u666f\u4e2d\u7684\u591a\u7279\u5f81\u68c0\u6d4b\u4e0e\u4e3b\u89c2\u504f\u597d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5e76\u5728\u591a\u65b9\u9762\u5b9e\u73b0\u9ad8\u4e0e\u4eba\u7c7b\u4e00\u81f4\u7684\u81ea\u52a8\u8bc4\u4f30\uff0c\u4f46\u4ecd\u9700\u9488\u5bf9\u5176\u5197\u4f59\u6027\u548c\u4f4d\u7f6e\u504f\u7f6e\u52a0\u4ee5\u6539\u8fdb\u3002"}}
{"id": "2507.12801", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.12801", "abs": "https://arxiv.org/abs/2507.12801", "authors": ["Sosui Moribe", "Taketoshi Ushiama"], "title": "Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning", "comment": "This is the preprint version of the paper published in IMCOM 2025,\n  IEEE Xplore (DOI: 10.1109/IMCOM64595.2025.10857528)", "summary": "In recent years, peer learning has gained attention as a method that promotes\nspontaneous thinking among learners, and its effectiveness has been confirmed\nby numerous studies. This study aims to develop an AI Agent as a learning\ncompanion that enables peer learning anytime and anywhere. However, peer\nlearning between humans has various limitations, and it is not always\neffective. Effective peer learning requires companions at the same proficiency\nlevels. In this study, we assume that a learner's peers with the same\nproficiency level as the learner make the same mistakes as the learner does and\nfocus on English composition as a specific example to validate this approach.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cdAI\u5b66\u4e60\u4f19\u4f34\uff0c\u901a\u8fc7\u6a21\u62df\u540c\u884c\u6c34\u5e73\u548c\u5171\u6027\u9519\u8bef\uff0c\u63a2\u7d22\u63d0\u5347\u82f1\u8bed\u5199\u4f5c\u540c\u884c\u5b66\u4e60\u6548\u679c\u7684\u65b9\u6cd5\uff0c\u4ee5\u671f\u89e3\u51b3\u73b0\u5b9e\u540c\u884c\u5b66\u4e60\u4e2d\u7684\u53d7\u4f17\u5339\u914d\u5c40\u9650\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u540c\u884c\u5b66\u4e60\u56e0\u80fd\u4fc3\u8fdb\u5b66\u4e60\u8005\u81ea\u53d1\u601d\u8003\u800c\u5907\u53d7\u5173\u6ce8\uff0c\u4f46\u73b0\u5b9e\u4e2d\u4eba\u4e0e\u4eba\u4e4b\u95f4\u7684\u540c\u884c\u5b66\u4e60\u5b58\u5728\u6c34\u5e73\u5339\u914d\u96be\u7b49\u5c40\u9650\u3002\u8be5\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u53ef\u968f\u65f6\u968f\u5730\u8fdb\u884c\u540c\u884c\u5b66\u4e60\u7684AI\u5b66\u4e60\u4f19\u4f34\u3002", "method": "\u5047\u8bbe\u548c\u5b66\u4e60\u8005\u5904\u4e8e\u76f8\u540c\u6c34\u5e73\u7684\u540c\u4f34\u4f1a\u72af\u540c\u6837\u7684\u9519\u8bef\uff0c\u5e76\u4ee5\u82f1\u8bed\u5199\u4f5c\u4e3a\u4f8b\uff0c\u9a8c\u8bc1\u8be5AI Agent\u7684\u8bbe\u8ba1\u601d\u8def\u3002", "result": "\u7814\u7a76\u805a\u7126\u4e8eAI\u5b66\u4e60\u4f19\u4f34\u5728\u540c\u884c\u5b66\u4e60\u60c5\u5883\u4e2d\u7684\u6548\u679c\uff0c\u7279\u522b\u662f\u6c34\u5e73\u5339\u914d\u53ca\u9519\u8bef\u5171\u6027\u5bf9\u5b66\u4e60\u6548\u679c\u7684\u5f71\u54cd\u3002", "conclusion": "AI Agent\u6709\u6f5c\u529b\u514b\u670d\u4eba\u7c7b\u540c\u884c\u5b66\u4e60\u4e2d\u7684\u9650\u5236\uff0c\u4e3a\u5b66\u4e60\u8005\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u652f\u6301\uff0c\u5c24\u5176\u662f\u5728\u540c\u884c\u6c34\u5e73\u5339\u914d\u65b9\u9762\u3002"}}
{"id": "2507.12720", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.12720", "abs": "https://arxiv.org/abs/2507.12720", "authors": ["Abraham Toluase Owodunni", "Orevaoghene Ahia", "Sachin Kumar"], "title": "FLEXITOKENS: Flexible Tokenization for Evolving Language Models", "comment": null, "summary": "Language models (LMs) are challenging to adapt to new data distributions by\nsimple finetuning. This is due to the rigidity of their subword tokenizers,\nwhich typically remain unchanged during adaptation. This inflexibility often\nleads to inefficient tokenization, causing overfragmentation of\nout-of-distribution domains, unseen languages, or scripts. In this work, we\ndevelop byte-level LMs with learnable tokenizers to make tokenization adaptive.\nOur models include a submodule that learns to predict boundaries between the\ninput byte sequence, encoding it into variable-length segments. Existing\ntokenizer-free methods train this boundary predictor using an auxiliary loss\nthat enforces a fixed compression rate across the training corpus, introducing\na new kind of rigidity. We propose FLEXITOKENS, a simplified training objective\nthat enables significantly greater flexibility during adaptation. Evaluating\nacross multiple multilingual benchmarks, morphologically diverse tasks, and\ndomains, we demonstrate that FLEXITOKENS consistently reduces token\nover-fragmentation and achieves up to 10\\% improvements on downstream task\nperformance compared to subword and other gradient-based tokenizers. Code and\ndata for our experiments will be released at\nhttps://github.com/owos/flexitokens", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FLEXITOKENS\uff0c\u4e00\u79cd\u53ef\u5b66\u4e60\u3001\u7075\u6d3b\u7684\u5206\u8bcd\u673a\u5236\uff0c\u6709\u6548\u51cf\u5c11\u5206\u8bcd\u788e\u7247\u5316\uff0c\u5e76\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u4e0b\u6e38\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684\u8bed\u8a00\u6a21\u578b\uff08LMs\uff09\u5728\u901a\u8fc7\u7b80\u5355\u5fae\u8c03\u9002\u5e94\u65b0\u6570\u636e\u5206\u5e03\u65f6\u9762\u4e34\u6311\u6218\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u5176\u5b50\u8bcd\u5206\u8bcd\u5668\u7684\u50f5\u5316\uff0c\u96be\u4ee5\u8c03\u6574\u4ee5\u9002\u5e94\u65b0\u7684\u8bed\u8a00\u3001\u811a\u672c\u6216\u9886\u57df\uff0c\u4f1a\u5bfc\u81f4\u5206\u8bcd\u788e\u7247\u5316\u3001\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b57\u8282\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u53ef\u5b66\u4e60\u5206\u8bcd\u5668\u6a21\u5757\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u81ea\u9002\u5e94\u5730\u8fdb\u884c\u5206\u8bcd\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9884\u6d4b\u5b57\u8282\u5e8f\u5217\u4e2d\u7684\u8fb9\u754c\uff0c\u5c06\u8f93\u5165\u7f16\u7801\u4e3a\u53d8\u957f\u7247\u6bb5\u3002\u4e0d\u540c\u4e8e\u73b0\u6709\u901a\u8fc7\u5f3a\u5236\u56fa\u5b9a\u538b\u7f29\u7387\u8bad\u7ec3\u5206\u8bcd\u8fb9\u754c\u7684\u65b9\u6cd5\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86FLEXITOKENS\uff0c\u4e00\u79cd\u7b80\u5316\u7684\u8bad\u7ec3\u76ee\u6807\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u5bf9\u65b0\u9886\u57df\u7684\u9002\u5e94\u6027\u3002", "result": "\u5728\u591a\u4e2a\u591a\u8bed\u8a00\u57fa\u51c6\u3001\u5f62\u6001\u591a\u6837\u4efb\u52a1\u548c\u4e0d\u540c\u9886\u57df\u4e2d\u8bc4\u4f30\uff0cFLEXITOKENS\u6709\u52a9\u4e8e\u51cf\u5c11\u5206\u8bcd\u788e\u7247\u5316\u73b0\u8c61\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u4e0a\u6bd4\u5b50\u8bcd\u53ca\u5176\u5b83\u57fa\u4e8e\u68af\u5ea6\u7684\u5206\u8bcd\u65b9\u6cd5\u63d0\u5347\u4e86\u6700\u9ad810%\u7684\u6027\u80fd\u3002", "conclusion": "\u53ef\u5b66\u4e60\u3001\u81ea\u9002\u5e94\u5206\u8bcd\u673a\u5236\u80fd\u663e\u8457\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u65f6\u57df\u3001\u8bed\u8a00\u548c\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u9645\u8868\u73b0\uff0c\u6709\u6548\u514b\u670d\u4f20\u7edf\u5206\u8bcd\u5668\u7684\u50f5\u5316\u95ee\u9898\u3002"}}
{"id": "2507.12806", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.12806", "abs": "https://arxiv.org/abs/2507.12806", "authors": ["Zhiwei Liu", "Jielin Qiu", "Shiyu Wang", "Jianguo Zhang", "Zuxin Liu", "Roshan Ram", "Haolin Chen", "Weiran Yao", "Huan Wang", "Shelby Heinecke", "Silvio Savarese", "Caiming Xiong"], "title": "MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models", "comment": "https://github.com/SalesforceAIResearch/MCPEval", "summary": "The rapid rise of Large Language Models (LLMs)-based intelligent agents\nunderscores the need for robust, scalable evaluation frameworks. Existing\nmethods rely on static benchmarks and labor-intensive data collection, limiting\npractical assessment. We introduce \\oursystemname, an open-source Model Context\nProtocol (MCP)-based framework that automates end-to-end task generation and\ndeep evaluation of LLM agents across diverse domains. MCPEval standardizes\nmetrics, seamlessly integrates with native agent tools, and eliminates manual\neffort in building evaluation pipelines. Empirical results across five\nreal-world domains show its effectiveness in revealing nuanced, domain-specific\nperformance. We publicly release MCPEval\nhttps://github.com/SalesforceAIResearch/MCPEval to promote reproducible and\nstandardized LLM agent evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMCPEval\u5f00\u6e90\u8bc4\u6d4b\u6846\u67b6\uff0c\u5b9e\u73b0LLM\u667a\u80fd\u4f53\u8bc4\u6d4b\u7684\u81ea\u52a8\u5316\u548c\u6807\u51c6\u5316\uff0c\u53ef\u6d88\u9664\u4eba\u5de5\u6570\u636e\u6784\u5efa\u73af\u8282\uff0c\u5728\u591a\u4e2a\u9886\u57df\u5b9e\u9a8c\u8868\u73b0\u4f18\u79c0\uff0c\u5df2\u5bf9\u5916\u5f00\u653e\u3002", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u7684\u8bc4\u6d4b\u65b9\u6cd5\u53d7\u9650\u4e8e\u9759\u6001\u57fa\u51c6\u548c\u9ad8\u4eba\u5de5\u6210\u672c\uff0c\u7f3a\u4e4f\u53ef\u6269\u5c55\u3001\u81ea\u52a8\u5316\u7684\u8bc4\u6d4b\u4f53\u7cfb\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u57fa\u4e8eModel Context Protocol\uff08MCP\uff09\u7684\u5f00\u653e\u6e90\u4ee3\u7801\u8bc4\u6d4b\u6846\u67b6MCPEval\uff0c\u652f\u6301\u7aef\u5230\u7aef\u81ea\u52a8\u4efb\u52a1\u751f\u6210\u548c\u591a\u7ef4\u5ea6\u8bc4\u6d4b\uff0c\u5e76\u80fd\u65e0\u7f1d\u96c6\u6210\u73b0\u6709\u667a\u80fd\u4f53\u5de5\u5177\u3002", "result": "MCPEval\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u9886\u57df\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u51fa\u533a\u5206\u7ec6\u7c92\u5ea6\u3001\u9886\u57df\u76f8\u5173\u6027\u80fd\u7684\u6709\u6548\u6027\u3002\u6846\u67b6\u5df2\u5f00\u6e90\uff0c\u63a8\u52a8\u8bc4\u6d4b\u7684\u6807\u51c6\u5316\u548c\u53ef\u590d\u73b0\u3002", "conclusion": "MCPEval\u6846\u67b6\u80fd\u591f\u6709\u6548\u81ea\u52a8\u5316\u5e76\u6807\u51c6\u5316LLM\u667a\u80fd\u4f53\u5728\u4e0d\u540c\u9886\u57df\u7684\u6df1\u5ea6\u8bc4\u6d4b\uff0c\u4e3a\u5927\u89c4\u6a21\u3001\u53ef\u590d\u73b0\u3001\u6807\u51c6\u5316\u7684\u667a\u80fd\u4f53\u8bc4\u6d4b\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2507.12724", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.12724", "abs": "https://arxiv.org/abs/2507.12724", "authors": ["Richard Sproat", "Tianyu Zhao", "Llion Jones"], "title": "TransEvalnia: Reasoning-based Evaluation and Ranking of Translations", "comment": null, "summary": "We present TransEvalnia, a prompting-based translation evaluation and ranking\nsystem that uses reasoning in performing its evaluations and ranking. This\nsystem presents fine-grained evaluations based on a subset of the\nMultidimensional Quality Metrics (https://themqm.org/), returns an assessment\nof which translation it deems the best, and provides numerical scores for the\nvarious dimensions and for the overall translation. We show that TransEvalnia\nperforms as well as or better than the state-of-the-art MT-Ranker (Moosa et al.\n2024) on our own English-Japanese data as well as several language pairs from\nvarious WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and\nQwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations\nreturned are deemed highly acceptable to human raters, and that the scores\nassigned to the translations by Sonnet, as well as other LLMs, correlate well\nwith scores assigned by the human raters. We also note the sensitivity of our\nsystem -- as well as MT-Ranker -- to the order in which the translations are\npresented, and we propose methods to address this position bias. All data,\nincluding the system's evaluation and reasoning, human assessments, as well as\ncode is released.", "AI": {"tldr": "TransEvalnia\u662f\u4e00\u4e2a\u57fa\u4e8eprompt\u548cLLM\u63a8\u7406\u7684\u673a\u5668\u7ffb\u8bd1\u8bc4\u4ef7\u7cfb\u7edf\uff0c\u5728\u7ec6\u7c92\u5ea6\u6253\u5206\u3001\u4e0e\u4eba\u5de5\u4e00\u81f4\u6027\u548c\u90e8\u5206\u8bed\u8a00\u5bf9\u5b9e\u9a8c\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u516c\u5f00\u6240\u6709\u8d44\u6e90\uff0c\u63a8\u52a8\u4e86\u81ea\u52a8\u7ffb\u8bd1\u8bc4\u4ef7\u7684\u8fdb\u6b65\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u7cfb\u7edf\u5728\u591a\u7ef4\u5ea6\u3001\u7ec6\u7c92\u5ea6\u8bc4\u5206\u548c\u4e0e\u4eba\u7c7b\u8bc4\u4ef7\u4e00\u81f4\u6027\u7b49\u65b9\u9762\u4ecd\u6709\u4e00\u5b9a\u5c40\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u7cbe\u7ec6\u3001\u53ef\u89e3\u91ca\uff0c\u4e14\u4e0e\u4eba\u5de5\u8bc4\u4ef7\u76f8\u5173\u6027\u9ad8\u7684\u81ea\u52a8\u5316\u8bc4\u4ef7\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u57fa\u4e8eprompt\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982Claude-3.5-Sonnet\u548cQwen-2.5-72B-Instruct\uff09\u8fdb\u884c\u63a8\u7406\u5f0f\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u5206\uff0c\u4f9d\u636eMQM\u7684\u591a\u4e2a\u7ef4\u5ea6\u8f93\u51fa\u7ec6\u7c92\u5ea6\u5206\u6570\u4e0e\u6700\u7ec8\u8bc4\u4ef7\u3002\u8fd8\u63d0\u51fa\u5904\u7406\u8bc4\u5206\u987a\u5e8f\u504f\u7f6e\u7684\u65b9\u6cd5\u3002", "result": "TransEvalnia\u5728\u82f1\u65e5\u7b49\u591a\u4e2a\u8bed\u5bf9\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8bc4\u4ef7\u8868\u73b0\u4e0e\u6216\u4f18\u4e8e\u6700\u5148\u8fdb\u7cfb\u7edfMT-Ranker\uff0c\u4e14\u81ea\u52a8\u8bc4\u4ef7\u5206\u6570\u4e0e\u4eba\u5de5\u8bc4\u5206\u9ad8\u5ea6\u76f8\u5173\uff1b\u53d1\u73b0\u8bc4\u5206\u987a\u5e8f\u5bf9\u8bc4\u4ef7\u6709\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u5bf9\u5e94\u89e3\u51b3\u65b9\u6848\u3002\u7cfb\u7edf\u76f8\u5173\u8d44\u6e90\u5747\u5df2\u5f00\u6e90\u3002", "conclusion": "TransEvalnia\u7cfb\u7edf\u80fd\u591f\u5728\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4ef7\u548c\u6392\u5e8f\u65b9\u9762\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u76f8\u5ab2\u7f8e\uff0c\u751a\u81f3\u66f4\u4f73\uff0c\u5e76\u4e14\u5176\u7ed3\u679c\u4e0e\u4eba\u5de5\u8bc4\u4ef7\u9ad8\u5ea6\u4e00\u81f4\u3002\u7cfb\u7edf\u548c\u5b9e\u9a8c\u6570\u636e\u3001\u4ee3\u7801\u5747\u5df2\u516c\u5f00\u3002"}}
{"id": "2507.12820", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.12820", "abs": "https://arxiv.org/abs/2507.12820", "authors": ["Shiquan Wang", "Ruiyu Fang", "Zhongjiang He", "Shuangyong Song", "Yongxiang Li"], "title": "Emotional Support with LLM-based Empathetic Dialogue Generation", "comment": null, "summary": "Emotional Support Conversation (ESC) aims to provide empathetic and effective\nemotional assistance through dialogue, addressing the growing demand for mental\nhealth support. This paper presents our solution for the NLPCC 2025 Task 8 ESC\nevaluation, where we leverage large-scale language models enhanced by prompt\nengineering and finetuning techniques. We explore both parameter-efficient\nLow-Rank Adaptation and full-parameter fine-tuning strategies to improve the\nmodel's ability to generate supportive and contextually appropriate responses.\nOur best model ranked second in the competition, highlighting the potential of\ncombining LLMs with effective adaptation methods for ESC tasks. Future work\nwill focus on further enhancing emotional understanding and response\npersonalization to build more practical and reliable emotional support systems.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u4efb\u52a1\uff0c\u63d0\u51fa\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u4e0e\u4f4e\u79e9\u9002\u914d\u6216\u5168\u53c2\u6570\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6848\uff0c\u5728NLPCC 2025\u6bd4\u8d5b\u4e2d\u53d6\u5f97\u7b2c\u4e8c\u540d\uff0c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u60c5\u611f\u652f\u6301\u4efb\u52a1\u4e2d\u7684\u5f3a\u5927\u6f5c\u529b\u3002", "motivation": "\u9762\u5bf9\u4e0d\u65ad\u589e\u957f\u7684\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u9700\u6c42\uff0c\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\uff08ESC\uff09\u65e8\u5728\u901a\u8fc7\u5bf9\u8bdd\u63d0\u4f9b\u540c\u7406\u5fc3\u548c\u6709\u6548\u7684\u60c5\u611f\u534f\u52a9\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u548c\u5fae\u8c03\u6280\u672f\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u65b9\u6848\uff0c\u63a2\u7d22\u4e86\u53c2\u6570\u9ad8\u6548\u7684\u4f4e\u79e9\u9002\u914d\uff08LoRA\uff09\u4e0e\u5168\u53c2\u6570\u5fae\u8c03\u4e24\u79cd\u7b56\u7565\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u5728\u60c5\u611f\u652f\u6301\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6700\u4f73\u6a21\u578b\u5728NLPCC 2025 Task 8\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u8bc4\u6d4b\u4e2d\u83b7\u5f97\u7b2c\u4e8c\u540d\uff0c\u8bc1\u660e\u4e86\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u9ad8\u6548\u9002\u914d\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u9002\u914d\u7b56\u7565\u5728\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u6307\u51fa\u672a\u6765\u5c06\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u7684\u60c5\u611f\u7406\u89e3\u548c\u4e2a\u6027\u5316\u56de\u5e94\u80fd\u529b\uff0c\u4ee5\u6784\u5efa\u66f4\u5b9e\u7528\u53ef\u9760\u7684\u60c5\u611f\u652f\u6301\u7cfb\u7edf\u3002"}}
{"id": "2507.12732", "categories": ["cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.12732", "abs": "https://arxiv.org/abs/2507.12732", "authors": ["Fuya Nakamori", "Yin Jou Huang", "Fei Cheng"], "title": "Strategy Adaptation in Large Language Model Werewolf Agents", "comment": "7 pages, 2 figures", "summary": "This study proposes a method to improve the performance of Werewolf agents by\nswitching between predefined strategies based on the attitudes of other players\nand the context of conversations. While prior works of Werewolf agents using\nprompt engineering have employed methods where effective strategies are\nimplicitly defined, they cannot adapt to changing situations. In this research,\nwe propose a method that explicitly selects an appropriate strategy based on\nthe game context and the estimated roles of other players. We compare the\nstrategy adaptation Werewolf agents with baseline agents using implicit or\nfixed strategies and verify the effectiveness of our proposed method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u548c\u73a9\u5bb6\u6001\u5ea6\u52a8\u6001\u5207\u6362\u9884\u5b9a\u4e49\u7b56\u7565\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4eba\u72fc\u6e38\u620fAI\u5bf9\u590d\u6742\u573a\u666f\u7684\u5e94\u5bf9\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u4ee5\u5f80\u4eba\u72fc\u6e38\u620fAI\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u5b9e\u73b0\u7b56\u7565\uff0c\u5b58\u5728\u7b56\u7565\u9690\u6027\u5b9a\u4e49\u3001\u96be\u4ee5\u5e94\u5bf9\u53d8\u5316\u7684\u95ee\u9898\u3002\u4f5c\u8005\u5e0c\u671b\u63d0\u5347\u4eba\u72fcAI\u9488\u5bf9\u4e0d\u540c\u5bf9\u5c40\u60c5\u5883\u7684\u81ea\u9002\u5e94\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e0a\u4e0b\u6587\u548c\u4ed6\u4eba\u6001\u5ea6\u52a8\u6001\u5207\u6362\u9884\u5b9a\u4e49\u7b56\u7565\u7684\u65b9\u6cd5\uff0c\u663e\u5f0f\u6839\u636e\u6e38\u620f\u4e0a\u4e0b\u6587\u53ca\u5176\u4ed6\u73a9\u5bb6\u89d2\u8272\u4f30\u8ba1\u9009\u62e9\u6700\u4f18\u7b56\u7565\u3002", "result": "\u4e0e\u91c7\u7528\u9690\u5f0f\u6216\u56fa\u5b9a\u7b56\u7565\u7684\u57fa\u7ebfAI\u5bf9\u6bd4\uff0c\u9a8c\u8bc1\u4e86\u7b56\u7565\u81ea\u9002\u5e94AI\u6548\u679c\u66f4\u4f18\u3002", "conclusion": "\u663e\u5f0f\u7b56\u7565\u5207\u6362\u80fd\u63d0\u5347\u4eba\u72fc\u6e38\u620fAI\u5bf9\u53d8\u5316\u573a\u666f\u7684\u9002\u5e94\u529b\u548c\u6574\u4f53\u8868\u73b0\u3002"}}
{"id": "2507.12821", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.12821", "abs": "https://arxiv.org/abs/2507.12821", "authors": ["Lance Ying", "Katherine M. Collins", "Prafull Sharma", "Cedric Colas", "Kaiya Ivy Zhao", "Adrian Weller", "Zenna Tavares", "Phillip Isola", "Samuel J. Gershman", "Jacob D. Andreas", "Thomas L. Griffiths", "Francois Chollet", "Kelsey R. Allen", "Joshua B. Tenenbaum"], "title": "Assessing adaptive world models in machines with novel games", "comment": "17 pages, 4 figures", "summary": "Human intelligence exhibits a remarkable capacity for rapid adaptation and\neffective problem-solving in novel and unfamiliar contexts. We argue that this\nprofound adaptability is fundamentally linked to the efficient construction and\nrefinement of internal representations of the environment, commonly referred to\nas world models, and we refer to this adaptation mechanism as world model\ninduction. However, current understanding and evaluation of world models in\nartificial intelligence (AI) remains narrow, often focusing on static\nrepresentations learned from training on a massive corpora of data, instead of\nthe efficiency and efficacy of models in learning these representations through\ninteraction and exploration within a novel environment. In this Perspective, we\nprovide a view of world model induction drawing on decades of research in\ncognitive science on how humans learn and adapt so efficiently; we then call\nfor a new evaluation framework for assessing adaptive world models in AI.\nConcretely, we propose a new benchmarking paradigm based on suites of carefully\ndesigned games with genuine, deep and continually refreshing novelty in the\nunderlying game structures -- we refer to this kind of games as novel games. We\ndetail key desiderata for constructing these games and propose appropriate\nmetrics to explicitly challenge and evaluate the agent's ability for rapid\nworld model induction. We hope that this new evaluation framework will inspire\nfuture evaluation efforts on world models in AI and provide a crucial step\ntowards developing AI systems capable of the human-like rapid adaptation and\nrobust generalization -- a critical component of artificial general\nintelligence.", "AI": {"tldr": "\u4eba\u7c7b\u667a\u80fd\u4f9d\u9760\u9ad8\u6548\u7684\u73af\u5883\u4e16\u754c\u6a21\u578b\u5b66\u4e60\u5b9e\u73b0\u5feb\u901f\u9002\u5e94\u3002\u672c\u6587\u501f\u9274\u8ba4\u77e5\u79d1\u5b66\u7ecf\u9a8c\uff0c\u63d0\u51fa\u7528\u6301\u7eed\u521b\u65b0\u7684\u65b0\u9896\u6e38\u620f\u8861\u91cfAI\u7cfb\u7edf\u4e16\u754c\u6a21\u578b\u5f52\u7eb3\u80fd\u529b\uff0c\u4e3a\u901a\u7528AI\u7684\u8bc4\u4f30\u548c\u53d1\u5c55\u63d0\u4f9b\u65b0\u6846\u67b6\u548c\u6807\u51c6\u3002", "motivation": "\u4eba\u7c7b\u667a\u80fd\u80fd\u591f\u5728\u65b0\u9896\u548c\u4e0d\u719f\u6089\u7684\u60c5\u5883\u4e2d\u5feb\u901f\u9002\u5e94\u548c\u9ad8\u6548\u89e3\u51b3\u95ee\u9898\uff0c\u800c\u8fd9\u79cd\u80fd\u529b\u4e0e\u5bf9\u73af\u5883\u5185\u90e8\u8868\u5f81\uff08\u5373\u201c\u4e16\u754c\u6a21\u578b\u201d\uff09\u7684\u9ad8\u6548\u6784\u5efa\u548c\u4f18\u5316\u5bc6\u5207\u76f8\u5173\u3002\u7136\u800c\uff0c\u76ee\u524d\u4eba\u5de5\u667a\u80fd\u9886\u57df\u5bf9\u4e16\u754c\u6a21\u578b\u7684\u7406\u89e3\u548c\u8bc4\u4f30\u8fc7\u4e8e\u72ed\u7a84\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728\u57fa\u4e8e\u5927\u91cf\u6570\u636e\u8bed\u6599\u5b66\u4e60\u7684\u9759\u6001\u8868\u793a\uff0c\u800c\u5ffd\u7565\u4e86\u6a21\u578b\u901a\u8fc7\u4e0e\u65b0\u73af\u5883\u4ea4\u4e92\u548c\u63a2\u7d22\u9ad8\u6548\u5b66\u4e60\u8fd9\u4e9b\u8868\u793a\u7684\u80fd\u529b\u3002", "method": "\u672c\u6587\u501f\u9274\u8ba4\u77e5\u79d1\u5b66\u9886\u57df\u5173\u4e8e\u4eba\u7c7b\u9ad8\u6548\u5b66\u4e60\u548c\u9002\u5e94\u7684\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0d\u65ad\u521b\u65b0\u3001\u7ed3\u6784\u591a\u53d8\u7684\u2018\u65b0\u9896\u6e38\u620f\u2019\u5957\u4ef6\u4f5c\u4e3a\u57fa\u51c6\u7684\u65b0\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u6b64\u6765\u6311\u6218\u548c\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u5feb\u901f\u4e16\u754c\u6a21\u578b\u5f52\u7eb3\u80fd\u529b\u3002\u6587\u7ae0\u5177\u4f53\u9610\u660e\u4e86\u8bbe\u8ba1\u8fd9\u4e9b\u6e38\u620f\u7684\u5173\u952e\u8981\u6c42\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u8861\u91cf\u6307\u6807\u3002", "result": "\u63d0\u51fa\u5e76\u7ec6\u5316\u4e86\u4e00\u5957\u7528\u4ee5\u8bc4\u4ef7\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u4e16\u754c\u6a21\u578b\u5f52\u7eb3\u548c\u5feb\u901f\u9002\u5e94\u80fd\u529b\u7684\u5168\u65b0\u8bc4\u4f30\u6846\u67b6\uff0c\u540c\u65f6\u660e\u786e\u4e86\u6784\u5efa\u65b0\u9896\u6e38\u620f\u53ca\u5176\u5ea6\u91cf\u6807\u51c6\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u8bba\u6587\u547c\u5401AI\u9886\u57df\u5e94\u91cd\u89c6\u5e76\u91c7\u7528\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u6301\u7eed\u65b0\u9896\u7684\u6e38\u620f\u6765\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u548c\u63a8\u52a8AI\u7cfb\u7edf\u4e16\u754c\u6a21\u578b\u5f52\u7eb3\u3001\u5feb\u901f\u9002\u5e94\u4e0e\u6cdb\u5316\u80fd\u529b\u7684\u63d0\u5347\uff0c\u4ece\u800c\u8fc8\u5411\u7c7b\u4eba\u901a\u7528\u667a\u80fd\u3002"}}
{"id": "2507.12759", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.12759", "abs": "https://arxiv.org/abs/2507.12759", "authors": ["Yunxiang Zhang", "Muhammad Khalifa", "Lechen Zhang", "Xin Liu", "Ayoung Lee", "Xinliang Frederick Zhang", "Farima Fatahi Bayat", "Lu Wang"], "title": "Logit Arithmetic Elicits Long Reasoning Capabilities Without Training", "comment": null, "summary": "Large reasoning models (LRMs) can do complex reasoning via long\nchain-of-thought (CoT) involving cognitive strategies such as backtracking and\nself-correction. Recent studies suggest that some models inherently possess\nthese long reasoning abilities, which may be unlocked via extra training. Our\nwork first investigates whether we can elicit such behavior without any\ntraining. To this end, we propose a decoding-time approach, ThinkLogit, which\nutilizes logits arithmetic (Liu et al., 2024) to tune a target large LM for\nlong reasoning using a substantially smaller model as guider. We then show that\nwe can further boost performance by training the guider model with preference\noptimization over correct/incorrect reasoning pairs sampled from both the\ntarget and guider model -- a setup we refer to as ThinkLogit-DPO. Our\nexperiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative\nimprovement in pass@1 by 26% and 29%, respectively, over four mathematical\ndatasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model\n21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skills\nacquired through reinforcement learning, improving pass@1 by 13% relative\ncompared to the Qwen2.5-32B base model. Our work presents a\ncomputationally-efficient method to elicit long reasoning in large models with\nminimal or no additional training.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51faThinkLogit\u53ca\u5176\u4f18\u5316\u7248\uff0c\u5229\u7528\u5c0f\u6a21\u578b\u63a8\u7406\u6307\u5bfc\uff0c\u65e0\u9700\u6216\u6781\u5c11\u989d\u5916\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u957f\u94fe\u63a8\u7406\u6027\u80fd\uff0c\u8282\u7701\u7b97\u529b\u4e14\u6548\u679c\u51fa\u8272\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRM\uff09\u5728\u957f\u94fe\u601d\u7ef4\uff08CoT\uff09\u4e0b\u80fd\u8fdb\u884c\u590d\u6742\u63a8\u7406\uff0c\u4f46\u5982\u4f55\u9ad8\u6548\u6fc0\u53d1\u5176\u5185\u5728\u7684\u957f\u63a8\u7406\u80fd\u529b\u5c1a\u4e0d\u6e05\u695a\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u6570\u4f9d\u8d56\u989d\u5916\u8bad\u7ec3\uff0c\u6d88\u8017\u5927\u91cf\u7b97\u529b\u3002\u4f5c\u8005\u5e0c\u671b\u63a2\u7d22\u80fd\u5426\u4ee5\u66f4\u4f4e\u6210\u672c\uff08\u751a\u6216\u65e0\u9700\u8bad\u7ec3\uff09\u6fc0\u53d1\u5927\u6a21\u578b\u7684\u957f\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faThinkLogit\uff0c\u4e00\u79cd\u63a8\u7406\u65f6\uff08decoding-time\uff09\u65b9\u6cd5\uff0c\u5229\u7528logits\u7b97\u672f\u5fae\u8c03\u7528\u76ee\u6807\u5927\u6a21\u578b\uff0c\u7531\u4e00\u4e2a\u5c0f\u5f97\u591a\u7684\u201c\u5f15\u5bfc\u8005\u201d\u6a21\u578b\u6307\u5f15\uff1b\u8fdb\u4e00\u6b65\u63d0\u51faThinkLogit-DPO\uff0c\u901a\u8fc7\u5bf9\u6b63\u786e/\u9519\u8bef\u63a8\u7406\u6837\u672c\u8fdb\u884c\u504f\u597d\u4f18\u5316\u8bad\u7ec3\u5f15\u5bfc\u8005\u6a21\u578b\uff1b\u5b9e\u9a8c\u5728\u6570\u5b66\u6570\u636e\u96c6\u4e0a\u7528Qwen2.5-32B\u548cR1-Distill-Qwen-1.5B\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "ThinkLogit\u548cThinkLogit-DPO\u57284\u4e2a\u6570\u5b66\u6570\u636e\u96c6\u7684pass@1\u6307\u6807\u4e0a\u5206\u522b\u63d0\u9ad826%\u548c29%\uff0c\u7528R1-Distill-Qwen-1.5B\uff0821\u500d\u5c0f\u7684\u5f15\u5bfc\u8005\uff09\u6307\u5bfcQwen2.5-32B\uff1bThinkLogit\u8fd8\u80fd\u8fc1\u79fb\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u83b7\u5f97\u7684\u957f\u63a8\u7406\u6280\u80fd\uff0c\u8f83\u57fa\u7840\u6a21\u578b\u63d0\u534713%\u3002", "conclusion": "\u63d0\u51fa\u65e0\u9700\u6216\u6781\u5c11\u8bad\u7ec3\u5373\u53ef\u6fc0\u53d1\u5927\u6a21\u578b\u957f\u94fe\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u5927\u5e45\u63d0\u5347\u6027\u80fd\u4e14\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u4f4e\u3002\u65b9\u6cd5\u7b80\u5355\u9ad8\u6548\uff0c\u9002\u5408\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\u5feb\u901f\u589e\u5f3a\u3002"}}
{"id": "2507.12862", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.12862", "abs": "https://arxiv.org/abs/2507.12862", "authors": ["Hussein Abbass", "Taylan Akay", "Harrison Tolley"], "title": "Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command", "comment": null, "summary": "In the age of AI, human commanders need to use the computational powers\navailable in today's environment to simulate a very large number of scenarios.\nWithin each scenario, situations occur where different decision design options\ncould have ethical consequences. Making these decisions reliant on human\njudgement is both counter-productive to the aim of exploring very large number\nof scenarios in a timely manner and infeasible when considering the workload\nneeded to involve humans in each of these choices. In this paper, we move human\njudgement outside the simulation decision cycle. Basically, the human will\ndesign the ethical metric space, leaving it to the simulated environment to\nexplore the space. When the simulation completes its testing cycles, the\ntesting environment will come back to the human commander with a few options to\nselect from. The human commander will then exercise human-judgement to select\nthe most appropriate course of action, which will then get executed\naccordingly. We assume that the problem of designing metrics that are\nsufficiently granular to assess the ethical implications of decisions is\nsolved. Subsequently, the fundamental problem we look at in this paper is how\nto weight ethical decisions during the running of these simulations; that is,\nhow to dynamically weight the ethical attributes when agents are faced with\ndecision options with ethical implications during generative simulations. The\nmulti-criteria decision making literature has started to look at nearby\nproblems, where the concept of entropy has been used to determine the weights\nduring aggregation. We draw from that literature different approaches to\nautomatically calculate the weights for ethical attributes during\nsimulation-based testing and evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u4f26\u7406\u8bc4\u4ef7\u4e0e\u6a21\u62df\u6d41\u7a0b\u5206\u79bb\uff0c\u501f\u9274\u591a\u51c6\u5219\u51b3\u7b56\u7684\u71b5\u6743\u6cd5\uff0c\u5b9e\u73b0\u4eff\u771f\u4e2d\u4f26\u7406\u6307\u6807\u7684\u52a8\u6001\u81ea\u52a8\u52a0\u6743\uff0c\u63d0\u9ad8\u4e86\u5927\u89c4\u6a21\u4eff\u771f\u4e2d\u7684\u51b3\u7b56\u4f26\u7406\u8bc4\u4f30\u6548\u7387\u3002", "motivation": "\u5728AI\u65f6\u4ee3\uff0c\u4eba\u7c7b\u6307\u6325\u5b98\u9700\u8981\u5229\u7528\u73b0\u6709\u8ba1\u7b97\u80fd\u529b\u6a21\u62df\u5927\u91cf\u573a\u666f\u3002\u6bcf\u4e2a\u573a\u666f\u4e2d\u51b3\u7b56\u9009\u9879\u53ef\u80fd\u4ea7\u751f\u4f26\u7406\u540e\u679c\uff0c\u8fdb\u800c\u9700\u8981\u4eba\u5de5\u5224\u65ad\uff0c\u4f46\u8fd9\u65e2\u4f4e\u6548\u53c8\u96be\u4ee5\u5b9e\u73b0\u5927\u89c4\u6a21\u6a21\u62df\uff0c\u56e0\u6b64\u4e9f\u9700\u51cf\u5c11\u4eba\u7c7b\u5224\u65ad\u5728\u6a21\u62df\u8fc7\u7a0b\u4e2d\u6240\u5360\u636e\u7684\u73af\u8282\u3002", "method": "\u5c06\u201c\u4eba\u7c7b\u5224\u65ad\u201d\u79fb\u51fa\u6a21\u62df\u51b3\u7b56\u5faa\u73af\uff0c\u7531\u4eba\u7c7b\u4e8b\u5148\u8bbe\u8ba1\u4f26\u7406\u5ea6\u91cf\u7a7a\u95f4\uff0c\u6a21\u62df\u73af\u5883\u81ea\u52a8\u5728\u6b64\u7a7a\u95f4\u5185\u63a2\u7d22\uff0c\u6700\u7ec8\u53ea\u5728\u5173\u952e\u9009\u9879\u4e0a\u7531\u4eba\u7c7b\u51b3\u7b56\u3002\u7814\u7a76\u91cd\u70b9\u662f\u4eff\u771f\u8fd0\u884c\u65f6\u5982\u4f55\u52a8\u6001\u52a0\u6743\u5404\u7c7b\u4f26\u7406\u5c5e\u6027\uff0c\u5373\u5982\u4f55\u81ea\u52a8\u8ba1\u7b97\u4f26\u7406\u6307\u6807\u7684\u6743\u91cd\uff0c\u501f\u9274\u591a\u6307\u6807\u51b3\u7b56\u9886\u57df\u4e2d\u6709\u5173\u201c\u71b5\u201d\u65b9\u6cd5\u7684\u6587\u732e\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4eff\u771f\u6d4b\u8bd5\u4e0e\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u81ea\u52a8\u786e\u5b9a\u4f26\u7406\u5c5e\u6027\u6743\u91cd\u7684\u65b9\u6cd5\uff0c\u501f\u9274\u4e86\u591a\u51c6\u5219\u51b3\u7b56\uff08MCDM\uff09\u9886\u57df\u4e2d\u57fa\u4e8e\u201c\u71b5\u201d\u7684\u6743\u91cd\u5206\u914d\u601d\u8def\uff0c\u5b9e\u73b0\u4e86\u4f26\u7406\u5c5e\u6027\u5728\u6a21\u62df\u73af\u5883\u4e0b\u7684\u52a8\u6001\u52a0\u6743\u3002", "conclusion": "\u901a\u8fc7\u5c06\u4eba\u7c7b\u5224\u65ad\u79fb\u81f3\u4eff\u771f\u5faa\u73af\u4e4b\u5916\uff0c\u5e76\u91c7\u7528\u81ea\u52a8\u6743\u91cd\u5206\u914d\u673a\u5236\uff0c\u53ef\u4ee5\u5728\u5927\u89c4\u6a21\u60c5\u666f\u6a21\u62df\u4e2d\u9ad8\u6548\u4e14\u7cfb\u7edf\u5730\u5bf9\u4f26\u7406\u654f\u611f\u7684\u51b3\u7b56\u9009\u9879\u8fdb\u884c\u8bc4\u4f30\uff0c\u63d0\u5347\u51b3\u7b56\u6548\u7387\uff0c\u51cf\u5c11\u4eba\u529b\u8d1f\u62c5\u3002"}}
{"id": "2507.12769", "categories": ["cs.CL", "cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.12769", "abs": "https://arxiv.org/abs/2507.12769", "authors": ["Keli Zheng", "Zerong Xie"], "title": "Synergy: End-to-end Concept Model", "comment": null, "summary": "In this paper, we present Synergy, a language model that bridges different\nlevels of abstraction in an end-to-end fashion through a learned routing\nmechanism. Focusing on low-level linguistic abstraction, we trained our model\nas a byte-level language model. Our model spontaneously learns to tokenize\nbytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE)\ntokenizers while keeping comparable performance. By comparing with Llama3, we\nobserved an advantage of Synergy under the same model scale and training\ndataset size. Further studies show that the middle part (the higher abstraction\npart) of our model performs better when positional encodings are removed,\nsuggesting the emergence of position-independent concepts. These findings\ndemonstrate the feasibility of tokenizer-free architectures, paving the way for\nmore robust and flexible pipelines.", "AI": {"tldr": "Synergy\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5206\u8bcd\u5668\u3001\u7aef\u5230\u7aef\u5b66\u4e60\u7684\u5b57\u8282\u7ea7\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u5b66\u4e60\u5206\u8bcd\u83b7\u5f97\u6bd4BBPE\u66f4\u5c11\u7684token\u4e14\u6027\u80fd\u4e0d\u964d\uff0c\u90e8\u5206\u6a21\u5757\u8fd8\u8868\u73b0\u51fa\u4f4d\u7f6e\u65e0\u5173\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u65e0\u5206\u8bcd\u5668NLP\u67b6\u6784\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u4e8e\u56fa\u5b9a\u7684\u5206\u8bcd\u5668\u8fdb\u884c\u6587\u672c\u5904\u7406\uff0c\u8fd9\u53ef\u80fd\u9650\u5236\u6a21\u578b\u5bf9\u4f4e\u5c42\u6b21\u8bed\u8a00\u62bd\u8c61\u7684\u6355\u6349\u80fd\u529b\uff0c\u5e76\u5f71\u54cd\u5176\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u548c\u7075\u6d3b\u6027\u3002\u5982\u4f55\u8bbe\u8ba1\u4e00\u79cd\u80fd\u591f\u81ea\u4e3b\u5b66\u4e60\u5206\u8bcd\u7684\u7aef\u5230\u7aef\u8bed\u8a00\u6a21\u578b\uff0c\u662f\u63d0\u5347\u6a21\u578b\u9002\u5e94\u6027\u548c\u8868\u73b0\u7684\u4e00\u4e2a\u91cd\u8981\u65b9\u5411\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSynergy\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u91c7\u7528\u7aef\u5230\u7aef\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u5230\u7684\u8def\u7531\u673a\u5236\u6865\u63a5\u4e0d\u540c\u62bd\u8c61\u5c42\u6b21\u3002\u6a21\u578b\u4ee5\u5b57\u8282\u4e3a\u57fa\u7840\u8fdb\u884c\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u65e0\u5206\u8bcd\u5668\uff08tokenizer-free\uff09\u7684\u5904\u7406\u6d41\u7a0b\uff0c\u5e76\u4e0e\u4f20\u7edf\u7684BBPE\u5206\u8bcd\u5668\u548cLlama3\u6a21\u578b\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "Synergy\u80fd\u81ea\u52a8\u5b66\u4e60\u6709\u6548\u7684\u5206\u8bcd\u65b9\u5f0f\uff0c\u5176\u751f\u6210\u7684\u6982\u5ff5token\u6570\u91cf\u5c11\u4e8eBBPE\u5206\u8bcd\u5668\uff0c\u5728\u6a21\u578b\u89c4\u6a21\u548c\u8bad\u7ec3\u6570\u636e\u96c6\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\u6027\u80fd\u6301\u5e73\u751a\u81f3\u4f18\u4e8eLlama3\u3002\u6b64\u5916\uff0c\u8fdb\u4e00\u6b65\u5b9e\u9a8c\u8868\u660e\uff0c\u6a21\u578b\u4e2d\u8f83\u9ad8\u62bd\u8c61\u5c42\u7684\u90e8\u5206\u5728\u79fb\u9664\u4f4d\u7f6e\u7f16\u7801\u540e\u8868\u73b0\u66f4\u597d\uff0c\u663e\u793a\u4e86\u4f4d\u7f6e\u65e0\u5173\u6982\u5ff5\u7684\u81ea\u53d1\u6d8c\u73b0\u3002", "conclusion": "Synergy\u6a21\u578b\u9a8c\u8bc1\u4e86\u53bb\u5206\u8bcd\u5668\u5316\u67b6\u6784\uff08tokenizer-free architecture\uff09\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u6784\u5efa\u66f4\u5065\u58ee\u3001\u66f4\u7075\u6d3b\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6d41\u7a0b\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\u3002"}}
