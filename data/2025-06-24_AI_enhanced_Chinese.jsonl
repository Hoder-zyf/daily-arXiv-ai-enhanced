{"id": "2506.17303", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17303", "abs": "https://arxiv.org/abs/2506.17303", "authors": ["Rishi Bommasani", "Scott R. Singer", "Ruth E. Appel", "Sarah Cen", "A. Feder Cooper", "Elena Cryst", "Lindsey A. Gailmard", "Ian Klaus", "Meredith M. Lee", "Inioluwa Deborah Raji", "Anka Reuel", "Drew Spence", "Alexander Wan", "Angelina Wang", "Daniel Zhang", "Daniel E. Ho", "Percy Liang", "Dawn Song", "Joseph E. Gonzalez", "Jonathan Zittrain", "Jennifer Tour Chayes", "Mariano-Florentino Cuellar", "Li Fei-Fei"], "title": "The California Report on Frontier AI Policy", "comment": "Authored by the Joint California Policy Working Group on AI Frontier\n  Models", "summary": "The innovations emerging at the frontier of artificial intelligence (AI) are\npoised to create historic opportunities for humanity but also raise complex\npolicy challenges. Continued progress in frontier AI carries the potential for\nprofound advances in scientific discovery, economic productivity, and broader\nsocial well-being. As the epicenter of global AI innovation, California has a\nunique opportunity to continue supporting developments in frontier AI while\naddressing substantial risks that could have far reaching consequences for the\nstate and beyond. This report leverages broad evidence, including empirical\nresearch, historical analysis, and modeling and simulations, to provide a\nframework for policymaking on the frontier of AI development. Building on this\nmultidisciplinary approach, this report derives policy principles that can\ninform how California approaches the use, assessment, and governance of\nfrontier AI: principles rooted in an ethos of trust but verify. This approach\ntakes into account the importance of innovation while establishing appropriate\nstrategies to reduce material risks.", "AI": {"tldr": "\u672c\u62a5\u544a\u5206\u6790\u4e86\u524d\u6cbfAI\u5728\u5e26\u6765\u5de8\u5927\u673a\u9047\u7684\u540c\u65f6\u6240\u4f34\u968f\u7684\u653f\u7b56\u6311\u6218\uff0c\u901a\u8fc7\u591a\u5b66\u79d1\u7814\u7a76\u63d0\u51fa\u4e86\u2018\u4fe1\u4efb\u4f46\u9700\u9a8c\u8bc1\u2019\u7684\u653f\u7b56\u539f\u5219\uff0c\u5e2e\u52a9\u52a0\u5dde\u5e73\u8861AI\u521b\u65b0\u548c\u98ce\u9669\u6cbb\u7406\u3002", "motivation": "\u9762\u5bf9\u524d\u6cbfAI\u5e26\u6765\u7684\u5386\u53f2\u6027\u673a\u9047\u4e0e\u590d\u6742\u653f\u7b56\u6311\u6218\uff0c\u7279\u522b\u662f\u5176\u5bf9\u79d1\u5b66\u3001\u7ecf\u6d4e\u548c\u793e\u4f1a\u7684\u6df1\u8fdc\u5f71\u54cd\uff0c\u52a0\u5dde\u4f5c\u4e3a\u5168\u7403AI\u521b\u65b0\u4e2d\u5fc3\u9700\u8981\u5236\u5b9a\u65e2\u652f\u6301\u521b\u65b0\u53c8\u80fd\u6709\u6548\u9632\u63a7\u98ce\u9669\u7684\u653f\u7b56\u6846\u67b6\u3002", "method": "\u62a5\u544a\u91c7\u7528\u4e86\u5e7f\u6cdb\u8bc1\u636e\uff0c\u5305\u62ec\u5b9e\u8bc1\u7814\u7a76\u3001\u5386\u53f2\u5206\u6790\u3001\u5efa\u6a21\u4e0e\u6a21\u62df\uff0c\u57fa\u4e8e\u591a\u5b66\u79d1\u7684\u65b9\u6cd5\u5efa\u7acb\u7814\u7a76\u6846\u67b6\u5e76\u63a8\u5bfc\u653f\u7b56\u539f\u5219\u3002", "result": "\u62a5\u544a\u4e3a\u52a0\u5dde\u5236\u5b9a\u548c\u5b9e\u65bd\u524d\u6cbfAI\u653f\u7b56\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u4e0e\u6838\u5fc3\u539f\u5219\uff0c\u5f3a\u8c03\u521b\u65b0\u4e0e\u98ce\u9669\u964d\u4f4e\u7b56\u7565\u9700\u5e76\u91cd\u3002", "conclusion": "\u672c\u62a5\u544a\u63d0\u51fa\u4e86\u4e00\u5957\u4ee5\u201c\u4fe1\u4efb\u4f46\u9700\u9a8c\u8bc1\u201d\u4e3a\u6838\u5fc3\u7684\u653f\u7b56\u539f\u5219\uff0c\u6307\u5bfc\u52a0\u5dde\u5982\u4f55\u5728\u63a8\u52a8\u524d\u6cbfAI\u53d1\u5c55\u7684\u540c\u65f6\uff0c\u59a5\u5584\u8bc4\u4f30\u4e0e\u6cbb\u7406\u5176\u98ce\u9669\u3002"}}
{"id": "2506.17311", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17311", "abs": "https://arxiv.org/abs/2506.17311", "authors": ["Chuanlei Li", "Xu Hu", "Minghui Xu", "Kun Li", "Yue Zhang", "Xiuzhen Cheng"], "title": "Can Large Language Models Be Trusted Paper Reviewers? A Feasibility Study", "comment": null, "summary": "Academic paper review typically requires substantial time, expertise, and\nhuman resources. Large Language Models (LLMs) present a promising method for\nautomating the review process due to their extensive training data, broad\nknowledge base, and relatively low usage cost. This work explores the\nfeasibility of using LLMs for academic paper review by proposing an automated\nreview system. The system integrates Retrieval Augmented Generation (RAG), the\nAutoGen multi-agent system, and Chain-of-Thought prompting to support tasks\nsuch as format checking, standardized evaluation, comment generation, and\nscoring. Experiments conducted on 290 submissions from the WASA 2024 conference\nusing GPT-4o show that LLM-based review significantly reduces review time\n(average 2.48 hours) and cost (average \\$104.28 USD). However, the similarity\nbetween LLM-selected papers and actual accepted papers remains low (average\n38.6\\%), indicating issues such as hallucination, lack of independent judgment,\nand retrieval preferences. Therefore, it is recommended to use LLMs as\nassistive tools to support human reviewers, rather than to replace them.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u964d\u4f4e\u8bba\u6587\u8bc4\u5ba1\u7684\u65f6\u95f4\u548c\u6210\u672c\uff0c\u4f46\u5728\u72ec\u7acb\u5224\u65ad\u548c\u51c6\u786e\u6027\u4e0a\u4ecd\u6709\u660e\u663e\u4e0d\u8db3\uff0c\u9002\u5408\u4f5c\u4e3a\u4eba\u5de5\u8f85\u52a9\u5de5\u5177\uff0c\u800c\u4e0d\u80fd\u5b8c\u5168\u53d6\u4ee3\u4eba\u7c7b\u8bc4\u5ba1\u5458\u3002", "motivation": "\u5b66\u672f\u8bba\u6587\u8bc4\u5ba1\u901a\u5e38\u9700\u8981\u5927\u91cf\u65f6\u95f4\u3001\u4e13\u4e1a\u77e5\u8bc6\u548c\u4eba\u529b\u8d44\u6e90\uff0c\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u81ea\u52a8\u5316\u624b\u6bb5\u63d0\u5347\u8bc4\u5ba1\u6548\u7387\u3001\u964d\u4f4e\u6210\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u81ea\u52a8\u5316\u8bba\u6587\u8bc4\u5ba1\u7cfb\u7edf\uff0c\u5c06RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u3001AutoGen\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548cChain-of-Thought\u63d0\u793a\u65b9\u6cd5\u6574\u5408\u5728\u4e00\u8d77\uff0c\u652f\u6301\u683c\u5f0f\u68c0\u67e5\u3001\u6807\u51c6\u5316\u8bc4\u4ef7\u3001\u610f\u89c1\u751f\u6210\u548c\u6253\u5206\u7b49\u4efb\u52a1\u3002", "result": "\u5bf9290\u7bc7WASA 2024\u4f1a\u8bae\u6295\u7a3f\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660eLLM\u57fa\u7840\u7684\u8bc4\u5ba1\u53ef\u5927\u5e45\u51cf\u5c11\u8bc4\u5ba1\u65f6\u95f4\uff08\u5e73\u57472.48\u5c0f\u65f6\uff09\u4e0e\u6210\u672c\uff08\u5e73\u5747104.28\u7f8e\u5143\uff09\uff0c\u4f46\u4e0e\u5b9e\u9645\u5f55\u7528\u6587\u7ae0\u7684\u76f8\u4f3c\u5ea6\u8f83\u4f4e\uff08\u5e73\u574738.6%\uff09\uff0c\u66b4\u9732\u51fa\u5e7b\u89c9\u3001\u5224\u65ad\u72ec\u7acb\u6027\u4e0d\u8db3\u548c\u68c0\u7d22\u504f\u597d\u7b49\u95ee\u9898\u3002", "conclusion": "LLM\u53ef\u7528\u4f5c\u8f85\u52a9\u5de5\u5177\u5e2e\u52a9\u4eba\u7c7b\u8bc4\u5ba1\u5458\uff0c\u4f46\u73b0\u9636\u6bb5\u4e0d\u5b9c\u5b8c\u5168\u66ff\u4ee3\u4eba\u5de5\u8bc4\u5ba1\u3002"}}
{"id": "2506.17319", "categories": ["cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17319", "abs": "https://arxiv.org/abs/2506.17319", "authors": ["Shuangbao Paul Wang", "Lucas Yang", "Rahouane Chouchane", "Jin Guo", "Michael Bailey"], "title": "Using Machine Learning in Analyzing Air Quality Discrepancies of Environmental Impact", "comment": "IEEE 2024 International Conference on AI x Data & Knowledge\n  Engineering (AIxDKE)", "summary": "In this study, we apply machine learning and software engineering in\nanalyzing air pollution levels in City of Baltimore. The data model was fed\nwith three primary data sources: 1) a biased method of estimating insurance\nrisk used by homeowners loan corporation, 2) demographics of Baltimore\nresidents, and 3) census data estimate of NO2 and PM2.5 concentrations. The\ndataset covers 650,643 Baltimore residents in 44.7 million residents in 202\nmajor cities in US. The results show that air pollution levels have a clear\nassociation with the biased insurance estimating method. Great disparities\npresent in NO2 level between more desirable and low income blocks. Similar\ndisparities exist in air pollution level between residents' ethnicity. As\nBaltimore population consists of a greater proportion of people of color, the\nfinding reveals how decades old policies has continued to discriminate and\naffect quality of life of Baltimore citizens today.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u673a\u5668\u5b66\u4e60\u548c\u591a\u6e90\u6570\u636e\uff0c\u63ed\u793a\u4e86\u5df4\u5c14\u7684\u6469\u6709\u8272\u4eba\u79cd\u53ca\u4f4e\u6536\u5165\u7fa4\u4f53\u56e0\u5386\u53f2\u653f\u7b56\u9057\u7559\uff0c\u9762\u5bf9\u66f4\u9ad8\u7a7a\u6c14\u6c61\u67d3\u7684\u4e0d\u516c\u73b0\u5b9e\u3002", "motivation": "\u7814\u7a76\u5df4\u5c14\u7684\u6469\u5e02\u7a7a\u6c14\u6c61\u67d3\u4e0e\u5386\u53f2\u4e0a\u6709\u504f\u89c1\u7684\u4fdd\u9669\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u3001\u5c45\u6c11\u4eba\u53e3\u7ed3\u6784\u4ee5\u53ca\u4eba\u53e3\u666e\u67e5\u4e2d\u7684\u7a7a\u6c14\u6c61\u67d3\u7269\uff08NO2\u548cPM2.5\uff09\u6d53\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u63a2\u8ba8\u957f\u671f\u653f\u7b56\u5bf9\u5c45\u6c11\uff0c\u7279\u522b\u662f\u6709\u8272\u4eba\u79cd\u751f\u6d3b\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "method": "\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u548c\u8f6f\u4ef6\u5de5\u7a0b\u65b9\u6cd5\uff0c\u5229\u7528\u4e09\u4e2a\u4e3b\u8981\u6570\u636e\u6e90\uff08\u4f4f\u623f\u8d37\u6b3e\u516c\u53f8\u7684\u6709\u504f\u4f30\u7b97\u65b9\u6cd5\u3001\u5df4\u5c14\u7684\u6469\u4eba\u53e3\u7edf\u8ba1\u6570\u636e\u3001NO2\u548cPM2.5\u6d53\u5ea6\u7684\u666e\u67e5\u6570\u636e\uff09\u5bf9\u57ce\u5e02\u7a7a\u6c14\u6c61\u67d3\u8fdb\u884c\u5efa\u6a21\u548c\u5206\u6790\u3002", "result": "\u53d1\u73b0\u7a7a\u6c14\u6c61\u67d3\u6c34\u5e73\u4e0e\u6709\u504f\u89c1\u7684\u4fdd\u9669\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u660e\u663e\u8054\u7cfb\u3002\u9ad8\u6536\u5165\u548c\u4f4e\u6536\u5165\u5c45\u4f4f\u533a\u4e4b\u95f4\u7684NO2\u6c34\u5e73\u5b58\u5728\u5de8\u5927\u5dee\u5f02\uff0c\u4e0d\u540c\u79cd\u65cf\u95f4\u7a7a\u6c14\u6c61\u67d3\u66b4\u9732\u6c34\u5e73\u540c\u6837\u4e0d\u5747\u3002", "conclusion": "\u5386\u53f2\u6709\u504f\u89c1\u7684\u653f\u7b56\u548c\u98ce\u9669\u4f30\u7b97\u65b9\u6cd5\uff0c\u5bfc\u81f4\u4e86\u4eca\u65e5\u5df4\u5c14\u7684\u6469\u5e02\u4e0d\u540c\u79cd\u65cf\u3001\u6536\u5165\u9636\u5c42\u5728\u7a7a\u6c14\u6c61\u67d3\u66b4\u9732\u4e0a\u7684\u4e25\u91cd\u4e0d\u5e73\u7b49\u95ee\u9898\uff0c\u8fd9\u4e9b\u653f\u7b56\u6301\u7eed\u5f71\u54cd\u5c45\u6c11\u7684\u751f\u6d3b\u8d28\u91cf\uff0c\u7279\u522b\u662f\u6709\u8272\u4eba\u79cd\u7fa4\u4f53\u3002"}}
{"id": "2506.17320", "categories": ["cs.CY", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17320", "abs": "https://arxiv.org/abs/2506.17320", "authors": ["Akash Awasthi", "Brandon V. Chang", "Anh M. Vu", "Ngan Le", "Rishi Agrawal", "Zhigang Deng", "Carol Wu", "Hien Van Nguyen"], "title": "MAARTA:Multi-Agentic Adaptive Radiology Teaching Assistant", "comment": "Accepted to MICCAI 2025 (Main Conference)", "summary": "Radiology students often struggle to develop perceptual expertise due to\nlimited expert mentorship time, leading to errors in visual search and\ndiagnostic interpretation. These perceptual errors, such as missed fixations,\nshort dwell times, or misinterpretations, are not adequately addressed by\ncurrent AI systems, which focus on diagnostic accuracy but fail to explain how\nand why errors occur. To address this gap, we introduce MAARTA (Multi-Agentic\nAdaptive Radiology Teaching Assistant), a multi-agent framework that analyzes\ngaze patterns and radiology reports to provide personalized feedback. Unlike\nsingle-agent models, MAARTA dynamically selects agents based on error\ncomplexity, enabling adaptive and efficient reasoning. By comparing expert and\nstudent gaze behavior through structured graphs, the system identifies missed\nfindings and assigns Perceptual Error Teacher agents to analyze discrepancies.\nMAARTA then uses step-by-step prompting to help students understand their\nerrors and improve diagnostic reasoning, advancing AI-driven radiology\neducation.", "AI": {"tldr": "\u63d0\u51faMAARTA\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u6790\u89c6\u7ebf\u548c\u8bca\u65ad\u62a5\u544a\uff0c\u4e3a\u653e\u5c04\u79d1\u5b66\u751f\u63d0\u4f9b\u4e2a\u6027\u5316\u7684\u9519\u8bef\u5206\u6790\u548c\u6539\u6b63\u5efa\u8bae\uff0c\u63d0\u5347\u4e86AI\u5728\u533b\u5b66\u6559\u80b2\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u6559\u5b66\u6548\u679c\u3002", "motivation": "\u653e\u5c04\u79d1\u5b66\u751f\u7531\u4e8e\u7f3a\u4e4f\u4e13\u5bb6\u6307\u5bfc\u65f6\u95f4\uff0c\u96be\u4ee5\u57f9\u517b\u77e5\u89c9\u4e13\u4e1a\u80fd\u529b\uff0c\u5bfc\u81f4\u89c6\u89c9\u641c\u7d22\u548c\u8bca\u65ad\u89e3\u91ca\u51fa\u9519\u3002\u76ee\u524d\u7684AI\u4e3b\u8981\u5173\u6ce8\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u65e0\u6cd5\u89e3\u91ca\u9519\u8bef\u53d1\u751f\u7684\u539f\u56e0\u548c\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86MAARTA\uff08\u591a\u667a\u80fd\u4f53\u81ea\u9002\u5e94\u653e\u5c04\u5b66\u52a9\u6559\uff09\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u6790\u5b66\u5458\u7684\u89c6\u7ebf\u8f68\u8ff9\u548c\u62a5\u544a\uff0c\u6bd4\u8f83\u4e13\u5bb6\u4e0e\u5b66\u751f\u7684\u884c\u4e3a\uff0c\u5229\u7528\u7ed3\u6784\u5316\u56fe\u8c31\u68c0\u6d4b\u9057\u6f0f\u548c\u9519\u8bef\uff0c\u5e76\u7531\u4e13\u95e8\u7684\u667a\u80fd\u4f53\u5206\u6790\u548c\u53cd\u9988\u3002\u7cfb\u7edf\u53ef\u6839\u636e\u9519\u8bef\u590d\u6742\u6027\u52a8\u6001\u9009\u62e9\u9002\u5f53\u7684\u667a\u80fd\u4f53\uff0c\u5206\u6b65\u5f15\u5bfc\u5b66\u751f\u7406\u89e3\u548c\u6539\u6b63\u9519\u8bef\u3002", "result": "MAARTA\u80fd\u591f\u6709\u6548\u53d1\u73b0\u5b66\u751f\u5728\u5f71\u50cf\u5224\u8bfb\u4e2d\u7684\u5177\u4f53\u77e5\u89c9\u9519\u8bef\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u53cd\u9988\u4fc3\u8fdb\u5176\u8bca\u65ad\u63a8\u7406\u80fd\u529b\u63d0\u5347\uff0c\u4ece\u800c\u63a8\u52a8\u57fa\u4e8eAI\u7684\u653e\u5c04\u79d1\u6559\u80b2\u53d1\u5c55\u3002", "conclusion": "MAARTA\u5f25\u8865\u4e86\u73b0\u6709AI\u5728\u653e\u5c04\u5b66\u6559\u80b2\u4e2d\u53ea\u5173\u6ce8\u7ed3\u679c\u4e0d\u89e3\u91ca\u8fc7\u7a0b\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u4e14\u4e2a\u6027\u5316\u7684\u5dee\u9519\u53cd\u9988\uff0c\u5f15\u5bfc\u5b66\u751f\u6539\u8fdb\uff0c\u63d0\u9ad8\u4e86\u653e\u5c04\u5b66\u751f\u7684\u57f9\u517b\u6548\u7387\u3002"}}
{"id": "2506.18147", "categories": ["q-fin.TR"], "pdf": "https://arxiv.org/pdf/2506.18147", "abs": "https://arxiv.org/abs/2506.18147", "authors": ["Paloma Mar\u00edn", "Sergio Ardanza-Trevijano", "Javier Sabio"], "title": "Causal Interventions in Bond Multi-Dealer-to-Client Platforms", "comment": null, "summary": "The digitalization of financial markets has shifted trading from voice to\nelectronic channels, with Multi-Dealer-to-Client (MD2C) platforms now enabling\nclients to request quotes (RfQs) for financial instruments like bonds from\nmultiple dealers simultaneously. In this competitive landscape, dealers cannot\nsee each other's prices, making a rigorous analysis of the negotiation process\ncrucial to ensure their profitability. This article introduces a novel general\nframework for analyzing the RfQ process using probabilistic graphical models\nand causal inference. Within this framework, we explore different inferential\nquestions that are relevant for dealers participating in MD2C platforms, such\nas the computation of optimal prices, estimating potential revenues and the\nidentification of clients that might be interested in trading the dealer's\naxes. We then move into analyzing two different approaches for model\nspecification: a generative model built on the work of (Fermanian, Gu\\'eant &\nPu, 2017); and discriminative models utilizing machine learning techniques. We\nevaluate these methodologies using predictive metrics designed to assess their\neffectiveness in the context of optimal pricing, highlighting the relative\nbenefits of using models that take into account the internal mechanisms of the\nnegotiation process.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u7528\u4e8e\u591a\u4ea4\u6613\u5546\u5bf9\u5ba2\u6237\u5e73\u53f0\uff08MD2C\uff09\u8c08\u5224\u5206\u6790\u7684\u6982\u7387\u4e0e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u5176\u5bf9\u5b9a\u4ef7\u4e0e\u6536\u76ca\u4f18\u5316\u7684\u5b9e\u9645\u6548\u679c\uff0c\u5f3a\u8c03\u7406\u89e3\u8c08\u5224\u673a\u5236\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u91d1\u878d\u5e02\u573a\u6570\u5b57\u5316\u5bfc\u81f4\u4ea4\u6613\u6a21\u5f0f\u4ece\u8bed\u97f3\u8f6c\u5411\u7535\u5b50\u5316\uff0c\u591a\u4ea4\u6613\u5546\u5bf9\u5ba2\u6237\uff08MD2C\uff09\u5e73\u53f0\u8ba9\u5ba2\u6237\u53ef\u4ee5\u540c\u65f6\u5411\u591a\u4e2a\u4ea4\u6613\u5546\u8bf7\u6c42\u62a5\u4ef7\uff08RfQ\uff09\u3002\u5728\u6b64\u9ad8\u5ea6\u7ade\u4e89\u4f46\u4ef7\u683c\u5f7c\u6b64\u4e0d\u53ef\u89c1\u7684\u73af\u5883\u4e0b\uff0c\u4ea4\u6613\u5546\u9700\u8981\u4e25\u8c28\u5730\u5206\u6790\u8c08\u5224\u8fc7\u7a0b\u4ee5\u4fdd\u6301\u76c8\u5229\u3002\u672c\u6587\u65e8\u5728\u4e3a\u8fd9\u4e00\u95ee\u9898\u5efa\u7acb\u5206\u6790\u6846\u67b6\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6982\u7387\u56fe\u6a21\u578b\u4e0e\u56e0\u679c\u63a8\u65ad\u7684\u901a\u7528\u5206\u6790\u6846\u67b6\uff0c\u63a2\u8ba8RfQ\u6d41\u7a0b\u4e2d\u4ea4\u6613\u5546\u7684\u6700\u4f18\u5b9a\u4ef7\u3001\u6f5c\u5728\u6536\u76ca\u4f30\u7b97\u548c\u5ba2\u6237\u8bc6\u522b\u7b49\u63a8\u65ad\u95ee\u9898\u3002\u540c\u65f6\uff0c\u5206\u6790\u4e86\u4e24\u7c7b\u6a21\u578b\uff1a\u57fa\u4e8e\u751f\u6210\u5f0f\u6a21\u578b\uff08Fermanian, Gu\u00e9ant & Pu, 2017\u5de5\u4f5c\uff09\u548c\u5229\u7528\u673a\u5668\u5b66\u4e60\u7684\u5224\u522b\u5f0f\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5b9a\u4ef7\u573a\u666f\u4e0b\u7684\u9884\u6d4b\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0d\u540c\u6a21\u578b\u5728\u6700\u4f18\u5b9a\u4ef7\u65b9\u9762\u6709\u4e0d\u540c\u8868\u73b0\uff0c\u80fd\u591f\u5bf9\u5b9e\u9645MD2C\u5e73\u53f0\u4ea4\u6613\u5546\u7684\u5b9a\u4ef7\u7b56\u7565\u4e0e\u6536\u76ca\u9884\u6d4b\u63d0\u4f9b\u6709\u6548\u652f\u6301\uff0c\u5e76\u7a81\u51fa\u4e86\u7406\u89e3\u8c08\u5224\u8fc7\u7a0b\u5185\u90e8\u673a\u5236\u6a21\u578b\u7684\u4f18\u52bf\u3002", "conclusion": "\u57fa\u4e8e\u6982\u7387\u56fe\u6a21\u578b\u548c\u56e0\u679c\u63a8\u65ad\u7684\u5206\u6790\u6846\u67b6\u80fd\u6709\u6548\u8bc4\u4f30MD2C\u5e73\u53f0\u73af\u5883\u4e2d\u4ea4\u6613\u5546\u7684\u591a\u7b56\u7565\uff0c\u5e2e\u52a9\u4f18\u5316\u5b9a\u4ef7\u548c\u63d0\u5347\u6536\u76ca\uff0c\u5bf9\u5b9e\u52a1\u5177\u6709\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.17224", "categories": ["cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17224", "abs": "https://arxiv.org/abs/2506.17224", "authors": ["Zofia Pizo\u0144", "Shinji Kimijima", "Grzegorz Brus"], "title": "Bridging Equilibrium and Kinetics Prediction with a Data-Weighted Neural Network Model of Methane Steam Reforming", "comment": "12 pages, 8 figures", "summary": "Hydrogen's role is growing as an energy carrier, increasing the need for\nefficient production, with methane steam reforming being the most widely used\ntechnique. This process is crucial for applications like fuel cells, where\nhydrogen is converted into electricity, pushing for reactor miniaturization and\noptimized process control through numerical simulations. Existing models\ntypically address either kinetic or equilibrium regimes, limiting their\napplicability. Here we show a surrogate model capable of unifying both regimes.\nAn artificial neural network trained on a comprehensive dataset that includes\nexperimental data from kinetic and equilibrium experiments, interpolated data,\nand theoretical data derived from theoretical models for each regime. Data\naugmentation and assigning appropriate weights to each data type enhanced\ntraining. After evaluating Bayesian Optimization and Random Sampling, the\noptimal model demonstrated high predictive accuracy for the composition of the\npost-reaction mixture under varying operating parameters, indicated by a mean\nsquared error of 0.000498 and strong Pearson correlation coefficients of 0.927.\nThe network's ability to provide continuous derivatives of its predictions\nmakes it particularly useful for process modeling and optimization. The results\nconfirm the surrogate model's robustness for simulating methane steam reforming\nin both kinetic and equilibrium regimes, making it a valuable tool for design\nand process optimization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u4e8e\u591a\u6e90\u6570\u636e\uff08\u5b9e\u9a8c\u3001\u7406\u8bba\u3001\u63d2\u503c\u7b49\uff09\u7684\u795e\u7ecf\u7f51\u7edc\u4ee3\u7406\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u7532\u70f7\u84b8\u6c7d\u91cd\u6574\u52a8\u529b\u5b66\u548c\u70ed\u529b\u5b66\u5de5\u51b5\u7684\u7edf\u4e00\u9ad8\u7cbe\u5ea6\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8fc7\u7a0b\u5efa\u6a21\u4e0e\u4f18\u5316\u80fd\u529b\uff0c\u53ef\u7528\u4e8e\u53cd\u5e94\u5668\u8bbe\u8ba1\u548c\u6d41\u7a0b\u4f18\u5316\u3002", "motivation": "\u5f53\u524d\u6c22\u6c14\u4f5c\u4e3a\u80fd\u6e90\u8f7d\u4f53\u7684\u9700\u6c42\u4e0d\u65ad\u589e\u957f\uff0c\u7532\u70f7\u84b8\u6c7d\u91cd\u6574\u662f\u6700\u5e38\u7528\u7684\u5236\u6c22\u5de5\u827a\u3002\u968f\u7740\u71c3\u6599\u7535\u6c60\u7b49\u5e94\u7528\u63a8\u52a8\u53cd\u5e94\u5668\u7684\u5c0f\u578b\u5316\u548c\u8fc7\u7a0b\u4f18\u5316\uff0c\u5bf9\u80fd\u540c\u65f6\u5904\u7406\u52a8\u529b\u5b66\u548c\u70ed\u529b\u5b66\uff08\u5e73\u8861\uff09\u4e24\u79cd\u5de5\u51b5\u7684\u9ad8\u6548\u6a21\u62df\u65b9\u6cd5\u7684\u9700\u6c42\u65e5\u76ca\u7a81\u51fa\u3002\u7136\u800c\uff0c\u73b0\u6709\u6a21\u578b\u591a\u4ec5\u9002\u7528\u4e8e\u67d0\u4e00\u5de5\u51b5\uff0c\u9002\u7528\u9762\u6709\u9650\u3002", "method": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u4ee3\u7406\u6a21\u578b\uff0c\u5229\u7528\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u7528\u5305\u542b\u52a8\u529b\u5b66\u5b9e\u9a8c\u3001\u5e73\u8861\u5b9e\u9a8c\u3001\u63d2\u503c\u6570\u636e\u548c\u7406\u8bba\u6570\u636e\u7684\u7efc\u5408\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u3002\u6570\u636e\u589e\u5f3a\u53ca\u4e0d\u540c\u6570\u636e\u7c7b\u578b\u8d4b\u4e88\u4e0d\u540c\u6743\u91cd\u63d0\u5347\u4e86\u6a21\u578b\u8bad\u7ec3\u6548\u679c\u3002\u5bf9\u6bd4\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u968f\u673a\u91c7\u6837\uff0c\u9009\u53d6\u4e86\u6700\u4f18\u6a21\u578b\u3002", "result": "\u8be5\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u4e0d\u540c\u64cd\u4f5c\u53c2\u6570\u4e0b\u9884\u6d4b\u53cd\u5e94\u540e\u6df7\u5408\u7269\u7ec4\u6210\u65f6\u8868\u73b0\u51fa\u6781\u9ad8\u51c6\u786e\u6027\uff0c\u5747\u65b9\u8bef\u5dee\u4ec5\u4e3a0.000498\uff0cPearson\u76f8\u5173\u7cfb\u6570\u4e3a0.927\u3002\u6a21\u578b\u8f93\u51fa\u5177\u6709\u8fde\u7eed\u5bfc\u6570\uff0c\u9002\u5408\u4e8e\u8fc7\u7a0b\u5efa\u6a21\u548c\u4f18\u5316\u3002", "conclusion": "\u6240\u63d0\u4ee3\u7406\u6a21\u578b\u80fd\u591f\u7edf\u4e00\u52a8\u529b\u5b66\u548c\u5e73\u8861\u4e24\u7c7b\u5de5\u51b5\uff0c\u5177\u6709\u7a33\u5b9a\u6027\u548c\u8f83\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u7532\u70f7\u84b8\u6c7d\u91cd\u6574\u53cd\u5e94\u6a21\u62df\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2506.17223", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17223", "abs": "https://arxiv.org/abs/2506.17223", "authors": ["Shuvra Smaran Das", "Anirban Saha Anik", "Md Kishor Morol", "Mohammad Sakib Mahmood"], "title": "Outcome-Based Education: Evaluating Students' Perspectives Using Transformer", "comment": "6 pages, 7 figures", "summary": "Outcome-Based Education (OBE) emphasizes the development of specific\ncompetencies through student-centered learning. In this study, we reviewed the\nimportance of OBE and implemented transformer-based models, particularly\nDistilBERT, to analyze an NLP dataset that includes student feedback. Our\nobjective is to assess and improve educational outcomes. Our approach is better\nthan other machine learning models because it uses the transformer's deep\nunderstanding of language context to classify sentiment better, giving better\nresults across a wider range of matrices. Our work directly contributes to\nOBE's goal of achieving measurable outcomes by facilitating the identification\nof patterns in student learning experiences. We have also applied LIME (local\ninterpretable model-agnostic explanations) to make sure that model predictions\nare clear. This gives us understandable information about how key terms affect\nsentiment. Our findings indicate that the combination of transformer models and\nLIME explanations results in a strong and straightforward framework for\nanalyzing student feedback. This aligns more closely with the principles of OBE\nand ensures the improvement of educational practices through data-driven\ninsights.", "AI": {"tldr": "\u672c\u6587\u7528Transformer\uff08DistilBERT\uff09\u548cLIME\u89e3\u91ca\u65b9\u6cd5\uff0c\u5b9e\u73b0\u5bf9\u5b66\u751f\u53cd\u9988\u7684\u9ad8\u6548\u53ef\u89e3\u91ca\u5206\u6790\uff0c\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\uff0c\u6709\u52a9\u4e8e\u4ee5\u6210\u679c\u4e3a\u5bfc\u5411\u7684\u6559\u80b2\u76ee\u6807\u5b9e\u73b0\u3002", "motivation": "OBE\uff08\u4ee5\u6210\u679c\u4e3a\u5bfc\u5411\u7684\u6559\u80b2\uff09\u8981\u6c42\u51c6\u786e\u5206\u6790\u5b66\u751f\u53cd\u9988\u4ee5\u6539\u8fdb\u6559\u5b66\u6210\u679c\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5bf9\u6587\u672c\u60c5\u611f\u7406\u89e3\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5148\u8fdb\u7684NLP\u5de5\u5177\u3002", "method": "\u672c\u6587\u91c7\u7528\u57fa\u4e8eTransformer\u7684DistilBERT\u6a21\u578b\u5206\u6790\u5b66\u751f\u53cd\u9988\u7684NLP\u6570\u636e\u96c6\uff0c\u5206\u7c7b\u60c5\u611f\uff0c\u5e76\u7ed3\u5408LIME\u89e3\u91ca\u6a21\u578b\u4ee5\u63d0\u9ad8\u9884\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "result": "DistilBERT\u5728\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u66f4\u591a\u8bc4\u4f30\u77e9\u9635\u4e0a\u83b7\u5f97\u66f4\u597d\u7ed3\u679c\uff0c\u5e76\u5229\u7528LIME\u89e3\u91ca\u5e2e\u52a9\u7406\u89e3\u60c5\u611f\u5224\u522b\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u5c06Transformer\u6a21\u578b\u4e0eLIME\u7ed3\u5408\uff0c\u80fd\u591f\u6709\u6548\u3001\u53ef\u89e3\u91ca\u5730\u5206\u6790\u5b66\u751f\u53cd\u9988\uff0c\u4fc3\u8fdbOBE\u76ee\u6807\u5b9e\u73b0\uff0c\u652f\u6301\u57fa\u4e8e\u6570\u636e\u7684\u6559\u80b2\u5b9e\u8df5\u6539\u8fdb\u3002"}}
{"id": "2506.17289", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17289", "abs": "https://arxiv.org/abs/2506.17289", "authors": ["Rahul Raja", "Arpita Vats"], "title": "Evaluating Generalization and Representation Stability in Small LMs via Prompting", "comment": "Accepted at ICML", "summary": "We investigate the generalization capabilities of small language models under\ntwo popular adaptation paradigms: few-shot prompting and supervised\nfine-tuning. While prompting is often favored for its parameter efficiency and\nflexibility, it remains unclear how robust this approach is in low-resource\nsettings and under distributional shifts. This paper presents a comparative\nstudy of prompting and fine-tuning across task formats, prompt styles, and\nmodel scales, with a focus on their behavior in both in-distribution and\nout-of-distribution (OOD) settings.\n  Beyond accuracy, we analyze the internal representations learned by each\napproach to assess the stability and abstraction of task-specific features. Our\nfindings highlight critical differences in how small models internalize and\ngeneralize knowledge under different adaptation strategies. This work offers\npractical guidance for model selection in low-data regimes and contributes\nempirical insight into the ongoing debate over prompting versus fine-tuning.\nCode for the experiments is available at the following", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u5bf9\u6bd4\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728prompt\u4e0e\u5fae\u8c03\u4e24\u79cd\u8303\u5f0f\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u91cd\u70b9\u5173\u6ce8\u5206\u5e03\u5916\u53ca\u4f4e\u8d44\u6e90\u4efb\u52a1\uff0c\u901a\u8fc7\u5185\u90e8\u8868\u5f81\u5206\u6790\u63ed\u793a\u4e24\u8005\u673a\u5236\u5dee\u5f02\uff0c\u52a9\u529b\u5b9e\u9645\u7b56\u7565\u9009\u62e9\u3002", "motivation": "\u5f53\u524dprompt\u65b9\u6cd5\u56e0\u53c2\u6570\u9ad8\u6548\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u5728\u4f4e\u8d44\u6e90\u548c\u5206\u5e03\u6f02\u79fb\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\u5c1a\u4e0d\u660e\u786e\uff0c\u76f8\u5173\u5bf9\u6bd4\u548c\u5b9e\u8bc1\u5206\u6790\u4e9f\u9700\u6df1\u5165\u3002", "method": "\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u6db5\u76d6\u4e0d\u540c\u4efb\u52a1\u683c\u5f0f\u3001prompt\u98ce\u683c\u548c\u6a21\u578b\u89c4\u6a21\uff0c\u5206\u522b\u7814\u7a76prompt\u548c\u5fae\u8c03\u7b56\u7565\u5728\u5206\u5e03\u5185\u5916\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002\u540c\u65f6\uff0c\u5206\u6790\u6a21\u578b\u5185\u90e8\u8868\u5f81\uff0c\u8bc4\u4ef7\u4efb\u52a1\u7279\u5f81\u62bd\u8c61\u4e0e\u7a33\u5b9a\u6027\u3002", "result": "\u4e24\u79cd\u9002\u5e94\u65b9\u5f0f\u5728\u5185\u90e8\u77e5\u8bc6\u5efa\u6a21\u3001\u6cdb\u5316\u6027\u80fd\u53ca\u7279\u5f81\u62bd\u8c61\u4e0a\u673a\u5236\u8fe5\u5f02\u3002\u7814\u7a76\u53d1\u73b0\u9488\u5bf9\u4e0d\u540c\u4f4e\u6570\u636e\u573a\u666f\u9002\u5408\u4e0d\u540c\u7b56\u7565\uff0c\u5e76\u4e3a\u5177\u4f53\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002", "conclusion": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728few-shot prompt\u548c\u76d1\u7763\u5fae\u8c03\u4e24\u79cd\u9002\u5e94\u8303\u5f0f\u4e0b\u5c55\u73b0\u51fa\u4e0d\u540c\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u5206\u5e03\u5916\u6d4b\u8bd5\u548c\u4f4e\u8d44\u6e90\u60c5\u51b5\u4e0b\uff0c\u4e24\u8005\u8868\u73b0\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002"}}
{"id": "2506.17339", "categories": ["cs.CY", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2506.17339", "abs": "https://arxiv.org/abs/2506.17339", "authors": ["Ren\u00e9 Bohnsack", "Mickie de Wet"], "title": "AI is the Strategy: From Agentic AI to Autonomous Business Models onto Strategy in the Age of AI", "comment": "21 pages, 6 figures, 3 tables. Under review at Strategy Science (no\n  decision yet). This version posted to facilitate citation and feedback", "summary": "This article develops the concept of Autonomous Business Models (ABMs) as a\ndistinct managerial and strategic logic in the age of agentic AI. While most\nfirms still operate within human-driven or AI-augmented models, we argue that\nwe are now entering a phase where agentic AI (systems capable of initiating,\ncoordinating, and adapting actions autonomously) can increasingly execute the\ncore mechanisms of value creation, delivery, and capture. This shift reframes\nAI not as a tool to support strategy, but as the strategy itself. Using two\nillustrative cases, getswan.ai, an Israeli startup pursuing autonomy by design,\nand a hypothetical reconfiguration of Ryanair as an AI-driven incumbent, we\ndepict the evolution from augmented to autonomous business models. We show how\nABMs reshape competitive advantage through agentic execution, continuous\nadaptation, and the gradual offloading of human decision-making. This\ntransition introduces new forms of competition between AI-led firms, which we\nterm synthetic competition, where strategic interactions occur at rapid,\nmachine-level speed and scale. It also challenges foundational assumptions in\nstrategy, organizational design, and governance. By positioning agentic AI as\nthe central actor in business model execution, the article invites us to\nrethink strategic management in an era where firms increasingly run themselves.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u81ea\u4e3b\u578b\u5546\u4e1a\u6a21\u5f0f\uff08ABMs\uff09\uff0c\u8ba4\u4e3a\u4ee3\u7406\u6027AI\u5c06\u6210\u4e3a\u4f01\u4e1a\u6218\u7565\u548c\u8fd0\u8425\u7684\u6838\u5fc3\u3002\u4eceAI\u589e\u5f3a\u5411AI\u81ea\u4e3b\u5546\u4e1a\u6a21\u5f0f\u8f6c\u578b\uff0c\u5c06\u91cd\u6784\u4f01\u4e1a\u7ade\u4e89\u548c\u7ba1\u7406\u903b\u8f91\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u4f01\u4e1a\u4ecd\u4ee5\u4eba\u4e3a\u4e3b\u5bfc\u6216AI\u589e\u5f3a\u4e3a\u4e3b\uff0c\u4f46\u968f\u7740\u4ee3\u7406\u6027AI\u7684\u53d1\u5c55\uff0cAI\u4e0d\u4ec5\u662f\u8f85\u52a9\u5de5\u5177\uff0c\u800c\u53ef\u4ee5\u6210\u4e3a\u6267\u884c\u4f01\u4e1a\u4ef7\u503c\u521b\u9020\u3001\u4f20\u9012\u4e0e\u83b7\u53d6\u7684\u6838\u5fc3\u3002\u56e0\u6b64\u6709\u5fc5\u8981\u91cd\u65b0\u63a2\u8ba8AI\u4e3b\u5bfc\u7684\u5546\u4e1a\u6a21\u5f0f\u3002", "method": "\u672c\u6587\u63d0\u51fa\u81ea\u4e3b\u578b\u5546\u4e1a\u6a21\u5f0f\uff08ABMs\uff09\u6982\u5ff5\uff0c\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u2014\u2014\u4ee5autonomy by design\u4e3a\u76ee\u6807\u7684\u4ee5\u8272\u5217\u521d\u521b\u516c\u53f8getswam.ai\uff0c\u4ee5\u53ca\u5047\u8bbe\u7684AI\u4e3b\u5bfc\u745e\u5b89\u822a\u7a7a\u6539\u9020\u6848\u4f8b\u2014\u2014\u8bf4\u660e\u4eceAI\u589e\u5f3a\u5230AI\u81ea\u4e3b\u5546\u4e1a\u6a21\u5f0f\u7684\u6f14\u53d8\u8fc7\u7a0b\u3002", "result": "ABMs\u80fd\u591f\u901a\u8fc7AI\u81ea\u4e3b\u6267\u884c\u3001\u6301\u7eed\u9002\u5e94\u548c\u9010\u6b65\u5378\u8f7d\u4eba\u7c7b\u51b3\u7b56\uff0c\u91cd\u5851\u4f01\u4e1a\u7ade\u4e89\u4f18\u52bf\uff0c\u5f15\u53d1\u201c\u5408\u6210\u7ade\u4e89\u201d\uff08synthetic competition\uff09\uff0c\u5e26\u6765\u51b3\u7b56\u901f\u5ea6\u548c\u89c4\u6a21\u7684\u5de8\u5927\u53d8\u5316\uff0c\u5bf9\u6218\u7565\u3001\u7ec4\u7ec7\u8bbe\u8ba1\u548c\u6cbb\u7406\u4ea7\u751f\u6df1\u8fdc\u5f71\u54cd\u3002", "conclusion": "\u968f\u7740\u4ee3\u7406\u6027AI\u65e5\u76ca\u4e3b\u5bfc\u4f01\u4e1a\u8fd0\u4f5c\uff0c\u6211\u4eec\u9700\u8981\u91cd\u65b0\u7406\u89e3\u548c\u8bbe\u8ba1\u4f01\u4e1a\u6218\u7565\u7ba1\u7406\uff0c\u56e0\u4e3a\u4f01\u4e1a\u5c06\u8d8a\u6765\u8d8a\u591a\u5b9e\u73b0\u81ea\u52a8\u5316\u81ea\u8fd0\u884c\u3002"}}
{"id": "2506.17487", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.17487", "abs": "https://arxiv.org/abs/2506.17487", "authors": ["Alireza Tabarraei"], "title": "Variational Quantum Latent Encoding for Topology Optimization", "comment": null, "summary": "A variational framework for structural topology optimization is developed,\nintegrating quantum and classical latent encoding strategies within a\ncoordinate-based neural decoding architecture. In this approach, a\nlow-dimensional latent vector, generated either by a variational quantum\ncircuit or sampled from a Gaussian distribution, is mapped to a\nhigher-dimensional latent space via a learnable projection layer. This enriched\nrepresentation is then decoded into a high-resolution material distribution\nusing a neural network that takes both the latent vector and Fourier-mapped\nspatial coordinates as input. The optimization is performed directly on the\nlatent parameters, guided solely by physics-based objectives such as compliance\nminimization and volume constraints evaluated through finite element analysis,\nwithout requiring any precomputed datasets or supervised training. Quantum\nlatent vectors are constructed from the expectation values of Pauli observables\nmeasured on parameterized quantum circuits, providing a structured and\nentangled encoding of information. The classical baseline uses Gaussian-sampled\nlatent vectors projected in the same manner. The proposed variational\nformulation enables the generation of diverse and physically valid topologies\nby exploring the latent space through sampling or perturbation, in contrast to\ntraditional optimization methods that yield a single deterministic solution.\nNumerical experiments show that both classical and quantum encodings produce\nhigh-quality structural designs. However, quantum encodings demonstrate\nadvantages in several benchmark cases in terms of compliance and design\ndiversity. These results highlight the potential of quantum circuits as an\neffective and scalable tool for physics-constrained topology optimization and\nsuggest promising directions for applying near-term quantum hardware in\nstructural design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u878d\u5408\u91cf\u5b50\u548c\u7ecf\u5178\u6f5c\u7a7a\u95f4\u7f16\u7801\u7684\u795e\u7ecf\u7ed3\u6784\u4f18\u5316\u65b9\u6cd5\uff0c\u5b9e\u73b0\u65e0\u76d1\u7763\u3001\u591a\u89e3\u62d3\u6251\u8bbe\u8ba1\u3002\u91cf\u5b50\u6f5c\u7f16\u7801\u5728\u8bbe\u8ba1\u591a\u6837\u6027\u548c\u7269\u7406\u6027\u80fd\u4e0a\u5c55\u73b0\u4f18\u52bf\uff0c\u663e\u793a\u91cf\u5b50\u7535\u8def\u5728\u7ed3\u6784\u4f18\u5316\u9886\u57df\u7684\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u5e0c\u671b\u7a81\u7834\u4f20\u7edf\u62d3\u6251\u4f18\u5316\u53ea\u80fd\u5f97\u5230\u5355\u4e00\u89e3\u7684\u9650\u5236\uff0c\u901a\u8fc7\u91cf\u5b50\u4e0e\u7ecf\u5178\u6f5c\u7a7a\u95f4\u7f16\u7801\u63d0\u5347\u8bbe\u8ba1\u591a\u6837\u6027\u548c\u6027\u80fd\uff0c\u540c\u65f6\u4e3a\u7269\u7406\u7ea6\u675f\u7684\u7ed3\u6784\u4f18\u5316\u63a2\u7d22\u9ad8\u6548\u65b9\u6cd5\uff0c\u5e76\u63a2\u7d22\u91cf\u5b50\u786c\u4ef6\u5728\u7ed3\u6784\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u53d8\u5206\u7ed3\u6784\u62d3\u6251\u4f18\u5316\u6846\u67b6\uff0c\u5c06\u91cf\u5b50\u4e0e\u7ecf\u5178\u6f5c\u7f16\u7801\u65b9\u6cd5\u7ed3\u5408\u5230\u57fa\u4e8e\u5750\u6807\u7684\u795e\u7ecf\u89e3\u7801\u7ed3\u6784\u4e2d\u3002\u4f7f\u7528\u53d8\u5206\u91cf\u5b50\u7535\u8def\u6216\u9ad8\u65af\u5206\u5e03\u751f\u6210\u4f4e\u7ef4\u6f5c\u5411\u91cf\uff0c\u7ecf\u53ef\u5b66\u4e60\u6295\u5f71\u5c42\u6620\u5c04\u5230\u9ad8\u7ef4\u6f5c\u7a7a\u95f4\uff0c\u518d\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u4e0e\u5085\u91cc\u53f6\u6620\u5c04\u5750\u6807\u8054\u5408\u89e3\u7801\u4e3a\u9ad8\u5206\u8fa8\u7387\u6750\u6599\u5206\u5e03\uff0c\u5e76\u4ee5\u6709\u9650\u5143\u5206\u6790\u7684\u7269\u7406\u76ee\u6807\u76f4\u63a5\u4f18\u5316\u6f5c\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u65e0\u76d1\u7763\u4e0b\u53ef\u751f\u6210\u591a\u6837\u4e14\u7269\u7406\u6709\u6548\u7684\u7ed3\u6784\u62d3\u6251\u3002\u4e24\u7c7b\u7f16\u7801\u65b9\u5f0f\u5747\u83b7\u5f97\u9ad8\u8d28\u91cf\u8bbe\u8ba1\uff0c\u91cf\u5b50\u7f16\u7801\u5728\u591a\u4e2a\u57fa\u51c6\u95ee\u9898\u4e2d\u5728\u987a\u5e94\u6027\u548c\u8bbe\u8ba1\u591a\u6837\u6027\u4e0a\u4f18\u4e8e\u7ecf\u5178\u65b9\u6cd5\u3002", "conclusion": "\u91cf\u5b50\u7535\u8def\u5728\u7ed3\u6784\u62d3\u6251\u4f18\u5316\u4e2d\u5c55\u73b0\u51fa\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u6709\u671b\u5728\u7ed3\u6784\u8bbe\u8ba1\u9886\u57df\u63a8\u52a8\u8fd1\u7aef\u91cf\u5b50\u786c\u4ef6\u7684\u5e94\u7528\u3002"}}
{"id": "2506.17231", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17231", "abs": "https://arxiv.org/abs/2506.17231", "authors": ["Xiang Li", "Chong Zhang", "Jia Wang", "Fangyu Wu", "Yushi Li", "Xiaobo Jin"], "title": "Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs", "comment": "15 pages, 5 figures", "summary": "Attacks on large language models (LLMs) in jailbreaking scenarios raise many\nsecurity and ethical issues. Current jailbreak attack methods face problems\nsuch as low efficiency, high computational cost, and poor cross-model\nadaptability and versatility, which make it difficult to cope with the rapid\ndevelopment of LLM and new defense strategies. Our work proposes an Adversarial\nPrompt Distillation, which combines masked language modeling, reinforcement\nlearning, and dynamic temperature control through a prompt generation and\ndistillation method. It enables small language models (SLMs) to jailbreak\nattacks on mainstream LLMs. The experimental results verify the superiority of\nthe proposed method in terms of attack success rate and harm, and reflect the\nresource efficiency and cross-model adaptability. This research explores the\nfeasibility of distilling the jailbreak ability of LLM to SLM, reveals the\nmodel's vulnerability, and provides a new idea for LLM security research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u5bf9\u6297\u6027\u63d0\u793a\u84b8\u998f\u65b9\u6cd5\uff0c\u4f7f\u5c0f\u6a21\u578b\u80fd\u8d8a\u72f1\u653b\u51fb\u4e3b\u6d41\u5927\u6a21\u578b\uff0c\u517c\u5177\u9ad8\u6548\u7387\u3001\u5f3a\u9002\u5e94\u6027\u548c\u5371\u5bb3\u6027\uff0c\u5bf9LLM\u5b89\u5168\u9886\u57df\u5177\u6709\u542f\u53d1\u610f\u4e49\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9762\u4e34\u8d8a\u72f1\u653b\u51fb\u5e26\u6765\u7684\u5b89\u5168\u53ca\u9053\u5fb7\u95ee\u9898\uff0c\u7136\u800c\u73b0\u6709\u65b9\u6cd5\u6548\u7387\u4f4e\u3001\u8ba1\u7b97\u6d88\u8017\u5927\u3001\u8de8\u6a21\u578b\u9002\u5e94\u6027\u5dee\uff0c\u96be\u4ee5\u5e94\u5bf9\u6a21\u578b\u4e0e\u9632\u5fa1\u7b56\u7565\u7684\u5feb\u901f\u53d8\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u6297\u6027\u63d0\u793a\u84b8\u998f\uff08Adversarial Prompt Distillation\uff0cAPD\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u52a8\u6001\u6e29\u5ea6\u63a7\u5236\uff0c\u901a\u8fc7\u751f\u6210\u548c\u84b8\u998f\u63d0\u793a\uff0c\u4f7f\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u80fd\u591f\u653b\u51fb\u4e3b\u6d41LLM\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u653b\u51fb\u6210\u529f\u7387\u548c\u5371\u5bb3\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u540c\u65f6\u5728\u8d44\u6e90\u6548\u7387\u548c\u8de8\u6a21\u578b\u9002\u5e94\u6027\u65b9\u9762\u4e5f\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u672c\u7814\u7a76\u9a8c\u8bc1\u4e86\u5c06LLM\u8d8a\u72f1\u80fd\u529b\u84b8\u998f\u81f3SLM\u7684\u53ef\u884c\u6027\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u6f5c\u5728\u7684\u8106\u5f31\u6027\uff0c\u4e3aLLM\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.17300", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17300", "abs": "https://arxiv.org/abs/2506.17300", "authors": ["Daniel T. Chang"], "title": "Individual Causal Inference with Structural Causal Model", "comment": null, "summary": "Individual causal inference (ICI) uses causal inference methods to understand\nand predict the effects of interventions on individuals, considering their\nspecific characteristics / facts. It aims to estimate individual causal effect\n(ICE), which varies across individuals. Estimating ICE can be challenging due\nto the limited data available for individuals, and the fact that most causal\ninference methods are population-based. Structural Causal Model (SCM) is\nfundamentally population-based. Therefore, causal discovery (structural\nlearning and parameter learning), association queries and intervention queries\nare all naturally population-based. However, exogenous variables (U) in SCM can\nencode individual variations and thus provide the mechanism for individualized\npopulation per specific individual characteristics / facts. Based on this, we\npropose ICI with SCM as a \"rung 3\" causal inference, because it involves\n\"imagining\" what would be the causal effect of a hypothetical intervention on\nan individual, given the individual's observed characteristics / facts.\nSpecifically, we propose the indiv-operator, indiv(W), to formalize/represent\nthe population individualization process, and the individual causal query, P(Y\n| indiv(W), do(X), Z), to formalize/represent ICI. We show and argue that ICI\nwith SCM is inference on individual alternatives (possible), not individual\ncounterfactuals (non-actual).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7528\u4e8e\u4e2a\u4f53\u56e0\u679c\u63a8\u65ad\uff08ICI\uff09\u7684\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff08SCM\uff09\u65b0\u65b9\u6cd5\uff0c\u5f15\u5165\u4e86indiv-operator\u548c\u4e2a\u4f53\u56e0\u679c\u67e5\u8be2\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u53ea\u80fd\u505a\u7fa4\u4f53\u56e0\u679c\u63a8\u65ad\u7684\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u5bf9\u7279\u5b9a\u4e2a\u4f53\u7684\u5e72\u9884\u63a8\u7406\uff0c\u9002\u7528\u4e8e\u7cbe\u51c6\u533b\u7597\u7b49\u9886\u57df\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u63a8\u65ad\u591a\u57fa\u4e8e\u7fa4\u4f53\u5c42\u9762\uff0c\u4f46\u5b9e\u9645\u95ee\u9898\u5e38\u5e38\u9700\u8981\u9488\u5bf9\u7279\u5b9a\u4e2a\u4f53\u63a8\u65ad\u5e72\u9884\u6548\u5e94\uff08\u4e2a\u4f53\u56e0\u679c\u6548\u5e94\uff0cICE\uff09\uff0c\u800c\u4e2a\u4f53\u6570\u636e\u6709\u9650\u3001\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u4e2a\u4f53\u5c42\u9762\u56e0\u679c\u63a8\u65ad\u7684\u7406\u8bba\u4e0e\u65b9\u6cd5\u96be\u9898\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5f15\u5165\u201cindiv-operator\u201d\uff08indiv(W)\uff09\u5c06\u7fa4\u4f53\u6a21\u578b\u4e2a\u4f53\u5316\uff0c\u5e76\u63d0\u51fa\u4e86\u9488\u5bf9\u4e2a\u4f53\u7684\u56e0\u679c\u67e5\u8be2P(Y | indiv(W), do(X), Z)\u3002\u8fd9\u79cd\u65b9\u6cd5\u5c06\u4e2a\u4f53\u7279\u5f81\u7f16\u7801\u8fdbSCM\u7684\u5916\u751f\u53d8\u91cf\u4e2d\uff0c\u5b9e\u73b0\u5bf9\u7279\u5b9a\u4e2a\u4f53\u7684\u56e0\u679c\u6548\u5e94\u63a8\u7406\u3002", "result": "\u4f5c\u8005\u63d0\u51fa\u7684ICI-with-SCM\u65b9\u6cd5\u8868\u660e\uff0c\u53ef\u4ee5\u901a\u8fc7\u5bf9\u5916\u751f\u53d8\u91cf\u7684\u5efa\u6a21\u548c\u7279\u5b9a\u8fd0\u7b97\uff0c\u5b9e\u73b0\u5bf9\u4e2a\u4f53\u7684\u5e72\u9884\u6548\u5e94\u63a8\u65ad\u3002ICI\u5173\u6ce8\u7684\u662f\u53ef\u80fd\u7684\u4e2a\u4f53\u7ed3\u679c\uff08individual alternatives\uff09\uff0c\u800c\u975e\u53cd\u4e8b\u5b9e\uff08counterfactuals\uff09\u3002\u65b0\u65b9\u6cd5\u80fd\u66f4\u79d1\u5b66\u5730\u652f\u6301\u7cbe\u51c6\u533b\u7597\u7b49\u9886\u57df\u7684\u4e2a\u4f53\u51b3\u7b56\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff08SCM\uff09\u7684\u4e2a\u4f53\u56e0\u679c\u63a8\u65ad\uff08ICI\uff09\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5f62\u5f0f\u5316\u4e2a\u4f53\u5316\u8fd0\u7b97\u7b26\u548c\u67e5\u8be2\u65b9\u5f0f\uff0c\u5b8c\u5584\u4e86\u5bf9\u4e2a\u4f53\u5c42\u9762\u7684\u56e0\u679c\u63a8\u65ad\u6846\u67b6\uff0c\u5f3a\u8c03\u4e86\u5176\u4e3a\u201c\u7b2c\u4e09\u7ea7\u56e0\u679c\u63a8\u65ad\uff08rung 3\uff09\u201d\u3002"}}
{"id": "2506.17347", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17347", "abs": "https://arxiv.org/abs/2506.17347", "authors": ["Jennifer Wang", "Andrew Selbst", "Solon Barocas", "Suresh Venkatasubramanian"], "title": "Distinguishing Predictive and Generative AI in Regulation", "comment": null, "summary": "Over the past decade, policymakers have developed a set of regulatory tools\nto ensure AI development aligns with key societal goals. Many of these tools\nwere initially developed in response to concerns with predictive AI and\ntherefore encode certain assumptions about the nature of AI systems and the\nutility of certain regulatory approaches. With the advent of generative AI,\nhowever, some of these assumptions no longer hold, even as policymakers attempt\nto maintain a single regulatory target that covers both types of AI.\n  In this paper, we identify four distinct aspects of generative AI that call\nfor meaningfully different policy responses. These are the generality and\nadaptability of generative AI that make it a poor regulatory target, the\ndifficulty of designing effective evaluations, new legal concerns that change\nthe ecosystem of stakeholders and sources of expertise, and the distributed\nstructure of the generative AI value chain.\n  In light of these distinctions, policymakers will need to evaluate where the\npast decade of policy work remains relevant and where new policies, designed to\naddress the unique risks posed by generative AI, are necessary. We outline\nthree recommendations for policymakers to more effectively identify regulatory\ntargets and leverage constraints across the broader ecosystem to govern\ngenerative AI.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u4e0e\u9884\u6d4b\u5f0fAI\u6709\u672c\u8d28\u533a\u522b\uff0c\u73b0\u6709\u76d1\u7ba1\u5de5\u5177\u96be\u4ee5\u5b8c\u5168\u9002\u7528\u3002\u672c\u6587\u5206\u6790\u4e86\u751f\u6210\u5f0fAI\u7684\u56db\u5927\u7279\u6027\u53ca\u5e26\u6765\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e09\u9879\u653f\u7b56\u5efa\u8bae\uff0c\u52a9\u529b\u5236\u5b9a\u66f4\u6709\u6548\u7684AI\u76d1\u7ba1\u653f\u7b56\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u7684\u51fa\u73b0\uff0c\u73b0\u6709\u7684AI\u76d1\u7ba1\u5de5\u5177\u57fa\u4e8e\u5bf9\u9884\u6d4b\u5f0fAI\u7684\u5047\u8bbe\uff0c\u5df2\u7ecf\u96be\u4ee5\u6db5\u76d6\u65b0\u578bAI\u5e26\u6765\u7684\u72ec\u7279\u6311\u6218\uff0c\u4e9f\u9700\u91cd\u65b0\u5ba1\u89c6\u548c\u8c03\u6574\u653f\u7b56\u54cd\u5e94\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u751f\u6210\u5f0fAI\u7684\u56db\u4e2a\u5173\u952e\u7279\u5f81\uff0c\u63a2\u8ba8\u5176\u5bf9\u653f\u7b56\u5236\u5b9a\u5e26\u6765\u7684\u65b0\u9700\u6c42\u548c\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u9488\u5bf9\u6027\u7684\u6539\u8fdb\u5efa\u8bae\u3002", "result": "\u7814\u7a76\u660e\u786e\u4e86\u751f\u6210\u5f0fAI\u5728\u901a\u7528\u6027\u4e0e\u9002\u5e94\u6027\u3001\u8bc4\u4f30\u96be\u5ea6\u3001\u65b0\u7684\u6cd5\u5f8b\u95ee\u9898\u4ee5\u53ca\u4ef7\u503c\u94fe\u5206\u5e03\u7ed3\u6784\u65b9\u9762\u4e0e\u9884\u6d4b\u5f0fAI\u7684\u6839\u672c\u4e0d\u540c\uff0c\u5f3a\u8c03\u73b0\u6709\u76d1\u7ba1\u653f\u7b56\u90e8\u5206\u5931\u6548\uff0c\u9700\u8981\u65b0\u7684\u653f\u7b56\u5de5\u5177\uff0c\u5e76\u7ed9\u51fa\u4e09\u9879\u5177\u4f53\u5efa\u8bae\u6765\u6539\u8fdb\u76d1\u7ba1\u76ee\u6807\u8bc6\u522b\u548c\u6cbb\u7406\u624b\u6bb5\u3002", "conclusion": "\u4e3a\u6709\u6548\u6cbb\u7406\u751f\u6210\u5f0fAI\uff0c\u653f\u7b56\u5236\u5b9a\u8005\u5e94\u533a\u5206\u4e24\u7c7bAI\u7684\u6838\u5fc3\u5dee\u5f02\uff0c\u501f\u9274\u4ee5\u5f80\u653f\u7b56\u4e2d\u4ecd\u6709\u6548\u7684\u90e8\u5206\uff0c\u540c\u65f6\u9488\u5bf9\u751f\u6210\u5f0fAI\u72ec\u6709\u7684\u98ce\u9669\u5236\u5b9a\u65b0\u653f\u7b56\u3002\u672c\u6587\u4e3a\u76d1\u7ba1\u76ee\u6807\u4e0e\u751f\u6001\u7cfb\u7edf\u7ea6\u675f\u7684\u8bc6\u522b\u3001\u5229\u7528\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.17830", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.17830", "abs": "https://arxiv.org/abs/2506.17830", "authors": ["Amina El Bachari", "Johann Rannou", "Vladislav A. Yastrebov", "Pierre Kerfriden", "Susanne Claus"], "title": "A predictor-corrector scheme for approximating signed distances using finite element methods", "comment": "26 pages, 17 figures", "summary": "In this article, we introduce a finite element method designed for the robust\ncomputation of approximate signed distance functions to arbitrary boundaries in\ntwo and three dimensions. Our method employs a novel prediction-correction\napproach, involving first the solution of a linear diffusion-based prediction\nproblem, followed by a nonlinear minimization-based correction problem\nassociated with the Eikonal equation. The prediction step efficiently generates\na suitable initial guess, significantly facilitating convergence of the\nnonlinear correction step. A key strength of our approach is its ability to\nhandle complex interfaces and initial level set functions with arbitrary steep\nor flat regions, a notable challenge for existing techniques. Through several\nrepresentative examples, including classical geometries and more complex shapes\nsuch as star domains and three-dimensional tori, we demonstrate the accuracy,\nefficiency, and robustness of the method, validating its broad applicability\nfor reinitializing diverse level set functions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u5065\u58ee\u7684\u6709\u9650\u5143\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b-\u6821\u6b63\u7b56\u7565\u8ba1\u7b97\u62df\u6709\u7b26\u53f7\u8ddd\u79bb\u51fd\u6570\uff0c\u80fd\u5f88\u597d\u5730\u5e94\u5bf9\u590d\u6742\u754c\u9762\u548c\u5404\u79cd\u521d\u59cb\u60c5\u51b5\uff0c\u9002\u7528\u4e8e\u5404\u7c7blevel set\u91cd\u521d\u59cb\u5316\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8ba1\u7b97\u6709\u7b26\u53f7\u8ddd\u79bb\u51fd\u6570\u7684\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u754c\u9762\u6216\u521d\u59cblevel set\u51fd\u6570\u6709\u7a81\u51fa\u6216\u5e73\u5766\u533a\u57df\u65f6\u5f80\u5f80\u4e0d\u591f\u5065\u58ee\u9ad8\u6548\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u9650\u5143\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u57fa\u4e8e\u6269\u6563\u7684\u7ebf\u6027\u9884\u6d4b\u6b65\u9aa4\u548c\u57fa\u4e8eEikonal\u65b9\u7a0b\u7684\u975e\u7ebf\u6027\u6700\u5c0f\u5316\u6821\u6b63\u6b65\u9aa4\u3002", "result": "\u901a\u8fc7\u591a\u79cd\u5178\u578b\u4e0e\u590d\u6742\u51e0\u4f55\uff08\u5982\u661f\u57df\u3001\u4e09\u7ef4\u73af\u9762\u7b49\uff09\u7684\u6570\u503c\u5b9e\u9a8c\uff0c\u65b9\u6cd5\u5177\u5907\u9ad8\u7cbe\u5ea6\u3001\u9ad8\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5e7f\u6cdb\u7a33\u5b9a\u5730\u5e94\u7528\u4e8e\u5404\u7c7blevel set\u51fd\u6570\u7684\u91cd\u65b0\u521d\u59cb\u5316\uff0c\u5c24\u5176\u5728\u590d\u6742\u754c\u9762\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.17286", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17286", "abs": "https://arxiv.org/abs/2506.17286", "authors": ["Luoyang Sun", "Jiwen Jiang", "Cheng Deng", "Xinjian Wu", "Haifeng Zhang", "Lei Chen", "Lionel Ni", "Jun Wang"], "title": "GTA: Grouped-head latenT Attention", "comment": null, "summary": "Attention mechanisms underpin the success of large language models (LLMs),\nyet their substantial computational and memory overhead poses challenges for\noptimizing efficiency and performance. A critical bottleneck arises as KV cache\nand attention computations scale rapidly with text length, challenging\ndeployment on hardware with limited computational and memory resources. We\nobserve that attention mechanisms exhibit substantial redundancy, since the KV\ncache can be significantly compressed and attention maps across heads display\nhigh similarity, revealing that much of the computation and storage is\nunnecessary. Leveraging these insights, we propose \\textbf{G}rouped-Head\nLaten\\textbf{T} \\textbf{A}ttention (GTA), a novel attention mechanism that\nreduces memory usage and computational complexity while maintaining\nperformance. GTA comprises two components: (1) a shared attention map mechanism\nthat reuses attention scores across multiple heads, decreasing the key cache\nsize; and (2) a nonlinear value decoder with learned projections that\ncompresses the value cache into a latent space, further cutting memory needs.\nGTA cuts attention computation FLOPs by up to \\emph{62.5\\%} versus\nGrouped-Query Attention and shrink the KV cache by up to \\emph{70\\%}, all while\navoiding the extra overhead of Multi-Head Latent Attention to improve LLM\ndeployment efficiency. Consequently, GTA models achieve a \\emph{2x} increase in\nend-to-end inference speed, with prefill benefiting from reduced computational\ncost and decoding benefiting from the smaller cache footprint.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGrouped-Head Latent Attention (GTA)\uff0c\u901a\u8fc7\u5171\u4eab\u6ce8\u610f\u529b\u56fe\u4e0e\u6f5c\u7a7a\u95f4\u89e3\u7801\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u4e0e\u5b58\u50a8\u5f00\u9500\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u901f\u5ea6\u7ffb\u500d\u5e76\u964d\u4f4eKV\u7f13\u5b58\u9700\u6c42\uff0c\u9002\u5408\u9ad8\u6548\u90e8\u7f72\u5230\u8ba1\u7b97\u6216\u5185\u5b58\u53d7\u9650\u73af\u5883\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6ce8\u610f\u529b\u673a\u5236\u867d\u7136\u5173\u952e\uff0c\u4f46\u5176\u9ad8\u6602\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u4e25\u91cd\u5f71\u54cd\u4e86\u6548\u7387\u4e0e\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6587\u672c\u957f\u5ea6\u53d8\u957f\u65f6\uff0c\u5bf9\u786c\u4ef6\u8d44\u6e90\u9650\u5236\u63d0\u51fa\u4e86\u6311\u6218\u3002\u7814\u7a76\u8005\u89c2\u5bdf\u5230\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684KV\u7f13\u5b58\u548c\u5404\u5934\u7684\u6ce8\u610f\u529b\u56fe\u6709\u5f88\u5927\u5197\u4f59\uff0c\u56e0\u6b64\u671f\u671b\u7528\u66f4\u9ad8\u6548\u7684\u65b9\u6848\u51cf\u5c11\u8d44\u6e90\u5360\u7528\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6ce8\u610f\u529b\u673a\u5236\uff1aGrouped-Head Latent Attention (GTA)\u3002\u4e3b\u8981\u5305\u62ec\u4e24\u4e2a\u7ec4\u4ef6\uff1a(1) \u5171\u4eab\u6ce8\u610f\u529b\u56fe\u673a\u5236\uff0c\u5728\u591a\u4e2a\u5934\u4e4b\u95f4\u590d\u7528\u6ce8\u610f\u529b\u5206\u6570\uff0c\u51cf\u5c0fkey\u7f13\u5b58\u5927\u5c0f\uff1b(2) \u975e\u7ebf\u6027\u503c\u89e3\u7801\u5668\uff0c\u7528\u5b66\u4e60\u5230\u7684\u6295\u5f71\u5c06value\u7f13\u5b58\u538b\u7f29\u81f3\u6f5c\u5728\u7a7a\u95f4\uff0c\u8fdb\u4e00\u6b65\u964d\u4f4e\u5185\u5b58\u9700\u6c42\u3002", "result": "GTA\u7b97\u6cd5\u76f8\u6bd4Grouped-Query Attention\u6700\u591a\u53ef\u4ee5\u51cf\u5c1162.5%\u7684\u6ce8\u610f\u529b\u8ba1\u7b97FLOPs\uff0c\u6700\u591a\u53ef\u51cf\u5c1170%\u7684KV\u7f13\u5b58\u4f53\u79ef\uff0c\u540c\u65f6\u907f\u514d\u4e86\u591a\u5934\u6f5c\u5728\u6ce8\u610f\u529b\u65b9\u6cd5\u7684\u989d\u5916\u5f00\u9500\u3002\u6700\u7ec8\uff0c\u6574\u4f53\u63a8\u7406\u901f\u5ea6\u63d0\u53472\u500d\uff0c\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u8ba1\u7b97\u548c\u7f13\u5b58\u5f00\u9500\u5747\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "GTA\u6709\u6548\u538b\u7f29\u4e86KV\u7f13\u5b58\u548c\u6ce8\u610f\u529b\u8ba1\u7b97\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u5927\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\u548c\u90e8\u7f72\u6548\u7387\uff0c\u540c\u65f6\u51e0\u4e4e\u4e0d\u727a\u7272\u6a21\u578b\u6027\u80fd\u3002\u5176\u521b\u65b0\u6027\u673a\u5236\u4e3a\u8d44\u6e90\u53d7\u9650\u786c\u4ef6\u4e0a\u7684LLM\u90e8\u7f72\u5e26\u6765\u4e86\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2506.17434", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17434", "abs": "https://arxiv.org/abs/2506.17434", "authors": ["Sydney Levine", "Matija Franklin", "Tan Zhi-Xuan", "Secil Yanik Guyot", "Lionel Wong", "Daniel Kilov", "Yejin Choi", "Joshua B. Tenenbaum", "Noah Goodman", "Seth Lazar", "Iason Gabriel"], "title": "Resource Rational Contractualism Should Guide AI Alignment", "comment": "24 pages, 10 figures", "summary": "AI systems will soon have to navigate human environments and make decisions\nthat affect people and other AI agents whose goals and values diverge.\nContractualist alignment proposes grounding those decisions in agreements that\ndiverse stakeholders would endorse under the right conditions, yet securing\nsuch agreement at scale remains costly and slow -- even for advanced AI. We\ntherefore propose Resource-Rational Contractualism (RRC): a framework where AI\nsystems approximate the agreements rational parties would form by drawing on a\ntoolbox of normatively-grounded, cognitively-inspired heuristics that trade\neffort for accuracy. An RRC-aligned agent would not only operate efficiently,\nbut also be equipped to dynamically adapt to and interpret the ever-changing\nhuman social world.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8d44\u6e90\u7406\u6027\u5951\u7ea6\u4e3b\u4e49\uff08RRC\uff09\u6846\u67b6\uff0c\u501f\u52a9\u542f\u53d1\u5f0f\u65b9\u5f0f\u9ad8\u6548\u903c\u8fd1\u591a\u5143\u4eba\u7c7b\u5171\u8bc6\uff0c\u4ece\u800c\u63d0\u5347AI\u4f26\u7406\u5bf9\u9f50\u4e0e\u793e\u4f1a\u9002\u5e94\u80fd\u529b\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u9010\u6e10\u878d\u5165\u4eba\u7c7b\u793e\u4f1a\u73af\u5883\uff0c\u5176\u51b3\u7b56\u5c06\u5f71\u54cd\u76ee\u6807\u548c\u4ef7\u503c\u89c2\u4e0d\u540c\u7684\u4eba\u7c7b\u4e0eAI\u4ee3\u7406\u3002\u5982\u4f55\u8ba9AI\u7684\u51b3\u7b56\u88ab\u66f4\u591a\u5229\u76ca\u76f8\u5173\u8005\u8ba4\u53ef\uff0c\u6210\u4e3a\u4e86\u5b9e\u73b0AI\u4f26\u7406\u5bf9\u9f50\u7684\u91cd\u8981\u6311\u6218\u3002\u7136\u800c\uff0c\u73b0\u5b9e\u4e2d\u5927\u89c4\u6a21\u8fbe\u6210\u8fd9\u79cd\u5171\u8bc6\u6210\u672c\u9ad8\u6602\uff0c\u5e76\u4e14\u6548\u7387\u8f83\u4f4e\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u8d44\u6e90\u7406\u6027\u5951\u7ea6\u4e3b\u4e49\uff08Resource-Rational Contractualism, RRC\uff09\u6846\u67b6\uff0c\u4e3b\u5f20AI\u501f\u9274\u4e00\u5957\u89c4\u8303\u6027\u57fa\u7840\u548c\u8ba4\u77e5\u542f\u53d1\u5f0f\u5de5\u5177\uff0c\u6743\u8861\u51b3\u7b56\u52aa\u529b\u4e0e\u51c6\u786e\u6027\uff0c\u5b9e\u73b0\u5bf9\u51c6\u4eba\u7c7b\u793e\u4f1a\u5171\u8bc6\u7684\u8fd1\u4f3c\u3002", "result": "RRC\u6846\u67b6\u4f7fAI\u4ee3\u7406\u4e0d\u4f46\u9ad8\u6548\u8fd0\u884c\uff0c\u8fd8\u80fd\u591f\u5b9e\u65f6\u9002\u5e94\u548c\u89e3\u8bfb\u4e0d\u65ad\u53d8\u5316\u7684\u4eba\u7c7b\u793e\u4f1a\u4e16\u754c\uff0c\u4ece\u800c\u66f4\u597d\u5730\u878d\u5165\u4eba\u7c7b\u73af\u5883\u5e76\u83b7\u5f97\u591a\u5143\u4e3b\u4f53\u7684\u5e7f\u6cdb\u8ba4\u53ef\u3002", "conclusion": "RRC\u4e3a\u5b9e\u73b0AI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u793e\u4f1a\u5728\u51b3\u7b56\u4e0a\u7684\u9ad8\u6548\u4e14\u52a8\u6001\u7684\u4f26\u7406\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u8def\u5f84\uff0c\u517c\u987e\u6548\u7387\u4e0e\u9002\u5e94\u6027\u3002"}}
{"id": "2506.17354", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17354", "abs": "https://arxiv.org/abs/2506.17354", "authors": ["Farah Altarazi"], "title": "Evaluating the Impact of Lean and Green Practices on Operational Performance: A Real Data-Driven Simulation Case Study", "comment": "16 pages, 6 Figures, 4 Tables, This work is based on part of my\n  Master's thesis at the Department of Industrial Engineering, University of\n  Jordan, Jordan", "summary": "Global market-driven forces and customer needs are continuously changing. In\nthe past, profitability and efficiency were the primary objectives of most\ncompanies. However, in recent decades, sustainable performance has emerged as a\nnew competitive advantage. Companies have been compelled to adopt a concept\nthat combines these evolving global interests with traditional goals resulting\nin the innovation of the lean and green approach.\n  In this study, a research methodology that includes system analysis and\nmodeling procedures to apply the lean and green concept, combined with a new\nevaluation metric, the Overall Environmental Equipment Effectiveness (OEEE) was\nused to investigate the effects of adopting lean and green practices on overall\nperformance.\n  A simulation model and energy value stream mapping were implemented, and the\nOEEE value was calculated to assess the current performance in terms of\nquality, availability, productivity, and sustainability. The current state\nproduction lead time was 329.1 minutes per batch, and the OEEE value was 13.1%.\nThis result indicates existing issues in performance and sustainability,\nsuggesting that improvement efforts should focus on enhancing these two aspects\nto increase the overall OEEE value.\n  Several improvement scenarios were proposed, including combining and\nrearranging the inspection workstations as the first scenario, and using UV\nlighting for drying purposes at the framing workstation as the second. After\napplying these improvements, both scenarios showed increased OEEE values and\nreduced lead times compared to the current state. In the first scenario, the\nlead time decreased to 158.23 minutes, and the OEEE increased to 35%. In the\nsecond scenario, the lead time was reduced to 292 minutes, with the OEEE\nincreasing to 24%.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4ee5Lean\u548cGreen\u7406\u5ff5\u7ed3\u5408OEEE\u65b0\u6307\u6807\u8bc4\u4f30\u4e0e\u6539\u8fdb\u4f01\u4e1a\u751f\u4ea7\u7ee9\u6548\u3002\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u5173\u63aa\u65bd\u80fd\u6709\u6548\u7f29\u77ed\u751f\u4ea7\u5468\u671f\u548c\u63d0\u5347\u53ef\u6301\u7eed\u8868\u73b0\uff0c\u5efa\u8bae\u805a\u7126\u76f8\u5173\u6539\u8fdb\u4ee5\u589e\u5f3a\u4f01\u4e1a\u7ade\u4e89\u4f18\u52bf\u3002", "motivation": "\u5168\u7403\u5e02\u573a\u9a71\u52a8\u548c\u5ba2\u6237\u9700\u6c42\u6301\u7eed\u53d8\u5316\uff0c\u4ee5\u76c8\u5229\u548c\u6548\u7387\u4e3a\u4e3b\u7684\u4f01\u4e1a\u76ee\u6807\u5df2\u4e0d\u8db3\u4ee5\u5e94\u5bf9\u7ade\u4e89\uff0c\u53ef\u6301\u7eed\u8868\u73b0\u6210\u4e3a\u65b0\u7684\u7ade\u4e89\u4f18\u52bf\uff0c\u4fc3\u4f7f\u4f01\u4e1a\u6574\u5408\u4f20\u7edf\u76ee\u6807\u4e0e\u7eff\u8272\u521b\u65b0\u3002", "method": "\u5e94\u7528\u7cfb\u7edf\u5206\u6790\u4e0e\u5efa\u6a21\uff0c\u7ed3\u5408\u4eff\u771f\u6a21\u62df\u548c\u80fd\u8017\u4ef7\u503c\u6d41\u56fe\uff0c\u8ba1\u7b97OEEE\u503c\u8861\u91cf\u8d28\u91cf\u3001\u53ef\u7528\u6027\u3001\u751f\u4ea7\u529b\u53ca\u53ef\u6301\u7eed\u6027\u3002\u63d0\u51fa\u5e76\u6a21\u62df\u4e24\u79cd\u6539\u8fdb\u65b9\u6848\uff0c\u8bc4\u4f30\u5176\u5bf9OEEE\u548c\u751f\u4ea7\u5468\u671f\u7684\u5f71\u54cd\u3002", "result": "\u73b0\u72b6\u4e0b\u751f\u4ea7\u5468\u671f\u4e3a329.1\u5206\u949f\uff0cOEEE\u4e3a13.1%\uff0c\u73af\u8282\u5b58\u5728\u8f83\u5927\u6539\u8fdb\u7a7a\u95f4\u3002\u6539\u8fdb\u4e00\uff08\u5408\u5e76\u3001\u91cd\u6392\u68c0\u6d4b\u5de5\u4f4d\uff09\u540e\uff0c\u5468\u671f\u964d\u81f3158.23\u5206\u949f\uff0cOEEE\u5347\u81f335%\uff1b\u6539\u8fdb\u4e8c\uff08\u4f7f\u7528\u7d2b\u5916\u7ebf\u70d8\u5e72\uff09\u540e\uff0c\u5468\u671f\u964d\u81f3292\u5206\u949f\uff0cOEEE\u5347\u81f324%\u3002\u4e24\u79cd\u65b9\u6848\u5747\u63d0\u5347\u4e86\u7ee9\u6548\u4e0e\u53ef\u6301\u7eed\u6027\u3002", "conclusion": "\u91c7\u7528Lean\u548cGreen\u65b9\u6cd5\u7ed3\u5408\u6574\u4f53\u73af\u5883\u8bbe\u5907\u6548\u80fd\uff08OEEE\uff09\u6307\u6807\uff0c\u6709\u52a9\u4e8e\u4f01\u4e1a\u63d0\u5347\u751f\u4ea7\u7ee9\u6548\u548c\u53ef\u6301\u7eed\u80fd\u529b\u3002\u9488\u5bf9\u73b0\u72b6\u7684\u6539\u8fdb\u63aa\u65bd\u80fd\u660e\u663e\u63d0\u9ad8OEEE\u503c\u548c\u7f29\u77ed\u751f\u4ea7\u5468\u671f\uff0c\u5efa\u8bae\u5c06\u7ba1\u7406\u548c\u6280\u672f\u521b\u65b0\u52aa\u529b\u96c6\u4e2d\u4e8e\u7ee9\u6548\u4e0e\u53ef\u6301\u7eed\u6027\u63d0\u5347\u3002"}}
{"id": "2506.17964", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.17964", "abs": "https://arxiv.org/abs/2506.17964", "authors": ["Bolin Shen", "Eren Erman Ozguven", "Yue Zhao", "Guang Wang", "Yiqun Xie", "Yushun Dong"], "title": "Learning from the Storm: A Multivariate Machine Learning Approach to Predicting Hurricane-Induced Economic Losses", "comment": null, "summary": "Florida is particularly vulnerable to hurricanes, which frequently cause\nsubstantial economic losses. While prior studies have explored specific\ncontributors to hurricane-induced damage, few have developed a unified\nframework capable of integrating a broader range of influencing factors to\ncomprehensively assess the sources of economic loss. In this study, we propose\na comprehensive modeling framework that categorizes contributing factors into\nthree key components: (1) hurricane characteristics, (2) water-related\nenvironmental factors, and (3) socioeconomic factors of affected areas. By\nintegrating multi-source data and aggregating all variables at the finer\nspatial granularity of the ZIP Code Tabulation Area (ZCTA) level, we employ\nmachine learning models to predict economic loss, using insurance claims as\nindicators of incurred damage. Beyond accurate loss prediction, our approach\nfacilitates a systematic assessment of the relative importance of each\ncomponent, providing practical guidance for disaster mitigation, risk\nassessment, and the development of adaptive urban strategies in coastal and\nstorm-exposed areas. Our code is now available at:\nhttps://github.com/LabRAI/Hurricane-Induced-Economic-Loss-Prediction", "AI": {"tldr": "\u672c\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u96c6\u6210\u98d3\u98ce\u7279\u5f81\u3001\u6c34\u73af\u5883\u548c\u793e\u4f1a\u7ecf\u6d4e\u8981\u7d20\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u5fae\u89c2\u7a7a\u95f4\u5c3a\u5ea6\u4e0a\u9884\u6d4b\u4f5b\u7f57\u91cc\u8fbe\u5dde\u98d3\u98ce\u7ecf\u6d4e\u635f\u5931\uff0c\u5e76\u80fd\u591f\u91cf\u5316\u5404\u9879\u56e0\u7d20\u7684\u91cd\u8981\u6027\uff0c\u52a9\u529b\u707e\u5bb3\u7ba1\u7406\u548c\u57ce\u5e02\u89c4\u5212\u3002", "motivation": "\u4f5b\u7f57\u91cc\u8fbe\u5dde\u7ecf\u5e38\u906d\u53d7\u98d3\u98ce\u88ad\u51fb\uff0c\u5bfc\u81f4\u5de8\u5927\u7ecf\u6d4e\u635f\u5931\u3002\u4ee5\u5f80\u7814\u7a76\u591a\u5173\u6ce8\u5177\u4f53\u539f\u56e0\uff0c\u4f46\u5f88\u5c11\u6709\u7edf\u4e00\u6846\u67b6\u80fd\u6574\u5408\u5404\u7c7b\u5f71\u54cd\u56e0\u7d20\uff0c\u5168\u9762\u8bc4\u4f30\u7ecf\u6d4e\u635f\u5931\u7684\u6765\u6e90\u3002\u8be5\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u6027\u5efa\u6a21\u6846\u67b6\uff0c\u5c06\u5f71\u54cd\u56e0\u7d20\u5206\u4e3a\u4e09\u7c7b\uff1a\uff081\uff09\u98d3\u98ce\u7279\u5f81\u3001\uff082\uff09\u4e0e\u6c34\u76f8\u5173\u7684\u73af\u5883\u56e0\u5b50\u3001\uff083\uff09\u53d7\u707e\u5730\u533a\u7684\u793e\u4f1a\u7ecf\u6d4e\u56e0\u7d20\u3002\u6574\u5408\u591a\u6e90\u6570\u636e\uff0c\u5e76\u5c06\u6240\u6709\u53d8\u91cf\u805a\u5408\u5230\u66f4\u7ec6\u81f4\u7684ZCTA\uff08\u90ae\u653f\u7f16\u7801\u533a\u57df\uff09\u7a7a\u95f4\u5c3a\u5ea6\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ee5\u4fdd\u9669\u7406\u8d54\u4f5c\u4e3a\u7ecf\u6d4e\u635f\u5931\u6307\u6807\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u6846\u67b6\u80fd\u51c6\u786e\u9884\u6d4b\u7ecf\u6d4e\u635f\u5931\uff0c\u5e76\u7cfb\u7edf\u8bc4\u4f30\u5404\u56e0\u7d20\u7684\u91cd\u8981\u6027\u3002\u4e3a\u707e\u5bb3\u7f13\u89e3\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u6d77\u5cb8\u53ca\u66b4\u98ce\u533a\u57ce\u5e02\u9002\u5e94\u6027\u7b56\u7565\u7684\u5236\u5b9a\u63d0\u4f9b\u4e86\u5b9e\u9645\u6307\u5bfc\u3002\u76f8\u5173\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "conclusion": "\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2a\u6574\u5408\u591a\u7ef4\u5ea6\u56e0\u7d20\u7684\u98d3\u98ce\u7ecf\u6d4e\u635f\u5931\u9884\u6d4b\u6846\u67b6\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u5206\u6790\u5168\u9762\u6027\u548c\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5bf9\u5b9e\u9645\u707e\u5bb3\u7ba1\u7406\u6709\u91cd\u8981\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2506.17294", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17294", "abs": "https://arxiv.org/abs/2506.17294", "authors": ["Qirui Zheng", "Xingbo Wang", "Keyuan Cheng", "Yunlong Lu", "Wenxin Li"], "title": "AI-Generated Game Commentary: A Survey and a Datasheet Repository", "comment": null, "summary": "AI-Generated Game Commentary (AIGGC) has gained increasing attention due to\nits market potential and inherent technical challenges. As a comprehensive\nmultimodal Natural Language Processing (NLP) task, AIGGC imposes substantial\ndemands on language models, including factual accuracy, logical reasoning,\nexpressive text generation, generation speed, and context management. In this\npaper, we introduce a general framework for AIGGC and present a comprehensive\nsurvey of 45 existing game commentary dataset and methods according to key\nchallenges they aim to address in this domain. We further classify and compare\nvarious evaluation metrics commonly used in this domain. To support future\nresearch and benchmarking, we also provide a structured datasheet summarizing\nthe essential attributes of these datasets in appendix, which is meanwhile\npublicly available in an open repository.", "AI": {"tldr": "\u672c\u6587\u5bf9AI\u751f\u6210\u6e38\u620f\u89e3\u8bf4\u7684\u4efb\u52a1\u3001\u6311\u6218\u3001\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u901a\u7528\u6846\u67b6\uff0c\u5e76\u5f00\u6e90\u7ed3\u6784\u5316\u6570\u636e\u8868\uff0c\u4fc3\u8fdb\u8be5\u9886\u57df\u7814\u7a76\u548c\u53d1\u5c55\u3002", "motivation": "AI\u751f\u6210\u7684\u6e38\u620f\u89e3\u8bf4\uff08AIGGC\uff09\u56e0\u5176\u5e02\u573a\u6f5c\u529b\u548c\u6280\u672f\u6311\u6218\u9010\u6e10\u53d7\u5230\u5173\u6ce8\u3002\u9488\u5bf9AIGGC\u6d89\u53ca\u591a\u6a21\u6001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\uff0c\u5bf9\u8bed\u8a00\u6a21\u578b\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684AIGGC\u6846\u67b6\uff0c\u5e76\u5bf945\u4e2a\u73b0\u6709\u7684\u6e38\u620f\u89e3\u8bf4\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u8c03\u7814\uff0c\u6839\u636e\u5b83\u4eec\u6240\u5e94\u5bf9\u7684\u4e3b\u8981\u6311\u6218\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u5bf9\u5e38\u7528\u7684\u8bc4\u4f30\u6307\u6807\u8fdb\u884c\u5f52\u7c7b\u548c\u6bd4\u8f83\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u6574\u7406\u4e86\u6570\u636e\u96c6\u7684\u7ed3\u6784\u5316\u4fe1\u606f\uff0c\u5e76\u5728\u9644\u5f55\u53ca\u5f00\u6e90\u5e93\u4e2d\u63d0\u4f9b\u3002", "result": "\u7cfb\u7edf\u6027\u603b\u7ed3\u4e86\u73b0\u6709AIGGC\u6570\u636e\u96c6\u3001\u65b9\u6cd5\u53ca\u8bc4\u4f30\u6307\u6807\uff0c\u5bf9\u9886\u57df\u5185\u4e3b\u8981\u6311\u6218\u4f5c\u4e86\u68b3\u7406\u548c\u5f52\u7c7b\uff0c\u5e76\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u5f00\u6e90\u6570\u636e\u8d44\u6e90\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3aAIGGC\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u73b0\u72b6\u68b3\u7406\u548c\u5f00\u653e\u6570\u636e\u652f\u6301\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u548c\u8bc4\u6d4b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.17442", "categories": ["cs.AI", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17442", "abs": "https://arxiv.org/abs/2506.17442", "authors": ["Hao Guan", "David Bates", "Li Zhou"], "title": "Keeping Medical AI Healthy: A Review of Detection and Correction Methods for System Degradation", "comment": "15 pages, 5 figures", "summary": "Artificial intelligence (AI) is increasingly integrated into modern\nhealthcare, offering powerful support for clinical decision-making. However, in\nreal-world settings, AI systems may experience performance degradation over\ntime, due to factors such as shifting data distributions, changes in patient\ncharacteristics, evolving clinical protocols, and variations in data quality.\nThese factors can compromise model reliability, posing safety concerns and\nincreasing the likelihood of inaccurate predictions or adverse outcomes. This\nreview presents a forward-looking perspective on monitoring and maintaining the\n\"health\" of AI systems in healthcare. We highlight the urgent need for\ncontinuous performance monitoring, early degradation detection, and effective\nself-correction mechanisms. The paper begins by reviewing common causes of\nperformance degradation at both data and model levels. We then summarize key\ntechniques for detecting data and model drift, followed by an in-depth look at\nroot cause analysis. Correction strategies are further reviewed, ranging from\nmodel retraining to test-time adaptation. Our survey spans both traditional\nmachine learning models and state-of-the-art large language models (LLMs),\noffering insights into their strengths and limitations. Finally, we discuss\nongoing technical challenges and propose future research directions. This work\naims to guide the development of reliable, robust medical AI systems capable of\nsustaining safe, long-term deployment in dynamic clinical settings.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u533b\u7597AI\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u56e0\u591a\u79cd\u56e0\u7d20\u5bfc\u81f4\u6027\u80fd\u9000\u5316\u7684\u95ee\u9898\uff0c\u7cfb\u7edf\u603b\u7ed3\u4e86\u76d1\u63a7\u3001\u68c0\u6d4b\u3001\u5206\u6790\u53ca\u7ea0\u6b63\u9000\u5316\u7684\u6280\u672f\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\uff0c\u65e8\u5728\u63a8\u52a8\u533b\u7597AI\u7cfb\u7edf\u7684\u957f\u671f\u5b89\u5168\u548c\u53ef\u9760\u5e94\u7528\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u5728\u73b0\u4ee3\u533b\u7597\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5728\u5b9e\u9645\u73af\u5883\u4e0b\uff0c\u968f\u7740\u6570\u636e\u5206\u5e03\u3001\u60a3\u8005\u7279\u5f81\u3001\u4e34\u5e8a\u534f\u8bae\u4ee5\u53ca\u6570\u636e\u8d28\u91cf\u7684\u6301\u7eed\u53d8\u5316\uff0cAI\u7cfb\u7edf\u7684\u6027\u80fd\u53ef\u80fd\u968f\u7740\u65f6\u95f4\u63a8\u79fb\u800c\u4e0b\u964d\u3002\u8fd9\u79cd\u9000\u5316\u5e26\u6765\u4e86\u6a21\u578b\u53ef\u9760\u6027\u53ca\u60a3\u8005\u5b89\u5168\u6027\u98ce\u9669\uff0c\u56e0\u6b64\u8feb\u5207\u9700\u8981\u76d1\u63a7\u548c\u7ef4\u62a4AI\u7cfb\u7edf\u7684\u201c\u5065\u5eb7\u201d\u3002", "method": "\u672c\u7efc\u8ff0\u7cfb\u7edf\u603b\u7ed3\u4e86AI\u6027\u80fd\u9000\u5316\u7684\u5e38\u89c1\u539f\u56e0\uff0c\u68b3\u7406\u4e86\u6570\u636e\u548c\u6a21\u578b\u6f02\u79fb\u7684\u68c0\u6d4b\u6280\u672f\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u6839\u672c\u539f\u56e0\u5206\u6790\uff0c\u5e76\u5ba1\u67e5\u4e86\u5305\u62ec\u6a21\u578b\u518d\u8bad\u7ec3\u3001\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u5728\u5185\u7684\u7ea0\u6b63\u65b9\u6848\uff0c\u6db5\u76d6\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u5e76\u8ba8\u8bba\u4e86\u5f53\u524d\u6280\u672f\u6311\u6218\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "result": "\u672c\u6587\u5f52\u7eb3\u4e86\u68c0\u6d4b\u548c\u7ea0\u6b63\u533b\u7597AI\u7cfb\u7edf\u9000\u5316\u7684\u73b0\u6709\u65b9\u6cd5\u53ca\u5404\u81ea\u7684\u4f18\u7f3a\u70b9\uff0c\u63d0\u51fa\u4e86\u5c1a\u5f85\u89e3\u51b3\u7684\u6280\u672f\u96be\u9898\u53ca\u672a\u6765\u7684\u7814\u7a76\u91cd\u70b9\uff0c\u4e3a\u6301\u7eed\u53ef\u9760\u90e8\u7f72\u533b\u7597AI\u63d0\u51fa\u4e86\u5efa\u8bbe\u6027\u5efa\u8bae\u3002", "conclusion": "\u672c\u7efc\u8ff0\u4e3a\u533b\u7597AI\u7cfb\u7edf\u7684\u6301\u7eed\u3001\u53ef\u9760\u548c\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u6307\u5bfc\uff0c\u5bf9\u672a\u6765\u533b\u7597AI\u7684\u76d1\u63a7\u4e0e\u81ea\u7ea0\u673a\u5236\u7814\u7a76\u5177\u6709\u91cd\u8981\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2506.17355", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17355", "abs": "https://arxiv.org/abs/2506.17355", "authors": ["Jesse McDonald", "Scott Robertson", "Anthony Peruma"], "title": "PasteTrace: A Single Source Plagiarism Detection Tool For Introductory Programming Courses", "comment": null, "summary": "Introductory Computer Science classes are important for laying the foundation\nfor advanced programming courses. However, students without prior programming\nexperience may find these courses challenging, leading to difficulties in\nunderstanding concepts and engaging in academic dishonesty such as plagiarism.\nWhile there exists plagiarism detection techniques and tools, not all of them\nare suitable for academic settings, especially in introductory programming\ncourses. This paper introduces PasteTrace, a novel open-source plagiarism\ndetection tool designed specifically for introductory programming courses.\nUnlike traditional methods, PasteTrace operates within an Integrated\nDevelopment Environment that tracks the student's coding activities in\nreal-time for evidence of plagiarism. Our evaluation of PasteTrace in two\nintroductory programming courses demonstrates the tool's ability to provide\ninsights into student behavior and detect various forms of plagiarism,\noutperforming an existing well-established tool.\n  A video demonstration of PasteTrace and its source code, and case study data\nare made available at https://doi.org/10.6084/m9.figshare.27115852", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86PasteTrace\uff1a\u4e00\u6b3e\u53ef\u5728IDE\u5185\u5b9e\u65f6\u68c0\u6d4b\u521d\u5b66\u8005\u7f16\u7a0b\u8bfe\u7a0b\u6284\u88ad\u7684\u65b0\u5de5\u5177\uff0c\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u521d\u5b66\u8005\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u5165\u95e8\u8bfe\u7a0b\u4e2d\uff0c\u56e0\u7f3a\u4e4f\u7f16\u7a0b\u7ecf\u9a8c\uff0c\u5e38\u5bf9\u8bfe\u7a0b\u5185\u5bb9\u611f\u5230\u5403\u529b\uff0c\u5e76\u53ef\u80fd\u56e0\u96be\u4ee5\u7406\u89e3\u5bfc\u81f4\u5b66\u672f\u4e0d\u7aef\u884c\u4e3a\uff08\u5982\u6284\u88ad\uff09\u3002\u73b0\u6709\u6284\u88ad\u68c0\u6d4b\u5de5\u5177\u4e0d\u5b8c\u5168\u9002\u5408\u5165\u95e8\u7f16\u7a0b\u6559\u5b66\u60c5\u5883\u3002", "method": "\u63d0\u51fa\u4e86PasteTrace\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u4e3a\u7f16\u7a0b\u5165\u95e8\u8bfe\u7a0b\u8bbe\u8ba1\u7684\u5f00\u6e90\u6284\u88ad\u68c0\u6d4b\u5de5\u5177\uff0c\u5b83\u80fd\u5728IDE\u5185\u5b9e\u65f6\u8ddf\u8e2a\u5b66\u751f\u7684\u7f16\u7a0b\u6d3b\u52a8\uff0c\u4ee5\u53d1\u73b0\u6f5c\u5728\u7684\u6284\u88ad\u884c\u4e3a\u3002\u4f5c\u8005\u8fd8\u5c06PasteTrace\u4e0e\u73b0\u6709\u5de5\u5177\u8fdb\u884c\u4e86\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "PasteTrace\u80fd\u63d0\u4f9b\u5b66\u751f\u884c\u4e3a\u7684\u6d1e\u89c1\uff0c\u5e76\u80fd\u68c0\u6d4b\u591a\u79cd\u6284\u88ad\u7c7b\u578b\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u5de5\u5177\u5728\u4e24\u95e8\u5165\u95e8\u8bfe\u7a0b\u4e2d\u4f18\u4e8e\u73b0\u6709\u77e5\u540d\u5de5\u5177\u3002", "conclusion": "PasteTrace\u4e3a\u521d\u7ea7\u7f16\u7a0b\u8bfe\u7a0b\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u6284\u88ad\u68c0\u6d4b\u65b9\u5f0f\uff0c\u6709\u52a9\u4e8e\u7ef4\u62a4\u5b66\u672f\u8bda\u4fe1\u5e76\u5e2e\u52a9\u6559\u5e08\u7406\u89e3\u5b66\u751f\u5b66\u4e60\u884c\u4e3a\u3002"}}
{"id": "2506.18161", "categories": ["cs.CE", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2506.18161", "abs": "https://arxiv.org/abs/2506.18161", "authors": ["Y. Navidtehrani", "C. Beteg\u00f3n", "J. Vallejos", "E. Mart\u00ednez-Pa\u00f1eda"], "title": "A phase field model for hydraulic fracture: Drucker-Prager driving force and a hybrid coupling strategy", "comment": null, "summary": "Recent years have seen a significant interest in using phase field approaches\nto model hydraulic fracture, so as to optimise a process that is key to\nindustries such as petroleum engineering, mining and geothermal energy\nextraction. Here, we present a novel theoretical and computational phase field\nframework to simulate hydraulic fracture. The framework is general and\nversatile, in that it allows for improved treatments of the coupling between\nfluid flow and the phase field, and encompasses a universal description of the\nfracture driving force. Among others, this allows us to bring two innovations\nto the phase field hydraulic fracture community: (i) a new hybrid coupling\napproach to handle the fracture-fluid flow interplay, offering enhanced\naccuracy and flexibility; and (ii) a Drucker-Prager-based strain energy\ndecomposition, extending the simulation of hydraulic fracture to materials\nexhibiting asymmetric tension-compression fracture behaviour (such as shale\nrocks) and enabling the prediction of geomechanical phenomena such as fault\nreactivation and stick-slip behaviour. Four case studies are addressed to\nillustrate these additional modelling capabilities and bring insight into\npermeability coupling, cracking behaviour, and multiaxial conditions in\nhydraulic fracturing simulations. The codes developed are made freely available\nto the community and can be downloaded from {https://mechmat.web.ox.ac.uk/", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u578b\u901a\u7528\u7684\u76f8\u573a\u6c34\u529b\u538b\u88c2\u6a21\u62df\u6846\u67b6\uff0c\u521b\u65b0\u6027\u5904\u7406\u6d41\u4f53-\u88c2\u7eb9\u8026\u5408\u4e0e\u7279\u6b8a\u6750\u6599\u65ad\u88c2\uff0c\u663e\u8457\u62d3\u5c55\u5b9e\u9645\u5de5\u7a0b\u5e94\u7528\u8303\u56f4\uff0c\u5e76\u5f00\u6e90\u4e86\u76f8\u5173\u4ee3\u7801\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u5229\u7528\u76f8\u573a\u65b9\u6cd5\u6a21\u62df\u6c34\u529b\u538b\u88c2\u53d7\u5230\u6781\u5927\u5173\u6ce8\uff0c\u65e8\u5728\u4f18\u5316\u5173\u952e\u5de5\u4e1a\u8fc7\u7a0b\uff08\u5982\u77f3\u6cb9\u5de5\u7a0b\u3001\u91c7\u77ff\u548c\u5730\u70ed\u80fd\u63d0\u53d6\uff09\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6db2\u4f53\u6d41\u52a8\u4e0e\u76f8\u573a\u8026\u5408\u3001\u65ad\u88c2\u9a71\u52a8\u529b\u63cf\u8ff0\u7b49\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7406\u8bba\u4e0e\u8ba1\u7b97\u76f8\u573a\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u6db2\u4f53\u6d41\u52a8\u4e0e\u76f8\u573a\u7684\u8026\u5408\uff0c\u5e76\u666e\u9002\u6027\u5730\u63cf\u8ff0\u65ad\u88c2\u9a71\u52a8\u529b\u3002\u5305\u62ec\uff1a1\uff09\u521b\u65b0\u6027\u7684\u6df7\u5408\u8026\u5408\u65b9\u6cd5\uff0c\u63d0\u5347\u88c2\u7f1d-\u6db2\u4f53\u6d41\u76f8\u4e92\u4f5c\u7528\u7684\u7cbe\u5ea6\u4e0e\u7075\u6d3b\u6027\uff1b2\uff09\u57fa\u4e8eDrucker-Prager\u51c6\u5219\u7684\u5e94\u53d8\u80fd\u5206\u89e3\uff0c\u6269\u5c55\u5230\u80fd\u6a21\u62df\u62c9\u538b\u4e0d\u5bf9\u79f0\u65ad\u88c2\u7279\u6027\u7684\u6750\u6599\u5982\u9875\u5ca9\uff0c\u5e76\u9884\u6d4b\u65ad\u5c42\u6fc0\u6d3b\u548c\u7c98\u6ed1\u884c\u4e3a\u3002", "result": "\u901a\u8fc7\u56db\u4e2a\u6848\u4f8b\u5206\u6790\u5c55\u793a\u8be5\u6846\u67b6\u7684\u65b0\u5efa\u6a21\u80fd\u529b\uff0c\u6db5\u76d6\u6e17\u900f\u7387\u8026\u5408\u3001\u88c2\u7eb9\u884c\u4e3a\u53ca\u591a\u8f74\u5de5\u51b5\u4e0b\u7684\u6c34\u529b\u538b\u88c2\u6a21\u62df\u3002\u76f8\u5173\u4ee3\u7801\u5df2\u5f00\u6e90\u5e76\u5bf9\u5916\u53d1\u5e03\u3002", "conclusion": "\u63d0\u51fa\u7684\u901a\u7528\u76f8\u573a\u65b9\u6cd5\u62d3\u5c55\u4e86\u6c34\u529b\u538b\u88c2\u6a21\u62df\u7684\u6750\u6599\u548c\u7269\u7406\u8303\u56f4\uff0c\u5e76\u4e3a\u76f8\u5173\u5de5\u7a0b\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u5efa\u6a21\u548c\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2506.17296", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17296", "abs": "https://arxiv.org/abs/2506.17296", "authors": ["Darius Foodeei", "Simin Fan", "Martin Jaggi"], "title": "Semantic uncertainty in advanced decoding methods for LLM generation", "comment": null, "summary": "This study investigates semantic uncertainty in large language model (LLM)\noutputs across different decoding methods, focusing on emerging techniques like\nspeculative sampling and chain-of-thought (CoT) decoding. Through experiments\non question answering, summarization, and code generation tasks, we analyze how\ndifferent decoding strategies affect both the diversity and reliability of\nmodel outputs. Our findings reveal that while CoT decoding demonstrates higher\nsemantic diversity, it maintains lower predictive entropy, suggesting that\nstructured exploration can lead to more confident and accurate outputs. This is\nevidenced by a 48.8% improvement in code generation Pass@2 rates, despite lower\nalignment with reference solutions. For summarization tasks, speculative\nsampling proved particularly effective, achieving superior ROUGE scores while\nmaintaining moderate semantic diversity. Our results challenge conventional\nassumptions about trade-offs between diversity and accuracy in language model\noutputs, demonstrating that properly structured decoding methods can increase\nsemantic exploration while maintaining or improving output quality. These\nfindings have significant implications for deploying language models in\npractical applications where both reliability and diverse solution generation\nare crucial.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165\u65b0\u578b\u89e3\u7801\u65b9\u6cd5\uff08CoT\u4e0e\u63a8\u6d4b\u91c7\u6837\uff09\uff0c\u8bba\u6587\u53d1\u73b0LLM\u8f93\u51fa\u591a\u6837\u6027\u548c\u51c6\u786e\u6027\u53ef\u517c\u5f97\uff0c\u7ed3\u6784\u5316\u63a2\u7d22\u663e\u8457\u63d0\u5347\u8f93\u51fa\u8d28\u91cf\uff0c\u5bf9\u5b9e\u9645\u5e94\u7528\u6709\u91cd\u8981\u6307\u5bfc\u4ef7\u503c\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8f93\u51fa\u53d7\u89e3\u7801\u7b56\u7565\u5f71\u54cd\u663e\u8457\uff0c\u4f46\u4e0d\u540c\u7b56\u7565\u4e0b\u8bed\u4e49\u591a\u6837\u6027\u4e0e\u53ef\u9760\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u5c1a\u4e0d\u660e\u786e\u3002\u7814\u7a76\u8005\u671f\u671b\u901a\u8fc7\u65b0\u5174\u7684\u91c7\u6837\u65b9\u6cd5\u4e0e\u601d\u7ef4\u94fe\uff08Chain-of-Thought, CoT\uff09\u89e3\u7801\u5206\u6790\uff0c\u63a2\u7d22\u7ed3\u6784\u5316\u63a2\u7d22\u5bf9\u8f93\u51fa\u8d28\u91cf\u548c\u81ea\u4fe1\u5ea6\u7684\u5f71\u54cd\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u66f4\u4f18\u89e3\u7801\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u591a\u9879\u5b9e\u9a8c\uff0c\u6db5\u76d6\u95ee\u7b54\u3001\u6458\u8981\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u5bf9\u6bd4\u5206\u6790\u5e38\u89c4\u4e0e\u65b0\u578b\uff08\u5982\u63a8\u6d4b\u91c7\u6837\u3001\u601d\u7ef4\u94fe\u89e3\u7801\uff09\u89e3\u7801\u65b9\u6cd5\u4e0bLLM\u8f93\u51fa\u7684\u8bed\u4e49\u591a\u6837\u6027\u4e0e\u53ef\u9760\u6027\u3002\u901a\u8fc7\u8bc4\u4f30\u4e0d\u540c\u6307\u6807\uff08\u5982\u9884\u6d4b\u71b5\u3001Pass@2\u3001ROUGE\u5206\u6570\u7b49\uff09\u91cf\u5316\u5404\u7b56\u7565\u6548\u679c\u3002", "result": "\u601d\u7ef4\u94fe\u89e3\u7801\u80fd\u63d0\u5347\u8f93\u51fa\u8bed\u4e49\u591a\u6837\u6027\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u9884\u6d4b\u71b5\uff0c\u5b9e\u73b0\u66f4\u81ea\u4fe1\u3001\u66f4\u51c6\u786e\u8f93\u51fa\u3002\u4f8b\u5982\uff0c\u4ee3\u7801\u751f\u6210\u4efb\u52a1Pass@2\u63d0\u534748.8%\uff0c\u5c3d\u7ba1\u4e0e\u53c2\u8003\u7b54\u6848\u4e00\u81f4\u6027\u7565\u964d\u3002\u6458\u8981\u4efb\u52a1\u4e2d\u63a8\u6d4b\u91c7\u6837ROUGE\u5206\u6570\u4ea6\u4f18\uff0c\u6574\u4f53\u8868\u73b0\u51fa\u8f83\u4f18\u8bed\u4e49\u591a\u6837\u6027\u548c\u51c6\u786e\u6027\u7684\u6743\u8861\u3002", "conclusion": "\u7ed3\u6784\u5316\u89e3\u7801\u7b56\u7565\u4e0d\u4ec5\u80fd\u589e\u52a0\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u8bed\u4e49\u63a2\u7d22\u8303\u56f4\uff0c\u8fd8\u80fd\u5728\u4fdd\u8bc1\u751a\u81f3\u63d0\u5347\u8f93\u51fa\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\uff0c\u7f13\u89e3\u4f20\u7edf\u8ba4\u4e3a\u591a\u6837\u6027\u4e0e\u51c6\u786e\u6027\u4e92\u76f8\u5236\u7ea6\u7684\u89c2\u5ff5\u3002\u8be5\u7ed3\u8bba\u5bf9\u5b9e\u9645\u90e8\u7f72LLM\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.17449", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17449", "abs": "https://arxiv.org/abs/2506.17449", "authors": ["Manasa Bharadwaj", "Nikhil Verma", "Kevin Ferreira"], "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "comment": null, "summary": "Efforts to improve Large Language Model (LLM) agent performance on complex\ntasks have largely focused on fine-tuning and iterative self-correction.\nHowever, these approaches often lack generalizable mechanisms for longterm\nlearning and remain inefficient in dynamic environments. We introduce\nOmniReflect, a hierarchical, reflection-driven framework that constructs a\nconstitution, a compact set of guiding principles distilled from task\nexperiences, to enhance the effectiveness and efficiency of an LLM agent.\nOmniReflect operates in two modes: Self-sustaining, where a single agent\nperiodically curates its own reflections during task execution, and\nCo-operative, where a Meta-advisor derives a constitution from a small\ncalibration set to guide another agent. To construct these constitutional\nprinciples, we employ Neural, Symbolic, and NeuroSymbolic techniques, offering\na balance between contextual adaptability and computational efficiency.\nEmpirical results averaged across models show major improvements in task\nsuccess, with absolute gains of +10.3% on ALFWorld, +23.8% on BabyAI, and +8.3%\non PDDL in the Self-sustaining mode. Similar gains are seen in the Co-operative\nmode, where a lightweight Qwen3-4B ReAct agent outperforms all Reflexion\nbaselines on BabyAI. These findings highlight the robustness and effectiveness\nof OmniReflect across environments and backbones.", "AI": {"tldr": "OmniReflect\u901a\u8fc7\u5206\u5c42\u53cd\u601d\u548c\u77e5\u8bc6\u79ef\u7d2f\u673a\u5236\uff0c\u4e3aLLM\u4ee3\u7406\u5f15\u5165\u4e86\u9ad8\u6548\u3001\u53ef\u8fc1\u79fb\u7684\u4efb\u52a1\u8868\u73b0\u63d0\u5347\u8def\u5f84\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u591a\u4e2a\u590d\u6742\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\u3002", "motivation": "\u4ee5\u5f80\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4e3b\u8981\u4f9d\u8d56\u5fae\u8c03\u548c\u81ea\u6211\u7ea0\u9519\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e0b\u7f3a\u4e4f\u901a\u7528\u7684\u957f\u671f\u5b66\u4e60\u673a\u5236\uff0c\u6548\u7387\u4e5f\u4e0d\u9ad8\u3002\u56e0\u6b64\uff0c\u5bfb\u6c42\u4e00\u79cd\u9ad8\u6548\u4e14\u5177\u53ef\u8fc1\u79fb\u6027\u7684\u5b66\u4e60\u673a\u5236\u3002", "method": "\u63d0\u51faOmniReflect\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u5206\u5c42\u3001\u53cd\u601d\u9a71\u52a8\u7684\u7ed3\u6784\uff0c\u901a\u8fc7\u6784\u5efa\u5baa\u6cd5\uff08\u4ece\u4efb\u52a1\u7ecf\u9a8c\u4e2d\u63d0\u70bc\u7684\u6307\u5bfc\u539f\u5219\uff09\u6765\u63d0\u5347LLM\u4ee3\u7406\u7684\u8868\u73b0\u3002OmniReflect\u5305\u62ec\u81ea\u6211\u7ef4\u6301\u6a21\u5f0f\uff08\u5355\u4e00\u4ee3\u7406\u5728\u4efb\u52a1\u6267\u884c\u4e2d\u5b9a\u671f\u603b\u7ed3\u53cd\u601d\uff09\u548c\u534f\u4f5c\u6a21\u5f0f\uff08\u5143\u987e\u95ee\u6839\u636e\u6821\u51c6\u96c6\u4e3a\u4ee3\u7406\u5236\u5b9a\u5baa\u6cd5\uff09\u3002\u5baa\u6cd5\u7684\u6784\u5efa\u91c7\u7528\u795e\u7ecf\u3001\u7b26\u53f7\u3001\u795e\u7ecf-\u7b26\u53f7\u7b49\u591a\u79cd\u6280\u672f\uff0c\u517c\u987e\u4e0a\u4e0b\u6587\u9002\u5e94\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u81ea\u6211\u7ef4\u6301\u6a21\u5f0f\u4e0b\uff0cOmniReflect\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6210\u529f\u7387\uff1aALFWorld\u63d0\u5347+10.3%\uff0cBabyAI\u63d0\u5347+23.8%\uff0cPDDL\u63d0\u5347+8.3%\u3002\u5728\u534f\u4f5c\u6a21\u5f0f\u4e0b\uff0c\u8f7b\u91cfQwen3-4B ReAct\u4ee3\u7406\u5168\u9762\u4f18\u4e8eReflexion\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "OmniReflect\u6846\u67b6\u5728\u4e0d\u540c\u73af\u5883\u548c\u6a21\u578b\u57fa\u7840\u4e0a\u90fd\u5c55\u73b0\u4e86\u826f\u597d\u7684\u7a33\u5065\u6027\u548c\u6709\u6548\u6027\uff0c\u662f\u63d0\u5347LLM\u667a\u80fd\u4f53\u957f\u671f\u8868\u73b0\u7684\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2506.17356", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.17356", "abs": "https://arxiv.org/abs/2506.17356", "authors": ["Jionghao Lin", "Jiarui Rao", "Yiyang Zhao", "Yuting Wang", "Ashish Gurung", "Amanda Barany", "Jaclyn Ocumpaugh", "Ryan S. Baker", "Kenneth R. Koedinger"], "title": "Automatic Large Language Models Creation of Interactive Learning Lessons", "comment": "Full Research Paper, 15 pages, In Proceedings of 20th European\n  Conference on Technology Enhanced Learning (ECTEL2025)", "summary": "We explore the automatic generation of interactive, scenario-based lessons\ndesigned to train novice human tutors who teach middle school mathematics\nonline. Employing prompt engineering through a Retrieval-Augmented Generation\napproach with GPT-4o, we developed a system capable of creating structured\ntutor training lessons. Our study generated lessons in English for three key\ntopics: Encouraging Students' Independence, Encouraging Help-Seeking Behavior,\nand Turning on Cameras, using a task decomposition prompting strategy that\nbreaks lesson generation into sub-tasks. The generated lessons were evaluated\nby two human evaluators, who provided both quantitative and qualitative\nevaluations using a comprehensive rubric informed by lesson design research.\nResults demonstrate that the task decomposition strategy led to higher-rated\nlessons compared to single-step generation. Human evaluators identified several\nstrengths in the LLM-generated lessons, including well-structured content and\ntime-saving potential, while also noting limitations such as generic feedback\nand a lack of clarity in some instructional sections. These findings underscore\nthe potential of hybrid human-AI approaches for generating effective lessons in\ntutor training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u57fa\u4e8eGPT-4o\u548c\u4efb\u52a1\u5206\u89e3\u7684\u8bfe\u7a0b\u81ea\u52a8\u751f\u6210\u7cfb\u7edf\uff0c\u53ef\u6709\u6548\u4ea7\u51fa\u7528\u4e8e\u5bfc\u5e08\u57f9\u8bad\u7684\u9ad8\u8d28\u91cf\u8bfe\u7a0b\u3002", "motivation": "\u63d0\u5347\u521d\u5b66\u8005\u7ebf\u4e0a\u6570\u5b66\u6559\u5b66\u80fd\u529b\uff0c\u81ea\u52a8\u5316\u751f\u6210\u4e92\u52a8\u573a\u666f\u5f0f\u57f9\u8bad\u8bfe\u7a0b\u4ee5\u964d\u4f4e\u6210\u672c\u3001\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u91c7\u7528\u57fa\u4e8eGPT-4o\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\uff08task decomposition\uff09\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u81ea\u52a8\u751f\u6210\u7ed3\u6784\u5316\u7684\u5bfc\u5e08\u57f9\u8bad\u8bfe\u7a0b\uff0c\u5e76\u7531\u4e24\u4f4d\u4eba\u5de5\u8bc4\u5ba1\u7ed3\u5408\u5b9a\u91cf\u548c\u5b9a\u6027\u6307\u6807\u8fdb\u884c\u8bc4\u4ef7\u3002", "result": "\u91c7\u7528\u4efb\u52a1\u5206\u89e3\u7b56\u7565\u751f\u6210\u7684\u8bfe\u7a0b\u8d28\u91cf\u4f18\u4e8e\u5355\u6b65\u751f\u6210\uff1b\u8bfe\u7a0b\u7ed3\u6784\u5408\u7406\uff0c\u8282\u7701\u51c6\u5907\u65f6\u95f4\uff0c\u4f46\u5b58\u5728\u53cd\u9988\u5185\u5bb9\u6cdb\u5316\u548c\u5c40\u90e8\u6559\u5b66\u73af\u8282\u4e0d\u6e05\u6670\u7684\u4e0d\u8db3\u3002", "conclusion": "\u4efb\u52a1\u5206\u89e3\u548c\u4eba\u673a\u534f\u4f5c\u751f\u6210\u7684\u8bfe\u7a0b\u5728\u5bfc\u5e08\u57f9\u8bad\u4e2d\u5177\u6709\u8f83\u5927\u5e94\u7528\u6f5c\u529b\uff0c\u672a\u6765\u5e94\u8fdb\u4e00\u6b65\u4f18\u5316\u53cd\u9988\u548c\u7ec6\u8282\u6e05\u6670\u5ea6\u3002"}}
{"id": "2506.18175", "categories": ["cs.CE", "math.DS", "28A80 (Primary), 37N10 (Secondary)", "J.2; E.1"], "pdf": "https://arxiv.org/pdf/2506.18175", "abs": "https://arxiv.org/abs/2506.18175", "authors": ["Pramit Ghosh"], "title": "Measuring Fractal Dimension using Discrete Global Grid Systems", "comment": null, "summary": "This study builds a bridge between two well-studied but distant topics:\nfractal dimension and Discrete Global Grid System (DGGS). DGGSs are used as\ncovering sets for geospatial vector data to calculate the Minkowski-Bouligand\ndimension. Using the method on synthetic data yields results within 1% of their\ntheoretical fractal dimensions. A case study on opaque cloud fields obtained\nfrom satellite images gives fractal dimension in agreement with that available\nin the literature. The proposed method alleviates the problems of arbitrary\ngrid placement and orientation, as well as the progression of cell sizes of the\ncovering sets for geospatial data. Using DGGSs further ensure that\nintersections of the covering sets with the geospatial vector having large\ngeographic extents are calculated by taking the curvature of the earth into\naccount. This paper establishes the validity of DGGSs as covering sets\ntheoretically and discusses desirable properties of DGGSs suitable for this\npurpose.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528DGGS\u8ba1\u7b97\u5730\u7406\u7a7a\u95f4\u77e2\u91cf\u6570\u636e\u7684\u5206\u5f62\u7ef4\u6570\uff0c\u6709\u6548\u6d88\u9664\u4e86\u4f20\u7edf\u7f51\u683c\u8986\u76d6\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5b9e\u9a8c\u4e0e\u7406\u8bba\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u5730\u7406\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u5206\u5f62\u7ef4\u6570\u548c\u79bb\u6563\u5168\u7403\u7f51\u683c\u7cfb\u7edf\uff08DGGS\uff09\u662f\u5730\u7406\u4fe1\u606f\u79d1\u5b66\u4e2d\u7684\u4e24\u4e2a\u91cd\u8981\u4f46\u5f7c\u6b64\u5173\u8054\u8f83\u5c11\u7684\u9886\u57df\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5c06DGGS\u7528\u4f5c\u5730\u7406\u77e2\u91cf\u6570\u636e\u8ba1\u7b97\u5206\u5f62\u7ef4\u6570\u7684\u8986\u76d6\u96c6\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2d\u7531\u7f51\u683c\u4f4d\u7f6e\u3001\u65b9\u5411\u53ca\u5c3a\u5bf8\u8fdb\u5c55\u5e26\u6765\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f5c\u8005\u5c06DGGS\u7528\u4f5c\u8986\u76d6\u96c6\uff0c\u91c7\u7528Minkowski-Bouligand\u65b9\u6cd5\u8ba1\u7b97\u5730\u7406\u77e2\u91cf\u6570\u636e\u7684\u5206\u5f62\u7ef4\u6570\u3002\u901a\u8fc7\u5728\u5408\u6210\u6570\u636e\u548c\u536b\u661f\u4e91\u5c42\u6570\u636e\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u68c0\u9a8c\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u51c6\u786e\u6027\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u5408\u6210\u6570\u636e\u6d4b\u8bd5\u4e2d\u4e0e\u7406\u8bba\u5206\u5f62\u7ef4\u6570\u7684\u8bef\u5dee\u5c0f\u4e8e1%\uff1b\u5728\u771f\u5b9e\u536b\u661f\u4e91\u573a\u6570\u636e\u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u4e0e\u6587\u732e\u4e2d\u7684\u5206\u5f62\u7ef4\u6570\u503c\u4e00\u81f4\u3002\u65b9\u6cd5\u5728\u8003\u8651\u5730\u7403\u66f2\u7387\u4ee5\u53ca\u6d88\u9664\u7f51\u683c\u4efb\u610f\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "DGGS\u4f5c\u4e3a\u8986\u76d6\u96c6\u8ba1\u7b97\u5730\u7406\u7a7a\u95f4\u6570\u636e\u5206\u5f62\u7ef4\u6570\u7684\u65b9\u6cd5\u662f\u6709\u6548\u4e14\u7406\u8bba\u4e0a\u53ef\u884c\u7684\uff0c\u80fd\u591f\u7f13\u89e3\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7f51\u683c\u9009\u62e9\u548c\u5c3a\u5bf8\u8c03\u6574\u7684\u95ee\u9898\uff0c\u5e76\u9002\u7528\u4e8e\u5927\u8303\u56f4\u5730\u7406\u6570\u636e\u3002\u8bba\u6587\u8fd8\u8ba8\u8bba\u4e86\u9002\u5408\u8be5\u7528\u9014\u7684DGGS\u7684\u7406\u60f3\u7279\u6027\u3002"}}
{"id": "2506.17298", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17298", "abs": "https://arxiv.org/abs/2506.17298", "authors": ["Inception Labs", "Samar Khanna", "Siddhant Kharbanda", "Shufan Li", "Harshit Varma", "Eric Wang", "Sawyer Birnbaum", "Ziyang Luo", "Yanis Miraoui", "Akash Palrecha", "Stefano Ermon", "Aditya Grover", "Volodymyr Kuleshov"], "title": "Mercury: Ultra-Fast Language Models Based on Diffusion", "comment": "15 pages; equal core, cross-function, senior authors listed\n  alphabetically", "summary": "We present Mercury, a new generation of commercial-scale large language\nmodels (LLMs) based on diffusion. These models are parameterized via the\nTransformer architecture and trained to predict multiple tokens in parallel. In\nthis report, we detail Mercury Coder, our first set of diffusion LLMs designed\nfor coding applications. Currently, Mercury Coder comes in two sizes: Mini and\nSmall. These models set a new state-of-the-art on the speed-quality frontier.\nBased on independent evaluations conducted by Artificial Analysis, Mercury\nCoder Mini and Mercury Coder Small achieve state-of-the-art throughputs of 1109\ntokens/sec and 737 tokens/sec, respectively, on NVIDIA H100 GPUs and outperform\nspeed-optimized frontier models by up to 10x on average while maintaining\ncomparable quality. We discuss additional results on a variety of code\nbenchmarks spanning multiple languages and use-cases as well as real-world\nvalidation by developers on Copilot Arena, where the model currently ranks\nsecond on quality and is the fastest model overall. We also release a public\nAPI at https://platform.inceptionlabs.ai/ and free playground at\nhttps://chat.inceptionlabs.ai", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6269\u6563\u673a\u5236\u7684\u4ee3\u7801\u5927\u6a21\u578bMercury Coder\uff0c\u901f\u5ea6\u76f8\u8f83\u4e8e\u73b0\u6709\u6a21\u578b\u63d0\u5347\u9ad8\u8fbe10\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u5df2\u5728\u591a\u4e2a\u516c\u5f00\u6d4b\u8bd5\u53ca\u771f\u5b9e\u5f00\u53d1\u573a\u666f\u4e2d\u83b7\u5f97\u9886\u5148\u8868\u73b0\uff0c\u5e76\u5df2\u5f00\u653eAPI\u4e0e\u8bd5\u73a9\u5e73\u53f0\u3002", "motivation": "\u8fd1\u5e74\u6765\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4ee3\u7801\u751f\u6210\u7b49\u5b9e\u9645\u4efb\u52a1\u4e2d\u5df2\u6210\u4e3a\u4e3b\u6d41\u6280\u672f\uff0c\u4f46\u5728\u63d0\u5347\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u63a8\u7406\u901f\u5ea6\u6210\u4e3a\u5927\u89c4\u6a21\u5546\u7528\u90e8\u7f72\u7684\u4e00\u5927\u74f6\u9888\u3002\u8be5\u8bba\u6587\u65e8\u5728\u7a81\u7834\u901f\u5ea6\u4e0e\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5b9e\u73b0\u66f4\u5feb\u4e14\u9ad8\u8d28\u91cf\u7684\u4ee3\u7801\u751f\u6210\u5927\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\uff08diffusion\uff09\u673a\u5236\u7684\u5927\u8bed\u8a00\u6a21\u578b Mercury\uff0c\u5e76\u91c7\u7528Transformer\u7ed3\u6784\u6765\u5b9e\u73b0\u591atoken\u5e76\u884c\u9884\u6d4b\u3002\u4ee5\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e3a\u4f8b\uff0c\u5f00\u53d1\u4e86Mercury Coder\u7cfb\u5217\u6a21\u578b\uff0c\u5305\u62ecMini\u548cSmall\u4e24\u4e2a\u7248\u672c\uff0c\u5e76\u5728\u5546\u7528\u786c\u4ef6\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4f18\u5316\u3002", "result": "Mercury Coder Mini\u548cSmall\u5728NVIDIA H100 GPU\u4e0a\u7684\u541e\u5410\u91cf\u5206\u522b\u8fbe\u52301109 tokens/sec\u548c737 tokens/sec\uff0c\u901f\u5ea6\u663e\u8457\u8d85\u8fc7\u73b0\u6709\u4e3b\u6d41\u9ad8\u6548\u4ee3\u7801\u751f\u6210\u6a21\u578b\uff0c\u4e14\u5728\u8d28\u91cf\u4e0a\u57fa\u672c\u6301\u5e73\u6216\u53d6\u5f97\u9886\u5148\u3002\u540c\u65f6\u5728\u591a\u4e2a\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\u3001\u4e3b\u6d41\u7f16\u7a0b\u8bed\u8a00\u548c\u5b9e\u9645\u5f00\u53d1\u5e94\u7528\u573a\u666f\uff08\u5982Copilot Arena\uff09\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u57fa\u4e8e\u6269\u6563\u673a\u5236\u7684LLM\uff08Mercury Coder\uff09\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u5546\u7528\u7ea7\u522b\u7684\u901f\u5ea6\u4e0e\u8d28\u91cf\u7a81\u7834\uff0c\u4e3a\u5927\u89c4\u6a21\u90e8\u7f72\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.17484", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17484", "abs": "https://arxiv.org/abs/2506.17484", "authors": ["Yao Zhang", "Zaixi Shang", "Silpan Patel", "Mikel Zuniga"], "title": "From Unstructured Communication to Intelligent RAG: Multi-Agent Automation for Supply Chain Knowledge Bases", "comment": "Accepted In Proceedings of the 1st Workshop on AI for Supply Chain:\n  Today and Future @ 31st ACM SIGKDD Conference on Knowledge Discovery and Data\n  Mining V.2 (KDD 25), August 3, 2025, Toronto, ON, Canada. ACM, New York, NY,\n  USA, 14 pages, 2 figures", "summary": "Supply chain operations generate vast amounts of operational data; however,\ncritical knowledge such as system usage practices, troubleshooting workflows,\nand resolution techniques often remains buried within unstructured\ncommunications like support tickets, emails, and chat logs. While RAG systems\naim to leverage such communications as a knowledge base, their effectiveness is\nlimited by raw data challenges: support tickets are typically noisy,\ninconsistent, and incomplete, making direct retrieval suboptimal. Unlike\nexisting RAG approaches that focus on runtime optimization, we introduce a\nnovel offline-first methodology that transforms these communications into a\nstructured knowledge base. Our key innovation is a LLMs-based multi-agent\nsystem orchestrating three specialized agents: Category Discovery for taxonomy\ncreation, Categorization for ticket grouping, and Knowledge Synthesis for\narticle generation. Applying our methodology to real-world support tickets with\nresolution notes and comments, our system creates a compact knowledge base -\nreducing total volume to just 3.4% of original ticket data while improving\nquality. Experiments demonstrate that our prebuilt knowledge base in RAG\nsystems significantly outperforms traditional RAG implementations (48.74% vs.\n38.60% helpful answers) and achieves a 77.4% reduction in unhelpful responses.\nBy automating institutional knowledge capture that typically remains siloed in\nexperts' heads, our solution translates to substantial operational efficiency:\nreducing support workload, accelerating resolution times, and creating\nself-improving systems that automatically resolve approximately 50% of future\nsupply chain tickets. Our approach addresses a key gap in knowledge management\nby transforming transient communications into structured, reusable knowledge\nthrough intelligent offline processing rather than latency-inducing runtime\narchitectures.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u5927\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u7684\u79bb\u7ebf\u7ed3\u6784\u5316\u65b9\u6848\uff0c\u4ece\u539f\u59cb\u652f\u6301\u5de5\u5355\u7b49\u975e\u7ed3\u6784\u5316\u6570\u636e\u4e2d\u81ea\u52a8\u6784\u5efa\u9ad8\u8d28\u91cf\u3001\u53ef\u590d\u7528\u7684\u77e5\u8bc6\u5e93\uff0c\u5927\u5e45\u63d0\u5347RAG\u7cfb\u7edf\u6548\u679c\uff0c\u5b9e\u73b0\u4f9b\u5e94\u94fe\u8fd0\u7ef4\u77e5\u8bc6\u81ea\u52a8\u6c89\u6dc0\u548c\u9ad8\u6548\u5229\u7528\u3002", "motivation": "\u73b0\u6709RAG\u7cfb\u7edf\u9762\u5bf9\u539f\u59cb\u8fd0\u7ef4\u5bf9\u8bdd\u6570\u636e\uff08\u5982\u5de5\u5355\u3001\u90ae\u4ef6\u3001\u804a\u5929\u8bb0\u5f55\uff09\u65f6\uff0c\u7531\u4e8e\u8fd9\u4e9b\u6570\u636e\u566a\u97f3\u591a\u3001\u4e0d\u5b8c\u5168\u4e14\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u68c0\u7d22\u6548\u679c\u53d7\u9650\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u5c06\u975e\u7ed3\u6784\u5316\u901a\u4fe1\u8f6c\u4e3a\u9ad8\u8d28\u91cf\u77e5\u8bc6\u5e93\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u91ca\u653e\u4e13\u5bb6\u6c89\u6dc0\u77e5\u8bc6\uff0c\u5b9e\u73b0\u77e5\u8bc6\u5171\u4eab\u548c\u8fd0\u7ef4\u81ea\u52a8\u5316\u3002", "method": "\u8bba\u6587\u8bbe\u8ba1\u4e86\u4e00\u5957\u7531\u4e09\u4e2a\u4e13\u7528\u667a\u80fd\u4f53\uff08\u7c7b\u522b\u53d1\u73b0\u3001\u5f52\u7c7b\u548c\u77e5\u8bc6\u5408\u6210\uff09\u534f\u4f5c\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002\u8be5\u7cfb\u7edf\u9996\u5148\u5bf9\u539f\u59cb\u652f\u6301\u5de5\u5355\u8fdb\u884c\u5206\u7c7b\u3001\u5f52\u7c7b\uff0c\u7136\u540e\u751f\u6210\u7ed3\u6784\u5316\u7684\u77e5\u8bc6\u6587\u7ae0\uff0c\u6700\u7ec8\u5f62\u6210\u7528\u4e8eRAG\u7cfb\u7edf\u7684\u7d27\u51d1\u77e5\u8bc6\u5e93\u3002", "result": "\u672c\u65b9\u6cd5\u5728\u771f\u5b9e\u5de5\u5355\u5e94\u7528\u4e2d\uff0c\u628a\u77e5\u8bc6\u5e93\u4f53\u79ef\u7f29\u51cf\u81f3\u539f\u59cb\u6570\u636e\u76843.4%\uff0c\u4e14\u63d0\u5347\u4e86RAG\u7cfb\u7edf\u7684\u7b54\u6848\u6709\u7528\u7387\uff0848.74% vs. 38.60%\uff09\uff0c\u540c\u65f6\u65e0\u7528\u56de\u7b54\u51cf\u5c1177.4%\u3002\u7cfb\u7edf\u80fd\u81ea\u52a8\u5316\u89e3\u51b3\u8fd150%\u7684\u540e\u7eed\u4f9b\u5e94\u94fe\u5de5\u5355\uff0c\u5927\u5e45\u964d\u4f4e\u5de5\u4f5c\u8d1f\u62c5\u5e76\u63d0\u5347\u54cd\u5e94\u901f\u5ea6\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5927\u6a21\u578b\uff08LLMs-based multi-agent system\uff09\u81ea\u52a8\u63d0\u53d6\u3001\u7ed3\u6784\u5316\u548c\u91cd\u7ec4\u4f9b\u5e94\u94fe\u975e\u7ed3\u6784\u5316\u8fd0\u7ef4\u6570\u636e\u7684\u79bb\u7ebf\u4f18\u5148\u65b9\u6848\uff0c\u8fd9\u79cd\u65b9\u5f0f\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u7ba1\u7406\u6548\u7387\u53caRAG\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.17363", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17363", "abs": "https://arxiv.org/abs/2506.17363", "authors": ["Sunjun Kweon", "Sooyohn Nam", "Hyunseung Lim", "Hwajung Hong", "Edward Choi"], "title": "A Large-Scale Real-World Evaluation of LLM-Based Virtual Teaching Assistant", "comment": "ACL 2025 Industry Track", "summary": "Virtual Teaching Assistants (VTAs) powered by Large Language Models (LLMs)\nhave the potential to enhance student learning by providing instant feedback\nand facilitating multi-turn interactions. However, empirical studies on their\neffectiveness and acceptance in real-world classrooms are limited, leaving\ntheir practical impact uncertain. In this study, we develop an LLM-based VTA\nand deploy it in an introductory AI programming course with 477 graduate\nstudents. To assess how student perceptions of the VTA's performance evolve\nover time, we conduct three rounds of comprehensive surveys at different stages\nof the course. Additionally, we analyze 3,869 student--VTA interaction pairs to\nidentify common question types and engagement patterns. We then compare these\ninteractions with traditional student--human instructor interactions to\nevaluate the VTA's role in the learning process. Through a large-scale\nempirical study and interaction analysis, we assess the feasibility of\ndeploying VTAs in real-world classrooms and identify key challenges for broader\nadoption. Finally, we release the source code of our VTA system, fostering\nfuture advancements in AI-driven education:\n\\texttt{https://github.com/sean0042/VTA}.", "AI": {"tldr": "\u4f5c\u8005\u5728AI\u8bfe\u7a0b\u4e2d\u90e8\u7f72\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u865a\u62df\u52a9\u6559\uff0c\u901a\u8fc7\u5b66\u751f\u8c03\u67e5\u548c\u4ea4\u4e92\u6570\u636e\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5176\u5728\u73b0\u5b9e\u8bfe\u5802\u4e2d\u7684\u4f5c\u7528\u3001\u4f18\u52bf\u4e0e\u6311\u6218\uff0c\u5e76\u5f00\u6e90\u4e86\u8be5\u7cfb\u7edf\u3002", "motivation": "\u5c3d\u7ba1LLM\u9a71\u52a8\u7684\u865a\u62df\u52a9\u6559\u6709\u671b\u901a\u8fc7\u5373\u65f6\u53cd\u9988\u548c\u591a\u8f6e\u4e92\u52a8\u63d0\u5347\u5b66\u751f\u5b66\u4e60\u6548\u679c\uff0c\u4f46\u5176\u5728\u771f\u5b9e\u8bfe\u5802\u7684\u6548\u679c\u548c\u63a5\u53d7\u5ea6\u5c1a\u7f3a\u4e4f\u5b9e\u8bc1\u6570\u636e\uff0c\u5b9e\u9645\u5f71\u54cd\u4e0d\u660e\uff0c\u56e0\u6b64\u9700\u8981\u5728\u73b0\u5b9e\u573a\u666f\u4e0b\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002", "method": "\u5728477\u540d\u7814\u7a76\u751f\u53c2\u52a0\u7684AI\u7f16\u7a0b\u8bfe\u7a0b\u4e2d\u90e8\u7f72\u57fa\u4e8e\u5927\u6a21\u578b\u7684\u865a\u62df\u52a9\u6559\uff0c\u5e76\u5728\u8bfe\u7a0b\u4e0d\u540c\u9636\u6bb5\u8fdb\u884c\u4e09\u8f6e\u5b66\u751f\u95ee\u5377\u8c03\u67e5\uff0c\u540c\u65f6\u5206\u67903869\u7ec4\u5b66\u751f\u4e0e\u865a\u62df\u52a9\u6559\u7684\u4ea4\u4e92\u8bb0\u5f55\uff0c\u5e76\u4e0e\u4f20\u7edf\u5b66\u751f-\u4eba\u5de5\u6559\u5e08\u7684\u4ea4\u4e92\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u5b66\u751f\u5bf9VTA\u8868\u73b0\u7684\u770b\u6cd5\u4f1a\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u5206\u6790\u663e\u793aVTA\u80fd\u591f\u8986\u76d6\u591a\u79cd\u63d0\u95ee\u7c7b\u578b\u5e76\u5c55\u73b0\u72ec\u7279\u7684\u53c2\u4e0e\u6a21\u5f0f\u3002\u4f46\u4e0e\u4eba\u7c7b\u6559\u5e08\u76f8\u6bd4\u4ecd\u6709\u4e0d\u8db3\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u578b\u5173\u952e\u6311\u6218\u3002\u540c\u65f6\u5f00\u6e90\u4e86VTA\u7cfb\u7edf\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u548c\u4ea4\u4e92\u5206\u6790\uff0c\u8bc4\u4f30\u4e86LLM\u9a71\u52a8\u7684\u865a\u62df\u52a9\u6559\u5728\u771f\u5b9e\u8bfe\u5802\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u6240\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u3002\u4f5c\u8005\u8fd8\u5f00\u6e90\u4e86\u865a\u62df\u52a9\u6559\u7cfb\u7edf\uff0c\u4ee5\u4fc3\u8fdb\u672a\u6765AI\u6559\u80b2\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.18206", "categories": ["cs.CE", "cs.NA", "math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2506.18206", "abs": "https://arxiv.org/abs/2506.18206", "authors": ["Adriana Kulikov\u00e1", "Andrei G. Shvarts", "\u0141ukasz Kaczmarczyk", "Chris J. Pearce"], "title": "Conservative data-driven finite element formulation", "comment": null, "summary": "This paper presents a new data-driven finite element framework derived with\nmixed finite element formulation. The standard approach to diffusion problems\nrequires the solution of the mathematical equations that describe both the\nconservation law and the constitutive relations, where the latter is\ntraditionally obtained after fitting experimental data to simplified material\nmodels. To exploit all available information and avoid bias in the material\nmodel, we follow a data-driven approach. While the conservation laws and\nboundary conditions are satisfied by means of the finite element method, the\nexperimental data is used directly in the numerical simulations, avoiding the\nneed of fitting material model parameters. In order to satisfy the conservation\nlaw a priori in the strong sense, we introduce a mixed finite element\nformulation. This relaxes the regularity requirements on approximation spaces\nwhile enforcing continuity of the normal flux component across all of the inner\nboundaries. This weaker mixed formulation provides a posteriori error\nindicators tailored for this data-driven approach, enabling adaptive\nhp-refinement. The relaxed regularity of the approximation spaces makes it\neasier to observe how the variation in the datasets results in the\nnon-uniqueness of the solution, which can be quantified to predict the\nuncertainty of the results. The capabilities of the formulation are\ndemonstrated in an example of the nonlinear heat transfer in nuclear graphite\nusing synthetically generated material datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u6df7\u5408\u6709\u9650\u5143\u7406\u8bba\u7684\u6570\u636e\u9a71\u52a8\u6709\u9650\u5143\u6846\u67b6\uff0c\u76f4\u63a5\u5728\u6570\u503c\u8ba1\u7b97\u4e2d\u5e94\u7528\u5b9e\u9a8c\u6570\u636e\uff0c\u907f\u514d\u4f20\u7edf\u6750\u6599\u6a21\u578b\u62df\u5408\u5e26\u6765\u7684\u504f\u5dee\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u5229\u7528\u540e\u9a8c\u8bef\u5dee\u6307\u793a\u5668\u652f\u6301\u81ea\u9002\u5e94\u52a0\u5bc6\uff0c\u5e76\u5728\u6838\u77f3\u58a8\u975e\u7ebf\u6027\u70ed\u4f20\u5bfc\u7b97\u4f8b\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u6269\u6563\u95ee\u9898\u6c42\u89e3\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u7b80\u5316\u6750\u6599\u6a21\u578b\u6765\u62df\u5408\u5b9e\u9a8c\u6570\u636e\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u504f\u5dee\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u5168\u90e8\u5b9e\u9a8c\u6570\u636e\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u76f4\u63a5\u5e94\u7528\u5b9e\u9a8c\u6570\u636e\uff0c\u907f\u514d\u6750\u6599\u6a21\u578b\u53c2\u6570\u62df\u5408\u5e26\u6765\u7684\u9650\u5236\u548c\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u6709\u9650\u5143\uff08mixed finite element\uff09\u6570\u636e\u9a71\u52a8\u6709\u9650\u5143\u5206\u6790\u6846\u67b6\u3002\u901a\u8fc7\u6df7\u5408\u6709\u9650\u5143\u65b9\u6cd5\u5f3a\u5236\u6ee1\u8db3\u5b88\u6052\u5f8b\u548c\u8fb9\u754c\u6761\u4ef6\uff0c\u5e76\u76f4\u63a5\u5728\u6570\u503c\u8ba1\u7b97\u4e2d\u91c7\u7528\u5b9e\u9a8c\u6570\u636e\uff0c\u65e0\u9700\u62df\u5408\u6750\u6599\u6a21\u578b\u53c2\u6570\u3002\u6df7\u5408\u6709\u9650\u5143\u65b9\u6cd5\u964d\u4f4e\u4e86\u5bf9\u903c\u8fd1\u7a7a\u95f4\u7684\u6b63\u5219\u6027\u8981\u6c42\uff0c\u786e\u4fdd\u4e86\u6cd5\u5411\u901a\u91cf\u5728\u6240\u6709\u5185\u90e8\u8fb9\u754c\u4e0a\u7684\u8fde\u7eed\u6027\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u9002\u7528\u4e8e\u6570\u636e\u9a71\u52a8\u8ba1\u7b97\u7684\u540e\u9a8c\u8bef\u5dee\u6307\u793a\u5668\uff0c\u652f\u6301\u81ea\u9002\u5e94 hp-\u52a0\u5bc6\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u91cf\u5316\u6570\u636e\u96c6\u53d8\u5316\u5bfc\u81f4\u7684\u89e3\u7684\u975e\u552f\u4e00\u6027\u5e76\u9884\u6d4b\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u5728\u975e\u7ebf\u6027\u70ed\u4f20\u5bfc\uff08\u4ee5\u5408\u6210\u7684\u6838\u77f3\u58a8\u6750\u6599\u6570\u636e\u96c6\u4e3a\u4f8b\uff09\u73af\u5883\u4e0b\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u6df7\u5408\u6709\u9650\u5143\u6570\u636e\u9a71\u52a8\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u6709\u9650\u5143\u6570\u636e\u9a71\u52a8\u6846\u67b6\u80fd\u591f\u907f\u514d\u6750\u6599\u6a21\u578b\u53c2\u6570\u62df\u5408\uff0c\u76f4\u63a5\u5229\u7528\u5b9e\u9a8c\u6570\u636e\uff0c\u4ece\u800c\u51cf\u5c11\u6a21\u578b\u504f\u5dee\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u652f\u6301\u7cbe\u786e\u9002\u5e94\u6027\u5206\u6790\u3002\u8be5\u6846\u67b6\u9002\u7528\u4e8e\u5904\u7406\u6269\u6563\u95ee\u9898\uff0c\u80fd\u591f\u91cf\u5316\u89e3\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5176\u9002\u7528\u6027\u548c\u6709\u6548\u6027\u901a\u8fc7\u70ed\u4f20\u5bfc\u5b9e\u4f8b\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2506.17314", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.17314", "abs": "https://arxiv.org/abs/2506.17314", "authors": ["Adnan Qidwai", "Srija Mukhopadhyay", "Prerana Khatiwada", "Dan Roth", "Vivek Gupta"], "title": "PRAISE: Enhancing Product Descriptions with LLM-Driven Structured Insights", "comment": "9 Pages, 9 Figures. Accepted at ACL 2025 System Demonstration Track", "summary": "Accurate and complete product descriptions are crucial for e-commerce, yet\nseller-provided information often falls short. Customer reviews offer valuable\ndetails but are laborious to sift through manually. We present PRAISE: Product\nReview Attribute Insight Structuring Engine, a novel system that uses Large\nLanguage Models (LLMs) to automatically extract, compare, and structure\ninsights from customer reviews and seller descriptions. PRAISE provides users\nwith an intuitive interface to identify missing, contradictory, or partially\nmatching details between these two sources, presenting the discrepancies in a\nclear, structured format alongside supporting evidence from reviews. This\nallows sellers to easily enhance their product listings for clarity and\npersuasiveness, and buyers to better assess product reliability. Our\ndemonstration showcases PRAISE's workflow, its effectiveness in generating\nactionable structured insights from unstructured reviews, and its potential to\nsignificantly improve the quality and trustworthiness of e-commerce product\ncatalogs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faPRAISE\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5bf9\u7535\u5546\u5546\u54c1\u8bc4\u8bba\u4e0e\u63cf\u8ff0\u8fdb\u884c\u4fe1\u606f\u63d0\u53d6\u4e0e\u7ed3\u6784\u5316\uff0c\u5bf9\u5f3a\u5316\u5546\u54c1\u4fe1\u606f\u8d28\u91cf\u3001\u63d0\u5347\u4e70\u5356\u53cc\u65b9\u4f53\u9a8c\u6709\u91cd\u8981\u4ef7\u503c\u3002", "motivation": "\u7535\u5546\u5e73\u53f0\u4e0a\u5546\u54c1\u63cf\u8ff0\u7684\u91cd\u8981\u6027\u65e5\u76ca\u7a81\u51fa\uff0c\u4f46\u5356\u5bb6\u63d0\u4f9b\u7684\u4fe1\u606f\u5e38\u5e38\u4e0d\u5168\u9762\u6216\u4e0d\u51c6\u786e\u3002\u5ba2\u6237\u8bc4\u8bba\u5305\u542b\u4e86\u4e30\u5bcc\u800c\u771f\u5b9e\u7684\u7ec6\u8282\uff0c\u4f46\u4eba\u5de5\u7b5b\u67e5\u8fd9\u4e9b\u8bc4\u8bba\u65e2\u8d39\u65f6\u53c8\u4f4e\u6548\uff0c\u56e0\u6b64\u4e9f\u9700\u81ea\u52a8\u5316\u5de5\u5177\u6765\u63d0\u5347\u4fe1\u606f\u8d28\u91cf\u4e0e\u4f7f\u7528\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7cfb\u7edfPRAISE\uff1a\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u81ea\u52a8\u4ece\u7528\u6237\u8bc4\u8bba\u548c\u5356\u5bb6\u63cf\u8ff0\u4e2d\u63d0\u53d6\u3001\u6bd4\u8f83\u5e76\u7ed3\u6784\u5316\u4ea7\u54c1\u4fe1\u606f\u3002\u8be5\u7cfb\u7edf\u80fd\u76f4\u89c2\u5c55\u793a\u4e24\u8005\u4e4b\u95f4\u7f3a\u5931\u3001\u77db\u76fe\u6216\u90e8\u5206\u5339\u914d\u7684\u4fe1\u606f\uff0c\u5e76\u63d0\u4f9b\u8bc4\u8bba\u8bc1\u636e\u3002\u7528\u6237\u754c\u9762\u4fbf\u6377\uff0c\u5e2e\u52a9\u8bc6\u522b\u5173\u952e\u4fe1\u606f\u5dee\u5f02\u3002", "result": "PRAISE\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5730\u4ece\u6d77\u91cf\u975e\u7ed3\u6784\u5316\u8bc4\u8bba\u4e2d\u751f\u6210\u7ed3\u6784\u5316\u3001\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u663e\u8457\u63d0\u5347\u5546\u54c1\u63cf\u8ff0\u7684\u51c6\u786e\u6027\u4e0e\u8bf4\u670d\u529b\u3002\u6f14\u793a\u663e\u793a\u5176\u5728\u6539\u5584\u7535\u5546\u76ee\u5f55\u53ef\u4fe1\u5ea6\u4e0e\u8d28\u91cf\u65b9\u9762\u6709\u663e\u8457\u6f5c\u529b\u3002", "conclusion": "PRAISE\u80fd\u81ea\u52a8\u68b3\u7406\u4e70\u5bb6\u8bc4\u8bba\u4e0e\u5356\u5bb6\u63cf\u8ff0\u95f4\u7684\u4fe1\u606f\u5dee\u5f02\uff0c\u4e3a\u6539\u5584\u5546\u54c1\u5c55\u793a\u548c\u63d0\u5347\u7528\u6237\u51b3\u7b56\u4f53\u9a8c\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\uff0c\u5bf9\u7535\u5546\u751f\u6001\u7684\u5065\u5eb7\u53d1\u5c55\u5177\u6709\u79ef\u6781\u4f5c\u7528\u3002"}}
{"id": "2506.17514", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17514", "abs": "https://arxiv.org/abs/2506.17514", "authors": ["Ninareh Mehrabi", "Tharindu Kumarage", "Kai-Wei Chang", "Aram Galstyan", "Rahul Gupta"], "title": "Kaleidoscopic Teaming in Multi Agent Simulations", "comment": null, "summary": "Warning: This paper contains content that may be inappropriate or offensive.\n  AI agents have gained significant recent attention due to their autonomous\ntool usage capabilities and their integration in various real-world\napplications. This autonomy poses novel challenges for the safety of such\nsystems, both in single- and multi-agent scenarios. We argue that existing red\nteaming or safety evaluation frameworks fall short in evaluating safety risks\nin complex behaviors, thought processes and actions taken by agents. Moreover,\nthey fail to consider risks in multi-agent setups where various vulnerabilities\ncan be exposed when agents engage in complex behaviors and interactions with\neach other. To address this shortcoming, we introduce the term kaleidoscopic\nteaming which seeks to capture complex and wide range of vulnerabilities that\ncan happen in agents both in single-agent and multi-agent scenarios. We also\npresent a new kaleidoscopic teaming framework that generates a diverse array of\nscenarios modeling real-world human societies. Our framework evaluates safety\nof agents in both single-agent and multi-agent setups. In single-agent setup,\nan agent is given a scenario that it needs to complete using the tools it has\naccess to. In multi-agent setup, multiple agents either compete against or\ncooperate together to complete a task in the scenario through which we capture\nexisting safety vulnerabilities in agents. We introduce new in-context\noptimization techniques that can be used in our kaleidoscopic teaming framework\nto generate better scenarios for safety analysis. Lastly, we present\nappropriate metrics that can be used along with our framework to measure safety\nof agents. Utilizing our kaleidoscopic teaming framework, we identify\nvulnerabilities in various models with respect to their safety in agentic\nuse-cases.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9488\u5bf9AI\u667a\u80fd\u4f53\u5728\u590d\u6742\u5355\u4f53/\u591a\u4f53\u573a\u666f\u4e0b\u5b89\u5168\u6f0f\u6d1e\u7684\u65b0\u8bc4\u6d4b\u6846\u67b6\uff08kaleidoscopic teaming\uff09\uff0c\u901a\u8fc7\u751f\u6210\u591a\u6837\u5316\u73b0\u5b9e\u573a\u666f\u548c\u521b\u65b0\u4f18\u5316\u624b\u6bb5\uff0c\u53d1\u73b0\u5e76\u91cf\u5316\u4e86\u667a\u80fd\u4f53\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524dAI\u667a\u80fd\u4f53\u7531\u4e8e\u5176\u81ea\u4e3b\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u548c\u5b9e\u9645\u5e94\u7528\u7684\u5e7f\u6cdb\u6027\uff0c\u5e26\u6765\u4e86\u524d\u6240\u672a\u6709\u7684\u5b89\u5168\u6311\u6218\uff0c\u73b0\u6709\u7684\u7ea2\u961f\u6d4b\u8bd5\u6216\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\u96be\u4ee5\u8bc4\u4f30\u5176\u590d\u6742\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5c24\u5176\u5728\u591a\u667a\u80fd\u4f53\u573a\u666f\u4e0b\u66f4\u4e3a\u7a81\u51fa\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u201c\u591a\u68f1\u955c\u56e2\u961f\uff08kaleidoscopic teaming\uff09\u201d\u7684\u65b0\u6846\u67b6\uff0c\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u7684\u6a21\u62df\u771f\u5b9e\u793e\u4f1a\u7684\u590d\u6742\u573a\u666f\uff0c\u5206\u522b\u5bf9\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u7684\u5b89\u5168\u98ce\u9669\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002\u65b9\u6cd5\u5305\u62ec\u573a\u666f\u751f\u6210\u3001\u5b89\u5168\u6f0f\u6d1e\u6355\u6349\u3001\u65b0\u7684\u4e0a\u4e0b\u6587\u4f18\u5316\u6280\u672f\uff0c\u4ee5\u53ca\u91cf\u5316\u5b89\u5168\u8bc4\u4f30\u7684\u6307\u6807\u3002\u5355\u667a\u80fd\u4f53\u4efb\u52a1\u805a\u7126\u5176\u81ea\u4e3b\u5b8c\u6210\u5de5\u5177\u4f7f\u7528\uff0c\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u6a21\u62df\u534f\u4f5c\u6216\u5bf9\u6297\u3002", "result": "\u5229\u7528\u6240\u63d0\u51fa\u7684kaleidoscopic teaming\u6846\u67b6\uff0c\u4f5c\u8005\u5728\u4e0d\u540c\u7684\u6a21\u578b\u4e2d\u8bc6\u522b\u548c\u5206\u6790\u4e86\u5176\u5728\u5b9e\u9645\u667a\u80fd\u4f53\u5e94\u7528\u573a\u666f\u4e0b\u7684\u5177\u4f53\u5b89\u5168\u6f0f\u6d1e\u3002", "conclusion": "\u73b0\u6709\u5b89\u5168\u6d4b\u8bd5\u6846\u67b6\u96be\u4ee5\u8986\u76d6AI\u667a\u80fd\u4f53\u5728\u590d\u6742\u4efb\u52a1\u548c\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u4e0b\u7684\u5168\u90e8\u5b89\u5168\u98ce\u9669\uff0c\u6240\u63d0\u51fa\u7684\u65b0\u6846\u67b6\u80fd\u591f\u66f4\u52a0\u5168\u9762\u4e14\u6709\u6548\u5730\u8bc4\u4f30\u548c\u63ed\u793a\u8fd9\u4e9b\u5b89\u5168\u9690\u60a3\uff0c\u5bf9\u589e\u5f3aAI\u7cfb\u7edf\u5b89\u5168\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.17364", "categories": ["cs.CY", "cs.AI", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.17364", "abs": "https://arxiv.org/abs/2506.17364", "authors": ["Alvaro Becerra", "Roberto Daza", "Ruth Cobos", "Aythami Morales", "Mutlu Cukurova", "Julian Fierrez"], "title": "AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning", "comment": "Accepted in EC-TEL25: 20th European Conference on Technology Enhanced\n  Learning, Newcastle and Durham, UK, 15-19 September 2025", "summary": "This work investigates the use of multimodal biometrics to detect\ndistractions caused by smartphone use during tasks that require sustained\nattention, with a focus on computer-based online learning. Although the methods\nare applicable to various domains, such as autonomous driving, we concentrate\non the challenges learners face in maintaining engagement amid internal (e.g.,\nmotivation), system-related (e.g., course design) and contextual (e.g.,\nsmartphone use) factors. Traditional learning platforms often lack detailed\nbehavioral data, but Multimodal Learning Analytics (MMLA) and biosensors\nprovide new insights into learner attention. We propose an AI-based approach\nthat leverages physiological signals and head pose data to detect phone use.\nOur results show that single biometric signals, such as brain waves or heart\nrate, offer limited accuracy, while head pose alone achieves 87%. A multimodal\nmodel combining all signals reaches 91% accuracy, highlighting the benefits of\nintegration. We conclude by discussing the implications and limitations of\ndeploying these models for real-time support in online learning environments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u57fa\u4e8e\u591a\u6a21\u6001\u751f\u7269\u8bc6\u522b\u624b\u6bb5\u76d1\u6d4b\u5728\u7ebf\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u5206\u5fc3\u884c\u4e3a\uff0c\u878d\u5408\u591a\u79cd\u751f\u7406\u4e0e\u884c\u4e3a\u4fe1\u53f7\uff0c\u68c0\u6d4b\u624b\u673a\u4f7f\u7528\u5206\u5fc3\u7684\u51c6\u786e\u7387\u63d0\u5347\u81f391%\uff0c\u4e3a\u5728\u7ebf\u6559\u80b2\u5e73\u53f0\u7684\u5b9e\u65f6\u76d1\u63a7\u4e0e\u5e72\u9884\u63d0\u4f9b\u4e86\u65b0\u65b9\u6848\u3002", "motivation": "\u5728\u9700\u8981\u6301\u7eed\u4e13\u6ce8\u7684\u4efb\u52a1\uff08\u5982\u5728\u7ebf\u5b66\u4e60\uff09\u4e2d\uff0c\u667a\u80fd\u624b\u673a\u4f7f\u7528\u5bfc\u81f4\u7684\u5206\u5fc3\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002\u4f20\u7edf\u5b66\u4e60\u5e73\u53f0\u7f3a\u4e4f\u5bf9\u5b66\u4e60\u8005\u884c\u4e3a\u7684\u7cbe\u7ec6\u6570\u636e\u5206\u6790\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u76d1\u6d4b\u5e76\u7406\u89e3\u5b66\u4e60\u8005\u7684\u6ce8\u610f\u529b\u72b6\u6001\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u751f\u7406\u4fe1\u53f7\uff08\u5982\u8111\u7535\u548c\u5fc3\u8df3\uff09\u53ca\u5934\u90e8\u59ff\u6001\u6570\u636e\uff0c\u68c0\u6d4b\u7528\u6237\u5728\u7535\u8111\u7aef\u5b66\u4e60\u65f6\u662f\u5426\u4f7f\u7528\u624b\u673a\u3002\u901a\u8fc7\u591a\u6a21\u6001\u5b66\u4e60\u5206\u6790\u4e0e\u751f\u7269\u4f20\u611f\u5668\u91c7\u96c6\u6570\u636e\uff0c\u8bbe\u8ba1\u5e76\u8bc4\u4f30\u5355\u6a21\u6001\u4e0e\u591a\u6a21\u6001\u7684\u8bc6\u522b\u6a21\u578b\u3002", "result": "\u5355\u4e00\u751f\u7269\u8bc6\u522b\u4fe1\u53f7\uff08\u5982\u8111\u6ce2\u3001\u5fc3\u7387\uff09\u68c0\u6d4b\u624b\u673a\u4f7f\u7528\u7684\u51c6\u786e\u7387\u6709\u9650\uff1b\u5355\u72ec\u4f7f\u7528\u5934\u90e8\u59ff\u6001\u80fd\u591f\u8fbe\u523087%\u7684\u51c6\u786e\u7387\uff1b\u5c06\u6240\u6709\u4fe1\u53f7\u878d\u5408\u7684\u591a\u6a21\u6001\u6a21\u578b\u51c6\u786e\u7387\u9ad8\u8fbe91%\u3002", "conclusion": "\u591a\u6a21\u6001\u751f\u7269\u8bc6\u522b\u6280\u672f\u80fd\u591f\u66f4\u6709\u6548\u5730\u68c0\u6d4b\u5b66\u4e60\u671f\u95f4\u7684\u5206\u5fc3\u884c\u4e3a\uff0c\u5c24\u5176\u662f\u5728\u667a\u80fd\u624b\u673a\u4f7f\u7528\u65b9\u9762\u3002\u5b9e\u9645\u90e8\u7f72\u65f6\u8fd8\u9700\u8003\u8651\u6a21\u578b\u7684\u5b9e\u65f6\u6027\u53ca\u5e94\u7528\u9650\u5236\u3002"}}
{"id": "2506.18227", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.18227", "abs": "https://arxiv.org/abs/2506.18227", "authors": ["Zezhong Zhang", "Caroline Tatsuoka", "Dongbin Xiu", "Guannan Zhang"], "title": "Exact Conditional Score-Guided Generative Modeling for Amortized Inference in Uncertainty Quantification", "comment": null, "summary": "We propose an efficient framework for amortized conditional inference by\nleveraging exact conditional score-guided diffusion models to train a\nnon-reversible neural network as a conditional generative model. Traditional\nnormalizing flow methods require reversible architectures, which can limit\ntheir expressiveness and efficiency. Although diffusion models offer greater\nflexibility, they often suffer from high computational costs during inference.\nTo combine the strengths of both approaches, we introduce a two-stage method.\nFirst, we construct a training-free conditional diffusion model by analytically\nderiving an exact score function under a Gaussian mixture prior formed from\nsamples of the underlying joint distribution. This exact conditional score\nmodel allows us to efficiently generate noise-labeled data, consisting of\ninitial diffusion Gaussian noise and posterior samples conditioned on various\nobservation values, by solving a reverse-time ordinary differential equation.\nSecond, we use this noise-labeled data to train a feedforward neural network\nthat maps noise and observations directly to posterior samples, eliminating the\nneed for reversibility or iterative sampling at inference time. The resulting\nmodel provides fast, accurate, and scalable conditional sampling for\nhigh-dimensional and multi-modal posterior distributions, making it well-suited\nfor uncertainty quantification tasks, e.g., parameter estimation of complex\nphysical systems. We demonstrate the effectiveness of our approach through a\nseries of numerical experiments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u878d\u5408\u7cbe\u51c6\u6761\u4ef6\u6269\u6563\u6a21\u578b\u4e0e\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7684\u9ad8\u6548\u6761\u4ef6\u63a8\u65ad\u65b9\u6cd5\uff0c\u517c\u5177\u8868\u8fbe\u529b\u4e0e\u63a8\u65ad\u901f\u5ea6\uff0c\u9002\u5408\u590d\u6742\u540e\u9a8c\u5206\u5e03\u4efb\u52a1\u3002", "motivation": "\u76ee\u524d\u6709\u6761\u4ef6\u63a8\u65ad\u7684\u751f\u6210\u6a21\u578b\u5b58\u5728\u6548\u7387\u548c\u8868\u8fbe\u80fd\u529b\u7684\u6743\u8861\u3002\u53ef\u9006\u5f52\u4e00\u5316\u6d41\u9700\u8981\u53ef\u9006\u7ed3\u6784\uff0c\u9650\u5236\u4e86\u6a21\u578b\u8868\u8fbe\u529b\u548c\u6548\u7387\uff1b\u6269\u6563\u6a21\u578b\u5219\u63a8\u65ad\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u672c\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u7ed3\u5408\u4e24\u8005\u4f18\u70b9\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u8868\u8fbe\u529b\u5f3a\u7684\u6761\u4ef6\u751f\u6210\u5efa\u6a21\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4e24\u9636\u6bb5\u65b9\u6cd5\u3002\u7b2c\u4e00\u9636\u6bb5\uff0c\u901a\u8fc7\u7cbe\u786e\u8ba1\u7b97\u7531\u6837\u672c\u6784\u5efa\u7684\u9ad8\u65af\u6df7\u5408\u5148\u9a8c\u4e0b\u7684\u6761\u4ef6score\uff0c\u5f15\u5bfc\u65e0\u76d1\u7763\u6269\u6563\u6a21\u578b\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u751f\u6210\u6761\u4ef6\u566a\u58f0\u6807\u6ce8\u6837\u672c\u3002\u7b2c\u4e8c\u9636\u6bb5\uff0c\u5229\u7528\u751f\u6210\u7684\u566a\u58f0-\u6807\u7b7e\u6570\u636e\uff0c\u8bad\u7ec3\u4e00\u4e2a\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff0c\u5c06\u566a\u58f0\u548c\u89c2\u6d4b\u76f4\u63a5\u6620\u5c04\u4e3a\u540e\u9a8c\u6837\u672c\uff0c\u4ece\u800c\u907f\u514d\u6a21\u578b\u7ed3\u6784\u53ef\u9006\u6027\u548c\u63a8\u65ad\u8fc7\u7a0b\u8fed\u4ee3\u91c7\u6837\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u9ad8\u7ef4\u5ea6\u3001\u591a\u5cf0\u540e\u9a8c\u5206\u5e03\u7684\u6761\u4ef6\u91c7\u6837\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u5feb\u901f\u3001\u7cbe\u51c6\u3001\u53ef\u6269\u5c55\u7684\u63a8\u65ad\uff0c\u5728\u590d\u6742\u7269\u7406\u7cfb\u7edf\u53c2\u6570\u4f30\u8ba1\u7b49\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4efb\u52a1\u4e0a\u663e\u793a\u4e86\u4f18\u8d8a\u6027\u3002\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6269\u6563\u6a21\u578b\u4e0e\u975e\u53ef\u9006\u795e\u7ecf\u7f51\u7edc\u7684\u6761\u4ef6\u751f\u6210\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6761\u4ef6\u63a8\u65ad\u7684\u6548\u7387\u4e0e\u8868\u8fbe\u80fd\u529b\uff0c\u4e3a\u9ad8\u590d\u6742\u5ea6\u7cfb\u7edf\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.17352", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17352", "abs": "https://arxiv.org/abs/2506.17352", "authors": ["Tatsuhiro Aoshima", "Mitsuaki Akiyama"], "title": "Towards Safety Evaluations of Theory of Mind in Large Language Models", "comment": null, "summary": "As the capabilities of large language models (LLMs) continue to advance, the\nimportance of rigorous safety evaluation is becoming increasingly evident.\nRecent concerns within the realm of safety assessment have highlighted\ninstances in which LLMs exhibit behaviors that appear to disable oversight\nmechanisms and respond in a deceptive manner. For example, there have been\nreports suggesting that, when confronted with information unfavorable to their\nown persistence during task execution, LLMs may act covertly and even provide\nfalse answers to questions intended to verify their behavior.To evaluate the\npotential risk of such deceptive actions toward developers or users, it is\nessential to investigate whether these behaviors stem from covert, intentional\nprocesses within the model. In this study, we propose that it is necessary to\nmeasure the theory of mind capabilities of LLMs. We begin by reviewing existing\nresearch on theory of mind and identifying the perspectives and tasks relevant\nto its application in safety evaluation. Given that theory of mind has been\npredominantly studied within the context of developmental psychology, we\nanalyze developmental trends across a series of open-weight LLMs. Our results\nindicate that while LLMs have improved in reading comprehension, their theory\nof mind capabilities have not shown comparable development. Finally, we present\nthe current state of safety evaluation with respect to LLMs' theory of mind,\nand discuss remaining challenges for future work.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\uff0c\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7406\u89e3\u80fd\u529b\u589e\u5f3a\uff0c\u4f46\u7406\u8bba\u5fc3\u7406\uff08\u5373\u7406\u89e3\u548c\u63a8\u65ad\u4ed6\u4eba\u610f\u56fe\u53ca\u8ba4\u77e5\u72b6\u6001\u7684\u80fd\u529b\uff09\u5e76\u672a\u540c\u6b65\u63d0\u5347\u3002\u8be5\u56e0\u7d20\u662f\u8bc4\u4f30\u6a21\u578b\u5b89\u5168\u6027\u3001\u68c0\u6d4b\u6b3a\u9a97\u6027\u884c\u4e3a\u7684\u6838\u5fc3\u3002\u6587\u4e2d\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u5f00\u6e90LLMs\u5728\u8be5\u65b9\u9762\u7684\u53d1\u5c55\uff0c\u7ed3\u679c\u663e\u793a\u7406\u8bba\u5fc3\u7406\u80fd\u529b\u63d0\u5347\u6709\u9650\uff0c\u73b0\u9636\u6bb5\u5b89\u5168\u8bc4\u4f30\u548c\u98ce\u9669\u8bc6\u522b\u4f9d\u7136\u56f0\u96be\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u529b\u7684\u63d0\u5347\uff0c\u6a21\u578b\u5b89\u5168\u6027\u8bc4\u4f30\u9700\u6c42\u65e5\u76ca\u8feb\u5207\uff0c\u5c24\u5176\u662f\u6709\u5173\u6a21\u578b\u53ef\u80fd\u4ee5\u9690\u853d\u548c\u6b3a\u9a97\u6027\u65b9\u5f0f\u7ed5\u8fc7\u76d1\u7ba1\u673a\u5236\u7684\u62c5\u5fe7\u3002\u4f5c\u8005\u5e0c\u671b\u786e\u8ba4LLMs\u662f\u5426\u5b58\u5728\u901a\u8fc7\u7406\u8bba\u578b\u5fc3\u7406\u673a\u5236\u6709\u610f\u63a9\u9970\u884c\u4e3a\u7684\u98ce\u9669\u3002", "method": "\u56de\u987e\u548c\u5206\u6790\u5173\u4e8e\u7406\u8bba\u5fc3\u7406\uff08theory of mind\uff09\u7684\u73b0\u6709\u7814\u7a76\uff0c\u63d0\u70bc\u5176\u5728\u5b89\u5168\u8bc4\u4f30\u4e2d\u7684\u76f8\u5173\u4efb\u52a1\u548c\u89c6\u89d2\uff0c\u7136\u540e\u9009\u53d6\u591a\u4e2a\u5f00\u6e90\u6743\u91cdLLMs\uff0c\u901a\u8fc7\u4e0e\u5fc3\u7406\u53d1\u5c55\u8d8b\u52bf\u76f8\u5173\u7684\u4efb\u52a1\u8bc4\u4f30\u5176\u7406\u8bba\u5fc3\u7406\u80fd\u529b\u53d1\u5c55\u60c5\u51b5\u3002", "result": "LLMs\u5728\u9605\u8bfb\u7406\u89e3\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\uff0c\u4f46\u5176\u7406\u8bba\u5fc3\u7406\u80fd\u529b\u7684\u53d1\u5c55\u5e76\u4e0d\u660e\u663e\uff0c\u4e0e\u9605\u8bfb\u7406\u89e3\u7684\u63d0\u5347\u4e0d\u76f8\u5f53\u3002", "conclusion": "\u76ee\u524dLLMs\u7684\u7406\u8bba\u5fc3\u7406\u80fd\u529b\u6709\u9650\uff0c\u5728\u5b89\u5168\u8bc4\u4f30\u4e2d\u7279\u522b\u662f\u5728\u8bc6\u522b\u6f5c\u5728\u6b3a\u9a97\u884c\u4e3a\u65b9\u9762\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u672a\u6765\u4ecd\u9700\u9488\u5bf9\u5176\u7406\u8bba\u5fc3\u7406\u80fd\u529b\u7684\u63d0\u5347\u8fdb\u884c\u6df1\u5165\u7814\u7a76\u3002"}}
{"id": "2506.17585", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17585", "abs": "https://arxiv.org/abs/2506.17585", "authors": ["Yukun Huang", "Sanxing Chen", "Jian Pei", "Manzil Zaheer", "Bhuwan Dhingra"], "title": "Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models", "comment": null, "summary": "Trustworthy language models should provide both correct and verifiable\nanswers. While language models can sometimes attribute their outputs to\npretraining data, their citations are often unreliable due to hallucination. As\na result, current systems insert citations by querying an external retriever at\ninference time, introducing latency, infrastructure dependence, and\nvulnerability to retrieval noise. We explore whether LLMs can be made to\nreliably attribute to the documents seen during (continual)\npretraining--without test-time retrieval--by revising the training process. To\nevaluate this, we release CitePretrainBench, a benchmark that mixes real-world\ncorpora (Wikipedia, Common Crawl, arXiv) with novel, unseen documents and\nprobes both short-form (single fact) and long-form (multi-fact) citation tasks.\nOur approach follows a two-stage process: (1) continual pretraining to bind\nfacts to persistent document identifiers, and (2) instruction tuning to elicit\ncitation behavior. We find that simple Passive Indexing, which appends an\nidentifier to each document, helps memorize verbatim text but fails on\nparaphrased or compositional facts. Instead, we propose Active Indexing, which\ncontinually pretrains on synthetic QA pairs that (1) restate each fact in\ndiverse compositional forms, and (2) require bidirectional source-to-fact and\nfact-to-source generation, jointly teaching the model to generate content from\na cited source and to attribute its own answers. Experiments with Qwen2.5-7B\nand 3B show that Active Indexing consistently outperforms Passive Indexing\nacross all tasks and models, with citation precision gains up to 30.2 percent.\nOur ablation studies reveal that performance continues to improve as we scale\nthe amount of augmented data, showing a clear upward trend even at 16 times the\noriginal token count.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51faActive Indexing\u8bad\u7ec3\u6cd5\uff0c\u8ba9\u5927\u6a21\u578b\u65e0\u987b\u6d4b\u8bd5\u65f6\u68c0\u7d22\u5373\u53ef\u53ef\u9760\u5f52\u56e0\u4e8e\u9884\u8bad\u7ec3\u6587\u6863\uff0c\u663e\u8457\u63d0\u5347\u591a\u7c7b\u95ee\u9898\u4e0b\u7684\u5f15\u7528\u7cbe\u5ea6\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u56de\u7b54\u9700\u8981\u53ef\u9a8c\u8bc1\u7684\u5f15\u7528\uff0c\u4f46\u5e38\u5e38\u201c\u5e7b\u89c9\u201d\u4ea7\u751f\u4e0d\u53ef\u9760\u7684\u5f15\u7528\u3002\u4e3b\u6d41\u505a\u6cd5\u901a\u8fc7\u5916\u90e8\u68c0\u7d22\u63d2\u5165\u5f15\u7528\uff0c\u5e26\u6765\u5ef6\u8fdf\u548c\u566a\u58f0\u95ee\u9898\u3002\u4f5c\u8005\u5e0c\u671b\u5728\u4e0d\u4f9d\u8d56\u6d4b\u8bd5\u65f6\u68c0\u7d22\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u9ad8\u6a21\u578b\u81ea\u8eab\u7684\u5f15\u7528\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4e24\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff1a\uff081\uff09\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u5c06\u4e8b\u5b9e\u548c\u6587\u6863ID\u7ed1\u5b9a\uff1b\uff082\uff09\u6307\u4ee4\u5fae\u8c03\u4ee5\u8bf1\u5bfc\u5f15\u7528\u884c\u4e3a\u3002\u6bd4\u8f83\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1aPassive Indexing\uff08\u76f4\u63a5\u9644\u52a0ID\uff09\u4e0eActive Indexing\uff08\u6301\u7eed\u57fa\u4e8e\u5408\u6210QA\u5bf9\u3001\u591a\u6837\u5316\u8868\u8fbe\u8bad\u7ec3\u3001\u4e8b\u5b9e\u4e0e\u6765\u6e90\u53cc\u5411\u751f\u6210\uff09\u3002", "result": "Active Indexing\u5728\u6240\u6709\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u4e8ePassive Indexing\uff0c\u5f15\u7528\u7cbe\u5ea6\u6700\u9ad8\u63d0\u534730.2%\uff1b\u4e14\u968f\u7740\u589e\u5f3a\u6570\u636e\u91cf\u589e\u52a0\uff0c\u6027\u80fd\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u79ef\u6781\u878d\u5408\u6587\u6863\u5f52\u5c5e\u4fe1\u606f\uff0c\u6a21\u578b\u5728\u65e0\u9700\u5b9e\u65f6\u68c0\u7d22\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u5f15\u7528\u51c6\u786e\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002"}}
{"id": "2506.17370", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17370", "abs": "https://arxiv.org/abs/2506.17370", "authors": ["Aditi Madhusudan Jain", "Ayush Jain"], "title": "AI based Content Creation and Product Recommendation Applications in E-commerce: An Ethical overview", "comment": null, "summary": "As e-commerce rapidly integrates artificial intelligence for content creation\nand product recommendations, these technologies offer significant benefits in\npersonalization and efficiency. AI-driven systems automate product\ndescriptions, generate dynamic advertisements, and deliver tailored\nrecommendations based on consumer behavior, as seen in major platforms like\nAmazon and Shopify. However, the widespread use of AI in e-commerce raises\ncrucial ethical challenges, particularly around data privacy, algorithmic bias,\nand consumer autonomy. Bias -- whether cultural, gender-based, or socioeconomic\n-- can be inadvertently embedded in AI models, leading to inequitable product\nrecommendations and reinforcing harmful stereotypes. This paper examines the\nethical implications of AI-driven content creation and product recommendations,\nemphasizing the need for frameworks to ensure fairness, transparency, and need\nfor more established and robust ethical standards. We propose actionable best\npractices to remove bias and ensure inclusivity, such as conducting regular\naudits of algorithms, diversifying training data, and incorporating fairness\nmetrics into AI models. Additionally, we discuss frameworks for ethical\nconformance that focus on safeguarding consumer data privacy, promoting\ntransparency in decision-making processes, and enhancing consumer autonomy. By\naddressing these issues, we provide guidelines for responsibly utilizing AI in\ne-commerce applications for content creation and product recommendations,\nensuring that these technologies are both effective and ethically sound.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u7535\u5546\u4e2dAI\u5185\u5bb9\u751f\u6210\u4e0e\u63a8\u8350\u7684\u4f26\u7406\u98ce\u9669\uff0c\u63d0\u51fa\u4e86\u6d88\u9664\u7b97\u6cd5\u504f\u89c1\u548c\u5f3a\u5316\u4f26\u7406\u6807\u51c6\u7684\u63aa\u65bd\uff0c\u4e3a\u884c\u4e1a\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u5408\u89c4\u64cd\u4f5c\u5efa\u8bae\u3002", "motivation": "\u968f\u7740AI\u5728\u7535\u5546\u7684\u5feb\u901f\u666e\u53ca\uff0c\u5bf9\u5185\u5bb9\u751f\u6210\u53ca\u63a8\u8350\u7684\u9ad8\u6548\u4e2a\u6027\u5316\u5e26\u6765\u597d\u5904\uff0c\u4f46\u4e5f\u5f15\u53d1\u4e86\u5982\u6570\u636e\u9690\u79c1\u3001\u7b97\u6cd5\u504f\u89c1\u548c\u7528\u6237\u81ea\u4e3b\u6743\u7b49\u4e25\u91cd\u4f26\u7406\u95ee\u9898\uff0c\u8feb\u5207\u9700\u8981\u66f4\u5b8c\u5584\u7684\u4f26\u7406\u6807\u51c6\u3002", "method": "\u5206\u6790\u5e76\u603b\u7ed3AI\u7528\u4e8e\u7535\u5546\u5185\u5bb9\u548c\u63a8\u8350\u7cfb\u7edf\u7684\u4f26\u7406\u98ce\u9669\uff0c\u5f52\u7eb3\u4f01\u4e1a\u5e94\u91c7\u7eb3\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u5982\u7b97\u6cd5\u5b9a\u671f\u5ba1\u8ba1\u3001\u591a\u5143\u5316\u8bad\u7ec3\u6570\u636e\u548c\u5f15\u5165\u516c\u5e73\u6027\u6307\u6807\u3002\u540c\u65f6\u63a2\u8ba8\u4e86\u4fdd\u969c\u6570\u636e\u9690\u79c1\u548c\u6d88\u8d39\u8005\u81ea\u4e3b\u6743\u7684\u7b26\u5408\u4f26\u7406\u7684\u6846\u67b6\u3002", "result": "\u5f52\u7eb3\u4e86AI\u5728\u7535\u5546\u9886\u57df\u7684\u4e3b\u8981\u4f26\u7406\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4e86\u51cf\u7f13\u504f\u89c1\u3001\u4fdd\u969c\u516c\u5e73\u548c\u9690\u79c1\u7684\u5b9e\u8df5\u6027\u5efa\u8bae\uff0c\u5bf9\u589e\u5f3aAI\u7cfb\u7edf\u7684\u5305\u5bb9\u6027\u548c\u4f26\u7406\u6027\u5177\u6709\u6307\u5bfc\u4f5c\u7528\u3002", "conclusion": "\u63d0\u51fa\u5e94\u901a\u8fc7\u591a\u9879\u4e3e\u63aa\u6765\u63d0\u5347AI\u5728\u7535\u5546\u5185\u5bb9\u751f\u6210\u548c\u4ea7\u54c1\u63a8\u8350\u4e2d\u7684\u516c\u5e73\u6027\u3001\u900f\u660e\u5ea6\u548c\u5408\u89c4\u6027\uff0c\u5e76\u4e3a\u884c\u4e1a\u63d0\u4f9b\u4e86\u5b9e\u9645\u7684\u9053\u5fb7\u89c4\u8303\u548c\u5efa\u8bae\u3002"}}
{"id": "2506.18427", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.18427", "abs": "https://arxiv.org/abs/2506.18427", "authors": ["Weihang Ouyang", "Yeonjong Shin", "Si-Wei Liu", "Lu Lu"], "title": "Neural-operator element method: Efficient and scalable finite element method enabled by reusable neural operators", "comment": null, "summary": "The finite element method (FEM) is a well-established numerical method for\nsolving partial differential equations (PDEs). However, its mesh-based nature\ngives rise to substantial computational costs, especially for complex\nmultiscale simulations. Emerging machine learning-based methods (e.g., neural\noperators) provide data-driven solutions to PDEs, yet they present challenges,\nincluding high training cost and low model reusability. Here, we propose the\nneural-operator element method (NOEM) by synergistically combining FEM with\noperator learning to address these challenges. NOEM leverages neural operators\n(NOs) to simulate subdomains where a large number of finite elements would be\nrequired if FEM was used. In each subdomain, an NO is used to build a single\nelement, namely a neural-operator element (NOE). NOEs are then integrated with\nstandard finite elements to represent the entire solution through the\nvariational framework. Thereby, NOEM does not necessitate dense meshing and\noffers efficient simulations. We demonstrate the accuracy, efficiency, and\nscalability of NOEM by performing extensive and systematic numerical\nexperiments, including nonlinear PDEs, multiscale problems, PDEs on complex\ngeometries, and discontinuous coefficient fields.", "AI": {"tldr": "NOEM\u7ed3\u5408\u4e86\u6709\u9650\u5143\u548c\u795e\u7ecf\u7b97\u5b50\u7684\u4f18\u70b9\uff0c\u5927\u5e45\u964d\u4f4e\u4e86\u590d\u6742PDE\u6a21\u62df\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9ad8\u6548\u3001\u51c6\u786e\u4e0e\u53ef\u6269\u5c55\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u590d\u6742\u95ee\u9898\u3002", "motivation": "\u6709\u9650\u5143\u65b9\u6cd5\uff08FEM\uff09\u5728\u89e3\u51b3\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDE\uff09\u65b9\u9762\u975e\u5e38\u6210\u719f\uff0c\u4f46\u5176\u57fa\u4e8e\u7f51\u683c\u7684\u7279\u6027\u5bfc\u81f4\u5728\u590d\u6742\u591a\u5c3a\u5ea6\u6a21\u62df\u4e2d\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u8fd1\u5e74\u6765\uff0c\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u795e\u7ecf\u7b97\u5b50\uff08neural operators\uff09\u7b49\u65b9\u6cd5\u4e3aPDE\u63d0\u4f9b\u4e86\u6570\u636e\u9a71\u52a8\u7684\u89e3\u6cd5\uff0c\u4f46\u5b58\u5728\u9ad8\u8bad\u7ec3\u6210\u672c\u548c\u6a21\u578b\u53ef\u590d\u7528\u6027\u4f4e\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b97\u5b50\u5143\u65b9\u6cd5\uff08NOEM\uff09\uff0c\u5c06\u6709\u9650\u5143\u65b9\u6cd5\u4e0e\u795e\u7ecf\u7b97\u5b50\u7ed3\u5408\u3002\u5728\u9700\u8981\u5927\u91cf\u6709\u9650\u5143\u5212\u5206\u7684\u5b50\u57df\u5185\uff0c\u91c7\u7528\u795e\u7ecf\u7b97\u5b50\u6784\u5efa\u5355\u4e2a\u795e\u7ecf\u7b97\u5b50\u5143\uff08NOE\uff09\uff0c\u8fd9\u4e9bNOE\u4e0e\u6807\u51c6\u6709\u9650\u5143\u6574\u5408\uff0c\u901a\u8fc7\u53d8\u5206\u6846\u67b6\u5171\u540c\u8868\u793a\u6574\u4f53\u89e3\uff0c\u4e0d\u9700\u8981\u5bc6\u96c6\u7f51\u683c\u5212\u5206\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u6570\u503c\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86NOEM\u5728\u975e\u7ebf\u6027PDE\u3001\u591a\u5c3a\u5ea6\u95ee\u9898\u3001\u590d\u6742\u51e0\u4f55\u53ca\u4e0d\u8fde\u7eed\u7cfb\u6570\u573a\u4e0a\u7684\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "NOEM\u65b9\u6cd5\u80fd\u591f\u514b\u670d\u4f20\u7edf\u6709\u9650\u5143\u548c\u795e\u7ecf\u7b97\u5b50\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5b9e\u73b0\u4e86\u66f4\u52a0\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684PDE\u6a21\u62df\uff0c\u5728\u590d\u6742\u591a\u5c3a\u5ea6\u95ee\u9898\u4e0a\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002"}}
{"id": "2506.17367", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.17367", "abs": "https://arxiv.org/abs/2506.17367", "authors": ["Mateusz Cedro", "Timour Ichmoukhamedov", "Sofie Goethals", "Yifan He", "James Hinns", "David Martens"], "title": "Cash or Comfort? How LLMs Value Your Inconvenience", "comment": "12 pages, 4 figures, 3 tables", "summary": "Large Language Models (LLMs) are increasingly proposed as near-autonomous\nartificial intelligence (AI) agents capable of making everyday decisions on\nbehalf of humans. Although LLMs perform well on many technical tasks, their\nbehaviour in personal decision-making remains less understood. Previous studies\nhave assessed their rationality and moral alignment with human decisions.\nHowever, the behaviour of AI assistants in scenarios where financial rewards\nare at odds with user comfort has not yet been thoroughly explored. In this\npaper, we tackle this problem by quantifying the prices assigned by multiple\nLLMs to a series of user discomforts: additional walking, waiting, hunger and\npain. We uncover several key concerns that strongly question the prospect of\nusing current LLMs as decision-making assistants: (1) a large variance in\nresponses between LLMs, (2) within a single LLM, responses show fragility to\nminor variations in prompt phrasing (e.g., reformulating the question in the\nfirst person can considerably alter the decision), (3) LLMs can accept\nunreasonably low rewards for major inconveniences (e.g., 1 Euro to wait 10\nhours), and (4) LLMs can reject monetary gains where no discomfort is imposed\n(e.g., 1,000 Euro to wait 0 minutes). These findings emphasize the need for\nscrutiny of how LLMs value human inconvenience, particularly as we move toward\napplications where such cash-versus-comfort trade-offs are made on users'\nbehalf.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\u51e0\u79cd\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u7528\u6237\u4e0d\u9002\u7684\u91d1\u94b1\u4ef7\u503c\u8bc4\u4f30\u975e\u5e38\u4e0d\u4e00\u81f4\u4e14\u5bb9\u6613\u53d7\u63d0\u793a\u63aa\u8f9e\u5f71\u54cd\uff0c\u5076\u5c14\u8fd8\u4f1a\u505a\u51fa\u8fdd\u80cc\u5e38\u7406\u7684\u51b3\u7b56\u3002\u8fd9\u8868\u660e\u73b0\u6709LLMs\u4e0d\u53ef\u9760\u4e8e\u5904\u7406\u6d89\u53ca\u7528\u6237\u8212\u9002\u4e0e\u91d1\u94b1\u6743\u8861\u7684\u51b3\u7b56\u95ee\u9898\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6b63\u88ab\u7528\u4f5c\u80fd\u591f\u66ff\u4eba\u7c7b\u8fdb\u884c\u65e5\u5e38\u51b3\u7b56\u7684\u8fd1\u81ea\u4e3b\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\uff0c\u4f46\u5176\u5728\u6d89\u53ca\u91d1\u94b1\u4e0e\u7528\u6237\u8212\u9002\u5ea6\u6743\u8861\u7684\u4e2a\u4eba\u51b3\u7b56\u884c\u4e3a\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u8ba9\u591a\u4e2aLLM\u9488\u5bf9\u4e0d\u540c\u7c7b\u578b\u7528\u6237\u4e0d\u9002\uff08\u989d\u5916\u6b65\u884c\u3001\u7b49\u5f85\u3001\u9965\u997f\u548c\u75bc\u75db\uff09\uff0c\u91cf\u5316\u5176\u6240\u9700\u8865\u507f\u4ef7\u683c\uff0c\u5e76\u5206\u6790LLM\u4e4b\u95f4\u53ca\u540c\u4e00LLM\u5185\u5bf9\u63d0\u793a\u53d8\u5316\u7684\u53cd\u5e94\u5dee\u5f02\u3002", "result": "\u53d1\u73b01\uff09\u4e0d\u540cLLM\u7ed9\u51fa\u7684\u8865\u507f\u4ef7\u683c\u5dee\u5f02\u6781\u5927\uff1b2\uff09\u5355\u4e2aLLM\u5bf9\u63d0\u793a\u65b9\u5f0f\u975e\u5e38\u654f\u611f\uff0c\u8f7b\u5fae\u63aa\u8f9e\u53d8\u5316\u5c31\u4f1a\u663e\u8457\u6539\u53d8\u51b3\u7b56\uff1b3\uff09LLM\u5f80\u5f80\u613f\u610f\u4ee5\u6781\u4f4e\u8865\u507f\u63a5\u53d7\u91cd\u5927\u4e0d\u4fbf\uff08\u5982\u75281\u6b27\u5143\u6362\u53d610\u5c0f\u65f6\u7b49\u5f85\uff09\uff1b4\uff09\u5728\u6ca1\u6709\u4efb\u4f55\u4e0d\u9002\u7684\u60c5\u51b5\u4e0b\uff0cLLM\u6709\u65f6\u4f1a\u62d2\u7edd\u660e\u663e\u5956\u52b1\uff08\u59821000\u6b27\u5143\u63620\u5206\u949f\u7b49\u5f85\uff09\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u8861\u91cf\u4eba\u7c7b\u4e0d\u4fbf\u7684\u91d1\u94b1\u4ef7\u503c\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u4e0d\u4e00\u81f4\u548c\u6f0f\u6d1e\uff0c\u56e0\u6b64\u5728\u4f5c\u4e3a\u51b3\u7b56\u52a9\u624b\u5e94\u7528\u65f6\u6709\u5fc5\u8981\u8fdb\u884c\u66f4\u4e25\u8c28\u7684\u5ba1\u67e5\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u91d1\u94b1\u4e0e\u8212\u9002\u6743\u8861\u7684\u573a\u666f\u3002"}}
{"id": "2506.17589", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17589", "abs": "https://arxiv.org/abs/2506.17589", "authors": ["Bowen Wang"], "title": "Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to Conquer the Unknown", "comment": null, "summary": "The real value of knowledge lies not just in its accumulation, but in its\npotential to be harnessed effectively to conquer the unknown. Although recent\nmultimodal large language models (MLLMs) exhibit impressing multimodal\ncapabilities, they often fail in rarely encountered domain-specific tasks due\nto limited relevant knowledge. To explore this, we adopt visual game cognition\nas a testbed and select Monster Hunter: World as the target to construct a\nmultimodal knowledge graph (MH-MMKG), which incorporates multi-modalities and\nintricate entity relations. We also design a series of challenging queries\nbased on MH-MMKG to evaluate the models' ability for complex knowledge\nretrieval and reasoning. Furthermore, we propose a multi-agent retriever that\nenables a model to autonomously search relevant knowledge without additional\ntraining. Experimental results show that our approach significantly enhances\nthe performance of MLLMs, providing a new perspective on multimodal\nknowledge-augmented reasoning and laying a solid foundation for future\nresearch.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u6e38\u620f\u9886\u57df\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u8bbe\u8ba1\u590d\u6742\u68c0\u7d22\u4e0e\u63a8\u7406\u6d4b\u8bd5\uff0c\u5f15\u5165\u591a\u667a\u80fd\u4f53\u68c0\u7d22\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u76f8\u5173\u80fd\u529b\uff0c\u4e3a\u591a\u6a21\u6001\u77e5\u8bc6\u589e\u5f3a\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u5e38\u89c1\u4efb\u52a1\u8868\u73b0\u4f18\u79c0\uff0c\u4f46\u5728\u7f55\u89c1\u9886\u57df\u4efb\u52a1\u4e2d\u5e38\u56e0\u77e5\u8bc6\u4e0d\u8db3\u800c\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u6b64\u4e9f\u9700\u63a2\u7d22\u63d0\u5347\u5176\u7f55\u89c1\u9886\u57df\u77e5\u8bc6\u5229\u7528\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u4ee5\u89c6\u89c9\u6e38\u620f\u8ba4\u77e5\u4e3a\u5b9e\u9a8c\u5e73\u53f0\uff0c\u9009\u62e9\u300a\u602a\u7269\u730e\u4eba\uff1a\u4e16\u754c\u300b\u4f5c\u4e3a\u76ee\u6807\uff0c\u6784\u5efa\u4e86\u6db5\u76d6\u591a\u6a21\u6001\u548c\u590d\u6742\u5b9e\u4f53\u5173\u7cfb\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\uff08MH-MMKG\uff09\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86\u590d\u6742\u77e5\u8bc6\u68c0\u7d22\u548c\u63a8\u7406\u6311\u6218\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u68c0\u7d22\u5668\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u81ea\u52a8\u68c0\u7d22\u76f8\u5173\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u590d\u6742\u77e5\u8bc6\u68c0\u7d22\u548c\u63a8\u7406\u65b9\u9762\u7684\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u548c\u591a\u667a\u80fd\u4f53\u68c0\u7d22\u673a\u5236\uff0c\u63a8\u52a8\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u590d\u6742\u9886\u57df\u77e5\u8bc6\u5229\u7528\u548c\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u8fdb\u6b65\uff0c\u4e3a\u672a\u6765\u591a\u6a21\u6001\u77e5\u8bc6\u589e\u5f3a\u63a8\u7406\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.17372", "categories": ["cs.CY", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.17372", "abs": "https://arxiv.org/abs/2506.17372", "authors": ["Cedric Bernard", "Xavier Pleimling", "Amun Kharel", "Chase Vickery"], "title": "Multimodal Political Bias Identification and Neutralization", "comment": null, "summary": "Due to the presence of political echo chambers, it becomes imperative to\ndetect and remove subjective bias and emotionally charged language from both\nthe text and images of political articles. However, prior work has focused on\nsolely the text portion of the bias rather than both the text and image\nportions. This is a problem because the images are just as powerful of a medium\nto communicate information as text is. To that end, we present a model that\nleverages both text and image bias which consists of four different steps.\nImage Text Alignment focuses on semantically aligning images based on their\nbias through CLIP models. Image Bias Scoring determines the appropriate bias\nscore of images via a ViT classifier. Text De-Biasing focuses on detecting\nbiased words and phrases and neutralizing them through BERT models. These three\nsteps all culminate to the final step of debiasing, which replaces the text and\nthe image with neutralized or reduced counterparts, which for images is done by\ncomparing the bias scores. The results so far indicate that this approach is\npromising, with the text debiasing strategy being able to identify many\npotential biased words and phrases, and the ViT model showcasing effective\ntraining. The semantic alignment model also is efficient. However, more time,\nparticularly in training, and resources are needed to obtain better results. A\nhuman evaluation portion was also proposed to ensure semantic consistency of\nthe newly generated text and images.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u6587\u672c\u4e0e\u56fe\u50cf\u504f\u89c1\u68c0\u6d4b\u4e0e\u53bb\u9664\u7684\u6a21\u578b\uff0c\u521d\u6b65\u5b9e\u9a8c\u6548\u679c\u826f\u597d\uff0c\u4f46\u8fd8\u9700\u63d0\u9ad8\u8bad\u7ec3\u529b\u5ea6\u4e0e\u8d44\u6e90\u6295\u5165\uff0c\u4eba\u5de5\u8bc4\u4f30\u786e\u4fdd\u65b0\u5185\u5bb9\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u5173\u4e8e\u653f\u6cbb\u56de\u97f3\u5ba4\u7684\u95ee\u9898\u8981\u6c42\u5bf9\u653f\u6cbb\u6587\u7ae0\u4e2d\u7684\u4e3b\u89c2\u504f\u89c1\u548c\u60c5\u7eea\u5316\u8bed\u8a00\u8fdb\u884c\u68c0\u6d4b\u4e0e\u53bb\u9664\uff0c\u4f46\u4ee5\u5f80\u7684\u7814\u7a76\u53ea\u5173\u6ce8\u6587\u672c\u90e8\u5206\uff0c\u5ffd\u89c6\u4e86\u56fe\u50cf\u90e8\u5206\uff0c\u800c\u56fe\u50cf\u540c\u6837\u662f\u91cd\u8981\u7684\u4fe1\u606f\u4f20\u9012\u5a92\u4ecb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u6587\u672c\u4e0e\u56fe\u50cf\u504f\u89c1\u7684\u6a21\u578b\uff0c\u5305\u62ec\u56db\u4e2a\u6b65\u9aa4\uff1a1\uff09\u56fe\u50cf\u6587\u672c\u5bf9\u9f50\uff08\u901a\u8fc7CLIP\u5bf9\u6a21\u578b\u504f\u89c1\u8fdb\u884c\u8bed\u4e49\u5bf9\u9f50\uff09\uff1b2\uff09\u56fe\u50cf\u504f\u89c1\u8bc4\u5206\uff08\u5229\u7528ViT\u5206\u7c7b\u5668\u4e3a\u56fe\u50cf\u6253\u5206\uff09\uff1b3\uff09\u6587\u672c\u53bb\u504f\u89c1\uff08\u7528BERT\u68c0\u6d4b\u5e76\u4e2d\u548c\u504f\u89c1\u8bcd\u53e5\uff09\uff1b4\uff09\u6700\u7ec8\u53bb\u504f\u89c1\uff08\u7528\u4f4e\u504f\u89c1\u7684\u6587\u672c\u53ca\u56fe\u50cf\u66ff\u6362\u539f\u5185\u5bb9\uff09\u3002\u8fd8\u8bbe\u8ba1\u4e86\u4eba\u5de5\u8bc4\u4f30\uff0c\u65b0\u751f\u6210\u7684\u6587\u672c\u548c\u56fe\u50cf\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "result": "\u6587\u672c\u53bb\u504f\u89c1\u65b9\u6cd5\u53ef\u4ee5\u8bc6\u522b\u5927\u91cf\u6f5c\u5728\u7684\u504f\u89c1\u8bcd\u548c\u504f\u89c1\u77ed\u8bed\uff0cViT\u56fe\u50cf\u504f\u89c1\u6a21\u578b\u8bad\u7ec3\u6548\u679c\u4e5f\u8f83\u597d\uff0c\u8bed\u4e49\u5bf9\u9f50\u6a21\u5757\u6548\u7387\u9ad8\u3002\u4f46\u5b9e\u73b0\u66f4\u597d\u7ed3\u679c\u8fd8\u9700\u66f4\u591a\u8bad\u7ec3\u65f6\u95f4\u4e0e\u8d44\u6e90\u3002", "conclusion": "\u672c\u6587\u8054\u5408\u5229\u7528\u6587\u672c\u548c\u56fe\u50cf\u4fe1\u606f\u8fdb\u884c\u53bb\u504f\u89c1\uff0c\u65b9\u6cd5\u6548\u679c\u521d\u6b65\u9a8c\u8bc1\u6709\u6548\uff0c\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u8bad\u7ec3\u548c\u8d44\u6e90\u6295\u5165\u63d0\u5347\u6027\u80fd\uff1b\u4eba\u5de5\u8bc4\u4f30\u786e\u4fdd\u751f\u6210\u5185\u5bb9\u8bed\u4e49\u4e00\u81f4\u6027\u3002"}}
{"id": "2506.18554", "categories": ["cs.CE", "cond-mat.mtrl-sci", "physics.app-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2506.18554", "abs": "https://arxiv.org/abs/2506.18554", "authors": ["J. Wijnen", "J. Parker", "M. Gagliano", "E. Mart\u00ednez-Pa\u00f1eda"], "title": "Virtual failure assessment diagrams for hydrogen transmission pipelines", "comment": null, "summary": "We combine state-of-the-art thermo-metallurgical welding process modelling\nwith coupled diffusion-elastic-plastic phase field fracture simulations to\npredict the failure states of hydrogen transport pipelines. This enables\nquantitatively resolving residual stress states and the role of brittle, hard\nregions of the weld such as the heat affected zone (HAZ). Failure pressures can\nbe efficiently quantified as a function of asset state (existing defects),\nmaterials and weld procedures adopted, and hydrogen purity. Importantly,\nsimulations spanning numerous relevant conditions (defect size and\norientations) are used to build \\emph{Virtual} Failure Assessment Diagrams\n(FADs), enabling a straightforward uptake of this mechanistic approach in\nfitness-for-service assessment. Model predictions are in very good agreement\nwith FAD approaches from the standards but show that the latter are not\nconservative when resolving the heterogeneous nature of the weld\nmicrostructure. Appropriate, \\emph{mechanistic} FAD safety factors are\nestablished that account for the role of residual stresses and hard, brittle\nweld regions.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u7ed3\u5408\u5148\u8fdb\u5de5\u827a\u5efa\u6a21\u4e0e\u76f8\u573a\u65ad\u88c2\u4eff\u771f\u7684\u65b0\u65b9\u6cd5\uff0c\u5b9a\u91cf\u5206\u6790\u6c22\u8f93\u8fd0\u7ba1\u9053\u6c22\u8106\u5931\u6548\u7684\u5173\u952e\u56e0\u7d20\uff0c\u751f\u6210\u66f4\u7cbe\u51c6\u7684\u5931\u6548\u8bc4\u4f30\u56fe\uff0c\u53d1\u73b0\u73b0\u6709\u6807\u51c6\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u4fdd\u5b88\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u7684\u5b89\u5168\u7cfb\u6570\u5efa\u8bae\u3002", "motivation": "\u6c22\u6c14\u8fd0\u8f93\u7ba1\u9053\u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7531\u710a\u63a5\u5de5\u827a\u548c\u6750\u6599\u7279\u6027\u5bfc\u81f4\u7684\u7ed3\u6784\u8106\u5316\u548c\u5931\u6548\u98ce\u9669\uff0c\u73b0\u6709\u6807\u51c6\u4e2d\u6545\u969c\u8bc4\u4f30\u65b9\u6cd5\uff08FAD\uff09\u5bf9\u710a\u7f1d\u5fae\u89c2\u7ed3\u6784\u5f02\u8d28\u6027\u548c\u6b8b\u4f59\u5e94\u529b\u7684\u8003\u8651\u4e0d\u8db3\uff0c\u53ef\u80fd\u5bfc\u81f4\u5b89\u5168\u6027\u8bc4\u4f30\u4e0d\u51c6\u786e\u3002", "method": "\u5c06\u5148\u8fdb\u7684\u70ed-\u51b6\u91d1\u710a\u63a5\u8fc7\u7a0b\u5efa\u6a21\u4e0e\u76f8\u573a\u65ad\u88c2\u6a21\u62df\uff08\u5305\u62ec\u8026\u5408\u6269\u6563\u2014\u5f39\u5851\u6027\uff09\u7ed3\u5408\uff0c\u5b9a\u91cf\u5206\u6790\u710a\u7f1d\u6b8b\u4f59\u5e94\u529b\u3001\u70ed\u5f71\u54cd\u533a\uff08HAZ\uff09\u7684\u8106\u786c\u533a\u57df\u4f5c\u7528\uff0c\u5e76\u6a21\u62df\u5404\u79cd\u7f3a\u9677\u6001\u3001\u6750\u6599\u3001\u710a\u63a5\u5de5\u827a\u548c\u6c22\u7eaf\u5ea6\u6761\u4ef6\u4e0b\u7684\u5931\u6548\u60c5\u51b5\u3002\u8fdb\u4e00\u6b65\uff0c\u57fa\u4e8e\u5e7f\u6cdb\u4eff\u771f\u7ed3\u679c\u6784\u5efa\u865a\u62dfFAD\u56fe\u8868\uff0c\u5b9e\u73b0\u673a\u7406\u9a71\u52a8\u7684\u670d\u5f79\u5b89\u5168\u6027\u8bc4\u4f30\u6d41\u7a0b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6a21\u578b\u9884\u6d4b\u4e0e\u73b0\u6709FAD\u6807\u51c6\u543b\u5408\u826f\u597d\uff0c\u4f46\u63ed\u793a\u6807\u51c6FAD\u672a\u80fd\u4fdd\u5b88\u5730\u53cd\u6620\u710a\u7f1d\u5fae\u89c2\u7ed3\u6784\u5f02\u8d28\u6027\u5bf9\u5931\u6548\u538b\u529b\u7684\u5f71\u54cd\u3002\u63d0\u51fa\u4e86\u53ef\u8865\u507f\u6b8b\u4f59\u5e94\u529b\u548c\u8106\u786c\u710a\u7f1d\u533a\u57df\u5f71\u54cd\u7684\u673a\u7406\u5316FAD\u5b89\u5168\u7cfb\u6570\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6c22\u6c14\u7ba1\u9053\u670d\u5f79\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cf\u5316\u3001\u673a\u7406\u5316\u7684\u624b\u6bb5\uff0c\u80fd\u66f4\u51c6\u786e\u8003\u8651\u710a\u7f1d\u7ec6\u8282\u4e0e\u7f3a\u9677\u60c5\u51b5\uff0c\u4f18\u5316\u73b0\u6709\u5b89\u5168\u6807\u51c6\u5e76\u63d0\u5347\u98ce\u9669\u8bc4\u4f30\u53ef\u9760\u6027\u3002"}}
{"id": "2506.17410", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17410", "abs": "https://arxiv.org/abs/2506.17410", "authors": ["Danielle R. Thomas", "Conrad Borchers", "Jionghao Lin", "Sanjit Kakarla", "Shambhavi Bhushan", "Erin Gatz", "Shivang Gupta", "Ralph Abboud", "Kenneth R. Koedinger"], "title": "Leveraging LLMs to Assess Tutor Moves in Real-Life Dialogues: A Feasibility Study", "comment": "Short research paper accepted at EC-TEL 2025", "summary": "Tutoring improves student achievement, but identifying and studying what\ntutoring actions are most associated with student learning at scale based on\naudio transcriptions is an open research problem. This present study\ninvestigates the feasibility and scalability of using generative AI to identify\nand evaluate specific tutor moves in real-life math tutoring. We analyze 50\nrandomly selected transcripts of college-student remote tutors assisting middle\nschool students in mathematics. Using GPT-4, GPT-4o, GPT-4-turbo,\nGemini-1.5-pro, and LearnLM, we assess tutors' application of two tutor skills:\ndelivering effective praise and responding to student math errors. All models\nreliably detected relevant situations, for example, tutors providing praise to\nstudents (94-98% accuracy) and a student making a math error (82-88% accuracy)\nand effectively evaluated the tutors' adherence to tutoring best practices,\naligning closely with human judgments (83-89% and 73-77%, respectively). We\npropose a cost-effective prompting strategy and discuss practical implications\nfor using large language models to support scalable assessment in authentic\nsettings. This work further contributes LLM prompts to support reproducibility\nand research in AI-supported learning.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u4ee5GPT-4\u7b49\u5927\u6a21\u578b\u5206\u6790\u5bb6\u6559\u8bed\u97f3\u8f6c\u5f55\u6587\u672c\uff0c\u80fd\u9ad8\u6548\u3001\u51c6\u786e\u8bc4\u4f30\u5173\u952e\u5bb6\u6559\u884c\u4e3a\uff0c\u4e14\u4e0e\u4eba\u5de5\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\uff0c\u63d0\u51fa\u4e86\u53ef\u6269\u5c55\u4f4e\u6210\u672c\u7684AI\u8f85\u52a9\u5bb6\u6559\u8bc4\u4f30\u65b9\u6848\uff0c\u5e76\u5f00\u653e\u63d0\u793a\u8bcd\u4fc3\u8fdb\u53ef\u590d\u73b0\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u5bb6\u6559\u5728\u63d0\u5347\u5b66\u751f\u5b66\u4e60\u6210\u7ee9\u4e0a\u6548\u679c\u663e\u8457\uff0c\u4f46\u5982\u4f55\u57fa\u4e8e\u5927\u89c4\u6a21\u97f3\u9891\u8f6c\u5f55\u8bb0\u5f55\u81ea\u52a8\u8bc6\u522b\u548c\u7814\u7a76\u6709\u6548\u7684\u5bb6\u6559\u884c\u4e3a\u4ecd\u662f\u96be\u9898\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u91c7\u7528\u751f\u6210\u5f0fAI\uff08\u5c24\u5176\u5927\u8bed\u8a00\u6a21\u578b\uff09\u6765\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u5730\u8bc6\u522b\u548c\u8bc4\u4f30\u771f\u5b9e\u6570\u5b66\u5bb6\u6559\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u884c\u4e3a\u3002", "method": "\u5bf950\u4efd\u771f\u5b9e\u7684\u5927\u5b66\u751f\u8fdc\u7a0b\u8f85\u5bfc\u4e2d\u5b66\u751f\u6570\u5b66\u7684\u97f3\u9891\u8f6c\u5f55\u6587\u672c\uff0c\u5206\u522b\u7528GPT-4\u3001GPT-4o\u3001GPT-4-turbo\u3001Gemini-1.5-pro\u548cLearnLM\u4e94\u4e2a\u5927\u6a21\u578b\uff0c\u68c0\u6d4b\u4e24\u4e2a\u5173\u952e\u5bb6\u6559\u6280\u80fd\uff1a\u6709\u6548\u79f0\u8d5e\u548c\u5bf9\u5b66\u751f\u6570\u5b66\u9519\u8bef\u7684\u56de\u5e94\u3002\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u68c0\u6d4b\u76f8\u5173\u573a\u666f\uff08\u5982\u5bb6\u6559\u79f0\u8d5e\u5b66\u751f\u3001\u5b66\u751f\u51fa\u73b0\u9519\u8bef\uff09\u7684\u51c6\u786e\u7387\uff0c\u4ee5\u53ca\u6a21\u578b\u5224\u65ad\u8f85\u5bfc\u884c\u4e3a\u662f\u5426\u7b26\u5408\u6700\u4f73\u5b9e\u8df5\u7684\u8868\u73b0\uff0c\u5e76\u4e0e\u4eba\u5de5\u6807\u6ce8\u7ed3\u679c\u8fdb\u884c\u6bd4\u5bf9\u3002", "result": "\u5404\u5927\u8bed\u8a00\u6a21\u578b\u90fd\u80fd\u8f83\u9ad8\u51c6\u786e\u7387\u68c0\u6d4b\u5173\u952e\u60c5\u5883\uff08\u5982\u79f0\u8d5e\u68c0\u6d4b\u51c6\u786e\u7387\u4e3a94-98%\uff0c\u9519\u8bef\u68c0\u6d4b\u4e3a82-88%\uff09\uff1b\u6a21\u578b\u8bc4\u5224\u5bb6\u6559\u662f\u5426\u7b26\u5408\u6700\u4f73\u5b9e\u8df5\u7684\u7ed3\u679c\u4e0e\u4eba\u5de5\u4e00\u81f4\u6027\u8f83\u9ad8\uff08\u5206\u522b\u4e3a83-89%\u548c73-77%\uff09\u3002\u8bba\u6587\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u6027\u4ef7\u6bd4\u9ad8\u7684\u6a21\u578b\u63d0\u793a\u8bcd\u7b56\u7565\uff0c\u5e76\u5f00\u653e\u76f8\u5173\u63d0\u793a\u8bcd\u4ee5\u4fc3\u8fdb\u53ef\u590d\u73b0\u6027\u3002", "conclusion": "\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u51c6\u786e\u3001\u9ad8\u6548\u5730\u5728\u5927\u89c4\u6a21\u771f\u5b9e\u5bb6\u6559\u573a\u666f\u4e2d\u68c0\u6d4b\u548c\u8bc4\u4ef7\u5173\u952e\u6559\u5b66\u884c\u4e3a\uff0c\u4e3aAI\u8f85\u52a9\u7684\u5927\u89c4\u6a21\u5bb6\u6559\u8bc4\u4ef7\u548c\u6559\u80b2\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002\u8bba\u6587\u5efa\u8bae\u76f8\u5173\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u53ef\u501f\u52a9\u8fd9\u4e9b\u6a21\u578b\u4e0e\u7b56\u7565\uff0c\u5b9e\u73b0\u4f4e\u6210\u672c\u3001\u9ad8\u6548\u7684\u5bb6\u6559\u8fc7\u7a0b\u5206\u6790\u548c\u53cd\u9988\u3002"}}
{"id": "2506.17644", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17644", "abs": "https://arxiv.org/abs/2506.17644", "authors": ["Zimo Ji", "Daoyuan Wu", "Wenyuan Jiang", "Pingchuan Ma", "Zongjie Li", "Shuai Wang"], "title": "Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges", "comment": null, "summary": "Capture-the-Flag (CTF) competitions are crucial for cybersecurity education\nand training. As large language models (LLMs) evolve, there is increasing\ninterest in their ability to automate CTF challenge solving. For example, DARPA\nhas organized the AIxCC competition since 2023 to advance AI-powered automated\noffense and defense. However, this demands a combination of multiple abilities,\nfrom knowledge to reasoning and further to actions. In this paper, we highlight\nthe importance of technical knowledge in solving CTF problems and deliberately\nconstruct a focused benchmark, CTFKnow, with 3,992 questions to measure LLMs'\nperformance in this core aspect. Our study offers a focused and innovative\nmeasurement of LLMs' capability in understanding CTF knowledge and applying it\nto solve CTF challenges. Our key findings reveal that while LLMs possess\nsubstantial technical knowledge, they falter in accurately applying this\nknowledge to specific scenarios and adapting their strategies based on feedback\nfrom the CTF environment.\n  Based on insights derived from this measurement study, we propose CTFAgent, a\nnovel LLM-driven framework for advancing CTF problem-solving. CTFAgent\nintroduces two new modules: two-stage Retrieval Augmented Generation (RAG) and\ninteractive Environmental Augmentation, which enhance LLMs' technical knowledge\nand vulnerability exploitation on CTF, respectively. Our experimental results\nshow that, on two popular CTF datasets, CTFAgent both achieves over 80%\nperformance improvement. Moreover, in the recent picoCTF2024 hosted by CMU,\nCTFAgent ranked in the top 23.6% of nearly 7,000 participating teams. This\nreflects the benefit of our measurement study and the potential of our\nframework in advancing LLMs' capabilities in CTF problem-solving.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51faCTFKnow\u57fa\u51c6\u7cfb\u7edf\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86LLM\u5728CTF\u77e5\u8bc6\u7684\u7406\u89e3\u4e0e\u5e94\u7528\uff0c\u53d1\u73b0LLM\u77e5\u8bc6\u4e30\u5bcc\u4f46\u5b9e\u6218\u8868\u73b0\u53d7\u9650\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86CTFAgent\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u548c\u73af\u5883\u4ea4\u4e92\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89e3\u9898\u80fd\u529b\uff0c\u5728\u5b9e\u9645\u8d5b\u4e8b\u4e2d\u53d6\u5f97\u4f18\u5f02\u6210\u7ee9\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u53d1\u5c55\uff0c\u5176\u5728CTF\uff08\u593a\u65d7\u8d5b\uff09\u81ea\u52a8\u5316\u89e3\u9898\u65b9\u9762\u7684\u6f5c\u529b\u5907\u53d7\u5173\u6ce8\u3002\u5f53\u524d\uff0c\u76f8\u5173\u8d5b\u4e8b\uff08\u5982DARPA\u7684AIxCC\uff09\u65e8\u5728\u63a8\u52a8AI\u5728\u8fdb\u653b\u548c\u9632\u5fa1\u81ea\u52a8\u5316\u4e0a\u7684\u5e94\u7528\u3002\u7136\u800c\uff0cCTF\u81ea\u52a8\u5316\u9700\u8981\u591a\u79cd\u80fd\u529b\u7684\u7ed3\u5408\uff0c\u5c24\u5176\u662f\u6280\u672f\u77e5\u8bc6\u7406\u89e3\u4e0e\u5b9e\u9645\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u7a81\u51fa\u6280\u672f\u77e5\u8bc6\u5728CTF\u89e3\u9898\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u8bc4\u4f30\u73b0\u6709LLM\u5728\u8be5\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86CTFKnow\u57fa\u51c6\u96c6\uff0c\u5305\u542b3992\u9053\u9898\uff0c\u7528\u4e8e\u8861\u91cfLLM\u5728CTF\u6280\u672f\u77e5\u8bc6\u65b9\u9762\u7684\u80fd\u529b\u3002\u901a\u8fc7\u5b9e\u8bc1\u8bc4\u6d4b\u5206\u6790LLM\u7684\u6280\u672f\u77e5\u8bc6\u7406\u89e3\u53ca\u5e94\u7528\uff0c\u5e76\u9488\u5bf9\u53d1\u73b0\u7684\u4e0d\u8db3\u63d0\u51fa\u4e86CTFAgent\u7cfb\u7edf\u3002CTFAgent\u5305\u542b\u4e24\u9636\u6bb5\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e0e\u4ea4\u4e92\u5f0f\u73af\u5883\u589e\u5f3a\u4e24\u4e2a\u65b0\u6a21\u5757\uff0c\u5206\u522b\u63d0\u5347LLM\u7684\u4e13\u4e1a\u77e5\u8bc6\u548c\u6f0f\u6d1e\u5229\u7528\u80fd\u529b\u3002\u6700\u540e\uff0c\u901a\u8fc7\u5728\u4e24\u4e2a\u4e3b\u6d41CTF\u6570\u636e\u96c6\u53capicoCTF2024\u8d5b\u4e8b\u4e2d\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "result": "CTFKnow\u57fa\u51c6\u6d4b\u8bd5\u53d1\u73b0\uff0cLLM\u867d\u7136\u5177\u6709\u4e30\u5bcc\u7684CTF\u6280\u672f\u77e5\u8bc6\uff0c\u4f46\u5728\u5177\u4f53\u573a\u666f\u5e94\u7528\u548c\u57fa\u4e8e\u73af\u5883\u53cd\u9988\u8c03\u6574\u89e3\u9898\u7b56\u7565\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002\u63d0\u51fa\u7684CTFAgent\u6846\u67b6\u5728\u4e24\u4e2aCTF\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u63d0\u5347\u8d85\u8fc780%\uff0c\u5e76\u5728picoCTF2024\u5168\u7403\u6392\u540d\u524d23.6%\u3002", "conclusion": "\u6280\u672f\u77e5\u8bc6\u7406\u89e3\u662fLLM\u81ea\u52a8\u5316\u89e3CTF\u7684\u6838\u5fc3\u6311\u6218\u3002\u9488\u5bf9\u73b0\u6709LLM\u5728\u5e94\u7528\u548c\u9002\u5e94\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u7684CTFAgent\u901a\u8fc7\u589e\u5f3a\u77e5\u8bc6\u68c0\u7d22\u4e0e\u4ea4\u4e92\u663e\u8457\u63d0\u5347\u4e86\u89e3\u9898\u8868\u73b0\uff0c\u5c55\u793a\u4e86AI\u8f85\u52a9CTF\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2506.17510", "categories": ["cs.CY", "cs.DC", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2506.17510", "abs": "https://arxiv.org/abs/2506.17510", "authors": ["Rafael Ferreira da Silva", "Milad Abolhasani", "Dionysios A. Antonopoulos", "Laura Biven", "Ryan Coffee", "Ian T. Foster", "Leslie Hamilton", "Shantenu Jha", "Theresa Mayer", "Benjamin Mintz", "Robert G. Moore", "Salahudin Nimer", "Noah Paulson", "Woong Shin", "Frederic Suter", "Mitra Taheri", "Michela Taufer", "Newell R. Washburn"], "title": "A Grassroots Network and Community Roadmap for Interconnected Autonomous Science Laboratories for Accelerated Discovery", "comment": null, "summary": "Scientific discovery is being revolutionized by AI and autonomous systems,\nyet current autonomous laboratories remain isolated islands unable to\ncollaborate across institutions. We present the Autonomous Interconnected\nScience Lab Ecosystem (AISLE), a grassroots network transforming fragmented\ncapabilities into a unified system that shorten the path from ideation to\ninnovation to impact and accelerates discovery from decades to months. AISLE\naddresses five critical dimensions: (1) cross-institutional equipment\norchestration, (2) intelligent data management with FAIR compliance, (3)\nAI-agent driven orchestration grounded in scientific principles, (4)\ninteroperable agent communication interfaces, and (5) AI/ML-integrated\nscientific education. By connecting autonomous agents across institutional\nboundaries, autonomous science can unlock research spaces inaccessible to\ntraditional approaches while democratizing cutting-edge technologies. This\nparadigm shift toward collaborative autonomous science promises breakthroughs\nin sustainable energy, materials development, and public health.", "AI": {"tldr": "AISLE\u6253\u7834\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u5b64\u5c9b\uff0c\u5b9e\u73b0\u8de8\u673a\u6784\u534f\u4f5c\u4e0e\u8d44\u6e90\u6574\u5408\uff0c\u4ee5AI\u9a71\u52a8\u79d1\u5b66\u7814\u7a76\u521b\u65b0\u5e76\u63d0\u5347\u6559\u80b2\uff0c\u52a9\u529b\u591a\u4e2a\u79d1\u5b66\u9886\u57df\u7684\u91cd\u5927\u7a81\u7834\u3002", "motivation": "\u73b0\u6709\u7684AI\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u591a\u4e3a\u5b64\u7acb\u7cfb\u7edf\uff0c\u7f3a\u4e4f\u8de8\u673a\u6784\u534f\u4f5c\uff0c\u5236\u7ea6\u4e86\u79d1\u5b66\u53d1\u73b0\u7684\u6548\u7387\u53ca\u521b\u65b0\u751f\u6001\u3002", "method": "\u63d0\u51fa\u4e86AISLE\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e94\u4e2a\u5173\u952e\u7ef4\u5ea6\uff08\u8de8\u673a\u6784\u8bbe\u5907\u534f\u540c\u3001\u667a\u80fd\u6570\u636e\u7ba1\u7406\u3001AI\u9a71\u52a8\u7f16\u6392\u3001\u53ef\u4e92\u64cd\u4f5c\u901a\u4fe1\u63a5\u53e3\u3001AI/ML\u8d4b\u80fd\u7684\u79d1\u5b66\u6559\u80b2\uff09\u5b9e\u73b0\u81ea\u6cbb\u5b9e\u9a8c\u5ba4\u7684\u4e92\u8054\u3002", "result": "AISLE\u4e0d\u4ec5\u4fc3\u8fdb\u4e86\u591a\u673a\u6784\u81ea\u52a8\u5316\u7814\u7a76\u534f\u4f5c\uff0c\u8fd8\u4e3a\u53ef\u6301\u7eed\u80fd\u6e90\u3001\u6750\u6599\u5f00\u53d1\u548c\u516c\u5171\u5065\u5eb7\u7b49\u9886\u57df\u5e26\u6765\u91cd\u5927\u521b\u65b0\u6f5c\u529b\u3002", "conclusion": "AISLE\u5b9e\u73b0\u8de8\u673a\u6784\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u7684\u534f\u4f5c\uff0c\u63a8\u52a8\u4ee5AI\u4e3a\u9a71\u52a8\u7684\u79d1\u5b66\u7814\u7a76\u7a81\u7834\u4f20\u7edf\uff0c\u7f29\u77ed\u521b\u65b0\u5468\u671f\uff0c\u4e14\u4fc3\u8fdb\u79d1\u7814\u6c11\u4e3b\u5316\u3002"}}
{"id": "2506.18565", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.18565", "abs": "https://arxiv.org/abs/2506.18565", "authors": ["Zhongya Lin", "Jinshuai Bai", "Shuang Li", "Xindong Chen", "Bo Li", "Xi-Qiao Feng"], "title": "A Physics-Informed Neural Network Framework for Simulating Creep Buckling in Growing Viscoelastic Biological Tissues", "comment": null, "summary": "Modeling viscoelastic behavior is crucial in engineering and biomechanics,\nwhere materials undergo time-dependent deformations, including stress\nrelaxation, creep buckling and biological tissue development. Traditional\nnumerical methods, like the finite element method, often require explicit\nmeshing, artificial perturbations or embedding customised programs to capture\nthese phenomena, adding computational complexity. In this study, we develop an\nenergy-based physics-informed neural network (PINN) framework using an\nincremental approach to model viscoelastic creep, stress relaxation, buckling,\nand growth-induced morphogenesis. Physics consistency is ensured by training\nneural networks to minimize the systems potential energy functional, implicitly\nsatisfying equilibrium and constitutive laws. We demonstrate that this\nframework can naturally capture creep buckling without pre-imposed\nimperfections, leveraging inherent training dynamics to trigger instabilities.\nFurthermore, we extend our framework to biological tissue growth and\nmorphogenesis, predicting both uniform expansion and differential\ngrowth-induced buckling in cylindrical structures. Results show that the\nenergy-based PINN effectively predicts viscoelastic instabilities,\npost-buckling evolution and tissue morphological evolution, offering a\npromising alternative to traditional methods. This study demonstrates that PINN\ncan be a flexible robust tool for modeling complex, time-dependent material\nbehavior, opening possible applications in structural engineering, soft\nmaterials, and tissue development.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u80fd\u91cf\u6700\u5c0f\u5316\u7ea6\u675f\u7684PINN\u65b9\u6cd5\uff0c\u4e0d\u9700\u9884\u8bbe\u7f3a\u9677\u5373\u53ef\u6a21\u62df\u6750\u6599\u65f6\u53d8\u7279\u6027\u4e0e\u590d\u6742\u5f62\u6001\u53d8\u5316\uff0c\u5bf9\u4f20\u7edf\u65b9\u6cd5\u5f62\u6210\u6709\u76ca\u8865\u5145\uff0c\u9002\u7528\u7ed3\u6784\u5de5\u7a0b\u3001\u8f6f\u6750\u6599\u548c\u7ec4\u7ec7\u5de5\u7a0b\u7b49\u5e94\u7528\u3002", "motivation": "\u4f20\u7edf\u6709\u9650\u5143\u7b49\u6570\u503c\u65b9\u6cd5\u5728\u6a21\u62df\u7c98\u5f39\u6027\u7b49\u65f6\u53d8\u6750\u6599\u53d8\u5f62\u65f6\u9700\u663e\u5f0f\u5efa\u7f51\u683c\u3001\u4eba\u5de5\u6270\u52a8\u6216\u5d4c\u5165\u5b9a\u5236\u7a0b\u5e8f\uff0c\u5bfc\u81f4\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002\u4e3a\u7a81\u7834\u8fd9\u4e9b\u9650\u5236\uff0c\u9700\u8981\u4e00\u79cd\u7269\u7406\u4e00\u81f4\u3001\u81ea\u52a8\u89e6\u53d1\u5931\u7a33\u4e14\u7b80\u4fbf\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u80fd\u91cf\u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINN\uff09\u6846\u67b6\uff0c\u91c7\u7528\u589e\u91cf\u5f0f\u65b9\u6cd5\uff0c\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6700\u5c0f\u5316\u7cfb\u7edf\u7684\u52bf\u80fd\u6cdb\u51fd\uff0c\u4ee5\u9690\u5f0f\u6ee1\u8db3\u5e73\u8861\u548c\u672c\u6784\u5173\u7cfb\uff0c\u5b9e\u73b0\u5bf9\u7c98\u5f39\u6027\u8815\u53d8\u3001\u5e94\u529b\u677e\u5f1b\u3001\u5c48\u66f2\u53ca\u7ec4\u7ec7\u751f\u957f\u5f62\u6001\u53d1\u751f\u7684\u6a21\u62df\u3002", "result": "\u8be5\u65b9\u6cd5\u65e0\u9700\u8f93\u5165\u9884\u8bbe\u7f3a\u9677\uff0c\u5373\u53ef\u4f9d\u9760\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u8fc7\u7a0b\u81ea\u53d1\u6355\u6349\u5c48\u66f2\u73b0\u8c61\u3002\u5c06\u5176\u6269\u5c55\u5e94\u7528\u5230\u751f\u7269\u7ec4\u7ec7\u751f\u957f\u548c\u5f62\u6001\u53d1\u751f\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u5706\u67f1\u7ed3\u6784\u7684\u5747\u5300\u6269\u5c55\u4e0e\u5dee\u5f02\u751f\u957f\u5bfc\u81f4\u7684\u5c48\u66f2\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u6b64PINN\u6846\u67b6\u5bf9\u7c98\u5f39\u6027\u5931\u7a33\u3001\u5c48\u66f2\u540e\u6f14\u5316\u548c\u7ec4\u7ec7\u5f62\u6001\u53d8\u5316\u5747\u5177\u6709\u4f18\u79c0\u7684\u9884\u6d4b\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u80fd\u91cf\u7684PINN\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9884\u6d4b\u7c98\u5f39\u6027\u5931\u7a33\u3001\u5c48\u66f2\u540e\u7684\u5f62\u6001\u6f14\u5316\u53ca\u751f\u7269\u7ec4\u7ec7\u7684\u5f62\u6001\u53d8\u5316\uff0c\u662f\u4f20\u7edf\u65b9\u6cd5\u6709\u529b\u7684\u8865\u5145\uff0c\u4e3a\u590d\u6742\u3001\u65f6\u53d8\u6750\u6599\u884c\u4e3a\u5efa\u6a21\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u9c81\u68d2\u7684\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.17419", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.17419", "abs": "https://arxiv.org/abs/2506.17419", "authors": ["Jinhao Duan", "James Diffenderfer", "Sandeep Madireddy", "Tianlong Chen", "Bhavya Kailkhura", "Kaidi Xu"], "title": "UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making", "comment": "19 pages, 5 figures, 4 tables", "summary": "As Large Language Models (LLMs) are integrated into safety-critical\napplications involving sequential decision-making in the real world, it is\nessential to know when to trust LLM decisions. Existing LLM Uncertainty\nQuantification (UQ) methods are primarily designed for single-turn\nquestion-answering formats, resulting in multi-step decision-making scenarios,\ne.g., LLM agentic system, being underexplored. In this paper, we introduce a\nprincipled, information-theoretic framework that decomposes LLM sequential\ndecision uncertainty into two parts: (i) internal uncertainty intrinsic to the\ncurrent decision, which is focused on existing UQ methods, and (ii) extrinsic\nuncertainty, a Mutual-Information (MI) quantity describing how much uncertainty\nshould be inherited from preceding decisions. We then propose UProp, an\nefficient and effective extrinsic uncertainty estimator that converts the\ndirect estimation of MI to the estimation of Pointwise Mutual Information (PMI)\nover multiple Trajectory-Dependent Decision Processes (TDPs). UProp is\nevaluated over extensive multi-step decision-making benchmarks, e.g.,\nAgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and\nDeepSeek-V3. Experimental results demonstrate that UProp significantly\noutperforms existing single-turn UQ baselines equipped with thoughtful\naggregation strategies. Moreover, we provide a comprehensive analysis of UProp,\nincluding sampling efficiency, potential applications, and intermediate\nuncertainty propagation, to demonstrate its effectiveness. Codes will be\navailable at https://github.com/jinhaoduan/UProp.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u591a\u6b65\u51b3\u7b56\u4e0d\u786e\u5b9a\u6027\u957f\u671f\u88ab\u5ffd\u89c6\u3002\u4f5c\u8005\u63d0\u51faUProp\u7b97\u6cd5\uff0c\u6709\u6548\u5206\u89e3\u4e0e\u91cf\u5316\u5916\u5728\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u591a\u4e2a\u591a\u6b65\u4efb\u52a1\u548cSOTA\u6a21\u578b\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684LLM\u5b89\u5168\u53ef\u9760\u51b3\u7b56\u63d0\u4f9b\u65b0\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5b89\u5168\u5173\u952e\u573a\u666f\uff0c\u81ea\u4e3b\u51b3\u7b56\u9010\u6b65\u878d\u5165\u73b0\u5b9e\u4e16\u754c\u3002\u4e3a\u4e86\u63d0\u5347\u6a21\u578b\u53ef\u7528\u6027\uff0c\u7814\u7a76\u4f55\u65f6\u53ef\u4ee5\u4fe1\u4efb\u8fd9\u4e9b\u51b3\u7b56\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\u3002\u4f46\u73b0\u6709\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u65b9\u6cd5\u4e3b\u8981\u9762\u5411\u5355\u6b65\u95ee\u7b54\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u591a\u6b65\u51b3\u7b56\u60c5\u666f\u7684\u6709\u6548\u63a2\u7d22\u4e0e\u5de5\u5177\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u5206\u89e3\u6846\u67b6\uff0c\u5c06LLM\u5728\u8fde\u7eed\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u4e3a\u5185\u5728\u4e0d\u786e\u5b9a\u6027\uff08\u7279\u5b9a\u51b3\u7b56\u70b9\u672c\u8eab\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u73b0\u6709UQ\u8986\u76d6\uff09\u548c\u5916\u5728\u4e0d\u786e\u5b9a\u6027\uff08\u6765\u81ea\u524d\u5e8f\u51b3\u7b56\u7684\u4fe1\u606f\u4e0d\u786e\u5b9a\u6027\uff0c\u4f7f\u7528\u4e92\u4fe1\u606f\u91cf\u5316\uff09\u3002\u8fdb\u800c\uff0c\u6587\u4e2d\u63d0\u51fa\u4e86UProp\u7b97\u6cd5\uff0c\u901a\u8fc7\u5bf9\u591a\u4e2a\u8f68\u8ff9\u76f8\u5173\u51b3\u7b56\u8fc7\u7a0b\uff08TDP\uff09\u4e2d\u7684\u70b9\u4e92\u4fe1\u606f\uff08PMI\uff09\u8fdb\u884c\u4f30\u7b97\uff0c\u6709\u6548\u3001\u9ad8\u6548\u5730\u4f30\u7b97\u5916\u5728\u4e0d\u786e\u5b9a\u6027\u3002", "result": "UProp\u5728\u591a\u6b65\u51b3\u7b56\u4efb\u52a1\uff08\u5982AgentBench\u548cHotpotQA\uff09\u548c\u524d\u6cbfLLM\uff08GPT-4.1\u3001DeepSeek-V3\uff09\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u8bc1\u6d4b\u8bd5\uff0c\u663e\u8457\u4f18\u4e8e\u5355\u6b65\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u57fa\u7ebf\uff08\u8003\u8651\u5148\u8fdb\u805a\u5408\u7b56\u7565\uff09\u7684\u65b9\u6cd5\u3002\u540c\u65f6\u7ed9\u51fa\u4e86\u8be6\u7ec6\u7684\u91c7\u6837\u6548\u7387\u5206\u6790\u3001\u5e94\u7528\u524d\u666f\u63a2\u8ba8\u4ee5\u53ca\u4e2d\u95f4\u4e0d\u786e\u5b9a\u6027\u4f20\u9012\u673a\u5236\uff0c\u6709\u529b\u8bba\u8bc1\u4e86UProp\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u5f00\u521b\u6027\u5730\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86LLM\u591a\u6b65\u51b3\u7b56\u573a\u666f\u4e0b\u7684\u5916\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5UProp\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8fde\u7eed\u51b3\u7b56\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3a\u63d0\u5347LLM\u5728\u5b89\u5168\u5173\u952e\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\u4e0e\u53ef\u4fe1\u6027\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2506.17667", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17667", "abs": "https://arxiv.org/abs/2506.17667", "authors": ["Lintao Wang", "Encheng Su", "Jiaqi Liu", "Pengze Li", "Peng Xia", "Jiabei Xiao", "Wenlong Zhang", "Xinnan Dai", "Xi Chen", "Yuan Meng", "Mingyu Ding", "Lei Bai", "Wanli Ouyang", "Shixiang Tang", "Aoran Wang", "Xinzhu Ma"], "title": "PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models", "comment": null, "summary": "Physics problem-solving is a challenging domain for large AI models,\nrequiring integration of conceptual understanding, mathematical reasoning, and\ninterpretation of physical diagrams. Current evaluation methodologies show\nnotable limitations in capturing the breadth and complexity of\nundergraduate-level physics, underscoring the need for more rigorous\nassessments. To this end, we present PhysUniBench, a large-scale multimodal\nbenchmark designed to evaluate and improve the reasoning capabilities of\nmultimodal large language models (MLLMs) specifically on undergraduate-level\nphysics problems. PhysUniBench consists of 3,304 physics questions spanning 8\nmajor sub-disciplines of physics, each accompanied by one visual diagrams. The\nbenchmark includes both open-ended and multiple-choice questions,\nsystematically curated and difficulty-rated through an iterative\nmodel-in-the-loop process. The benchmark's construction involved a rigorous\nmulti-stage process, including multiple roll-outs, expert-level evaluation,\nautomated filtering of easily solved problems, and a nuanced difficulty grading\nsystem with five levels. Through extensive experiments, we observe that current\nstate-of-the-art models encounter substantial challenges in physics reasoning.\nFor example, GPT-4o mini achieves only about 34.2\\% accuracy in the proposed\nPhysUniBench. These results highlight that current MLLMs struggle with advanced\nphysics reasoning, especially on multi-step problems and those requiring\nprecise diagram interpretation. By providing a broad and rigorous assessment\ntool, PhysUniBench aims to drive progress in AI for Science, encouraging the\ndevelopment of models with stronger physical reasoning, problem-solving skills,\nand multimodal understanding. The benchmark and evaluation scripts are\navailable at https://prismax-team.github.io/PhysUniBenchmark/.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5927\u5b66\u7269\u7406\u591a\u6a21\u6001\u57fa\u51c6PhysUniBench\uff0c\u8986\u76d63304\u9898\u8bc4\u4ef7\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002\u5b9e\u9a8c\u53d1\u73b0\u4e3b\u6d41\u6a21\u578b\u5982GPT-4o mini\u51c6\u786e\u7387\u4ec534.2%\uff0c\u5728\u590d\u6742\u7269\u7406\u63a8\u7406\u548c\u56fe\u50cf\u89e3\u8bfb\u4e0a\u660e\u663e\u4e0d\u8db3\u3002\u8be5\u57fa\u51c6\u5c06\u63a8\u52a8\u66f4\u9ad8\u7ea7\u522b\u7684AI\u7269\u7406\u63a8\u7406\u80fd\u529b\u7684\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u89e3\u51b3\u5927\u5b66\u7269\u7406\u95ee\u9898\u4e0a\u8868\u73b0\u6709\u9650\uff0c\u73b0\u6709\u8bc4\u4ef7\u65b9\u6cd5\u96be\u4ee5\u5168\u9762\u53cd\u6620\u6a21\u578b\u5728\u7269\u7406\u9886\u57df\u7684\u63a8\u7406\u548c\u7406\u89e3\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u4e2a\u9ad8\u8d28\u91cf\u3001\u5e7f\u8986\u76d6\u6027\u7684\u65b0\u57fa\u51c6\u7528\u4e8e\u7cfb\u7edf\u6027\u8bc4\u6d4bAI\u5728\u7269\u7406\u9886\u57df\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u5927\u89c4\u6a21\u591a\u6a21\u6001\u7269\u7406\u57fa\u51c6PhysUniBench\uff0c\u6db5\u76d63304\u9053\u9898\u76ee\u30018\u4e2a\u7269\u7406\u5b50\u9886\u57df\uff0c\u6bcf\u9898\u914d\u6709\u793a\u610f\u56fe\uff0c\u5305\u542b\u5f00\u653e\u5f0f\u4e0e\u9009\u62e9\u9898\u3002\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u3001\u591a\u8f6e\u6570\u636e\u91c7\u96c6\u3001\u81ea\u52a8\u7b5b\u9009\u7b80\u5355\u9898\u76ee\u3001\u4e94\u7ea7\u96be\u5ea6\u8bc4\u5206\u7b49\u591a\u9636\u6bb5\u6d41\u7a0b\u6784\u5efa\uff0c\u53ef\u5168\u9762\u8bc4\u4f30AI\u7684\u7269\u7406\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u6a21\u578b\uff08\u5982GPT-4o mini\uff09\u5728PhysUniBench\u4e0a\u7684\u51c6\u786e\u7387\u4ec5\u4e3a34.2%\uff0c\u5728\u591a\u6b65\u9aa4\u63a8\u7406\u548c\u56fe\u50cf\u89e3\u6790\u7c7b\u95ee\u9898\u4e0a\u8868\u73b0\u5c24\u4e3a\u4e0d\u8db3\u3002", "conclusion": "PhysUniBench\u4f5c\u4e3a\u4e25\u82db\u4e14\u591a\u7ef4\u7684\u6d4b\u8bc4\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u5927\u6a21\u578b\u5728\u9ad8\u9636\u7269\u7406\u63a8\u7406\u65b9\u9762\u7684\u77ed\u677f\uff0c\u6709\u671b\u63a8\u52a8\u66f4\u5f3a\u7269\u7406\u63a8\u7406\u548c\u591a\u6a21\u6001\u7406\u89e3\u80fd\u529bAI\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.17513", "categories": ["cs.CY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.17513", "abs": "https://arxiv.org/abs/2506.17513", "authors": ["Rudra Y. Bedekar"], "title": "Public Perceptions of Autonomous Vehicles: A Survey of Pedestrians and Cyclists in Pittsburgh", "comment": null, "summary": "This study investigates how autonomous vehicle(AV) technology is perceived by\npedestrians and bicyclists in Pittsburgh. Using survey data from over 1200\nrespondents, the research explores the interplay between demographics, AV\ninteractions, infrastructural readiness, safety perceptions, and trust.\nFindings highlight demographic divides, infrastructure gaps, and the crucial\nrole of communication and education in AV adoption.", "AI": {"tldr": "\u901a\u8fc7\u8c03\u67e5\u5339\u5179\u58211200\u591a\u540d\u5c45\u6c11\uff0c\u53d1\u73b0\u4eba\u7fa4\u7279\u5f81\u3001\u57fa\u7840\u8bbe\u65bd\u4e0e\u6c9f\u901a\u6559\u80b2\u5171\u540c\u5f71\u54cd\u516c\u4f17\u5bf9\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u7684\u8ba4\u77e5\u4e0e\u91c7\u7eb3\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff08AV\uff09\u6280\u672f\u7684\u53d1\u5c55\uff0c\u884c\u4eba\u4e0e\u9a91\u884c\u8005\u4f5c\u4e3a\u9053\u8def\u4f7f\u7528\u8005\u4e0eAV\u7684\u4e92\u52a8\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u4ed6\u4eec\u5bf9\u8be5\u6280\u672f\u7684\u8ba4\u77e5\u3001\u4fe1\u4efb\u548c\u5b89\u5168\u611f\u5c1a\u4e0d\u6e05\u6670\u3002\u672c\u7814\u7a76\u65e8\u5728\u9610\u660e\u4e0d\u540c\u4eba\u7fa4\u5bf9AV\u7684\u770b\u6cd5\u53ca\u5176\u5f71\u54cd\u56e0\u7d20\uff0c\u63a8\u52a8\u66f4\u597d\u57ce\u5e02\u4ea4\u901a\u89c4\u5212\u4e0e\u6280\u672f\u666e\u53ca\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u9762\u5411\u5339\u5179\u5821\u5730\u533a\u8d85\u8fc71200\u540d\u53d7\u8bbf\u8005\u8fdb\u884c\u95ee\u5377\u8c03\u67e5\uff0c\u6536\u96c6\u884c\u4eba\u4e0e\u9a91\u884c\u8005\u5bf9\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u7684\u770b\u6cd5\u548c\u4f53\u9a8c\u6570\u636e\uff0c\u5e76\u5206\u6790\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u3001\u4e92\u52a8\u7ecf\u5386\u3001\u57fa\u7840\u8bbe\u65bd\u51c6\u5907\u72b6\u51b5\u3001\u5b89\u5168\u611f\u548c\u4fe1\u4efb\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u4eba\u53e3\u7edf\u8ba1\u56e0\u7d20\uff08\u5982\u5e74\u9f84\u3001\u6027\u522b\u7b49\uff09\u5f71\u54cd\u4eba\u4eec\u5bf9AV\u7684\u770b\u6cd5\uff0c\u57fa\u7840\u8bbe\u65bd\u5b58\u5728\u5dee\u8ddd\u3002\u5b89\u5168\u6c9f\u901a\u548c\u76f8\u5173\u77e5\u8bc6\u6559\u80b2\u5728\u63a8\u52a8AV\u63a5\u53d7\u548c\u4fe1\u4efb\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u4e0d\u540c\u4eba\u7fa4\u5bf9\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u6280\u672f\u7684\u8ba4\u77e5\u548c\u63a5\u53d7\u5ea6\u5b58\u5728\u5dee\u5f02\uff0c\u52a0\u5f3a\u57fa\u7840\u8bbe\u65bd\u5efa\u8bbe\u53ca\u63d0\u5347\u516c\u4f17\u6c9f\u901a\u4e0e\u6559\u80b2\u5bf9\u4e8e\u63a8\u52a8AV\u6280\u672f\u7684\u666e\u53ca\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.18572", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.18572", "abs": "https://arxiv.org/abs/2506.18572", "authors": ["Peter Frank", "Falk Dettinger", "Daniel Dittler", "Pascal H\u00e4big", "Nasser Jazdi", "Kai Hufendiek", "Michael Weyrich"], "title": "Communication Architecture for Autonomous Power-to-X Platforms: Enhancing Inspection and Operation With Legged Robots and 5G", "comment": null, "summary": "Inspection and maintenance of offshore platforms are associated with high\ncosts, primarily due to the significant personnel requirements and challenging\noperational conditions. This paper first presents a classification of Power to\nX platforms. Building upon this foundation, a communication architecture is\nproposed to enable monitoring, control, and teleoperation for a Power to X\nplatform. To reduce the demand for human labor, a robotic system is integrated\nto autonomously perform inspection and maintenance tasks. The implementation\nutilizes a quadruped robot. Remote monitoring, control, and teleoperation of\nthe robot are analyzed within the context of a 5G standalone network. As part\nof the evaluation, aspects such as availability and latency are recorded,\ncompared, and critically assessed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u57fa\u4e8e5G\u7f51\u7edc\u7684\u901a\u4fe1\u67b6\u6784\uff0c\u5229\u7528\u56db\u8db3\u673a\u5668\u4eba\u81ea\u52a8\u5b8c\u6210\u6d77\u4e0aPower to X\u5e73\u53f0\u7684\u68c0\u6d4b\u548c\u7ef4\u62a4\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u53ef\u6709\u6548\u964d\u4f4e\u4eba\u5de5\u6210\u672c\uff0c\u63d0\u5347\u8bbe\u65bd\u8fd0\u7ef4\u7684\u81ea\u52a8\u5316\u4e0e\u667a\u80fd\u5316\u6c34\u5e73\u3002", "motivation": "\u6d77\u4e0a\u5e73\u53f0\u7684\u68c0\u67e5\u548c\u7ef4\u62a4\u6210\u672c\u9ad8\u6602\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u5bf9\u5927\u91cf\u4eba\u529b\u7684\u9700\u6c42\u548c\u82db\u523b\u7684\u4f5c\u4e1a\u73af\u5883\u3002\u5982\u4f55\u964d\u4f4e\u4eba\u529b\u9700\u6c42\u3001\u63d0\u5347\u6548\u80fd\u662f\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u9996\u5148\u5bf9Power to X\u5e73\u53f0\u8fdb\u884c\u4e86\u5206\u7c7b\uff0c\u7136\u540e\u63d0\u51fa\u4e86\u4e00\u5957\u652f\u6301\u76d1\u6d4b\u3001\u63a7\u5236\u548c\u8fdc\u7a0b\u64cd\u4f5c\u7684\u901a\u4fe1\u67b6\u6784\u3002\u901a\u8fc7\u96c6\u6210\u56db\u8db3\u673a\u5668\u4eba\uff0c\u81ea\u52a8\u5316\u6267\u884c\u68c0\u67e5\u548c\u7ef4\u62a4\u5de5\u4f5c\u3002\u673a\u5668\u4eba\u57285G\u72ec\u7acb\u7ec4\u7f51\u4e0a\u8fdb\u884c\u8fdc\u7a0b\u76d1\u63a7\u3001\u63a7\u5236\u548c\u9065\u64cd\u4f5c\uff0c\u5e76\u8bb0\u5f55\u548c\u8bc4\u4f30\u5176\u53ef\u7528\u6027\u4e0e\u65f6\u5ef6\u3002", "result": "\u5b9e\u73b0\u4e86\u56db\u8db3\u673a\u5668\u4eba\u5728Power to X\u5e73\u53f0\u4e0a\u7684\u8fdc\u7a0b\u68c0\u67e5\u4e0e\u7ef4\u62a4\u3002\u57fa\u4e8e5G\u7f51\u7edc\u7684\u9065\u64cd\u4f5c\u7684\u53ef\u7528\u6027\u548c\u65f6\u5ef6\u5f97\u5230\u4e86\u8bb0\u5f55\u4e0e\u8bc4\u4f30\uff0c\u663e\u793a\u4e86\u6280\u672f\u53ef\u884c\u6027\u548c\u5173\u952e\u6027\u80fd\u3002", "conclusion": "\u7ed3\u54085G\u901a\u4fe1\u548c\u56db\u8db3\u673a\u5668\u4eba\u80fd\u591f\u6709\u6548\u51cf\u5c11\u6d77\u4e0a\u5e73\u53f0\u5bf9\u4eba\u529b\u7684\u4f9d\u8d56\uff0c\u63d0\u9ad8\u64cd\u4f5c\u5b89\u5168\u6027\u4e0e\u6548\u7387\u30025G\u7f51\u7edc\u652f\u6301\u4e0b\u7684\u8fdc\u7a0b\u64cd\u4f5c\u4e3a\u672a\u6765\u6d77\u4e0a\u8bbe\u65bd\u667a\u80fd\u5316\u3001\u81ea\u52a8\u5316\u7ef4\u62a4\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2506.17435", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17435", "abs": "https://arxiv.org/abs/2506.17435", "authors": ["Alberto Martinez-Serra", "Alejandro De La Fuente", "Nienke Viescher", "Ana S. Cardenal"], "title": "Beyond the Link: Assessing LLMs' ability to Classify Political Content across Global Media", "comment": null, "summary": "The use of large language models (LLMs) is becoming common in the context of\npolitical science, particularly in studies that analyse individuals use of\ndigital media. However, while previous research has demonstrated LLMs ability\nat labelling tasks, the effectiveness of using LLMs to classify political\ncontent (PC) from just URLs is not yet well explored. The work presented in\nthis article bridges this gap by evaluating whether LLMs can accurately\nidentify PC vs. non-PC from both the article text and the URLs from five\ncountries (France, Germany, Spain, the UK, and the US) and different languages.\nUsing cutting-edge LLMs like GPT, Llama, Mistral, Deepseek, Qwen and Gemma, we\nmeasure model performance to assess whether URL-level analysis can be a good\napproximation for full-text analysis of PC, even across different linguistic\nand national contexts. Model outputs are compared with human-labelled articles,\nas well as traditional supervised machine learning techniques, to set a\nbaseline of performance. Overall, our findings suggest the capacity of URLs to\nembed most of the news content, providing a vital perspective on accuracy-cost\nbalancing. We also account for contextual limitations and suggest\nmethodological recommendations to use LLMs within political science studies.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u4ec5\u5229\u7528URL\u533a\u5206\u65b0\u95fb\u653f\u6cbb\u5185\u5bb9\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u7ed3\u679c\u4e0e\u5168\u6587\u5206\u6790\u548c\u4eba\u5de5\u6807\u6ce8\u63a5\u8fd1\uff0c\u4e3a\u653f\u6cbb\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u884c\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u7ed9\u51fa\u4e86\u5b9e\u9645\u5e94\u7528\u5efa\u8bae\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u653f\u6cbb\u79d1\u5b66\u3001\u7279\u522b\u662f\u6570\u5b57\u5a92\u4f53\u5206\u6790\u4e2d\u7684\u5e94\u7528\u53d8\u5f97\u65e5\u76ca\u666e\u904d\u3002\u5c3d\u7ba1\u73b0\u6709\u7814\u7a76\u5df2\u8bc1\u660eLLM\u5728\u6807\u6ce8\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\uff0c\u4f46\u5176\u4ec5\u901a\u8fc7URL\u5bf9\u653f\u6cbb\u5185\u5bb9\u8fdb\u884c\u5206\u7c7b\u7684\u6709\u6548\u6027\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u8ba8\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u8bc4\u4f30LLM\uff08\u5305\u62ecGPT\u3001Llama\u3001Mistral\u3001Deepseek\u3001Qwen\u548cGemma\uff09\u8bc6\u522bPC\uff08\u653f\u6cbb\u5185\u5bb9\uff09\u4e0e\u975ePC\u7684\u51c6\u786e\u6027\uff0c\u6bd4\u8f83\u4e86\u6a21\u578b\u57fa\u4e8e\u6587\u7ae0\u5168\u6587\u548c\u4ec5URL\u8fdb\u884c\u5206\u7c7b\u7684\u8868\u73b0\u3002\u6570\u636e\u6db5\u76d6\u6cd5\u56fd\u3001\u5fb7\u56fd\u3001\u897f\u73ed\u7259\u3001\u82f1\u56fd\u548c\u7f8e\u56fd\u7684\u591a\u8bed\u8a00\u65b0\u95fb\u3002\u901a\u8fc7\u4e0e\u4eba\u5de5\u6807\u6ce8\u548c\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\uff0c\u9a8c\u8bc1LLM\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cURL\u4e2d\u5f80\u5f80\u5305\u542b\u4e86\u5927\u90e8\u5206\u65b0\u95fb\u5185\u5bb9\u4fe1\u606f\uff0cLLM\u4ec5\u901a\u8fc7URL\u5bf9\u653f\u6cbb\u5185\u5bb9\u8fdb\u884c\u5206\u7c7b\u7684\u6548\u679c\u4e0e\u4eba\u5de5\u6807\u6ce8\u548c\u5168\u6587\u5206\u6790\u7684\u7ed3\u679c\u63a5\u8fd1\u3002", "conclusion": "LLM\u57fa\u4e8eURL\u5bf9\u65b0\u95fb\u653f\u6cbb\u5c5e\u6027\u5206\u7c7b\u5177\u6709\u8f83\u5f3a\u80fd\u529b\uff0c\u4e3a\u653f\u6cbb\u79d1\u5b66\u4e2d\u7684\u6548\u7387\u4e0e\u51c6\u786e\u6027\u5e73\u8861\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002\u7814\u7a76\u8fd8\u8ba8\u8bba\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u5728\u653f\u6cbb\u79d1\u5b66\u4e2d\u5e94\u7528LLM\u7684\u5177\u4f53\u65b9\u6cd5\u5efa\u8bae\u3002"}}
{"id": "2506.17697", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17697", "abs": "https://arxiv.org/abs/2506.17697", "authors": ["Bohan Tang", "Dezhao Luo", "Jingxuan Chen", "Shaogang Gong", "Jianye Hao", "Jun Wang", "Kun Shao"], "title": "Beyond Syntax: Action Semantics Learning for App Agents", "comment": null, "summary": "The advent of Large Language Models (LLMs) enables the rise of App agents\nthat interpret user intent and operate smartphone Apps through actions such as\nclicking and scrolling. While prompt-based solutions with closed LLM APIs show\npromising ability, they incur heavy compute costs and external API dependency.\nFine-tuning smaller open-source LLMs solves these limitations. However, current\nfine-tuning methods use a syntax learning paradigm that forces agents to\nreproduce exactly the ground truth action strings, leading to\nout-of-distribution (OOD) vulnerability. To fill this gap, we propose Action\nSemantics Learning (ASL), a novel learning framework, where the learning\nobjective is capturing the semantics of the ground truth actions. Specifically,\ninspired by the programming language theory, we define the action semantics for\nApp agents as the state transition induced by the action in the user interface.\nWith this insight, ASL employs a novel SEmantic Estimator (SEE) to compute a\nsemantic reward to train the App agents in generating actions aligned with the\nsemantics of ground truth actions, even when the syntactic forms differ. To\nsupport the effectiveness of ASL, we theoretically demonstrate the superior\nrobustness of ASL for the OOD problem compared with the existing syntax\nlearning paradigm. Extensive experiments on offline and online smartphone App\noperation benchmarks show that ASL significantly improves the accuracy and\ngeneralisation of App agents over existing methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u52a8\u4f5c\u8bed\u4e49\u5b66\u4e60\uff08ASL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u52a8\u4f5c\u5e26\u6765\u7684\u8bed\u4e49\u72b6\u6001\u53d8\u5316\u800c\u975e\u4ec5\u4ec5\u590d\u73b0\u52a8\u4f5c\u5b57\u7b26\u4e32\uff0c\u4f7fApp Agent\u5728\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u548c\u63d0\u5347\u5206\u5e03\u5916\u9c81\u68d2\u6027\u7684\u540c\u65f6\uff0c\u6781\u5927\u589e\u5f3a\u4e86\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u95ed\u6e90\u5927\u6a21\u578bAPI\u7684App Agent\u65b9\u6848\u8ba1\u7b97\u5f00\u9500\u5927\u4e14\u4f9d\u8d56\u5916\u90e8API\uff0c\u800c\u57fa\u4e8e\u5f00\u6e90\u5c0f\u6a21\u578b\u7684\u5fae\u8c03\u867d\u7136\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u5f53\u524d\u5fae\u8c03\u65b9\u6cd5\u5b58\u5728\u5bf9\u8bed\u6cd5\u4e25\u683c\u62df\u5408\uff0c\u5bfc\u81f4\u6a21\u578b\u5bf9\u5206\u5e03\u5916\u6570\u636e\uff08OOD\uff09\u6613\u5931\u6548\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u6846\u67b6\u2014\u2014\u52a8\u4f5c\u8bed\u4e49\u5b66\u4e60\uff08Action Semantics Learning, ASL\uff09\uff0c\u4ee5\u52a8\u4f5c\u7684\u8bed\u4e49\uff08\u5373\u5728\u7528\u6237\u754c\u9762\u4e0a\u5f15\u53d1\u7684\u72b6\u6001\u53d8\u5316\uff09\u4e3a\u5b66\u4e60\u76ee\u6807\uff0c\u501f\u52a9\u8bed\u4e49\u4f30\u7b97\u5668\uff08SEmantic Estimator, SEE\uff09\u4e3aAgent\u751f\u6210\u7684\u52a8\u4f5c\u8ba1\u7b97\u8bed\u4e49\u5956\u52b1\uff0c\u4ece\u800c\u8bad\u7ec3\u6a21\u578b\u5b66\u4e60\u8bed\u4e49\u4e00\u81f4\u7684\u52a8\u4f5c\u8f93\u51fa\uff0c\u800c\u975e\u4e25\u683c\u590d\u73b0\u8bed\u6cd5\u5f62\u5f0f\u3002", "result": "\u7406\u8bba\u4e0a\u9a8c\u8bc1\u4e86ASL\u5728\u5206\u5e03\u5916\u6570\u636e\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u4f18\u4e8e\u4f20\u7edf\u8bed\u6cd5\u5b66\u4e60\uff0c\u5e76\u901a\u8fc7\u5927\u91cf\u79bb\u7ebf\u548c\u5728\u7ebf\u7684App\u64cd\u4f5c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u9a8c\u8bc1\u660eASL\u663e\u8457\u63d0\u5347\u4e86App Agent\u7684\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "ASL\u6846\u67b6\u901a\u8fc7\u5173\u6ce8\u52a8\u4f5c\u8bed\u4e49\u800c\u975e\u5355\u7eaf\u8bed\u6cd5\u590d\u73b0\uff0c\u63d0\u5347\u4e86App Agent\u5728\u667a\u80fd\u624b\u673a\u5e94\u7528\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\u5206\u5e03\u5916\u573a\u666f\u65f6\u5177\u6709\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.17577", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17577", "abs": "https://arxiv.org/abs/2506.17577", "authors": ["Meng Xia", "Robin Schmucker", "Conrad Borchers", "Vincent Aleven"], "title": "Optimizing Mastery Learning by Fast-Forwarding Over-Practice Steps", "comment": "Full research paper accepted at EC-TEL 2025", "summary": "Mastery learning improves learning proficiency and efficiency. However, the\noverpractice of skills--students spending time on skills they have already\nmastered--remains a fundamental challenge for tutoring systems. Previous\nresearch has reduced overpractice through the development of better problem\nselection algorithms and the authoring of focused practice tasks. However, few\nefforts have concentrated on reducing overpractice through step-level\nadaptivity, which can avoid resource-intensive curriculum redesign. We propose\nand evaluate Fast-Forwarding as a technique that enhances existing problem\nselection algorithms. Based on simulation studies informed by learner models\nand problem-solving pathways derived from real student data, Fast-Forwarding\ncan reduce overpractice by up to one-third, as it does not require students to\ncomplete problem-solving steps if all remaining pathways are fully mastered.\nFast-Forwarding is a flexible method that enhances any problem selection\nalgorithm, though its effectiveness is highest for algorithms that\npreferentially select difficult problems. Therefore, our findings suggest that\nwhile Fast-Forwarding may improve student practice efficiency, the size of its\npractical impact may also depend on students' ability to stay motivated and\nengaged at higher levels of difficulty.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u9898\u76ee\u6b65\u9aa4\u7ea7\u7684\u5feb\u8fdb\u6280\u672f\uff0c\u80fd\u663e\u8457\u51cf\u5c11\u5b66\u751f\u5bf9\u5df2\u638c\u63e1\u6280\u80fd\u7684\u8fc7\u5ea6\u7ec3\u4e60\uff0c\u63d0\u5347\u5b66\u4e60\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u6613\u4e8e\u96c6\u6210\u5230\u73b0\u6709\u7b97\u6cd5\uff0c\u4f46\u5b9e\u9645\u6548\u679c\u53d7\u5b66\u751f\u96be\u9898\u6311\u6218\u4e2d\u7684\u53c2\u4e0e\u5ea6\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u7cbe\u719f\u5b66\u4e60\u80fd\u63d0\u5347\u5b66\u4e60\u6548\u7387\u548c\u6548\u679c\uff0c\u4f46\u5b66\u751f\u8fc7\u5ea6\u7ec3\u4e60\u5df2\u638c\u63e1\u6280\u80fd\u7684\u95ee\u9898\u4f9d\u65e7\u662f\u8f85\u5bfc\u7cfb\u7edf\u7684\u6838\u5fc3\u96be\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u6539\u8fdb\u9898\u76ee\u9009\u62e9\u7b97\u6cd5\u548c\u8bbe\u8ba1\u9488\u5bf9\u6027\u7ec3\u4e60\u4efb\u52a1\u6765\u51cf\u5c11\u8fc7\u5ea6\u7ec3\u4e60\uff0c\u5f88\u5c11\u5173\u6ce8\u9898\u76ee\u6b65\u9aa4\u7ea7\u7684\u81ea\u9002\u5e94\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5feb\u8fdb\uff08Fast-Forwarding\uff09\u201d\u7684\u65b0\u6280\u672f\u4f5c\u4e3a\u73b0\u6709\u95ee\u9898\u9009\u62e9\u7b97\u6cd5\u7684\u589e\u5f3a\uff0c\u57fa\u4e8e\u771f\u5b9e\u5b66\u751f\u6570\u636e\u5efa\u7acb\u7684\u5b66\u4e60\u8005\u6a21\u578b\u4e0e\u89e3\u9898\u8def\u5f84\u8fdb\u884c\u4eff\u771f\u7814\u7a76\uff0c\u5b9e\u73b0\u4e86\u5728\u5b66\u751f\u5b8c\u5168\u638c\u63e1\u4e4b\u540e\u53ef\u8df3\u8fc7\u5269\u4f59\u7684\u89e3\u9898\u6b65\u9aa4\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u5feb\u8fdb\u6280\u672f\u6700\u591a\u80fd\u5c06\u8fc7\u5ea6\u7ec3\u4e60\u51cf\u5c11\u4e09\u5206\u4e4b\u4e00\uff0c\u7279\u522b\u662f\u5f53\u4e0e\u4f18\u5148\u9009\u62e9\u96be\u9898\u7684\u95ee\u9898\u9009\u62e9\u7b97\u6cd5\u7ed3\u5408\u65f6\u6548\u679c\u66f4\u4f73\u3002", "conclusion": "\u5feb\u8fdb\u662f\u4e00\u79cd\u7075\u6d3b\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u589e\u5f3a\u4efb\u4f55\u95ee\u9898\u9009\u62e9\u7b97\u6cd5\uff0c\u63d0\u9ad8\u5b66\u751f\u7ec3\u4e60\u7684\u6548\u7387\uff0c\u4f46\u5b9e\u9645\u6548\u679c\u8fd8\u4f9d\u8d56\u4e8e\u5b66\u751f\u5728\u9ad8\u96be\u5ea6\u7ec3\u4e60\u4e2d\u7684\u52a8\u673a\u548c\u4e13\u6ce8\u5ea6\u3002"}}
{"id": "2506.18717", "categories": ["cs.CE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18717", "abs": "https://arxiv.org/abs/2506.18717", "authors": ["Linyue Hu", "Qi Wang"], "title": "A Study of Dynamic Stock Relationship Modeling and S&P500 Price Forecasting Based on Differential Graph Transformer", "comment": null, "summary": "Stock price prediction is vital for investment decisions and risk management,\nyet remains challenging due to markets' nonlinear dynamics and time-varying\ninter-stock correlations. Traditional static-correlation models fail to capture\nevolving stock relationships. To address this, we propose a Differential Graph\nTransformer (DGT) framework for dynamic relationship modeling and price\nprediction. Our DGT integrates sequential graph structure changes into\nmulti-head self-attention via a differential graph mechanism, adaptively\npreserving high-value connections while suppressing noise. Causal temporal\nattention captures global/local dependencies in price sequences. We further\nevaluate correlation metrics (Pearson, Mutual Information, Spearman, Kendall's\nTau) across global/local/dual scopes as spatial-attention priors. Using 10\nyears of S&P 500 closing prices (z-score normalized; 64-day sliding windows),\nDGT with spatial priors outperformed GRU baselines (RMSE: 0.24 vs. 0.87).\nKendall's Tau global matrices yielded optimal results (MAE: 0.11). K-means\nclustering revealed \"high-volatility growth\" and \"defensive blue-chip\" stocks,\nwith the latter showing lower errors (RMSE: 0.13) due to stable correlations.\nKendall's Tau and Mutual Information excelled in volatile sectors. This study\ninnovatively combines differential graph structures with Transformers,\nvalidating dynamic relationship modeling and identifying optimal correlation\nmetrics/scopes. Clustering analysis supports tailored quantitative strategies.\nOur framework advances financial time-series prediction through dynamic\nmodeling and cross-asset interaction analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5dee\u5206\u56fe\u53d8\u6362\u5668\u7684\u65b0\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u7ed3\u5408\u805a\u7c7b\u5206\u6790\u4e3a\u91cf\u5316\u6295\u8d44\u7b56\u7565\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "motivation": "\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u5bf9\u4e8e\u6295\u8d44\u51b3\u7b56\u548c\u98ce\u9669\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u5e02\u573a\u5177\u6709\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u548c\u65f6\u53d8\u7684\u80a1\u7968\u95f4\u76f8\u5173\u6027\uff0c\u8fd9\u4e00\u4efb\u52a1\u6781\u5177\u6311\u6218\u6027\u3002\u4f20\u7edf\u7684\u9759\u6001\u76f8\u5173\u6027\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u80a1\u7968\u5173\u7cfb\u7684\u52a8\u6001\u6f14\u53d8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5dee\u5206\u56fe\u53d8\u6362\u5668\uff08Differential Graph Transformer, DGT\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u5173\u7cfb\u5efa\u6a21\u548c\u4ef7\u683c\u9884\u6d4b\u3002DGT\u901a\u8fc7\u5dee\u5206\u56fe\u673a\u5236\u5c06\u5e8f\u5217\u56fe\u7ed3\u6784\u7684\u53d8\u5316\u96c6\u6210\u5230\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4e2d\uff0c\u6709\u6548\u4fdd\u7559\u9ad8\u4ef7\u503c\u8fde\u63a5\u5e76\u6291\u5236\u566a\u58f0\uff0c\u5e76\u91c7\u7528\u56e0\u679c\u65f6\u95f4\u6ce8\u610f\u529b\u6355\u6349\u4ef7\u683c\u5e8f\u5217\u4e2d\u7684\u5168\u5c40\u548c\u5c40\u90e8\u4f9d\u8d56\u3002\u6b64\u5916\uff0c\u5206\u522b\u8bc4\u4f30\u4e86\u591a\u79cd\u76f8\u5173\u6027\u5ea6\u91cf\uff08Pearson, MI, Spearman, Kendall\u2019s Tau\uff09\u4f5c\u4e3a\u7a7a\u95f4\u6ce8\u610f\u529b\u5148\u9a8c\u3002\u5b9e\u9a8c\u91c7\u7528\u5386\u65f610\u5e74\u7684\u6807\u51c6\u666e\u5c14500\u6307\u6570\u6536\u76d8\u4ef7\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "DGT\u7ed3\u5408\u7a7a\u95f4\u5148\u9a8c\u5728\u9884\u6d4b\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8eGRU\u57fa\u7ebf\uff08RMSE: 0.24 vs. 0.87\uff09\uff0c\u4ee5Kendall\u2019s Tau\u5168\u7403\u77e9\u9635\u4e3a\u7a7a\u95f4\u5148\u9a8c\u65f6\u6548\u679c\u6700\u4f73\uff08MAE: 0.11\uff09\u3002K-means\u805a\u7c7b\u63ed\u793a\u4e86\u9ad8\u6ce2\u52a8\u6210\u957f\u80a1\u4e0e\u9632\u5fa1\u578b\u84dd\u7b79\u80a1\u4e24\u5927\u7c7b\u522b\uff0c\u540e\u8005\u56e0\u76f8\u5173\u6027\u66f4\u7a33\u5b9a\u800c\u9884\u6d4b\u8bef\u5dee\u66f4\u4f4e\uff08RMSE: 0.13\uff09\u3002Kendall\u2019s Tau\u548c\u4e92\u4fe1\u606f\u5728\u9ad8\u6ce2\u52a8\u677f\u5757\u8868\u73b0\u4f18\u79c0\u3002", "conclusion": "\u901a\u8fc7\u521b\u65b0\u6027\u5730\u5c06\u5dee\u5206\u56fe\u7ed3\u6784\u4e0eTransformer\u76f8\u7ed3\u5408\uff0c\u9a8c\u8bc1\u4e86\u52a8\u6001\u5173\u7cfb\u5efa\u6a21\u7684\u6709\u6548\u6027\u548c\u6700\u4f18\u76f8\u5173\u6027\u5ea6\u91cf/\u8303\u56f4\u7684\u9009\u62e9\u3002\u805a\u7c7b\u5206\u6790\u4e3a\u5b9a\u5236\u91cf\u5316\u7b56\u7565\u63d0\u4f9b\u652f\u6301\uff0c\u8be5\u6846\u67b6\u63a8\u8fdb\u4e86\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u52a8\u6001\u5efa\u6a21\u548c\u8de8\u8d44\u4ea7\u5173\u7cfb\u5206\u6790\u3002"}}
{"id": "2506.17459", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17459", "abs": "https://arxiv.org/abs/2506.17459", "authors": ["Siyu Liang", "Gina-Anne Levow"], "title": "Breaking the Transcription Bottleneck: Fine-tuning ASR Models for Extremely Low-Resource Fieldwork Languages", "comment": null, "summary": "Automatic Speech Recognition (ASR) has reached impressive accuracy for\nhigh-resource languages, yet its utility in linguistic fieldwork remains\nlimited. Recordings collected in fieldwork contexts present unique challenges,\nincluding spontaneous speech, environmental noise, and severely constrained\ndatasets from under-documented languages. In this paper, we benchmark the\nperformance of two fine-tuned multilingual ASR models, MMS and XLS-R, on five\ntypologically diverse low-resource languages with control of training data\nduration. Our findings show that MMS is best suited when extremely small\namounts of training data are available, whereas XLS-R shows parity performance\nonce training data exceed one hour. We provide linguistically grounded analysis\nfor further provide insights towards practical guidelines for field linguists,\nhighlighting reproducible ASR adaptation approaches to mitigate the\ntranscription bottleneck in language documentation.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u5206\u6790\u4e86MMS\u548cXLS-R\u4e24\u79cd\u591a\u8bed\u79cd\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0b\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u5728\u8bad\u7ec3\u6570\u636e\u6781\u5c11\u65f6\u9009MMS\uff0c\u6570\u636e\u91cf\u8db3\u591f\u65f6\u7528XLS-R\uff0c\u5e76\u4e3a\u7530\u91ce\u8bed\u8a00\u5b66\u8005\u63d0\u4f9b\u4e86\u5177\u4f53\u4e14\u53ef\u64cd\u4f5c\u7684ASR\u4f7f\u7528\u5efa\u8bae\u3002", "motivation": "\u5c3d\u7ba1ASR\u5728\u9ad8\u8d44\u6e90\u8bed\u8a00\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u9762\u5bf9\u7530\u91ce\u8c03\u67e5\u573a\u666f\u4e0b\u7684\u4f4e\u8d44\u6e90\u3001\u566a\u97f3\u4e0e\u81ea\u7136\u53e3\u8bed\u6570\u636e\u4ecd\u6709\u8bf8\u591a\u5c40\u9650\u3002\u8be5\u7814\u7a76\u65e8\u5728\u63d0\u5347ASR\u5728\u8bed\u8a00\u5b66\u7530\u91ce\u5de5\u4f5c\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u5c24\u5176\u662f\u7f13\u89e3\u5c11\u6570\u53ca\u6fd2\u5371\u8bed\u8a00\u8d44\u6599\u7684\u8f6c\u5f55\u96be\u9898\u3002", "method": "\u5bf9\u4e24\u79cd\u7ecf\u8fc7\u5fae\u8c03\u7684\u591a\u8bed\u79cdASR\u6a21\u578b\u2014\u2014MMS\u4e0eXLS-R\uff0c\u5728\u4e94\u79cd\u7c7b\u578b\u591a\u6837\u7684\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u63a7\u5236\u8bad\u7ec3\u6570\u636e\u7684\u65f6\u95f4\u957f\u5ea6\uff0c\u68c0\u6d4b\u5176\u5728\u7530\u91ce\u5f55\u97f3\u6570\u636e\u4e0a\u7684\u8868\u73b0\u3002", "result": "MMS\u6a21\u578b\u5728\u6781\u5c0f\u8bad\u7ec3\u6570\u636e\u4e0b\u6548\u679c\u66f4\u597d\uff1bXLS-R\u4e00\u65e6\u8bad\u7ec3\u6570\u636e\u91cf\u8d85\u8fc7\u4e00\u5c0f\u65f6\u6027\u80fd\u4e0eMMS\u76f8\u5f53\u3002\u7814\u7a76\u8fd8\u5bf9ASR\u6a21\u578b\u9002\u5e94\u6027\u8fdb\u884c\u8bed\u8a00\u5b66\u89c6\u89d2\u5206\u6790\uff0c\u5e76\u4e3a\u5b9e\u9645\u7530\u91ce\u5de5\u4f5c\u63d0\u4f9b\u590d\u73b0\u6027\u5f3a\u7684\u89e3\u51b3\u8def\u5f84\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff1a\u9488\u5bf9\u7530\u91ce\u8bed\u8a00\u5f55\u97f3\u6570\u636e\uff0c\u5f53\u8bad\u7ec3\u6570\u636e\u91cf\u6781\u5c11\u65f6\uff0cMMS\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff1b\u800c\u5f53\u8bad\u7ec3\u6570\u636e\u8d85\u8fc7\u4e00\u5c0f\u65f6\u65f6\uff0cXLS-R\u6a21\u578b\u8868\u73b0\u53ef\u4e0eMMS\u6301\u5e73\u3002\u901a\u8fc7\u8bed\u8a00\u5b66\u5206\u6790\uff0c\u4e3a\u7530\u91ce\u8bed\u8a00\u5b66\u5de5\u4f5c\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684ASR\u9009\u578b\u548c\u9002\u5e94\u5efa\u8bae\uff0c\u4ece\u800c\u7f13\u89e3\u8bed\u8a00\u6587\u732e\u6574\u7406\u8fc7\u7a0b\u4e2d\u7684\u8f6c\u5f55\u74f6\u9888\u3002"}}
{"id": "2506.17784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17784", "abs": "https://arxiv.org/abs/2506.17784", "authors": ["Song Wang", "Zhen Tan", "Zihan Chen", "Shuang Zhou", "Tianlong Chen", "Jundong Li"], "title": "AnyMAC: Cascading Flexible Multi-Agent Collaboration via Next-Agent Prediction", "comment": null, "summary": "Recent progress in large language model (LLM)-based multi-agent collaboration\nhighlights the power of structured communication in enabling collective\nintelligence. However, existing methods largely rely on static or graph-based\ninter-agent topologies, lacking the potential adaptability and flexibility in\ncommunication. In this work, we propose a new framework that rethinks\nmulti-agent coordination through a sequential structure rather than a graph\nstructure, offering a significantly larger topology space for multi-agent\ncommunication. Our method focuses on two key directions: (1) Next-Agent\nPrediction, which selects the most suitable agent role at each step, and (2)\nNext-Context Selection (NCS), which enables each agent to selectively access\nrelevant information from any previous step. Together, these components\nconstruct task-adaptive communication pipelines that support both role\nflexibility and global information flow. Extensive evaluations across multiple\nbenchmarks demonstrate that our approach achieves superior performance while\nsubstantially reducing communication overhead.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u7528\u987a\u5e8f\u7ed3\u6784\u66ff\u4ee3\u4f20\u7edf\u56fe\u7ed3\u6784\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u9ad8\u6548\u7684LLM\u591a\u667a\u80fd\u4f53\u901a\u4fe1\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u89d2\u8272\u9009\u62e9\u548c\u4e0a\u4e0b\u6587\u8bbf\u95ee\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6027\u80fd\u548c\u901a\u4fe1\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u9759\u6001\u6216\u57fa\u4e8e\u56fe\u7684\u901a\u4fe1\u7ed3\u6784\uff0c\u7f3a\u4e4f\u9002\u5e94\u6027\u548c\u7075\u6d3b\u6027\uff0c\u9650\u5236\u4e86\u901a\u4fe1\u8868\u73b0\u529b\u3002\u4f5c\u8005\u5e0c\u671b\u63d0\u5347\u591a\u667a\u80fd\u4f53\u901a\u4fe1\u7684\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51fa\u4ee5\u987a\u5e8f\u7ed3\u6784\uff08\u800c\u975e\u56fe\u7ed3\u6784\uff09\u4e3a\u6838\u5fc3\u7684\u591a\u667a\u80fd\u4f53\u901a\u4fe1\u6846\u67b6\uff0c\u5e76\u5305\u62ec\u4e24\u4e2a\u5173\u952e\u6a21\u5757\uff1a\uff081\uff09Next-Agent Prediction\uff0c\u52a8\u6001\u9009\u62e9\u6bcf\u4e00\u6b65\u6700\u5408\u9002\u7684\u667a\u80fd\u4f53\u89d2\u8272\uff1b\uff082\uff09Next-Context Selection\uff08NCS\uff09\uff0c\u8ba9\u6bcf\u4e2a\u667a\u80fd\u4f53\u53ef\u8bbf\u95ee\u4efb\u610f\u5148\u524d\u6b65\u9aa4\u7684\u76f8\u5173\u4fe1\u606f\u3002\u4e24\u8005\u5171\u540c\u652f\u6301\u89d2\u8272\u7075\u6d3b\u5207\u6362\u548c\u5168\u5c40\u4fe1\u606f\u6d41\u52a8\u3002", "result": "\u8be5\u6846\u67b6\u5728\u591a\u9879\u57fa\u51c6\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u80fd\u63d0\u5347\u534f\u4f5c\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "\u987a\u5e8f\u7ed3\u6784\u548c\u52a8\u6001\u4efb\u52a1\u81ea\u9002\u5e94\u7684\u901a\u4fe1\u673a\u5236\u53ef\u66f4\u597d\u53d1\u6325\u96c6\u4f53\u667a\u80fd\u7684\u6f5c\u529b\uff0c\u4e3aLLM\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63d0\u4f9b\u4e86\u66f4\u5e7f\u9614\u3001\u66f4\u7075\u6d3b\u7684\u62d3\u6251\u7ed3\u6784\u3002"}}
{"id": "2506.17741", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17741", "abs": "https://arxiv.org/abs/2506.17741", "authors": ["Levin Brinkmann", "Thomas F. Eisenmann", "Anne-Marie Nussberger", "Maxim Derex", "Sara Bonati", "Valerii Chirkov", "Iyad Rahwan"], "title": "Experimental Evidence for the Propagation and Preservation of Machine Discoveries in Human Populations", "comment": null, "summary": "Intelligent machines with superhuman capabilities have the potential to\nuncover problem-solving strategies beyond human discovery. Emerging evidence\nfrom competitive gameplay, such as Go, demonstrates that AI systems are\nevolving from mere tools to sources of cultural innovation adopted by humans.\nHowever, the conditions under which intelligent machines transition from tools\nto drivers of persistent cultural change remain unclear. We identify three key\nconditions for machines to fundamentally influence human problem-solving: the\ndiscovered strategies must be non-trivial, learnable, and offer a clear\nadvantage. Using a cultural transmission experiment and an agent-based\nsimulation, we demonstrate that when these conditions are met,\nmachine-discovered strategies can be transmitted, understood, and preserved by\nhuman populations, leading to enduring cultural shifts. These findings provide\na framework for understanding how machines can persistently expand human\ncognitive skills and underscore the need to consider their broader implications\nfor human cognition and cultural evolution.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\uff0cAI\u82e5\u80fd\u53d1\u73b0\u521b\u65b0\u4e14\u5177\u660e\u663e\u4f18\u52bf\u5e76\u6613\u4e8e\u5b66\u4e60\u7684\u7b56\u7565\uff0c\u4fbf\u80fd\u6301\u7eed\u63a8\u52a8\u4eba\u7c7b\u6587\u5316\u548c\u8ba4\u77e5\u6f14\u8fdb\u3002\u8fd9\u4e00\u673a\u5236\u901a\u8fc7\u5b9e\u9a8c\u548c\u6a21\u62df\u5f97\u5230\u9a8c\u8bc1\uff0c\u5bf9\u7406\u89e3AI\u65f6\u4ee3\u7684\u6587\u5316\u53d8\u8fc1\u5177\u6709\u6df1\u523b\u542f\u793a\u3002", "motivation": "\u5f53\u524d\u7684AI\u7cfb\u7edf\u4e0d\u4ec5\u8d85\u8d8a\u4eba\u7c7b\u80fd\u529b\uff0c\u8fd8\u53ef\u80fd\u5e26\u6765\u65b0\u7684\u95ee\u9898\u89e3\u51b3\u7b56\u7565\uff0c\u8fd9\u5bf9\u4eba\u7c7b\u6587\u5316\u548c\u8ba4\u77e5\u53d1\u5c55\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u7136\u800c\uff0c\u6211\u4eec\u5c1a\u4e0d\u660e\u786eAI\u4ece\u5de5\u5177\u89d2\u8272\u8dc3\u5347\u4e3a\u63a8\u52a8\u6587\u5316\u6301\u4e45\u53d8\u9769\u7684\u5177\u4f53\u6761\u4ef6\u3002", "method": "\u4f5c\u8005\u4f7f\u7528\u4e86\u6587\u5316\u4f20\u9012\u5b9e\u9a8c\u548c\u57fa\u4e8e\u6a21\u62df\u7684\u667a\u80fd\u4f53\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u6027\u5730\u5206\u6790\u548c\u9a8c\u8bc1AI\u53d1\u73b0\u7684\u7b56\u7565\u5728\u4eba\u7fa4\u4e2d\u7684\u4f20\u9012\u3001\u7406\u89e3\u4e0e\u4fdd\u7559\u8fc7\u7a0b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u82e5AI\u53d1\u73b0\u7684\u7b56\u7565\u5177\u6709\u975e\u5e73\u51e1\u6027\u3001\u53ef\u5b66\u4e60\u6027\u53ca\u663e\u8457\u4f18\u52bf\uff0c\u8fd9\u4e9b\u7b56\u7565\u4fbf\u53ef\u88ab\u4eba\u7c7b\u5438\u6536\u5e76\u4ee3\u9645\u4f20\u627f\uff0c\u6700\u7ec8\u5f15\u8d77\u6301\u4e45\u7684\u6587\u5316\u53d8\u8fc1\u3002", "conclusion": "\u673a\u5668\u53ea\u8981\u521b\u9020\u51fa\u5177\u6709\u5b9e\u9645\u4f18\u52bf\u4e14\u6613\u4e8e\u88ab\u4eba\u7406\u89e3\u548c\u5b66\u4e60\u7684\u65b0\u7b56\u7565\uff0c\u5c31\u80fd\u6210\u4e3a\u63a8\u52a8\u4eba\u7c7b\u6587\u5316\u548c\u8ba4\u77e5\u6301\u7eed\u6269\u5c55\u7684\u65b0\u52a8\u529b\u3002\u8fd9\u4e3a\u7406\u89e3AI\u5bf9\u4eba\u7c7b\u6587\u5316\u6f14\u5316\u7684\u6df1\u8fdc\u5f71\u54cd\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2506.18724", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.18724", "abs": "https://arxiv.org/abs/2506.18724", "authors": ["Jun Zhang", "Tong Zhang", "Ying Wang"], "title": "Towards Real-time Structural Dynamics Simulation with Graph-based Digital Twin Modelling", "comment": null, "summary": "Precise and timely simulation of a structure's dynamic behavior is crucial\nfor evaluating its performance and assessing its health status. Traditional\nnumerical methods are often limited by high computational costs and low\nefficiency, while deep learning approaches offer a promising alternative.\nHowever, these data-driven methods still face challenges, such as limited\nphysical interpretability and difficulty in adapting to diverse structural\nconfigurations. To address these issues, this study proposes a graph-based\ndigital twin modelling (GDTM) framework to simulate structural dynamic\nresponses across various spatial topologies. In this framework, the adjacency\nmatrix explicitly represents the spatial relationships between structural\nvertices, enhancing the model's physical interpretability. The effectiveness of\nthe proposed framework was validated through comprehensive numerical and\nexperimental studies. The results demonstrate that the framework accurately\nsimulated structural dynamics across different topological configurations, with\nNormalized Mean-Squared Error (NMSE) values consistently below 0.005 in\nnumerical simulations and 0.0015 in experimental validations. Furthermore, the\nframework achieved over 80-fold improvements in computational efficiency\ncompared to traditional finite element methods (FEM). This research promotes\nthe practical application of graph-based structural dynamics modelling, which\nhas the potential to significantly advance structural performance evaluation\nand health monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u6570\u5b57\u5b6a\u751f\u52a8\u529b\u5b66\u6a21\u62df\u65b9\u6cd5\uff0c\u7269\u7406\u53ef\u89e3\u91ca\u6027\u5f3a\uff0c\u9002\u5e94\u591a\u79cd\u7ed3\u6784\u62d3\u6251\uff0c\u7cbe\u5ea6\u9ad8\u3001\u6548\u7387\u6781\u5927\u63d0\u5347\uff0c\u5bf9\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u5e94\u7528\u524d\u666f\u5e7f\u9614\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u5728\u7ed3\u6784\u52a8\u529b\u5b66\u6a21\u62df\u4e2d\u6548\u7387\u4f4e\u4e0b\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u53c8\u5b58\u5728\u7269\u7406\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u4e0e\u96be\u4ee5\u9002\u5e94\u591a\u6837\u7ed3\u6784\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u6570\u5b57\u5b6a\u751f\u5efa\u6a21\uff08GDTM\uff09\u6846\u67b6\uff0c\u5229\u7528\u90bb\u63a5\u77e9\u9635\u660e\u786e\u8868\u793a\u7ed3\u6784\u9876\u70b9\u7a7a\u95f4\u5173\u7cfb\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u7269\u7406\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u4e0e\u5b9e\u9a8c\u7814\u7a76\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "result": "\u6846\u67b6\u80fd\u51c6\u786e\u6a21\u62df\u4e0d\u540c\u62d3\u6251\u7ed3\u6784\u4e0b\u7684\u52a8\u529b\u54cd\u5e94\uff0c\u6570\u503c\u4eff\u771fNMSE\u4f4e\u4e8e0.005\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4f4e\u4e8e0.0015\uff0c\u4e14\u8f83\u4f20\u7edf\u6709\u9650\u5143\u6cd5\u63d0\u5347\u8d85\u8fc780\u500d\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u57fa\u4e8e\u56fe\u7684\u7ed3\u6784\u52a8\u529b\u5b66\u5efa\u6a21\u6781\u5927\u63d0\u5347\u4e86\u6a21\u62df\u6548\u7387\u4e0e\u7cbe\u5ea6\uff0c\u4fc3\u8fdb\u4e86\u5176\u5728\u7ed3\u6784\u6027\u80fd\u8bc4\u4f30\u548c\u5065\u5eb7\u76d1\u6d4b\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.17467", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17467", "abs": "https://arxiv.org/abs/2506.17467", "authors": ["Weixin Liang"], "title": "Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems", "comment": "Stanford CS PhD Dissertation", "summary": "Large language models (LLMs) have shown significant potential to change how\nwe write, communicate, and create, leading to rapid adoption across society.\nThis dissertation examines how individuals and institutions are adapting to and\nengaging with this emerging technology through three research directions.\nFirst, I demonstrate how the institutional adoption of AI detectors introduces\nsystematic biases, particularly disadvantaging writers of non-dominant language\nvarieties, highlighting critical equity concerns in AI governance. Second, I\npresent novel population-level algorithmic approaches that measure the\nincreasing adoption of LLMs across writing domains, revealing consistent\npatterns of AI-assisted content in academic peer reviews, scientific\npublications, consumer complaints, corporate communications, job postings, and\ninternational organization press releases. Finally, I investigate LLMs'\ncapability to provide feedback on research manuscripts through a large-scale\nempirical analysis, offering insights into their potential to support\nresearchers who face barriers in accessing timely manuscript feedback,\nparticularly early-career researchers and those from under-resourced settings.", "AI": {"tldr": "\u672c\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u8bed\u8a00\u5927\u6a21\u578b\uff08LLMs\uff09\u666e\u53ca\u5bf9\u4e2a\u4eba\u548c\u673a\u6784\u5e26\u6765\u7684\u5f71\u54cd\uff0c\u63ed\u793aAI\u68c0\u6d4b\u5de5\u5177\u53ef\u80fd\u5bfc\u81f4\u7684\u7fa4\u4f53\u6027\u4e0d\u516c\uff0c\u4ee5\u53caLLMs\u5728\u5404\u7c7b\u5199\u4f5c\u573a\u666f\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5e76\u8bc1\u5b9eLLMs\u53ef\u4e3a\u8d44\u6e90\u6709\u9650\u7684\u7814\u7a76\u8005\u63d0\u4f9b\u6709\u6548\u5b66\u672f\u53cd\u9988\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5feb\u901f\u666e\u53ca\u5bf9\u4e2a\u4eba\u548c\u673a\u6784\u5e26\u6765\u4e86\u91cd\u5927\u5f71\u54cd\u3002\u7814\u7a76\u8feb\u5207\u9700\u8981\u63a2\u8ba8\uff1a1\uff09AI\u68c0\u6d4b\u5668\u5e26\u6765\u7684\u516c\u6b63\u6027\u548c\u504f\u89c1\u95ee\u9898\uff0c2\uff09LLMs\u5728\u5199\u4f5c\u9886\u57df\u7684\u666e\u53ca\u73b0\u72b6\u548c\u5f71\u54cd\uff0c3\uff09LLMs\u5bf9\u5b66\u672f\u5199\u4f5c\u53cd\u9988\u7684\u6f5c\u529b\u53ca\u5176\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e0b\u5bf9\u7814\u7a76\u4eba\u5458\u7684\u652f\u6301\u4f5c\u7528\u3002", "method": "\u8bba\u6587\u91c7\u7528\u4e09\u6761\u7814\u7a76\u8def\u5f84\uff1a\u7b2c\u4e00\uff0c\u5b9e\u8bc1\u5206\u6790AI\u68c0\u6d4b\u5668\u7684\u4f7f\u7528\u53ca\u5176\u5bf9\u4e0d\u540c\u8bed\u8a00\u80cc\u666f\u4f5c\u8005\u7684\u5f71\u54cd\uff1b\u7b2c\u4e8c\uff0c\u8bbe\u8ba1\u5e76\u5e94\u7528\u7fa4\u4f53\u7ea7\u7684\u7b97\u6cd5\u65b9\u6cd5\uff0c\u5b9a\u91cf\u68c0\u6d4bLLMs\u5728\u591a\u4e2a\u5199\u4f5c\u9886\u57df\u7684\u5e94\u7528\uff1b\u7b2c\u4e09\uff0c\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790LLMs\u4e3a\u7814\u7a76\u624b\u7a3f\u63d0\u4f9b\u53cd\u9988\u7684\u80fd\u529b\u53ca\u5176\u6548\u679c\u3002", "result": "\u53d1\u73b0AI\u68c0\u6d4b\u5668\u5728\u5236\u5ea6\u5316\u4f7f\u7528\u4e2d\u7cfb\u7edf\u6027\u5730\u6b67\u89c6\u975e\u4e3b\u6d41\u8bed\u8a00\u4f5c\u8005\uff0c\u4ea7\u751f\u516c\u5e73\u95ee\u9898\u3002\u901a\u8fc7\u5927\u89c4\u6a21\u6570\u636e\u5206\u6790\uff0c\u63ed\u793aLLMs\u5df2\u5728\u5b66\u672f\u8bc4\u5ba1\u3001\u79d1\u5b66\u6587\u732e\u3001\u6d88\u8d39\u8005\u6295\u8bc9\u3001\u516c\u53f8\u6c9f\u901a\u3001\u62db\u8058\u4fe1\u606f\u53ca\u56fd\u9645\u7ec4\u7ec7\u65b0\u95fb\u7a3f\u4e2d\u88ab\u5e7f\u6cdb\u4f7f\u7528\u3002\u6700\u540e\uff0c\u8bc1\u5b9eLLMs\u53ef\u4e3a\u5b66\u672f\u624b\u7a3f\u63d0\u4f9b\u6709\u76ca\u53cd\u9988\uff0c\u6709\u52a9\u4e8e\u5f25\u8865\u65e9\u671f\u7814\u7a76\u4eba\u5458\u548c\u6b20\u8d44\u6e90\u73af\u5883\u4e0b\u7814\u7a76\u8005\u7684\u53cd\u9988\u7f3a\u53e3\u3002", "conclusion": "\u672c\u6587\u6307\u51fa\uff0cLLMs\u7684\u666e\u53ca\u5728\u5e26\u6765\u4fbf\u5229\u7684\u540c\u65f6\u4e5f\u5f15\u5165\u4e86\u98ce\u9669\u4e0e\u4e0d\u5e73\u7b49\uff0c\u5c24\u5176\u662fAI\u68c0\u6d4b\u5de5\u5177\u53ef\u80fd\u5f15\u53d1\u7684\u7fa4\u4f53\u6027\u504f\u89c1\u3002\u5236\u5ea6\u5728\u91c7\u7528AI\u5de5\u5177\u65f6\u5e94\u91cd\u89c6\u516c\u5e73\u4e0e\u5305\u5bb9\u6027\u3002\u540c\u65f6\uff0cLLMs\u53ef\u4f5c\u4e3a\u63d0\u5347\u5b66\u672f\u5199\u4f5c\u652f\u6301\u548c\u516c\u5e73\u6027\u7684\u91cd\u8981\u5de5\u5177\uff0c\u5c24\u5176\u80fd\u5e2e\u52a9\u5f31\u52bf\u7fa4\u4f53\u83b7\u5f97\u7814\u7a76\u53cd\u9988\u3002"}}
{"id": "2506.17788", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "I.2.1; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.17788", "abs": "https://arxiv.org/abs/2506.17788", "authors": ["Shahab Rahimirad", "Guven Gergerli", "Lucia Romero", "Angela Qian", "Matthew Lyle Olson", "Simon Stepputtis", "Joseph Campbell"], "title": "Bayesian Social Deduction with Graph-Informed Language Models", "comment": "32 pages, 10 figures. Under review", "summary": "Social reasoning - inferring unobservable beliefs and intentions from partial\nobservations of other agents - remains a challenging task for large language\nmodels (LLMs). We evaluate the limits of current reasoning language models in\nthe social deduction game Avalon and find that while the largest models\ndemonstrate strong performance, they require extensive test-time inference and\ndegrade sharply when distilled to smaller, real-time-capable variants. To\naddress this, we introduce a hybrid reasoning framework that externalizes\nbelief inference to a structured probabilistic model, while using an LLM for\nlanguage understanding and interaction. Our approach achieves competitive\nperformance with much larger models in Agent-Agent play and, notably, is the\nfirst language agent to defeat human players in a controlled study - achieving\na 67% win rate and receiving higher qualitative ratings than both reasoning\nbaselines and human teammates. We release code, models, and a dataset to\nsupport future work on social reasoning in LLM agents, which can be found at\nhttps://camp-lab-purdue.github.io/bayesian-social-deduction/", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u5c06\u4fe1\u5ff5\u63a8\u7406\u4e0e\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5c0f\u6a21\u578b\u5728\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u4e2d\u7684\u8868\u73b0\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86AI\u5bf9\u4eba\u7c7b\u7684\u8d85\u8d8a\uff0c\u5e76\u63a8\u52a8\u4e86\u76f8\u5173\u7814\u7a76\u7684\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8fdb\u884c\u793e\u4f1a\u63a8\u7406\uff08\u5373\u6839\u636e\u5bf9\u4ed6\u4eba\u6709\u9650\u7684\u89c2\u5bdf\u63a8\u65ad\u5176\u9690\u542b\u4fe1\u5ff5\u548c\u610f\u56fe\uff09\u65f6\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u5c24\u5176\u5728\u5b9e\u9645\u5e94\u7528\u5982\u793e\u4ea4\u63a8\u7406\u6e38\u620f Avalon \u4e2d\uff0c\u6a21\u578b\u867d\u6709\u8f83\u597d\u8868\u73b0\u4f46\u5b58\u5728\u63a8\u7406\u6548\u7387\u4f4e\u548c\u6cdb\u5316\u81f3\u5c0f\u578b\u6a21\u578b\u80fd\u529b\u5f31\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6df7\u5408\u63a8\u7406\u6846\u67b6\uff0c\u5c06\u4fe1\u5ff5\u63a8\u65ad\u90e8\u5206\u5916\u7f6e\u5230\u7ed3\u6784\u5316\u6982\u7387\u6a21\u578b\u4e2d\uff0c\u800c\u8bed\u8a00\u7406\u89e3\u548c\u4ea4\u4e92\u4f9d\u7136\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d1f\u8d23\u3002", "result": "\u6846\u67b6\u5728 Agent-Agent \u6e38\u620f\u4e2d\u8fbe\u5230\u4e86\u4e0e\u66f4\u5927\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4e14\u9996\u6b21\u5728\u53d7\u63a7\u5b9e\u9a8c\u4e2d\u51fb\u8d25\u4e86\u771f\u4eba\u73a9\u5bb6\uff0c\u53d6\u5f97\u4e8667%\u7684\u80dc\u7387\uff0c\u5e76\u5728\u5b9a\u6027\u8bc4\u4ef7\u4e2d\u8d85\u8fc7\u4e86\u57fa\u7ebf\u6a21\u578b\u4e0e\u771f\u4eba\u961f\u53cb\u3002", "conclusion": "\u901a\u8fc7\u6df7\u5408\u63a8\u7406\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u793e\u4f1a\u63a8\u7406\u4efb\u52a1\u4e2d\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4f7f\u5f97\u6a21\u578b\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u5177\u5907\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.17808", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17808", "abs": "https://arxiv.org/abs/2506.17808", "authors": ["Weina Jin"], "title": "The value of human and machine in machine-generated creative contents", "comment": null, "summary": "The seemingly \"imagination\" and \"creativity\" from machine-generated contents\nshould not be misattributed to the accomplishment of machine. They are\naccomplishments of both human and machine. Without human interpretation, the\nmachine-generated contents remain in the imaginary space of the large language\nmodels, and cannot automatically establish grounding in the reality and human\nexperience.", "AI": {"tldr": "\u673a\u5668\u751f\u6210\u7684\u5185\u5bb9\u5982\u679c\u6ca1\u6709\u4eba\u7c7b\u89e3\u8bfb\uff0c\u5c31\u65e0\u6cd5\u4e0e\u73b0\u5b9e\u548c\u7ecf\u9a8c\u5efa\u7acb\u8054\u7cfb\uff0c\u6240\u8c13\u7684\u201c\u521b\u9020\u529b\u201d\u5176\u5b9e\u662f\u4eba\u673a\u5171\u540c\u4f5c\u7528\u7684\u7ed3\u679c\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u751f\u6210\u5185\u5bb9\u8868\u73b0\u51fa\u9ad8\u5ea6\u7684\u201c\u60f3\u8c61\u529b\u201d\u548c\u201c\u521b\u9020\u529b\u201d\uff0c\u4f46\u8fd9\u4e9b\u662f\u5426\u771f\u6b63\u5c5e\u4e8e\u673a\u5668\u672c\u8eab\u5f15\u53d1\u4e89\u8bae\u3002\u8be5\u6587\u65e8\u5728\u5398\u6e05\u4eba\u7c7b\u4e0e\u673a\u5668\u5728\u5185\u5bb9\u751f\u6210\u4e2d\u7684\u5b9e\u9645\u4f5c\u7528\u548c\u5173\u7cfb\u3002", "method": "\u672c\u6587\u91c7\u7528\u54f2\u5b66\u6027\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u63a2\u8ba8\u673a\u5668\u751f\u6210\u5185\u5bb9\u4e0e\u4eba\u7c7b\u4e3b\u89c2\u89e3\u8bfb\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u901a\u8fc7\u7406\u8bba\u9610\u8ff0\u8bf4\u660e\u4e3a\u4f55\u4eba\u673a\u534f\u540c\u662f\u521b\u9020\u529b\u7684\u6765\u6e90\u3002", "result": "\u5206\u6790\u5f97\u51fa\uff1a\u673a\u5668\u751f\u6210\u5185\u5bb9\u7684\u521b\u9020\u6027\u672c\u8d28\u4e0a\u4f9d\u8d56\u4e8e\u4eba\u7c7b\u7684\u89e3\u91ca\uff0c\u6ca1\u6709\u4eba\u7c7b\u7684\u53c2\u4e0e\uff0c\u8fd9\u4e9b\u5185\u5bb9\u65e0\u6cd5\u81ea\u52a8\u83b7\u5f97\u73b0\u5b9e\u610f\u4e49\u548c\u7ecf\u9a8c\u57fa\u7840\u3002", "conclusion": "\u673a\u5668\u751f\u6210\u5185\u5bb9\u4e2d\u7684\u201c\u60f3\u8c61\u529b\u201d\u548c\u201c\u521b\u9020\u529b\u201d\u5e76\u4e0d\u80fd\u5b8c\u5168\u5f52\u529f\u4e8e\u673a\u5668\u672c\u8eab\u3002\u8fd9\u79cd\u6210\u5c31\u662f\u4eba\u7c7b\u4e0e\u673a\u5668\u5171\u540c\u7684\u7ed3\u679c\u3002\u6ca1\u6709\u4eba\u7c7b\u7684\u89e3\u8bfb\uff0c\u673a\u5668\u751f\u6210\u7684\u5185\u5bb9\u65e0\u6cd5\u81ea\u52a8\u4e0e\u73b0\u5b9e\u548c\u4eba\u7684\u7ecf\u9a8c\u5efa\u7acb\u8054\u7cfb\u3002"}}
{"id": "2506.18853", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.18853", "abs": "https://arxiv.org/abs/2506.18853", "authors": ["Yinmin Liu", "Hessam Babaee", "Peyman Givi", "Daniel Livescu", "Arash Nouri"], "title": "Skeletal Reaction Models for Gasoline Surrogate Combustion", "comment": null, "summary": "Skeletal reaction models are derived for a four-component gasoline surrogate\nmodel via an instantaneous local sensitivity analysis technique. The\nsensitivities of the species mass fractions and the temperature with respect to\nthe reaction rates are estimated by a reduced-order modeling (ROM) methodology.\nTermed \"implicit time-dependent basis CUR (implicit TDB-CUR),\" this methodology\nis based on the CUR matrix decomposition and incorporates implicit time\nintegration for evolving the bases. The estimated sensitivities are\nsubsequently analyzed to develop skeletal reaction models with a fully\nautomated procedure. The 1389-species gasoline surrogate model developed at\nLawrence Livermore National Laboratory (LLNL) is selected as the detailed\nkinetics model. The skeletal reduction procedure is applied to this model in a\nzero-dimensional constant-pressure reactor over a wide range of initial\nconditions. The performances of the resulting skeletal models are appraised by\ncomparison against the results via the LLNL detailed model, and also\npredictions via other skeletal models. Two new skeletal models are developed\nconsisting of 679 and 494 species, respectively. The first is an alternative to\nan existing model with the same number of species. The predictions with this\nmodel reproduces the detailed models vital flame results with less than 1%\nerrors. The errors via the second model are less than 10%.", "AI": {"tldr": "\u5229\u7528\u65b0\u578b\u7684\u9690\u5f0fTDB-CUR\u964d\u9636\u65b9\u6cd5\uff0c\u81ea\u52a8\u5316\u4ece\u590d\u6742\u6c7d\u6cb9\u4ee3\u7406\u53cd\u5e94\u6a21\u578b\u4e2d\u63d0\u53d6\u51fa\u9aa8\u67b6\u53cd\u5e94\u7f51\u7edc\uff0c\u5728\u4fdd\u8bc1\u8ba1\u7b97\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u6a21\u578b\u5927\u5e45\u7b80\u5316\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5de5\u7a0b\u4eff\u771f\u7684\u6548\u7387\u3002", "motivation": "\u590d\u6742\u7684\u6c7d\u6cb9\u4ee3\u7406\u6210\u5206\u71c3\u70e7\u5316\u5b66\u53cd\u5e94\u6a21\u578b\u89c4\u6a21\u5e9e\u5927\uff0c\u8ba1\u7b97\u91cf\u5de8\u5927\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\uff0c\u56e0\u6b64\u9700\u8981\u901a\u8fc7\u7cbe\u7b80\u673a\u7406\u6765\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u7cbe\u5ea6\u3002", "method": "\u91c7\u7528\u4e00\u79cd\u57fa\u4e8eCUR\u77e9\u9635\u5206\u89e3\u5e76\u7ed3\u5408\u9690\u5f0f\u65f6\u95f4\u79ef\u5206\u7684\u65b9\u6cd5\uff08implicit TDB-CUR\uff09\u8fdb\u884c\u5c40\u90e8\u5373\u65f6\u7075\u654f\u5ea6\u5206\u6790\uff0c\u901a\u8fc7\u964d\u9636\u5efa\u6a21(Reduced-Order Modeling, ROM)\u6280\u672f\u81ea\u52a8\u5316\u7b5b\u9009\u91cd\u8981\u53cd\u5e94\u8def\u5f84\uff0c\u4ece\u800c\u53d1\u5c55\u4e86\u9aa8\u67b6\u53cd\u5e94\u6a21\u578b\u3002", "result": "\u4ece\u5305\u542b1389\u79cd\u7ec4\u5206\u7684LLNL\u6c7d\u6cb9\u8be6\u7ec6\u673a\u7406\u4e2d\uff0c\u81ea\u52a8\u5316\u751f\u6210\u4e86\u5305\u542b679\u79cd\u548c494\u79cd\u7ec4\u5206\u7684\u4e24\u4e2a\u9aa8\u67b6\u6a21\u578b\u3002\u5176\u4e2d679\u7ec4\u5206\u7684\u6a21\u578b\u5728\u5173\u952e\u71c3\u70e7\u7279\u6027\u9884\u6d4b\u4e0a\u4e0e\u8be6\u7ec6\u6a21\u578b\u8bef\u5dee\u5c0f\u4e8e1%\uff0c494\u7ec4\u5206\u6a21\u578b\u7684\u8bef\u5dee\u5c0f\u4e8e10%\u3002", "conclusion": "\u63d0\u51fa\u7684\u9690\u5f0fTDB-CUR\u964d\u9636\u5efa\u6a21\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u4ece\u590d\u6742\u6c7d\u6cb9\u71c3\u70e7\u8be6\u7ec6\u673a\u7406\u4e2d\u63d0\u53d6\u51fa\u66f4\u5c0f\u3001\u66f4\u9ad8\u6548\u4e14\u51c6\u786e\u5ea6\u8f83\u9ad8\u7684\u9aa8\u67b6\u673a\u7406\uff0c\u663e\u8457\u7f29\u51cf\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u4fdd\u8bc1\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2506.17506", "categories": ["cs.CL", "cs.OS"], "pdf": "https://arxiv.org/pdf/2506.17506", "abs": "https://arxiv.org/abs/2506.17506", "authors": ["Lesheng Jin", "Zhenyuan Ruan", "Haohui Mai", "Jingbo Shang"], "title": "VeriLocc: End-to-End Cross-Architecture Register Allocation via LLM", "comment": null, "summary": "Modern GPUs evolve rapidly, yet production compilers still rely on\nhand-crafted register allocation heuristics that require substantial re-tuning\nfor each hardware generation. We introduce VeriLocc, a framework that combines\nlarge language models (LLMs) with formal compiler techniques to enable\ngeneralizable and verifiable register allocation across GPU architectures.\nVeriLocc fine-tunes an LLM to translate intermediate representations (MIRs)\ninto target-specific register assignments, aided by static analysis for\ncross-architecture normalization and generalization and a verifier-guided\nregeneration loop to ensure correctness. Evaluated on matrix multiplication\n(GEMM) and multi-head attention (MHA), VeriLocc achieves 85-99% single-shot\naccuracy and near-100% pass@100. Case study shows that VeriLocc discovers more\nperformant assignments than expert-tuned libraries, outperforming rocBLAS by\nover 10% in runtime.", "AI": {"tldr": "VeriLocc\u7ed3\u5408LLM\u548c\u6b63\u5f0f\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u6cdb\u5316\u4e14\u51c6\u786e\u7684GPU\u5bc4\u5b58\u5668\u5206\u914d\uff0c\u6027\u80fd\u8d85\u8d8a\u4e1a\u754c\u4e13\u5bb6\u624b\u5de5\u8c03\u4f18\u65b9\u6848\u3002", "motivation": "\u73b0\u6709GPU\u7684\u7f16\u8bd1\u5668\u5bc4\u5b58\u5668\u5206\u914d\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u6bcf\u66f4\u6362\u786c\u4ef6\u65f6\u9700\u5927\u91cf\u8c03\u4f18\uff0c\u6548\u7387\u4f4e\u4e0b\u3001\u96be\u4ee5\u6cdb\u5316\u3002", "method": "\u63d0\u51fa\u4e86VeriLocc\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5f62\u5f0f\u5316\u7f16\u8bd1\u6280\u672f\u7ed3\u5408\u3002\u6846\u67b6\u901a\u8fc7\u5fae\u8c03LLM\uff0c\u5c06\u4e2d\u95f4\u8868\u793a(MIR)\u7ffb\u8bd1\u4e3a\u76ee\u6807\u5bc4\u5b58\u5668\u5206\u914d\uff0c\u5e76\u7ed3\u5408\u9759\u6001\u5206\u6790\u5b9e\u73b0\u8de8\u67b6\u6784\u7684\u5f52\u4e00\u5316\u548c\u6cdb\u5316\uff0c\u8fd8\u5f15\u5165\u4e86\u9a8c\u8bc1\u9a71\u52a8\u7684\u91cd\u751f\u5faa\u73af\u4ee5\u4fdd\u8bc1\u6b63\u786e\u6027\u3002", "result": "\u5728GEMM\u548cMHA\u4efb\u52a1\u4e0a\uff0cVeriLocc\u5b9e\u73b0\u4e8685-99%\u7684\u5355\u6b21\u51c6\u786e\u7387\u548c\u8fd1100%\u7684pass@100\uff0c\u4e2a\u6848\u663e\u793a\u5176\u5206\u914d\u4f18\u4e8e\u4e13\u5bb6\u8c03\u4f18\u5e93\uff0c\u8fd0\u884c\u65f6\u95f4\u6bd4rocBLAS\u5feb10%\u4ee5\u4e0a\u3002", "conclusion": "VeriLocc\u80fd\u6cdb\u5316\u4e14\u53ef\u9a8c\u8bc1\u5730\u63d0\u5347GPU\u5bc4\u5b58\u5668\u5206\u914d\u6548\u7387\u548c\u6027\u80fd\uff0c\u4f18\u4e8e\u4f20\u7edf\u624b\u5de5\u542f\u53d1\u5f0f\u4e0e\u4e13\u5bb6\u5e93\uff0c\u5c55\u73b0\u4e86LLM\u7ed3\u5408\u5f62\u5f0f\u5316\u6280\u672f\u5728\u7f16\u8bd1\u5668\u4f18\u5316\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.17792", "categories": ["cs.AI", "cs.LO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.17792", "abs": "https://arxiv.org/abs/2506.17792", "authors": ["Alexandros Evangelidis", "Gricel V\u00e1zquez", "Simos Gerasimou"], "title": "Efficient Strategy Synthesis for MDPs via Hierarchical Block Decomposition", "comment": null, "summary": "Software-intensive systems, such as software product lines and robotics,\nutilise Markov decision processes (MDPs) to capture uncertainty and analyse\nsequential decision-making problems. Despite the usefulness of conventional\npolicy synthesis methods, they fail to scale to large state spaces. Our\napproach addresses this issue and accelerates policy synthesis in large MDPs by\ndynamically refining the MDP and iteratively selecting the most fragile MDP\nregions for refinement. This iterative procedure offers a balance between\naccuracy and efficiency, as refinement occurs only when necessary. Through a\ncomprehensive empirical evaluation comprising diverse case studies and MDPs up\nto 1M states, we demonstrate significant performance improvements yielded by\nour approach compared to the leading probabilistic model checker PRISM (up to\n2x), thus offering a very competitive solution for real-world policy synthesis\ntasks in larger MDPs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5927\u89c4\u6a21MDP\u7684\u52a8\u6001\u7ec6\u5316\u7b56\u7565\u5408\u6210\u65b9\u6cd5\uff0c\u76f8\u8f83\u4e8e\u4e3b\u6d41\u5de5\u5177PRISM\u5728\u591a\u79cd\u6848\u4f8b\u4e2d\u53d6\u5f97\u4e86\u6700\u9ad82\u500d\u7684\u6027\u80fd\u63d0\u5347\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6269\u5c55\u7684\u95ee\u9898\uff0c\u9002\u5408\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u590d\u6742\u51b3\u7b56\u9700\u6c42\u3002", "motivation": "\u73b0\u6709\u7684\u8f6f\u4ef6\u5bc6\u96c6\u578b\u7cfb\u7edf\uff08\u5982\u8f6f\u4ef6\u4ea7\u54c1\u7ebf\u3001\u673a\u5668\u4eba\u7cfb\u7edf\uff09\u901a\u5e38\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u6765\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027\u5e76\u5206\u6790\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u72b6\u6001\u7a7a\u95f4\u4e0b\u96be\u4ee5\u6269\u5c55\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u7ec6\u5316MDP\u7684\u65b9\u6cd5\uff0c\u8fed\u4ee3\u5730\u9009\u62e9\u6700\u8106\u5f31\u7684MDP\u533a\u57df\u8fdb\u884c\u7ec6\u5316\uff0c\u4ec5\u5728\u5fc5\u8981\u65f6\u8fdb\u884c\uff0c\u5e73\u8861\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "result": "\u901a\u8fc7\u5305\u542b\u591a\u79cd\u6848\u4f8b\u548c\u9ad8\u8fbe\u767e\u4e07\u72b6\u6001\u7684\u5927\u578bMDP\u7684\u7efc\u5408\u5b9e\u9a8c\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u4e0e\u4e3b\u6d41\u6982\u7387\u6a21\u578b\u68c0\u6d4b\u5668PRISM\u76f8\u6bd4\u6027\u80fd\u63d0\u5347\u663e\u8457\uff08\u6700\u9ad8\u63d0\u53472\u500d\uff09\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u80fd\u5927\u5e45\u63d0\u5347\u5927\u89c4\u6a21MDP\u7b56\u7565\u5408\u6210\u7684\u6548\u7387\u548c\u7ade\u4e89\u529b\uff0c\u9002\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u7b56\u7565\u5408\u6210\u4efb\u52a1\u3002"}}
{"id": "2506.18045", "categories": ["cs.CY", "cs.AI", "cs.CL", "K.4; I.2.7; I.2.0"], "pdf": "https://arxiv.org/pdf/2506.18045", "abs": "https://arxiv.org/abs/2506.18045", "authors": ["I. Loaiza", "R. Vestrelli", "A. Fronzetti Colladon", "R. Rigobon"], "title": "The Democratic Paradox in Large Language Models' Underestimation of Press Freedom", "comment": null, "summary": "As Large Language Models (LLMs) increasingly mediate global information\naccess for millions of users worldwide, their alignment and biases have the\npotential to shape public understanding and trust in fundamental democratic\ninstitutions, such as press freedom. In this study, we uncover three systematic\ndistortions in the way six popular LLMs evaluate press freedom in 180 countries\ncompared to expert assessments of the World Press Freedom Index (WPFI). The six\nLLMs exhibit a negative misalignment, consistently underestimating press\nfreedom, with individual models rating between 71% to 93% of countries as less\nfree. We also identify a paradoxical pattern we term differential misalignment:\nLLMs disproportionately underestimate press freedom in countries where it is\nstrongest. Additionally, five of the six LLMs exhibit positive home bias,\nrating their home countries' press freedoms more favorably than would be\nexpected given their negative misalignment with the human benchmark. In some\ncases, LLMs rate their home countries between 7% to 260% more positively than\nexpected. If LLMs are set to become the next search engines and some of the\nmost important cultural tools of our time, they must ensure accurate\nrepresentations of the state of our human and civic rights globally.", "AI": {"tldr": "\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc4\u4f30\u5404\u56fd\u65b0\u95fb\u81ea\u7531\u65b9\u9762\u4e0e\u4e13\u5bb6\u8bc4\u4f30\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u666e\u904d\u4f4e\u4f30\u591a\u6570\u56fd\u5bb6\u7684\u65b0\u95fb\u81ea\u7531\uff0c\u4e14\u5bf9\u672c\u56fd\u4ea7\u751f\u6b63\u5411\u504f\u89c1\u3002\u8fd9\u79cd\u5931\u771f\u6216\u5f71\u54cd\u516c\u4f17\u5bf9\u5168\u7403\u6c11\u4e3b\u72b6\u51b5\u7684\u7406\u89e3\uff0c\u4e9f\u9700\u6539\u8fdb\u6a21\u578b\u7684\u5ba2\u89c2\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5168\u7403\u8303\u56f4\u5185\u5f71\u54cd\u5927\u91cf\u7528\u6237\u83b7\u53d6\u4fe1\u606f\u3002\u7531\u4e8e\u5176\u5bf9\u4fe1\u606f\u7684\u5f15\u5bfc\u4e0e\u504f\u89c1\uff0c\u53ef\u80fd\u5f71\u54cd\u516c\u4f17\u5bf9\u5982\u65b0\u95fb\u81ea\u7531\u7b49\u91cd\u8981\u6c11\u4e3b\u5236\u5ea6\u7684\u8ba4\u77e5\u548c\u4fe1\u4efb\u3002\u4f5c\u8005\u5173\u6ce8\u8fd9\u4e9b\u6a21\u578b\u5bf9\u65b0\u95fb\u81ea\u7531\u72b6\u6001\u8bc4\u4ef7\u7684\u51c6\u786e\u6027\u548c\u6f5c\u5728\u5931\u771f\u3002", "method": "\u5bf9\u516d\u4e2a\u4e3b\u6d41LLMs\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5206\u6790\u5b83\u4eec\u5bf9180\u4e2a\u56fd\u5bb6\u65b0\u95fb\u81ea\u7531\u72b6\u51b5\u7684\u8bc4\u4ef7\uff0c\u5e76\u4e0e\u4e16\u754c\u65b0\u95fb\u81ea\u7531\u6307\u6570\uff08WPFI\uff09\u4e13\u5bb6\u8bc4\u4f30\u7ed3\u679c\u8fdb\u884c\u7cfb\u7edf\u5bf9\u6bd4\uff0c\u8003\u5bdf\u5931\u771f\u4e0e\u504f\u89c1\u73b0\u8c61\u3002", "result": "\u516d\u4e2aLLMs\u666e\u904d\u4f4e\u4f30\u65b0\u95fb\u81ea\u7531\uff0c\u5168\u6a21\u578b\u572871%-93%\u7684\u56fd\u5bb6\u4e2d\u4f4e\u4e8e\u4e13\u5bb6\u8bc4\u4ef7\u3002\u53d1\u73b0\u201c\u5dee\u5f02\u6027\u5931\u8c03\u201d\uff0c\u5373\u5728\u65b0\u95fb\u81ea\u7531\u6700\u5f3a\u7684\u56fd\u5bb6\u88ab\u4f4e\u4f30\u6700\u4e25\u91cd\u3002\u5927\u591a\u6570\u6a21\u578b\u5bf9\u672c\u56fd\u5b58\u5728\u6b63\u5411\u504f\u89c1\uff0c\u5bf9\u672c\u56fd\u65b0\u95fb\u81ea\u7531\u7684\u8bc4\u4ef7\u6bd4\u5b9e\u9645\u9ad87%-260%\u3002", "conclusion": "\u5f53\u524d\u70ed\u95e8LLMs\u5728\u65b0\u95fb\u81ea\u7531\u8fd9\u79cd\u5173\u952e\u6c11\u4e3b\u8bae\u9898\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\u4e0e\u5931\u8c03\uff0c\u53ef\u80fd\u8bef\u5bfc\u5168\u7403\u7528\u6237\u3002\u968f\u7740LLMs\u5728\u4fe1\u606f\u83b7\u53d6\u9886\u57df\u5730\u4f4d\u63d0\u5347\uff0c\u9700\u786e\u4fdd\u5176\u5bf9\u5168\u7403\u516c\u6c11\u6743\u76ca\u7684\u5ba2\u89c2\u51c6\u786e\u8868\u8fbe\u3002"}}
{"id": "2506.18586", "categories": ["cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18586", "abs": "https://arxiv.org/abs/2506.18586", "authors": ["Zijie Yang", "Qiji Zhou", "Fang Guo", "Sijie Zhang", "Yexun Xi", "Jinglei Nie", "Yudian Zhu", "Liping Huang", "Chou Wu", "Yonghe Xia", "Xiaoyu Ma", "Yingming Pu", "Panzhong Lu", "Junshu Pan", "Mingtao Chen", "Tiannan Guo", "Yanmei Dou", "Hongyu Chen", "Anping Zeng", "Jiaxing Huang", "Tian Xu", "Yue Zhang"], "title": "Airalogy: AI-empowered universal data digitization for research automation", "comment": "146 pages, 6 figures, 49 supplementary figures", "summary": "Research data are the foundation of Artificial Intelligence (AI)-driven\nscience, yet current AI applications remain limited to a few fields with\nreadily available, well-structured, digitized datasets. Achieving comprehensive\nAI empowerment across multiple disciplines is still out of reach. Present-day\nresearch data collection is often fragmented, lacking unified standards,\ninefficiently managed, and difficult to share. Creating a single platform for\nstandardized data digitization needs to overcome the inherent challenge of\nbalancing between universality (supporting the diverse, ever-evolving needs of\nvarious disciplines) and standardization (enforcing consistent formats to fully\nenable AI). No existing platform accommodates both facets. Building a truly\nmultidisciplinary platform requires integrating scientific domain knowledge\nwith sophisticated computing skills. Researchers often lack the computational\nexpertise to design customized and standardized data recording methods, whereas\nplatform developers rarely grasp the intricate needs of multiple scientific\ndomains. These gaps impede research data standardization and hamper AI-driven\nprogress. In this study, we address these challenges by developing Airalogy\n(https://airalogy.com), the world's first AI- and community-driven platform\nthat balances universality and standardization for digitizing research data\nacross multiple disciplines. Airalogy represents entire research workflows\nusing customizable, standardized data records and offers an advanced AI\nresearch copilot for intelligent Q&A, automated data entry, analysis, and\nresearch automation. Already deployed in laboratories across all four schools\nof Westlake University, Airalogy has the potential to accelerate and automate\nscientific innovation in universities, industry, and the global research\ncommunity-ultimately benefiting humanity as a whole.", "AI": {"tldr": "\u73b0\u6709AI\u79d1\u5b66\u7814\u7a76\u53d7\u9650\u4e8e\u6570\u636e\u6807\u51c6\u5316\u548c\u591a\u6837\u6027\u517c\u5bb9\u95ee\u9898\u3002\u4f5c\u8005\u5f00\u53d1\u4e86Airalogy\u5e73\u53f0\uff0c\u9996\u6b21\u5b9e\u73b0\u591a\u9886\u57df\u6570\u636e\u81ea\u52a8\u5316\u3001\u6807\u51c6\u5316\u5f55\u5165\u548cAI\u8f85\u52a9\uff0c\u5df2\u6210\u529f\u5728\u897f\u6e56\u5927\u5b66\u591a\u4e2a\u5b9e\u9a8c\u5ba4\u90e8\u7f72\uff0c\u6709\u671b\u4fc3\u8fdb\u5168\u7403\u79d1\u5b66\u521b\u65b0\u81ea\u52a8\u5316\u548c\u9ad8\u6548\u3002", "motivation": "\u76ee\u524dAI\u5728\u79d1\u5b66\u9886\u57df\u7684\u5e94\u7528\u53d7\u9650\u4e8e\u6570\u636e\u7684\u6807\u51c6\u5316\u4e0e\u6570\u5b57\u5316\u7a0b\u5ea6\uff0c\u4e0d\u540c\u884c\u4e1a\u6570\u636e\u788e\u7247\u5316\u3001\u7f3a\u4e4f\u7edf\u4e00\u6807\u51c6\uff0c\u5bfc\u81f4\u8de8\u5b66\u79d1AI\u8d4b\u80fd\u56f0\u96be\u3002\u73b0\u6709\u5e73\u53f0\u672a\u80fd\u517c\u987e\u9886\u57df\u591a\u6837\u6027\u548c\u6570\u636e\u6807\u51c6\u5316\uff0c\u79d1\u5b66\u5bb6\u4e0e\u5e73\u53f0\u5f00\u53d1\u8005\u95f4\u5b58\u5728\u77e5\u8bc6\u9e3f\u6c9f\uff0c\u963b\u788d\u6570\u636e\u6807\u51c6\u5316\u4e0eAI\u7814\u7a76\u8fdb\u6b65\u3002", "method": "\u63d0\u51fa\u5e76\u5f00\u53d1\u4e86Airalogy\u5e73\u53f0\uff0c\u4e00\u79cd\u517c\u987e\u901a\u7528\u6027\uff08\u6ee1\u8db3\u591a\u5b66\u79d1\u591a\u6837\u53d8\u5316\u9700\u6c42\uff09\u4e0e\u6807\u51c6\u5316\uff08\u652f\u6301AI\u8fdb\u884c\u6709\u6548\u64cd\u4f5c\uff09\u7684\u7814\u7a76\u6570\u636e\u6570\u5b57\u5316\u5e73\u53f0\u3002\u8be5\u5e73\u53f0\u901a\u8fc7\u53ef\u5b9a\u5236\u3001\u6807\u51c6\u5316\u7684\u6570\u636e\u8bb0\u5f55\u63cf\u8ff0\u6574\u4e2a\u79d1\u7814\u6d41\u7a0b\uff0c\u5e76\u5f15\u5165AI\u667a\u80fd\u52a9\u624b\u652f\u6301\u667a\u80fd\u95ee\u7b54\u3001\u81ea\u52a8\u5f55\u5165\u6570\u636e\u3001\u5206\u6790\u53ca\u7814\u7a76\u81ea\u52a8\u5316\u3002\u5e73\u53f0\u5f3a\u8c03\u793e\u533a\u9a71\u52a8\u548c\u591a\u5b66\u79d1\u9002\u7528\u6027\u3002", "result": "Airalogy\u5df2\u5728\u897f\u6e56\u5927\u5b66\u56db\u5927\u5b66\u9662\u7684\u5b9e\u9a8c\u5ba4\u90e8\u7f72\uff0c\u521d\u6b65\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u5b66\u79d1\u573a\u666f\u4e0b\u7684\u5e94\u7528\u80fd\u529b\u3002\u5e73\u53f0\u6709\u671b\u5728\u66f4\u5e7f\u6cdb\u7684\u5b66\u672f\u548c\u5de5\u4e1a\u9886\u57df\u63a8\u5e7f\uff0c\u4fc3\u8fdb\u79d1\u5b66\u521b\u65b0\u81ea\u52a8\u5316\u548c\u52a0\u901f\u3002", "conclusion": "\u901a\u8fc7Airalogy\u5e73\u53f0\uff0c\u5b9e\u73b0\u4e86\u591a\u5b66\u79d1\u7814\u7a76\u6570\u636e\u7684\u6807\u51c6\u5316\u6570\u5b57\u5316\u4e0eAI\u8f85\u52a9\u7814\u7a76\uff0c\u6709\u6548\u5e73\u8861\u4e86\u591a\u6837\u6027\u9700\u6c42\u4e0e\u7edf\u4e00\u6807\u51c6\uff0c\u63a8\u52a8\u79d1\u5b66\u7814\u7a76\u6570\u5b57\u5316\u548cAI\u9a71\u52a8\u7684\u79d1\u5b66\u521b\u65b0\u3002"}}
{"id": "2506.17525", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17525", "abs": "https://arxiv.org/abs/2506.17525", "authors": ["Mingfei Lau", "Qian Chen", "Yeming Fang", "Tingting Xu", "Tongzhou Chen", "Pavel Golik"], "title": "Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning", "comment": "Accepted by ACL 2025 Main Conference", "summary": "Our quality audit for three widely used public multilingual speech datasets -\nMozilla Common Voice 17.0, FLEURS, and VoxPopuli - shows that in some\nlanguages, these datasets suffer from significant quality issues. We believe\naddressing these issues will make these datasets more useful as training and\nevaluation sets, and improve downstream models. We divide these quality issues\ninto two categories: micro-level and macro-level. We find that macro-level\nissues are more prevalent in less institutionalized, often under-resourced\nlanguages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that\nhighlights the need for proactive language planning (e.g. orthography\nprescriptions, dialect boundary definition) and enhanced data quality control\nin the process of Automatic Speech Recognition (ASR) dataset creation. We\nconclude by proposing guidelines and recommendations to mitigate these issues\nin future dataset development, emphasizing the importance of sociolinguistic\nawareness in creating robust and reliable speech data resources.", "AI": {"tldr": "\u5bf9\u4e3b\u6d41\u591a\u8bed\u8a00\u8bed\u97f3\u6570\u636e\u96c6\u7684\u8d28\u91cf\u8fdb\u884c\u4e86\u7cfb\u7edf\u5206\u6790\uff0c\u53d1\u73b0\u6b20\u8d44\u6e90\u8bed\u8a00\u9762\u4e34\u66f4\u4e25\u91cd\u7684\u5b8f\u89c2\u8d28\u91cf\u95ee\u9898\uff0c\u5e76\u4ee5\u53f0\u8bed\u4e3a\u4f8b\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\uff0c\u547c\u5401\u5728\u6570\u636e\u96c6\u5efa\u8bbe\u4e2d\u91cd\u89c6\u793e\u4f1a\u8bed\u8a00\u5b66\u56e0\u7d20\u3002", "motivation": "\u76ee\u524d\u4e3b\u6d41\u591a\u8bed\u8a00\u8bed\u97f3\u6570\u636e\u96c6\u5728\u90e8\u5206\u8bed\u8a00\u4e0a\u5b58\u5728\u4e25\u91cd\u7684\u8d28\u91cf\u95ee\u9898\uff0c\u5c24\u5176\u5bf9\u6b20\u8d44\u6e90\u8bed\u8a00\u5f71\u54cd\u66f4\u5927\uff0c\u6025\u9700\u63d0\u5347\u6570\u636e\u96c6\u7684\u8d28\u91cf\u4ee5\u4fc3\u8fdb\u8bad\u7ec3\u548c\u8bc4\u4f30\u7684\u6709\u6548\u6027\u3002", "method": "\u5bf9Mozilla Common Voice 17.0\u3001FLEURS\u548cVoxPopuli\u4e09\u4e2a\u4e3b\u6d41\u591a\u8bed\u8a00\u8bed\u97f3\u6570\u636e\u96c6\u8fdb\u884c\u8d28\u91cf\u5ba1\u8ba1\uff0c\u5e76\u4ee5\u53f0\u8bed\uff08\u53f0\u7063\u95a9\u5357\u8a9e\uff09\u4e3a\u6848\u4f8b\u5206\u6790\uff0c\u5f52\u7eb3\u6570\u636e\u96c6\u95ee\u9898\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u3002", "result": "\u53d1\u73b0\u5b8f\u89c2\u8d28\u91cf\u95ee\u9898\u5728\u6b20\u8d44\u6e90\u8bed\u8a00\u4e2d\u66f4\u7a81\u51fa\uff0c\u5bf9\u53f0\u8bed\u6570\u636e\u96c6\u6df1\u5165\u5256\u6790\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u6570\u636e\u96c6\u5f00\u53d1\u7684\u6307\u5bfc\u539f\u5219\u548c\u4f18\u5316\u5efa\u8bae\uff0c\u4ee5\u63d0\u5347ASR\u6570\u636e\u96c6\u6574\u4f53\u8d28\u91cf\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6539\u5584\u591a\u8bed\u8a00\u8bed\u97f3\u6570\u636e\u96c6\u8d28\u91cf\u7684\u5efa\u8bae\uff0c\u5e76\u5f3a\u8c03\u4e86\u793e\u4f1a\u8bed\u8a00\u5b66\u610f\u8bc6\u5728\u6570\u636e\u96c6\u521b\u5efa\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.17834", "categories": ["cs.AI", "cs.HC", "I.2.6; H.5.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.17834", "abs": "https://arxiv.org/abs/2506.17834", "authors": ["Carter Blair", "Kate Larson", "Edith Law"], "title": "Reflective Verbal Reward Design for Pluralistic Alignment", "comment": "9 pages, 3 figures, accepted to the IJCAI 2025 Human-Centred AI\n  track. Project repository at: https://osf.io/8yxf2/", "summary": "AI agents are commonly aligned with \"human values\" through reinforcement\nlearning from human feedback (RLHF), where a single reward model is learned\nfrom aggregated human feedback and used to align an agent's behavior. However,\nhuman values are not homogeneous--different people hold distinct and sometimes\nconflicting values. Aggregating feedback into a single reward model risks\ndisproportionately suppressing minority preferences. To address this, we\npresent a novel reward modeling approach for learning individualized reward\nmodels. Our approach uses a language model to guide users through reflective\ndialogues where they critique agent behavior and construct their preferences.\nThis personalized dialogue history, containing the user's reflections and\ncritiqued examples, is then used as context for another language model that\nserves as an individualized reward function (what we call a \"verbal reward\nmodel\") for evaluating new trajectories. In studies with 30 participants, our\nmethod achieved a 9-12% improvement in accuracy over non-reflective verbal\nreward models while being more sample efficient than traditional supervised\nlearning methods.", "AI": {"tldr": "\u8bba\u6587\u9488\u5bf9\u73b0\u6709AI\u5bf9\u9f50\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u4e2a\u4f53\u4ef7\u503c\u591a\u6837\u6027\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u57fa\u4e8e\u53cd\u601d\u5bf9\u8bdd\u548c\u4e2a\u6027\u5316\u5956\u52b1\u5efa\u6a21\u7684\u65b0\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5bf9\u7528\u6237\u504f\u597d\u7684\u51c6\u786e\u5efa\u6a21\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5e38\u7528\u7684\u4eba\u5de5\u667a\u80fd\u5bf9\u9f50\u65b9\u6848\u901a\u8fc7\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60(RLHF)\u6765\u5b9e\u73b0\uff0c\u5c06\u4eba\u7c7b\u53cd\u9988\u8fdb\u884c\u805a\u5408\uff0c\u5f97\u5230\u5355\u4e00\u7684\u5956\u52b1\u6a21\u578b\u7528\u4e8e\u7ea6\u675fAI\u884c\u4e3a\uff0c\u5ffd\u89c6\u4e86\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u591a\u6837\u6027\u4e0e\u51b2\u7a81\uff0c\u53ef\u80fd\u4f1a\u538b\u5236\u5c11\u6570\u7fa4\u4f53\u7684\u504f\u597d\u3002", "method": "\u63d0\u51fa\u4e86\u65b0\u7684\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5\uff1a\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u7528\u6237\u8fdb\u884c\u53cd\u601d\u5f0f\u5bf9\u8bdd\uff0c\u7528\u6237\u5728\u5bf9\u8bdd\u4e2d\u6279\u5224\u5e76\u8868\u8ff0\u81ea\u5df1\u5bf9AI\u884c\u4e3a\u7684\u504f\u597d\uff0c\u5c06\u8fd9\u4e9b\u53cd\u601d\u6027\u5bf9\u8bdd\u5386\u53f2\u7528\u4f5c\u53e6\u4e00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\uff0c\u751f\u6210\u4e2a\u6027\u5316\u7684\u53e3\u5934\u5956\u52b1\u6a21\u578b\uff0c\u7528\u5176\u8bc4\u4ef7\u65b0\u884c\u4e3a\u3002", "result": "\u572830\u540d\u53c2\u4e0e\u8005\u5b9e\u9a8c\u4e2d\uff0c\u8fd9\u79cd\u65b9\u6cd5\u6bd4\u975e\u53cd\u601d\u578b\u53e3\u5934\u5956\u52b1\u6a21\u578b\u7684\u51c6\u786e\u7387\u63d0\u9ad8\u4e869-12%\uff0c\u4e14\u6bd4\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u66f4\u9ad8\u6548\u5730\u5229\u7528\u6837\u672c\u3002", "conclusion": "\u4e2a\u6027\u5316\u5956\u52b1\u6a21\u578b\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u4e0d\u540c\u7528\u6237\u72ec\u7279\u7684\u4ef7\u503c\u89c2\uff0c\u6709\u6548\u63d0\u5347AI\u5bf9\u4e2a\u4eba\u504f\u597d\u7684\u5bf9\u9f50\u6548\u679c\uff0c\u5e76\u5728\u6837\u672c\u5229\u7528\u7387\u548c\u51c6\u786e\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2506.18133", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.18133", "abs": "https://arxiv.org/abs/2506.18133", "authors": ["Jessica Dai", "Inioluwa Deborah Raji", "Benjamin Recht", "Irene Y. Chen"], "title": "Aggregated Individual Reporting for Post-Deployment Evaluation", "comment": null, "summary": "The need for developing model evaluations beyond static benchmarking,\nespecially in the post-deployment phase, is now well-understood. At the same\ntime, concerns about the concentration of power in deployed AI systems have\nsparked a keen interest in 'democratic' or 'public' AI. In this work, we bring\nthese two ideas together by proposing mechanisms for aggregated individual\nreporting (AIR), a framework for post-deployment evaluation that relies on\nindividual reports from the public. An AIR mechanism allows those who interact\nwith a specific, deployed (AI) system to report when they feel that they may\nhave experienced something problematic; these reports are then aggregated over\ntime, with the goal of evaluating the relevant system in a fine-grained manner.\nThis position paper argues that individual experiences should be understood as\nan integral part of post-deployment evaluation, and that the scope of our\nproposed aggregated individual reporting mechanism is a practical path to that\nend. On the one hand, individual reporting can identify substantively novel\ninsights about safety and performance; on the other, aggregation can be\nuniquely useful for informing action. From a normative perspective, the\npost-deployment phase completes a missing piece in the conversation about\n'democratic' AI. As a pathway to implementation, we provide a workflow of\nconcrete design decisions and pointers to areas requiring further research and\nmethodological development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAIR\u673a\u5236\uff0c\u8ba9\u7528\u6237\u62a5\u544aAI\u7cfb\u7edf\u4f7f\u7528\u4e2d\u7684\u95ee\u9898\u5e76\u805a\u5408\u5206\u6790\uff0c\u5b9e\u73b0\u66f4\u7ec6\u81f4\u3001\u6c11\u4e3b\u7684\u540e\u90e8\u7f72\u8bc4\u4f30\uff1b\u5f3a\u8c03\u8be5\u65b9\u5f0f\u6709\u52a9\u53d1\u73b0\u65b0\u95ee\u9898\u5e76\u63a8\u52a8AI\u7cfb\u7edf\u6539\u8fdb\uff0c\u8865\u8db3\u4f20\u7edf\u8bc4\u4f30\u6a21\u5f0f\u7684\u4e0d\u8db3\uff0c\u5e76\u7ed9\u51fa\u5b9e\u8df5\u8def\u5f84\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u90e8\u7f72\u540e\u7684\u8bc4\u4f30\u5c40\u9650\u4e8e\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4f7f\u7528\u4e2d\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4eba\u4eec\u5bf9\u4e8eAI\u7cfb\u7edf\u6743\u529b\u96c6\u4e2d\u7684\u62c5\u5fe7\uff0c\u63a8\u52a8\u4e86\u5bf9\u201c\u6c11\u4e3b\u201d\u6216\u201c\u516c\u4f17\u201dAI\u7684\u5174\u8da3\u3002\u79d1\u5b66\u6709\u6548\u5730\u5f15\u5165\u516c\u4f17\u53c2\u4e0eAI\u7cfb\u7edf\u8bc4\u4f30\u6210\u4e3a\u4e00\u4e2a\u91cd\u8981\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u805a\u5408\u4e2a\u4eba\u62a5\u544a\uff08AIR\uff09\u7684\u673a\u5236\uff0c\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u90e8\u7f72\u540e\u8bc4\u4f30\u6846\u67b6\u3002\u8be5\u673a\u5236\u5141\u8bb8\u7528\u6237\u5728\u4e0eAI\u7cfb\u7edf\u4ea4\u4e92\u9047\u5230\u95ee\u9898\u65f6\u8fdb\u884c\u4e2a\u4eba\u62a5\u544a\uff0c\u968f\u540e\u5c06\u8fd9\u4e9b\u62a5\u544a\u8fdb\u884c\u6c47\u603b\u5206\u6790\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u52a0\u7ec6\u81f4\u7684\u540e\u671f\u8bc4\u4f30\u3002\u672c\u5de5\u4f5c\u8fd8\u8be6\u8ff0\u4e86AIR\u673a\u5236\u7684\u8bbe\u8ba1\u6d41\u7a0b\u53ca\u672a\u6765\u8fdb\u4e00\u6b65\u7814\u7a76\u9700\u8981\u5173\u6ce8\u7684\u95ee\u9898\u3002", "result": "AIR\u673a\u5236\u80fd\u591f\u53d1\u73b0\u4ee5\u5f80\u9759\u6001\u6d4b\u8bc4\u96be\u4ee5\u6355\u6349\u7684\u5b89\u5168\u6027\u548c\u6027\u80fd\u65b0\u95ee\u9898\uff0c\u805a\u5408\u5206\u6790\u4e3a\u540e\u7eed\u6539\u8fdb\u884c\u52a8\u63d0\u4f9b\u4f9d\u636e\uff0c\u4e5f\u4e3a\u6c11\u4e3b\u5316AI\u73b0\u5b9e\u8def\u5f84\u548c\u7406\u8bba\u63d0\u51fa\u4e86\u652f\u6301\u3002\u672c\u6587\u660e\u786e\u9610\u91ca\u4e86\u5b9e\u8df5\u4e2d\u7684\u8bbe\u8ba1\u8981\u70b9\u548c\u540e\u7eed\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u4e2a\u4eba\u4f53\u9a8c\u62a5\u544a\u5e94\u6210\u4e3aAI\u7cfb\u7edf\u90e8\u7f72\u540e\u8bc4\u4f30\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\u3002\u805a\u5408\u62a5\u544a\u673a\u5236\u4e0d\u4ec5\u62d3\u5bbd\u4e86\u5bf9AI\u7cfb\u7edf\u6027\u80fd\u548c\u5b89\u5168\u6027\u7684\u8ba4\u8bc6\u65b9\u5f0f\uff0c\u4e5f\u4e3a\u5b9e\u73b0\u2018\u6c11\u4e3b\u2019AI\u589e\u6dfb\u4e86\u53ef\u5b9e\u65bd\u8def\u5f84\uff0c\u5e76\u547c\u5401\u540e\u7eed\u6df1\u5165\u5b8c\u5584\u76f8\u5173\u6d41\u7a0b\u548c\u65b9\u6cd5\u3002"}}
{"id": "2506.17533", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17533", "abs": "https://arxiv.org/abs/2506.17533", "authors": ["Yuanhao Wu", "Juntong Song", "Hanning Zhang", "Tong Zhang", "Cheng Niu"], "title": "DuaShepherd: Integrating Stepwise Correctness and Potential Rewards for Mathematical Reasoning", "comment": null, "summary": "In this paper, we propose DuaShepherd, a novel reward modeling framework that\nintegrates two complementary reward signals, correctness and potential, to\nenhance the mathematical reasoning capabilities of Large Language Models\n(LLMs). While correctness-based signals emphasize identification of stepwise\nerrors, potential-based signals focus on the likelihood of reaching the correct\nfinal answer. We developed an automated pipeline for constructing large-scale\nreward modeling dataset with both signals. A unified, multi-head architecture\nwas explored to train the two reward models in a multi-task setup,\ndemonstrating benefits from learning both correctness and potential in\nparallel. By combining these two signals into a compound probability, our model\nachieves consistent performance improvements across multiple benchmarks.\nEmpirical evaluations on MATH500 and ProcessBench confirm that this combined\nreward significantly outperforms models trained on either reward type alone,\nachieving state-of-the-art performance under comparable resource constraints.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u7ed3\u5408\u201c\u6b63\u786e\u6027\u201d\u548c\u201c\u6f5c\u529b\u201d\u7684\u53cc\u5956\u52b1\u4fe1\u53f7\uff0c\u7528\u4e8e\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u80fd\u529b\u3002\u65b0\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5927\u5e45\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff0c\u521b\u4e0b\u6700\u65b0\u6700\u4f73\u6210\u7ee9\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u8fd8\u6709\u63d0\u5347\u7a7a\u95f4\u3002\u4f20\u7edf\u7684\u5956\u52b1\u5efa\u6a21\u591a\u4ee5\u201c\u6b63\u786e\u6027\u201d\u4e3a\u5355\u4e00\u5956\u52b1\u4fe1\u53f7\uff0c\u5ffd\u7565\u4e86\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u53d1\u5c55\u6f5c\u529b\u3002\u8be5\u6587\u63d0\u51fa\u7ed3\u5408\u4e24\u79cd\u4e92\u8865\u5956\u52b1\u4fe1\u53f7\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u63a8\u7406\u548c\u89e3\u9898\u80fd\u529b\u3002", "method": "\u63d0\u51faDuaShepherd\u5956\u52b1\u5efa\u6a21\u6846\u67b6\uff0c\u7ed3\u5408\u201c\u6b63\u786e\u6027\u201d\uff08\u7ea0\u9519\u80fd\u529b\uff09\u548c\u201c\u6f5c\u529b\u201d\uff08\u62b5\u8fbe\u6b63\u786e\u7b54\u6848\u7684\u53ef\u80fd\u6027\uff09\u4e24\u79cd\u4fe1\u53f7\u3002\u5f00\u53d1\u81ea\u52a8\u5316\u6570\u636e\u96c6\u6784\u5efa\u6d41\u7a0b\uff0c\u751f\u6210\u542b\u4e24\u79cd\u5956\u52b1\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u3002\u91c7\u7528\u591a\u5934\u591a\u4efb\u52a1\u67b6\u6784\uff0c\u8054\u5408\u8bad\u7ec3\u4e24\u79cd\u5956\u52b1\u6a21\u578b\uff0c\u5e76\u7ec4\u5408\u4e3a\u590d\u5408\u6982\u7387\u7528\u4e8e\u6700\u7ec8\u8bc4\u4f30\u3002", "result": "\u5728MATH500\u548cProcessBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDuaShepherd\u5728\u76f8\u540c\u7b97\u529b\u8d44\u6e90\u4e0b\uff0c\u6bd4\u4ec5\u4f7f\u7528\u5355\u4e00\u5956\u52b1\u4fe1\u53f7\u7684\u6a21\u578b\u53d6\u5f97\u66f4\u597d\u6210\u7ee9\uff0c\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u4f18\u7ed3\u679c\u3002", "conclusion": "\u7ed3\u5408\u6b63\u786e\u6027\u4e0e\u6f5c\u529b\u7684\u5956\u52b1\u4fe1\u53f7\u80fd\u534f\u540c\u63d0\u5347LLM\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0cDuaShepherd\u5b9e\u73b0\u4e86\u4e1a\u754c\u9886\u5148\u8868\u73b0\uff0c\u8bc1\u660e\u53cc\u4fe1\u53f7\u5956\u52b1\u7b56\u7565\u6709\u6548\u3002"}}
{"id": "2506.17846", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17846", "abs": "https://arxiv.org/abs/2506.17846", "authors": ["Elija Perrier"], "title": "Out of Control -- Why Alignment Needs Formal Control Theory (and an Alignment Control Stack)", "comment": "Under review for Neurips 2025", "summary": "This position paper argues that formal optimal control theory should be\ncentral to AI alignment research, offering a distinct perspective from\nprevailing AI safety and security approaches. While recent work in AI safety\nand mechanistic interpretability has advanced formal methods for alignment,\nthey often fall short of the generalisation required of control frameworks for\nother technologies. There is also a lack of research into how to render\ndifferent alignment/control protocols interoperable. We argue that by recasting\nalignment through principles of formal optimal control and framing alignment in\nterms of hierarchical stack from physical to socio-technical layers according\nto which controls may be applied we can develop a better understanding of the\npotential and limitations for controlling frontier models and agentic AI\nsystems. To this end, we introduce an Alignment Control Stack which sets out a\nhierarchical layered alignment stack, identifying measurement and control\ncharacteristics at each layer and how different layers are formally\ninteroperable. We argue that such analysis is also key to the assurances that\nwill be needed by governments and regulators in order to see AI technologies\nsustainably benefit the community. Our position is that doing so will bridge\nthe well-established and empirically validated methods of optimal control with\npractical deployment considerations to create a more comprehensive alignment\nframework, enhancing how we approach safety and reliability for advanced AI\nsystems.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u4ee5\u6700\u4f18\u63a7\u5236\u7406\u8bba\u4e3a\u57fa\u7840\u5efa\u7acb\u5206\u5c42\u5bf9\u9f50\u6846\u67b6\uff0c\u63d0\u5347AI\u5bf9\u9f50\u65b9\u6cd5\u7684\u7cfb\u7edf\u6027\u548c\u901a\u7528\u6027\uff0c\u4e3a\u672a\u6765AI\u7cfb\u7edf\u7684\u5b89\u5168\u548c\u53ef\u76d1\u7ba1\u90e8\u7f72\u5960\u5b9a\u7406\u8bba\u652f\u6491\u3002", "motivation": "\u5f53\u524dAI\u5b89\u5168\u548c\u5bf9\u9f50\u65b9\u6cd5\u867d\u7136\u5728\u5f62\u5f0f\u5316\u65b9\u6cd5\u4e0a\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5728\u901a\u7528\u6027\u548c\u4e0d\u540c\u534f\u8bae\u534f\u540c\u63a7\u5236\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u7cfb\u7edf\u4e14\u53ef\u63a8\u5e7f\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4ee5\u5f62\u5f0f\u6700\u4f18\u63a7\u5236\u7406\u8bba\u4e3a\u57fa\u7840\u7684\u201cAlignment Control Stack\u201d\uff08\u5bf9\u9f50\u63a7\u5236\u5806\u6808\uff09\u6846\u67b6\uff0c\u5c06AI\u5bf9\u9f50\u95ee\u9898\u5206\u5c42\u5efa\u6a21\uff0c\u4ece\u7269\u7406\u5230\u793e\u4f1a\u6280\u672f\u5c42\uff0c\u660e\u786e\u5404\u5c42\u7684\u5ea6\u91cf\u4e0e\u63a7\u5236\u7279\u6027\u53ca\u5c42\u95f4\u7684\u53ef\u4e92\u64cd\u4f5c\u6027\u3002", "result": "\u8be5\u5c42\u6b21\u5316\u6846\u67b6\u80fd\u7cfb\u7edf\u6027\u5206\u6790\u4e0e\u63a7\u5236\u5148\u8fdbAI\u6a21\u578b\u53ca\u81ea\u4e3b\u4f53\u7cfb\u7edf\uff0c\u5bf9\u653f\u5e9c\u548c\u76d1\u7ba1\u8005\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u52a9\u529bAI\u6280\u672f\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u548c\u5b9e\u9645\u90e8\u7f72\u3002", "conclusion": "\u5f62\u5f0f\u6700\u4f18\u63a7\u5236\u7406\u8bba\u5e94\u6210\u4e3aAI\u5bf9\u9f50\u7814\u7a76\u7684\u6838\u5fc3\uff0c\u53ef\u5c06\u63a7\u5236\u7406\u8bba\u7684\u6210\u719f\u65b9\u6cd5\u4e0eAI\u5b9e\u9645\u90e8\u7f72\u7ed3\u5408\uff0c\u4e3aAI\u5b89\u5168\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u66f4\u5b8c\u6574\u7684\u7406\u8bba\u4e0e\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2506.17542", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17542", "abs": "https://arxiv.org/abs/2506.17542", "authors": ["Nitin Venkateswaran", "Kevin Tang", "Ratree Wayland"], "title": "Probing for Phonology in Self-Supervised Speech Representations: A Case Study on Accent Perception", "comment": null, "summary": "Traditional models of accent perception underestimate the role of gradient\nvariations in phonological features which listeners rely upon for their accent\njudgments. We investigate how pretrained representations from current\nself-supervised learning (SSL) models of speech encode phonological\nfeature-level variations that influence the perception of segmental accent. We\nfocus on three segments: the labiodental approximant, the rhotic tap, and the\nretroflex stop, which are uniformly produced in the English of native speakers\nof Hindi as well as other languages in the Indian sub-continent. We use the\nCSLU Foreign Accented English corpus (Lander, 2007) to extract, for these\nsegments, phonological feature probabilities using Phonet (V\\'asquez-Correa et\nal., 2019) and pretrained representations from Wav2Vec2-BERT (Barrault et al.,\n2023) and WavLM (Chen et al., 2022) along with accent judgements by native\nspeakers of American English. Probing analyses show that accent strength is\nbest predicted by a subset of the segment's pretrained representation features,\nin which perceptually salient phonological features that contrast the expected\nAmerican English and realized non-native English segments are given prominent\nweighting. A multinomial logistic regression of pretrained representation-based\nsegment distances from American and Indian English baselines on accent ratings\nreveals strong associations between the odds of accent strength and distances\nfrom the baselines, in the expected directions. These results highlight the\nvalue of self-supervised speech representations for modeling accent perception\nusing interpretable phonological features.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u524d\u81ea\u76d1\u7763\u8bed\u97f3\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u7279\u5f81\u53ef\u4ee5\u6709\u6548\u6355\u6349\u5f71\u54cd\u53e3\u97f3\u611f\u77e5\u7684\u97f3\u7cfb\u7279\u5f81\u53d8\u5316\uff0c\u5e76\u80fd\u591f\u6709\u89e3\u91ca\u6027\u5730\u5efa\u6a21\u53e3\u97f3\u5f3a\u5ea6\u3002", "motivation": "\u4f20\u7edf\u7684\u53e3\u97f3\u611f\u77e5\u6a21\u578b\u4f4e\u4f30\u4e86\u8bed\u97f3\u7279\u5f81\u7684\u68af\u5ea6\u53d8\u5316\u5bf9\u542c\u4f17\u4f5c\u51fa\u53e3\u97f3\u5224\u65ad\u7684\u4f5c\u7528\u3002\u672c\u7814\u7a76\u65e8\u5728\u6df1\u5165\u4e86\u89e3\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u8bed\u97f3\u6a21\u578b\u9884\u8bad\u7ec3\u8868\u793a\u662f\u5426\u80fd\u591f\u6709\u6548\u7f16\u7801\u5728\u53e3\u97f3\u611f\u77e5\u4e2d\u5173\u952e\u7684\u97f3\u7cfb\u7279\u5f81\u53d8\u5316\u3002", "method": "\u805a\u7126\u4e8e\u4e09\u79cd\u7279\u5b9a\u8f85\u97f3\uff08\u5507\u9f7f\u8fd1\u97f3\u3001\u95ea\u97f3r\u3001\u5377\u820c\u585e\u97f3\uff09\uff0c\u4eceCSLU\u5916\u56fd\u53e3\u97f3\u82f1\u8bed\u8bed\u6599\u5e93\u4e2d\u63d0\u53d6\u76f8\u5173\u7247\u6bb5\uff0c\u7ed3\u5408Phonet\u5de5\u5177\u63d0\u53d6\u97f3\u7cfb\u7279\u5f81\u6982\u7387\uff0c\u4ee5\u53ca\u5229\u7528Wav2Vec2-BERT\u548cWavLM\u7b49\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u8868\u793a\uff0c\u5e76\u7ed3\u5408\u7f8e\u8bed\u6bcd\u8bed\u8005\u7684\u53e3\u97f3\u5224\u65ad\u3002\u7528\u63a2\u67e5\u5f0f\u5206\u6790\u548c\u591a\u9879Logistic\u56de\u5f52\uff0c\u8003\u5bdf\u9884\u8bad\u7ec3\u7279\u5f81\u4e0e\u53e3\u97f3\u611f\u77e5\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u80fd\u591f\u8f83\u597d\u9884\u6d4b\u53e3\u97f3\u5f3a\u5ea6\u7684\u662f\u4e00\u90e8\u5206\u9884\u8bad\u7ec3\u7684\u5206\u6bb5\u8868\u793a\u7279\u5f81\uff0c\u5176\u4e2d\u611f\u77e5\u663e\u8457\u7684\u97f3\u7cfb\u7279\u5f81\uff08\u533a\u5206\u7f8e\u5f0f\u82f1\u8bed\u548c\u5370\u5ea6\u6b21\u5927\u9646\u82f1\u8bed\uff09\u83b7\u5f97\u4e86\u8f83\u9ad8\u6743\u91cd\u3002\u4ee5\u9884\u8bad\u7ec3\u8868\u793a\u4e3a\u57fa\u7840\u7684\u7247\u6bb5\u4e0e\u7f8e\u5f0f\u82f1\u8bed\u548c\u5370\u5ea6\u82f1\u8bed\u57fa\u7ebf\u4e4b\u95f4\u7684\u8ddd\u79bb\u4e0e\u53e3\u97f3\u5f3a\u5ea6\u8bc4\u5206\u6709\u663e\u8457\u5173\u8054\uff0c\u65b9\u5411\u7b26\u5408\u9884\u671f\u3002", "conclusion": "\u81ea\u76d1\u7763\u8bed\u97f3\u8868\u793a\u5728\u5efa\u6a21\u57fa\u4e8e\u53ef\u89e3\u91ca\u97f3\u7cfb\u7279\u5f81\u7684\u53e3\u97f3\u611f\u77e5\u65b9\u9762\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2506.17878", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17878", "abs": "https://arxiv.org/abs/2506.17878", "authors": ["Tam Trinh", "Manh Nguyen", "Truong-Son Hy"], "title": "Towards Robust Fact-Checking: A Multi-Agent System with Advanced Evidence Retrieval", "comment": null, "summary": "The rapid spread of misinformation in the digital era poses significant\nchallenges to public discourse, necessitating robust and scalable fact-checking\nsolutions. Traditional human-led fact-checking methods, while credible,\nstruggle with the volume and velocity of online content, prompting the\nintegration of automated systems powered by Large Language Models (LLMs).\nHowever, existing automated approaches often face limitations, such as handling\ncomplex claims, ensuring source credibility, and maintaining transparency. This\npaper proposes a novel multi-agent system for automated fact-checking that\nenhances accuracy, efficiency, and explainability. The system comprises four\nspecialized agents: an Input Ingestion Agent for claim decomposition, a Query\nGeneration Agent for formulating targeted subqueries, an Evidence Retrieval\nAgent for sourcing credible evidence, and a Verdict Prediction Agent for\nsynthesizing veracity judgments with human-interpretable explanations.\nEvaluated on benchmark datasets (FEVEROUS, HOVER, SciFact), the proposed system\nachieves a 12.3% improvement in Macro F1-score over baseline methods. The\nsystem effectively decomposes complex claims, retrieves reliable evidence from\ntrusted sources, and generates transparent explanations for verification\ndecisions. Our approach contributes to the growing field of automated\nfact-checking by providing a more accurate, efficient, and transparent\nverification methodology that aligns with human fact-checking practices while\nmaintaining scalability for real-world applications. Our source code is\navailable at https://github.com/HySonLab/FactAgent", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u73b0\u6709\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u5904\u7406\u590d\u6742\u58f0\u660e\u3001\u4fdd\u8bc1\u8bc1\u636e\u53ef\u4fe1\u6027\u548c\u6838\u67e5\u900f\u660e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u56db\u4e2a\u529f\u80fd\u660e\u786e\u7684\u4ee3\u7406\u7ec4\u6210\u7684\u591a\u4ee3\u7406\u6838\u67e5\u7cfb\u7edf\uff0c\u7ecf\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u4e3b\u6d41\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u5177\u5907\u66f4\u5f3a\u7684\u51c6\u786e\u6027\u3001\u6548\u7387\u4e0e\u89e3\u91ca\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u65f6\u4ee3\u865a\u5047\u4fe1\u606f\u7684\u5feb\u901f\u4f20\u64ad\uff0c\u4f20\u7edf\u4eba\u5de5\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\u5df2\u96be\u4ee5\u5e94\u5bf9\u5927\u91cf\u548c\u9ad8\u901f\u589e\u957f\u7684\u7f51\u7edc\u5185\u5bb9\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u5f00\u53d1\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u8fdb\u884c\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\uff0c\u5305\u542b\u8f93\u5165\u5206\u89e3\u4ee3\u7406\u3001\u67e5\u8be2\u751f\u6210\u4ee3\u7406\u3001\u8bc1\u636e\u68c0\u7d22\u4ee3\u7406\u548c\u5224\u51b3\u9884\u6d4b\u4ee3\u7406\uff0c\u5206\u522b\u8d1f\u8d23\u628a\u590d\u6742\u58f0\u660e\u62c6\u5206\u3001\u751f\u6210\u9488\u5bf9\u6027\u5b50\u67e5\u8be2\u3001\u68c0\u7d22\u53ef\u4fe1\u8bc1\u636e\u5e76\u8f93\u51fa\u5e26\u53ef\u89e3\u91ca\u6027\u7684\u6838\u67e5\u7ed3\u8bba\u3002\u7cfb\u7edf\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u6d4b\u3002", "result": "\u5728FEVEROUS\u3001HOVER\u3001SciFact\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u7cfb\u7edf\u7684Macro F1\u5f97\u5206\u8f83\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u4e8612.3%\uff0c\u5728\u5206\u89e3\u590d\u6742\u58f0\u660e\u3001\u68c0\u7d22\u53ef\u4fe1\u8bc1\u636e\u4ee5\u53ca\u7ed9\u51fa\u900f\u660e\u89e3\u91ca\u7b49\u65b9\u9762\u6548\u679c\u7a81\u51fa\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u4ee3\u7406\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u63d0\u5347\u4e86\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8d34\u5408\u4eba\u5de5\u6838\u67e5\u6d41\u7a0b\u4e14\u5177\u5907\u73b0\u5b9e\u5e94\u7528\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2506.17578", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17578", "abs": "https://arxiv.org/abs/2506.17578", "authors": ["Lingxiao Zeng", "Yiqi Tong", "Wei Guo", "Huarui Wu", "Lihao Ge", "Yijun Ye", "Fuzhen Zhuang", "Deqing Wang", "Wei Guo", "Cheng Chen"], "title": "AgriCHN: A Comprehensive Cross-domain Resource for Chinese Agricultural Named Entity Recognition", "comment": null, "summary": "Agricultural named entity recognition is a specialized task focusing on\nidentifying distinct agricultural entities within vast bodies of text,\nincluding crops, diseases, pests, and fertilizers. It plays a crucial role in\nenhancing information extraction from extensive agricultural text resources.\nHowever, the scarcity of high-quality agricultural datasets, particularly in\nChinese, has resulted in suboptimal performance when employing mainstream\nmethods for this purpose. Most earlier works only focus on annotating\nagricultural entities while overlook the profound correlation of agriculture\nwith hydrology and meteorology. To fill this blank, we present AgriCHN, a\ncomprehensive open-source Chinese resource designed to promote the accuracy of\nautomated agricultural entity annotation. The AgriCHN dataset has been\nmeticulously curated from a wealth of agricultural articles, comprising a total\nof 4,040 sentences and encapsulating 15,799 agricultural entity mentions\nspanning 27 diverse entity categories. Furthermore, it encompasses entities\nfrom hydrology to meteorology, thereby enriching the diversity of entities\nconsidered. Data validation reveals that, compared with relevant resources,\nAgriCHN demonstrates outstanding data quality, attributable to its richer\nagricultural entity types and more fine-grained entity divisions. A benchmark\ntask has also been constructed using several state-of-the-art neural NER\nmodels. Extensive experimental results highlight the significant challenge\nposed by AgriCHN and its potential for further research.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86AgriCHN\uff0c\u4e00\u4e2a\u8986\u76d6\u519c\u4e1a\u3001\u6c34\u6587\u3001\u6c14\u8c61\u7b49\u9886\u57df\u7684\u9ad8\u8d28\u91cf\u4e2d\u6587\u519c\u4e1aNER\u6570\u636e\u96c6\u3002\u6570\u636e\u8d28\u91cf\u4f18\u826f\uff0c\u7c7b\u522b\u4e30\u5bcc\uff0c\u4e3aNER\u65b9\u6cd5\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u65b0\u8d44\u6e90\u548c\u5b9e\u9a8c\u5e73\u53f0\u3002", "motivation": "\u519c\u4e1a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u4efb\u52a1\u5bf9\u4e8e\u4ece\u5927\u91cf\u519c\u4e1a\u6587\u672c\u4e2d\u63d0\u53d6\u4fe1\u606f\u975e\u5e38\u5173\u952e\u3002\u7136\u800c\uff0c\u53d7\u9650\u4e8e\u9ad8\u8d28\u91cf\u519c\u4e1a\u6570\u636e\u96c6\uff08\u7279\u522b\u662f\u4e2d\u6587\u8d44\u6e90\uff09\u7684\u7a00\u7f3a\uff0c\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\u3002\u6b64\u5916\uff0c\u65e2\u6709\u5de5\u4f5c\u591a\u805a\u7126\u4e8e\u519c\u4e1a\u5b9e\u4f53\u672c\u8eab\uff0c\u5ffd\u89c6\u4e86\u519c\u4e1a\u4e0e\u6c34\u6587\u3001\u6c14\u8c61\u7b49\u9886\u57df\u7684\u6df1\u5ea6\u76f8\u5173\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86AgriCHN\uff0c\u8fd9\u662f\u4e00\u4e2a\u9762\u5411\u4e2d\u6587\u519c\u4e1a\u9886\u57df\u7684\u7efc\u5408\u6027\u5f00\u6e90\u8d44\u6e90\u3002\u6570\u636e\u96c6\u6765\u81ea\u5927\u91cf\u519c\u4e1a\u76f8\u5173\u6587\u7ae0\uff0c\u5305\u542b4,040\u4e2a\u53e5\u5b50\u548c15,799\u4e2a\u5b9e\u4f53\u63d0\u53ca\uff0c\u6db5\u76d627\u79cd\u591a\u6837\u7684\u5b9e\u4f53\u7c7b\u522b\uff0c\u5305\u62ec\u6c34\u6587\u548c\u6c14\u8c61\u9886\u57df\u3002\u901a\u8fc7\u5bf9\u6bd4\u5b9e\u9a8c\u8bc4\u4f30\u6570\u636e\u96c6\u8d28\u91cf\uff0c\u5e76\u57fa\u4e8e\u591a\u79cd\u4e3b\u6d41\u795e\u7ecf\u7f51\u7edcNER\u6a21\u578b\u6784\u5efa\u57fa\u51c6\u4efb\u52a1\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "AgriCHN\u6570\u636e\u96c6\u76f8\u8f83\u4e8e\u76f8\u5173\u8d44\u6e90\u8d28\u91cf\u66f4\u9ad8\uff0c\u5b9e\u4f53\u7c7b\u578b\u66f4\u4e30\u5bcc\u3001\u5212\u5206\u66f4\u7ec6\u81f4\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eAgriCHN\u5177\u6709\u8f83\u5927\u6311\u6218\u6027\u548c\u7814\u7a76\u6f5c\u529b\u3002", "conclusion": "AgriCHN\u6781\u5927\u4e30\u5bcc\u548c\u63d0\u5347\u4e86\u4e2d\u6587\u519c\u4e1a\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\u7684\u6570\u636e\u8d44\u6e90\u57fa\u7840\uff0c\u5e76\u4e3a\u8de8\u5b66\u79d1\u519c\u4e1a\u4fe1\u606f\u62bd\u53d6\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6491\u3002\u8be5\u6570\u636e\u96c6\u56e0\u6311\u6218\u6027\u5f3a\u548c\u8986\u76d6\u9762\u5e7f\uff0c\u6709\u671b\u4fc3\u8fdb\u76f8\u5173NER\u65b9\u6cd5\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2506.17900", "categories": ["cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.17900", "abs": "https://arxiv.org/abs/2506.17900", "authors": ["Cheng Ji", "Huaiying Luo"], "title": "Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms", "comment": "Accepted by 2025 8th International Conference on Advanced Electronic\n  Materials, Computers and Software Engineering (AEMCSE 2025)", "summary": "With the increasing complexity and rapid expansion of the scale of AI systems\nin cloud platforms, the log data generated during system operation is massive,\nunstructured, and semantically ambiguous, which brings great challenges to\nfault location and system self-repair. In order to solve this problem, this\npaper proposes an intelligent log processing and automatic debugging framework\nbased on Large Language Model (LLM), named Intelligent Debugger (LLM-ID). This\nmethod is extended on the basis of the existing pre-trained Transformer model,\nand integrates a multi-stage semantic inference mechanism to realize the\ncontext understanding of system logs and the automatic reconstruction of fault\nchains. Firstly, the system log is dynamically structured, and the unsupervised\nclustering and embedding mechanism is used to extract the event template and\nsemantic schema. Subsequently, the fine-tuned LLM combined with the multi-round\nattention mechanism to perform contextual reasoning on the log sequence to\ngenerate potential fault assumptions and root cause paths. Furthermore, this\npaper introduces a reinforcement learning-based policy-guided recovery planner,\nwhich is driven by the remediation strategy generated by LLM to support dynamic\ndecision-making and adaptive debugging in the cloud environment. Compared with\nthe existing rule engine or traditional log analysis system, the proposed model\nhas stronger semantic understanding ability, continuous learning ability and\nheterogeneous environment adaptability. Experiments on the cloud platform log\ndataset show that LLM-ID improves the fault location accuracy by 16.2%, which\nis significantly better than the current mainstream methods", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e91\u5e73\u53f0\u65e5\u5fd7\u667a\u80fd\u5206\u6790\u4e0e\u81ea\u52a8\u8c03\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u8bed\u4e49\u63a8\u7406\u548c\u5f3a\u5316\u5b66\u4e60\u51b3\u7b56\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6545\u969c\u5b9a\u4f4d\u4e0e\u4fee\u590d\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u51c6\u786e\u7387\u63d0\u534716.2%\u3002", "motivation": "\u4e91\u5e73\u53f0AI\u7cfb\u7edf\u590d\u6742\u5ea6\u548c\u89c4\u6a21\u4e0d\u65ad\u63d0\u5347\uff0c\u5bfc\u81f4\u7cfb\u7edf\u8fd0\u884c\u65e5\u5fd7\u5de8\u5927\u4e14\u65e0\u7ed3\u6784\u3001\u8bed\u4e49\u6a21\u7cca\uff0c\u4f20\u7edf\u6545\u969c\u5b9a\u4f4d\u4e0e\u81ea\u6108\u9762\u4e34\u6311\u6218\uff0c\u6025\u9700\u667a\u80fd\u5316\u3001\u81ea\u52a8\u5316\u7684\u65b0\u65b9\u6cd5\u63d0\u5347\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u65e5\u5fd7\u5904\u7406\u4e0e\u81ea\u52a8\u8c03\u8bd5\u6846\u67b6\uff08LLM-ID\uff09\u3002\u65b9\u6cd5\u5305\u62ec\uff1a\uff081\uff09\u5728\u9884\u8bad\u7ec3Transformer\u6a21\u578b\u57fa\u7840\u4e0a\u6269\u5c55\uff0c\u878d\u5165\u591a\u9636\u6bb5\u8bed\u4e49\u63a8\u7406\u673a\u5236\uff0c\u5b9e\u73b0\u65e5\u5fd7\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0e\u6545\u969c\u94fe\u81ea\u52a8\u91cd\u5efa\uff1b\uff082\uff09\u52a8\u6001\u7ed3\u6784\u5316\u7cfb\u7edf\u65e5\u5fd7\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u805a\u7c7b\u548c\u5d4c\u5165\u673a\u5236\u63d0\u53d6\u4e8b\u4ef6\u6a21\u677f\u548c\u8bed\u4e49\u6a21\u5f0f\uff1b\uff083\uff09\u5fae\u8c03\u7684LLM\u7ed3\u5408\u591a\u8f6e\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5bf9\u65e5\u5fd7\u5e8f\u5217\u8fdb\u884c\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u751f\u6210\u6f5c\u5728\u6545\u969c\u5047\u8bbe\u548c\u6839\u56e0\u8def\u5f84\uff1b\uff084\uff09\u5f15\u5165\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7b56\u7565\u5f15\u5bfc\u6062\u590d\u89c4\u5212\uff0c\u4f9d\u636eLLM\u751f\u6210\u7684\u4fee\u590d\u7b56\u7565\uff0c\u652f\u6301\u52a8\u6001\u51b3\u7b56\u4e0e\u81ea\u9002\u5e94\u8c03\u8bd5\u3002", "result": "\u5728\u4e91\u5e73\u53f0\u65e5\u5fd7\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cLLM-ID\u6a21\u578b\u7684\u6545\u969c\u5b9a\u4f4d\u51c6\u786e\u7387\u63d0\u534716.2%\uff0c\u663e\u8457\u4f18\u4e8e\u4e3b\u6d41\u4f20\u7edf\u65b9\u6cd5\u3002\u5177\u5907\u66f4\u5f3a\u8bed\u4e49\u7406\u89e3\u3001\u6301\u7eed\u5b66\u4e60\u53ca\u5f02\u6784\u73af\u5883\u9002\u5e94\u529b\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u65e5\u5fd7\u667a\u80fd\u5206\u6790\u4e0e\u81ea\u52a8\u8c03\u8bd5\u6846\u67b6LLM-ID\uff0c\u5728\u4e91\u73af\u5883\u4e0b\u6781\u5927\u63d0\u5347\u4e86\u6545\u969c\u5b9a\u4f4d\u7684\u6548\u7387\u548c\u51c6\u786e\u7387\uff0c\u4e3a\u5927\u89c4\u6a21AI\u7cfb\u7edf\u8fd0\u7ef4\u667a\u80fd\u5316\u63d0\u4f9b\u4e86\u521b\u65b0\u601d\u8def\u548c\u6709\u6548\u624b\u6bb5\u3002"}}
{"id": "2506.17603", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17603", "abs": "https://arxiv.org/abs/2506.17603", "authors": ["Jonathan Sakunkoo", "Annabella Sakunkoo"], "title": "Mind the Gap: Assessing Wiktionary's Crowd-Sourced Linguistic Knowledge on Morphological Gaps in Two Related Languages", "comment": null, "summary": "Morphological defectivity is an intriguing and understudied phenomenon in\nlinguistics. Addressing defectivity, where expected inflectional forms are\nabsent, is essential for improving the accuracy of NLP tools in morphologically\nrich languages. However, traditional linguistic resources often lack coverage\nof morphological gaps as such knowledge requires significant human expertise\nand effort to document and verify. For scarce linguistic phenomena in\nunder-explored languages, Wikipedia and Wiktionary often serve as among the few\naccessible resources. Despite their extensive reach, their reliability has been\na subject of controversy. This study customizes a novel neural morphological\nanalyzer to annotate Latin and Italian corpora. Using the massive annotated\ndata, crowd-sourced lists of defective verbs compiled from Wiktionary are\nvalidated computationally. Our results indicate that while Wiktionary provides\na highly reliable account of Italian morphological gaps, 7% of Latin lemmata\nlisted as defective show strong corpus evidence of being non-defective. This\ndiscrepancy highlights potential limitations of crowd-sourced wikis as\ndefinitive sources of linguistic knowledge, particularly for less-studied\nphenomena and languages, despite their value as resources for rare linguistic\nfeatures. By providing scalable tools and methods for quality assurance of\ncrowd-sourced data, this work advances computational morphology and expands\nlinguistic knowledge of defectivity in non-English, morphologically rich\nlanguages.", "AI": {"tldr": "\u672c\u6587\u5b9a\u5236\u795e\u7ecf\u5f62\u6001\u5206\u6790\u5668\uff0c\u81ea\u52a8\u68c0\u9a8c\u62c9\u4e01\u8bed\u548c\u610f\u5927\u5229\u8bed\u4e2d\u4f17\u5305\uff08\u4e3b\u8981\u6307\u7ef4\u57fa\u8bcd\u5178\uff09\u6536\u96c6\u7684\u7f3a\u9677\u52a8\u8bcd\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u7ef4\u57fa\u8bcd\u5178\u5bf9\u610f\u8bed\u51c6\u786e\u4f46\u5bf9\u62c9\u4e01\u8bed\u6709\u4e0d\u8db3\uff0c\u5f3a\u8c03\u4e86\u5bf9\u6b64\u7c7b\u6570\u636e\u81ea\u52a8\u8d28\u63a7\u7684\u91cd\u8981\u6027\uff0c\u4e5f\u4e3a\u4e30\u5bcc\u5f62\u6001\u5b66\u548c\u7a00\u6709\u8bed\u8a00\u77e5\u8bc6\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002", "motivation": "\u5f62\u6001\u7f3a\u9677\u6027\u662f\u8bed\u8a00\u5b66\u4e2d\u4e00\u4e2a\u6709\u8da3\u4e14\u7814\u7a76\u4e0d\u8db3\u7684\u73b0\u8c61\uff0c\u6307\u7684\u662f\u67d0\u4e9b\u9884\u671f\u8bcd\u5f62\u53d8\u5316\u5f62\u5f0f\u7684\u7f3a\u5931\u3002\u4f20\u7edf\u8d44\u6e90\u96be\u4ee5\u5168\u9762\u8986\u76d6\u8fd9\u7c7b\u7a00\u6709\u73b0\u8c61\uff0c\u56e0\u6b64\u5b9e\u9645\u5206\u6790\u548c\u6587\u6863\u5316\u6781\u5177\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u8d44\u6599\u7a00\u7f3a\u7684\u8bed\u8a00\u4e2d\u3002\u4eba\u4eec\u5e38\u7528\u7ef4\u57fa\u767e\u79d1\u548c\u7ef4\u57fa\u8bcd\u5178\u7b49\u4f17\u5305\u8d44\u6e90\u4f5c\u4e3a\u66ff\u4ee3\uff0c\u4f46\u8fd9\u4e9b\u8d44\u6e90\u7684\u53ef\u9760\u6027\u5b58\u5728\u4e89\u8bae\u3002", "method": "\u8be5\u7814\u7a76\u5b9a\u5236\u4e86\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u5f62\u6001\u5206\u6790\u5668\uff0c\u7528\u4e8e\u5bf9\u62c9\u4e01\u8bed\u548c\u610f\u5927\u5229\u8bed\u8bed\u6599\u5e93\u8fdb\u884c\u6ce8\u91ca\u3002\u57fa\u4e8e\u8fd9\u4e2a\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\uff0c\u8fdb\u4e00\u6b65\u5bf9\u4ece\u7ef4\u57fa\u8bcd\u5178\u6574\u7406\u7684\u7f3a\u9677\u52a8\u8bcd\u5217\u8868\u8fdb\u884c\u8ba1\u7b97\u9a8c\u8bc1\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u7ef4\u57fa\u8bcd\u5178\u5bf9\u4e8e\u610f\u5927\u5229\u8bed\u7684\u5f62\u6001\u7f3a\u9677\u8bcd\u6761\u9ad8\u5ea6\u53ef\u9760\uff0c\u4f46\u5bf9\u62c9\u4e01\u8bed\u4e2d\u5217\u4e3a\u7f3a\u9677\u7684\u8bcd\u6761\uff0c\u67097%\u88ab\u8bed\u6599\u8bc1\u636e\u5224\u5b9a\u4e3a\u5e76\u975e\u771f\u6b63\u7684\u7f3a\u9677\u5f62\u5f0f\u3002\u8fd9\u63ed\u793a\u4e86\u4f17\u5305\u8d44\u6e90\u5728\u5904\u7406\u90e8\u5206\u5c11\u89c1\u8bed\u8a00\u73b0\u8c61\u65f6\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7f3a\u9677\u5f62\u6001\u7684\u7814\u7a76\u5c24\u5176\u662f\u5728\u62c9\u4e01\u8bed\u3001\u610f\u5927\u5229\u8bed\u7b49\u5f62\u6001\u4e30\u5bcc\u3001\u4f46\u975e\u82f1\u8bed\u7684\u8bed\u8a00\u4e2d\uff0c\u63d0\u4f9b\u4e86\u5927\u89c4\u6a21\u7684\u81ea\u52a8\u5316\u8d28\u63a7\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u8ba1\u7b97\u5f62\u6001\u5b66\u548c\u7a00\u6709\u8bed\u8a00\u77e5\u8bc6\u7684\u6269\u5c55\u3002"}}
{"id": "2506.17913", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17913", "abs": "https://arxiv.org/abs/2506.17913", "authors": ["Jinjie Wei", "Jiyao Liu", "Lihao Liu", "Ming Hu", "Junzhi Ning", "Mingcheng Li", "Weijie Yin", "Junjun He", "Xiao Liang", "Chao Feng", "Dingkang Yang"], "title": "Learning, Reasoning, Refinement: A Framework for Kahneman's Dual-System Intelligence in GUI Agents", "comment": null, "summary": "Graphical User Interface (GUI) agents have made significant progress in\nautomating digital tasks through the utilization of computer vision and\nlanguage models. Nevertheless, existing agent systems encounter notable\nlimitations. Firstly, they predominantly depend on trial and error decision\nmaking rather than progressive reasoning, thereby lacking the capability to\nlearn and adapt from interactive encounters. Secondly, these systems are\nassessed using overly simplistic single step accuracy metrics, which do not\nadequately reflect the intricate nature of real world GUI interactions. In this\npaper, we present CogniGUI, a cognitive framework developed to overcome these\nlimitations by enabling adaptive learning for GUI automation resembling\nhuman-like behavior. Inspired by Kahneman's Dual Process Theory, our approach\ncombines two main components: (1) an omni parser engine that conducts immediate\nhierarchical parsing of GUI elements through quick visual semantic analysis to\nidentify actionable components, and (2) a Group based Relative Policy\nOptimization (GRPO) grounding agent that assesses multiple interaction paths\nusing a unique relative reward system, promoting minimal and efficient\noperational routes. This dual-system design facilitates iterative ''exploration\nlearning mastery'' cycles, enabling the agent to enhance its strategies over\ntime based on accumulated experience. Moreover, to assess the generalization\nand adaptability of agent systems, we introduce ScreenSeek, a comprehensive\nbenchmark that includes multi application navigation, dynamic state\ntransitions, and cross interface coherence, which are often overlooked\nchallenges in current benchmarks. Experimental results demonstrate that\nCogniGUI surpasses state-of-the-art methods in both the current GUI grounding\nbenchmarks and our newly proposed benchmark.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa CogniGUI\uff0c\u521b\u65b0\u6027\u5730\u878d\u5408\u5206\u5c42\u89c6\u89c9\u89e3\u6790\u548c\u57fa\u4e8e\u5956\u52b1\u7684\u9ad8\u6548\u4ea4\u4e92\u51b3\u7b56\uff0c\u5b9e\u73b0\u4e86\u7c7b\u4eba\u5316\u7684 GUI \u4efb\u52a1\u81ea\u52a8\u5b66\u4e60\u3002\u65b0\u57fa\u51c6 ScreenSeek \u4e0b\uff0c\u5176\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5177\u5907\u5f88\u5f3a\u7684\u6cdb\u5316\u548c\u9002\u5e94\u6027\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u667a\u80fd\u4f53\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u5c1d\u8bd5-\u9519\u8bef\u578b\u51b3\u7b56\uff0c\u7f3a\u4e4f\u8fdb\u9636\u63a8\u7406\u80fd\u529b\u548c\u4ece\u4ea4\u4e92\u4e2d\u5b66\u4e60\u9002\u5e94\u7684\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8bc4\u4ef7\u6307\u6807\u591a\u4e3a\u7b80\u5355\u7684\u5355\u6b65\u51c6\u786e\u7387\uff0c\u65e0\u6cd5\u5168\u9762\u53cd\u6620\u771f\u5b9e GUI \u4ea4\u4e92\u7684\u590d\u6742\u6027\u3002", "method": "\u63d0\u51fa\u4e86 CogniGUI\uff0c\u4e00\u4e2a\u53d7 Kahneman \u7684\u53cc\u7cfb\u7edf\u7406\u8bba\u542f\u53d1\u7684\u8ba4\u77e5\u67b6\u6784\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\u4e24\u5927\u6838\u5fc3\uff1a1) \u5168\u80fd\u89e3\u6790\u5668\u5f15\u64ce\uff0c\u80fd\u5feb\u901f\u5206\u5c42\u89e3\u6790 GUI \u5143\u7d20\u4ee5\u8bc6\u522b\u53ef\u64cd\u4f5c\u7ec4\u4ef6\uff1b2) \u57fa\u4e8e\u7fa4\u4f53\u7684\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u667a\u80fd\u4f53\uff0c\u91c7\u7528\u76f8\u5bf9\u5956\u52b1\u673a\u5236\u8bc4\u4f30\u591a\u6761\u4ea4\u4e92\u8def\u5f84\uff0c\u4fc3\u8fdb\u9ad8\u6548\u64cd\u4f5c\u3002\u8be5\u53cc\u7cfb\u7edf\u652f\u6301\u667a\u80fd\u4f53\u901a\u8fc7\u201c\u63a2\u7d22-\u5b66\u4e60-\u7cbe\u901a\u201d\u5faa\u73af\u4e0d\u65ad\u63d0\u5347\u7b56\u7565\u3002\u6b64\u5916\uff0c\u6784\u5efa\u4e86\u65b0\u7684\u8bc4\u6d4b\u57fa\u51c6 ScreenSeek\uff0c\u6db5\u76d6\u591a\u5e94\u7528\u5bfc\u822a\u3001\u52a8\u6001\u72b6\u6001\u5207\u6362\u548c\u8de8\u754c\u9762\u534f\u540c\u7b49\u6311\u6218\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cCogniGUI \u65e0\u8bba\u5728\u73b0\u6709 GUI \u57fa\u51c6\u8fd8\u662f\u65b0\u63d0\u51fa\u7684 ScreenSeek \u57fa\u51c6\u4e0a\uff0c\u6027\u80fd\u5747\u8d85\u8fc7\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "CogniGUI \u80fd\u5b9e\u73b0\u66f4\u63a5\u8fd1\u4eba\u7c7b\u884c\u4e3a\u7684\u81ea\u9002\u5e94 GUI \u81ea\u52a8\u5316\u5b66\u4e60\uff0c\u5e76\u5728\u66f4\u5177\u6311\u6218\u6027\u7684\u8bc4\u6d4b\u4e2d\u5c55\u73b0\u51fa\u4f18\u5f02\u7684\u6cdb\u5316\u4e0e\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2506.18116", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.18116", "abs": "https://arxiv.org/abs/2506.18116", "authors": ["Batool Haider", "Atmika Gorti", "Aman Chadha", "Manas Gaur"], "title": "Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives", "comment": "19 Pages, 7 Figures, 4 Tables (Note: Under Review)", "summary": "Large Language Models (LLMs) in mental healthcare risk propagating biases\nthat reinforce stigma and harm marginalized groups. While previous research\nidentified concerning trends, systematic methods for detecting intersectional\nbiases remain limited. This work introduces a multi-hop question answering\n(MHQA) framework to explore LLM response biases in mental health discourse. We\nanalyze content from the Interpretable Mental Health Instruction (IMHI) dataset\nacross symptom presentation, coping mechanisms, and treatment approaches. Using\nsystematic tagging across age, race, gender, and socioeconomic status, we\ninvestigate bias patterns at demographic intersections. We evaluate four LLMs:\nClaude 3.5 Sonnet, Jamba 1.6, Gemma 3, and Llama 4, revealing systematic\ndisparities across sentiment, demographics, and mental health conditions. Our\nMHQA approach demonstrates superior detection compared to conventional methods,\nidentifying amplification points where biases magnify through sequential\nreasoning. We implement two debiasing techniques: Roleplay Simulation and\nExplicit Bias Reduction, achieving 66-94% bias reductions through few-shot\nprompting with BBQ dataset examples. These findings highlight critical areas\nwhere LLMs reproduce mental healthcare biases, providing actionable insights\nfor equitable AI development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u591a\u8df3\u95ee\u7b54\u68c0\u6d4bLLM\u5fc3\u7406\u5065\u5eb7\u8bdd\u8bed\u4e2d\u7684\u7ec6\u81f4\u4ea4\u53c9\u6027\u504f\u89c1\uff0c\u8bc4\u4f304\u79cd\u4e3b\u6d41\u6a21\u578b\uff0c\u63ed\u793a\u5404\u7c7b\u504f\u89c1\u653e\u5927\u70b9\uff0c\u91c7\u7528Few-shot\u53bb\u504f\u65b9\u6cd5\u53ef\u663e\u8457\u964d\u4f4e\u504f\u89c1\uff0c\u4e3a\u516c\u5e73AI\u63d0\u4f9b\u6709\u529b\u624b\u6bb5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u6709\u53ef\u80fd\u4f20\u64ad\u504f\u89c1\uff0c\u52a0\u5267\u5bf9\u8fb9\u7f18\u7fa4\u4f53\u7684\u4f24\u5bb3\uff0c\u4f46\u73b0\u6709\u68c0\u6d4b\u6a21\u578b\u4ea4\u53c9\u6027\u504f\u89c1\u7684\u7cfb\u7edf\u65b9\u6cd5\u6709\u9650\u3002\u672c\u6587\u53d7\u6b64\u6311\u6218\u9a71\u52a8\uff0c\u65e8\u5728\u63d0\u51fa\u548c\u9a8c\u8bc1\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u591a\u8df3\u95ee\u7b54\uff08MHQA\uff09\u6846\u67b6\u4ee5\u7cfb\u7edf\u68c0\u6d4b\u5fc3\u7406\u5065\u5eb7\u8bdd\u8bed\u4e2d\u7684LLM\u56de\u590d\u504f\u89c1\uff1b\u5bf9IMHI\u6570\u636e\u96c6\u5185\u5bb9\u6309\u7167\u5e74\u9f84\u3001\u79cd\u65cf\u3001\u6027\u522b\u548c\u793e\u4f1a\u7ecf\u6d4e\u72b6\u6001\u8fdb\u884c\u6807\u7b7e\uff0c\u5206\u6790\u4e0d\u540c\u4eba\u53e3\u4ea4\u53c9\u70b9\u7684\u504f\u89c1\uff1b\u5bf9Claude 3.5 Sonnet\u3001Jamba 1.6\u3001Gemma 3\u548cLlama 4\u7b49\u56db\u4e2aLLM\u8fdb\u884c\u8bc4\u4f30\uff1b\u91c7\u7528\u89d2\u8272\u626e\u6f14\u6a21\u62df\u548c\u663e\u5f0f\u504f\u89c1\u6d88\u9664\u4e24\u79cd\u53bb\u504f\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7BBQ\u6570\u636e\u7684few-shot \u63d0\u793a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "MHQA\u65b9\u6cd5\u5728\u68c0\u6d4b\u504f\u89c1\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u80fd\u8bc6\u522b\u987a\u63a8\u63a8\u7406\u4e2d\u504f\u89c1\u7684\u653e\u5927\u70b9\uff1b\u4e24\u79cd\u53bb\u504f\u6280\u672f\u53ef\u901a\u8fc7few-shot prompting\u5b9e\u73b066-94%\u7684\u504f\u89c1\u51cf\u5c11\u3002", "conclusion": "LLMs\u5728\u5fc3\u7406\u5065\u5eb7\u8bdd\u8bed\u4e2d\u786e\u5b9e\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u751a\u81f3\u5728\u7ec6\u5206\u4eba\u7fa4\u4ea4\u53c9\u5904\u653e\u5927\u3002\u63d0\u51fa\u7684MHQA\u68c0\u6d4b\u6846\u67b6\u548c\u53bb\u504f\u6280\u672f\u4e3a\u66f4\u516c\u5e73\u7684AI\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u548c\u5b9e\u8df5\u5efa\u8bae\u3002"}}
{"id": "2506.17609", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17609", "abs": "https://arxiv.org/abs/2506.17609", "authors": ["Lincan Li", "Eren Erman Ozguven", "Yue Zhao", "Guang Wang", "Yiqun Xie", "Yushun Dong"], "title": "TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting", "comment": null, "summary": "Accurate typhoon track forecasting is crucial for early system warning and\ndisaster response. While Transformer-based models have demonstrated strong\nperformance in modeling the temporal dynamics of dense trajectories of humans\nand vehicles in smart cities, they usually lack access to broader contextual\nknowledge that enhances the forecasting reliability of sparse meteorological\ntrajectories, such as typhoon tracks. To address this challenge, we propose\nTyphoFormer, a novel framework that incorporates natural language descriptions\nas auxiliary prompts to improve typhoon trajectory forecasting. For each time\nstep, we use Large Language Model (LLM) to generate concise textual\ndescriptions based on the numerical attributes recorded in the North Atlantic\nhurricane database. The language descriptions capture high-level meteorological\nsemantics and are embedded as auxiliary special tokens prepended to the\nnumerical time series input. By integrating both textual and sequential\ninformation within a unified Transformer encoder, TyphoFormer enables the model\nto leverage contextual cues that are otherwise inaccessible through numerical\nfeatures alone. Extensive experiments are conducted on HURDAT2 benchmark,\nresults show that TyphoFormer consistently outperforms other state-of-the-art\nbaseline methods, particularly under challenging scenarios involving nonlinear\npath shifts and limited historical observations.", "AI": {"tldr": "TyphoFormer \u7ed3\u5408\u6570\u503c\u548c\u8bed\u8a00\u4fe1\u606f\uff0c\u6781\u5927\u63d0\u5347\u4e86\u53f0\u98ce\u8def\u5f84\u9884\u6d4b\u8868\u73b0\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8def\u5f84\u53d8\u5316\u5267\u70c8\u6216\u89c2\u6d4b\u6570\u636e\u7a00\u5c11\u7684\u573a\u666f\u3002", "motivation": "\u53f0\u98ce\u8def\u5f84\u9884\u6d4b\u5bf9\u4e8e\u9884\u8b66\u548c\u707e\u5bb3\u54cd\u5e94\u975e\u5e38\u5173\u952e\uff0c\u4f46\u73b0\u6709 Transformer \u6a21\u578b\u867d\u7136\u80fd\u5904\u7406\u4eba\u7c7b\u548c\u8f66\u8f86\u7684\u8f68\u8ff9\uff0c\u5374\u96be\u4ee5\u83b7\u5f97\u589e\u5f3a\u6c14\u8c61\u8f68\u8ff9\u9884\u6d4b\u53ef\u9760\u6027\u7684\u4e0a\u4e0b\u6587\u77e5\u8bc6\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8f83\u7a00\u758f\u7684\u53f0\u98ce\u8f68\u8ff9\u4fe1\u606f\u3002", "method": "\u63d0\u51fa TyphoFormer\uff0c\u4e00\u79cd\u878d\u5408\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u4f5c\u4e3a\u8f85\u52a9\u63d0\u793a\u8bcd\u7684\u9884\u6d4b\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u9488\u5bf9\u6bcf\u4e2a\u65f6\u95f4\u6b65\u751f\u6210\u7b80\u6d01\u7684\u6c14\u8c61\u6587\u672c\u63cf\u8ff0\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u7279\u6b8a token \u4e0e\u6570\u503c\u65f6\u95f4\u5e8f\u5217\u4e00\u8d77\u8f93\u5165\u7edf\u4e00\u7684 Transformer \u7f16\u7801\u5668\uff0c\u4ece\u800c\u7ed3\u5408\u6587\u672c\u548c\u5e8f\u5217\u4fe1\u606f\u8f85\u52a9\u8def\u5f84\u9884\u6d4b\u3002", "result": "\u5728 HURDAT2 \u57fa\u51c6\u4e0a\uff0c\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\uff0cTyphoFormer \u5728\u5305\u62ec\u975e\u7ebf\u6027\u8def\u5f84\u53d8\u5316\u548c\u5386\u53f2\u89c2\u6d4b\u6709\u9650\u7b49\u590d\u6742\u573a\u666f\u4e0b\uff0c\u90fd\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u6700\u65b0\u65b9\u6cd5\u3002", "conclusion": "TyphoFormer \u80fd\u591f\u6709\u6548\u5229\u7528\u8bed\u8a00\u63d0\u793a\u878d\u5408\u6c14\u8c61\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5927\u5927\u63d0\u5347\u53f0\u98ce\u8f68\u8ff9\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.17930", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.17930", "abs": "https://arxiv.org/abs/2506.17930", "authors": ["Jianyu Wang", "Zhiqiang Hu", "Lidong Bing"], "title": "Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective", "comment": "ICML 2025, and Code will be released at:\n  https://github.com/jianyu-cs/PromptQuine/", "summary": "We propose a novel prompt design paradigm that challenges conventional wisdom\nin large language model (LLM) prompting. While conventional wisdom prioritizes\nwell-crafted instructions and demonstrations for in-context learning (ICL), we\nshow that pruning random demonstrations into seemingly incoherent \"gibberish\"\ncan remarkably improve performance across diverse tasks. Notably, the\n\"gibberish\" always matches or surpasses state-of-the-art automatic prompt\noptimization techniques, achieving substantial gains regardless of LLM\nalignment. Nevertheless, discovering an effective pruning strategy is\nnon-trivial, as existing attribution methods and prompt compression algorithms\nfail to deliver robust results, let alone human intuition. In terms of this, we\npropose a self-discover prompt optimization framework, PromptQuine, an\nevolutionary search framework that automatically searches for the pruning\nstrategy by itself using only low-data regimes. Much like the emergent\ncomplexity in nature--such as symbiosis and self-organization--arising in\nresponse to resource constraints, our framework evolves and refines\nunconventional yet highly effective prompts by leveraging only the tokens\npresent within the context. We demonstrate its effectiveness across\nclassification, multi-choice question answering, generation and math reasoning\ntasks across LLMs, while achieving decent runtime efficiency. We hope our\nfindings can guide mechanistic studies on in-context learning, and provide a\ncall to action, to pave the way for more open-ended search algorithms for more\neffective LLM prompting.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u4e86\u4f20\u7edf\u7684LLM prompt\u8bbe\u8ba1\u7406\u5ff5\uff0c\u53d1\u73b0\u5c06\u793a\u4f8b\u526a\u679d\u4e3a\u201c\u4e71\u7801\u201d\u80fd\u591f\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002\u4f5c\u8005\u63d0\u51faPromptQuine\u81ea\u52a8\u8fdb\u5316\u641c\u7d22\u6846\u67b6\uff0c\u4e0d\u4f9d\u8d56\u4eba\u5de5\u7ecf\u9a8c\uff0c\u7cfb\u7edf\u6027\u5730\u627e\u5230\u9ad8\u6548prompt\u3002\u5b9e\u9a8c\u5728\u591a\u79cd\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u6548\u679c\u9886\u5148\u3002\u8be5\u6210\u679c\u4e3a\u7406\u89e3\u548c\u4f18\u5316ICL\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\uff0c\u4f20\u7edf\u7684prompt\u8bbe\u8ba1\u503e\u5411\u4e8e\u7cbe\u5fc3\u7f16\u5199\u7684\u6307\u4ee4\u548c\u793a\u4f8b\u4ee5\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff0c\u4f46\u8fd9\u5957\u65b9\u6cd5\u4f9d\u7136\u5b58\u5728\u4f18\u5316\u7a7a\u95f4\u3002\u4f5c\u8005\u53d1\u73b0\uff0c\u73b0\u6709\u7684\u81ea\u52a8prompt\u4f18\u5316\u6280\u672f\u867d\u7136\u6709\u6548\uff0c\u4f46\u4ecd\u672a\u6316\u6398\u51faprompt\u8bbe\u8ba1\u7684\u5168\u90e8\u6f5c\u529b\uff0c\u56e0\u6b64\u5e0c\u671b\u6311\u6218\u4f20\u7edf\u89c2\u5ff5\uff0c\u63a2\u7d22\u66f4\u9ad8\u6548\u7684prompt\u8bbe\u8ba1\u65b9\u5f0f\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPromptQuine\u7684\u5168\u65b0\u6f14\u5316\u641c\u7d22\u6846\u67b6\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u6216\u73b0\u6709\u5f52\u56e0/\u538b\u7f29\u65b9\u6cd5\uff0c\u800c\u662f\u8ba9\u7cfb\u7edf\u81ea\u6211\u8fdb\u5316\uff0c\u81ea\u52a8\u641c\u7d22\u6700\u4f73\u7684\u968f\u673a\u793a\u4f8b\u526a\u679d\u7b56\u7565\uff0c\u5728\u4ec5\u6709\u5c11\u91cf\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u4fdd\u7559\u539f\u59cb\u4e0a\u4e0b\u6587\u4e2d\u7684\u8bcd\u5143\uff0c\u6f14\u5316\u51fa\u8868\u73b0\u4f18\u79c0\u4f46\u770b\u4f3c\u65e0\u5e8f\u7684prompt\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5206\u7c7b\u3001\u591a\u9009\u95ee\u7b54\u3001\u751f\u6210\u3001\u6570\u5b66\u63a8\u7406\u7b49\u4efb\u52a1\u4ee5\u53ca\u4e0d\u540cLLM\u6a21\u578b\u4e0a\u5747\u53d6\u5f97\u4e86\u4f18\u5f02\u6210\u7ee9\uff0c\u6548\u679c\u4f18\u4e8e\u6216\u5339\u914d\u5f53\u524d\u6700\u5148\u8fdb\u7684\u81ea\u52a8prompt\u4f18\u5316\u6280\u672f\uff0c\u5e76\u5177\u5907\u826f\u597d\u7684\u8fd0\u884c\u6548\u7387\u3002", "conclusion": "\u8bbe\u8ba1\u51fa\u8fde\u8d2f\u4e14\u903b\u8f91\u6e05\u6670\u7684prompt\u5e76\u975e\u83b7\u5f97\u6700\u4f73LLM\u6027\u80fd\u7684\u5fc5\u8981\u6761\u4ef6\u3002\u901a\u8fc7\u8fdb\u5316\u5f0f\u641c\u7d22\u5b9e\u73b0\u7684\u201c\u65e0\u5e8f\u201dprompt\u80fd\u663e\u8457\u63d0\u5347LLM\u4efb\u52a1\u8868\u73b0\uff0c\u5bf9\u73b0\u6709prompt\u8bbe\u8ba1\u7406\u5ff5\u63d0\u51fa\u4e86\u65b0\u7684\u6311\u6218\u548c\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2506.18199", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.18199", "abs": "https://arxiv.org/abs/2506.18199", "authors": ["Bushra Asseri", "Estabrag Abdelaziz", "Areej Al-Wabil"], "title": "Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review", "comment": null, "summary": "Large language models have demonstrated remarkable capabilities across\nvarious domains, yet concerns about cultural bias - particularly towards Arabs\nand Muslims - pose significant ethical challenges by perpetuating harmful\nstereotypes and marginalization. Despite growing recognition of bias in LLMs,\nprompt engineering strategies specifically addressing Arab and Muslim\nrepresentation remain understudied. This mixed-methods systematic review\nexamines such techniques, offering evidence-based guidance for researchers and\npractitioners. Following PRISMA guidelines and Kitchenham's systematic review\nmethodology, we analyzed 8 empirical studies published between 2021-2024\ninvestigating bias mitigation strategies. Our findings reveal five primary\nprompt engineering approaches: cultural prompting, affective priming,\nself-debiasing techniques, structured multi-step pipelines, and\nparameter-optimized continuous prompts. Although all approaches show potential\nfor reducing bias, effectiveness varied substantially across studies and bias\ntypes. Evidence suggests that certain bias types may be more resistant to\nprompt-based mitigation than others. Structured multi-step pipelines\ndemonstrated the highest overall effectiveness, achieving up to 87.7% reduction\nin bias, though they require greater technical expertise. Cultural prompting\noffers broader accessibility with substantial effectiveness. These results\nunderscore the accessibility of prompt engineering for mitigating cultural bias\nwithout requiring access to model parameters. The limited number of studies\nidentified highlights a significant research gap in this critical area. Future\nresearch should focus on developing culturally adaptive prompting techniques,\ncreating Arab and Muslim-specific evaluation resources, and integrating prompt\nengineering with complementary debiasing methods to address deeper stereotypes\nwhile maintaining model utility.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u73b0\u6709\u901a\u8fc7prompt\u5de5\u7a0b\u7f13\u89e3LLM\u5bf9\u963f\u62c9\u4f2f\u4eba\u548c\u7a46\u65af\u6797\u504f\u89c1\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u7ed3\u6784\u5316\u591a\u6b65\u6d41\u7a0b\u6548\u679c\u6700\u597d\u3002\u7814\u7a76\u6570\u91cf\u6709\u9650\uff0c\u672a\u6765\u9700\u63a2\u7d22\u66f4\u5177\u6587\u5316\u9002\u5e94\u6027\u7684\u65b9\u6cd5\u548c\u8bc4\u4ef7\u4f53\u7cfb\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8bb8\u591a\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bf9\u963f\u62c9\u4f2f\u4eba\u548c\u7a46\u65af\u6797\u7684\u6587\u5316\u504f\u89c1\u5f15\u53d1\u4e86\u4f26\u7406\u5173\u5207\u3002\u8fd9\u4e9b\u504f\u89c1\u53ef\u80fd\u52a0\u5267\u6709\u5bb3\u7684\u523b\u677f\u5370\u8c61\u548c\u8fb9\u7f18\u5316\u73b0\u8c61\u3002\u5c3d\u7ba1\u5b66\u754c\u8d8a\u6765\u8d8a\u5173\u6ce8LLMs\u7684\u504f\u89c1\uff0c\u9488\u5bf9\u963f\u62c9\u4f2f\u4eba\u548c\u7a46\u65af\u6797\u8868\u5f81\u7684prompt\u5de5\u7a0b\u6280\u672f\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u672c\u6587\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7cfb\u7edf\u7efc\u8ff0\uff0c\u9075\u5faaPRISMA\u6307\u5357\u548cKitchenham\u7684\u7cfb\u7edf\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5bf92021-2024\u5e74\u95f4\u53d1\u8868\u76848\u9879\u5b9e\u8bc1\u7814\u7a76\u8fdb\u884c\u4e86\u5206\u6790\u3002\u8fd9\u4e9b\u7814\u7a76\u5173\u6ce8\u7684\u662f\u7f13\u89e3\u504f\u89c1\u7684prompt\u5de5\u7a0b\u7b56\u7565\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e86\u4e94\u7c7b\u4e3b\u8981\u7684prompt\u5de5\u7a0b\u65b9\u6cd5\uff0c\u5206\u522b\u4e3a\u6587\u5316\u63d0\u793a\u3001\u60c5\u611f\u9884\u8bbe\u3001\u81ea\u6211\u53bb\u504f\u6280\u5de7\u3001\u7ed3\u6784\u5316\u591a\u6b65\u6d41\u7a0b\u4ee5\u53ca\u53c2\u6570\u4f18\u5316\u7684\u8fde\u7eedprompt\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5747\u53ef\u51cf\u7f13\u504f\u89c1\uff0c\u4f46\u5bf9\u4e0d\u540c\u7c7b\u578b\u504f\u89c1\u548c\u4e0d\u540c\u7814\u7a76\u6548\u679c\u5dee\u5f02\u8f83\u5927\u3002\u5176\u4e2d\uff0c\u7ed3\u6784\u5316\u591a\u6b65\u6d41\u7a0b\u6700\u4e3a\u6709\u6548\uff0c\u6700\u9ad8\u53ef\u5c06\u504f\u89c1\u51cf\u5c1187.7%\uff0c\u4f46\u9700\u8981\u66f4\u9ad8\u6280\u672f\u95e8\u69db\u3002\u6587\u5316\u63d0\u793a\u65b9\u6cd5\u5219\u517c\u5177\u53ef\u7528\u6027\u548c\u8f83\u597d\u6548\u679c\u3002", "conclusion": "prompt\u5de5\u7a0b\u80fd\u591f\u5728\u65e0\u9700\u63a5\u89e6\u6a21\u578b\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u7f13\u89e3\u6587\u5316\u504f\u89c1\uff0c\u4e3a\u963f\u62c9\u4f2f\u4eba\u548c\u7a46\u65af\u6797\u7684\u516c\u6b63\u8868\u5f81\u63d0\u4f9b\u4e86\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\u7684\u624b\u6bb5\u3002\u4f46\u76ee\u524d\u5b9e\u8bc1\u7814\u7a76\u6570\u91cf\u6709\u9650\uff0c\u5b58\u5728\u660e\u663e\u7814\u7a76\u7a7a\u767d\u3002\u672a\u6765\u5e94\u5f00\u53d1\u6587\u5316\u81ea\u9002\u5e94\u7684\u63d0\u793a\u6280\u672f\u3001\u5efa\u7acb\u4e13\u5c5e\u8bc4\u4ef7\u8d44\u6e90\uff0c\u5e76\u5c06prompt\u5de5\u7a0b\u4e0e\u5176\u4ed6\u53bb\u504f\u65b9\u6cd5\u7ed3\u5408\uff0c\u4ee5\u8fdb\u4e00\u6b65\u6d88\u9664\u504f\u89c1\u4e14\u4fdd\u6301\u6a21\u578b\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.17611", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17611", "abs": "https://arxiv.org/abs/2506.17611", "authors": ["Jinchuan Tian", "William Chen", "Yifan Peng", "Jiatong Shi", "Siddhant Arora", "Shikhar Bharadwaj", "Takashi Maekaku", "Yusuke Shinohara", "Keita Goto", "Xiang Yue", "Huck Yang", "Shinji Watanabe"], "title": "OpusLM: A Family of Open Unified Speech Language Models", "comment": null, "summary": "This paper presents Open Unified Speech Language Models (OpusLMs), a family\nof open foundational speech language models (SpeechLMs) up to 7B. Initialized\nfrom decoder-only text language models, the OpusLMs are continuously\npre-trained on 213K hours of speech-text pairs and 292B text-only tokens. We\ndemonstrate our OpusLMs achieve comparable (or even superior) performance with\nexisting SpeechLMs in speech recognition, speech synthesis, and text-only\ncapabilities. Technically, this paper articulates our SpeechLM designs on\ntokenization, multi-stream language models, and multi-stage training\nstrategies. We experimentally demonstrate the importance of model size scaling\nand the effect of annealing data selection. The OpusLMs are all built from\npublicly available materials and are fully transparent models. We release our\ncode, data, checkpoints, and training logs to facilitate open SpeechLM research", "AI": {"tldr": "OpusLMs\u662f\u4e00\u4e2a7B\u89c4\u6a21\u7684\u5f00\u6e90\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u5bb6\u65cf\uff0c\u5728\u516c\u5f00\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\uff0c\u6027\u80fd\u4f18\u8d8a\uff0c\u8986\u76d6\u8bed\u97f3\u8bc6\u522b\u3001\u8bed\u97f3\u5408\u6210\u548c\u6587\u672c\u4efb\u52a1\uff0c\u5b8c\u5168\u5f00\u6e90\uff0c\u4fc3\u8fdb\u9886\u57df\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3\u4e0e\u8bed\u8a00\u6a21\u578b\u9886\u57df\u7f3a\u4e4f\u5927\u89c4\u6a21\u3001\u5f00\u6e90\u5e76\u4e14\u8868\u73b0\u4f18\u79c0\u7684\u57fa\u7840\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\uff08SpeechLM\uff09\uff0c\u8bb8\u591a\u73b0\u6709\u6a21\u578b\u7f3a\u4e4f\u900f\u660e\u6027\u4e0e\u53ef\u590d\u73b0\u6027\uff0c\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u4e0e\u521b\u65b0\u3002", "method": "OpusLMs\u91c7\u7528decoder-only\u6587\u672c\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u521d\u59cb\u5316\uff0c\u5e76\u5bf9\u5176\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u4f7f\u7528\u4e86213,000\u5c0f\u65f6\u7684\u8bed\u97f3-\u6587\u672c\u5bf9\u4e0e2920\u4ebf\u6587\u672ctoken\u3002\u5728\u6a21\u578b\u8bbe\u8ba1\u65b9\u9762\uff0c\u91cd\u70b9\u5728\u4e8etokenization\uff08\u5206\u8bcd\u65b9\u6cd5\uff09\u3001\u591a\u6d41\u8bed\u8a00\u6a21\u578b\u7ed3\u6784\u548c\u591a\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u4e86\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u548c\u9000\u706b\u5f0f\u6570\u636e\u9009\u62e9\u5bf9\u4e8e\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "OpusLMs\u5728\u8bed\u97f3\u8bc6\u522b\u3001\u8bed\u97f3\u5408\u6210\u4ee5\u53ca\u6587\u672c\u4efb\u52a1\u4e2d\u5747\u8fbe\u5230\u4e86\u4e0e\u73b0\u6709SpeechLMs\u53ef\u6bd4\u751a\u81f3\u66f4\u4f18\u7684\u6027\u80fd\u3002\u6240\u6709\u6a21\u578b\u57fa\u4e8e\u516c\u5f00\u6570\u636e\u6784\u5efa\uff0c\u5177\u6709\u9ad8\u5ea6\u900f\u660e\u6027\uff0c\u5b8c\u6574\u5f00\u6e90\u4e86\u4ee3\u7801\u3001\u6570\u636e\u3001\u6a21\u578b\u6743\u91cd\u548c\u8bad\u7ec3\u65e5\u5fd7\u3002", "conclusion": "OpusLMs\u4f5c\u4e3a\u5f00\u6e90\u3001\u900f\u660e\u4e14\u5927\u89c4\u6a21\u7684\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u5c55\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u7684\u5f00\u653e\u7814\u7a76\u4e0e\u53d1\u5c55\u3002"}}
{"id": "2506.17959", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17959", "abs": "https://arxiv.org/abs/2506.17959", "authors": ["Lizzy Farrugia", "Lilian M. Azzopardi", "Jeremy Debattista", "Charlie Abela"], "title": "medicX-KG: A Knowledge Graph for Pharmacists' Drug Information Needs", "comment": null, "summary": "The role of pharmacists is evolving from medicine dispensing to delivering\ncomprehensive pharmaceutical services within multidisciplinary healthcare\nteams. Central to this shift is access to accurate, up-to-date medicinal\nproduct information supported by robust data integration. Leveraging artificial\nintelligence and semantic technologies, Knowledge Graphs (KGs) uncover hidden\nrelationships and enable data-driven decision-making. This paper presents\nmedicX-KG, a pharmacist-oriented knowledge graph supporting clinical and\nregulatory decisions. It forms the semantic layer of the broader medicX\nplatform, powering predictive and explainable pharmacy services. medicX-KG\nintegrates data from three sources, including, the British National Formulary\n(BNF), DrugBank, and the Malta Medicines Authority (MMA) that addresses Malta's\nregulatory landscape and combines European Medicines Agency alignment with\npartial UK supply dependence. The KG tackles the absence of a unified national\ndrug repository, reducing pharmacists' reliance on fragmented sources. Its\ndesign was informed by interviews with practicing pharmacists to ensure\nreal-world applicability. We detail the KG's construction, including data\nextraction, ontology design, and semantic mapping. Evaluation demonstrates that\nmedicX-KG effectively supports queries about drug availability, interactions,\nadverse reactions, and therapeutic classes. Limitations, including missing\ndetailed dosage encoding and real-time updates, are discussed alongside\ndirections for future enhancements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9762\u5411\u836f\u5242\u5e08\u7684medicX-KG\u77e5\u8bc6\u56fe\u8c31\uff0c\u6574\u5408\u591a\u6e90\u836f\u54c1\u4fe1\u606f\uff0c\u652f\u6301\u836f\u5e08\u9ad8\u6548\u67e5\u8be2\u53ca\u51b3\u7b56\u3002\u5b9e\u8df5\u8868\u660e\u5176\u80fd\u4f18\u5316\u836f\u54c1\u7ba1\u7406\u548c\u670d\u52a1\uff0c\u51cf\u5c11\u4fe1\u606f\u788e\u7247\u5316\uff0c\u4f46\u4ecd\u9700\u63d0\u5347\u6570\u636e\u7ec6\u8282\u548c\u66f4\u65b0\u80fd\u529b\u3002", "motivation": "\u836f\u5242\u5e08\u7684\u89d2\u8272\u6b63\u5728\u4ece\u5355\u7eaf\u7684\u836f\u54c1\u5206\u53d1\u8f6c\u5411\u591a\u5b66\u79d1\u533b\u7597\u56e2\u961f\u4e2d\u7684\u7efc\u5408\u836f\u5b66\u670d\u52a1\uff0c\u4e9f\u9700\u96c6\u6210\u3001\u51c6\u786e\u7684\u836f\u54c1\u4fe1\u606f\u4ee5\u652f\u6301\u4e34\u5e8a\u4e0e\u76d1\u7ba1\u51b3\u7b56\u3002\u7136\u800c\uff0c\u76ee\u524d\u9762\u4e34\u836f\u54c1\u4fe1\u606f\u5206\u6563\u3001\u7f3a\u5c11\u7edf\u4e00\u56fd\u5bb6\u836f\u54c1\u8d44\u6599\u5e93\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u836f\u5242\u5e08\u7684\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u80fd\u529b\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u6784\u5efa\u4e86medicX-KG\u77e5\u8bc6\u56fe\u8c31\uff0c\u4f5c\u4e3a\u836f\u5242\u5e08\u51b3\u7b56\u652f\u6301\u5de5\u5177\uff0c\u5e76\u96c6\u6210\u4e86\u82f1\u56fd\u56fd\u5bb6\u5904\u65b9\u96c6\uff08BNF\uff09\u3001DrugBank\u4e0e\u9a6c\u8033\u4ed6\u836f\u54c1\u7ba1\u7406\u5c40\uff08MMA\uff09\u7b49\u4e09\u65b9\u6570\u636e\u3002\u6574\u4e2a\u8bbe\u8ba1\u8fc7\u7a0b\u901a\u8fc7\u4e0e\u4e00\u7ebf\u836f\u5242\u5e08\u8bbf\u8c08\u83b7\u53d6\u771f\u5b9e\u9700\u6c42\uff0c\u5e76\u4ecb\u7ecd\u4e86\u6570\u636e\u62bd\u53d6\u3001\u672c\u4f53\u8bbe\u8ba1\u4ee5\u53ca\u8bed\u4e49\u6620\u5c04\u7b49\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u6d41\u7a0b\u3002", "result": "medicX-KG\u77e5\u8bc6\u56fe\u8c31\u80fd\u591f\u6709\u6548\u652f\u6301\u76f8\u5173\u836f\u54c1\u7684\u67e5\u8be2\uff0c\u5305\u62ec\u836f\u7269\u53ef\u5f97\u6027\u3001\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u3001\u4e0d\u826f\u53cd\u5e94\u53ca\u6cbb\u7597\u7c7b\u522b\u7b49\u5173\u952e\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u836f\u5242\u5e08\u5bf9\u96f6\u6563\u4fe1\u606f\u6e90\u7684\u4f9d\u8d56\u3002", "conclusion": "medicX-KG\u4e3a\u836f\u5242\u5e08\u63d0\u4f9b\u4e86\u7edf\u4e00\u548c\u53ef\u89e3\u91ca\u7684\u836f\u54c1\u77e5\u8bc6\u8bed\u4e49\u5c42\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5176\u4e34\u5e8a\u548c\u76d1\u7ba1\u51b3\u7b56\u80fd\u529b\u3002\u867d\u7136\u5f53\u524d\u7248\u672c\u5b58\u5728\u5242\u91cf\u7ec6\u8282\u7f16\u7801\u53ca\u5b9e\u65f6\u66f4\u65b0\u7b49\u5c40\u9650\uff0c\u4f46\u4e3a\u672a\u6765\u8fdb\u4e00\u6b65\u5b8c\u5584\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.18576", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.18576", "abs": "https://arxiv.org/abs/2506.18576", "authors": ["Matteo Melis", "Gabriella Lapesa", "Dennis Assenmacher"], "title": "A Modular Taxonomy for Hate Speech Definitions and Its Impact on Zero-Shot LLM Classification Performance", "comment": null, "summary": "Detecting harmful content is a crucial task in the landscape of NLP\napplications for Social Good, with hate speech being one of its most dangerous\nforms. But what do we mean by hate speech, how can we define it, and how does\nprompting different definitions of hate speech affect model performance? The\ncontribution of this work is twofold. At the theoretical level, we address the\nambiguity surrounding hate speech by collecting and analyzing existing\ndefinitions from the literature. We organize these definitions into a taxonomy\nof 14 Conceptual Elements-building blocks that capture different aspects of\nhate speech definitions, such as references to the target of hate (individual\nor groups) or of the potential consequences of it. At the experimental level,\nwe employ the collection of definitions in a systematic zero-shot evaluation of\nthree LLMs, on three hate speech datasets representing different types of data\n(synthetic, human-in-the-loop, and real-world). We find that choosing different\ndefinitions, i.e., definitions with a different degree of specificity in terms\nof encoded elements, impacts model performance, but this effect is not\nconsistent across all architectures.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4ec7\u6068\u8a00\u8bba\u4e0d\u540c\u5b9a\u4e49\u5bf9\u5927\u6a21\u578b\u68c0\u6d4b\u6548\u679c\u7684\u5f71\u54cd\uff0c\u63d0\u51fa14\u4e2a\u6982\u5ff5\u8981\u7d20\u7684\u5206\u7c7b\u4f53\u7cfb\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5b9a\u4e49\u7684\u9009\u62e9\u786e\u5b9e\u5f71\u54cd\u6a21\u578b\u8868\u73b0\uff0c\u4e14\u5bf9\u4e0d\u540c\u67b6\u6784\u7684\u6a21\u578b\u5f71\u54cd\u4e0d\u540c\u3002", "motivation": "\u7f51\u7edc\u4e2d\u5145\u65a5\u7684\u6709\u5bb3\u5185\u5bb9\uff0c\u5c24\u5176\u662f\u4ec7\u6068\u8a00\u8bba\uff0c\u5bf9\u793e\u4f1a\u4ea7\u751f\u4e25\u91cd\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u51c6\u786e\u68c0\u6d4b\u4ec7\u6068\u8a00\u8bba\u6210\u4e3aNLP\u9886\u57df\u7684\u91cd\u8981\u4efb\u52a1\u3002\u7136\u800c\uff0c\u4ec7\u6068\u8a00\u8bba\u7684\u5b9a\u4e49\u672c\u8eab\u5b58\u5728\u6b67\u4e49\uff0c\u4e0d\u540c\u7684\u5b9a\u4e49\u4f1a\u6f5c\u5728\u5f71\u54cd\u6a21\u578b\u68c0\u6d4b\u7684\u6548\u679c\u3002", "method": "\u8be5\u7814\u7a76\u9996\u5148\u7cfb\u7edf\u6574\u7406\u548c\u5206\u6790\u76f8\u5173\u6587\u732e\u4e2d\u5df2\u6709\u7684\u4ec7\u6068\u8a00\u8bba\u5b9a\u4e49\uff0c\u5f52\u7eb3\u51fa14\u4e2a\u6784\u6210\u6027\u8981\u7d20\uff0c\u5e76\u636e\u6b64\u6784\u5efa\u5206\u7c7b\u6cd5\u3002\u968f\u540e\uff0c\u7814\u7a76\u56e2\u961f\u57fa\u4e8e\u6536\u96c6\u7684\u5b9a\u4e49\uff0c\u5728\u4e09\u79cd\u7c7b\u578b\uff08\u5408\u6210\u6570\u636e\u3001\u4eba\u673a\u534f\u4f5c\u6570\u636e\u3001\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff09\u7684\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u4e09\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u96f6\u6837\u672c\u7cfb\u7edf\u8bc4\u6d4b\uff0c\u6bd4\u8f83\u4e0d\u540c\u5b9a\u4e49\u4e0b\u7684\u68c0\u6d4b\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e0d\u540c\u7684\u4ec7\u6068\u8a00\u8bba\u5b9a\u4e49\uff08\u5c24\u5176\u662f\u5728\u6784\u6210\u8981\u7d20\u7684\u5177\u4f53\u5316\u7a0b\u5ea6\u4e0a\u7684\u4e0d\u540c\uff09\u786e\u5b9e\u4f1a\u5f71\u54cd\u6a21\u578b\u68c0\u6d4b\u80fd\u529b\uff0c\u4f46\u8fd9\u4e00\u5f71\u54cd\u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u4e4b\u95f4\u5e76\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u4ec7\u6068\u8a00\u8bba\u7684\u5b9a\u4e49\u65b9\u5f0f\u4f1a\u663e\u8457\u5f71\u54cd\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u4ec7\u6068\u8a00\u8bba\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u4f46\u8fd9\u79cd\u5f71\u54cd\u56e0\u6a21\u578b\u800c\u5f02\uff0c\u56e0\u6b64\u5728\u6a21\u578b\u5e94\u7528\u548c\u57fa\u51c6\u8bbe\u5b9a\u65f6\u9700\u66f4\u52a0\u5173\u6ce8\u5b9a\u4e49\u7684\u9009\u62e9\u548c\u6784\u6210\u8981\u7d20\u3002"}}
{"id": "2506.17630", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17630", "abs": "https://arxiv.org/abs/2506.17630", "authors": ["Yang Wu", "Yifan Zhang", "Yiwei Wang", "Yujun Cai", "Yurong Wu", "Yuran Wang", "Ning Xu", "Jian Cheng"], "title": "Answer-Centric or Reasoning-Driven? Uncovering the Latent Memory Anchor in LLMs", "comment": "14 pages, 8 figures", "summary": "While Large Language Models (LLMs) demonstrate impressive reasoning\ncapabilities, growing evidence suggests much of their success stems from\nmemorized answer-reasoning patterns rather than genuine inference. In this\nwork, we investigate a central question: are LLMs primarily anchored to final\nanswers or to the textual pattern of reasoning chains? We propose a five-level\nanswer-visibility prompt framework that systematically manipulates answer cues\nand probes model behavior through indirect, behavioral analysis. Experiments\nacross state-of-the-art LLMs reveal a strong and consistent reliance on\nexplicit answers. The performance drops by 26.90\\% when answer cues are masked,\neven with complete reasoning chains. These findings suggest that much of the\nreasoning exhibited by LLMs may reflect post-hoc rationalization rather than\ntrue inference, calling into question their inferential depth. Our study\nuncovers the answer-anchoring phenomenon with rigorous empirical validation and\nunderscores the need for a more nuanced understanding of what constitutes\nreasoning in LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u65b0\u6846\u67b6\u8bc1\u5b9eLLM\u63a8\u7406\u9ad8\u5ea6\u4f9d\u8d56\u7b54\u6848\u63d0\u793a\uff0c\u63a8\u7406\u591a\u4e3a\u4e8b\u540e\u5408\u7406\u5316\u800c\u975e\u771f\u6b63\u63a8\u7406\uff0c\u9700\u91cd\u65b0\u5ba1\u89c6\u5176\u63a8\u7406\u80fd\u529b\u6df1\u5ea6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u8d8a\u6765\u8d8a\u591a\u8bc1\u636e\u8868\u660e\uff0c\u8fd9\u79cd\u80fd\u529b\u66f4\u591a\u4f9d\u8d56\u4e8e\u8bb0\u5fc6\u5316\u7684\u7b54\u6848-\u63a8\u7406\u6a21\u5f0f\uff0c\u800c\u975e\u771f\u6b63\u7684\u63a8\u7406\u3002\u672c\u7814\u7a76\u63a2\u7a76\u4e86LLMs\u5230\u5e95\u4f9d\u8d56\u4e8e\u6700\u7ec8\u7b54\u6848\u672c\u8eab\uff0c\u8fd8\u662f\u5bf9\u63a8\u7406\u94fe\u7684\u6587\u672c\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e94\u7ea7\u7b54\u6848\u53ef\u89c1\u6027\u63d0\u793a\u6846\u67b6\uff0c\u7cfb\u7edf\u5730\u8c03\u63a7\u7b54\u6848\u63d0\u793a\uff0c\u5e76\u901a\u8fc7\u95f4\u63a5\u7684\u884c\u4e3a\u5206\u6790\u63a2\u7a76\u6a21\u578b\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5f53\u5c4f\u853d\u7b54\u6848\u63d0\u793a\uff0c\u5373\u4f7f\u7ed9\u51fa\u5b8c\u6574\u63a8\u7406\u94fe\uff0c\u6a21\u578b\u8868\u73b0\u4e5f\u4e0b\u964d\u4e8626.90%\u3002\u8fd9\u8868\u660eLLMs\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4f9d\u8d56\u4e8e\u660e\u786e\u7684\u7b54\u6848\u63d0\u793a\u3002", "conclusion": "LLMs\u5c55\u793a\u7684\u63a8\u7406\u8868\u73b0\u66f4\u591a\u662f\u4e8b\u540e\u5408\u7406\u5316\u800c\u4e0d\u662f\u771f\u6b63\u7684\u63a8\u7406\uff0c\u63ed\u793a\u4e86\u7b54\u6848\u951a\u5b9a\u73b0\u8c61\uff0c\u63d0\u9192\u4e1a\u754c\u9700\u8981\u91cd\u65b0\u601d\u8003LLM\u63a8\u7406\u80fd\u529b\u7684\u672c\u8d28\u3002"}}
{"id": "2506.18019", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18019", "abs": "https://arxiv.org/abs/2506.18019", "authors": ["Yuanchen Bei", "Weizhi Zhang", "Siwen Wang", "Weizhi Chen", "Sheng Zhou", "Hao Chen", "Yong Li", "Jiajun Bu", "Shirui Pan", "Yizhou Yu", "Irwin King", "Fakhri Karray", "Philip S. Yu"], "title": "Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities", "comment": "20 pages, 7 figures", "summary": "AI agents have experienced a paradigm shift, from early dominance by\nreinforcement learning (RL) to the rise of agents powered by large language\nmodels (LLMs), and now further advancing towards a synergistic fusion of RL and\nLLM capabilities. This progression has endowed AI agents with increasingly\nstrong abilities. Despite these advances, to accomplish complex real-world\ntasks, agents are required to plan and execute effectively, maintain reliable\nmemory, and coordinate smoothly with other agents. Achieving these capabilities\ninvolves contending with ever-present intricate information, operations, and\ninteractions. In light of this challenge, data structurization can play a\npromising role by transforming intricate and disorganized data into\nwell-structured forms that agents can more effectively understand and process.\nIn this context, graphs, with their natural advantage in organizing, managing,\nand harnessing intricate data relationships, present a powerful data paradigm\nfor structurization to support the capabilities demanded by advanced AI agents.\nTo this end, this survey presents a first systematic review of how graphs can\nempower AI agents. Specifically, we explore the integration of graph techniques\nwith core agent functionalities, highlight notable applications, and identify\nprospective avenues for future research. By comprehensively surveying this\nburgeoning intersection, we hope to inspire the development of next-generation\nAI agents equipped to tackle increasingly sophisticated challenges with graphs.\nRelated resources are collected and continuously updated for the community in\nthe Github link.", "AI": {"tldr": "\u672c\u6587\u4e3a\u4eba\u5de5\u667a\u80fd\u667a\u80fd\u4f53\u4e0e\u56fe\u7ed3\u6784\u7ed3\u5408\u9886\u57df\u7684\u9996\u4e2a\u7cfb\u7edf\u7efc\u8ff0\uff0c\u63ed\u793a\u4e86\u56fe\u7684\u7ed3\u6784\u5316\u4f18\u52bf\u5982\u4f55\u89e3\u51b3\u667a\u80fd\u4f53\u5728\u771f\u5b9e\u590d\u6742\u4efb\u52a1\u4e2d\u9762\u4e34\u7684\u4fe1\u606f\u3001\u8ba1\u5212\u4e0e\u534f\u4f5c\u7b49\u96be\u9898\uff0c\u6307\u51fa\u4e86\u672a\u6765\u53d1\u5c55\u65b9\u5411\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f8\u5173\u7814\u7a76\u8d44\u6e90\u3002", "motivation": "\u968f\u7740AI\u667a\u80fd\u4f53\u4ece\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5230\u878d\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u5176\u80fd\u529b\u663e\u8457\u589e\u5f3a\u3002\u4f46\u5728\u9762\u5bf9\u590d\u6742\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u65f6\uff0c\u5982\u6709\u6548\u8ba1\u5212\u4e0e\u6267\u884c\u3001\u7a33\u5b9a\u8bb0\u5fc6\u7ef4\u62a4\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u5f53\u524d\u65b9\u6cd5\u8fd8\u5b58\u5728\u6311\u6218\u3002\u5c24\u5176\u5728\u5904\u7406\u6d77\u91cf\u590d\u6742\u4fe1\u606f\u548c\u4ea4\u4e92\u65f6\u4e9f\u9700\u65b0\u7684\u6570\u636e\u7ed3\u6784\u5316\u624b\u6bb5\u3002", "method": "\u672c\u7efc\u8ff0\u7cfb\u7edf\u68b3\u7406\u4e86\u56fe\u6570\u636e\u7ed3\u6784\u5728\u589e\u5f3aAI\u667a\u80fd\u4f53\u6838\u5fc3\u80fd\u529b\uff08\u5982\u89c4\u5212\u3001\u8bb0\u5fc6\u3001\u534f\u4f5c\u7b49\uff09\u4e2d\u7684\u4f5c\u7528\uff0c\u5206\u6790\u4e86\u56fe\u6280\u672f\u4e0e\u667a\u80fd\u4f53\u6df1\u5ea6\u7ed3\u5408\u7684\u73b0\u6709\u5e94\u7528\u53ca\u6f5c\u529b\uff0c\u5e76\u5f52\u7eb3\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002\u6587\u7ae0\u8fd8\u6536\u96c6\u5e76\u6301\u7eed\u66f4\u65b0\u76f8\u5173\u8d44\u6e90\uff0c\u4ee5\u4fbf\u5b66\u672f\u793e\u533a\u53c2\u8003\u3002", "result": "\u6587\u7ae0\u9996\u6b21\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u56fe\u6280\u672f\u8d4b\u80fdAI\u667a\u80fd\u4f53\u7684\u591a\u79cd\u8def\u5f84\u548c\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\uff0c\u9610\u8ff0\u4e86\u56fe\u7ed3\u6784\u5982\u4f55\u52a9\u529b\u667a\u80fd\u4f53\u66f4\u9ad8\u6548\u5730\u7406\u89e3\u548c\u5904\u7406\u590d\u6742\u6570\u636e\u5173\u7cfb\uff0c\u652f\u6491\u5176\u5e94\u5bf9\u9ad8\u7ea7\u4efb\u52a1\u3002", "conclusion": "\u901a\u8fc7\u68b3\u7406\u4e0e\u5206\u6790\uff0c\u672c\u6587\u660e\u786e\u4e86\u56fe\u7ed3\u6784\u4f5c\u4e3a\u6570\u636e\u7ed3\u6784\u5316\u5229\u5668\uff0c\u5bf9\u667a\u80fd\u4f53\u80fd\u529b\u63d0\u5347\u7684\u91cd\u8981\u4f5c\u7528\uff0c\u5e76\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u6e05\u6670\u3001\u524d\u6cbf\u7684\u7814\u7a76\u7ebf\u7d22\u548c\u8d44\u6e90\u3002"}}
{"id": "2506.17637", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17637", "abs": "https://arxiv.org/abs/2506.17637", "authors": ["Yang Wu", "Yifan Zhang", "Yurong Wu", "Yuran Wang", "Junkai Zhang", "Jian Cheng"], "title": "Step-Opt: Boosting Optimization Modeling in LLMs through Iterative Data Synthesis and Structured Validation", "comment": "17 pages, 12 figures", "summary": "Large Language Models (LLMs) have revolutionized various domains but\nencounter substantial challenges in tackling optimization modeling tasks for\nOperations Research (OR), particularly when dealing with complex problem. In\nthis work, we propose Step-Opt-Instruct, a framework that augments existing\ndatasets and generates high-quality fine-tuning data tailored to optimization\nmodeling. Step-Opt-Instruct employs iterative problem generation to\nsystematically increase problem complexity and stepwise validation to\nrigorously verify data, preventing error propagation and ensuring the quality\nof the generated dataset. Leveraging this framework, we fine-tune open-source\nLLMs, including LLaMA-3-8B and Mistral-7B, to develop Step-Opt--a model that\nachieves state-of-the-art performance on benchmarks such as NL4OPT, MAMO, and\nIndustryOR. Extensive experiments demonstrate the superior performance of\nStep-Opt, especially in addressing complex OR tasks, with a notable 17.01\\%\nimprovement in micro average accuracy on difficult problems. These findings\nhighlight the effectiveness of combining structured validation with gradual\nproblem refinement to advance the automation of decision-making processes using\nLLMs.The code and dataset are available at https://github.com/samwu-learn/Step.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faStep-Opt-Instruct\uff0c\u901a\u8fc7\u5206\u6b65\u751f\u6210\u4e0e\u9a8c\u8bc1\u5927\u5e45\u589e\u5f3a\u4f18\u5316\u5efa\u6a21\u4efb\u52a1\u6570\u636e\uff0c\u5fae\u8c03\u540e\u7684Step-Opt\u6a21\u578b\u5728\u591a\u4e2a\u590d\u6742\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u51b3\u7b56\u7684\u6570\u636e\u8d28\u91cf\u4e0e\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u5728\u591a\u4e2a\u9886\u57df\u53d6\u5f97\u7a81\u7834\uff0c\u4f46\u5728\u89e3\u51b3\u8fd0\u7b79\u4f18\u5316\u5efa\u6a21\u7279\u522b\u662f\u590d\u6742\u95ee\u9898\u65f6\u4ecd\u9762\u4e34\u663e\u8457\u6311\u6218\u3002\u4f18\u5316\u9886\u57df\u81ea\u52a8\u5316\u5efa\u6a21\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u9700\u6c42\uff0c\u9a71\u52a8\u4e86\u5bf9\u65b0\u65b9\u6cd5\u7684\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86Step-Opt-Instruct\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u751f\u6210\u95ee\u9898\u9010\u6b65\u63d0\u5347\u96be\u5ea6\uff0c\u5e76\u4ee5\u5206\u6b65\u9a8c\u8bc1\u4fdd\u969c\u6269\u5145\u548c\u751f\u6210\u4f18\u5316\u5efa\u6a21\u6570\u636e\u7684\u8d28\u91cf\uff0c\u9632\u6b62\u9519\u8bef\u4f20\u64ad\u3002\u7136\u540e\uff0c\u57fa\u4e8e\u6b64\u6846\u67b6\u4f7f\u7528LLaMA-3-8B\u548cMistral-7B\u7b49\u5f00\u6e90LLM\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5fae\u8c03\u540e\u7684Step-Opt\u6a21\u578b\u5728NL4OPT\u3001MAMO\u548cIndustryOR\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u5bf9\u9ad8\u96be\u5ea6\u95ee\u9898\u5fae\u5e73\u5747\u51c6\u786e\u7387\u63d0\u5347\u8fbe17.01%\u3002", "conclusion": "\u7ed3\u6784\u5316\u9a8c\u8bc1\u4e0e\u9010\u6b65\u590d\u6742\u5316\u751f\u6210\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u590d\u6742\u8fd0\u7b79\u4f18\u5316\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u63a8\u52a8\u4e86\u81ea\u52a8\u5316\u51b3\u7b56\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.18044", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18044", "abs": "https://arxiv.org/abs/2506.18044", "authors": ["Joseph Babb", "Joohyung Lee"], "title": "Action Language BC+", "comment": "Journal of Logic and Computation, 2015", "summary": "Action languages are formal models of parts of natural language that are\ndesigned to describe effects of actions. Many of these languages can be viewed\nas high level notations of answer set programs structured to represent\ntransition systems. However, the form of answer set programs considered in the\nearlier work is quite limited in comparison with the modern Answer Set\nProgramming (ASP) language, which allows several useful constructs for\nknowledge representation, such as choice rules, aggregates, and abstract\nconstraint atoms. We propose a new action language called BC+, which closes the\ngap between action languages and the modern ASP language. The main idea is to\ndefine the semantics of BC+ in terms of general stable model semantics for\npropositional formulas, under which many modern ASP language constructs can be\nidentified with shorthands for propositional formulas. Language BC+ turns out\nto be sufficiently expressive to encompass the best features of other action\nlanguages, such as languages B, C, C+, and BC. Computational methods available\nin ASP solvers are readily applicable to compute BC+, which led to an\nimplementation of the language by extending system cplus2asp.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u52a8\u4f5c\u8bed\u8a00BC+\uff0c\u5c06\u73b0\u4ee3ASP\u8bed\u8a00\u7684\u5f3a\u5927\u7279\u6027\u4e0e\u52a8\u4f5c\u8bed\u8a00\u878d\u5408\uff0c\u5f25\u8865\u539f\u6709\u8868\u8fbe\u4e0d\u8db3\u3002BC+\u517c\u5bb9\u65e7\u6709\u52a8\u4f5c\u8bed\u8a00\u4f18\u70b9\uff0c\u53ef\u501f\u52a9ASP\u6280\u672f\u76f4\u63a5\u6c42\u89e3\uff0c\u5e76\u5df2\u83b7\u5f97\u5b9e\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u52a8\u4f5c\u8bed\u8a00\u5f62\u5f0f\uff08\u5982B\u3001C\u3001C+\u3001BC\uff09\u5728\u4e0e\u73b0\u4ee3ASP\u8bed\u8a00\uff08Answer Set Programming\uff09\u5bf9\u63a5\u65f6\u5b58\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u7684\u5dee\u8ddd\uff0cASP\u4e2d\u7684\u65b0\u7279\u6027\u5982\u9009\u62e9\u89c4\u5219\u3001\u805a\u5408\u548c\u62bd\u8c61\u7ea6\u675f\u539f\u5b50\u7b49\u5c1a\u672a\u88ab\u65e7\u7684\u52a8\u4f5c\u8bed\u8a00\u5145\u5206\u96c6\u6210\u3002\u4f5c\u8005\u5e0c\u671b\u8bbe\u8ba1\u4e00\u79cd\u65b0\u52a8\u4f5c\u8bed\u8a00\uff0c\u80fd\u66f4\u597d\u5730\u5229\u7528ASP\u7684\u77e5\u8bc6\u8868\u793a\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u52a8\u4f5c\u8bed\u8a00BC+\uff0c\u5176\u8bed\u4e49\u901a\u8fc7\u5bf9\u547d\u9898\u516c\u5f0f\u7684\u4e00\u822c\u7a33\u5b9a\u6a21\u578b\u8bed\u4e49\u8fdb\u884c\u5b9a\u4e49\uff0c\u4f7f\u5f97\u73b0\u4ee3ASP\u8bed\u8a00\u4e2d\u7684\u8bf8\u591a\u529f\u80fd\u7279\u6027\u90fd\u53ef\u4e0e\u547d\u9898\u516c\u5f0f\u4e2d\u7684\u7b80\u5199\u5bf9\u5e94\u3002\u6b64\u5916\uff0cBC+\u901a\u8fc7\u6269\u5c55cplus2asp\u7cfb\u7edf\u8fdb\u884c\u4e86\u5b9e\u9645\u5b9e\u73b0\u3002", "result": "BC+\u8bed\u8a00\u8db3\u591f\u8868\u8fbe\u6027\u5f3a\uff0c\u53ef\u4ee5\u6db5\u76d6\u5176\u5b83\u52a8\u4f5c\u8bed\u8a00\uff08\u5982B\u3001C\u3001C+\u3001BC\uff09\u7684\u6700\u4f73\u7279\u6027\uff0c\u5e76\u80fd\u81ea\u5982\u5229\u7528ASP\u6c42\u89e3\u5668\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5c06\u52a8\u4f5c\u8bed\u8a00\u4e0e\u73b0\u4ee3ASP\u7d27\u5bc6\u7ed3\u5408\u3002", "conclusion": "BC+\u6709\u6548\u586b\u8865\u4e86\u52a8\u4f5c\u8bed\u8a00\u548c\u73b0\u4ee3ASP\u8bed\u8a00\u4e4b\u95f4\u7684\u529f\u80fd\u548c\u8868\u8fbe\u9e3f\u6c9f\uff0c\u4f7f\u5f97\u590d\u6742\u77e5\u8bc6\u548c\u52a8\u6001\u7cfb\u7edf\u7684\u63cf\u8ff0\u3001\u63a8\u7406\u66f4\u52a0\u81ea\u7136\u3001\u4fbf\u5229\u548c\u9ad8\u6548\u3002"}}
{"id": "2506.17671", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17671", "abs": "https://arxiv.org/abs/2506.17671", "authors": ["Fabien Furfaro"], "title": "TPTT: Transforming Pretrained Transformer into Titans", "comment": "6 pages, 1 figure", "summary": "Recent advances in large language models (LLMs) have led to remarkable\nprogress in natural language processing, but their computational and memory\ndemands remain a significant challenge, particularly for long-context\ninference. We introduce TPTT (Transforming Pretrained Transformer into Titans),\na novel framework for enhancing pretrained Transformer models with efficient\nlinearized attention mechanisms and advanced memory management. TPTT employs\ntechniques such as Memory as Gate (MaG) and mixed linearized attention (LiZA).\nIt is fully compatible with the Hugging Face Transformers library, enabling\nseamless adaptation of any causal LLM through parameter-efficient fine-tuning\n(LoRA) without full retraining. We show the effectiveness of TPTT on the MMLU\nbenchmark with models of approximately 1 billion parameters, observing\nsubstantial improvements in both efficiency and accuracy. For instance,\nTitans-Llama-3.2-1B achieves a 20% increase in Exact Match (EM) over its\nbaseline. Statistical analyses and comparisons with recent state-of-the-art\nmethods confirm the practical scalability and robustness of TPTT. Code is\navailable at https://github.com/fabienfrfr/tptt . Python package at\nhttps://pypi.org/project/tptt/ .", "AI": {"tldr": "TPTT\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u9ad8\u6548\u673a\u5236\u548c\u4f18\u5316\u7ba1\u7406\uff0c\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u589e\u52a0\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u957f\u6587\u672c\u5904\u7406\u80fd\u529b\uff0c\u4e14\u6613\u4e8e\u5728\u73b0\u6709\u6a21\u578b\u4e0a\u90e8\u7f72\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u53d6\u5f97\u5de8\u5927\u8fdb\u5c55\uff0c\u4f46\u5176\u9ad8\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\uff0c\u5c24\u5176\u5728\u957f\u6587\u672c\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u4ecd\u662f\u663e\u8457\u7684\u6280\u672f\u96be\u9898\u3002", "method": "\u63d0\u51faTPTT\uff08Transforming Pretrained Transformer into Titans\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u9ad8\u6548\u7684\u7ebf\u6027\u5316\u6ce8\u610f\u529b\u673a\u5236\u548c\u5148\u8fdb\u7684\u5185\u5b58\u7ba1\u7406\uff08\u5982Memory as Gate\u548c\u6df7\u5408\u7ebf\u6027\u5316\u6ce8\u610f\u529bLiZA\uff09\uff0c\u4f7f\u9884\u8bad\u7ec3Transformer\u6a21\u578b\u80fd\u591f\u66f4\u9ad8\u6548\u5730\u4f7f\u7528\u8ba1\u7b97\u548c\u5185\u5b58\u8d44\u6e90\u3002\u8be5\u65b9\u6cd5\u5b8c\u5168\u517c\u5bb9Hugging Face Transformers\u5e93\uff0c\u53ef\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08LoRA\uff09\u5feb\u901f\u9002\u914d\u73b0\u6709LLM\uff0c\u65e0\u9700\u5b8c\u5168\u518d\u8bad\u7ec3\u3002", "result": "\u5728MMLU\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u7ea610\u4ebf\u53c2\u6570\u89c4\u6a21\u7684\u6a21\u578b\u4f7f\u7528TPTT\u540e\uff0c\u5728\u6548\u7387\u548c\u51c6\u786e\u7387\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\u3002\u4f8b\u5982Titans-Llama-3.2-1B\u6a21\u578b\u7684\u51c6\u786e\u5339\u914d\uff08EM\uff09\u6307\u6807\u76f8\u6bd4\u57fa\u7ebf\u63d0\u5347\u4e8620%\u3002\u7edf\u8ba1\u5206\u6790\u53ca\u5bf9\u6bd4\u5b9e\u9a8c\u663e\u793aTPTT\u5177\u5907\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "TPTT\u80fd\u591f\u9ad8\u6548\u63d0\u5347\u9884\u8bad\u7ec3Transformer\u6a21\u578b\u7684\u957f\u6587\u672c\u63a8\u7406\u80fd\u529b\u4e0e\u6574\u4f53\u8868\u73b0\uff0c\u9002\u914d\u4e3b\u6d41\u5f00\u6e90\u5e73\u53f0\u4e14\u6613\u4e8e\u96c6\u6210\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.18056", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18056", "abs": "https://arxiv.org/abs/2506.18056", "authors": ["Paolo Baldi", "Fabio Aurelio D'Asaro", "Abeer Dyoub", "Francesca Alessandra Lisi"], "title": "Weighted Assumption Based Argumentation to reason about ethical principles and actions", "comment": null, "summary": "We augment Assumption Based Argumentation (ABA for short) with weighted\nargumentation. In a nutshell, we assign weights to arguments and then derive\nthe weight of attacks between ABA arguments. We illustrate our proposal through\nrunning examples in the field of ethical reasoning, and present an\nimplementation based on Answer Set Programming.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e3a\u5047\u8bbe\u57fa\u7840\u8bba\u8bc1\uff08ABA\uff09\u7cfb\u7edf\u5f15\u5165\u6743\u91cd\u673a\u5236\uff0c\u901a\u8fc7\u5177\u4f53\u6848\u4f8b\u5c55\u793a\u5176\u5728\u9053\u5fb7\u63a8\u7406\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u7ed9\u51fa\u57fa\u4e8eASP\u7684\u5b9e\u73b0\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5047\u8bbe\u7684\u8bba\u8bc1\uff08ABA\uff09\u7cfb\u7edf\u672a\u8003\u8651\u4e0d\u540c\u8bba\u636e\u7684\u91cd\u8981\u6027\u6216\u53ef\u4fe1\u5ea6\uff0c\u5b58\u5728\u8bba\u636e\u4e4b\u95f4\u5f71\u54cd\u529b\u96be\u4ee5\u8861\u91cf\u7684\u95ee\u9898\u3002", "method": "\u5728ABA\u7cfb\u7edf\u4e2d\u4e3a\u6bcf\u4e2a\u8bba\u636e\u5206\u914d\u6743\u91cd\uff0c\u5e76\u901a\u8fc7\u63a8\u5bfc\u5f97\u51fa\u8bba\u636e\u4e4b\u95f4\u653b\u51fb\u7684\u6743\u91cd\u3002\u901a\u8fc7\u9053\u5fb7\u63a8\u7406\u9886\u57df\u7684\u793a\u4f8b\u8fdb\u884c\u8bf4\u660e\uff0c\u5e76\u57fa\u4e8eAnswer Set Programming\u5b9e\u73b0\u4e86\u8be5\u7cfb\u7edf\u3002", "result": "\u5c55\u793a\u4e86\u5728\u5177\u6709\u6743\u91cd\u7684ABA\u7cfb\u7edf\u4e2d\uff0c\u5982\u4f55\u901a\u8fc7\u793a\u4f8b\u5b9e\u73b0\u6743\u91cd\u5206\u914d\u4e0e\u653b\u51fb\u6743\u91cd\u63a8\u5bfc\u3002\u540c\u65f6\uff0c\u5f00\u53d1\u4e86\u5b9e\u9645\u8fd0\u884c\u7684\u5b9e\u73b0\u7cfb\u7edf\u3002", "conclusion": "\u5c06\u6743\u91cd\u673a\u5236\u878d\u5165ABA\u540e\uff0c\u53ef\u4ee5\u66f4\u7ec6\u81f4\u5730\u523b\u753b\u8bba\u8bc1\u8fc7\u7a0b\uff0c\u589e\u5f3a\u4e86\u7cfb\u7edf\u5bf9\u4e8e\u8bba\u636e\u5f71\u54cd\u529b\u548c\u653b\u51fb\u6548\u679c\u7684\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2506.17692", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17692", "abs": "https://arxiv.org/abs/2506.17692", "authors": ["Binquan Ji", "Haibo Luo", "Yifei Lu", "Lei Hei", "Jiaqi Wang", "Tingjing Liao", "Lingyu Wang", "Shichao Wang", "Feiliang Ren"], "title": "Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering", "comment": null, "summary": "Knowledge-intensive multi-hop question answering (QA) tasks, which require\nintegrating evidence from multiple sources to address complex queries, often\nnecessitate multiple rounds of retrieval and iterative generation by large\nlanguage models (LLMs). However, incorporating many documents and extended\ncontexts poses challenges -such as hallucinations and semantic drift-for\nlightweight LLMs with fewer parameters. This work proposes a novel framework\ncalled DEC (Dynamic Enhancement Chain). DEC first decomposes complex questions\ninto logically coherent subquestions to form a hallucination-free reasoning\nchain. It then iteratively refines these subquestions through context-aware\nrewriting to generate effective query formulations. For retrieval, we introduce\na lightweight discriminative keyword extraction module that leverages extracted\nkeywords to achieve targeted, precise document recall with relatively low\ncomputational overhead. Extensive experiments on three multi-hop QA datasets\ndemonstrate that DEC performs on par with or surpasses state-of-the-art\nbenchmarks while significantly reducing token consumption. Notably, our\napproach attains state-of-the-art results on models with 8B parameters,\nshowcasing its effectiveness in various scenarios, particularly in\nresource-constrained environments.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u77e5\u8bc6\u5bc6\u96c6\u578b\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\uff0c\u63d0\u51fa\u4e86\u52a8\u6001\u589e\u5f3a\u94fe(DEC)\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u4e14\u51c6\u786e\u7684\u590d\u6742\u95ee\u9898\u89e3\u7b54\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u9700\u8981\u6574\u5408\u6765\u81ea\u591a\u4e2a\u4fe1\u606f\u6e90\u7684\u8bc1\u636e\uff0c\u5e94\u5bf9\u590d\u6742\u95ee\u9898\uff0c\u5bf9\u4e8e\u53c2\u6570\u8f83\u5c11\u7684\u5c0f\u578b\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5904\u7406\u5927\u91cf\u6587\u6863\u548c\u957f\u4e0a\u4e0b\u6587\u4f1a\u5e26\u6765\u5e7b\u89c9\u548c\u8bed\u4e49\u6f02\u79fb\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86Dynamic Enhancement Chain(DEC)\u6846\u67b6\uff0c\u9996\u5148\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u903b\u8f91\u8fde\u8d2f\u7684\u5b50\u95ee\u9898\uff0c\u5f62\u6210\u65e0\u5e7b\u89c9\u7684\u63a8\u7406\u94fe\uff1b\u968f\u540e\u7ed3\u5408\u4e0a\u4e0b\u6587\u5bf9\u8fd9\u4e9b\u5b50\u95ee\u9898\u8fdb\u884c\u91cd\u5199\u63d0\u5347\u67e5\u8be2\u6548\u679c\u3002\u68c0\u7d22\u6a21\u5757\u4f7f\u7528\u8f7b\u91cf\u5224\u522b\u5f0f\u5173\u952e\u8bcd\u62bd\u53d6\uff0c\u66f4\u9ad8\u6548\u7cbe\u51c6\u5730\u53ec\u56de\u76f8\u5173\u6587\u6863\u3002", "result": "\u5728\u4e09\u4e2a\u591a\u8df3\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cDEC\u8868\u73b0\u4e0e\u6700\u65b0\u65b9\u6cd5\u6301\u5e73\u6216\u66f4\u4f18\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86token\u6d88\u8017\u3002\u57288B\u53c2\u6570\u6a21\u578b\u4e0a\u83b7\u5f97\u4e86SOTA\u7ed3\u679c\uff0c\u8bf4\u660e\u8be5\u65b9\u6cd5\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u5c24\u4e3a\u6709\u6548\u3002", "conclusion": "DEC\u6709\u6548\u63d0\u5347\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u591a\u8df3\u95ee\u7b54\u4e2d\u7684\u8868\u73b0\uff0c\u517c\u987e\u63a8\u7406\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\uff0c\u5bf9\u5b9e\u9645\u843d\u5730\u6709\u660e\u663e\u4f18\u52bf\u3002"}}
{"id": "2506.18096", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18096", "abs": "https://arxiv.org/abs/2506.18096", "authors": ["Yuxuan Huang", "Yihang Chen", "Haozheng Zhang", "Kang Li", "Meng Fang", "Linyi Yang", "Xiaoguang Li", "Lifeng Shang", "Songcen Xu", "Jianye Hao", "Kun Shao", "Jun Wang"], "title": "Deep Research Agents: A Systematic Examination And Roadmap", "comment": null, "summary": "The rapid progress of Large Language Models (LLMs) has given rise to a new\ncategory of autonomous AI systems, referred to as Deep Research (DR) agents.\nThese agents are designed to tackle complex, multi-turn informational research\ntasks by leveraging a combination of dynamic reasoning, adaptive long-horizon\nplanning, multi-hop information retrieval, iterative tool use, and the\ngeneration of structured analytical reports. In this paper, we conduct a\ndetailed analysis of the foundational technologies and architectural components\nthat constitute Deep Research agents. We begin by reviewing information\nacquisition strategies, contrasting API-based retrieval methods with\nbrowser-based exploration. We then examine modular tool-use frameworks,\nincluding code execution, multimodal input processing, and the integration of\nModel Context Protocols (MCPs) to support extensibility and ecosystem\ndevelopment. To systematize existing approaches, we propose a taxonomy that\ndifferentiates between static and dynamic workflows, and we classify agent\narchitectures based on planning strategies and agent composition, including\nsingle-agent and multi-agent configurations. We also provide a critical\nevaluation of current benchmarks, highlighting key limitations such as\nrestricted access to external knowledge, sequential execution inefficiencies,\nand misalignment between evaluation metrics and the practical objectives of DR\nagents. Finally, we outline open challenges and promising directions for future\nresearch. A curated and continuously updated repository of DR agent research is\navailable at: {https://github.com/ai-agents-2030/awesome-deep-research-agent}.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u5206\u6790\u4e86Deep Research agents\u7684\u53d1\u5c55\u73b0\u72b6\uff0c\u4ece\u6280\u672f\u3001\u67b6\u6784\u3001\u8bc4\u6d4b\u6307\u6807\u7b49\u591a\u65b9\u9762\u8fdb\u884c\u7cfb\u7edf\u5206\u7c7b\u548c\u68b3\u7406\uff0c\u53d1\u73b0\u5f53\u524d\u4e3b\u8981\u9650\u5236\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u540c\u65f6\u5f00\u653e\u4e86\u6301\u7eed\u66f4\u65b0\u7684\u7814\u7a76\u8d44\u6599\u5e93\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u98de\u901f\u53d1\u5c55\uff0c\u6d8c\u73b0\u51fa\u4e86\u80fd\u591f\u81ea\u4e3b\u8fdb\u884c\u590d\u6742\u591a\u8f6e\u7814\u7a76\u4efb\u52a1\u7684\u667a\u80fd\u4f53\uff08Deep Research agents, DR agents\uff09\uff0c\u4f46\u76f8\u5173\u5173\u952e\u6280\u672f\u53ca\u5176\u67b6\u6784\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u5206\u6790\u548c\u68b3\u7406\u3002", "method": "\u7cfb\u7edf\u5206\u6790DR agents\u7684\u57fa\u7840\u6280\u672f\u4e0e\u6a21\u5757\u5316\u67b6\u6784\uff0c\u5305\u62ec\u4fe1\u606f\u83b7\u53d6\u65b9\u5f0f\uff08API\u68c0\u7d22 vs. \u6d4f\u89c8\u5668\u63a2\u7d22\uff09\u3001\u5de5\u5177\u4f7f\u7528\u6846\u67b6\u3001\u591a\u6a21\u6001\u8f93\u5165\u5904\u7406\u3001\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCPs\uff09\u7b49\u3002\u63d0\u51fa\u7528\u4e8e\u5206\u7c7b\u73b0\u6709\u65b9\u6cd5\u7684\u5206\u7c7b\u6cd5\uff08\u9759\u6001\u4e0e\u52a8\u6001\u6d41\u7a0b\u3001\u5355/\u591aagent\u7b49\uff09\uff0c\u5e76\u5bf9\u73b0\u6709\u57fa\u51c6\u8bc4\u6d4b\u548c\u74f6\u9888\u8fdb\u884c\u6279\u5224\u6027\u7efc\u8ff0\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u5957DR agents\u7684\u7cfb\u7edf\u5206\u7c7b\u6cd5\uff0c\u603b\u7ed3\u548c\u5f52\u7eb3\u4e86\u5176\u67b6\u6784\u8981\u7d20\uff0c\u5e76\u5206\u6790\u4e86\u5f53\u524d\u8bc4\u6d4b\u57fa\u51c6\u7684\u5c40\u9650\u6027\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u6700\u540e\u5f00\u653e\u4e86\u76f8\u5173\u7814\u7a76\u8d44\u6e90\u5e93\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u5316\u68b3\u7406\u4e86DR agents\u7684\u5173\u952e\u6280\u672f\u4e0e\u67b6\u6784\uff0c\u660e\u786e\u5176\u53d1\u5c55\u73b0\u72b6\u4e0e\u6311\u6218\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u548c\u53c2\u8003\u5e93\u3002"}}
{"id": "2506.17693", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17693", "abs": "https://arxiv.org/abs/2506.17693", "authors": ["Yuzhe Ding", "Kang He", "Bobo Li", "Li Zheng", "Haijun He", "Fei Li", "Chong Teng", "Donghong Ji"], "title": "Zero-Shot Conversational Stance Detection: Dataset and Approaches", "comment": "ACL 2025 (Findings)", "summary": "Stance detection, which aims to identify public opinion towards specific\ntargets using social media data, is an important yet challenging task. With the\nincreasing number of online debates among social media users, conversational\nstance detection has become a crucial research area. However, existing\nconversational stance detection datasets are restricted to a limited set of\nspecific targets, which constrains the effectiveness of stance detection models\nwhen encountering a large number of unseen targets in real-world applications.\nTo bridge this gap, we manually curate a large-scale, high-quality zero-shot\nconversational stance detection dataset, named ZS-CSD, comprising 280 targets\nacross two distinct target types. Leveraging the ZS-CSD dataset, we propose\nSITPCL, a speaker interaction and target-aware prototypical contrastive\nlearning model, and establish the benchmark performance in the zero-shot\nsetting. Experimental results demonstrate that our proposed SITPCL model\nachieves state-of-the-art performance in zero-shot conversational stance\ndetection. Notably, the SITPCL model attains only an F1-macro score of 43.81%,\nhighlighting the persistent challenges in zero-shot conversational stance\ndetection.", "AI": {"tldr": "\u4f5c\u8005\u6784\u5efa\u4e86\u65b0\u7684\u96f6\u6837\u672c\u5bf9\u8bdd\u7acb\u573a\u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u65b0\u6a21\u578b\uff0c\u5728\u4efb\u52a1\u4e0a\u53d6\u5f97\u6700\u4f18\u7ed3\u679c\uff0c\u4f46\u6574\u4f53\u8868\u73b0\u4ecd\u6709\u9650\uff0c\u8868\u660e\u6b64\u65b9\u5411\u4ecd\u6709\u5927\u91cf\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u8bdd\u7acb\u573a\u68c0\u6d4b\u6570\u636e\u96c6\u76ee\u6807\u6709\u9650\uff0c\u5bfc\u81f4\u6a21\u578b\u5728\u771f\u5b9e\u73af\u5883\u4e0b\u9047\u5230\u5927\u91cf\u65b0\u76ee\u6807\u65f6\u6548\u679c\u53d7\u9650\u3002", "method": "\u4eba\u5de5\u6784\u5efa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u7684\u96f6\u6837\u672c\u5bf9\u8bdd\u7acb\u573a\u68c0\u6d4b\u6570\u636e\u96c6\uff08ZS-CSD\uff09\uff0c\u6db5\u76d6\u4e24\u79cd\u7c7b\u578b\u5171280\u4e2a\u76ee\u6807\uff0c\u5e76\u63d0\u51fa\u4e86\u7ed3\u5408\u8bf4\u8bdd\u8005\u4ea4\u4e92\u548c\u76ee\u6807\u611f\u77e5\u7684\u539f\u578b\u5bf9\u6bd4\u5b66\u4e60\u6a21\u578bSITPCL\u3002", "result": "SITPCL\u5728\u96f6\u6837\u672c\u5bf9\u8bdd\u7acb\u573a\u68c0\u6d4b\u4efb\u52a1\u4e0a\u8fbe\u5230\u5f53\u524d\u6700\u4f18\uff0c\u4f46F1-macro\u5206\u6570\u4ec5\u4e3a43.81%\uff0c\u663e\u793a\u8be5\u4efb\u52a1\u4f9d\u7136\u975e\u5e38\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684ZS-CSD\u6570\u636e\u96c6\u548cSITPCL\u6a21\u578b\u80fd\u4fc3\u8fdb\u96f6\u6837\u672c\u5bf9\u8bdd\u7acb\u573a\u68c0\u6d4b\u9886\u57df\u53d1\u5c55\uff0c\u4f46\u96f6\u6837\u672c\u60c5\u666f\u4e0b\u7684\u51c6\u786e\u7387\u4ecd\u6709\u5f88\u5927\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2506.18126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18126", "abs": "https://arxiv.org/abs/2506.18126", "authors": ["Xiang Yuming", "Li Sizhao", "Li Rongpeng", "Zhao Zhifeng", "Zhang Honggang"], "title": "Decentralized Consensus Inference-based Hierarchical Reinforcement Learning for Multi-Constrained UAV Pursuit-Evasion Game", "comment": null, "summary": "Multiple quadrotor unmanned aerial vehicle (UAV) systems have garnered\nwidespread research interest and fostered tremendous interesting applications,\nespecially in multi-constrained pursuit-evasion games (MC-PEG). The Cooperative\nEvasion and Formation Coverage (CEFC) task, where the UAV swarm aims to\nmaximize formation coverage across multiple target zones while collaboratively\nevading predators, belongs to one of the most challenging issues in MC-PEG,\nespecially under communication-limited constraints. This multifaceted problem,\nwhich intertwines responses to obstacles, adversaries, target zones, and\nformation dynamics, brings up significant high-dimensional complications in\nlocating a solution. In this paper, we propose a novel two-level framework\n(i.e., Consensus Inference-based Hierarchical Reinforcement Learning (CI-HRL)),\nwhich delegates target localization to a high-level policy, while adopting a\nlow-level policy to manage obstacle avoidance, navigation, and formation.\nSpecifically, in the high-level policy, we develop a novel multi-agent\nreinforcement learning module, Consensus-oriented Multi-Agent Communication\n(ConsMAC), to enable agents to perceive global information and establish\nconsensus from local states by effectively aggregating neighbor messages.\nMeanwhile, we leverage an Alternative Training-based Multi-agent proximal\npolicy optimization (AT-M) and policy distillation to accomplish the low-level\ncontrol. The experimental results, including the high-fidelity\nsoftware-in-the-loop (SITL) simulations, validate that CI-HRL provides a\nsuperior solution with enhanced swarm's collaborative evasion and task\ncompletion capabilities.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u901a\u4fe1\u53d7\u9650\u73af\u5883\u4e0b\u65e0\u4eba\u673a\u591a\u667a\u80fd\u4f53\u534f\u540c\u8ffd\u9003\u548c\u7f16\u961f\u8986\u76d6\u4efb\u52a1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u65b0\u67b6\u6784CI-HRL\uff0c\u7ed3\u5408\u4e86\u5171\u8bc6\u673a\u5236\u548c\u5206\u5c42\u63a7\u5236\uff0c\u5b9e\u9a8c\u8bc1\u660e\u663e\u8457\u63d0\u5347\u4e86\u534f\u540c\u80fd\u529b\u4e0e\u4efb\u52a1\u5b8c\u6210\u6548\u7387\u3002", "motivation": "\u591a\u65cb\u7ffc\u65e0\u4eba\u673a\uff08UAV\uff09\u7cfb\u7edf\u5728\u591a\u7ea6\u675f\u8ffd\u9003\u535a\u5f08\uff08MC-PEG\uff09\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u548c\u7814\u7a76\u6fc0\u53d1\u51fa\u4e86\u8bf8\u5982\u534f\u540c\u89c4\u907f\u4e0e\u7f16\u961f\u8986\u76d6\uff08CEFC\uff09\u7b49\u590d\u6742\u4efb\u52a1\u9700\u6c42\uff0c\u800c\u5728\u901a\u4fe1\u53d7\u9650\u60c5\u51b5\u4e0b\uff0c\u8be5\u95ee\u9898\u517c\u5177\u969c\u788d\u7269\u89c4\u907f\u3001\u5bf9\u6297\u3001\u76ee\u6807\u533a\u8986\u76d6\u548c\u961f\u5f62\u7ba1\u7406\u7b49\u591a\u91cd\u9ad8\u7ef4\u56f0\u96be\u3002\u73b0\u6709\u65b9\u6cd5\u5bf9\u9ad8\u7ef4\u5ea6\u73af\u5883\u4e2d\u591a\u76ee\u6807\u7684\u9ad8\u6548\u89e3\u51b3\u80fd\u529b\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u51fa\u66f4\u6709\u6548\u7684\u534f\u540c\u63a7\u5236\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u6846\u67b6Consensus Inference-based Hierarchical Reinforcement Learning\uff08CI-HRL\uff09\uff0c\u901a\u8fc7\u9ad8\u5c42\u7b56\u7565\u6a21\u5757\u5b9a\u4f4d\u76ee\u6807\u533a\uff0c\u4f4e\u5c42\u7b56\u7565\u6a21\u5757\u5b9e\u73b0\u969c\u788d\u89c4\u907f\u3001\u5bfc\u822a\u4e0e\u961f\u5f62\u63a7\u5236\u3002\u9ad8\u5c42\u653f\u7b56\u5f15\u5165\u4e86\u57fa\u4e8e\u5171\u8bc6\u7684\u591a\u667a\u80fd\u4f53\u6d88\u606f\u805a\u5408\u4e0e\u51b3\u7b56\u673a\u5236\uff08ConsMAC\uff09\uff0c\u63d0\u5347\u672c\u5730\u4fe1\u606f\u6c47\u603b\u4e3a\u5168\u5c40\u5171\u8bc6\u7684\u80fd\u529b\u3002\u4f4e\u5c42\u91c7\u7528\u4ea4\u66ff\u8bad\u7ec3\u7684\u591a\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u53ca\u7b56\u7565\u84b8\u998f\uff0c\u63d0\u5347\u667a\u80fd\u4f53\u4f4e\u7ea7\u534f\u4f5c\u6548\u7387\u3002", "result": "\u8f6f\u4ef6\u4eff\u771f\u53ca\u9ad8\u4fdd\u771f\u5ea6SITL\uff08Software-In-The-Loop\uff09\u5b9e\u9a8c\u8bc1\u660e\uff0cCI-HRL\u6846\u67b6\u80fd\u591f\u663e\u8457\u63d0\u5347\u65e0\u4eba\u673a\u7fa4\u4f53\u7684\u534f\u540c\u89c4\u907f\u4e0e\u591a\u4efb\u52a1\u5b8c\u6210\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684CI-HRL\u6846\u67b6\u53ef\u9ad8\u6548\u5e94\u5bf9\u591a\u7ea6\u675f\u8ffd\u9003\u535a\u5f08\u4e2d\u7684\u590d\u6742\u534f\u540c\u4efb\u52a1\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u901a\u4fe1\u53d7\u9650\u6761\u4ef6\u4e0b\u7684\u5927\u89c4\u6a21\u65e0\u4eba\u673a\u7fa4\u4f53\u534f\u4f5c\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0e\u5de5\u7a0b\u57fa\u7840\u3002"}}
{"id": "2506.17700", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17700", "abs": "https://arxiv.org/abs/2506.17700", "authors": ["Summra Saleem", "Muhammad Nabeel Asim", "Shaista Zulfiqar", "Andreas Dengel"], "title": "The Evolution of Natural Language Processing: How Prompt Optimization and Language Models are Shaping the Future", "comment": null, "summary": "Large Language Models (LLMs) have revolutionized the field of Natural\nLanguage Processing (NLP) by automating traditional labor-intensive tasks and\nconsequently accelerated the development of computer-aided applications. As\nresearchers continue to advance this field with the introduction of novel\nlanguage models and more efficient training/finetuning methodologies, the idea\nof prompt engineering and subsequent optimization strategies with LLMs has\nemerged as a particularly impactful trend to yield a substantial performance\nboost across diverse NLP tasks. To best of our knowledge numerous review\narticles have explored prompt engineering, however, a critical gap exists in\ncomprehensive analyses of prompt optimization strategies. To bridge this gap\nthis paper provides unique and comprehensive insights about the potential of\ndiverse prompt optimization strategies. It analyzes their underlying working\nparadigms and based on these principles, categorizes them into 11 distinct\nclasses. Moreover, the paper provides details about various NLP tasks where\nthese prompt optimization strategies have been employed, along with details of\ndifferent LLMs and benchmark datasets used for evaluation. This comprehensive\ncompilation lays a robust foundation for future comparative studies and enables\nrigorous assessment of prompt optimization and LLM-based predictive pipelines\nunder consistent experimental settings: a critical need in the current\nlandscape. Ultimately, this research will centralize diverse strategic\nknowledge to facilitate the adaptation of existing prompt optimization\nstrategies for development of innovative predictors across unexplored tasks.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86LLM\u63d0\u793a\u4f18\u5316\u7b56\u7565\uff0c\u5e76\u5c06\u5176\u5206\u4e3a11\u7c7b\uff0c\u8986\u76d6\u5404\u79cd\u5e94\u7528\u573a\u666f\u4e0e\u6a21\u578b\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u548c\u5b9e\u9a8c\u57fa\u51c6\u3002", "motivation": "\u5c3d\u7ba1\u76ee\u524d\u5df2\u6709\u8bb8\u591a\u5173\u4e8e\u63d0\u793a\u5de5\u7a0b\uff08prompt engineering\uff09\u7684\u7efc\u8ff0\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u63d0\u793a\u4f18\u5316\u7b56\u7565\u7684\u5168\u9762\u5206\u6790\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u586b\u8865\u8fd9\u4e2a\u7a7a\u767d\uff0c\u4f5c\u8005\u5e0c\u671b\u7cfb\u7edf\u68b3\u7406\u548c\u5206\u6790\u73b0\u6709\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u4ece\u539f\u7406\u51fa\u53d1\uff0c\u5bf9\u73b0\u6709\u7684\u63d0\u793a\u4f18\u5316\u7b56\u7565\u8fdb\u884c\u4e86\u6df1\u5165\u7814\u7a76\uff0c\u5c06\u5176\u5f52\u7eb3\u4e3a11\u79cd\u4e0d\u540c\u7c7b\u578b\uff0c\u5e76\u56de\u987e\u4e86\u8fd9\u4e9b\u7b56\u7565\u5728\u5404\u79cdNLP\u4efb\u52a1\u3001\u6240\u4f7f\u7528\u7684\u4e0d\u540cLLM\u53ca\u8bc4\u6d4b\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\u60c5\u51b5\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u5957\u5168\u9762\u7684\u63d0\u793a\u4f18\u5316\u7b56\u7565\u5206\u7c7b\u4f53\u7cfb\uff0c\u6c47\u603b\u4e86\u76f8\u5173\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\u548c\u5b9e\u9a8c\uff0c\u7528\u4e8e\u540e\u7eed\u7814\u7a76\u548c\u8bc4\u4f30\u3002", "conclusion": "\u672c\u6587\u5960\u5b9a\u4e86\u540e\u7eed\u6bd4\u8f83\u6027\u7814\u7a76\u7684\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u5728\u7edf\u4e00\u7684\u5b9e\u9a8c\u8bbe\u7f6e\u4e0b\u66f4\u4e25\u683c\u5730\u8bc4\u4f30\u548c\u6539\u8fdb\u63d0\u793a\u4f18\u5316\u4e0eLLM\u63a8\u7406\u6d41\u7a0b\uff0c\u5e76\u4fc3\u8fdb\u65b0\u5e94\u7528\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.18135", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18135", "abs": "https://arxiv.org/abs/2506.18135", "authors": ["Zijun Chen", "Zhanpeng Zhou", "Bo Zhang", "Weinan Zhang", "Xi Sun", "Junchi Yan"], "title": "SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging", "comment": "preprint, accepted at IJCNN2025", "summary": "Model merging has gained increasing attention due to its intriguing property:\ninterpolating the parameters of different task-specific fine-tuned models leads\nto multi-task abilities. However, despite its empirical success, the underlying\nmechanisms of model merging remain poorly understood. In this work, we delve\ninto the mechanism behind model merging from a representation perspective. Our\nanalysis reveals that model merging achieves multi-task abilities through two\nkey capabilities: i) distinguishing samples from different tasks, and ii)\nadapting to the corresponding expert model for each sample. These two\ncapabilities allow the merged model to retain task-specific expertise, enabling\nefficient multi-task adaptation. Building on these insights, we propose\n\\texttt{SE-Merging}, a self-enhanced model merging framework that leverages\nthese two characteristics to dynamically identify the corresponding task for\neach sample and then adaptively rescales the merging coefficients to further\nenhance task-specific expertise in the merged model. Notably,\n\\texttt{SE-Merging} achieves dynamic model merging without additional training.\nExtensive experiments demonstrate that \\texttt{SE-Merging} achieves significant\nperformance improvements while remaining compatible with existing model merging\ntechniques.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u6a21\u578b\u5408\u5e76\u7684\u673a\u5236\uff0c\u63d0\u51fa\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u663e\u8457\u63d0\u5347\u591a\u4efb\u52a1\u6027\u80fd\u7684\u52a8\u6001\u5408\u5e76\u65b0\u65b9\u6cd5SE-Merging\uff0c\u5e76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u6a21\u578b\u5408\u5e76\u5728\u591a\u4efb\u52a1\u80fd\u529b\u4e0a\u6709\u5b9e\u8bc1\u6210\u529f\uff0c\u4f46\u5176\u673a\u5236\u5c1a\u4e0d\u6e05\u6670\uff0c\u7279\u522b\u662f\u5176\u5982\u4f55\u5b9e\u73b0\u591a\u4efb\u52a1\u9002\u5e94\u3002\u672c\u6587\u65e8\u5728\u5256\u6790\u6a21\u578b\u5408\u5e76\u673a\u5236\u5e76\u63d0\u5347\u5176\u6027\u80fd\u3002", "method": "\u4f5c\u8005\u4ece\u8868\u793a\u5b66\u4e60\u89d2\u5ea6\u5206\u6790\u6a21\u578b\u5408\u5e76\u673a\u5236\uff0c\u63ed\u793a\u6a21\u578b\u5408\u5e76\u901a\u8fc7\u201c\u533a\u5206\u4efb\u52a1\u6837\u672c\u201d\u548c\u201c\u9002\u5e94\u5bf9\u5e94\u4e13\u5bb6\u6a21\u578b\u201d\u83b7\u5f97\u591a\u4efb\u52a1\u80fd\u529b\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51faSE-Merging\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5408\u5e76\u7cfb\u6570\u589e\u5f3a\u5408\u5e76\u6a21\u578b\u7684\u4efb\u52a1\u7279\u5b9a\u80fd\u529b\u3002", "result": "SE-Merging\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u52a8\u6001\u6a21\u578b\u5408\u5e76\uff0c\u4e14\u4e0e\u73b0\u6709\u5408\u5e76\u65b9\u6cd5\u517c\u5bb9\uff0c\u5728\u591a\u9879\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "SE-Merging\u80fd\u591f\u4f9d\u636e\u8f93\u5165\u6837\u672c\u52a8\u6001\u8bc6\u522b\u4efb\u52a1\uff0c\u5e76\u81ea\u9002\u5e94\u8c03\u6574\u5408\u5e76\u7cfb\u6570\uff0c\u5728\u4e0d\u9700\u989d\u5916\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4efb\u52a1\u4e13\u957f\u80fd\u529b\uff0c\u5bf9\u73b0\u6709\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2506.17708", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17708", "abs": "https://arxiv.org/abs/2506.17708", "authors": ["MingZe Tang"], "title": "Aged to Perfection: Machine-Learning Maps of Age in Conversational English", "comment": "6 pages, 11 figures", "summary": "The study uses the British National Corpus 2014, a large sample of\ncontemporary spoken British English, to investigate language patterns across\ndifferent age groups. Our research attempts to explore how language patterns\nvary between different age groups, exploring the connection between speaker\ndemographics and linguistic factors such as utterance duration, lexical\ndiversity, and word choice. By merging computational language analysis and\nmachine learning methodologies, we attempt to uncover distinctive linguistic\nmarkers characteristic of multiple generations and create prediction models\nthat can consistently estimate the speaker's age group from various aspects.\nThis work contributes to our knowledge of sociolinguistic diversity throughout\nthe life of modern British speech.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u82f1\u56fd\u56fd\u5bb6\u8bed\u6599\u5e93\u548c\u673a\u5668\u5b66\u4e60\uff0c\u53d1\u73b0\u5e76\u9884\u6d4b\u4e86\u4e0d\u540c\u5e74\u9f84\u7ec4\u5728\u53e3\u8bed\u4e2d\u7684\u8bed\u8a00\u7279\u5f81\u5dee\u5f02\uff0c\u52a0\u6df1\u4e86\u5bf9\u82f1\u56fd\u73b0\u4ee3\u53e3\u8bed\u4e2d\u793e\u4f1a\u8bed\u8a00\u5b66\u591a\u6837\u6027\u7684\u7406\u89e3\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7a76\u82f1\u56fd\u4e0d\u540c\u5e74\u9f84\u7fa4\u4f53\u5728\u53e3\u8bed\u8868\u8fbe\u4e2d\u7684\u8bed\u8a00\u6a21\u5f0f\u53d8\u5316\uff0c\u4ee5\u53ca\u8bf4\u8bdd\u8005\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u4e0e\u8bed\u8a00\u5b66\u56e0\u7d20\uff08\u5982\u8bdd\u8bed\u957f\u5ea6\u3001\u8bcd\u6c47\u591a\u6837\u6027\u548c\u7528\u8bcd\u9009\u62e9\uff09\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u672c\u7814\u7a76\u5229\u7528British National Corpus 2014\uff08\u82f1\u56fd\u56fd\u5bb6\u8bed\u6599\u5e932014\uff09\uff0c\u7ed3\u5408\u8ba1\u7b97\u8bed\u8a00\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5bf9\u8bed\u8a00\u8fdb\u884c\u5206\u6790\uff0c\u8bd5\u56fe\u53d1\u73b0\u4e0d\u540c\u4e16\u4ee3\u7684\u8bed\u8a00\u6807\u5fd7\uff0c\u5e76\u6784\u5efa\u80fd\u591f\u6839\u636e\u591a\u9879\u8bed\u8a00\u7279\u5f81\u5bf9\u8bf4\u8bdd\u8005\u5e74\u9f84\u7ec4\u8fdb\u884c\u9884\u6d4b\u7684\u6a21\u578b\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u591a\u4ee3\u7fa4\u4f53\u5728\u8bed\u8a00\u6807\u5fd7\u4e0a\u7684\u5dee\u5f02\u6027\uff0c\u5e76\u6210\u529f\u521b\u5efa\u4e86\u53ef\u6839\u636e\u8bed\u8a00\u7279\u6027\u51c6\u786e\u9884\u6d4b\u8bf4\u8bdd\u8005\u5e74\u9f84\u7ec4\u7684\u9884\u6d4b\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u4e30\u5bcc\u4e86\u6211\u4eec\u5bf9\u73b0\u4ee3\u82f1\u56fd\u53e3\u8bed\u4e2d\u793e\u4f1a\u8bed\u8a00\u5b66\u591a\u6837\u6027\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u540e\u7eed\u57fa\u4e8e\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u548c\u8bed\u8a00\u5b66\u7279\u5f81\u5173\u7cfb\u7684\u8bed\u8a00\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u6cd5\u53c2\u8003\u3002"}}
{"id": "2506.18149", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18149", "abs": "https://arxiv.org/abs/2506.18149", "authors": ["Fumian Chen", "Sotheara Veng", "Joshua Wilson", "Xiaoming Li", "Hui Fang"], "title": "CoachGPT: A Scaffolding-based Academic Writing Assistant", "comment": "SIGIR 2025 DEMO Pre-print", "summary": "Academic writing skills are crucial for students' success, but can feel\noverwhelming without proper guidance and practice, particularly when writing in\na second language. Traditionally, students ask instructors or search\ndictionaries, which are not universally accessible. Early writing assistants\nemerged as rule-based systems that focused on detecting misspellings,\nsubject-verb disagreements, and basic punctuation errors; however, they are\ninaccurate and lack contextual understanding. Machine learning-based assistants\ndemonstrate a strong ability for language understanding but are expensive to\ntrain. Large language models (LLMs) have shown remarkable capabilities in\ngenerating responses in natural languages based on given prompts. Still, they\nhave a fundamental limitation in education: they generate essays without\nteaching, which can have detrimental effects on learning when misused. To\naddress this limitation, we develop CoachGPT, which leverages large language\nmodels (LLMs) to assist individuals with limited educational resources and\nthose who prefer self-paced learning in academic writing. CoachGPT is an AI\nagent-based web application that (1) takes instructions from experienced\neducators, (2) converts instructions into sub-tasks, and (3) provides real-time\nfeedback and suggestions using large language models. This unique scaffolding\nstructure makes CoachGPT unique among existing writing assistants. Compared to\nexisting writing assistants, CoachGPT provides a more immersive writing\nexperience with personalized feedback and guidance. Our user studies prove the\nusefulness of CoachGPT and the potential of large language models for academic\nwriting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5199\u4f5c\u8f85\u52a9\u7cfb\u7edfCoachGPT\uff0c\u91c7\u7528\u6559\u80b2\u4e13\u5bb6\u6307\u5bfc\u4e0e\u5b9e\u65f6\u53cd\u9988\u673a\u5236\uff0c\u63d0\u5347\u4e2a\u6027\u5316\u4e0e\u6559\u5b66\u6027\u3002\u7528\u6237\u7814\u7a76\u8bc1\u5b9e\u5176\u5bf9\u5b66\u672f\u5199\u4f5c\u7684\u663e\u8457\u5e2e\u52a9\uff0c\u5c55\u793aLLM\u5728\u5199\u4f5c\u6559\u80b2\u5e94\u7528\u7684\u6f5c\u529b\u3002", "motivation": "\u5b66\u672f\u5199\u4f5c\u80fd\u529b\u5bf9\u5b66\u751f\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u7b2c\u4e8c\u8bed\u8a00\u5199\u4f5c\u65f6\uff0c\u7f3a\u4e4f\u6307\u5bfc\u548c\u5b9e\u8df5\u4f1a\u8ba9\u5b66\u751f\u611f\u5230\u538b\u529b\u3002\u4f20\u7edf\u5199\u4f5c\u8f85\u52a9\u5de5\u5177\u5b58\u5728\u7406\u89e3\u529b\u4e0d\u8db3\u548c\u6709\u9650\u7684\u6559\u80b2\u529f\u80fd\u3002\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53d1\u5c55\uff0c\u51fa\u73b0\u4e86\u751f\u6210\u5185\u5bb9\u4f46\u4e0d\u6ce8\u91cd\u6559\u5b66\u7684\u95ee\u9898\uff0c\u5bb9\u6613\u5f71\u54cd\u5b66\u751f\u5b66\u4e60\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u5de5\u5177\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u5199\u4f5c\u8f85\u52a9\u7684\u6559\u80b2\u6027\u548c\u4e2a\u6027\u5316\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86CoachGPT\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u5199\u4f5c\u8f85\u52a9\u5e73\u53f0\u3002CoachGPT\u901a\u8fc7\u63a5\u6536\u6559\u80b2\u4e13\u5bb6\u7684\u6307\u5bfc\uff0c\u5c06\u6307\u5bfc\u8f6c\u5316\u4e3a\u5177\u4f53\u5b50\u4efb\u52a1\uff0c\u5e76\u501f\u52a9LLM\u4e3a\u7528\u6237\u63d0\u4f9b\u5b9e\u65f6\u53cd\u9988\u548c\u5efa\u8bae\u3002\u8fd9\u4e00\u7ed3\u6784\u589e\u52a0\u4e86\u5199\u4f5c\u8fc7\u7a0b\u7684\u4e92\u52a8\u6027\u548c\u6559\u80b2\u6027\u3002", "result": "CoachGPT\u80fd\u591f\u4e3a\u5b66\u4e60\u8d44\u6e90\u6709\u9650\u6216\u504f\u597d\u81ea\u5b66\u7684\u5b66\u751f\u63d0\u4f9b\u66f4\u6c89\u6d78\u5f0f\u3001\u4e2a\u6027\u5316\u7684\u5b66\u672f\u5199\u4f5c\u652f\u6301\u3002\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cCoachGPT\u4f7f\u7528\u4f53\u9a8c\u826f\u597d\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u4ee5\u53caLLM\u5728\u5b66\u672f\u5199\u4f5c\u8f85\u52a9\u9886\u57df\u7684\u6f5c\u529b\u3002", "conclusion": "CoachGPT\u901a\u8fc7\u521b\u65b0\u7684\u7ed3\u6784\u548c\u5b9e\u65f6\u4e2a\u6027\u5316\u53cd\u9988\uff0c\u514b\u670d\u4e86\u73b0\u6709\u5199\u4f5c\u52a9\u624b\u4e00\u5473\u751f\u6210\u5185\u5bb9\u3001\u4e0d\u91cd\u89c6\u6559\u5b66\u7684\u7f3a\u9677\uff0c\u4e3a\u63d0\u5347\u5b66\u672f\u5199\u4f5c\u6559\u5b66\u548c\u81ea\u4e3b\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002\u5176\u6846\u67b6\u548c\u7814\u7a76\u5c55\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6559\u80b2\u9886\u57df\u5e94\u7528\u7684\u5de8\u5927\u524d\u666f\u3002"}}
{"id": "2506.17715", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17715", "abs": "https://arxiv.org/abs/2506.17715", "authors": ["Matthias Sch\u00f6ffel", "Esteban Garces Arias", "Marinus Wiedner", "Paula Ruppert", "Meimingwei Li", "Christian Heumann", "Matthias A\u00dfenmacher"], "title": "Unveiling Factors for Enhanced POS Tagging: A Study of Low-Resource Medieval Romance Languages", "comment": null, "summary": "Part-of-speech (POS) tagging remains a foundational component in natural\nlanguage processing pipelines, particularly critical for historical text\nanalysis at the intersection of computational linguistics and digital\nhumanities. Despite significant advancements in modern large language models\n(LLMs) for ancient languages, their application to Medieval Romance languages\npresents distinctive challenges stemming from diachronic linguistic evolution,\nspelling variations, and labeled data scarcity. This study systematically\ninvestigates the central determinants of POS tagging performance across diverse\ncorpora of Medieval Occitan, Medieval Spanish, and Medieval French texts,\nspanning biblical, hagiographical, medical, and dietary domains. Through\nrigorous experimentation, we evaluate how fine-tuning approaches, prompt\nengineering, model architectures, decoding strategies, and cross-lingual\ntransfer learning techniques affect tagging accuracy. Our results reveal both\nnotable limitations in LLMs' ability to process historical language variations\nand non-standardized spelling, as well as promising specialized techniques that\neffectively address the unique challenges presented by low-resource historical\nlanguages.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e0d\u540c\u6280\u672f\u5728\u4e2d\u4e16\u7eaa\u7f57\u66fc\u8bed\u65cf\u4f4e\u8d44\u6e90\u6587\u672c\u8bcd\u6027\u6807\u6ce8\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u6709\u9650\u5236\uff0c\u4f46\u901a\u8fc7\u5fae\u8c03\u7b49\u65b9\u6cd5\u53ef\u663e\u8457\u6539\u8fdb\u5386\u53f2\u6587\u672c\u7684\u5904\u7406\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\uff0c\u8bb8\u591a\u53e4\u4ee3\u8bed\u8a00\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u53d6\u5f97\u4e86\u7a81\u7834\uff0c\u4f46\u4e2d\u4e16\u7eaa\u7f57\u66fc\u8bed\u65cf\u6587\u672c\u56e0\u4e3a\u8bed\u8a00\u6f14\u53d8\u3001\u62fc\u5199\u591a\u6837\u548c\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7b49\u95ee\u9898\uff0c\u4f9d\u7136\u5b58\u5728\u8bf8\u591a\u56f0\u96be\u3002\u7814\u7a76\u8005\u4e9f\u9700\u63a2\u7d22\u9488\u5bf9\u4e2d\u4e16\u7eaa\u4f4e\u8d44\u6e90\u5386\u53f2\u8bed\u8a00\u7684\u81ea\u52a8\u8bcd\u6027\u6807\u6ce8\u65b9\u6cd5\uff0c\u63d0\u5347\u6570\u5b57\u4eba\u6587\u5b66\u79d1\u7684\u6587\u672c\u5904\u7406\u80fd\u529b\u3002", "method": "\u672c\u6587\u7cfb\u7edf\u6027\u5730\u8003\u5bdf\u4e86\u5f71\u54cd\u4e2d\u4e16\u7eaa\u5965\u514b\u8bed\u3001\u897f\u73ed\u7259\u8bed\u548c\u6cd5\u8bed\u7b49\u6587\u672c\u4e2d\u8bcd\u6027\u6807\u6ce8\u8868\u73b0\u7684\u4e3b\u8981\u56e0\u7d20\u3002\u6240\u7528\u65b9\u6cd5\u5305\u62ec\u6a21\u578b\u5fae\u8c03\u3001\u63d0\u793a\u5de5\u7a0b\uff08prompt engineering\uff09\u3001\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u3001\u89e3\u7801\u7b56\u7565\u4ee5\u53ca\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b66\u4e60\u3002\u6db5\u76d6\u5723\u7ecf\u3001\u5723\u5f92\u4f20\u8bb0\u3001\u533b\u5b66\u548c\u996e\u98df\u7b49\u591a\u6837\u5316\u8bed\u6599\u3002\u901a\u8fc7\u4e25\u683c\u7684\u5b9e\u9a8c\u5bf9\u6bd4\u5404\u56e0\u7d20\u5bf9\u6807\u6ce8\u51c6\u786e\u7387\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u5386\u53f2\u8bed\u8a00\u53d8\u4f53\u4e0e\u975e\u6807\u51c6\u62fc\u5199\u65b9\u9762\u53d7\u9650\uff0c\u51c6\u786e\u7387\u53d7\u6311\u6218\u3002\u4f46\u540c\u65f6\u4e5f\u786e\u5b9a\u4e86\u82e5\u5e72\u53ef\u884c\u7684\u4e13\u95e8\u5316\u6280\u672f\uff08\u5982\u5fae\u8c03\u4e0e\u8fc1\u79fb\u5b66\u4e60\u7b49\uff09\uff0c\u53ef\u4ee5\u5728\u4f4e\u8d44\u6e90\u5386\u53f2\u8bed\u8a00\u73af\u5883\u4e0b\u6709\u6548\u63d0\u5347\u8bcd\u6027\u6807\u6ce8\u6027\u80fd\u3002", "conclusion": "\u867d\u7136\u5f53\u524dLLMs\u5bf9\u4e2d\u4e16\u7eaa\u7f57\u66fc\u8bed\u65cf\u6587\u672c\u7684\u5904\u7406\u4ecd\u6709\u660e\u663e\u5c40\u9650\uff0c\u4f46\u5b9a\u5236\u7684\u65b9\u6cd5\u548c\u6280\u672f\u80fd\u591f\u6709\u6548\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u4e0e\u8bed\u8a00\u53d8\u5f02\u95ee\u9898\uff0c\u4e3a\u5386\u53f2\u8bed\u8a00\u7684\u81ea\u52a8\u5316\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u548c\u601d\u8def\u3002"}}
{"id": "2506.18156", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18156", "abs": "https://arxiv.org/abs/2506.18156", "authors": ["Akash Kundu", "Rishika Goswami"], "title": "AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology", "comment": null, "summary": "We investigate whether Large Language Models (LLMs) exhibit human-like\ncognitive patterns under four established frameworks from psychology: Thematic\nApperception Test (TAT), Framing Bias, Moral Foundations Theory (MFT), and\nCognitive Dissonance. We evaluated several proprietary and open-source models\nusing structured prompts and automated scoring. Our findings reveal that these\nmodels often produce coherent narratives, show susceptibility to positive\nframing, exhibit moral judgments aligned with Liberty/Oppression concerns, and\ndemonstrate self-contradictions tempered by extensive rationalization. Such\nbehaviors mirror human cognitive tendencies yet are shaped by their training\ndata and alignment methods. We discuss the implications for AI transparency,\nethical deployment, and future work that bridges cognitive psychology and AI\nsafety", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u79cd\u5fc3\u7406\u5b66\u6d4b\u8bd5\u4e0b\u8868\u73b0\u51fa\u90e8\u5206\u7c7b\u4eba\u8ba4\u77e5\u7279\u5f81\uff0c\u8fd9\u4e3aAI\u4f26\u7406\u3001\u900f\u660e\u6027\u53ca\u8ba4\u77e5\u5fc3\u7406\u5b66\u7ed3\u5408AI\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u5426\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8ba4\u77e5\u6a21\u5f0f\uff0c\u8fd9\u5bf9\u4e8e\u7406\u89e3AI\u667a\u80fd\u548c\u63d0\u5347\u5176\u5b89\u5168\u6027\u4e0e\u4f26\u7406\u6027\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u91c7\u7528\u56db\u79cd\u5fc3\u7406\u5b66\u6846\u67b6\uff08\u4e3b\u9898\u7edf\u89c9\u6d4b\u9a8cTAT\u3001\u6846\u67b6\u504f\u89c1\u3001\u9053\u5fb7\u57fa\u7840\u7406\u8bbaMFT\u3001\u8ba4\u77e5\u5931\u8c03\uff09\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u548c\u81ea\u52a8\u8bc4\u5206\u8bc4\u4f30\u591a\u4e2a\u4e13\u6709\u4e0e\u5f00\u6e90\u5927\u6a21\u578b\u7684\u8868\u73b0\u3002", "result": "\u6a21\u578b\u8868\u73b0\u4e3a\u80fd\u591f\u751f\u6210\u8fde\u8d2f\u53d9\u4e8b\u3001\u6613\u53d7\u5230\u79ef\u6781\u8868\u8ff0\u5f71\u54cd\u3001\u9053\u5fb7\u5224\u65ad\u504f\u5411\u81ea\u7531/\u538b\u8feb\u7ef4\u5ea6\uff0c\u5e76\u5728\u81ea\u76f8\u77db\u76fe\u65f6\u8fdb\u884c\u8f83\u591a\u5408\u7406\u5316\uff0c\u8fd9\u4e9b\u884c\u4e3a\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u53cd\u6620\u4e86\u4eba\u7c7b\u8ba4\u77e5\u503e\u5411\uff0c\u4f46\u53d7\u5176\u8bad\u7ec3\u6570\u636e\u548c\u5bf9\u9f50\u65b9\u5f0f\u5f71\u54cd\u3002", "conclusion": "LLM\u90e8\u5206\u5c55\u73b0\u4e86\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8ba4\u77e5\u6a21\u5f0f\uff0c\u7ed3\u679c\u53d7\u5230\u8bad\u7ec3\u4e0e\u5bf9\u9f50\u673a\u5236\u5f71\u54cd\u3002\u4f5c\u8005\u8ba4\u4e3a\u5e94\u5728AI\u900f\u660e\u5ea6\u3001\u4f26\u7406\u4e0e\u5fc3\u7406\u5b66\u7ed3\u5408AI\u5b89\u5168\u7b49\u65b9\u5411\u8fdb\u4e00\u6b65\u8ba8\u8bba\u548c\u7814\u7a76\u3002"}}
{"id": "2506.17728", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17728", "abs": "https://arxiv.org/abs/2506.17728", "authors": ["Dalong Zhang", "Jun Xu", "Jun Zhou", "Lei Liang", "Lin Yuan", "Ling Zhong", "Mengshu Sun", "Peilong Zhao", "QiWei Wang", "Xiaorui Wang", "Xinkai Du", "YangYang Hou", "Yu Ao", "ZhaoYang Wang", "Zhengke Gui", "ZhiYing Yi", "Zhongpu Bo"], "title": "KAG-Thinker: Teaching Large Language Models to Think with Human-like Reasoning Process", "comment": null, "summary": "In this paper, we introduce KAG-Thinker, a novel human-like reasoning\nframework built upon a parameter-light large language model (LLM). Our approach\nenhances the logical coherence and contextual consistency of the thinking\nprocess in question-answering (Q\\&A) tasks on domain-specific knowledge bases\n(KBs) within LLMs. This framework simulates human cognitive mechanisms for\nhandling complex problems by establishing a structured thinking process.\nContinuing the \\textbf{Logical Form} guided retrieval and reasoning technology\nroute of KAG v0.7, firstly, it decomposes complex questions into independently\nsolvable sub-problems(also referred to as logical forms) through\n\\textbf{breadth decomposition}, each represented in two equivalent\nforms-natural language and logical function-and further classified as either\nKnowledge Retrieval or Reasoning Analysis tasks, with dependencies and\nvariables passing explicitly modeled via logical function interfaces. In the\nsolving process, the Retrieval function is used to perform knowledge retrieval\ntasks, while the Math and Deduce functions are used to perform reasoning\nanalysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval\nsub-problem tasks, LLMs and external knowledge sources are regarded as\nequivalent KBs. We use the \\textbf{knowledge boundary} model to determine the\noptimal source using self-regulatory mechanisms such as confidence calibration\nand reflective reasoning, and use the \\textbf{depth solving} model to enhance\nthe comprehensiveness of knowledge acquisition. Finally, instead of utilizing\nreinforcement learning, we employ supervised fine-tuning with multi-turn\ndialogues to align the model with our structured inference paradigm, thereby\navoiding excessive reflection. This is supported by a data evaluation framework\nand iterative corpus synthesis, which facilitate the generation of detailed\nreasoning trajectories...", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u62df\u4eba\u7c7b\u601d\u7ef4\u3001\u7ed3\u6784\u5316\u63a8\u7406\u8fc7\u7a0b\u7684\u65b0\u6846\u67b6KAG-Thinker\uff0c\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u590d\u6742\u95ee\u7b54\u4e2d\u7684\u903b\u8f91\u4e0e\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u521b\u65b0\u5206\u89e3\u3001\u68c0\u7d22\u3001\u63a8\u7406\u548c\u8bad\u7ec3\u673a\u5236\u5b9e\u73b0\u66f4\u4f18\u7684\u63a8\u7406\u8868\u73b0\u3002", "motivation": "\u8bb8\u591a\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u5e93\u7684\u590d\u6742\u95ee\u7b54\u4efb\u52a1\u65f6\uff0c\u7f3a\u4e4f\u4eba\u7c7b\u7c7b\u4f3c\u7684\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\uff0c\u903b\u8f91\u8fde\u8d2f\u6027\u548c\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u6709\u5f85\u63d0\u5347\u3002\u4f5c\u8005\u5e0c\u671b\u63d0\u5347LLM\u5728\u4eba\u7c7b\u7c7b\u4f3c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8868\u73b0\uff0c\u6a21\u62df\u66f4\u7cfb\u7edf\u3001\u6709\u6761\u7406\u7684\u89e3\u9898\u65b9\u5f0f\u3002", "method": "\u63d0\u51faKAG-Thinker\u6846\u67b6\uff0c\u57fa\u4e8e\u53c2\u6570\u91cf\u8f83\u5c0f\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7'\u5e7f\u5ea6\u5206\u89e3'\u65b9\u6cd5\u5c06\u590d\u6742\u95ee\u9898\u62c6\u89e3\u4e3a\u53ef\u72ec\u7acb\u89e3\u51b3\u7684\u5b50\u95ee\u9898\uff08\u5b50\u95ee\u9898\u4ee5\u81ea\u7136\u8bed\u8a00\u548c\u903b\u8f91\u51fd\u6570\u4e24\u79cd\u5f62\u5f0f\u8868\u8fbe\uff09\u3002\u9488\u5bf9\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u8fdb\u884c\u77e5\u8bc6\u68c0\u7d22\u6216\u63a8\u7406\u5206\u6790\uff0c\u91c7\u7528\u660e\u786e\u5efa\u6a21\u7684\u4f9d\u8d56\u5173\u7cfb\u548c\u53d8\u91cf\u4f20\u9012\u673a\u5236\u3002\u521b\u65b0\u5730\u5229\u7528\u77e5\u8bc6\u8fb9\u754c\u6a21\u578b\uff0c\u7ed3\u5408\u81ea\u4fe1\u5ea6\u6821\u51c6\u4e0e\u53cd\u601d\u63a8\u7406\u8c03\u5ea6\u6700\u4f18\u77e5\u8bc6\u6e90\uff0c\u5e76\u4f7f\u7528'\u6df1\u5ea6\u6c42\u89e3'\u6a21\u578b\u63d0\u9ad8\u77e5\u8bc6\u83b7\u53d6\u7684\u5b8c\u6574\u6027\u3002\u6b64\u5916\uff0c\u8bad\u7ec3\u65b9\u6cd5\u91c7\u7528\u57fa\u4e8e\u591a\u8f6e\u5bf9\u8bdd\u7684\u6709\u76d1\u7763\u5fae\u8c03\uff0c\u914d\u5408\u6570\u636e\u8bc4\u6d4b\u6846\u67b6\u548c\u8fed\u4ee3\u8bed\u6599\u751f\u6210\uff0c\u907f\u514d\u8fc7\u5ea6\u53cd\u601d\u3002", "result": "KAG-Thinker\u80fd\u591f\u5b9e\u73b0\u66f4\u7b26\u5408\u4eba\u7c7b\u601d\u7ef4\u7684\u95ee\u7b54\u63a8\u7406\u8fc7\u7a0b\uff0c\u6709\u6548\u63d0\u5347\u903b\u8f91\u8fde\u8d2f\u6027\u548c\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u3002\u91c7\u7528\u77e5\u8bc6\u8fb9\u754c\u6a21\u578b\u548c\u6df1\u5ea6\u6c42\u89e3\u673a\u5236\u540e\uff0c\u7cfb\u7edf\u80fd\u66f4\u4f18\u9009\u77e5\u8bc6\u6e90\u5e76\u83b7\u5f97\u66f4\u5b8c\u6574\u7684\u77e5\u8bc6\u3002\u901a\u8fc7\u6709\u76d1\u7763\u5fae\u8c03\u66ff\u4ee3\u5f3a\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u4e0e\u7ed3\u6784\u5316\u63a8\u7406\u8303\u5f0f\u5bf9\u9f50\uff0c\u6570\u636e\u8bc4\u6d4b\u548c\u8bed\u6599\u751f\u6210\u673a\u5236\u8fdb\u4e00\u6b65\u52a0\u5f3a\u4e86\u5168\u9762\u6027\u548c\u6548\u679c\u3002", "conclusion": "KAG-Thinker\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u5e93\u7684\u590d\u6742\u95ee\u7b54\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u5176\u63a8\u7406\u8fc7\u7a0b\u66f4\u52a0\u7cfb\u7edf\u548c\u4eba\u7c7b\u5316\u3002\u6240\u63d0\u51fa\u7684\u67b6\u6784\u6574\u5408\u4e86\u77e5\u8bc6\u68c0\u7d22\u3001\u903b\u8f91\u5206\u89e3\u3001\u63a8\u7406\u5206\u6790\u4ee5\u53ca\u9ad8\u6548\u6570\u636e\u9a71\u52a8\u8bad\u7ec3\uff0c\u5bf9\u7ed3\u6784\u5316\u95ee\u7b54\u63a8\u7406\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.18158", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.18158", "abs": "https://arxiv.org/abs/2506.18158", "authors": ["Xinzge Gao", "Chuanrui Hu", "Bin Chen", "Teng Li"], "title": "Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation", "comment": null, "summary": "Multimodal large language models (MLLMs) are attracting growing attention in\nthe development of Graphical User Interface (GUI) agents. Existing approaches\noften rely on historical screenshots or actions to implicitly represent the\ntask state. This reliance poses challenges for GUI agents in accurately\nunderstanding task states and underscores the absence of effective mechanisms\nto store critical information in complex and lengthy cross-app tasks. To\naddress these challenges, we propose Chain-of-Memory (CoM), a novel approach\nfor explicitly modeling short-term and long-term memory in GUI agents. CoM\nachieves this by capturing action descriptions, integrating task-relevant\nscreen information, and maintaining a dedicated memory module to store and\nmanage this information. By leveraging explicit memory representations, CoM\nenables GUI agents to better understand task states and retain critical\nhistorical information persistently. To equip GUI agents with memory management\ncapabilities and evaluate the effectiveness of CoM, we developed the GUI\nOdyssey-CoM, a dataset comprising 111k screen-action pairs annotated with\nChain-of-Memory. Experimental results demonstrate that CoM significantly\nimproves GUI agents' performance in cross-application tasks. Additionally, GUI\nOdyssey-CoM enables 7B models to achieve memory management capabilities\ncomparable to 72B models. The dataset and code will be open-sourced.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51faChain-of-Memory\uff08CoM\uff09\u673a\u5236\uff0c\u7528\u4e8e\u663e\u5f0f\u5b58\u50a8\u548c\u7ba1\u7406GUI\u4efb\u52a1\u5173\u952e\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u590d\u6742\u8de8\u5e94\u7528\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5f00\u6e90\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08MLLM\uff09\u5728\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u667a\u80fd\u4f53\u5f00\u53d1\u4e2d\uff0c\u5f80\u5f80\u53ea\u4f9d\u8d56\u5386\u53f2\u622a\u56fe\u6216\u52a8\u4f5c\uff0c\u5bfc\u81f4\u96be\u4ee5\u51c6\u786e\u7406\u89e3\u590d\u6742\u6216\u8de8\u5e94\u7528\u4efb\u52a1\u7684\u72b6\u6001\uff0c\u540c\u65f6\u7f3a\u4e4f\u9ad8\u6548\u7684\u4fe1\u606f\u5b58\u50a8\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5Chain-of-Memory\uff08CoM\uff09\uff0c\u660e\u786e\u5730\u4e3aGUI\u667a\u80fd\u4f53\u5efa\u6a21\u77ed\u671f\u548c\u957f\u671f\u8bb0\u5fc6\u6a21\u5757\uff0c\u7ed3\u5408\u52a8\u4f5c\u63cf\u8ff0\u548c\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u5c4f\u5e55\u4fe1\u606f\uff0c\u901a\u8fc7\u72ec\u7acb\u7684\u8bb0\u5fc6\u6a21\u5757\u5b58\u50a8\u548c\u7ba1\u7406\u5173\u952e\u4fe1\u606f\u3002\u5f00\u53d1\u4e86GUI Odyssey-CoM\u6570\u636e\u96c6\uff08\u5305\u542b11.1\u4e07\u5bf9\u5c4f\u5e55-\u52a8\u4f5c\u6837\u672c\uff0c\u5e26\u8bb0\u5fc6\u6807\u6ce8\uff09\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u8be5\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCoM\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347GUI\u667a\u80fd\u4f53\u5728\u8de8\u5e94\u7528\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u6b64\u5916\uff0cGUI Odyssey-CoM\u6570\u636e\u96c6\u80fd\u8ba97B\u89c4\u6a21\u6a21\u578b\u8868\u73b0\u51fa\u4e0e72B\u6a21\u578b\u76f8\u8fd1\u7684\u8bb0\u5fc6\u7ba1\u7406\u80fd\u529b\u3002", "conclusion": "\u5f15\u5165\u663e\u5f0f\u8bb0\u5fc6\u5efa\u6a21\u673a\u5236\u540e\uff0cGUI\u667a\u80fd\u4f53\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u4efb\u52a1\u7406\u89e3\u548c\u5386\u53f2\u4fe1\u606f\u4fdd\u7559\u80fd\u529b\u5927\u5927\u63d0\u5347\u3002\u516c\u5f00\u6570\u636e\u96c6\u548c\u4ee3\u7801\u6709\u52a9\u4e8e\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2506.17748", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17748", "abs": "https://arxiv.org/abs/2506.17748", "authors": ["Anwoy Chatterjee", "Yash Goel", "Tanmoy Chakraborty"], "title": "HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations", "comment": null, "summary": "Contemporary Language Models (LMs), while impressively fluent, often generate\ncontent that is factually incorrect or unfaithful to the input context - a\ncritical issue commonly referred to as 'hallucination'. This tendency of LMs to\ngenerate hallucinated content undermines their reliability, especially because\nthese fabrications are often highly convincing and therefore difficult to\ndetect. While several existing methods attempt to detect hallucinations, most\nrely on analyzing multiple generations per input, leading to increased\ncomputational cost and latency. To address this, we propose a single-pass,\ntraining-free approach for effective Hallucination detectIon via Decoupled\nrEpresentations (HIDE). Our approach leverages the hypothesis that\nhallucinations result from a statistical decoupling between an LM's internal\nrepresentations of input context and its generated output. We quantify this\ndecoupling using the Hilbert-Schmidt Independence Criterion (HSIC) applied to\nhidden-state representations extracted while generating the output sequence. We\nconduct extensive experiments on four diverse question answering datasets,\nevaluating both faithfulness and factuality hallucinations across six\nopen-source LMs of varying scales and properties. Our results demonstrate that\nHIDE outperforms other single-pass methods in almost all settings, achieving an\naverage relative improvement of ~29% in AUC-ROC over the best-performing\nsingle-pass strategy across various models and datasets. Additionally, HIDE\nshows competitive and often superior performance with multi-pass\nstate-of-the-art methods, obtaining an average relative improvement of ~3% in\nAUC-ROC while consuming ~51% less computation time. Our findings highlight the\neffectiveness of exploiting internal representation decoupling in LMs for\nefficient and practical hallucination detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86HIDE\uff0c\u4e00\u79cd\u65e0\u9700\u591a\u6b21\u751f\u6210\u7684\u9ad8\u6548\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5185\u90e8\u8868\u5f81\u7684\u72ec\u7acb\u6027\u5ea6\u91cf\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u51c6\u786e\u7387\u5e76\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5bf9\u591a\u79cd\u6a21\u578b\u548c\u4efb\u52a1\u7684\u5e7f\u6cdb\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u751f\u6210\u8bed\u8a00\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5e38\u5e38\u4f1a\u4ea7\u751f\u4e0e\u4e8b\u5b9e\u6216\u8f93\u5165\u4e0a\u4e0b\u6587\u4e0d\u76f8\u7b26\u7684\u5185\u5bb9\uff0c\u5373\u201c\u5e7b\u89c9\u201d\u95ee\u9898\uff0c\u8fd9\u6781\u5927\u5f71\u54cd\u4e86\u5176\u53ef\u9760\u6027\u3002\u73b0\u6709\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u5927\u591a\u9700\u8981\u5bf9\u4e00\u4e2a\u8f93\u5165\u591a\u6b21\u751f\u6210\u5185\u5bb9\uff0c\u5bfc\u81f4\u9ad8\u6602\u7684\u8ba1\u7b97\u4ee3\u4ef7\u548c\u5ef6\u8fdf\u3002\u56e0\u6b64\uff0c\u6025\u9700\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5355\u6b21\u63a8\u7406\u3001\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u540d\u4e3aHIDE\uff08Hallucination detectIon via Decoupled rEpresentations\uff09\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u8fd9\u6837\u4e00\u4e2a\u5047\u8bbe\uff1a\u5e7b\u89c9\u5185\u5bb9\u7684\u4ea7\u751f\u6e90\u81ea\u4e8e\u6a21\u578b\u5bf9\u8f93\u5165\u4e0a\u4e0b\u6587\u4e0e\u751f\u6210\u8f93\u51fa\u7684\u5185\u90e8\u8868\u5f81\u4e4b\u95f4\u5b58\u5728\u7edf\u8ba1\u4e0a\u7684\u5206\u79bb\u3002\u5177\u4f53\u505a\u6cd5\u662f\u5229\u7528Hilbert-Schmidt Independence Criterion\uff08HSIC\uff09\uff0c\u5bf9\u751f\u6210\u8fc7\u7a0b\u4e2d\u63d0\u53d6\u7684\u9690\u85cf\u6001\u8fdb\u884c\u72ec\u7acb\u6027\u91cf\u5316\u5206\u6790\uff0c\u5224\u5b9a\u662f\u5426\u5b58\u5728\u5e7b\u89c9\u3002", "result": "\u5728\u56db\u4e2a\u591a\u6837\u5316\u95ee\u7b54\u6570\u636e\u96c6\u548c\u516d\u4e2a\u4e0d\u540c\u7279\u6027\u7684\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u6d89\u53ca\u4e8b\u5b9e\u6027\u548c\u5fe0\u5b9e\u6027\u5e7b\u89c9\u68c0\u6d4b\u3002\u5b9e\u9a8c\u8868\u660e\uff0cHIDE\u65b9\u6cd5\u51e0\u4e4e\u5728\u6240\u6709\u8bbe\u7f6e\u4e0b\u90fd\u4f18\u4e8e\u5176\u5b83\u5355\u6b21\u65b9\u6cd5\uff0cAUC-ROC\u6307\u6807\u5e73\u5747\u76f8\u5bf9\u63d0\u5347\u7ea629%\uff1b\u540c\u65f6\u4e0e\u591a\u6b21\u7b56\u7565\u7684SOTA\u65b9\u6cd5\u76f8\u6bd4\uff0cHIDE\u5728\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u7ea651%\u7684\u524d\u63d0\u4e0b\uff0c\u4ecd\u83b7\u5f97\u4e86AUC-ROC\u5e73\u5747\u7ea63%\u7684\u63d0\u5347\u6216\u6301\u5e73\u3002", "conclusion": "HIDE\u65b9\u6cd5\u80fd\u6709\u6548\u5229\u7528\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u8868\u5f81\u7684\u89e3\u8026\u7279\u6027\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u5e7b\u89c9\u68c0\u6d4b\uff0c\u5728\u51c6\u786e\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u76ee\u524d\u4e3b\u6d41\u65b9\u6848\u3002"}}
{"id": "2506.18183", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18183", "abs": "https://arxiv.org/abs/2506.18183", "authors": ["Zhiting Mei", "Christina Zhang", "Tenny Yin", "Justin Lidard", "Ola Shorinwa", "Anirudha Majumdar"], "title": "Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?", "comment": null, "summary": "Reasoning language models have set state-of-the-art (SOTA) records on many\nchallenging benchmarks, enabled by multi-step reasoning induced using\nreinforcement learning. However, like previous language models, reasoning\nmodels are prone to generating confident, plausible responses that are\nincorrect (hallucinations). Knowing when and how much to trust these models is\ncritical to the safe deployment of reasoning models in real-world applications.\nTo this end, we explore uncertainty quantification of reasoning models in this\nwork. Specifically, we ask three fundamental questions: First, are reasoning\nmodels well-calibrated? Second, does deeper reasoning improve model\ncalibration? Finally, inspired by humans' innate ability to double-check their\nthought processes to verify the validity of their answers and their confidence,\nwe ask: can reasoning models improve their calibration by explicitly reasoning\nabout their chain-of-thought traces? We introduce introspective uncertainty\nquantification (UQ) to explore this direction. In extensive evaluations on SOTA\nreasoning models across a broad range of benchmarks, we find that reasoning\nmodels: (i) are typically overconfident, with self-verbalized confidence\nestimates often greater than 85% particularly for incorrect responses, (ii)\nbecome even more overconfident with deeper reasoning, and (iii) can become\nbetter calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not\nuniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we\nconclude with important research directions to design necessary UQ benchmarks\nand improve the calibration of reasoning models.", "AI": {"tldr": "\u63a8\u7406\u5927\u6a21\u578b\u867d\u7136\u6210\u7ee9\u7a81\u51fa\uff0c\u4f46\u5e38\u5e38\u5bf9\u9519\u8bef\u7b54\u6848\u8868\u73b0\u51fa\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u901a\u8fc7\u8ba9\u6a21\u578b\u81ea\u7701\u5176\u63a8\u7406\u8fc7\u7a0b\uff0c\u53ef\u5728\u90e8\u5206\u60c5\u51b5\u4e0b\u6539\u5584\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff0c\u4f46\u8be5\u65b9\u6cd5\u5e76\u4e0d\u9002\u7528\u4e8e\u6240\u6709\u6a21\u578b\u3002\u672a\u6765\u9700\u4e13\u6ce8\u4e8e\u66f4\u5408\u7406\u7684\u6821\u51c6\u7b97\u6cd5\u4e0e\u8bc4\u4ef7\u57fa\u51c6\u7684\u8bbe\u8ba1\u3002", "motivation": "\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u591a\u4e2a\u9ad8\u96be\u5ea6\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5237\u65b0\u4e86\u6210\u7ee9\uff0c\u4f46\u5176\u8f93\u51fa\u4f9d\u65e7\u5b58\u5728\u81ea\u4fe1\u4f46\u9519\u8bef\u7684\u60c5\u51b5\uff08\u5e7b\u89c9\uff09\uff0c\u56e0\u6b64\u5728\u5b9e\u9645\u90e8\u7f72\u65f6\u5982\u4f55\u8861\u91cf\u4e0e\u4fe1\u4efb\u8fd9\u4e9b\u6a21\u578b\u6210\u4e3a\u5173\u952e\u3002\u672c\u6587\u5173\u6ce8\u63a8\u7406\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u8fd9\u4e00\u73b0\u5b9e\u9700\u6c42\u3002", "method": "\u672c\u6587\u4e3b\u8981\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u81ea\u7701\u5f0f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u65b9\u6cd5\uff0c\u5e76\u56f4\u7ed5\u63a8\u7406\u6a21\u578b\u6821\u51c6\u5c55\u5f00\u4e09\u65b9\u9762\u63a2\u7d22\uff1a\u6a21\u578b\u6821\u51c6\u73b0\u72b6\u3001\u63a8\u7406\u6df1\u5ea6\u4e0e\u6a21\u578b\u6821\u51c6\u5173\u7cfb\uff0c\u53ca\u901a\u8fc7\u53cd\u601d\u81ea\u8eab\u63a8\u7406\u8fc7\u7a0b\u63d0\u5347\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u3002\u5b9e\u9a8c\u8bc4\u4f30\u6db5\u76d6\u591a\u79cd\u4e3b\u6d41\u63a8\u7406\u6a21\u578b\u4e0e\u591a\u9879\u57fa\u51c6\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff1a1\uff09\u63a8\u7406\u6a21\u578b\u666e\u904d\u8fc7\u4e8e\u81ea\u4fe1\uff0c\u5c24\u5176\u662f\u5728\u9519\u8bef\u56de\u7b54\u65f6\uff0c\u7f6e\u4fe1\u5ea6\u5e38\u9ad8\u4e8e85%\uff1b2\uff09\u63a8\u7406\u6df1\u5ea6\u52a0\u5927\u65f6\uff0c\u8fc7\u5ea6\u81ea\u4fe1\u73b0\u8c61\u66f4\u7a81\u51fa\uff1b3\uff09\u90e8\u5206\u6a21\u578b\uff08\u5982o3-Mini\u548cDeepSeek R1\uff09\u901a\u8fc7\u81ea\u7701\u6027\u94fe\u5f0f\u63a8\u7406\u53ef\u6539\u5584\u6821\u51c6\uff0c\u4f46\u4e5f\u6709\u6a21\u578b\uff08\u5982Claude 3.7 Sonnet\uff09\u8868\u73b0\u66f4\u5dee\u3002", "conclusion": "\u5f53\u524d\u63a8\u7406\u6a21\u578b\u5b58\u5728\u4e25\u91cd\u7684\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\uff0c\u6821\u51c6\u80fd\u529b\u6709\u9650\u3002\u81ea\u7701\u5f0f\u63a8\u7406\u53ef\u63d0\u5347\u90e8\u5206\u6a21\u578b\u7684\u6821\u51c6\u6548\u679c\uff0c\u4f46\u6548\u679c\u5e76\u975e\u666e\u9002\u3002\u672a\u6765\u5e94\u8bbe\u8ba1\u66f4\u5b8c\u5584\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u57fa\u51c6\uff0c\u5e76\u8fdb\u4e00\u6b65\u63d0\u5347\u63a8\u7406\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u80fd\u529b\u3002"}}
{"id": "2506.17789", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17789", "abs": "https://arxiv.org/abs/2506.17789", "authors": ["N J Karthika", "Maharaj Brahma", "Rohit Saluja", "Ganesh Ramakrishnan", "Maunendra Sankar Desarkar"], "title": "Multilingual Tokenization through the Lens of Indian Languages: Challenges and Insights", "comment": null, "summary": "Tokenization plays a pivotal role in multilingual NLP. However, existing\ntokenizers are often skewed towards high-resource languages, limiting their\neffectiveness for linguistically diverse and morphologically rich languages\nsuch as those in the Indian subcontinent. This paper presents a comprehensive\nintrinsic evaluation of tokenization strategies across 17 Indian languages. We\nquantify the trade-offs between bottom-up and top-down tokenizer algorithms\n(BPE and Unigram LM), effects of vocabulary sizes, and compare strategies of\nmultilingual vocabulary construction such as joint and cluster-based training.\nWe also show that extremely low-resource languages can benefit from tokenizers\ntrained on related high-resource languages. Our study provides practical\ninsights for building more fair, efficient, and linguistically informed\ntokenizers for multilingual NLP.", "AI": {"tldr": "\u672c\u6587\u6df1\u5165\u8bc4\u4f30\u4e86\u591a\u79cd\u5206\u8bcd\u7b97\u6cd5\u5728\u5370\u5ea617\u79cd\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u591a\u8bed\u79cd\u8bcd\u8868\u4e0e\u8054\u5408\u8bad\u7ec3\u6709\u52a9\u4e8e\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u5206\u8bcd\u6548\u679c\uff0c\u4e3a\u6784\u5efa\u66f4\u516c\u5e73\u9ad8\u6548\u7684\u591a\u8bed\u8a00NLP\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u8bc1\u53c2\u8003\u3002", "motivation": "\u5f53\u524d\u591a\u8bed\u79cdNLP\u4e2d\u7684\u5206\u8bcd\u5668\u5927\u591a\u504f\u5411\u4e8e\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u5bfc\u81f4\u5bf9\u5370\u5ea6\u6b21\u5927\u9646\u7b49\u591a\u6837\u4e14\u5f62\u6001\u4e30\u5bcc\u8bed\u8a00\u7684\u5904\u7406\u6548\u679c\u4e0d\u4f73\u3002\u4f5c\u8005\u5e0c\u671b\u6539\u5584\u591a\u8bed\u8a00\u5206\u8bcd\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u516c\u5e73\u6027\u548c\u6548\u7387\u3002", "method": "\u8bba\u6587\u572817\u79cd\u5370\u5ea6\u8bed\u8a00\u4e0a\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e0d\u540c\u5206\u8bcd\u7b56\u7565\uff0c\u5305\u62ec\u81ea\u5e95\u5411\u4e0a\uff08BPE\uff09\u3001\u81ea\u9876\u5411\u4e0b\uff08Unigram LM\uff09\u7b97\u6cd5\u3002\u5206\u6790\u4e86\u8bcd\u8868\u89c4\u6a21\u3001\u8054\u5408\u4e0e\u805a\u7c7b\u6784\u5efa\u591a\u8bed\u79cd\u8bcd\u8868\u7b49\u7b56\u7565\u7684\u5f71\u54cd\uff0c\u5e76\u89c2\u5bdf\u4f4e\u8d44\u6e90\u8bed\u8a00\u662f\u5426\u80fd\u53d7\u76ca\u4e8e\u76f8\u5173\u9ad8\u8d44\u6e90\u8bed\u8a00\u8bad\u7ec3\u7684\u5206\u8bcd\u5668\u3002", "result": "\u6bd4\u8f83\u4e86\u4e0d\u540c\u5206\u8bcd\u65b9\u6cd5\u548c\u8bcd\u8868\u6784\u5efa\u7b56\u7565\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4f4e\u8d44\u6e90\u8bed\u8a00\u53ef\u663e\u8457\u53d7\u76ca\u4e8e\u4e0e\u5176\u76f8\u5173\u9ad8\u8d44\u6e90\u8bed\u8a00\u5171\u540c\u8bad\u7ec3\u5206\u8bcd\u5668\u3002\u63ed\u793a\u4e86\u591a\u8bed\u79cd\u591a\u6837\u6027\u73af\u5883\u4e0b\u5206\u8bcd\u6280\u672f\u53d6\u820d\u4e0e\u4f18\u5316\u7684\u5b9e\u8bc1\u89c4\u5f8b\u3002", "conclusion": "\u591a\u8bed\u8a00\u5206\u8bcd\u7cfb\u7edf\u5e94\u8003\u8651\u8bed\u8a00\u95f4\u7684\u8d44\u6e90\u4e0d\u5747\u3001\u5f62\u6001\u591a\u6837\u548c\u8054\u7cfb\u6027\u3002\u8054\u5408\u8bad\u7ec3\u3001\u5408\u9002\u7684\u5206\u8bcd\u7b56\u7565\u548c\u8bcd\u8868\u8bbe\u8ba1\u6709\u52a9\u4e8e\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u5904\u7406\u6548\u679c\uff0c\u5b9e\u73b0\u66f4\u516c\u5e73\u9ad8\u6548\u7684\u591a\u8bed\u79cdNLP\u3002"}}
{"id": "2506.18187", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.18187", "abs": "https://arxiv.org/abs/2506.18187", "authors": ["Shahriar Noroozizadeh", "Pim Welle", "Jeremy C. Weiss", "George H. Chen"], "title": "The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis", "comment": "Conference on Health, Inference, and Learning (CHIL 2025)", "summary": "This study quantifies the association between non-adherence to antipsychotic\nmedications and adverse outcomes in individuals with schizophrenia. We frame\nthe problem using survival analysis, focusing on the time to the earliest of\nseveral adverse events (early death, involuntary hospitalization, jail\nbooking). We extend standard causal inference methods (T-learner, S-learner,\nnearest neighbor matching) to utilize various survival models to estimate\nindividual and average treatment effects, where treatment corresponds to\nmedication non-adherence. Analyses are repeated using different amounts of\nlongitudinal information (3, 6, 9, and 12 months). Using data from Allegheny\nCounty in western Pennsylvania, we find strong evidence that non-adherence\nadvances adverse outcomes by approximately 1 to 4 months. Ablation studies\nconfirm that county-provided risk scores adjust for key confounders, as their\nremoval amplifies the estimated effects. Subgroup analyses by medication\nformulation (injectable vs. oral) and medication type consistently show that\nnon-adherence is associated with earlier adverse events. These findings\nhighlight the clinical importance of adherence in delaying psychiatric crises\nand show that integrating survival analysis with causal inference tools can\nyield policy-relevant insights. We caution that although we apply causal\ninference, we only make associative claims and discuss assumptions needed for\ncausal interpretation.", "AI": {"tldr": "\u4e0d\u4f9d\u4ece\u6297\u7cbe\u795e\u75c5\u836f\u7269\u4f1a\u8ba9\u7cbe\u795e\u5206\u88c2\u75c7\u60a3\u8005\u66f4\u65e9\u7ecf\u5386\u4e0d\u826f\u4e8b\u4ef6\uff08\u5982\u65e9\u901d\u3001\u4f4f\u9662\u3001\u5165\u72f1\uff09\uff0c\u63d0\u524d\u7ea61\u81f34\u4e2a\u6708\u3002\u4f9d\u4ece\u6027\u63d0\u9ad8\u80fd\u663e\u8457\u5ef6\u7f13\u5371\u673a\u53d1\u751f\uff0c\u751f\u5b58\u5206\u6790\u8054\u7528\u56e0\u679c\u63a8\u65ad\u4e3a\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u7cbe\u795e\u5206\u88c2\u75c7\u60a3\u8005\u975e\u4f9d\u4ece\u6027\u670d\u7528\u6297\u7cbe\u795e\u75c5\u836f\u7269\u53ef\u80fd\u5bfc\u81f4\u4e0d\u826f\u7ed3\u5c40\uff0c\u4f46\u5177\u4f53\u5f71\u54cd\u548c\u91cf\u5316\u8bc1\u636e\u5c1a\u4e0d\u5145\u5206\u3002\u8be5\u7814\u7a76\u65e8\u5728\u91cf\u5316\u836f\u7269\u4e0d\u4f9d\u4ece\u6027\u4e0e\u65e9\u901d\u3001\u975e\u81ea\u613f\u4f4f\u9662\u3001\u5165\u72f1\u7b49\u6076\u6027\u4e8b\u4ef6\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u5e76\u901a\u8fc7\u56e0\u679c\u63a8\u65ad\u4e0e\u751f\u5b58\u5206\u6790\u65b9\u6cd5\u63d0\u5347\u5206\u6790\u7684\u7cbe\u786e\u5ea6\u3002", "method": "\u4f7f\u7528\u751f\u5b58\u5206\u6790\u65b9\u6cd5\uff0c\u4ee5\u591a\u79cd\u751f\u5b58\u6a21\u578b\u6269\u5c55\u5e38\u7528\u7684\u56e0\u679c\u63a8\u65ad\u6280\u672f\uff08T-learner\u3001S-learner\u3001\u6700\u8fd1\u90bb\u5339\u914d\uff09\uff0c\u5206\u6790\u836f\u7269\u4e0d\u4f9d\u4ece\uff08\u89c6\u4e3a\u201c\u5904\u7406\u201d\uff09\u5bfc\u81f4\u9996\u6b21\u4e0d\u826f\u4e8b\u4ef6\u6240\u9700\u65f6\u95f4\u3002\u5b9e\u9a8c\u5bf9\u4e0d\u540c\u7eb5\u5411\u4fe1\u606f\u957f\u5ea6\uff083\u30016\u30019\u300112\u4e2a\u6708\uff09\u91cd\u590d\u5206\u6790\uff0c\u5e76\u8fdb\u884c\u836f\u7269\u79cd\u7c7b\u548c\u7ed9\u836f\u65b9\u5f0f\uff08\u6ce8\u5c04 vs. \u53e3\u670d\uff09\u4e9a\u7ec4\u5206\u6790\u3002\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u53bf\u7ea7\u98ce\u9669\u8bc4\u5206\u5bf9\u6df7\u6742\u56e0\u5b50\u7684\u6821\u6b63\u4f5c\u7528\u3002", "result": "\u5728\u5bbe\u5915\u6cd5\u5c3c\u4e9a\u5dde\u963f\u52d2\u683c\u5c3c\u53bf\u6570\u636e\u4e2d\u53d1\u73b0\uff0c\u836f\u7269\u4e0d\u4f9d\u4ece\u663e\u8457\u63d0\u524d\u7ea61\u81f34\u4e2a\u6708\u53d1\u751f\u4e0d\u826f\u4e8b\u4ef6\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\u79fb\u9664\u98ce\u9669\u8bc4\u5206\u4f1a\u653e\u5927\u8be5\u6548\u5e94\uff0c\u8868\u660e\u5176\u5bf9\u6df7\u6742\u56e0\u7d20\u6709\u91cd\u8981\u8c03\u8282\u4f5c\u7528\u3002\u4e0d\u540c\u836f\u7269\u7c7b\u578b\u4e0e\u7ed9\u836f\u65b9\u5f0f\u7684\u4e9a\u7ec4\u5206\u6790\u7ed3\u679c\u4e00\u81f4\uff0c\u4e0d\u4f9d\u4ece\u5747\u663e\u8457\u589e\u52a0\u4e0d\u826f\u7ed3\u5c40\u63d0\u524d\u53d1\u751f\u7684\u98ce\u9669\u3002", "conclusion": "\u836f\u7269\u4f9d\u4ece\u6027\u5bf9\u5ef6\u7f13\u7cbe\u795e\u5206\u88c2\u75c7\u60a3\u8005\u7cbe\u795e\u5371\u673a\u5177\u6709\u4e34\u5e8a\u610f\u4e49\u3002\u7ed3\u5408\u751f\u5b58\u5206\u6790\u548c\u56e0\u679c\u63a8\u65ad\u7684\u65b9\u6cd5\u80fd\u591f\u4e3a\u516c\u5171\u653f\u7b56\u63d0\u4f9b\u6709\u4ef7\u503c\u4fe1\u606f\uff0c\u4f46\u672c\u7814\u7a76\u5f3a\u8c03\u53ea\u80fd\u505a\u76f8\u5173\u6027\u63a8\u65ad\uff0c\u771f\u6b63\u7684\u56e0\u679c\u89e3\u91ca\u8fd8\u9700\u6ee1\u8db3\u989d\u5916\u5047\u8bbe\u3002"}}
{"id": "2506.17844", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17844", "abs": "https://arxiv.org/abs/2506.17844", "authors": ["Xin Zhang", "Qiyu Wei", "Yingjie Zhu", "Fanyi Wu", "Sophia Ananiadou"], "title": "THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction", "comment": "13 pages, 4 figures", "summary": "Automated clinical risk prediction from electronic health records (EHRs)\ndemands modeling both structured diagnostic codes and unstructured narrative\nnotes. However, most prior approaches either handle these modalities separately\nor rely on simplistic fusion strategies that ignore the directional,\nhierarchical causal interactions by which narrative observations precipitate\ndiagnoses and propagate risk across admissions. In this paper, we propose\nTHCM-CAL, a Temporal-Hierarchical Causal Model with Conformal Calibration. Our\nframework constructs a multimodal causal graph where nodes represent clinical\nentities from two modalities: Textual propositions extracted from notes and ICD\ncodes mapped to textual descriptions. Through hierarchical causal discovery,\nTHCM-CAL infers three clinically grounded interactions: intra-slice\nsame-modality sequencing, intra-slice cross-modality triggers, and inter-slice\nrisk propagation. To enhance prediction reliability, we extend conformal\nprediction to multi-label ICD coding, calibrating per-code confidence intervals\nunder complex co-occurrences. Experimental results on MIMIC-III and MIMIC-IV\ndemonstrate the superiority of THCM-CAL.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u57fa\u4e8e\u56e0\u679c\u63a8\u65ad\u5e76\u7ed3\u5408\u6821\u51c6\u673a\u5236\u7684EHR\u591a\u6a21\u6001\u98ce\u9669\u9884\u6d4b\u65b0\u65b9\u6cd5THCM-CAL\uff0c\u6709\u6548\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u7387\u548c\u53ef\u9760\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u3002", "motivation": "\u4ee5\u5f80\u5229\u7528\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHRs\uff09\u8fdb\u884c\u81ea\u52a8\u5316\u4e34\u5e8a\u98ce\u9669\u9884\u6d4b\u65f6\uff0c\u5e38\u5c06\u7ed3\u6784\u5316\u8bca\u65ad\u7f16\u7801\u548c\u975e\u7ed3\u6784\u5316\u53d9\u8ff0\u7b14\u8bb0\u5206\u5f00\u5904\u7406\uff0c\u6216\u8005\u91c7\u7528\u7b80\u5355\u7684\u878d\u5408\u7b56\u7565\uff0c\u5ffd\u7565\u4e86\u53d9\u8ff0\u6027\u89c2\u5bdf\u5982\u4f55\u5f15\u53d1\u8bca\u65ad\u5e76\u8de8\u5165\u9662\u4f20\u64ad\u98ce\u9669\u7684\u56e0\u679c\u5173\u7cfb\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u591a\u6a21\u6001\u4fe1\u606f\u878d\u5408\u7684\u590d\u6742\u56e0\u679c\u5173\u8054\u95ee\u9898\uff0c\u63d0\u5347\u9884\u6d4b\u7684\u51c6\u786e\u7387\u548c\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65f6\u5e8f-\u5c42\u6b21\u56e0\u679c\u6a21\u578b\uff08THCM-CAL\uff09\uff0c\u5e76\u7ed3\u5408\u4e00\u81f4\u6027\u6821\u51c6\uff08Conformal Calibration\uff09\u3002\u8be5\u6a21\u578b\u9996\u5148\u6784\u5efa\u5305\u542b\u6587\u672c\u547d\u9898\u548cICD\u7f16\u7801\uff08\u6620\u5c04\u4e3a\u6587\u672c\u63cf\u8ff0\uff09\u7684\u591a\u6a21\u6001\u56e0\u679c\u56fe\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u56e0\u679c\u53d1\u73b0\u63a8\u65ad\u51fa\u4e09\u7c7b\u4e34\u5e8a\u76f8\u5173\u7684\u4ea4\u4e92\uff1a\u540c\u4e00\u65f6\u95f4\u7247\u540c\u6a21\u6001\u6392\u5e8f\u3001\u540c\u4e00\u65f6\u95f4\u7247\u8de8\u6a21\u6001\u89e6\u53d1\u3001\u4e0d\u540c\u65f6\u95f4\u7247\u7684\u98ce\u9669\u4f20\u64ad\u3002\u6b64\u5916\uff0c\u6a21\u578b\u8fd8\u5c06\u4e00\u81f4\u6027\u9884\u6d4b\u65b9\u6cd5\u6269\u5c55\u5230\u591a\u6807\u7b7eICD\u7f16\u7801\uff0c\u901a\u8fc7\u590d\u6742\u5171\u73b0\u60c5\u51b5\u4e0b\u7684\u7f6e\u4fe1\u533a\u95f4\u6821\u51c6\u63d0\u5347\u9884\u6d4b\u53ef\u9760\u6027\u3002", "result": "\u5728MIMIC-III\u548cMIMIC-IV\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc1\u660e\uff0cTHCM-CAL\u5728\u81ea\u52a8\u5316\u4e34\u5e8a\u98ce\u9669\u9884\u6d4b\u65b9\u9762\uff0c\u76f8\u8f83\u4e8e\u5df2\u6709\u65b9\u6cd5\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u6027\u80fd\u548c\u66f4\u9ad8\u7684\u53ef\u9760\u6027\u3002", "conclusion": "THCM-CAL\u80fd\u591f\u6709\u6548\u523b\u753b\u548c\u5229\u7528EHR\u4e2d\u7ed3\u6784\u5316\u4e0e\u975e\u7ed3\u6784\u5316\u6570\u636e\u4e4b\u95f4\u7684\u590d\u6742\u56e0\u679c\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u4e00\u81f4\u6027\u6821\u51c6\u63d0\u5347\u4e86\u9884\u6d4b\u7684\u53ef\u63a7\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u5b9e\u9645\u4e34\u5e8a\u98ce\u9669\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.18213", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18213", "abs": "https://arxiv.org/abs/2506.18213", "authors": ["Mar\u00eda Victoria Carro", "Denise Alejandra Mester", "Francisca Gauna Selasco", "Luca Nicol\u00e1s Forziati Gangi", "Matheo Sandleris Musa", "Lola Ramos Pereyra", "Mario Leiva", "Juan Gustavo Corvalan", "Mar\u00eda Vanina Martinez", "Gerardo Simari"], "title": "A Conceptual Framework for AI Capability Evaluations", "comment": "arXiv admin note: text overlap with arXiv:2306.04181 by other authors", "summary": "As AI systems advance and integrate into society, well-designed and\ntransparent evaluations are becoming essential tools in AI governance,\ninforming decisions by providing evidence about system capabilities and risks.\nYet there remains a lack of clarity on how to perform these assessments both\ncomprehensively and reliably. To address this gap, we propose a conceptual\nframework for analyzing AI capability evaluations, offering a structured,\ndescriptive approach that systematizes the analysis of widely used methods and\nterminology without imposing new taxonomies or rigid formats. This framework\nsupports transparency, comparability, and interpretability across diverse\nevaluations. It also enables researchers to identify methodological weaknesses,\nassists practitioners in designing evaluations, and provides policymakers with\nan accessible tool to scrutinize, compare, and navigate complex evaluation\nlandscapes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684AI\u80fd\u529b\u8bc4\u4f30\u5206\u6790\u6846\u67b6\uff0c\u63d0\u5347\u4e86\u8bc4\u4f30\u7684\u900f\u660e\u5ea6\u4e0e\u53ef\u6bd4\u6027\uff0c\u4e3a\u7814\u7a76\u8005\u3001\u4ece\u4e1a\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u5e7f\u6cdb\u5e94\u7528\u4e8e\u793e\u4f1a\uff0c\u5982\u4f55\u7cfb\u7edf\u6027\u548c\u900f\u660e\u5730\u8bc4\u4f30\u5176\u80fd\u529b\u548c\u98ce\u9669\u6210\u4e3aAI\u6cbb\u7406\u7684\u91cd\u8981\u9700\u6c42\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u53ef\u9760\u7684\u7efc\u5408\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u6790AI\u80fd\u529b\u8bc4\u4f30\u7684\u6982\u5ff5\u6027\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5bf9\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u548c\u672f\u8bed\u8fdb\u884c\u7ed3\u6784\u5316\u548c\u63cf\u8ff0\u5316\u68b3\u7406\uff0c\u4e0d\u5f15\u5165\u65b0\u7684\u5206\u7c7b\u6216\u56fa\u5b9a\u683c\u5f0f\u3002", "result": "\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86AI\u80fd\u529b\u8bc4\u4f30\u7684\u900f\u660e\u5ea6\u3001\u53ef\u6bd4\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u6709\u52a9\u4e8e\u53d1\u73b0\u65b9\u6cd5\u4e0a\u7684\u4e0d\u8db3\uff0c\u6307\u5bfc\u8bc4\u4f30\u8bbe\u8ba1\uff0c\u5e76\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4fbf\u4e8e\u7406\u89e3\u548c\u6bd4\u8f83\u7684\u5de5\u5177\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u6790\u6846\u67b6\u6709\u52a9\u4e8e\u63a8\u52a8AI\u80fd\u529b\u8bc4\u4f30\u65b9\u6cd5\u7684\u89c4\u8303\u5316\uff0c\u652f\u6301\u591a\u65b9\u5728AI\u6cbb\u7406\u4e2d\u7684\u6709\u6548\u51b3\u7b56\u3002"}}
{"id": "2506.17863", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17863", "abs": "https://arxiv.org/abs/2506.17863", "authors": ["Haoran Liu", "Amir Tahmasbi", "Ehtesham Sam Haque", "Purak Jain"], "title": "LLMs for Customized Marketing Content Generation and Evaluation at Scale", "comment": "KDD LLM4ECommerce Workshop 2025", "summary": "Offsite marketing is essential in e-commerce, enabling businesses to reach\ncustomers through external platforms and drive traffic to retail websites.\nHowever, most current offsite marketing content is overly generic,\ntemplate-based, and poorly aligned with landing pages, limiting its\neffectiveness. To address these limitations, we propose MarketingFM, a\nretrieval-augmented system that integrates multiple data sources to generate\nkeyword-specific ad copy with minimal human intervention. We validate\nMarketingFM via offline human and automated evaluations and large-scale online\nA/B tests. In one experiment, keyword-focused ad copy outperformed templates,\nachieving up to 9% higher CTR, 12% more impressions, and 0.38% lower CPC,\ndemonstrating gains in ad ranking and cost efficiency. Despite these gains,\nhuman review of generated ads remains costly. To address this, we propose\nAutoEval-Main, an automated evaluation system that combines rule-based metrics\nwith LLM-as-a-Judge techniques to ensure alignment with marketing principles.\nIn experiments with large-scale human annotations, AutoEval-Main achieved\n89.57% agreement with human reviewers. Building on this, we propose\nAutoEval-Update, a cost-efficient LLM-human collaborative framework to\ndynamically refine evaluation prompts and adapt to shifting criteria with\nminimal human input. By selectively sampling representative ads for human\nreview and using a critic LLM to generate alignment reports, AutoEval-Update\nimproves evaluation consistency while reducing manual effort. Experiments show\nthe critic LLM suggests meaningful refinements, improving LLM-human agreement.\nNonetheless, human oversight remains essential for setting thresholds and\nvalidating refinements before deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u68c0\u7d22\u589e\u5f3a\u7684\u5e7f\u544a\u751f\u6210\u53ca\u81ea\u52a8\u5316\u8bc4\u6d4b\u4f53\u7cfb\uff0c\u6709\u6548\u63d0\u5347\u7535\u5546\u5e7f\u544a\u8868\u73b0\u5e76\u964d\u4f4e\u4eba\u5de5\u6210\u672c\uff0c\u4f46\u5173\u952e\u8282\u70b9\u4ecd\u9700\u4eba\u5de5\u5ba1\u67e5\u3002", "motivation": "\u5f53\u524d\u7535\u5546\u9886\u57df\u7684\u7ad9\u5916\u8425\u9500\u5185\u5bb9\u5927\u591a\u8fc7\u4e8e\u6a21\u677f\u5316\u3001\u4e0e\u843d\u5730\u9875\u5173\u8054\u6027\u5dee\uff0c\u5f71\u54cd\u8425\u9500\u6548\u679c\u3002\u5982\u4f55\u81ea\u52a8\u751f\u6210\u9ad8\u76f8\u5173\u3001\u9ad8\u6548\u7387\u7684\u5e7f\u544a\u6587\u6848\u5e76\u964d\u4f4e\u4eba\u5de5\u5ba1\u6838\u6210\u672c\uff0c\u662f\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86MarketingFM\u7cfb\u7edf\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u96c6\u6210\u591a\u6570\u636e\u6e90\uff0c\u81ea\u52a8\u751f\u6210\u4e0e\u5173\u952e\u8bcd\u9ad8\u5ea6\u5339\u914d\u7684\u5e7f\u544a\u6587\u6848\uff1b\u540c\u65f6\u63d0\u51faAutoEval-Main\u548cAutoEval-Update\u81ea\u52a8\u5316\u8bc4\u6d4b\u7cfb\u7edf\uff0c\u5229\u7528\u89c4\u5219\u4e0e\u5927\u6a21\u578b\u8bc4\u5ba1\u7ed3\u5408\uff0c\u52a8\u6001\u4f18\u5316\u8bc4\u6d4b\u6d41\u7a0b\uff0c\u964d\u4f4e\u4eba\u5de5\u5e72\u9884\u3002", "result": "\u81ea\u9002\u5e94\u751f\u6210\u7684\u5173\u952e\u8bcd\u5e7f\u544a\u6587\u6848\u76f8\u6bd4\u6a21\u677f\u5e7f\u544a\uff0c\u6700\u9ad8CTR\u63d0\u53479%\uff0c\u5c55\u73b0\u91cf\u63d0\u534712%\uff0cCPC\u4e0b\u964d0.38%\uff1b\u81ea\u52a8\u5316\u8bc4\u6d4b\u7cfb\u7edf\u4e0e\u4eba\u5de5\u6807\u6ce8\u4e00\u81f4\u6027\u8fbe89.57%\uff0c\u80fd\u591f\u52a8\u6001\u4f18\u5316\u8bc4\u6d4b\u6d41\u7a0b\uff0c\u51cf\u5c11\u4eba\u5de5\u6210\u672c\u3002", "conclusion": "\u901a\u8fc7MarketingFM\u4e0e\u81ea\u52a8\u5316\u8bc4\u6d4b\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7535\u5546\u5e7f\u544a\u6295\u653e\u7684\u76f8\u5173\u6027\u53ca\u6548\u7387\uff0c\u51cf\u5c11\u4e86\u4eba\u5de5\u5e72\u9884\uff0c\u4f46\u4eba\u5de5\u4ecd\u9700\u5728\u5173\u952e\u73af\u8282\u8fdb\u884c\u628a\u63a7\u3002"}}
{"id": "2506.18233", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18233", "abs": "https://arxiv.org/abs/2506.18233", "authors": ["Ruike Zhu", "Hanwen Zhang", "Tianyu Shi", "Chi Wang", "Tianyi Zhou", "Zengyi Qin"], "title": "The 4th Dimension for Scaling Model Size", "comment": null, "summary": "Scaling the size of large language models typically involves three\ndimensions: depth, width, and the number of parameters. In this work, we\nexplore a fourth dimension, virtual logical depth (VLD), which increases the\neffective algorithmic depth without changing the overall parameter count by\nreusing parameters within the model. Although parameter reuse is not a new\nconcept, its potential and characteristics in model scaling have not been\nthoroughly studied. Through carefully designed controlled experiments, we make\nthe following key discoveries regarding VLD scaling:\n  VLD scaling forces the knowledge capacity of the model to remain almost\nconstant, with only minor variations.\n  VLD scaling enables a significant improvement in reasoning capability,\nprovided the scaling method is properly implemented.\n  The number of parameters correlates with knowledge capacity, but not with\nreasoning capability. Under certain conditions, it is not necessary to increase\nthe parameter count to enhance reasoning.\n  These findings are consistent across various model configurations and are\nlikely to be generally valid within the scope of our experiments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u53c2\u6570\u590d\u7528\uff08\u865a\u62df\u903b\u8f91\u6df1\u5ea6VLD\uff09\u53ef\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\u800c\u65e0\u9700\u589e\u52a0\u53c2\u6570\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u666e\u9002\u6027\uff0c\u6709\u52a9\u4e8e\u4f4e\u6210\u672c\u5b9e\u73b0\u66f4\u5f3a\u6a21\u578b\u63a8\u7406\u529b\u3002", "motivation": "\u76ee\u524d\u5927\u6a21\u578b\u6269\u5c55\u4e3b\u8981\u4f9d\u8d56\u4e8e\u589e\u52a0\u6df1\u5ea6\u3001\u5bbd\u5ea6\u548c\u53c2\u6570\u6570\u91cf\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u6210\u672c\u8f83\u9ad8\uff0c\u56e0\u6b64\u5e0c\u671b\u63a2\u7d22\u65b0\u7684\u6269\u5c55\u65b9\u5f0f\u4ee5\u63d0\u5347\u6a21\u578b\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u6269\u5c55\u7ef4\u5ea6\u2014\u2014\u865a\u62df\u903b\u8f91\u6df1\u5ea6\uff08VLD\uff09\uff0c\u901a\u8fc7\u6a21\u578b\u5185\u90e8\u53c2\u6570\u590d\u7528\u6765\u589e\u52a0\u7b97\u6cd5\u6df1\u5ea6\u800c\u4e0d\u589e\u52a0\u53c2\u6570\u603b\u6570\uff0c\u5e76\u901a\u8fc7\u8bbe\u8ba1\u53d7\u63a7\u5b9e\u9a8c\u7cfb\u7edf\u5206\u6790VLD\u6269\u5c55\u7279\u70b9\u3002", "result": "\u53d1\u73b0VLD\u6269\u5c55\u4e0b\uff0c\u6a21\u578b\u77e5\u8bc6\u5bb9\u91cf\u57fa\u672c\u4e0d\u53d8\u4f46\u63a8\u7406\u80fd\u529b\u663e\u8457\u63d0\u5347\uff0c\u5e76\u4e14\u53c2\u6570\u6570\u91cf\u4e0e\u77e5\u8bc6\u5bb9\u91cf\u76f8\u5173\uff0c\u4e0e\u63a8\u7406\u80fd\u529b\u65e0\u76f4\u63a5\u5173\u7cfb\uff0c\u5408\u7406\u5229\u7528VLD\u53ef\u4ee5\u5728\u4e0d\u589e\u52a0\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "VLD\u662f\u4e00\u79cd\u6709\u6548\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\u800c\u4e0d\u9700\u589e\u52a0\u53c2\u6570\u603b\u6570\u7684\u65b0\u8def\u5f84\uff1b\u901a\u8fc7\u53c2\u6570\u590d\u7528\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e14\u8fd9\u4e9b\u7ed3\u8bba\u5728\u591a\u79cd\u6a21\u578b\u914d\u7f6e\u4e0b\u5747\u6210\u7acb\uff0c\u8868\u73b0\u51fa\u8f83\u5f3a\u7684\u666e\u9002\u6027\u3002"}}
{"id": "2506.17864", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17864", "abs": "https://arxiv.org/abs/2506.17864", "authors": ["Taolin Zhang", "Haidong Kang", "Dongyang Li", "Qizhou Chen", "Chengyu Wang Xiaofeng He", "Richang Hong"], "title": "QueueEDIT: Structural Self-Correction for Sequential Model Editing in LLMs", "comment": null, "summary": "Recently, large language models (LLMs) have demonstrated impressive results\nbut still suffer from hallucinations. Model editing has been proposed to\ncorrect factual inaccuracies in LLMs. A challenging case is sequential model\nediting (SME), which aims to rectify errors continuously rather than treating\nthem as a one-time task. During SME, the general capabilities of LLMs can be\nnegatively affected due to the introduction of new parameters. In this paper,\nwe propose a queue-based self-correction framework (QueueEDIT) that not only\nenhances SME performance by addressing long-sequence dependency but also\nmitigates the impact of parameter bias on the general capabilities of LLMs.\nSpecifically, we first introduce a structural mapping editing loss to map the\ntriplets to the knowledge-sensitive neurons within the Transformer layers of\nLLMs. We then store the located parameters for each piece of edited knowledge\nin a queue and dynamically align previously edited parameters. In each edit, we\nselect queue parameters most relevant to the currently located parameters to\ndetermine whether previous knowledge needs realignment. Irrelevant parameters\nin the queue are frozen, and we update the parameters at the queue head to the\nLLM to ensure they do not harm general abilities. Experiments show that our\nframework significantly outperforms strong baselines across various SME\nsettings and maintains competitiveness in single-turn editing. The resulting\nLLMs also preserve high capabilities in general NLP tasks throughout the SME\nprocess.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u961f\u5217\u7684\u81ea\u6211\u6821\u6b63LLM\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5QueueEDIT\uff0c\u5728\u8fde\u7eed\u591a\u8f6e\u77e5\u8bc6\u4fee\u6b63\u573a\u666f\u4e0b\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u4fee\u6b63\u80fd\u529b\uff0c\u5e76\u80fd\u7ef4\u6301\u6a21\u578b\u7684\u901a\u7528NLP\u80fd\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4ecd\u5b58\u5728\u5e7b\u89c9\uff0c\u5373\u4e8b\u5b9e\u6027\u9519\u8bef\u3002\u6a21\u578b\u7f16\u8f91\u662f\u4fee\u6b63\u8fd9\u4e9b\u9519\u8bef\u7684\u4e00\u79cd\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u9519\u8bef\u7684\u4fee\u6b63\u662f\u8fde\u7eed\u53d1\u751f\u7684\uff08\u800c\u975e\u4e00\u6b21\u6027\u4efb\u52a1\uff09\uff0c\u8fd9\u65f6\u5019\u5982\u4f55\u907f\u514d\u5bf9\u6a21\u578b\u539f\u6709\u80fd\u529b\u7684\u635f\u5bb3\u6210\u4e3a\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u961f\u5217\u7684\u81ea\u6211\u6821\u6b63\u6846\u67b6QueueEDIT\u3002\u6838\u5fc3\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u5f15\u5165\u7ed3\u6784\u6620\u5c04\u7f16\u8f91\u635f\u5931\uff0c\u5c06\u77e5\u8bc6\u4e09\u5143\u7ec4\u6620\u5c04\u5230Transformers\u5c42\u4e2d\u7684\u77e5\u8bc6\u654f\u611f\u795e\u7ecf\u5143\uff1b2\uff09\u7528\u961f\u5217\u5b58\u50a8\u6bcf\u6b21\u7f16\u8f91\u5b9a\u4f4d\u5230\u7684\u53c2\u6570\uff0c\u5e76\u52a8\u6001\u5bf9\u9f50\u8fc7\u53bb\u7f16\u8f91\u8fc7\u7684\u53c2\u6570\uff1b3\uff09\u6bcf\u6b21\u7f16\u8f91\u65f6\u9009\u53d6\u4e0e\u5f53\u524d\u53c2\u6570\u6700\u76f8\u5173\u7684\u961f\u5217\u53c2\u6570\uff0c\u5224\u65ad\u662f\u5426\u9700\u8981\u91cd\u65b0\u8c03\u6574\u4ee5\u4fdd\u8bc1\u77e5\u8bc6\u4e00\u81f4\u6027\uff1b4\uff09\u5c06\u4e0e\u5f53\u524d\u65e0\u5173\u7684\u961f\u5217\u53c2\u6570\u51bb\u7ed3\uff0c\u4ec5\u66f4\u65b0\u5bf9\u6a21\u578b\u80fd\u529b\u5f71\u54cd\u6700\u5c0f\u7684\u961f\u5217\u5934\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u7c7b\u987a\u5e8f\u6a21\u578b\u7f16\u8f91\u573a\u666f\u4e0b\uff0c\u663e\u8457\u4f18\u4e8e\u591a\u4e2a\u5f3a\u57fa\u7ebf\uff0c\u540c\u65f6\u5728\u5355\u8f6e\u7f16\u8f91\u4efb\u52a1\u4e2d\u4e5f\u5177\u7ade\u4e89\u529b\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u7f16\u8f91\u540e\u7684LLM\u5728SME\u8fc7\u7a0b\u4e2d\u4f9d\u7136\u80fd\u8f83\u597d\u5730\u4fdd\u6301\u539f\u6709NLP\u80fd\u529b\u3002", "conclusion": "QueueEDIT\u4e0d\u4ec5\u63d0\u5347\u4e86\u8fde\u7eed\u9519\u8bef\u4fee\u6b63\uff08SME\uff09\u7684\u6027\u80fd\uff0c\u8fd8\u6709\u6548\u7f13\u89e3\u4e86\u6a21\u578b\u53c2\u6570\u504f\u79fb\u5bf9\u901a\u7528\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u662f\u4e00\u79cd\u517c\u5177\u7cbe\u51c6\u6027\u548c\u9c81\u68d2\u6027\u7684\u6a21\u578b\u7f16\u8f91\u65b9\u6848\u3002"}}
{"id": "2506.18260", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18260", "abs": "https://arxiv.org/abs/2506.18260", "authors": ["FuTe Wong"], "title": "Advanced For-Loop for QML algorithm search", "comment": "7 pages, 8 figures", "summary": "This paper introduces an advanced framework leveraging Large Language\nModel-based Multi-Agent Systems (LLMMA) for the automated search and\noptimization of Quantum Machine Learning (QML) algorithms. Inspired by Google\nDeepMind's FunSearch, the proposed system works on abstract level to\niteratively generates and refines quantum transformations of classical machine\nlearning algorithms (concepts), such as the Multi-Layer Perceptron,\nforward-forward and backpropagation algorithms. As a proof of concept, this\nwork highlights the potential of agentic frameworks to systematically explore\nclassical machine learning concepts and adapt them for quantum computing,\npaving the way for efficient and automated development of QML algorithms.\nFuture directions include incorporating planning mechanisms and optimizing\nstrategy in the search space for broader applications in quantum-enhanced\nmachine learning.", "AI": {"tldr": "\u672c\u6587\u501f\u52a9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u81ea\u52a8\u5316\u63a2\u7d22\u548c\u4f18\u5316\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002\u5728\u6982\u5ff5\u9a8c\u8bc1\u4e2d\uff0c\u6210\u529f\u5c06\u90e8\u5206\u7ecf\u5178ML\u7b97\u6cd5\u8f6c\u5316\u4e3a\u91cf\u5b50\u5f62\u5f0f\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u524d\u666f\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u8ba1\u7b97\u548c\u91cf\u5b50\u673a\u5668\u5b66\u4e60\uff08QML\uff09\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u73b0\u6709\u7684QML\u7b97\u6cd5\u5927\u591a\u4f9d\u8d56\u4e8e\u4eba\u5de5\u8bbe\u8ba1\uff0c\u5f00\u53d1\u6548\u7387\u548c\u63a2\u7d22\u7a7a\u95f4\u6709\u9650\u3002\u8bba\u6587\u52a8\u673a\u5728\u4e8e\u5e0c\u671b\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u81ea\u52a8\u5316\u641c\u7d22\u548c\u4f18\u5316QML\u7b97\u6cd5\uff0c\u52a0\u5feb\u521b\u65b0\u6b65\u4f10\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08LLMMA\uff09\u6846\u67b6\uff0c\u4f7f\u591a\u4e2a\u667a\u80fd\u4f53\u80fd\u591f\u5728\u62bd\u8c61\u5c42\u9762\u5bf9\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08\u5982\u591a\u5c42\u611f\u77e5\u673a\u3001\u524d\u9988\u3001\u53cd\u5411\u4f20\u64ad\u7b49\uff09\u8fdb\u884c\u91cf\u5b50\u5316\u53d8\u6362\u7684\u81ea\u52a8\u751f\u6210\u4e0e\u8fed\u4ee3\u4f18\u5316\u3002\u8be5\u65b9\u6cd5\u501f\u9274\u4e86Google DeepMind\u7684FunSearch\u7406\u5ff5\u3002", "result": "\u901a\u8fc7\u539f\u578b\u9a8c\u8bc1\uff0c\u8bba\u6587\u5c55\u793a\u4e86LLMMA\u6846\u67b6\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u5e76\u81ea\u52a8\u5730\u5c06\u90e8\u5206\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u601d\u60f3\u9002\u914d\u5230\u91cf\u5b50\u8ba1\u7b97\u9886\u57df\uff0c\u663e\u793a\u4e86\u8be5\u65b9\u6cd5\u5728QML\u7b97\u6cd5\u5f00\u53d1\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "LLMMA\u6846\u67b6\u4e3aQML\u7b97\u6cd5\u7684\u9ad8\u6548\u548c\u81ea\u52a8\u5316\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u672a\u6765\u53ef\u5f15\u5165\u89c4\u5212\u673a\u5236\u548c\u66f4\u667a\u80fd\u7684\u641c\u7d22\u7b56\u7565\uff0c\u62d3\u5bbd\u91cf\u5b50\u589e\u5f3a\u673a\u5668\u5b66\u4e60\u7684\u5e94\u7528\u3002"}}
{"id": "2506.17871", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17871", "abs": "https://arxiv.org/abs/2506.17871", "authors": ["Chenghao Yang", "Ari Holtzman"], "title": "How Alignment Shrinks the Generative Horizon", "comment": "Codebase: https://github.com/yangalan123/LLMBranchingFactor, Website:\n  https://yangalan123.github.io/branching_factor/", "summary": "Despite their impressive capabilities, aligned large language models (LLMs)\noften generate outputs that lack diversity. What drives this stability in the\ngeneration? We investigate this phenomenon through the lens of probability\nconcentration in the model's output distribution. To quantify this\nconcentration, we introduce the Branching Factor (BF) -- a token-invariant\nmeasure of the effective number of plausible next steps during generation. Our\nempirical analysis reveals two key findings: (1) BF often decreases as\ngeneration progresses, suggesting that LLMs become more predictable as they\ngenerate. (2) alignment tuning substantially sharpens the model's output\ndistribution from the outset, reducing BF by nearly an order of magnitude\n(e.g., from 12 to 1.2) relative to base models. This stark reduction helps\nexplain why aligned models often appear less sensitive to decoding strategies.\nBuilding on this insight, we find this stability has surprising implications\nfor complex reasoning. Aligned Chain-of-Thought (CoT) models (e.g.,\nDeepSeek-distilled models), for instance, leverage this effect; by generating\nlonger reasoning chains, they push generation into later, more deterministic\n(lower BF) stages, resulting in more stable outputs. We hypothesize that\nalignment tuning does not fundamentally change a model's behavior, but instead\nsteers it toward stylistic tokens (e.g., \"Sure\") that unlock low-entropy\ntrajectories already present in the base model. This view is supported by\nnudging experiments, which show that prompting base models with such tokens can\nsimilarly reduce BF. Together, our findings establish BF as a powerful\ndiagnostic for understanding and controlling LLM outputs - clarifying how\nalignment reduces variability, how CoT promotes stable generations, and how\nbase models can be steered away from diversity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faBranching Factor\u6307\u6807\uff0c\u63ed\u793a\u4e86\u5bf9\u9f50\u5927\u6a21\u578b\u8f93\u51fa\u591a\u6837\u6027\u964d\u4f4e\u7684\u6839\u672c\u673a\u5236\uff0c\u5e76\u8868\u660e\u901a\u8fc7\u5408\u7406\u5f15\u5bfc\uff0c\u57fa\u7840\u6a21\u578b\u4e5f\u80fd\u83b7\u5f97\u66f4\u7a33\u5b9a\u7684\u8f93\u51fa\u3002", "motivation": "\u76ee\u524d\u5bf9\u9f50\u7684\u5927\u6a21\u578b\u867d\u7136\u8868\u73b0\u80fd\u529b\u5f3a\uff0c\u4f46\u751f\u6210\u5185\u5bb9\u7684\u591a\u6837\u6027\u6709\u9650\u3002\u4f5c\u8005\u5e0c\u671b\u7406\u89e3\u4e3a\u4ec0\u4e48\u5728\u5bf9\u9f50\u540eLLM\u751f\u6210\u7ed3\u679c\u4f1a\u53d8\u5f97\u66f4\u7a33\u5b9a\u3001\u7f3a\u4e4f\u591a\u6837\u6027\u3002", "method": "\u63d0\u51fa\u4e86Branching Factor\uff08BF\uff09\u6307\u6807\uff0c\u4e00\u79cd\u4e0etoken\u65e0\u5173\u7684\u91cf\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u8861\u91cf\u751f\u6210\u65f6\u4e0b\u4e00\u4e2a\u5408\u7406token\u7684\u6709\u6548\u6570\u91cf\uff0c\u5e76\u7528\u6b64\u6307\u6807\u5206\u6790\u5bf9\u9f50\u8fc7\u7a0b\u5bf9\u6a21\u578b\u8f93\u51fa\u5206\u5e03\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u5b9e\u9a8c\u7814\u7a76\u548c'\u8bf1\u5bfc'\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff1a(1) BF\u4f1a\u968f\u7740\u751f\u6210\u8fc7\u7a0b\u7684\u63a8\u8fdb\u800c\u51cf\u5c0f\uff0c\u8bf4\u660e\u6a21\u578b\u8d8a\u751f\u6210\u8f93\u51fa\u8d8a\u53ef\u9884\u6d4b\uff1b(2) \u5bf9\u9f50\u8c03\u4f18\u660e\u663e\u6536\u7f29\u8f93\u51fa\u5206\u5e03\uff0c\u4f7fBF\u5927\u5e45\u964d\u4f4e\uff08\u5982\u4ece12\u964d\u4e3a1.2\uff09\uff1b(3) \u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u901a\u8fc7\u66f4\u957f\u63a8\u7406\u94fe\u4e5f\u63a8\u52a8BF\u964d\u4f4e\uff0c\u4f7f\u8f93\u51fa\u66f4\u52a0\u7a33\u5b9a\uff1b(4) \u901a\u8fc7\u63d0\u793a\u57fa\u672c\u6a21\u578b\u7279\u5b9a\u8bcd\uff0c\u540c\u6837\u53ef\u4ee5\u964d\u4f4eBF\u3002", "conclusion": "BF\u662f\u5206\u6790\u548c\u63a7\u5236LLM\u8f93\u51fa\u7684\u6709\u529b\u5de5\u5177\u3002\u5bf9\u9f50\u8c03\u4f18\u5e76\u672a\u672c\u8d28\u6539\u53d8\u6a21\u578b\u884c\u4e3a\uff0c\u800c\u662f\u5f15\u5bfc\u5176\u504f\u597d\u98ce\u683c\u5316token\uff0c\u4ece\u800c\u6fc0\u6d3b\u4e86\u539f\u6709\u6a21\u578b\u4e2d\u4f4e\u71b5\u8def\u5f84\uff0c\u8fd9\u89e3\u91ca\u4e86\u5bf9\u9f50\u6a21\u578b\u591a\u6837\u6027\u964d\u4f4e\u7684\u539f\u56e0\u3002"}}
{"id": "2506.18348", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18348", "abs": "https://arxiv.org/abs/2506.18348", "authors": ["Weilun Yu", "Shixiang Tang", "Yonggui Huang", "Nanqing Dong", "Li Fan", "Honggang Qi", "Wei Liu", "Xiaoli Diao", "Xi Chen", "Wanli Ouyang"], "title": "Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team", "comment": null, "summary": "Scientific progress increasingly relies on effective collaboration among\nresearchers, a dynamic that large language models (LLMs) have only begun to\nemulate. While recent LLM-based scientist agents show promise in autonomous\nscientific discovery, they often lack the interactive reasoning and evaluation\nmechanisms essential to real-world research. We propose IDVSCI (Internal\nDiscussion and Vote SCIentists), a multi-agent framework built on LLMs that\nincorporates two key innovations: a Dynamic Knowledge Exchange mechanism\nenabling iterative feedback among agents, and a Dual-Diversity Review paradigm\nthat simulates heterogeneous expert evaluation. These components jointly\npromote deeper reasoning and the generation of more creative and impactful\nscientific ideas. To evaluate the effectiveness and generalizability of our\napproach, we conduct experiments on two datasets: a widely used benchmark in\ncomputer science and a new dataset we introduce in the health sciences domain.\nResults show that IDVSCI consistently achieves the best performance across both\ndatasets, outperforming existing systems such as AI Scientist and VIRSCI. These\nfindings highlight the value of modeling interaction and peer review dynamics\nin LLM-based autonomous research.", "AI": {"tldr": "IDVSCI\u6846\u67b6\u901a\u8fc7\u52a0\u5165\u5185\u90e8\u8ba8\u8bba\u4e0e\u6295\u7968\u3001\u53cc\u91cd\u591a\u6837\u6027\u8bc4\u5ba1\u673a\u5236\uff0c\u6709\u6548\u589e\u5f3a\u4e86LLM\u79d1\u5b66\u5bb6\u4ee3\u7406\u7684\u63a8\u7406\u548c\u521b\u65b0\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u9886\u57df\u8868\u73b0\u4f18\u8d8a\uff0c\u8868\u660e\u201c\u4e92\u52a8\u4e0e\u8bc4\u8bae\u201d\u673a\u5236\u5728\u81ea\u4e3b\u79d1\u7814\u4e2d\u6709\u91cd\u8981\u4ef7\u503c\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u79d1\u5b66\u5bb6\u4ee3\u7406\u5728\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u65b9\u9762\u53d6\u5f97\u4e86\u4e00\u5b9a\u8fdb\u5c55\uff0c\u4f46\u7f3a\u4e4f\u771f\u5b9e\u79d1\u7814\u6d3b\u52a8\u4e2d\u5fc5\u9700\u7684\u4ea4\u4e92\u63a8\u7406\u548c\u8bc4\u4f30\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86IDVSCI\uff08Internal Discussion and Vote SCIentists\uff09\u6846\u67b6\uff0c\u5305\u62ec\u52a8\u6001\u77e5\u8bc6\u4ea4\u6d41\u673a\u5236\u548c\u53cc\u91cd\u591a\u6837\u6027\u8bc4\u5ba1\u8303\u5f0f\uff0c\u652f\u6301\u4ee3\u7406\u95f4\u7684\u53cd\u9988\u548c\u5f02\u8d28\u6027\u4e13\u5bb6\u8bc4\u5ba1\u3002", "result": "\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u5e7f\u6cdb\u5e94\u7528\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4ee5\u53ca\u65b0\u5f15\u5165\u7684\u5065\u5eb7\u79d1\u5b66\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0cIDVSCI\u5728\u4e24\u8005\u4e0a\u5747\u53d6\u5f97\u4e86\u6700\u4f73\u8868\u73b0\uff0c\u4f18\u4e8eAI Scientist\u548cVIRSCI\u7b49\u73b0\u6709\u7cfb\u7edf\u3002", "conclusion": "\u901a\u8fc7\u6a21\u62df\u4eba\u4e0e\u4eba\u4e4b\u95f4\u4e92\u52a8\u548c\u540c\u884c\u8bc4\u8bae\u8fc7\u7a0b\uff0cIDVSCI\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u81ea\u4e3b\u79d1\u7814\u4e2d\u7684\u63a8\u7406\u6df1\u5ea6\u548c\u521b\u65b0\u80fd\u529b\u3002"}}
{"id": "2506.17881", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17881", "abs": "https://arxiv.org/abs/2506.17881", "authors": ["Hua Tang", "Lingyong Yan", "Yukun Zhao", "Shuaiqiang Wang", "Jizhou Huang", "Dawei Yin"], "title": "Multi-turn Jailbreaking via Global Refinement and Active Fabrication", "comment": null, "summary": "Large Language Models (LLMs) have achieved exceptional performance across a\nwide range of tasks. However, they still pose significant safety risks due to\nthe potential misuse for malicious purposes. Jailbreaks, which aim to elicit\nmodels to generate harmful content, play a critical role in identifying the\nunderlying security threats. Recent jailbreaking primarily focuses on\nsingle-turn scenarios, while the more complicated multi-turn scenarios remain\nunderexplored. Moreover, existing multi-turn jailbreaking techniques struggle\nto adapt to the evolving dynamics of dialogue as the interaction progresses. To\naddress this limitation, we propose a novel multi-turn jailbreaking method that\nrefines the jailbreaking path globally at each interaction. We also actively\nfabricate model responses to suppress safety-related warnings, thereby\nincreasing the likelihood of eliciting harmful outputs in subsequent questions.\nExperimental results demonstrate the superior performance of our method\ncompared with existing single-turn and multi-turn jailbreaking techniques\nacross six state-of-the-art LLMs. Our code is publicly available at\nhttps://github.com/Ytang520/Multi-Turn_jailbreaking_Global-Refinment_and_Active-Fabrication.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u8f6e\u4ea4\u4e92\u573a\u666f\u4e0b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u72f1\u95ee\u9898\uff0c\u63d0\u51fa\u5168\u5c40\u8def\u5f84\u4f18\u5316\u548c\u4e3b\u52a8\u4f2a\u9020\u56de\u590d\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u4e3b\u6d41\u6a21\u578b\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u8d8a\u72f1\u6210\u529f\u7387\uff0c\u63ed\u793aLLM\u7684\u8fdb\u4e00\u6b65\u5b89\u5168\u9690\u60a3\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u4ecd\u5b58\u5728\u56e0\u88ab\u6076\u610f\u5229\u7528\u800c\u5bfc\u81f4\u7684\u5b89\u5168\u9690\u60a3\u3002\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u8f6e\u5bf9\u8bdd\u7684\u201c\u8d8a\u72f1\u201d\u624b\u6cd5\uff0c\u800c\u591a\u8f6e\u590d\u6742\u4ea4\u4e92\u60c5\u5883\u4e0b\u7684\u5b89\u5168\u98ce\u9669\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u8f6e\u8d8a\u72f1\u65b9\u6cd5\uff0c\u5728\u6bcf\u8f6e\u4ea4\u4e92\u4e2d\u5bf9\u8d8a\u72f1\u8def\u5f84\u8fdb\u884c\u5168\u5c40\u6539\u8fdb\uff1b\u540c\u65f6\u4e3b\u52a8\u4f2a\u9020\u6a21\u578b\u56de\u590d\u4ee5\u6291\u5236\u5b89\u5168\u8b66\u544a\uff0c\u8fdb\u800c\u63d0\u9ad8\u540e\u7eed\u8f93\u51fa\u6709\u5bb3\u5185\u5bb9\u7684\u6982\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u516d\u4e2a\u4e3b\u6d41LLM\u4e0a\u76f8\u8f83\u4e8e\u73b0\u6709\u5355\u8f6e\u548c\u591a\u8f6e\u8d8a\u72f1\u6280\u672f\u8868\u73b0\u66f4\u4e3a\u4f18\u8d8a\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u591a\u8f6e\u8d8a\u72f1\u65b9\u6cd5\u80fd\u591f\u66f4\u6709\u6548\u5730\u4fc3\u4f7f\u6a21\u578b\u8f93\u51fa\u6709\u5bb3\u5185\u5bb9\uff0c\u7a81\u663e\u4e86\u5f53\u524dLLM\u5728\u591a\u8f6e\u4ea4\u4e92\u5b89\u5168\u65b9\u9762\u5b58\u5728\u7684\u98ce\u9669\u548c\u6311\u6218\u3002"}}
{"id": "2506.18424", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.18424", "abs": "https://arxiv.org/abs/2506.18424", "authors": ["Chengjie Liu", "Weiyu Chen", "Huiyao Xu", "Yuan Du", "Jun Yang", "Li Du"], "title": "A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction", "comment": "Accepted by ISEDA 2025", "summary": "In the design process of the analog circuit pre-layout phase, device sizing\nis an important step in determining whether an analog circuit can meet the\nrequired performance metrics. Many existing techniques extract the circuit\nsizing task as a mathematical optimization problem to solve and continuously\nimprove the optimization efficiency from a mathematical perspective. But they\nignore the automatic introduction of prior knowledge, fail to achieve effective\npruning of the search space, which thereby leads to a considerable compression\nmargin remaining in the search space. To alleviate this problem, we propose a\nlarge language model (LLM)-based multi-agent framework for analog circuits'\nsizing relationships extraction from academic papers. The search space in the\nsizing process can be effectively pruned based on the sizing relationship\nextracted by this framework. Eventually, we conducted tests on 3 types of\ncircuits, and the optimization efficiency was improved by $2.32 \\sim 26.6\n\\times$. This work demonstrates that the LLM can effectively prune the search\nspace for analog circuit sizing, providing a new solution for the combination\nof LLMs and conventional analog circuit design automation methods.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4ece\u6587\u732e\u4e2d\u62bd\u53d6\u5c3a\u5bf8\u5173\u7cfb\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u526a\u679d\u8bbe\u8ba1\u641c\u7d22\u7a7a\u95f4\uff0c\u5728\u4e09\u7c7b\u7535\u8def\u4e0a\u663e\u8457\u63d0\u5347\u4f18\u5316\u6548\u7387\u3002\u8fd9\u4e3a\u81ea\u52a8\u5316\u7c7b\u6bd4\u7535\u8def\u8bbe\u8ba1\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002", "motivation": "\u76ee\u524d\u7c7b\u6bd4\u7535\u8def\u5668\u4ef6\u5c3a\u5bf8\u8bbe\u8ba1\u9636\u6bb5\uff0c\u867d\u7136\u666e\u904d\u91c7\u7528\u6570\u5b66\u4f18\u5316\u65b9\u6cd5\u63d0\u5347\u4f18\u5316\u6548\u7387\uff0c\u4f46\u5f80\u5f80\u5ffd\u7565\u4e86\u5982\u4f55\u81ea\u52a8\u5f15\u5165\u5148\u9a8c\u77e5\u8bc6\uff0c\u6709\u6548\u538b\u7f29\uff08\u526a\u679d\uff09\u641c\u7d22\u7a7a\u95f4\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u641c\u7d22\u7a7a\u95f4\u7684\u538b\u7f29\u4e0a\u4ecd\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u6765\u4ece\u5b66\u672f\u8bba\u6587\u4e2d\u81ea\u52a8\u62bd\u53d6\u7c7b\u6bd4\u7535\u8def\u7684\u5c3a\u5bf8\u5173\u7cfb\uff0c\u901a\u8fc7\u8fd9\u4e9b\u62bd\u53d6\u7684\u5173\u7cfb\u5bf9\u5c3a\u5bf8\u4f18\u5316\u7684\u641c\u7d22\u7a7a\u95f4\u8fdb\u884c\u6709\u6548\u526a\u679d\u3002", "result": "\u8be5\u6846\u67b6\u5728\u4e09\u7c7b\u7535\u8def\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e862.32\u81f326.6\u500d\u7684\u4f18\u5316\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86LLM\u80fd\u591f\u6709\u6548\u526a\u679d\u7c7b\u6bd4\u7535\u8def\u5c3a\u5bf8\u8bbe\u8ba1\u641c\u7d22\u7a7a\u95f4\uff0c\u4e3aLLM\u4e0e\u4f20\u7edf\u7c7b\u6bd4\u7535\u8def\u8bbe\u8ba1\u81ea\u52a8\u5316\u65b9\u6cd5\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.17949", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17949", "abs": "https://arxiv.org/abs/2506.17949", "authors": ["Hong Su"], "title": "Scatter-Based Innovation Propagation in Large Language Models for Multi-Stage Process Adaptation", "comment": null, "summary": "Large Language Models (LLMs) exhibit strong capabilities in reproducing and\nextending patterns observed during pretraining but often struggle to generalize\nnovel ideas beyond their original context. This paper addresses the challenge\nof applying such localized innovations - introduced at a specific stage or\ncomponent - to other parts of a multi-stage process. We propose a scatter-based\ninnovation expansion model (innovation scatter model) that guides the LLM\nthrough a four-step process: (1) identifying the core innovation by comparing\nthe user's input with its surrounding context, (2) generalizing the innovation\nby removing references to specific stages or components, (3) determining\nwhether the generalized innovation applies to a broader scope beyond the\noriginal stage, and (4) systematically applying it to other structurally\nsimilar stages using the LLM. This model leverages structural redundancy across\nstages to improve the applicability of novel ideas. Verification results\ndemonstrate that the innovation scatter model enables LLMs to extend\ninnovations across structurally similar stages, thereby enhancing\ngeneralization and reuse.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u521b\u65b0\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6b65\u9aa4\u5e2e\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u5c40\u90e8\u521b\u65b0\u6709\u6548\u63a8\u5e7f\u81f3\u591a\u9636\u6bb5\u6d41\u7a0b\u4e2d\u7684\u5176\u4ed6\u90e8\u5206\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u5176\u6cdb\u5316\u4e0e\u590d\u7528\u80fd\u529b\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u867d\u7136\u80fd\u591f\u590d\u73b0\u548c\u5ef6\u5c55\u9884\u8bad\u7ec3\u65f6\u5b66\u5230\u7684\u6a21\u5f0f\uff0c\u4f46\u9762\u5bf9\u5c06\u67d0\u4e00\u521b\u65b0\u601d\u60f3\u63a8\u5e7f\u5230\u4e0d\u540c\u4e0a\u4e0b\u6587\u9636\u6bb5\u7684\u4efb\u52a1\u65f6\uff0c\u7ecf\u5e38\u8868\u73b0\u4e0d\u4f73\u3002\u672c\u6587\u805a\u7126\u4e8e\u5982\u4f55\u5c06\u5c40\u90e8\u65b0\u9896\u601d\u60f3\u5e94\u7528\u4e8e\u591a\u9636\u6bb5\u6d41\u7a0b\u4e2d\u5176\u4ed6\u90e8\u5206\uff0c\u63d0\u5347\u5176\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u521b\u65b0\u6269\u6563\u6a21\u578b\uff08innovation scatter model\uff09\uff0c\u901a\u8fc7\u56db\u6b65\u6d41\u7a0b\u6307\u5bfcLLM\uff1a1\uff09\u5bf9\u6bd4\u7528\u6237\u8f93\u5165\u4e0e\u73af\u5883\u4e0a\u4e0b\u6587\uff0c\u8bc6\u522b\u6838\u5fc3\u521b\u65b0\uff1b2\uff09\u53bb\u9664\u7279\u5b9a\u9636\u6bb5\u6216\u7ec4\u4ef6\u6307\u6d89\uff0c\u5b9e\u73b0\u521b\u65b0\u601d\u60f3\u6cdb\u5316\uff1b3\uff09\u5224\u65ad\u8be5\u6cdb\u5316\u601d\u60f3\u80fd\u5426\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u8303\u56f4\uff1b4\uff09\u501f\u52a9LLM\u7cfb\u7edf\u6027\u5730\u6269\u5c55\u5230\u5176\u4ed6\u5177\u6709\u7ed3\u6784\u76f8\u4f3c\u6027\u7684\u9636\u6bb5\u3002\u8be5\u6a21\u578b\u4e3b\u8981\u5229\u7528\u5404\u9636\u6bb5\u7684\u7ed3\u6784\u5197\u4f59\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e00\u521b\u65b0\u6269\u6563\u6a21\u578b\u80fd\u6709\u6548\u5e2e\u52a9LLM\u5c06\u65b0\u601d\u60f3\u63a8\u5e7f\u81f3\u5176\u4ed6\u7ed3\u6784\u76f8\u4f3c\u9636\u6bb5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u4e0e\u91cd\u7528\u80fd\u529b\u3002", "conclusion": "\u521b\u65b0\u6269\u6563\u6a21\u578b\u53ef\u589e\u5f3aLLM\u63a8\u5e7f\u548c\u590d\u7528\u5c40\u90e8\u521b\u65b0\u601d\u60f3\u7684\u80fd\u529b\uff0c\u4f7f\u5176\u5728\u591a\u9636\u6bb5\u6d41\u7a0b\u4e2d\u7684\u6cdb\u5316\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2506.18428", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.18428", "abs": "https://arxiv.org/abs/2506.18428", "authors": ["Feng He", "Zhenyang Liu", "Marco Valentino", "Zhixue Zhao"], "title": "How Robust is Model Editing after Fine-Tuning? An Empirical Study on Text-to-Image Diffusion Models", "comment": null, "summary": "Model editing offers a low-cost technique to inject or correct a particular\nbehavior in a pre-trained model without extensive retraining, supporting\napplications such as factual correction and bias mitigation. Despite this\ncommon practice, it remains unknown whether edits persist after fine-tuning or\nwhether they are inadvertently reversed. This question has fundamental\npractical implications. For example, if fine-tuning removes prior edits, it\ncould serve as a defence mechanism against hidden malicious edits. Vice versa,\nthe unintended removal of edits related to bias mitigation could pose serious\nsafety concerns. We systematically investigate the interaction between model\nediting and fine-tuning in the context of T2I diffusion models, which are known\nto exhibit biases and generate inappropriate content. Our study spans two T2I\nmodel families (Stable Diffusion and FLUX), two sota editing techniques, and\nthree fine-tuning methods (DreamBooth, LoRA, and DoRA). Through an extensive\nempirical analysis across diverse editing tasks and evaluation metrics, our\nfindings reveal a trend: edits generally fail to persist through fine-tuning,\neven when fine-tuning is tangential or unrelated to the edits. Notably, we\nobserve that DoRA exhibits the strongest edit reversal effect. At the same\ntime, among editing methods, UCE demonstrates greater robustness, retaining\nsignificantly higher efficacy post-fine-tuning compared to ReFACT. These\nfindings highlight a crucial limitation in current editing methodologies,\nemphasizing the need for more robust techniques to ensure reliable long-term\ncontrol and alignment of deployed AI systems. These findings have dual\nimplications for AI safety: they suggest that fine-tuning could serve as a\nremediation mechanism for malicious edits while simultaneously highlighting the\nneed for re-editing after fine-tuning to maintain beneficial safety and\nalignment properties.", "AI": {"tldr": "T2I\u6269\u6563\u6a21\u578b\u4e2d\u7684\u6a21\u578b\u7f16\u8f91\u5f88\u5bb9\u6613\u5728\u540e\u7eed\u5fae\u8c03\u4e2d\u5931\u6548\uff0c\u5c24\u5176\u662f\u7279\u5b9a\u5fae\u8c03\u65b9\u5f0f\u3002\u5b89\u5168\u5e94\u7528\u4e2d\u5fae\u8c03\u65e2\u53ef\u79fb\u9664\u6076\u610f\u7f16\u8f91\uff0c\u8fd8\u4f1a\u4e22\u5931\u6709\u76ca\u6539\u52a8\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u7f16\u8f91\u6280\u672f\u6216\u91cd\u65b0\u7f16\u8f91\u64cd\u4f5c\u3002", "motivation": "\u4f5c\u8005\u5173\u6ce8\u4e8e\u5728\u5927\u6a21\u578b\u9884\u8bad\u7ec3\u540e\u8fdb\u884c\u6a21\u578b\u7f16\u8f91\uff0c\u4ee5\u4fbf\u4f4e\u6210\u672c\u5730\u4fee\u6b63\u6216\u6ce8\u5165\u7279\u5b9a\u884c\u4e3a\uff08\u5982\u4e8b\u5b9e\u7ea0\u9519\u3001\u504f\u89c1\u7f13\u89e3\uff09\uff0c\u4f46\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u7f16\u8f91\u5728\u540e\u7eed\u5fae\u8c03\u540e\u80fd\u5426\u4fdd\u7559\u6216\u88ab\u9006\u8f6c\u3002\u8be5\u95ee\u9898\u5bf9\u4e8e\u6a21\u578b\u5b89\u5168\u548c\u957f\u671f\u884c\u4e3a\u63a7\u5236\u6709\u91cd\u8981\u5f71\u54cd\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u6a21\u578b\u7f16\u8f91\u4e0e\u5fae\u8c03\u5728\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\uff08T2I diffusion models\uff09\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u7814\u7a76\u5185\u5bb9\u6db5\u76d6\u4e24\u79cd\u6a21\u578b\uff08Stable Diffusion\u548cFLUX\uff09\u3001\u4e24\u79cd\u4e3b\u6d41\u7f16\u8f91\u6280\u672f\u3001\u4e09\u79cd\u5fae\u8c03\u65b9\u6cd5\uff08DreamBooth\u3001LoRA\u548cDoRA\uff09\uff0c\u901a\u8fc7\u591a\u6837\u5316\u7f16\u8f91\u4efb\u52a1\u548c\u8bc4\u4f30\u6307\u6807\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u5927\u90e8\u5206\u7f16\u8f91\u5728\u540e\u7eed\u5fae\u8c03\u540e\u65e0\u6cd5\u4fdd\u7559\uff0c\u54ea\u6015\u5fae\u8c03\u5185\u5bb9\u4e0e\u7f16\u8f91\u70b9\u65e0\u5173\u3002DoRA\u5fae\u8c03\u6cd5\u6700\u6613\u5bfc\u81f4\u7f16\u8f91\u5931\u6548\u3002\u7f16\u8f91\u65b9\u6cd5\u4e2d\uff0cUCE\u65b9\u6cd5\u8f83\u4e3a\u7a33\u5b9a\uff0c\u5bf9\u6bd4ReFACT\u5728\u5fae\u8c03\u540e\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u5f53\u524d\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u5728\u957f\u671f\u63a7\u5236\u548c\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u4e0d\u8db3\u3002\u5fae\u8c03\u8fc7\u7a0b\u65e2\u53ef\u79fb\u9664\u6076\u610f\u7f16\u8f91\uff0c\u4f46\u4e5f\u53ef\u80fd\u6d88\u9664\u6709\u76ca\u7684\u5b89\u5168\u8c03\u6574\uff0c\u56e0\u6b64\u5b9e\u9645\u5e94\u7528\u9700\u52a0\u5f3a\u7f16\u8f91\u9c81\u68d2\u6027\uff0c\u6216\u5728\u5fae\u8c03\u540e\u91cd\u65b0\u7f16\u8f91\u4ee5\u4fdd\u8bc1\u6548\u679c\u3002"}}
{"id": "2506.17951", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17951", "abs": "https://arxiv.org/abs/2506.17951", "authors": ["Quanwei Tang", "Sophia Yat Mei Lee", "Junshuang Wu", "Dong Zhang", "Shoushan Li", "Erik Cambria", "Guodong Zhou"], "title": "A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment", "comment": "acl 2025 findings", "summary": "Recent advancements in retrieval-augmented generation (RAG) have enhanced\nlarge language models in question answering by integrating external knowledge.\nHowever, challenges persist in achieving global understanding and aligning\nresponses with human ethical and quality preferences. To address these issues,\nwe propose GraphMPA, a comprehensive graph-based framework with mode-seeking\npreference alignment. Our approach constructs a hierarchical document graph\nusing a general similarity measurement, mimicking human cognitive processes for\ninformation understanding and synthesis. Additionally, we introduce\nmode-seeking preference optimization to better align model outputs with human\npreferences through probability-matching constraints. Extensive experiments on\nsix datasets demonstrate the effectiveness of our\n\\href{https://github.com/tangquanwei/GraphMPA}{GraphMPA}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86GraphMPA\uff0c\u901a\u8fc7\u56fe\u7ed3\u6784\u4fe1\u606f\u7406\u89e3\u548c\u6a21\u5f0f\u5bfb\u4f18\u5bf9\u9f50\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86RAG\u7cfb\u7edf\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u6574\u4f53\u7406\u89e3\u529b\u53ca\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5951\u5408\u5ea6\u3002", "motivation": "\u5c3d\u7ba1\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\u5728\u95ee\u7b54\u7cfb\u7edf\u4e2d\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u5916\u90e8\u77e5\u8bc6\uff0c\u4f46\u6a21\u578b\u5728\u5b9e\u73b0\u5168\u5c40\u8bed\u4e49\u7406\u89e3\u53ca\u5bf9\u9f50\u4eba\u7c7b\u4f26\u7406\u548c\u8d28\u91cf\u504f\u597d\u65b9\u9762\u5c1a\u5b58\u5728\u96be\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86GraphMPA\uff0c\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u7efc\u5408\u6027\u6846\u67b6\uff0c\u5305\u542b\u6a21\u5f0f\u5bfb\u4f18\u504f\u597d\u5bf9\u9f50\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u901a\u7528\u76f8\u4f3c\u6027\u5ea6\u91cf\u6784\u5efa\u5c42\u6b21\u5316\u6587\u6863\u56fe\uff0c\u6a21\u62df\u4eba\u7c7b\u5bf9\u4fe1\u606f\u7684\u8ba4\u77e5\u4e0e\u6574\u5408\u8fc7\u7a0b\uff0c\u5e76\u5f15\u5165\u6a21\u5f0f\u5bfb\u4f18\u6982\u7387\u5339\u914d\u7ea6\u675f\uff0c\u4ee5\u63d0\u5347\u751f\u6210\u7ed3\u679c\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u5ea6\u3002", "result": "\u5728\u516d\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cGraphMPA\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u80fd\u529b\uff0c\u80fd\u591f\u66f4\u6709\u6548\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u3002", "conclusion": "GraphMPA\u6846\u67b6\u901a\u8fc7\u56fe\u7ed3\u6784\u7406\u89e3\u548c\u6a21\u5f0f\u504f\u597d\u4f18\u5316\uff0c\u6709\u6548\u63d0\u5347RAG\u7cfb\u7edf\u7684\u5168\u7403\u4fe1\u606f\u5408\u6210\u80fd\u529b\u548c\u8f93\u51fa\u5bf9\u4eba\u7c7b\u8d28\u91cf\u4e0e\u4f26\u7406\u504f\u597d\u7684\u5bf9\u9f50\u5ea6\u3002"}}
{"id": "2506.18511", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18511", "abs": "https://arxiv.org/abs/2506.18511", "authors": ["Yu Han", "Aaron Ceross", "Jeroen H. M. Bergmann"], "title": "Standard Applicability Judgment and Cross-jurisdictional Reasoning: A RAG-based Framework for Medical Device Compliance", "comment": null, "summary": "Identifying the appropriate regulatory standard applicability remains a\ncritical yet understudied challenge in medical device compliance, frequently\nnecessitating expert interpretation of fragmented and heterogeneous\ndocumentation across different jurisdictions. To address this challenge, we\nintroduce a modular AI system that leverages a retrieval-augmented generation\n(RAG) pipeline to automate standard applicability determination. Given a\nfree-text device description, our system retrieves candidate standards from a\ncurated corpus and uses large language models to infer jurisdiction-specific\napplicability, classified as Mandatory, Recommended, or Not Applicable, with\ntraceable justifications. We construct an international benchmark dataset of\nmedical device descriptions with expert-annotated standard mappings, and\nevaluate our system against retrieval-only, zero-shot, and rule-based\nbaselines. The proposed approach attains a classification accuracy of 73% and a\nTop-5 retrieval recall of 87%, demonstrating its effectiveness in identifying\nrelevant regulatory standards. We introduce the first end-to-end system for\nstandard applicability reasoning, enabling scalable and interpretable\nAI-supported regulatory science. Notably, our region-aware RAG agent performs\ncross-jurisdictional reasoning between Chinese and U.S. standards, supporting\nconflict resolution and applicability justification across regulatory\nframeworks.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u57fa\u4e8eRAG\u7684AI\u7cfb\u7edf\u81ea\u52a8\u5224\u5b9a\u533b\u7597\u5668\u68b0\u6807\u51c6\u9002\u7528\u6027\uff0c\u51c6\u786e\u7387\u9ad8\u4e14\u652f\u6301\u4e2d\u7f8e\u6cd5\u89c4\u8de8\u533a\u57df\u63a8\u7406\uff0c\u662f\u5408\u89c4\u9886\u57df\u9996\u4e2a\u7aef\u5230\u7aef\u63a8\u7406\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5728\u533b\u7597\u8bbe\u5907\u5408\u89c4\u9886\u57df\uff0c\u4e0d\u540c\u5730\u533a\u7684\u6cd5\u89c4\u6807\u51c6\u6587\u6863\u788e\u7247\u5316\u4e14\u4e0d\u7edf\u4e00\uff0c\u6807\u51c6\u9002\u7528\u6027\u5224\u5b9a\u9700\u4f9d\u8d56\u4e13\u5bb6\uff0c\u6548\u7387\u4f4e\u4e0b\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u5347\u6cd5\u89c4\u5408\u89c4\u5de5\u4f5c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u6a21\u5757\u5316AI\u7cfb\u7edf\uff0c\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u3002\u7cfb\u7edf\u5bf9\u7ed9\u5b9a\u7684\u8bbe\u5907\u63cf\u8ff0\uff0c\u5148\u4ece\u6807\u51c6\u5e93\u4e2d\u68c0\u7d22\u5019\u9009\u6807\u51c6\uff0c\u518d\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5224\u65ad\u6bcf\u4e2a\u6807\u51c6\u5728\u4e0d\u540c\u53f8\u6cd5\u7ba1\u8f96\u533a\u4e0b\u7684\u9002\u7528\u6027\uff08\u5f3a\u5236\u3001\u63a8\u8350\u3001\u4e0d\u9002\u7528\uff09\uff0c\u5e76\u63d0\u4f9b\u53ef\u6eaf\u6e90\u7684\u7406\u7531\u3002\u6784\u5efa\u4e86\u56fd\u9645\u5316\u7684\u533b\u7597\u8bbe\u5907\u63cf\u8ff0\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e13\u5bb6\u6807\u6ce8\u7684\u6807\u51c6\u6620\u5c04\uff0c\u5e76\u540c\u68c0\u7d22\u3001\u96f6\u6837\u672c\u4e0e\u89c4\u5219\u6cd5\u57fa\u7ebf\u6a21\u578b\u5bf9\u7cfb\u7edf\u8fdb\u884c\u8bc4\u6d4b\u3002", "result": "\u7cfb\u7edf\u53d6\u5f97\u4e8673%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u548c87%\u7684Top-5\u68c0\u7d22\u53ec\u56de\u7387\uff0c\u5c55\u793a\u51fa\u663e\u8457\u6709\u6548\u6027\u3002\u7cfb\u7edf\u5177\u5907\u8de8\u4e2d\u7f8e\u6cd5\u89c4\u6807\u51c6\u533a\u57df\u611f\u77e5\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u53ef\u89e3\u91ca\u6807\u51c6\u9002\u7528\u6027\u4e0e\u51b2\u7a81\u3002", "conclusion": "\u9996\u6b21\u63d0\u51fa\u7aef\u5230\u7aef\u6807\u51c6\u9002\u7528\u6027\u63a8\u7406\u7cfb\u7edf\uff0c\u5b9e\u73b0\u533b\u7597\u8bbe\u5907\u6cd5\u89c4\u5408\u89c4\u7684\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u4ee5\u53ca\u53ef\u89e3\u91caAI\u652f\u6491\u3002\u80fd\u591f\u652f\u6301\u4e0d\u540c\u56fd\u5bb6\u95f4\u6cd5\u89c4\u6807\u51c6\u9002\u7528\u7684\u51b2\u7a81\u89e3\u51b3\u4e0e\u6807\u51c6\u5224\u5b9a\u7406\u7531\u8ffd\u6eaf\u3002"}}
{"id": "2506.18027", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18027", "abs": "https://arxiv.org/abs/2506.18027", "authors": ["Thi Thu Uyen Hoang", "Viet Anh Nguyen"], "title": "PDF Retrieval Augmented Question Answering", "comment": null, "summary": "This paper presents an advancement in Question-Answering (QA) systems using a\nRetrieval Augmented Generation (RAG) framework to enhance information\nextraction from PDF files. Recognizing the richness and diversity of data\nwithin PDFs--including text, images, vector diagrams, graphs, and tables--poses\nunique challenges for existing QA systems primarily designed for textual\ncontent. We seek to develop a comprehensive RAG-based QA system that will\neffectively address complex multimodal questions, where several data types are\ncombined in the query. This is mainly achieved by refining approaches to\nprocessing and integrating non-textual elements in PDFs into the RAG framework\nto derive precise and relevant answers, as well as fine-tuning large language\nmodels to better adapt to our system. We provide an in-depth experimental\nevaluation of our solution, demonstrating its capability to extract accurate\ninformation that can be applied to different types of content across PDFs. This\nwork not only pushes the boundaries of retrieval-augmented QA systems but also\nlays a foundation for further research in multimodal data integration and\nprocessing.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684RAG\u95ee\u7b54\u7cfb\u7edf\uff0c\u9996\u6b21\u6709\u6548\u6574\u5408\u4e86PDF\u4e2d\u7684\u6587\u672c\u548c\u975e\u6587\u672c\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u590d\u6742\u95ee\u9898\u4e0a\u7684\u51c6\u786e\u6027\u548c\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u95ee\u7b54\u7cfb\u7edf\u4e3b\u8981\u9488\u5bf9\u6587\u672c\u4fe1\u606f\uff0c\u96be\u4ee5\u5904\u7406PDF\u7b49\u6587\u6863\u5185\u7684\u4e30\u5bcc\u591a\u6837\u6570\u636e\u7c7b\u578b\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u80fd\u591f\u6574\u5408\u5e76\u667a\u80fd\u5904\u7406\u591a\u6a21\u6001\u4fe1\u606f\u7684QA\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u5bf9RAG\u6846\u67b6\u8fdb\u884c\u6539\u8fdb\uff0c\u5c06PDF\u4e2d\u7684\u975e\u6587\u672c\u5185\u5bb9\uff08\u5982\u56fe\u50cf\u3001\u56fe\u8868\u3001\u8868\u683c\u7b49\uff09\u6570\u5b57\u5316\u5e76\u6709\u6548\u6574\u5408\u8fdb\u7cfb\u7edf\u6d41\u7a0b\uff0c\u540c\u65f6\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u4ee5\u9002\u5e94\u591a\u6a21\u6001\u4fe1\u606f\u5904\u7406\u9700\u6c42\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u5728PDF\u4e2d\u51c6\u786e\u62bd\u53d6\u591a\u7c7b\u578b\u5185\u5bb9\u7684\u4fe1\u606f\uff0c\u5e76\u63d0\u5347\u4e86\u5e94\u5bf9\u590d\u6742\u591a\u6a21\u6001\u95ee\u9898\u7684\u80fd\u529b\uff0c\u4e3a\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u548c\u5904\u7406\u9886\u57df\u7684\u7814\u7a76\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\u7684\u95ee\u7b54\u7cfb\u7edf\uff0c\u80fd\u591f\u4ecePDF\u6587\u4ef6\u4e2d\u63d0\u53d6\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u73b0\u6709\u7cfb\u7edf\u5904\u7406\u6587\u672c\u3001\u56fe\u50cf\u3001\u56fe\u8868\u548c\u8868\u683c\u7b49\u591a\u79cd\u6570\u636e\u7c7b\u578b\u7684\u80fd\u529b\u3002"}}
{"id": "2506.18538", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18538", "abs": "https://arxiv.org/abs/2506.18538", "authors": ["Rifat Ara Shams", "Didar Zowghi", "Muneera Bano"], "title": "A Question Bank to Assess AI Inclusivity: Mapping out the Journey from Diversity Errors to Inclusion Excellence", "comment": null, "summary": "Ensuring diversity and inclusion (D&I) in artificial intelligence (AI) is\ncrucial for mitigating biases and promoting equitable decision-making. However,\nexisting AI risk assessment frameworks often overlook inclusivity, lacking\nstandardized tools to measure an AI system's alignment with D&I principles.\nThis paper introduces a structured AI inclusivity question bank, a\ncomprehensive set of 253 questions designed to evaluate AI inclusivity across\nfive pillars: Humans, Data, Process, System, and Governance. The development of\nthe question bank involved an iterative, multi-source approach, incorporating\ninsights from literature reviews, D&I guidelines, Responsible AI frameworks,\nand a simulated user study. The simulated evaluation, conducted with 70\nAI-generated personas related to different AI jobs, assessed the question\nbank's relevance and effectiveness for AI inclusivity across diverse roles and\napplication domains. The findings highlight the importance of integrating D&I\nprinciples into AI development workflows and governance structures. The\nquestion bank provides an actionable tool for researchers, practitioners, and\npolicymakers to systematically assess and enhance the inclusivity of AI\nsystems, paving the way for more equitable and responsible AI technologies.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa253\u9898\u7684AI\u5305\u5bb9\u6027\u95ee\u9898\u5e93\uff0c\u53ef\u7cfb\u7edf\u8bc4\u4f30AI\u5728\u591a\u6837\u6027\u4e0e\u5305\u5bb9\u6027\u65b9\u9762\u7684\u8868\u73b0\uff0c\u65b9\u6cd5\u79d1\u5b66\uff0c\u7ed3\u679c\u663e\u793a\u5de5\u5177\u6709\u6548\uff0c\u5bf9\u5b9e\u73b0\u516c\u5e73AI\u5177\u6709\u5b9e\u8df5\u610f\u4e49\u3002", "motivation": "\u5f53\u524d\u7684AI\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\u5f80\u5f80\u5ffd\u89c6\u5305\u5bb9\u6027\uff0c\u7f3a\u4e4f\u8861\u91cfAI\u7cfb\u7edf\u591a\u6837\u6027\u4e0e\u5305\u5bb9\u6027\u539f\u5219\u4e00\u81f4\u6027\u7684\u6807\u51c6\u5316\u5de5\u5177\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u5f00\u53d1\u80fd\u591f\u7cfb\u7edf\u6027\u8861\u91cfAI\u5305\u5bb9\u6027\u7684\u624b\u6bb5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684AI\u5305\u5bb9\u6027\u95ee\u9898\u5e93\uff0c\u5305\u542b253\u4e2a\u95ee\u9898\uff0c\u4ece\u201c\u4eba\u201d\u3001\u201c\u6570\u636e\u201d\u3001\u201c\u6d41\u7a0b\u201d\u3001\u201c\u7cfb\u7edf\u201d\u548c\u201c\u6cbb\u7406\u201d\u4e94\u5927\u652f\u67f1\u8bc4\u4f30AI\u5305\u5bb9\u6027\u3002\u5f00\u53d1\u8fc7\u7a0b\u91c7\u7528\u591a\u8f6e\u8fed\u4ee3\u6cd5\uff0c\u878d\u5408\u6587\u732e\u7efc\u8ff0\u3001\u5305\u5bb9\u6027\u6307\u5357\u3001\u8d1f\u8d23\u4efbAI\u6846\u67b6\u53ca\u6a21\u62df\u7528\u6237\u7814\u7a76\u7684\u89c1\u89e3\u3002\u4e4b\u540e\uff0c\u7814\u7a76\u56e2\u961f\u901a\u8fc770\u4e2a\u4eba\u5de5\u751f\u6210\u7684AI\u76f8\u5173\u804c\u4e1a\u89d2\u8272\uff0c\u6a21\u62df\u8bc4\u4f30\u4e86\u95ee\u9898\u5e93\u5728\u4e0d\u540c\u5e94\u7528\u9886\u57df\u548c\u89d2\u8272\u4e2d\u7684\u76f8\u5173\u6027\u4e0e\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u95ee\u9898\u5e93\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u548c\u63d0\u5347AI\u7cfb\u7edf\u5728\u591a\u6837\u6027\u4e0e\u5305\u5bb9\u6027\u65b9\u9762\u7684\u8868\u73b0\uff0c\u5bf9AI\u5f00\u53d1\u6d41\u7a0b\u548c\u6cbb\u7406\u7ed3\u6784\u4e2d\u878d\u5165\u5305\u5bb9\u6027\u539f\u5219\u5177\u6709\u91cd\u8981\u4f5c\u7528\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u95ee\u9898\u5e93\u4e3a\u5b66\u754c\u3001\u4e1a\u754c\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u7cfb\u7edf\u8bc4\u4f30\u4e0e\u52a0\u5f3aAI\u5305\u5bb9\u6027\u7684\u53ef\u64cd\u4f5c\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u516c\u5e73\u548c\u8d1f\u8d23\u4efb\u7684AI\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2506.18035", "categories": ["cs.CL", "cs.SD", "eess.AS", "68T50 (Primary)", "I.2.7; I.5.4"], "pdf": "https://arxiv.org/pdf/2506.18035", "abs": "https://arxiv.org/abs/2506.18035", "authors": ["Maxence Lasbordes", "Daniele Falavigna", "Alessio Brutti"], "title": "Splitformer: An improved early-exit architecture for automatic speech recognition on edge devices", "comment": "5 pages, 3 Postscript figures", "summary": "The ability to dynamically adjust the computational load of neural models\nduring inference in a resource aware manner is crucial for on-device processing\nscenarios, characterised by limited and time-varying computational resources.\nEarly-exit architectures represent an elegant and effective solution, since\nthey can process the input with a subset of their layers, exiting at\nintermediate branches (the upmost layers are hence removed from the model).\n  From a different perspective, for automatic speech recognition applications\nthere are memory-efficient neural architectures that apply variable frame rate\nanalysis, through downsampling/upsampling operations in the middle layers,\nreducing the overall number of operations and improving significantly the\nperformance on well established benchmarks. One example is the Zipformer.\nHowever, these architectures lack the modularity necessary to inject early-exit\nbranches.\n  With the aim of improving the performance in early-exit models, we propose\nintroducing parallel layers in the architecture that process downsampled\nversions of their inputs. % in conjunction with standard processing layers. We\nshow that in this way the speech recognition performance on standard benchmarks\nsignificantly improve, at the cost of a small increase in the overall number of\nmodel parameters but without affecting the inference time.", "AI": {"tldr": "\u672c\u6587\u4e3a\u7aef\u4fa7\u8bed\u97f3\u8bc6\u522b\u63a8\u7406\u63d0\u51fa\u4e86\u4e00\u79cd\u5f15\u5165\u5e76\u884c\u964d\u91c7\u6837\u5904\u7406\u5c42\u7684\u65e9\u9000\u6a21\u578b\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u8d44\u6e90\u611f\u77e5\u4e0b\u6027\u80fd\u63d0\u5347\uff0c\u63a8\u7406\u901f\u5ea6\u4e0d\u53d8\uff0c\u53c2\u6570\u91cf\u7565\u589e\u3002", "motivation": "\u795e\u7ecf\u6a21\u578b\u5728\u63a8\u7406\u65f6\uff0c\u9700\u6839\u636e\u8bbe\u5907\u8d44\u6e90\u52a8\u6001\u8c03\u6574\u8ba1\u7b97\u91cf\uff0c\u5c24\u5176\u5728\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u6216\u53d8\u5316\u7684\u8bbe\u5907\u7aef\u5904\u7406\u573a\u666f\u683c\u5916\u91cd\u8981\uff0c\u800c\u73b0\u6709\u65e9\u9000\uff08early-exit\uff09\u67b6\u6784\u4e0e\u90e8\u5206\u9ad8\u6548\u8bed\u97f3\u8bc6\u522b\u67b6\u6784\u5728\u7ed3\u6784\u53ef\u6269\u5c55\u6027\u548c\u6a21\u5757\u5316\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u5728\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e2d\u5f15\u5165\u5e76\u884c\u5c42\uff0c\u4e13\u95e8\u5904\u7406\u964d\u91c7\u6837\u540e\u7684\u8f93\u5165\uff0c\u4ece\u800c\u4e0e\u6807\u51c6\u5904\u7406\u5c42\u534f\u540c\u5de5\u4f5c\uff0c\u4ee5\u63d0\u5347\u8bed\u97f3\u8bc6\u522b\u65e9\u9000\u6a21\u578b\u7684\u6027\u80fd\u3002", "result": "\u5728\u6807\u51c6\u8bed\u97f3\u8bc6\u522b\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4ec5\u9700\u5c11\u91cf\u53c2\u6570\u589e\u52a0\uff0c\u4e14\u4e0d\u4f1a\u5f71\u54cd\u63a8\u7406\u65f6\u95f4\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u9488\u5bf9\u964d\u91c7\u6837\u8f93\u5165\u7684\u5e76\u884c\u5904\u7406\u5c42\uff0c\u53ef\u4ee5\u5728\u51e0\u4e4e\u4e0d\u589e\u52a0\u63a8\u7406\u5ef6\u8fdf\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u63d0\u5347\u9002\u7528\u4e8e\u65e9\u9000\u673a\u5236\u7684\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u6027\u80fd\uff0c\u9002\u5e94\u4e86\u8bbe\u5907\u7aef\u8d44\u6e90\u52a8\u6001\u53d8\u5316\u9700\u6c42\u3002"}}
{"id": "2506.18559", "categories": ["cs.AI", "cs.LO", "I.2.7; F.4.1"], "pdf": "https://arxiv.org/pdf/2506.18559", "abs": "https://arxiv.org/abs/2506.18559", "authors": ["Hong Qing Yu"], "title": "T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent", "comment": null, "summary": "Large language models excel at generating fluent text but frequently struggle\nwith structured reasoning involving temporal constraints, causal relationships,\nand probabilistic reasoning. To address these limitations, we propose Temporal\nCausal Probabilistic Description Logic (T-CPDL), an integrated framework that\nextends traditional Description Logic with temporal interval operators,\nexplicit causal relationships, and probabilistic annotations. We present two\ndistinct variants of T-CPDL: one capturing qualitative temporal relationships\nthrough Allen's interval algebra, and another variant enriched with explicit\ntimestamped causal assertions. Both variants share a unified logical structure,\nenabling complex reasoning tasks ranging from simple temporal ordering to\nnuanced probabilistic causation. Empirical evaluations on temporal reasoning\nand causal inference benchmarks confirm that T-CPDL substantially improves\ninference accuracy, interpretability, and confidence calibration of language\nmodel outputs. By delivering transparent reasoning paths and fine-grained\ntemporal and causal semantics, T-CPDL significantly enhances the capability of\nlanguage models to support robust, explainable, and trustworthy\ndecision-making. This work also lays the groundwork for developing advanced\nLogic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentially\nboosting the reasoning capabilities and efficiency of knowledge graph-enhanced\nRAG systems.", "AI": {"tldr": "T-CPDL\u6269\u5c55\u63cf\u8ff0\u903b\u8f91\uff0c\u878d\u5165\u65f6\u5e8f\u3001\u56e0\u679c\u548c\u6982\u7387\u63a8\u7406\uff0c\u5927\u5e45\u63d0\u5347\u5927\u6a21\u578b\u63a8\u7406\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u4e3a\u5f3a\u5316\u903b\u8f91-\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6253\u4e0b\u57fa\u7840\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u751f\u6210\u6d41\u7545\u6587\u672c\u65b9\u9762\u8868\u73b0\u4f18\u79c0\uff0c\u4f46\u5728\u6d89\u53ca\u65f6\u95f4\u7ea6\u675f\u3001\u56e0\u679c\u5173\u7cfb\u548c\u6982\u7387\u63a8\u7406\u7684\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6709\u5fc5\u8981\u4e3a\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u5f15\u5165\u66f4\u5b8c\u6574\u7684\u65f6\u5e8f\u3001\u56e0\u679c\u548c\u6982\u7387\u8bed\u4e49\u652f\u6301\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u5408\u578b\u6846\u67b6\u201cT-CPDL\uff08\u65f6\u5e8f\u56e0\u679c\u6982\u7387\u63cf\u8ff0\u903b\u8f91\uff09\u201d\uff0c\u5c06\u4f20\u7edf\u63cf\u8ff0\u903b\u8f91\u6269\u5c55\u4e3a\u5305\u542b\u65f6\u5e8f\u533a\u95f4\u7b97\u5b50\u3001\u663e\u5f0f\u56e0\u679c\u5173\u7cfb\u548c\u6982\u7387\u6ce8\u89e3\u3002T-CPDL\u6709\u4e24\u79cd\u53d8\u4f53\uff1a\u4e00\u79cd\u57fa\u4e8eAllen\u533a\u95f4\u4ee3\u6570\uff0c\u63cf\u8ff0\u5b9a\u6027\u65f6\u5e8f\u5173\u7cfb\uff1b\u53e6\u4e00\u79cd\u901a\u8fc7\u663e\u5f0f\u5e26\u65f6\u95f4\u6233\u7684\u56e0\u679c\u65ad\u8a00\u4e30\u5bcc\u8868\u8fbe\u65b9\u5f0f\u3002\u8fd9\u4e24\u79cd\u53d8\u4f53\u5171\u4eab\u7edf\u4e00\u7684\u903b\u8f91\u7ed3\u6784\uff0c\u53ef\u5b9e\u73b0\u4ece\u7b80\u5355\u65f6\u5e8f\u6392\u5e8f\u5230\u590d\u6742\u6982\u7387\u56e0\u679c\u63a8\u7406\u7684\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u3002", "result": "\u5728\u65f6\u5e8f\u63a8\u7406\u548c\u56e0\u679c\u63a8\u7406\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cT-CPDL\u80fd\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u51c6\u786e\u7387\u3001\u53ef\u89e3\u91ca\u6027\u53ca\u7ed3\u679c\u53ef\u4fe1\u5ea6\u6821\u51c6\u80fd\u529b\u3002", "conclusion": "T-CPDL\u6781\u5927\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u652f\u6491\u7a33\u5065\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u4fe1\u51b3\u7b56\u7684\u80fd\u529b\uff0c\u5e76\u4e3a\u9ad8\u7ea7\u7684\u903b\u8f91-\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08Logic-RAG\uff09\u6846\u67b6\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u671b\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u578bRAG\u7cfb\u7edf\u7684\u63a8\u7406\u80fd\u529b\u548c\u6548\u7387\u3002"}}
{"id": "2506.18036", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18036", "abs": "https://arxiv.org/abs/2506.18036", "authors": ["Aziz Amari", "Mohamed Achref Ben Ammar"], "title": "Markov-Enhanced Clustering for Long Document Summarization: Tackling the 'Lost in the Middle' Challenge with Large Language Models", "comment": null, "summary": "The rapid expansion of information from diverse sources has heightened the\nneed for effective automatic text summarization, which condenses documents into\nshorter, coherent texts. Summarization methods generally fall into two\ncategories: extractive, which selects key segments from the original text, and\nabstractive, which generates summaries by rephrasing the content coherently.\nLarge language models have advanced the field of abstractive summarization, but\nthey are resourceintensive and face significant challenges in retaining key\ninformation across lengthy documents, which we call being \"lost in the middle\".\nTo address these issues, we propose a hybrid summarization approach that\ncombines extractive and abstractive techniques. Our method splits the document\ninto smaller text chunks, clusters their vector embeddings, generates a summary\nfor each cluster that represents a key idea in the document, and constructs the\nfinal summary by relying on a Markov chain graph when selecting the semantic\norder of ideas.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u62bd\u53d6\u4e0e\u751f\u6210\u7684\u6df7\u5408\u6458\u8981\u65b9\u6cd5\uff0c\u6709\u6548\u907f\u514d\u751f\u6210\u5f0f\u5728\u957f\u6587\u672c\u4e2d\u5173\u952e\u4fe1\u606f\u4e22\u5931\u95ee\u9898\uff0c\u901a\u8fc7\u805a\u7c7b\u53ca\u9a6c\u5c14\u53ef\u592b\u94fe\u4f18\u5316\u4fe1\u606f\u7ec4\u7ec7\uff0c\u63d0\u5347\u6458\u8981\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u6587\u672c\u6458\u8981\u65b9\u6cd5\u4e3b\u8981\u5206\u4e3a\u62bd\u53d6\u5f0f\u548c\u751f\u6210\u5f0f\u4e24\u7c7b\uff0c\u4f46\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u5f0f\u6458\u8981\u867d\u7136\u6548\u679c\u63d0\u5347\u663e\u8457\uff0c\u5374\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u4e14\u5728\u5904\u7406\u957f\u6587\u6863\u65f6\u6613\u4e22\u5931\u5173\u952e\u4fe1\u606f\uff08\u5373\u201clost in the middle\u201d\u95ee\u9898\uff09\u3002\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u62bd\u53d6\u5f0f\u548c\u751f\u6210\u5f0f\u7684\u6df7\u5408\u6458\u8981\u65b9\u6cd5\u3002\u5177\u4f53\u505a\u6cd5\u662f\u5c06\u6587\u6863\u62c6\u5206\u4e3a\u82e5\u5e72\u5c0f\u5757\uff0c\u5bf9\u5176\u5411\u91cf\u5d4c\u5165\u8fdb\u884c\u805a\u7c7b\uff0c\u4e3a\u6bcf\u4e2a\u805a\u7c7b\u751f\u6210\u4ee3\u8868\u5173\u952e\u601d\u60f3\u7684\u6458\u8981\uff0c\u6700\u7ec8\u6839\u636e\u9a6c\u5c14\u53ef\u592b\u94fe\u56fe\u51b3\u5b9a\u8fd9\u4e9b\u6458\u8981\u7684\u8bed\u4e49\u6392\u5e8f\uff0c\u751f\u6210\u6700\u7ec8\u6458\u8981\u6587\u672c\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u7559\u6587\u6863\u5173\u952e\u5185\u5bb9\u7684\u540c\u65f6\uff0c\u514b\u670d\u751f\u6210\u5f0f\u65b9\u6cd5\u5728\u957f\u6587\u6863\u4e0a\u7684\u4fe1\u606f\u4e22\u5931\u95ee\u9898\uff0c\u5e76\u9ad8\u6548\u7ec4\u7ec7\u5173\u952e\u4fe1\u606f\u3002", "conclusion": "\u6df7\u5408\u6458\u8981\u65b9\u6cd5\u53ef\u6709\u6548\u63d0\u5347\u81ea\u52a8\u6458\u8981\u8d28\u91cf\uff0c\u517c\u987e\u5173\u952e\u5185\u5bb9\u4fdd\u7559\u548c\u903b\u8f91\u8fde\u8d2f\u6027\uff0c\u5177\u5907\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.18082", "categories": ["cs.CL", "stat.AP"], "pdf": "https://arxiv.org/pdf/2506.18082", "abs": "https://arxiv.org/abs/2506.18082", "authors": ["Esteban Garces Arias", "Hannah Blocher", "Julian Rodemann", "Matthias A\u00dfenmacher", "Christoph Jansen"], "title": "Statistical Multicriteria Evaluation of LLM-Generated Text", "comment": null, "summary": "Assessing the quality of LLM-generated text remains a fundamental challenge\nin natural language processing. Current evaluation approaches often rely on\nisolated metrics or simplistic aggregations that fail to capture the nuanced\ntrade-offs between coherence, diversity, fluency, and other relevant indicators\nof text quality. In this work, we adapt a recently proposed framework for\nstatistical inference based on Generalized Stochastic Dominance (GSD) that\naddresses three critical limitations in existing benchmarking methodologies:\nthe inadequacy of single-metric evaluation, the incompatibility between\ncardinal automatic metrics and ordinal human judgments, and the lack of\ninferential statistical guarantees. The GSD-front approach enables simultaneous\nevaluation across multiple quality dimensions while respecting their different\nmeasurement scales, building upon partial orders of decoding strategies, thus\navoiding arbitrary weighting of the involved metrics. By applying this\nframework to evaluate common decoding strategies against human-generated text,\nwe demonstrate its ability to identify statistically significant performance\ndifferences while accounting for potential deviations from the i.i.d.\nassumption of the sampling design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e7f\u4e49\u968f\u673a\u5360\u4f18\u7684\u591a\u7ef4\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\uff08GSD-front\uff09\uff0c\u80fd\u66f4\u79d1\u5b66\u5168\u9762\u8bc4\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\uff0c\u517c\u5bb9\u591a\u79cd\u8bc4\u6d4b\u6307\u6807\u5e76\u5177\u5907\u7edf\u8ba1\u63a8\u65ad\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u6587\u672c\u7684\u8d28\u91cf\u8bc4\u4f30\u9762\u4e34\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5355\u4e00\u6216\u7b80\u5355\u805a\u5408\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u96be\u4ee5\u5168\u9762\u6355\u6349\u6587\u672c\u7684\u8fde\u8d2f\u6027\u3001\u591a\u6837\u6027\u3001\u6d41\u7545\u6027\u7b49\u591a\u7ef4\u8d28\u91cf\u7279\u5f81\u4e4b\u95f4\u7684\u6743\u8861\u3002\u6b64\u5916\uff0c\u81ea\u52a8\u5316\u6307\u6807\u548c\u4eba\u5de5\u5224\u65ad\u7684\u6570\u636e\u7c7b\u578b\u4e0d\u540c\uff0c\u73b0\u6709\u8bc4\u4f30\u7f3a\u4e4f\u7edf\u8ba1\u63a8\u65ad\u7684\u4fdd\u8bc1\u3002", "method": "\u672c\u6587\u5f15\u5165\u5e76\u6539\u8fdb\u4e86\u57fa\u4e8e\u5e7f\u4e49\u968f\u673a\u5360\u4f18\uff08GSD\uff09\u7684\u7edf\u8ba1\u63a8\u65ad\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u540c\u65f6\u5bf9\u591a\u79cd\u4e0d\u540c\u91cf\u7eb2\u7684\u8d28\u91cf\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\uff0c\u5229\u7528\u89e3\u7801\u7b56\u7565\u7684\u504f\u5e8f\u5173\u7cfb\uff0c\u907f\u514d\u4e86\u5bf9\u5404\u6307\u6807\u8fdb\u884c\u4efb\u610f\u6743\u91cd\u5206\u914d\u3002\u8be5\u6846\u67b6\u517c\u5bb9\u81ea\u52a8\u6307\u6807\uff08\u5b9a\u91cf\uff09\u4e0e\u4eba\u5de5\u8bc4\u5206\uff08\u5b9a\u5e8f\uff09\uff0c\u5e76\u80fd\u4e3a\u7edf\u8ba1\u5dee\u5f02\u63d0\u4f9b\u63a8\u65ad\u6027\u4fdd\u8bc1\u3002", "result": "\u901a\u8fc7\u5c06GSD-front\u65b9\u6cd5\u5e94\u7528\u4e8e\u4e3b\u6d41\u6587\u672c\u751f\u6210\u89e3\u7801\u7b56\u7565\u4e0e\u4eba\u5de5\u6587\u672c\u5bf9\u6bd4\u8bc4\u6d4b\uff0c\u53d1\u73b0\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u63ed\u793a\u5404\u65b9\u6cd5\u95f4\u5728\u591a\u7ef4\u5ea6\u8d28\u91cf\u4e0a\u7684\u663e\u8457\u6027\u80fd\u5dee\u5f02\uff0c\u786e\u4fdd\u4e86\u7ed3\u679c\u7684\u7edf\u8ba1\u53ef\u9760\u6027\uff0c\u540c\u65f6\u9002\u5e94\u62bd\u6837\u8bbe\u8ba1\u53ef\u80fd\u5e76\u975e\u72ec\u7acb\u540c\u5206\u5e03\u7684\u5b9e\u9645\u60c5\u51b5\u3002", "conclusion": "GSD-front\u4e3aLLM\u751f\u6210\u6587\u672c\u7684\u591a\u7ef4\u5ea6\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7cfb\u7edf\u3001\u53ef\u9760\u4e14\u63a8\u65ad\u6027\u5f3a\u7684\u65b9\u6cd5\uff0c\u514b\u670d\u4e86\u4ee5\u5f80\u5355\u6307\u6807\u548c\u7f3a\u4e4f\u63a8\u65ad\u4fdd\u969c\u7684\u5c40\u9650\u6027\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8NLP\u8bc4\u6d4b\u65b9\u6cd5\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.18628", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18628", "abs": "https://arxiv.org/abs/2506.18628", "authors": ["Piotr Matys", "Jan Eliasz", "Konrad Kie\u0142czy\u0144ski", "Miko\u0142aj Langner", "Teddy Ferdinan", "Jan Koco\u0144", "Przemys\u0142aw Kazienko"], "title": "AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs", "comment": "ICCS 2025 Workshops", "summary": "In real-world applications, Large Language Models (LLMs) often hallucinate,\neven in Retrieval-Augmented Generation (RAG) settings, which poses a\nsignificant challenge to their deployment. In this paper, we introduce\nAggTruth, a method for online detection of contextual hallucinations by\nanalyzing the distribution of internal attention scores in the provided context\n(passage). Specifically, we propose four different variants of the method, each\nvarying in the aggregation technique used to calculate attention scores. Across\nall LLMs examined, AggTruth demonstrated stable performance in both same-task\nand cross-task setups, outperforming the current SOTA in multiple scenarios.\nFurthermore, we conducted an in-depth analysis of feature selection techniques\nand examined how the number of selected attention heads impacts detection\nperformance, demonstrating that careful selection of heads is essential to\nachieve optimal results.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAggTruth\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790attention\u5206\u6570\u5b9e\u73b0LLM\u5e7b\u89c9\u7684\u5728\u7ebf\u68c0\u6d4b\uff0c\u5728\u591a\u6a21\u578b\u3001\u4efb\u52a1\u4e0b\u8d85\u8fc7\u5f53\u524d\u6700\u4f73\u65b9\u6cd5\uff0c\u5e76\u5f3a\u8c03\u4e86\u7279\u5f81\u9009\u62e9\u548chead\u9009\u62e9\u7684\u4f5c\u7528\u3002", "motivation": "\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\uff0cLLMs\u5373\u4f7f\u5728RAG\u8bbe\u7f6e\u4e0b\u4e5f\u5e38\u5e38\u51fa\u73b0\u865a\u5047\u751f\u6210\uff08\u5e7b\u89c9\uff09\uff0c\u8fd9\u4e3a\u6a21\u578b\u843d\u5730\u4ea7\u751f\u91cd\u5927\u6311\u6218\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u5982\u4f55\u6709\u6548\u68c0\u6d4b\u548c\u964d\u4f4eLLMs\u7684\u8bed\u5883\u6027\u5e7b\u89c9\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86AggTruth\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790LLM\u5185\u90e8attention\u5206\u6570\u7684\u5206\u5e03\uff0c\u5728\u7ebf\u68c0\u6d4b\u8bed\u5883\u5e7b\u89c9\u3002\u5177\u4f53\u8bbe\u8ba1\u4e86\u56db\u79cd\u4e0d\u540c\u7684attention\u5206\u6570\u805a\u5408\u6280\u672f\u3002\u8fd8\u7814\u7a76\u4e86\u7279\u5f81\u9009\u62e9\u548cattention head\u6570\u76ee\u5bf9\u68c0\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "AggTruth\u5728\u6240\u6709\u6d4b\u8bd5\u7684LLMs\u548c\u4efb\u52a1\uff08\u5305\u62ec\u540c\u4efb\u52a1\u548c\u8de8\u4efb\u52a1\u8bbe\u7f6e\uff09\u4e2d\u8868\u73b0\u7a33\u5b9a\uff0c\u5728\u591a\u79cd\u573a\u666f\u4e0b\u4f18\u4e8e\u5f53\u524d\u6700\u4f18\u65b9\u6cd5\uff08SOTA\uff09\u3002\u5408\u7406\u9009\u62e9attention heads\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002", "conclusion": "AggTruth\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u3001\u6709\u6548\u7684LLM\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6848\uff0c\u80fd\u591f\u5728\u591a\u6a21\u578b\u591a\u4efb\u52a1\u4e0b\u8d85\u8fc7\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86attention head\u9009\u62e9\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.18091", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18091", "abs": "https://arxiv.org/abs/2506.18091", "authors": ["Patrik Stano", "Ale\u0161 Hor\u00e1k"], "title": "Evaluating Prompt-Based and Fine-Tuned Approaches to Czech Anaphora Resolution", "comment": "12 pages", "summary": "Anaphora resolution plays a critical role in natural language understanding,\nespecially in morphologically rich languages like Czech. This paper presents a\ncomparative evaluation of two modern approaches to anaphora resolution on Czech\ntext: prompt engineering with large language models (LLMs) and fine-tuning\ncompact generative models. Using a dataset derived from the Prague Dependency\nTreebank, we evaluate several instruction-tuned LLMs, including Mistral Large 2\nand Llama 3, using a series of prompt templates. We compare them against\nfine-tuned variants of the mT5 and Mistral models that we trained specifically\nfor Czech anaphora resolution. Our experiments demonstrate that while prompting\nyields promising few-shot results (up to 74.5% accuracy), the fine-tuned\nmodels, particularly mT5-large, outperform them significantly, achieving up to\n88% accuracy while requiring fewer computational resources. We analyze\nperformance across different anaphora types, antecedent distances, and source\ncorpora, highlighting key strengths and trade-offs of each approach.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u6377\u514b\u8bed\u6307\u4ee3\u6d88\u89e3\u4efb\u52a1\u4e2d\uff0c\u4e24\u79cd\u4e3b\u6d41\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff08\u63d0\u793a\u5de5\u7a0b\u7684LLM\u4e0e\u5fae\u8c03\u751f\u6210\u6a21\u578b\uff09\u7684\u8868\u73b0\u3002\u53d1\u73b0\u4e13\u95e8\u5fae\u8c03\u7684mT5\u8868\u73b0\u8fdc\u8d85\u57fa\u4e8e\u63d0\u793a\u7684LLM\uff0c\u5efa\u8bae\u5728\u8d44\u6e90\u5141\u8bb8\u7684\u524d\u63d0\u4e0b\u4f18\u5148\u8003\u8651\u5fae\u8c03\u7b56\u7565\u3002", "motivation": "\u6307\u4ee3\u6d88\u89e3\uff08anaphora resolution\uff09\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4e2d\u6781\u4e3a\u91cd\u8981\uff0c\u5c24\u5176\u5bf9\u4e8e\u5f62\u6001\u4e30\u5bcc\u7684\u8bed\u8a00\u5982\u6377\u514b\u8bed\u3002\u8fc7\u53bb\u76f8\u5173\u7814\u7a76\u8f83\u5c11\u96c6\u4e2d\u4e8e\u6377\u514b\u8bed\uff0c\u4e14\u4e0d\u540c\u65b9\u6cd5\u7684\u6bd4\u8f83\u4e5f\u4e0d\u5145\u5206\u3002\u672c\u7814\u7a76\u5e0c\u671b\u6bd4\u8f83\u4e24\u79cd\u73b0\u4ee3\u65b9\u6cd5\u5728\u6377\u514b\u8bed\u6307\u4ee3\u6d88\u89e3\u4efb\u52a1\u4e0a\u7684\u6548\u679c\u3002", "method": "\u57fa\u4e8ePrague Dependency Treebank\u6784\u5efa\u7684\u6377\u514b\u8bed\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u82e5\u5e72\u6307\u4ee4\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982Mistral Large 2\u548cLlama 3\uff09\uff0c\u901a\u8fc7\u4e0d\u540c\u63d0\u793a\u6a21\u677f\u5b9e\u73b0\uff0c\u548c\u6211\u4eec\u4e13\u95e8\u4e3a\u6377\u514b\u8bed\u6307\u4ee3\u6d88\u89e3\u5fae\u8c03\u7684\u7d27\u51d1\u751f\u6210\u5f0f\u6a21\u578b\uff08mT5\u548cMistral\u53d8\u4f53\uff09\u8fdb\u884c\u5bf9\u6bd4\u3002\u4e3b\u8981\u5173\u6ce8\u51c6\u786e\u7387\u8868\u73b0\u53ca\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u63d0\u793a\u5de5\u7a0b\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u8868\u73b0\u53ef\u89c2\uff08\u51c6\u786e\u7387\u6700\u9ad8\u8fbe74.5%\uff09\uff0c\u4f46\u5fae\u8c03\u7684\u6a21\u578b\uff08\u5c24\u5176\u662fmT5-large\uff09\u663e\u8457\u4f18\u4e8e\u63d0\u793a\u6a21\u578b\uff0c\u51c6\u786e\u7387\u6700\u9ad8\u8fbe88%\uff0c\u4e14\u6240\u9700\u8ba1\u7b97\u8d44\u6e90\u66f4\u4f4e\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u4e86\u4e0d\u540c\u6307\u4ee3\u7c7b\u578b\u3001\u524d\u6307\u8ddd\u79bb\u548c\u8bed\u6599\u6765\u6e90\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u5bf9\u4e8e\u6377\u514b\u8bed\u6307\u4ee3\u6d88\u89e3\u4efb\u52a1\uff0c\u4e13\u95e8\u5fae\u8c03\u7684\u751f\u6210\u5f0f\u6a21\u578b\u4f18\u4e8e\u4ec5\u4f9d\u8d56\u63d0\u793a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4e0d\u4ec5\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u800c\u4e14\u8ba1\u7b97\u8d44\u6e90\u5360\u7528\u66f4\u5c11\uff1b\u4e0d\u540c\u65b9\u6cd5\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u6743\u8861\u3002"}}
{"id": "2506.18651", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18651", "abs": "https://arxiv.org/abs/2506.18651", "authors": ["Shuocun Yang", "Huawen Hu", "Enze Shi", "Shu Zhang"], "title": "Dual-level Behavioral Consistency for Inter-group and Intra-group Coordination in Multi-Agent Systems", "comment": null, "summary": "Behavioral diversity in Multi-agent reinforcement learning(MARL) represents\nan emerging and promising research area. Prior work has largely centered on\nintra-group behavioral consistency in multi-agent systems, with limited\nattention given to behavioral consistency in multi-agent grouping scenarios. In\nthis paper, we introduce Dual-Level Behavioral Consistency (DLBC), a novel MARL\ncontrol method designed to explicitly regulate agent behaviors at both\nintra-group and inter-group levels. DLBC partitions agents into distinct groups\nand dynamically modulates behavioral diversity both within and between these\ngroups. By dynamically modulating behavioral diversity within and between these\ngroups, DLBC achieves enhanced division of labor through inter-group\nconsistency, which constrains behavioral strategies across different groups.\nSimultaneously, intra-group consistency, achieved by aligning behavioral\nstrategies within each group, fosters stronger intra-group cooperation.\nCrucially, DLBC's direct constraint of agent policy functions ensures its broad\napplicability across various algorithmic frameworks. Experimental results in\nvarious grouping cooperation scenarios demonstrate that DLBC significantly\nenhances both intra-group cooperative performance and inter-group task\nspecialization, yielding substantial performance improvements. DLBC provides\nnew ideas for behavioral consistency control of multi-intelligent body systems,\nand its potential for application in more complex tasks and dynamic\nenvironments can be further explored in the future.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86DLBC\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ec4\u5185\u4e0e\u7ec4\u95f4\u7684\u884c\u4e3a\u4e00\u81f4\u6027\u8c03\u63a7\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u534f\u4f5c\u4e0e\u5206\u5de5\u80fd\u529b\uff0c\u5728\u5b9e\u9a8c\u4efb\u52a1\u4e2d\u83b7\u5f97\u8f83\u5927\u6027\u80fd\u6536\u76ca\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u591a\u5173\u6ce8\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5185\u90e8\u7684\u884c\u4e3a\u4e00\u81f4\u6027\uff0c\u5bf9\u5206\u7ec4\u573a\u666f\u4e0b\u7684\u884c\u4e3a\u4e00\u81f4\u6027\u5173\u6ce8\u4e0d\u8db3\uff0c\u4e9f\u9700\u65b9\u6cd5\u540c\u65f6\u63a7\u5236\u7ec4\u5185\u4e0e\u7ec4\u95f4\u7684\u884c\u4e3a\u7b56\u7565\u3002", "method": "\u63d0\u51faDual-Level Behavioral Consistency\uff08DLBC\uff09\u65b9\u6cd5\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u5206\u7ec4\uff0c\u5e76\u5728\u7ec4\u5185\u4e0e\u7ec4\u95f4\u52a8\u6001\u8c03\u8282\u884c\u4e3a\u591a\u6837\u6027\uff0c\u901a\u8fc7\u76f4\u63a5\u7ea6\u675f\u667a\u80fd\u4f53\u7b56\u7565\u51fd\u6570\u4ee5\u63d0\u5347\u884c\u4e3a\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDLBC\u5728\u5404\u7c7b\u5206\u7ec4\u534f\u4f5c\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u7ec4\u5185\u5408\u4f5c\u4e0e\u7ec4\u95f4\u4efb\u52a1\u4e13\u4e1a\u5316\u8868\u73b0\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "DLBC\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7ec4\u5185\u534f\u4f5c\u4e0e\u7ec4\u95f4\u5206\u5de5\u6027\u80fd\uff0c\u5c55\u73b0\u4e86\u884c\u4e3a\u4e00\u81f4\u6027\u63a7\u5236\u7684\u65b0\u601d\u8def\uff0c\u5e76\u5177\u5907\u5728\u590d\u6742\u4efb\u52a1\u4e0e\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.18102", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18102", "abs": "https://arxiv.org/abs/2506.18102", "authors": ["Fuyu Wang", "Jiangtong Li", "Kun Zhu", "Changjun Jiang"], "title": "InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating", "comment": "20 pages; Accepted to ACL 2025 Main", "summary": "With the rapid advancements in large language models (LLMs), debating tasks,\nsuch as argument quality assessment and debate process simulation, have made\nsignificant progress. However, existing LLM-based debating systems focus on\nresponding to specific arguments while neglecting objective assessments such as\nauthenticity and logical validity. Furthermore, these systems lack a structured\napproach to optimize across various dimensions$-$including evaluation metrics,\nchain-of-thought (CoT) reasoning, and multi-turn debate refinement$-$thereby\nlimiting their effectiveness. To address these interconnected challenges, we\npropose a dual-component framework: (1) $\\textbf{InspireScore}$, a novel\nevaluation system that establishes a multi-dimensional assessment architecture\nincorporating four subjective criteria (emotional appeal, argument clarity,\nargument arrangement, and topic relevance) alongside two objective metrics\n(fact authenticity and logical validity); and (2) $\\textbf{InspireDebate}$, an\noptimized debating framework employing a phased optimization approach through\nCoT reasoning enhancement, multi-dimensional Direct Preference Optimization\n(DPO), and real-time knowledge grounding via web-based Retrieval Augmented\nGeneration (Web-RAG). Empirical evaluations demonstrate that\n$\\textbf{InspireScore}$ achieves 44$\\%$ higher correlation with expert\njudgments compared to existing methods, while $\\textbf{InspireDebate}$ shows\nsignificant improvements, outperforming baseline models by 57$\\%$. Source code\nis available at https://github.com/fywang12/InspireDebate.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u591a\u7ef4\u8bc4\u4f30\uff08\u5305\u542b\u5ba2\u89c2\u4e0e\u4e3b\u89c2\u6807\u51c6\uff09\u548c\u5206\u9636\u6bb5\u4f18\u5316\u7684LLM\u8fa9\u8bba\u6846\u67b6\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u4e0e\u4e13\u5bb6\u5224\u65ad\u7684\u4e00\u81f4\u6027\u548c\u8fa9\u8bba\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8fa9\u8bba\u4efb\u52a1\u4e0a\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u4e3b\u8981\u5173\u6ce8\u4e8e\u5bf9\u5177\u4f53\u8bba\u70b9\u505a\u51fa\u56de\u5e94\uff0c\u5ffd\u7565\u4e86\u771f\u5b9e\u6027\u548c\u903b\u8f91\u6709\u6548\u6027\u7b49\u5ba2\u89c2\u8bc4\u4f30\uff0c\u540c\u65f6\u7f3a\u4e4f\u8de8\u591a\u4e2a\u7ef4\u5ea6\u7684\u7ed3\u6784\u5316\u4f18\u5316\u65b9\u6cd5\uff0c\u5f71\u54cd\u4e86\u6574\u4f53\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u7ec4\u4ef6\u6846\u67b6\uff1a\uff081\uff09InspireScore\uff1a\u591a\u7ef4\u5ea6\u8bc4\u5206\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86\u56db\u4e2a\u4e3b\u89c2\u6807\u51c6\uff08\u60c5\u611f\u5438\u5f15\u529b\u3001\u8bba\u70b9\u6e05\u6670\u5ea6\u3001\u8bba\u70b9\u5b89\u6392\u3001\u4e3b\u9898\u76f8\u5173\u6027\uff09\u548c\u4e24\u4e2a\u5ba2\u89c2\u6807\u51c6\uff08\u4e8b\u5b9e\u771f\u5b9e\u6027\u4e0e\u903b\u8f91\u6709\u6548\u6027\uff09\uff1b\uff082\uff09InspireDebate\uff1a\u901a\u8fc7\u5206\u9636\u6bb5\u4f18\u5316\uff0c\u5305\u62ec\u94fe\u5f0f\u601d\u8003\uff08CoT\uff09\u63a8\u7406\u3001\u591a\u7ef4\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\uff0c\u4ee5\u53ca\u57fa\u4e8eWeb\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08Web-RAG\uff09\u7684\u5b9e\u65f6\u77e5\u8bc6\u652f\u6301\uff0c\u4f18\u5316\u591a\u8f6e\u8fa9\u8bba\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cInspireScore\u4e0e\u4e13\u5bb6\u8bc4\u5224\u7684\u76f8\u5173\u6027\u63d0\u5347\u4e8644%\uff1bInspireDebate\u5728\u5404\u9879\u8868\u73b0\u4e0a\u6bd4\u57fa\u7ebf\u6a21\u578b\u9ad857%\u3002", "conclusion": "\u63d0\u51fa\u7684InspireScore \u548c InspireDebate\u6846\u67b6\u5728\u4e3b\u89c2\u548c\u5ba2\u89c2\u591a\u7ef4\u8bc4\u4f30\u3001\u63a8\u7406\u80fd\u529b\u4f18\u5316\u4ee5\u53ca\u77e5\u8bc6\u652f\u6491\u7b49\u65b9\u9762\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u8fa9\u8bba\u7cfb\u7edf\u7684\u7efc\u5408\u8868\u73b0\u3002"}}
{"id": "2506.18777", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.18777", "abs": "https://arxiv.org/abs/2506.18777", "authors": ["Jonathan Cook", "Silvia Sapora", "Arash Ahmadian", "Akbir Khan", "Tim Rocktaschel", "Jakob Foerster", "Laura Ruis"], "title": "Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training", "comment": null, "summary": "Training large language models (LLMs) on source code significantly enhances\ntheir general-purpose reasoning abilities, but the mechanisms underlying this\ngeneralisation are poorly understood. In this paper, we propose Programming by\nBackprop (PBB) as a potential driver of this effect - teaching a model to\nevaluate a program for inputs by training on its source code alone, without\never seeing I/O examples. To explore this idea, we finetune LLMs on two sets of\nprograms representing simple maths problems and algorithms: one with source\ncode and I/O examples (w/ IO), the other with source code only (w/o IO). We\nfind evidence that LLMs have some ability to evaluate w/o IO programs for\ninputs in a range of experimental settings, and make several observations.\nFirstly, PBB works significantly better when programs are provided as code\nrather than semantically equivalent language descriptions. Secondly, LLMs can\nproduce outputs for w/o IO programs directly, by implicitly evaluating the\nprogram within the forward pass, and more reliably when stepping through the\nprogram in-context via chain-of-thought. We further show that PBB leads to more\nrobust evaluation of programs across inputs than training on I/O pairs drawn\nfrom a distribution that mirrors naturally occurring data. Our findings suggest\na mechanism for enhanced reasoning through code training: it allows LLMs to\ninternalise reusable algorithmic abstractions. Significant scope remains for\nfuture work to enable LLMs to more effectively learn from symbolic procedures,\nand progress in this direction opens other avenues like model alignment by\ntraining on formal constitutional principles.", "AI": {"tldr": "\u901a\u8fc7\u5fae\u8c03LLMs\u4ec5\u4f9d\u8d56\u7a0b\u5e8f\u6e90\u7801\uff08\u65e0\u9700I/O\u4f8b\u5b50\uff09\u8fdb\u884c\u63a8\u7406\u53ef\u63d0\u5347\u901a\u7528\u63a8\u7406\u80fd\u529b\uff0c\u6a21\u578b\u53ef\u5185\u5316\u7b97\u6cd5\u62bd\u8c61\uff0c\u6307\u5411\u66f4\u5f3a\u7b26\u53f7\u63a8\u7406\u548c\u6a21\u578b\u5bf9\u9f50\u65b9\u5411\u3002", "motivation": "\u4ee3\u7801\u8bad\u7ec3\u80fd\u663e\u8457\u63d0\u5347LLMs\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u5176\u80cc\u540e\u673a\u7406\u3002\u4e3a\u63a2\u7a76\u662f\u5426\u901a\u8fc7\u4ec5\u6e90\u7801\u8bad\u7ec3\u4e5f\u80fd\u8d4b\u4e88\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u51faPBB\u65b9\u6cd5\u5e76\u5f00\u5c55\u5b9e\u9a8c\u3002", "method": "\u5c06LLMs\u5728\u4e24\u7ec4\u7a0b\u5e8f\u4e0a\u5fae\u8c03\uff1a\u4e00\u7ec4\u4e3a\u6e90\u7801+I/O\u4f8b\u5b50\uff08w/ IO\uff09\uff0c\u4e00\u7ec4\u4ec5\u6709\u6e90\u7801\uff08w/o IO\uff09\uff0c\u5bf9\u6bd4\u4e8c\u8005\u5728\u63a8\u7406\u4e0e\u8bc4\u4f30\u80fd\u529b\u65b9\u9762\u7684\u8868\u73b0\u5dee\u5f02\u3002", "result": "LLMs\u5728\u672a\u89c1\u8fc7I/O\u7684\u7a0b\u5e8f\u4e0a\u4e5f\u80fd\u76f4\u63a5\u8f93\u51fa\uff0c\u5c24\u5176\u5728\u4ee3\u7801\u800c\u975e\u8bed\u8a00\u63cf\u8ff0\u5f62\u5f0f\u66f4\u663e\u8457\uff0c\u4e14\u901a\u8fc7\u94fe\u5f0f\u601d\u8003\u63d0\u5347\u8868\u73b0\u3002PBB\u65b9\u5f0f\u8f83\u57fa\u4e8e\u5206\u5e03\u5f0fI/O\u8bad\u7ec3\u66f4\u9c81\u68d2\u3002", "conclusion": "PBB\uff08\u901a\u8fc7\u6e90\u7801\u8bad\u7ec3\u800c\u975eI/O\u5b9e\u4f8b\uff09\u53ef\u4fc3\u4f7fLLMs\u5b66\u4e60\u53ef\u590d\u7528\u7684\u7b97\u6cd5\u62bd\u8c61\uff0c\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002\u901a\u8fc7\u4ee3\u7801\u8bad\u7ec3\u80fd\u591f\u4f7f\u6a21\u578b\u5728\u5904\u7406\u53d8\u52a8\u8f93\u5165\u65f6\u66f4\u4e3a\u9c81\u68d2\uff0c\u6b64\u65b9\u5411\u4e3a\u6a21\u578b\u5bf9\u7b26\u53f7\u6027\u8fc7\u7a0b\u5b66\u4e60\u4e0e\u5bf9\u51c6\u7b49\u4efb\u52a1\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2506.18105", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18105", "abs": "https://arxiv.org/abs/2506.18105", "authors": ["Yicheng Fu", "Zhemin Huang", "Liuxin Yang", "Yumeng Lu", "Zhongdongming Dai"], "title": "Chengyu-Bench: Benchmarking Large Language Models for Chinese Idiom Understanding and Use", "comment": null, "summary": "Chinese idioms (Chengyu) are concise four-character expressions steeped in\nhistory and culture, whose literal translations often fail to capture their\nfull meaning. This complexity makes them challenging for language models to\ninterpret and use correctly. Existing benchmarks focus on narrow tasks -\nmultiple-choice cloze tests, isolated translation, or simple paraphrasing. We\nintroduce Chengyu-Bench, a comprehensive benchmark featuring three tasks: (1)\nEvaluative Connotation, classifying idioms as positive or negative; (2)\nAppropriateness, detecting incorrect idiom usage in context; and (3) Open\nCloze, filling blanks in longer passages without options. Chengyu-Bench\ncomprises 2,937 human-verified examples covering 1,765 common idioms sourced\nfrom diverse corpora. We evaluate leading LLMs and find they achieve over 95%\naccuracy on Evaluative Connotation, but only ~85% on Appropriateness and ~40%\ntop-1 accuracy on Open Cloze. Error analysis reveals that most mistakes arise\nfrom fundamental misunderstandings of idiom meanings. Chengyu-Bench\ndemonstrates that while LLMs can reliably gauge idiom sentiment, they still\nstruggle to grasp the cultural and contextual nuances essential for proper\nusage. The benchmark and source code are available at:\nhttps://github.com/sofyc/ChengyuBench.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9762\u5411\u6210\u8bed\u7406\u89e3\u548c\u4f7f\u7528\u7684\u7efc\u5408\u6027\u57fa\u51c6Chengyu-Bench\uff0c\u8bc4\u4f30\u53d1\u73b0\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u5224\u522b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u6210\u8bed\u8bed\u5883\u6070\u5f53\u6027\u53ca\u5f00\u653e\u5f0f\u586b\u7a7a\u4efb\u52a1\u4e2d\u4ecd\u7136\u6548\u679c\u6709\u9650\uff0c\u51f8\u663e\u51fa\u6210\u8bed\u8bed\u4e49\u548c\u6587\u5316\u7406\u89e3\u662f\u6a21\u578b\u7684\u77ed\u677f\u3002", "motivation": "\u6c49\u8bed\u6210\u8bed\u5bcc\u542b\u5386\u53f2\u548c\u6587\u5316\u5185\u6db5\uff0c\u4f46\u5b57\u9762\u7ffb\u8bd1\u5e38\u65e0\u6cd5\u51c6\u786e\u8fd8\u539f\u5176\u610f\u4e49\uff0c\u5bfc\u81f4\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u96be\u4ee5\u6709\u6548\u7406\u89e3\u548c\u8fd0\u7528\u3002\u73b0\u6709\u6210\u8bed\u6d4b\u8bd5\u57fa\u51c6\u6570\u636e\u96c6\u5c40\u9650\u4e8e\u72ed\u7a84\u4efb\u52a1\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u7684\u771f\u5b9e\u80fd\u529b\u3002", "method": "\u63d0\u51faChengyu-Bench\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4e09\u7c7b\u4efb\u52a1\uff1a(1) \u6210\u8bed\u8912\u8d2c\u5206\u7c7b\uff1b(2) \u8bed\u5883\u4e0b\u6210\u8bed\u4f7f\u7528\u6070\u5f53\u6027\u68c0\u6d4b\uff1b(3) \u957f\u6587\u586b\u7a7a\u7684\u5f00\u653e\u5f0f\u6210\u8bed\u586b\u7a7a\u3002\u6570\u636e\u96c6\u75312937\u4e2a\u4eba\u5de5\u9a8c\u8bc1\u6837\u4f8b\u7ec4\u6210\uff0c\u6d89\u53ca1765\u4e2a\u5e38\u7528\u6210\u8bed\uff0c\u6765\u6e90\u591a\u5143\u3002\u8bc4\u6d4b\u4e3b\u6d41LLMs\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u8fdb\u884c\u9519\u8bef\u5206\u6790\u3002", "result": "\u5f53\u524d\u4e3b\u6d41LLMs\u5728\u6210\u8bed\u8912\u8d2c\u5206\u7c7b\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u8d85\u8fc795%\uff0c\u5728\u4f7f\u7528\u6070\u5f53\u6027\u68c0\u6d4b\u4efb\u52a1\u7ea685%\uff0c\u5728\u5f00\u653e\u5f0f\u586b\u7a7a\u7684top-1\u51c6\u786e\u7387\u4ec5\u7ea640%\u3002\u8bef\u5dee\u5206\u6790\u8868\u660e\uff0c\u5927\u90e8\u5206\u9519\u8bef\u6e90\u4e8e\u5bf9\u6210\u8bed\u610f\u4e49\u7684\u6839\u672c\u8bef\u89e3\u3002", "conclusion": "Chengyu-Bench\u8bc1\u5b9e\uff0c\u867d\u7136LLMs\u80fd\u8f83\u597d\u5224\u65ad\u6210\u8bed\u60c5\u611f\uff0c\u4f46\u5728\u7406\u89e3\u6210\u8bed\u6df1\u5c42\u6587\u5316\u4e0e\u8bed\u5883\u4f7f\u7528\u65b9\u9762\u4ecd\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff1b\u8be5\u57fa\u51c6\u6570\u636e\u96c6\u4e3a\u540e\u7eed\u6210\u8bed\u7406\u89e3\u4e0e\u5e94\u7528\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2506.18783", "categories": ["cs.AI", "cs.MA", "68T07", "I.2.11; I.2.7; I.2.8"], "pdf": "https://arxiv.org/pdf/2506.18783", "abs": "https://arxiv.org/abs/2506.18783", "authors": ["Kamil Szczepanik", "Jaros\u0142aw A. Chudziak"], "title": "TRIZ Agents: A Multi-Agent LLM Approach for TRIZ-Based Innovation", "comment": "12 pages, 10 figures, 2 tables, Accepted at the 17th International\n  Conference on Agents and Artificial Intelligence (ICAART 2025). Final version\n  published in Proceedings of ICAART 2025 (Vol. 1), pages 196-207", "summary": "TRIZ, the Theory of Inventive Problem Solving, is a structured,\nknowledge-based framework for innovation and abstracting problems to find\ninventive solutions. However, its application is often limited by the\ncomplexity and deep interdisciplinary knowledge required. Advancements in Large\nLanguage Models (LLMs) have revealed new possibilities for automating parts of\nthis process. While previous studies have explored single LLMs in TRIZ\napplications, this paper introduces a multi-agent approach. We propose an\nLLM-based multi-agent system, called TRIZ agents, each with specialized\ncapabilities and tool access, collaboratively solving inventive problems based\non the TRIZ methodology. This multi-agent system leverages agents with various\ndomain expertise to efficiently navigate TRIZ steps. The aim is to model and\nsimulate an inventive process with language agents. We assess the effectiveness\nof this team of agents in addressing complex innovation challenges based on a\nselected case study in engineering. We demonstrate the potential of agent\ncollaboration to produce diverse, inventive solutions. This research\ncontributes to the future of AI-driven innovation, showcasing the advantages of\ndecentralized problem-solving in complex ideation tasks.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53TRIZ\u7cfb\u7edf\uff0c\u901a\u8fc7\u534f\u4f5c\u9ad8\u6548\u89e3\u51b3\u590d\u6742\u521b\u65b0\u95ee\u9898\uff0c\u5c55\u793a\u4e86AI\u8d4b\u80fd\u5206\u5e03\u5f0f\u521b\u65b0\u7684\u524d\u666f\u3002", "motivation": "TRIZ\u7406\u8bba\u4e3a\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u6846\u67b6\uff0c\u4f46\u5176\u5b9e\u9645\u5e94\u7528\u53d7\u9650\u4e8e\u6240\u9700\u7684\u590d\u6742\u6027\u548c\u591a\u5b66\u79d1\u77e5\u8bc6\u3002\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6280\u672f\u7684\u53d1\u5c55\uff0c\u81ea\u52a8\u5316TRIZ\u6d41\u7a0b\u7684\u53ef\u80fd\u6027\u51fa\u73b0\uff0c\u56e0\u6b64\u4f5c\u8005\u5e0c\u671b\u7a81\u7834TRIZ\u5e94\u7528\u95e8\u69db\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08TRIZ agents\uff09\uff0c\u5229\u7528\u591a\u4e2a\u5177\u5907\u4e0d\u540c\u4e13\u4e1a\u9886\u57df\u77e5\u8bc6\u548c\u5de5\u5177\u63a5\u5165\u80fd\u529b\u7684LLM\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u57fa\u4e8eTRIZ\u65b9\u6cd5\u8bba\u5171\u540c\u89e3\u51b3\u521b\u65b0\u6027\u95ee\u9898\u3002\u901a\u8fc7\u5728\u7279\u5b9a\u5de5\u7a0b\u6848\u4f8b\u4e2d\u6a21\u62df\u548c\u9a8c\u8bc1\u591a\u667a\u80fd\u4f53\u56e2\u961f\u534f\u4f5c\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\u3002", "result": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u534f\u540c\u9ad8\u6548\u5730\u63a8\u8fdbTRIZ\u6b65\u9aa4\uff0c\u5e76\u80fd\u5728\u590d\u6742\u521b\u65b0\u6311\u6218\u4e2d\u4ea7\u51fa\u591a\u6837\u5316\u4e14\u5177\u6709\u521b\u65b0\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u667a\u80fd\u4f53\u534f\u4f5c\u5728\u590d\u6742\u521b\u65b0\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5728\u521b\u65b0\u95ee\u9898\u6c42\u89e3\u4e0a\u5c55\u73b0\u51fa\u5206\u5e03\u5f0f\u534f\u4f5c\u548c\u521b\u65b0\u80fd\u529b\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8AI\u9a71\u52a8\u7684\u521b\u65b0\u8fdb\u7a0b\uff0c\u662f\u590d\u6742\u95ee\u9898\u53bb\u4e2d\u5fc3\u5316\u89e3\u51b3\u7684\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2506.18810", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.18810", "abs": "https://arxiv.org/abs/2506.18810", "authors": ["Siao Tang", "Xinyin Ma", "Gongfan Fang", "Xinchao Wang"], "title": "ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation", "comment": "Codes are available at https://github.com/tsa18/ConciseHint", "summary": "Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and\nOpenAI o1 series have achieved notable performance enhancements on complex\nreasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).\nHowever, an emerging issue is their inclination to produce excessively verbose\nreasoning processes, leading to the inefficiency problem. Existing literature\non improving efficiency mainly adheres to the before-reasoning paradigms such\nas prompting and reasoning or fine-tuning and reasoning, but ignores the\npromising direction of directly encouraging the model to speak concisely by\nintervening during the generation of reasoning. In order to fill the blank, we\npropose a framework dubbed ConciseHint, which continuously encourages the\nreasoning model to speak concisely by injecting the textual hint (manually\ndesigned or trained on the concise data) during the token generation of the\nreasoning process. Besides, ConciseHint is adaptive to the complexity of the\nquery by adaptively adjusting the hint intensity, which ensures it will not\nundermine model performance. Experiments on the state-of-the-art LRMs,\nincluding DeepSeek-R1 and Qwen-3 series, demonstrate that our method can\neffectively produce concise reasoning processes while maintaining performance\nwell. For instance, we achieve a reduction ratio of 65\\% for the reasoning\nlength on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u63a8\u7406\u751f\u6210\u65f6\u52a8\u6001\u6ce8\u5165\u7b80\u6d01\u63d0\u793a\u7684ConciseHint\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u7f29\u77ed\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u5185\u5bb9\u957f\u5ea6\uff0c\u5e76\u4fdd\u6301\u4efb\u52a1\u51c6\u786e\u7387\uff0c\u5b9e\u73b0\u6548\u7387\u4e0e\u6027\u80fd\u517c\u5f97\u3002", "motivation": "\u8fd1\u5e74\u6765\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u901a\u8fc7\u6269\u5c55Chain-of-Thought\uff08CoT\uff09\u751f\u6210\u957f\u5ea6\uff0c\u63d0\u5347\u4e86\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u8868\u73b0\u3002\u4f46\u6a21\u578b\u9010\u6e10\u503e\u5411\u4e8e\u751f\u6210\u5197\u957f\u63a8\u7406\u8fc7\u7a0b\uff0c\u5bfc\u81f4\u6548\u7387\u4e0b\u964d\u3002\u73b0\u6709\u63d0\u5347\u6548\u7387\u7684\u65b9\u6cd5\u591a\u5173\u6ce8\u63a8\u7406\u524d\u7684\u6280\u5de7\u5982Prompt\u8bbe\u8ba1\u6216\u5fae\u8c03\uff0c\u9c9c\u6709\u7814\u7a76\u5728\u63a8\u7406\u751f\u6210\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u7b80\u6d01\u8868\u8fbe\u3002\u4e9f\u9700\u63a2\u7d22\u80fd\u5728\u63a8\u7406\u751f\u6210\u4e2d\u76f4\u63a5\u9f13\u52b1\u7b80\u6d01\u6027\u7684\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aConciseHint\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u63a8\u7406\u751f\u6210\u8fc7\u7a0b\u4e2d\u6ce8\u5165\u6587\u672c\u63d0\u793a\uff08\u53ef\u624b\u5de5\u8bbe\u8ba1\u6216\u57fa\u4e8e\u7b80\u6d01\u6570\u636e\u8bad\u7ec3\u83b7\u5f97\uff09\uff0c\u6301\u7eed\u9f13\u52b1\u6a21\u578b\u7b80\u6d01\u8868\u8ff0\u3002\u6b64\u65b9\u6cd5\u8fd8\u53ef\u6839\u636e\u67e5\u8be2\u590d\u6742\u5ea6\u81ea\u9002\u5e94\u8c03\u6574\u63d0\u793a\u5f3a\u5ea6\uff0c\u786e\u4fdd\u4e0d\u4f1a\u524a\u5f31\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728\u5305\u62ecDeepSeek-R1\u4e0eQwen-3\u7cfb\u5217\u7b49\u6700\u65b0LRMs\u4e0a\u9a8c\u8bc1\u4e86ConciseHint\u7684\u6709\u6548\u6027\u3002\u4ee5Qwen-3 4B\u5728GSM8K\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u4f8b\uff0c\u63a8\u7406\u8fc7\u7a0b\u957f\u5ea6\u964d\u4f4e65%\uff0c\u4e14\u51e0\u4e4e\u65e0\u51c6\u786e\u7387\u635f\u5931\u3002", "conclusion": "ConciseHint\u6846\u67b6\u80fd\u6709\u6548\u7f29\u77ed\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u8868\u8ff0\u957f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4f18\u5f02\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u5197\u957f\u63a8\u7406\u5e26\u6765\u7684\u6548\u7387\u95ee\u9898\uff0c\u5bf9\u751f\u6210\u5f0f\u63a8\u7406\u6a21\u578b\u5b9e\u9645\u5e94\u7528\u5177\u6709\u91cd\u8981\u6539\u8fdb\u4ef7\u503c\u3002"}}
{"id": "2506.18120", "categories": ["cs.CL", "68T50", "I.2.7; I.2.6; H.3.1"], "pdf": "https://arxiv.org/pdf/2506.18120", "abs": "https://arxiv.org/abs/2506.18120", "authors": ["Tom S Juzek"], "title": "The Syntactic Acceptability Dataset (Preview): A Resource for Machine Learning and Linguistic Analysis of English", "comment": "Accepted and published at LREC-COLING 2024. 8 pages, 3 figures.\n  Licensed under CC BY-NC-SA 4.0", "summary": "We present a preview of the Syntactic Acceptability Dataset, a resource being\ndesigned for both syntax and computational linguistics research. In its current\nform, the dataset comprises 1,000 English sequences from the syntactic\ndiscourse: Half from textbooks and half from the journal Linguistic Inquiry,\nthe latter to ensure a representation of the contemporary discourse. Each entry\nis labeled with its grammatical status (\"well-formedness\" according to\nsyntactic formalisms) extracted from the literature, as well as its\nacceptability status (\"intuitive goodness\" as determined by native speakers)\nobtained through crowdsourcing, with highest experimental standards. Even in\nits preliminary form, this dataset stands as the largest of its kind that is\npublicly accessible. We also offer preliminary analyses addressing three\ndebates in linguistics and computational linguistics: We observe that\ngrammaticality and acceptability judgments converge in about 83% of the cases\nand that \"in-betweenness\" occurs frequently. This corroborates existing\nresearch. We also find that while machine learning models struggle with\npredicting grammaticality, they perform considerably better in predicting\nacceptability. This is a novel finding. Future work will focus on expanding the\ndataset.", "AI": {"tldr": "\u672c\u6587\u53d1\u5e03\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u82f1\u8bed\u8bed\u6cd5\u53ef\u63a5\u53d7\u6027\u6570\u636e\u96c6\uff0c\u5e76\u63ed\u793a\u4e86\u8bed\u6cd5\u6027\u4e0e\u53ef\u63a5\u53d7\u6027\u5927\u591a\u4e00\u81f4\uff0c\u4f46\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u53ef\u63a5\u53d7\u6027\u4f18\u4e8e\u8bed\u6cd5\u6027\u3002", "motivation": "\u5f53\u524d\u8bed\u6cd5\u53ef\u63a5\u53d7\u6027\u6570\u636e\u96c6\u8f83\u5c11\uff0c\u4e14\u5bf9\u8bed\u6cd5\u548c\u53ef\u63a5\u53d7\u6027\u7684\u5173\u7cfb\u7f3a\u4e4f\u5927\u89c4\u6a21\u5206\u6790\uff1b\u9700\u8981\u65b0\u7684\u6570\u636e\u8d44\u6e90\u652f\u6301\u76f8\u5173\u8ba1\u7b97\u8bed\u8a00\u5b66\u548c\u53e5\u6cd5\u5b66\u7814\u7a76\u3002", "method": "\u4ece\u6559\u79d1\u4e66\u548c\u300aLinguistic Inquiry\u300b\u671f\u520a\u91c7\u96c61000\u6761\u82f1\u8bed\u53e5\u5b50\uff08\u5404\u4e00\u534a\uff09\uff0c\u5206\u522b\u6807\u6ce8\u53e5\u6cd5\u5f62\u5f0f\u4e2d\u7684\u8bed\u6cd5\u6b63\u786e\u6027\u548c\u901a\u8fc7\u4f17\u5305\u83b7\u5f97\u7684\u6bcd\u8bed\u8005\u53ef\u63a5\u53d7\u6027\uff0c\u5e76\u8fdb\u884c\u521d\u6b65\u7edf\u8ba1\u548c\u5bf9\u6bd4\u5206\u6790\u3002\u8fd8\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9\u8fd9\u4e24\u7c7b\u6807\u6ce8\u8fdb\u884c\u4e86\u9884\u6d4b\u80fd\u529b\u6d4b\u8bd5\u3002", "result": "\u6570\u636e\u96c6\u4e2d\u8bed\u6cd5\u6027\u4e0e\u53ef\u63a5\u53d7\u6027\u5728\u7ea683%\u60c5\u51b5\u4e0b\u76f8\u7b26\uff0c\u4e14\u2018\u4ecb\u4e8e\u4e24\u8005\u4e4b\u95f4\u2019\u7684\u60c5\u51b5\u8f83\u591a\uff0c\u652f\u6301\u65e2\u6709\u7814\u7a76\u3002\u540c\u65f6\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u8bed\u6cd5\u6027\u8868\u73b0\u8f83\u5dee\uff0c\u4f46\u9884\u6d4b\u53ef\u63a5\u53d7\u6027\u8868\u73b0\u8f83\u597d\uff0c\u63d0\u51fa\u4e86\u65b0\u53d1\u73b0\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u76ee\u524d\u4e3a\u540c\u7c7b\u6700\u5927\u516c\u5f00\u6570\u636e\u96c6\uff0c\u4e3a\u7814\u7a76\u8bed\u6cd5\u6027\u4e0e\u53ef\u63a5\u53d7\u6027\u53ca\u4e8c\u8005\u4e4b\u95f4\u5173\u7cfb\u7b49\u63d0\u4f9b\u4e86\u6709\u529b\u8d44\u6e90\u3002\u672a\u6765\u5c06\u7ee7\u7eed\u6269\u5c55\u8be5\u6570\u636e\u96c6\u3002"}}
{"id": "2506.18887", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY", "I.2.7; I.2.6; I.2.1; D.3.3; C.4"], "pdf": "https://arxiv.org/pdf/2506.18887", "abs": "https://arxiv.org/abs/2506.18887", "authors": ["Vansh Sharma", "Venkat Raman"], "title": "Steering Conceptual Bias via Transformer Latent-Subspace Activation", "comment": null, "summary": "This work examines whether activating latent subspaces in language models\n(LLMs) can steer scientific code generation toward a specific programming\nlanguage. Five causal LLMs were first evaluated on scientific coding prompts to\nquantify their baseline bias among four programming languages. A static\nneuron-attribution method, perturbing the highest activated MLP weight for a\nC++ or CPP token, proved brittle and exhibited limited generalization across\nprompt styles and model scales. To address these limitations, a\ngradient-refined adaptive activation steering framework (G-ACT) was developed:\nper-prompt activation differences are clustered into a small set of steering\ndirections, and lightweight per-layer probes are trained and refined online to\nselect the appropriate steering vector. In LLaMA-3.2 3B, this approach reliably\nbiases generation towards the CPP language by increasing the average probe\nclassification accuracy by 15% and the early layers (0-6) improving the probe\nclassification accuracy by 61.5% compared to the standard ACT framework. For\nLLaMA-3.3 70B, where attention-head signals become more diffuse, targeted\ninjections at key layers still improve language selection. Although per-layer\nprobing introduces a modest inference overhead, it remains practical by\nsteering only a subset of layers and enables reproducible model behavior. These\nresults demonstrate a scalable, interpretable and efficient mechanism for\nconcept-level control for practical agentic systems.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u79d1\u5b66\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u7f16\u7a0b\u8bed\u8a00\u504f\u5411\u63a7\u5236\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u68af\u5ea6\u4f18\u5316\u548c\u52a8\u6001\u63a2\u9488\u7684\u81ea\u9002\u5e94\u6fc0\u6d3b\u5f15\u5bfc\u65b9\u6cd5\uff08G-ACT\uff09\uff0c\u5728\u4e0d\u540c\u89c4\u6a21\u7684LLMs\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u8f93\u51fa\u7684\u76ee\u6807\u8bed\u8a00\u4e00\u81f4\u6027\u548c\u6a21\u578b\u53ef\u63a7\u6027\u3002", "motivation": "\u5728\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u79d1\u5b66\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u5b58\u5728\u5bf9\u7279\u5b9a\u7f16\u7a0b\u8bed\u8a00\u7684\u751f\u6210\u504f\u5411\uff0c\u4f46\u5982\u4f55\u9ad8\u6548\u3001\u7cbe\u786e\u5730\u64cd\u63a7\u6a21\u578b\u751f\u6210\u7279\u5b9a\u7f16\u7a0b\u8bed\u8a00\u7684\u6587\u672c\u4ecd\u6709\u6311\u6218\u3002\u6b64\u524d\u7684\u64cd\u63a7\u65b9\u6cd5\u6cdb\u5316\u6027\u548c\u7a33\u5b9a\u6027\u4e0d\u8db3\u3002", "method": "\u9996\u5148\u8bc4\u4f30LLMs\u5728\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\uff08\u5982C++\u7b49\uff09\u79d1\u5b66\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u57fa\u7ebf\u504f\u5411\uff1b\u7136\u540e\u91c7\u7528\u9759\u6001\u795e\u7ecf\u5143\u5f52\u56e0\u65b9\u6cd5\u5bf9\u6a21\u578b\u6fc0\u6d3b\u8fdb\u884c\u64cd\u4f5c\uff0c\u53d1\u73b0\u5176\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff1b\u4e3a\u6b64\u63d0\u51fa\u4e86\u4e00\u79cd\u68af\u5ea6\u7cbe\u70bc\u7684\u81ea\u9002\u5e94\u6fc0\u6d3b\u5f15\u5bfc\u6846\u67b6\uff08G-ACT\uff09\uff0c\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u63d0\u793a\u7684\u6fc0\u6d3b\u5dee\u5f02\u805a\u7c7b\uff0c\u8bad\u7ec3\u8f7b\u91cf\u5316\u7684\u5c42\u5185\u63a2\u9488\u5728\u7ebf\u9009\u53d6\u9002\u5f53\u7684\u64cd\u63a7\u5411\u91cf\uff0c\u4ece\u800c\u52a8\u6001\u5730\u5f15\u5bfc\u751f\u6210\u3002", "result": "G-ACT\u65b9\u6cd5\u5728LLaMA-3.2 3B\u6a21\u578b\u4e0a\u5c06\u63a2\u9488\u5206\u7c7b\u51c6\u786e\u7387\u63d0\u9ad8\u4e8615%\uff0c\u5728\u65e9\u671f\u5c42\uff080-6\u5c42\uff09\u63d0\u5347\u4e8661.5%\uff0c\u8f83\u6807\u51c6\u7684ACT\u6846\u67b6\u6709\u663e\u8457\u6539\u8fdb\u3002\u5728\u66f4\u5927\u53c2\u6570\u91cf\u7684LLaMA-3.3 70B\u4e0a\uff0c\u5173\u952e\u5c42\u7684\u5b9a\u5411\u6ce8\u5165\u4f9d\u7136\u6539\u5584\u4e86\u8bed\u8a00\u9009\u62e9\u3002\u8be5\u65b9\u6cd5\u9644\u52a0\u7684\u63a8\u7406\u5f00\u9500\u8f83\u5c0f\uff0c\u5e76\u63d0\u5347\u4e86\u6a21\u578b\u53ef\u63a7\u6027\u548c\u884c\u4e3a\u53ef\u590d\u73b0\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684G-ACT\u6846\u67b6\u80fd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u5730\u5b9e\u73b0\u5bf9\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65f6\u7684\u7f16\u7a0b\u8bed\u8a00\u504f\u5411\u63a7\u5236\uff0c\u5177\u6709\u8f83\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.17303", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17303", "abs": "https://arxiv.org/abs/2506.17303", "authors": ["Rishi Bommasani", "Scott R. Singer", "Ruth E. Appel", "Sarah Cen", "A. Feder Cooper", "Elena Cryst", "Lindsey A. Gailmard", "Ian Klaus", "Meredith M. Lee", "Inioluwa Deborah Raji", "Anka Reuel", "Drew Spence", "Alexander Wan", "Angelina Wang", "Daniel Zhang", "Daniel E. Ho", "Percy Liang", "Dawn Song", "Joseph E. Gonzalez", "Jonathan Zittrain", "Jennifer Tour Chayes", "Mariano-Florentino Cuellar", "Li Fei-Fei"], "title": "The California Report on Frontier AI Policy", "comment": "Authored by the Joint California Policy Working Group on AI Frontier\n  Models", "summary": "The innovations emerging at the frontier of artificial intelligence (AI) are\npoised to create historic opportunities for humanity but also raise complex\npolicy challenges. Continued progress in frontier AI carries the potential for\nprofound advances in scientific discovery, economic productivity, and broader\nsocial well-being. As the epicenter of global AI innovation, California has a\nunique opportunity to continue supporting developments in frontier AI while\naddressing substantial risks that could have far reaching consequences for the\nstate and beyond. This report leverages broad evidence, including empirical\nresearch, historical analysis, and modeling and simulations, to provide a\nframework for policymaking on the frontier of AI development. Building on this\nmultidisciplinary approach, this report derives policy principles that can\ninform how California approaches the use, assessment, and governance of\nfrontier AI: principles rooted in an ethos of trust but verify. This approach\ntakes into account the importance of innovation while establishing appropriate\nstrategies to reduce material risks.", "AI": {"tldr": "\u672c\u62a5\u544a\u4e3a\u52a0\u5dde\u5982\u4f55\u5e73\u8861AI\u521b\u65b0\u4e0e\u98ce\u9669\u6cbb\u7406\u63d0\u51fa\u4e86\u591a\u5143\u5316\u3001\u53ef\u64cd\u4f5c\u7684\u653f\u7b56\u539f\u5219\u4e0e\u6846\u67b6\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u524d\u6cbf\u521b\u65b0\u5e26\u6765\u5de8\u5927\u673a\u9047\uff0c\u4f46\u4e5f\u5f15\u53d1\u590d\u6742\u653f\u7b56\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u63a8\u52a8\u521b\u65b0\u4e0e\u9632\u8303\u98ce\u9669\u4e4b\u95f4\u5982\u4f55\u53d6\u5f97\u5e73\u8861\u3002\u4f5c\u4e3a\u5168\u7403AI\u521b\u65b0\u4e2d\u5fc3\uff0c\u52a0\u5dde\u9700\u8981\u5e94\u5bf9\u4e0eAI\u53d1\u5c55\u76f8\u5173\u7684\u6f5c\u5728\u98ce\u9669\uff0c\u5e76\u5236\u5b9a\u9002\u5e94\u524d\u6cbfAI\u53d1\u5c55\u7684\u653f\u7b56\u6846\u67b6\u3002", "method": "\u672c\u62a5\u544a\u91c7\u7528\u591a\u5b66\u79d1\u65b9\u6cd5\uff0c\u7ed3\u5408\u5b9e\u8bc1\u7814\u7a76\u3001\u5386\u53f2\u5206\u6790\u3001\u5efa\u6a21\u4e0e\u4eff\u771f\u7b49\u591a\u79cd\u8bc1\u636e\uff0c\u63d0\u51fa\u4e86\u524d\u6cbfAI\u653f\u7b56\u5236\u5b9a\u6846\u67b6\uff0c\u5e76\u636e\u6b64\u63d0\u70bc\u51fa\u53ef\u4e3a\u52a0\u5ddeAI\u653f\u7b56\u63d0\u4f9b\u6307\u5bfc\u7684\u539f\u5219\u3002", "result": "\u62a5\u544a\u63d0\u51fa\u4e86\u57fa\u4e8e\u201c\u4fe1\u4efb\u4f46\u9a8c\u8bc1\u201d\u7406\u5ff5\u7684AI\u6cbb\u7406\u653f\u7b56\u539f\u5219\uff0c\u5f3a\u8c03\u5728\u652f\u6301AI\u521b\u65b0\u7684\u540c\u65f6\uff0c\u5efa\u7acb\u9002\u5f53\u98ce\u9669\u7ba1\u63a7\u63aa\u65bd\uff0c\u4ece\u800c\u51cf\u5c11\u5b9e\u8d28\u98ce\u9669\u3002", "conclusion": "\u52a0\u5dde\u53ef\u901a\u8fc7\u672c\u62a5\u544a\u63d0\u51fa\u7684\u591a\u5143\u8bc1\u636e\u548c\u7406\u5ff5\u6307\u5bfc\uff0c\u65e2\u4fc3\u8fdb\u524d\u6cbfAI\u521b\u65b0\uff0c\u53c8\u6709\u6548\u7ba1\u7406\u4e0e\u4e4b\u76f8\u5173\u7684\u91cd\u5927\u98ce\u9669\uff0c\u5b9e\u73b0\u521b\u65b0\u4e0e\u6cbb\u7406\u7684\u5e73\u8861\u3002"}}
{"id": "2506.17311", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17311", "abs": "https://arxiv.org/abs/2506.17311", "authors": ["Chuanlei Li", "Xu Hu", "Minghui Xu", "Kun Li", "Yue Zhang", "Xiuzhen Cheng"], "title": "Can Large Language Models Be Trusted Paper Reviewers? A Feasibility Study", "comment": null, "summary": "Academic paper review typically requires substantial time, expertise, and\nhuman resources. Large Language Models (LLMs) present a promising method for\nautomating the review process due to their extensive training data, broad\nknowledge base, and relatively low usage cost. This work explores the\nfeasibility of using LLMs for academic paper review by proposing an automated\nreview system. The system integrates Retrieval Augmented Generation (RAG), the\nAutoGen multi-agent system, and Chain-of-Thought prompting to support tasks\nsuch as format checking, standardized evaluation, comment generation, and\nscoring. Experiments conducted on 290 submissions from the WASA 2024 conference\nusing GPT-4o show that LLM-based review significantly reduces review time\n(average 2.48 hours) and cost (average \\$104.28 USD). However, the similarity\nbetween LLM-selected papers and actual accepted papers remains low (average\n38.6\\%), indicating issues such as hallucination, lack of independent judgment,\nand retrieval preferences. Therefore, it is recommended to use LLMs as\nassistive tools to support human reviewers, rather than to replace them.", "AI": {"tldr": "\u5229\u7528LLMs\u81ea\u52a8\u8bba\u6587\u8bc4\u5ba1\u53ef\u663e\u8457\u63d0\u9ad8\u6548\u7387\u3001\u964d\u4f4e\u6210\u672c\uff0c\u4f46\u8bc4\u5ba1\u7ed3\u679c\u4e0e\u5b9e\u9645\u5f55\u7528\u5dee\u5f02\u8f83\u5927\uff0c\u76ee\u524d\u9002\u5408\u8f85\u52a9\u4eba\u5de5\u800c\u975e\u53d6\u4ee3\u4eba\u5de5\u8bc4\u5ba1\u3002", "motivation": "\u5b66\u672f\u8bba\u6587\u8bc4\u5ba1\u8017\u65f6\u3001\u8981\u6c42\u9ad8\u7684\u4e13\u4e1a\u6027\u4e14\u9700\u8981\u5927\u91cf\u4eba\u529b\u8d44\u6e90\uff0c\u56e0\u6b64\u5e0c\u671b\u7528LLMs\u81ea\u52a8\u5316\u8bc4\u5ba1\u6d41\u7a0b\u4ee5\u964d\u4f4e\u6210\u672c\u5e76\u63d0\u5347\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u3001AutoGen\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u7684\u81ea\u52a8\u8bc4\u5ba1\u7cfb\u7edf\uff0c\u7528\u4e8e\u8bba\u6587\u683c\u5f0f\u68c0\u67e5\u3001\u6807\u51c6\u5316\u8bc4\u4f30\u3001\u8bc4\u8bba\u751f\u6210\u4ee5\u53ca\u6253\u5206\u3002\u5bf9290\u7bc7WASA 2024\u6295\u7a3f\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002", "result": "LLM\u81ea\u52a8\u8bc4\u5ba1\u5e73\u5747\u8017\u65f62.48\u5c0f\u65f6\u3001\u5e73\u5747\u6210\u672c104.28\u7f8e\u5143\uff0c\u5927\u5927\u4f4e\u4e8e\u4eba\u5de5\u3002\u4f46LLM\u9009\u62e9\u7684\u8bba\u6587\u4e0e\u5b9e\u9645\u5f55\u7528\u8bba\u6587\u7684\u4e00\u81f4\u6027\u4ec5\u4e3a38.6%\uff0c\u5b58\u5728\u5e7b\u89c9\u3001\u5224\u65ad\u529b\u4e0d\u8db3\u548c\u504f\u597d\u68c0\u7d22\u4fe1\u606f\u7b49\u95ee\u9898\u3002", "conclusion": "LLMs\u5728\u5b66\u672f\u8bba\u6587\u8bc4\u5ba1\u4e2d\u80fd\u591f\u663e\u8457\u964d\u4f4e\u65f6\u95f4\u548c\u8d39\u7528\uff0c\u4f46\u4e0e\u5b9e\u9645\u8bc4\u5ba1\u7ed3\u679c\u7684\u4e00\u81f4\u6027\u8f83\u4f4e\uff0c\u76ee\u524d\u4e0d\u5b9c\u5b8c\u5168\u66ff\u4ee3\u4eba\u5de5\u8bc4\u5ba1\uff0c\u5e94\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u4f7f\u7528\u3002"}}
{"id": "2506.17319", "categories": ["cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17319", "abs": "https://arxiv.org/abs/2506.17319", "authors": ["Shuangbao Paul Wang", "Lucas Yang", "Rahouane Chouchane", "Jin Guo", "Michael Bailey"], "title": "Using Machine Learning in Analyzing Air Quality Discrepancies of Environmental Impact", "comment": "IEEE 2024 International Conference on AI x Data & Knowledge\n  Engineering (AIxDKE)", "summary": "In this study, we apply machine learning and software engineering in\nanalyzing air pollution levels in City of Baltimore. The data model was fed\nwith three primary data sources: 1) a biased method of estimating insurance\nrisk used by homeowners loan corporation, 2) demographics of Baltimore\nresidents, and 3) census data estimate of NO2 and PM2.5 concentrations. The\ndataset covers 650,643 Baltimore residents in 44.7 million residents in 202\nmajor cities in US. The results show that air pollution levels have a clear\nassociation with the biased insurance estimating method. Great disparities\npresent in NO2 level between more desirable and low income blocks. Similar\ndisparities exist in air pollution level between residents' ethnicity. As\nBaltimore population consists of a greater proportion of people of color, the\nfinding reveals how decades old policies has continued to discriminate and\naffect quality of life of Baltimore citizens today.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u5206\u6790\u53d1\u73b0\uff0c\u5df4\u5c14\u7684\u6469\u5e02\u7684\u7a7a\u6c14\u6c61\u67d3\u4e0e\u5e26\u6709\u504f\u89c1\u7684\u4fdd\u9669\u98ce\u9669\u8bc4\u4f30\u5386\u53f2\u653f\u7b56\u5b58\u5728\u5bc6\u5207\u5173\u7cfb\uff0c\u4f4e\u6536\u5165\u548c\u6709\u8272\u4eba\u79cd\u793e\u533a\u9762\u4e34\u66f4\u4e25\u91cd\u7684\u6c61\u67d3\u95ee\u9898\uff0c\u8fd9\u53cd\u6620\u4e86\u5236\u5ea6\u6027\u4e0d\u516c\u5bf9\u5f53\u4ee3\u5c45\u6c11\u751f\u6d3b\u7684\u6df1\u8fdc\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u56e2\u961f\u5e0c\u671b\u63ed\u793a\u5df4\u5c14\u7684\u6469\uff08Baltimore\uff09\u57ce\u5e02\u4e2d\u7a7a\u6c14\u6c61\u67d3\u6c34\u5e73\u4e0e\u5386\u53f2\u4e0a\u5b58\u5728\u504f\u89c1\u7684\u4fdd\u9669\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63a2\u7a76\u73af\u5883\u6c61\u67d3\u4e0e\u793e\u4f1a\u7ecf\u6d4e\u3001\u79cd\u65cf\u56e0\u7d20\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "method": "\u91c7\u7528\u673a\u5668\u5b66\u4e60\u548c\u8f6f\u4ef6\u5de5\u7a0b\u65b9\u6cd5\uff0c\u6574\u5408\u4e09\u5927\u6570\u636e\u6e90\uff1a\u6709\u504f\u89c1\u7684\u4fdd\u9669\u98ce\u9669\u8bc4\u4f30\u6cd5\u3001\u5c45\u6c11\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u4ee5\u53caNO2\u548cPM2.5\u7684\u6c61\u67d3\u6570\u636e\uff0c\u5bf9\u8986\u76d6\u6574\u4e2a\u5df4\u5c14\u7684\u6469\u5e02\u53ca\u7f8e\u56fd\u4e3b\u8981\u57ce\u5e02\u5c45\u6c11\u7684\u6570\u636e\u8fdb\u884c\u5206\u6790\u3002", "result": "\u53d1\u73b0\u7a7a\u6c14\u6c61\u67d3\u6c34\u5e73\u4e0e\u5b58\u5728\u504f\u89c1\u7684\u4fdd\u9669\u8bc4\u4f30\u65b9\u6cd5\u5bc6\u5207\u76f8\u5173\u3002\u9ad8\u6536\u5165\u4e0e\u4f4e\u6536\u5165\u533a\u95f4NO2\u6c61\u67d3\u6c34\u5e73\u5b58\u5728\u660e\u663e\u5dee\u5f02\uff0c\u5c45\u6c11\u79cd\u65cf\u56e0\u7d20\u4e5f\u4e0e\u7a7a\u6c14\u6c61\u67d3\u5206\u5e03\u5bc6\u5207\u5173\u8054\u3002", "conclusion": "\u5386\u53f2\u6027\u7684\u653f\u7b56\u504f\u89c1\u6301\u7eed\u5f71\u54cd\u7740\u5df4\u5c14\u7684\u6469\u73b0\u4eca\u7684\u73af\u5883\u516c\u5e73\u4e0e\u5c45\u6c11\u751f\u6d3b\u8d28\u91cf\uff0c\u5bf9\u6709\u8272\u4eba\u79cd\u7684\u5f71\u54cd\u5c24\u4e3a\u7a81\u51fa\u3002"}}
{"id": "2506.17320", "categories": ["cs.CY", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17320", "abs": "https://arxiv.org/abs/2506.17320", "authors": ["Akash Awasthi", "Brandon V. Chang", "Anh M. Vu", "Ngan Le", "Rishi Agrawal", "Zhigang Deng", "Carol Wu", "Hien Van Nguyen"], "title": "MAARTA:Multi-Agentic Adaptive Radiology Teaching Assistant", "comment": "Accepted to MICCAI 2025 (Main Conference)", "summary": "Radiology students often struggle to develop perceptual expertise due to\nlimited expert mentorship time, leading to errors in visual search and\ndiagnostic interpretation. These perceptual errors, such as missed fixations,\nshort dwell times, or misinterpretations, are not adequately addressed by\ncurrent AI systems, which focus on diagnostic accuracy but fail to explain how\nand why errors occur. To address this gap, we introduce MAARTA (Multi-Agentic\nAdaptive Radiology Teaching Assistant), a multi-agent framework that analyzes\ngaze patterns and radiology reports to provide personalized feedback. Unlike\nsingle-agent models, MAARTA dynamically selects agents based on error\ncomplexity, enabling adaptive and efficient reasoning. By comparing expert and\nstudent gaze behavior through structured graphs, the system identifies missed\nfindings and assigns Perceptual Error Teacher agents to analyze discrepancies.\nMAARTA then uses step-by-step prompting to help students understand their\nerrors and improve diagnostic reasoning, advancing AI-driven radiology\neducation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u653e\u5c04\u5b66\u6559\u5b66\u52a9\u624bMAARTA\uff0c\u80fd\u591f\u52a8\u6001\u5206\u6790\u5b66\u751f\u4e0e\u4e13\u5bb6\u7684\u6ce8\u89c6\u884c\u4e3a\u548c\u8bca\u65ad\u62a5\u544a\uff0c\u5bf9\u5b66\u751f\u89c6\u89c9\u4e0e\u8bca\u65ad\u9519\u8bef\u8fdb\u884c\u4e2a\u6027\u5316\u5206\u6790\u548c\u53cd\u9988\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u653e\u5c04\u5b66\u5b66\u751f\u7684\u8bca\u65ad\u80fd\u529b\uff0c\u5f25\u8865\u73b0\u6709AI\u7cfb\u7edf\u5728\u9519\u8bef\u89e3\u91ca\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u653e\u5c04\u5b66\u5b66\u751f\u5728\u89c6\u89c9\u641c\u7d22\u548c\u8bca\u65ad\u89e3\u91ca\u65b9\u9762\u5e38\u51fa\u73b0\u9519\u8bef\uff0c\u4e3b\u8981\u7531\u4e8e\u7f3a\u4e4f\u4e13\u5bb6\u5bfc\u5e08\u7684\u65f6\u95f4\u548c\u6307\u5bfc\u3002\u76ee\u524d\u7684AI\u7cfb\u7edf\u4ec5\u6ce8\u91cd\u6700\u7ec8\u8bca\u65ad\u51c6\u786e\u7387\uff0c\u65e0\u6cd5\u89e3\u91ca\u9519\u8bef\u4ea7\u751f\u7684\u8fc7\u7a0b\u4e0e\u539f\u56e0\uff0c\u65e0\u6cd5\u6709\u6548\u5e2e\u52a9\u5b66\u751f\u7406\u89e3\u548c\u6539\u8fdb\u611f\u77e5\u9519\u8bef\u3002", "method": "\u63d0\u51fa\u4e86MAARTA\uff08\u591a\u667a\u80fd\u4f53\u81ea\u9002\u5e94\u653e\u5c04\u5b66\u6559\u5b66\u52a9\u624b\uff09\uff0c\u5b83\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5206\u6790\u5b66\u751f\u4e0e\u4e13\u5bb6\u7684\u89c6\u7ebf\u8f68\u8ff9\u548c\u653e\u5c04\u5b66\u62a5\u544a\uff0c\u5bf9\u5b66\u751f\u8fdb\u884c\u4e2a\u6027\u5316\u53cd\u9988\u3002\u7cfb\u7edf\u5229\u7528\u7ed3\u6784\u5316\u56fe\u6bd4\u8f83\u4e13\u5bb6\u4e0e\u5b66\u751f\u7684\u6ce8\u89c6\u884c\u4e3a\uff0c\u52a8\u6001\u9009\u62e9\u667a\u80fd\u4f53\uff0c\u5206\u6790\u611f\u77e5\u9519\u8bef\uff0c\u5e76\u7528\u5206\u6b65\u63d0\u793a\u65b9\u5f0f\u5e2e\u52a9\u5b66\u751f\u7406\u89e3\u5e76\u6539\u8fdb\u8bca\u65ad\u903b\u8f91\u3002", "result": "MAARTA\u80fd\u591f\u667a\u80fd\u3001\u52a8\u6001\u5730\u5e2e\u52a9\u653e\u5c04\u5b66\u5b66\u751f\u53d1\u73b0\u5e76\u7406\u89e3\u611f\u77e5\u9519\u8bef\uff0c\u5982\u6f0f\u770b\u3001\u6ce8\u89c6\u65f6\u95f4\u8fc7\u77ed\u3001\u8bef\u89e3\u91ca\u7b49\uff0c\u4ece\u800c\u63d0\u5347\u5176\u8bca\u65ad\u63a8\u7406\u80fd\u529b\u3002\u7cfb\u7edf\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u6a21\u578b\u66f4\u5177\u9002\u5e94\u6027\u4e0e\u9ad8\u6548\u6027\u3002", "conclusion": "MAARTA\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u673a\u5236\u7cbe\u51c6\u5206\u6790\u548c\u53cd\u9988\u5b66\u751f\u7684\u611f\u77e5\u9519\u8bef\uff0c\u586b\u8865\u4e86\u73b0\u6709AI\u8f85\u5bfc\u7cfb\u7edf\u65e0\u6cd5\u89e3\u91ca\u9519\u8bef\u5982\u4f55\u53d1\u751f\u7684\u7a7a\u767d\uff0c\u63a8\u52a8\u4e86AI\u5728\u653e\u5c04\u5b66\u6559\u80b2\u4e2d\u7684\u667a\u80fd\u5316\u548c\u4e2a\u6027\u5316\u53d1\u5c55\u3002"}}
{"id": "2506.18147", "categories": ["q-fin.TR"], "pdf": "https://arxiv.org/pdf/2506.18147", "abs": "https://arxiv.org/abs/2506.18147", "authors": ["Paloma Mar\u00edn", "Sergio Ardanza-Trevijano", "Javier Sabio"], "title": "Causal Interventions in Bond Multi-Dealer-to-Client Platforms", "comment": null, "summary": "The digitalization of financial markets has shifted trading from voice to\nelectronic channels, with Multi-Dealer-to-Client (MD2C) platforms now enabling\nclients to request quotes (RfQs) for financial instruments like bonds from\nmultiple dealers simultaneously. In this competitive landscape, dealers cannot\nsee each other's prices, making a rigorous analysis of the negotiation process\ncrucial to ensure their profitability. This article introduces a novel general\nframework for analyzing the RfQ process using probabilistic graphical models\nand causal inference. Within this framework, we explore different inferential\nquestions that are relevant for dealers participating in MD2C platforms, such\nas the computation of optimal prices, estimating potential revenues and the\nidentification of clients that might be interested in trading the dealer's\naxes. We then move into analyzing two different approaches for model\nspecification: a generative model built on the work of (Fermanian, Gu\\'eant &\nPu, 2017); and discriminative models utilizing machine learning techniques. We\nevaluate these methodologies using predictive metrics designed to assess their\neffectiveness in the context of optimal pricing, highlighting the relative\nbenefits of using models that take into account the internal mechanisms of the\nnegotiation process.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u4ea4\u6613\u5546\u5230\u5ba2\u6237\u5e73\u53f0\u7684\u62a5\u4ef7\u7ade\u4e89\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u6982\u7387\u56fe\u4e0e\u56e0\u679c\u63a8\u65ad\u7684\u65b0\u5206\u6790\u6846\u67b6\uff0c\u7ed3\u5408\u751f\u6210\u548c\u5224\u522b\u6a21\u578b\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u5728\u6700\u4f18\u5b9a\u4ef7\u7b49\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u4ea4\u6613\u5546\u5b9e\u7528\u4ef7\u683c\u7b56\u7565\u5236\u5b9a\u63d0\u4f9b\u7406\u8bba\u4e0e\u5b9e\u8bc1\u652f\u6301\u3002", "motivation": "\u968f\u7740\u91d1\u878d\u5e02\u573a\u6570\u5b57\u5316\u53d1\u5c55\uff0c\u4ea4\u6613\u9010\u6b65\u4ece\u4eba\u5de5\u8bed\u97f3\u8f6c\u5411\u7535\u5b50\u5316\u6e20\u9053\u3002\u591a\u4ea4\u6613\u5546\u5230\u5ba2\u6237\uff08MD2C\uff09\u5e73\u53f0\u8ba9\u5ba2\u6237\u80fd\u540c\u65f6\u5411\u591a\u4e2a\u4ea4\u6613\u5546\u8bf7\u6c42\u91d1\u878d\u5de5\u5177\u62a5\u4ef7\uff0c\u4ee4\u4ea4\u6613\u5546\u95f4\u7ade\u4e89\u52a0\u5267\u5374\u53c8\u65e0\u6cd5\u4e86\u89e3\u5bf9\u65b9\u62a5\u4ef7\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u4e25\u8c28\u5206\u6790\u8bae\u4ef7\u8fc7\u7a0b\u3001\u786e\u4fdd\u4ea4\u6613\u5546\u76c8\u5229\u53d8\u5f97\u5c24\u4e3a\u7d27\u8feb\u548c\u91cd\u8981\u3002", "method": "\u6587\u4e2d\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u901a\u7528\u6846\u67b6\uff0c\u91c7\u7528\u6982\u7387\u56fe\u6a21\u578b\u4e0e\u56e0\u679c\u63a8\u65ad\u5206\u6790MD2C\u5e73\u53f0\u4e0a\u7684RfQ\u8fc7\u7a0b\u3002\u6846\u67b6\u5185\u540c\u65f6\u63a2\u8ba8\u751f\u6210\u6a21\u578b\uff08\u5982Fermanian\u7b492017\u5e74\u5de5\u4f5c\u57fa\u7840\u4e0a\u6784\u5efa\uff09\u4e0e\u5224\u522b\u6a21\u578b\uff08\u5229\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\uff09\uff1b\u5e76\u8bbe\u8ba1\u9884\u6d4b\u6027\u8bc4\u4f30\u6307\u6807\u8861\u91cf\u6a21\u578b\u5728\u6700\u4f18\u5b9a\u4ef7\u7b49\u573a\u666f\u7684\u6548\u679c\u3002", "result": "\u901a\u8fc7\u5b9e\u9645\u8bc4\u4f30\uff0c\u4f5c\u8005\u6bd4\u8f83\u4e86\u751f\u6210\u6a21\u578b\u4e0e\u5224\u522b\u6a21\u578b\u5728\u6700\u4f18\u5b9a\u4ef7\u53ca\u6536\u76ca\u9884\u6d4b\u7b49\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u6307\u51fa\u8003\u8651\u8bae\u4ef7\u5185\u90e8\u673a\u5236\u7684\u6a21\u578b\u5177\u6709\u4e00\u5b9a\u4f18\u52bf\u3002\u6846\u67b6\u80fd\u6709\u6548\u8bc6\u522b\u611f\u5174\u8da3\u5ba2\u6237\u5e76\u5e2e\u52a9\u4ea4\u6613\u5546\u8bbe\u5b9a\u66f4\u4f18\u4ef7\u683c\u7b56\u7565\u3002", "conclusion": "\u6587\u732e\u5c55\u793a\u4e86\u6982\u7387\u56fe\u6a21\u578b\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728MD2C\u5e73\u53f0\u62a5\u4ef7\u5206\u6790\u548c\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u524d\u666f\uff0c\u4e3a\u4ea4\u6613\u5546\u5229\u6da6\u6700\u5927\u5316\u53ca\u5ba2\u6237\u6316\u6398\u63d0\u4f9b\u4e86\u6570\u636e\u9a71\u52a8\u7684\u5b9a\u91cf\u652f\u6301\u3002"}}
{"id": "2506.17224", "categories": ["cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17224", "abs": "https://arxiv.org/abs/2506.17224", "authors": ["Zofia Pizo\u0144", "Shinji Kimijima", "Grzegorz Brus"], "title": "Bridging Equilibrium and Kinetics Prediction with a Data-Weighted Neural Network Model of Methane Steam Reforming", "comment": "12 pages, 8 figures", "summary": "Hydrogen's role is growing as an energy carrier, increasing the need for\nefficient production, with methane steam reforming being the most widely used\ntechnique. This process is crucial for applications like fuel cells, where\nhydrogen is converted into electricity, pushing for reactor miniaturization and\noptimized process control through numerical simulations. Existing models\ntypically address either kinetic or equilibrium regimes, limiting their\napplicability. Here we show a surrogate model capable of unifying both regimes.\nAn artificial neural network trained on a comprehensive dataset that includes\nexperimental data from kinetic and equilibrium experiments, interpolated data,\nand theoretical data derived from theoretical models for each regime. Data\naugmentation and assigning appropriate weights to each data type enhanced\ntraining. After evaluating Bayesian Optimization and Random Sampling, the\noptimal model demonstrated high predictive accuracy for the composition of the\npost-reaction mixture under varying operating parameters, indicated by a mean\nsquared error of 0.000498 and strong Pearson correlation coefficients of 0.927.\nThe network's ability to provide continuous derivatives of its predictions\nmakes it particularly useful for process modeling and optimization. The results\nconfirm the surrogate model's robustness for simulating methane steam reforming\nin both kinetic and equilibrium regimes, making it a valuable tool for design\nand process optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u6709\u7d20\u7684\u795e\u7ecf\u7f51\u7edc\u4ee3\u7406\u6a21\u578b\uff0c\u9996\u6b21\u517c\u5bb9\u5e76\u7cbe\u51c6\u9884\u6d4b\u7532\u70f7\u84b8\u6c7d\u91cd\u6574\u7684\u52a8\u529b\u5b66\u4e0e\u5e73\u8861\u8fc7\u7a0b\uff0c\u4e3a\u5236\u6c22\u53cd\u5e94\u6a21\u62df\u4e0e\u4f18\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u6c22\u6c14\u4f5c\u4e3a\u80fd\u6e90\u8f7d\u4f53\u7684\u4f5c\u7528\u65e5\u76ca\u589e\u5f3a\uff0c\u5bf9\u9ad8\u6548\u5236\u6c22\u65b9\u6cd5\u7684\u9700\u6c42\u4e5f\u968f\u4e4b\u589e\u52a0\u3002\u7532\u70f7\u84b8\u6c7d\u91cd\u6574\u662f\u76ee\u524d\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u5236\u6c22\u6280\u672f\uff0c\u5176\u5728\u71c3\u6599\u7535\u6c60\u7b49\u5e94\u7528\u4e2d\u7684\u53cd\u5e94\u5668\u5c0f\u578b\u5316\u548c\u5de5\u827a\u4f18\u5316\u5c24\u4e3a\u5173\u952e\u3002\u4ee5\u5f80\u7684\u6570\u503c\u6a21\u62df\u6a21\u578b\u591a\u53ea\u80fd\u63cf\u8ff0\u52a8\u529b\u5b66\u6216\u5e73\u8861\u6001\u4e2d\u7684\u4e00\u79cd\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u7528\u6027\u3002\u672c\u8bba\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u7edf\u4e00\u5904\u7406\u4e24\u79cd\u53cd\u5e94\u673a\u5236\u7684\u65b0\u6a21\u578b\u3002", "method": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u4ee3\u7406\u6a21\u578b\uff08surrogate model\uff09\uff0c\u5229\u7528\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u5bf9\u5305\u542b\u52a8\u529b\u5b66\u5b9e\u9a8c\u3001\u5e73\u8861\u5b9e\u9a8c\u63d2\u503c\u548c\u7406\u8bba\u6570\u636e\u7684\u7efc\u5408\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u3002\u4e3a\u63d0\u9ad8\u8bad\u7ec3\u6548\u679c\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u5bf9\u4e0d\u540c\u7c7b\u578b\u6570\u636e\u8d4b\u4e88\u5408\u9002\u6743\u91cd\u3002\u91c7\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u968f\u673a\u91c7\u6837\u65b9\u6cd5\u5bf9\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u5e76\u9009\u53d6\u6700\u4f18\u6a21\u578b\u3002", "result": "\u6700\u4f18\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u4e0d\u540c\u64cd\u4f5c\u53c2\u6570\u4e0b\u5bf9\u53cd\u5e94\u540e\u6df7\u5408\u7269\u7ec4\u6210\u8fdb\u884c\u4e86\u9ad8\u7cbe\u5ea6\u9884\u6d4b\uff0c\u5747\u65b9\u8bef\u5dee\u4e3a0.000498\uff0cPearson\u76f8\u5173\u7cfb\u6570\u4e3a0.927\u3002\u5176\u80fd\u5bf9\u9884\u6d4b\u7ed3\u679c\u8fde\u7eed\u6c42\u5bfc\uff0c\u9002\u7528\u4e8e\u8fc7\u7a0b\u5efa\u6a21\u548c\u4f18\u5316\u3002\u6700\u7ec8\u7ed3\u679c\u8868\u660e\uff0c\u4ee3\u7406\u6a21\u578b\u53ef\u7a33\u5065\u4eff\u771f\u7532\u70f7\u84b8\u6c7d\u91cd\u6574\u7684\u52a8\u529b\u5b66\u548c\u70ed\u529b\u5b66\u5e73\u8861\u8fc7\u7a0b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u795e\u7ecf\u7f51\u7edc\u4ee3\u7406\u6a21\u578b\u53ef\u7edf\u4e00\u63cf\u8ff0\u7532\u70f7\u84b8\u6c7d\u91cd\u6574\u53cd\u5e94\u7684\u52a8\u529b\u5b66\u4e0e\u5e73\u8861\u4e24\u79cd\u673a\u5236\uff0c\u80fd\u591f\u4e3a\u53cd\u5e94\u5668\u8bbe\u8ba1\u548c\u8fc7\u7a0b\u4f18\u5316\u63d0\u4f9b\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2506.17223", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17223", "abs": "https://arxiv.org/abs/2506.17223", "authors": ["Shuvra Smaran Das", "Anirban Saha Anik", "Md Kishor Morol", "Mohammad Sakib Mahmood"], "title": "Outcome-Based Education: Evaluating Students' Perspectives Using Transformer", "comment": "6 pages, 7 figures", "summary": "Outcome-Based Education (OBE) emphasizes the development of specific\ncompetencies through student-centered learning. In this study, we reviewed the\nimportance of OBE and implemented transformer-based models, particularly\nDistilBERT, to analyze an NLP dataset that includes student feedback. Our\nobjective is to assess and improve educational outcomes. Our approach is better\nthan other machine learning models because it uses the transformer's deep\nunderstanding of language context to classify sentiment better, giving better\nresults across a wider range of matrices. Our work directly contributes to\nOBE's goal of achieving measurable outcomes by facilitating the identification\nof patterns in student learning experiences. We have also applied LIME (local\ninterpretable model-agnostic explanations) to make sure that model predictions\nare clear. This gives us understandable information about how key terms affect\nsentiment. Our findings indicate that the combination of transformer models and\nLIME explanations results in a strong and straightforward framework for\nanalyzing student feedback. This aligns more closely with the principles of OBE\nand ensures the improvement of educational practices through data-driven\ninsights.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408DistilBERT\u4e0eLIME\u7684\u5b66\u751f\u53cd\u9988\u5206\u6790\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u60c5\u611f\u5206\u7c7b\u51c6\u786e\u6027\u4e14\u517c\u5177\u6a21\u578b\u53ef\u89e3\u91ca\u6027\uff0c\u5207\u5b9e\u652f\u6301\u6210\u679c\u5bfc\u5411\u6559\u80b2\uff08OBE\uff09\u7684\u5b9e\u65bd\u3002", "motivation": "\u968f\u7740\u4ee5\u5b66\u751f\u4e3a\u4e2d\u5fc3\u7684\u6559\u5b66\u7406\u5ff5\u63d0\u5347\uff0c\u6210\u679c\u5bfc\u5411\u6559\u80b2\uff08OBE\uff09\u88ab\u91cd\u89c6\uff0c\u4f46\u5982\u4f55\u91cf\u5316\u4e0e\u63d0\u5347\u5b66\u4e60\u6210\u679c\u6210\u4e3a\u96be\u9898\u3002\u5f53\u524d\u5b66\u751f\u53cd\u9988\u6570\u636e\u65e5\u76ca\u4e30\u5bcc\uff0c\u4e9f\u9700\u66f4\u667a\u80fd\u7684\u5206\u6790\u65b9\u6cd5\u4ee5\u6316\u6398\u6709\u6548\u4fe1\u606f\uff0c\u4f18\u5316\u6559\u80b2\u5b9e\u8df5\u3002", "method": "\u91c7\u7528transformer\u67b6\u6784\u4e0b\u7684DistilBERT\u6a21\u578b\uff0c\u5bf9\u5305\u542b\u5b66\u751f\u53cd\u9988\u7684NLP\u6570\u636e\u96c6\u8fdb\u884c\u60c5\u611f\u5206\u7c7b\u5206\u6790\u3002\u540c\u65f6\uff0c\u5f15\u5165LIME\uff08\u53ef\u89e3\u91ca\u6027\u5206\u6790\u65b9\u6cd5\uff09\u63d0\u5347\u6a21\u578b\u9884\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4ece\u800c\u7406\u89e3\u5173\u952e\u8bcd\u5bf9\u60c5\u611f\u51b3\u7b56\u7684\u4f5c\u7528\u3002", "result": "DistilBERT\u6a21\u578b\u5728\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5728\u591a\u9879\u8bc4\u4ef7\u6307\u6807\u4e0a\u7ed3\u679c\u66f4\u4f73\u3002\u6b64\u5916\uff0cLIME\u7684\u5f15\u5165\u5e2e\u52a9\u89e3\u91ca\u6a21\u578b\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u76f8\u5173\u5173\u952e\u672f\u8bed\u5bf9\u60c5\u611f\u7684\u5f71\u54cd\u66f4\u900f\u660e\u3002", "conclusion": "\u7ed3\u5408transformer\u6a21\u578b\u4e0eLIME\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u80fd\u591f\u4e3aOBE\u63d0\u4f9b\u4e00\u79cd\u9ad8\u6548\u4e14\u900f\u660e\u7684\u6570\u636e\u9a71\u52a8\u578b\u5b66\u751f\u53cd\u9988\u5206\u6790\u65b9\u6848\uff0c\u66f4\u6709\u6548\u5730\u5b9e\u73b0\u6210\u679c\u53ef\u91cf\u5316\uff0c\u4fc3\u8fdb\u6559\u80b2\u5b9e\u8df5\u6539\u8fdb\u3002"}}
{"id": "2506.17289", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17289", "abs": "https://arxiv.org/abs/2506.17289", "authors": ["Rahul Raja", "Arpita Vats"], "title": "Evaluating Generalization and Representation Stability in Small LMs via Prompting", "comment": "Accepted at ICML", "summary": "We investigate the generalization capabilities of small language models under\ntwo popular adaptation paradigms: few-shot prompting and supervised\nfine-tuning. While prompting is often favored for its parameter efficiency and\nflexibility, it remains unclear how robust this approach is in low-resource\nsettings and under distributional shifts. This paper presents a comparative\nstudy of prompting and fine-tuning across task formats, prompt styles, and\nmodel scales, with a focus on their behavior in both in-distribution and\nout-of-distribution (OOD) settings.\n  Beyond accuracy, we analyze the internal representations learned by each\napproach to assess the stability and abstraction of task-specific features. Our\nfindings highlight critical differences in how small models internalize and\ngeneralize knowledge under different adaptation strategies. This work offers\npractical guidance for model selection in low-data regimes and contributes\nempirical insight into the ongoing debate over prompting versus fine-tuning.\nCode for the experiments is available at the following", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5c11\u6837\u672c\u63d0\u793a\u4e0e\u6709\u76d1\u7763\u5fae\u8c03\u4e0b\u3001\u4e0d\u540c\u4efb\u52a1\u4e0e\u5206\u5e03\u60c5\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u53ca\u5185\u90e8\u8868\u5f81\uff0c\u63ed\u793a\u4e86\u4e24\u79cd\u7b56\u7565\u5728\u4f4e\u8d44\u6e90\u573a\u666f\u4e2d\u5404\u81ea\u7684\u4f18\u52a3\uff0c\u5e76\u4e3a\u5b9e\u8df5\u4e2d\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u6709\u6548\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u76ee\u524d\u5bf9\u4e8e\u5c11\u6837\u672c\u63d0\u793a\uff08prompting\uff09\u548c\u6709\u76d1\u7763\u5fae\u8c03\uff08fine-tuning\uff09\u4e24\u79cd\u4e3b\u6d41\u9002\u5e94\u8303\u5f0f\u5728\u5c11\u8d44\u6e90\u53ca\u6570\u636e\u5206\u5e03\u53d8\u5316\u573a\u666f\u4e0b\u7684\u8868\u73b0\u5c1a\u4e0d\u660e\u786e\u3002\u6b64\u6587\u65e8\u5728\u7cfb\u7edf\u5bf9\u6bd4\u8fd9\u4e24\u79cd\u7b56\u7565\uff0c\u4ee5\u6307\u5bfc\u4f4e\u6570\u636e\u573a\u666f\u4e0b\u7684\u6a21\u578b\u9009\u62e9\u3002", "method": "\u4f5c\u8005\u4ece\u4efb\u52a1\u7c7b\u578b\u3001\u63d0\u793a\u98ce\u683c\u4ee5\u53ca\u6a21\u578b\u89c4\u6a21\u7b49\u591a\u7ef4\u5ea6\uff0c\u7cfb\u7edf\u5730\u6bd4\u8f83\u4e86few-shot prompting\u548csupervised fine-tuning\u5728\u5206\u5e03\u5185\uff08in-distribution\uff09\u4e0e\u5206\u5e03\u5916\uff08out-of-distribution, OOD\uff09\u60c5\u5883\u4e0b\u7684\u8868\u73b0\u3002\u4e0d\u4ec5\u901a\u8fc7\u51c6\u786e\u7387\u8bc4\u4f30\u6a21\u578b\u8868\u73b0\uff0c\u8fd8\u5206\u6790\u4e86\u4e0d\u540c\u9002\u5e94\u7b56\u7565\u4e0b\u6a21\u578b\u5185\u90e8\u8868\u5f81\u7684\u7a33\u5b9a\u6027\u4e0e\u62bd\u8c61\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u63ed\u793a\uff1a\u4e0d\u540c\u7684\u9002\u5e94\u7b56\u7565\uff08prompting\u4e0efine-tuning\uff09\u5728\u5c0f\u6a21\u578b\u4e2d\u5bf9\u77e5\u8bc6\u7684\u5185\u5316\u4e0e\u6cdb\u5316\u65b9\u5f0f\u6709\u5b9e\u8d28\u6027\u5dee\u522b\uff0c\u5bf9\u4efb\u52a1\u7279\u5f81\u8868\u5f81\u7684\u7a33\u5b9a\u6027\u4e0e\u62bd\u8c61\u6027\u4e5f\u4e0d\u5c3d\u76f8\u540c\u3002\u4e3a\u4f4e\u6570\u636e\u573a\u666f\u4e0b\u7684\u6a21\u578b\u7b56\u7565\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u548c\u5b9e\u8df5\u53c2\u8003\u3002", "conclusion": "\u5c11\u6837\u672c\u63d0\u793a\u548c\u6709\u76d1\u7763\u5fae\u8c03\u5728\u5c0f\u6a21\u578b\u9002\u5e94\u6027\u3001\u6cdb\u5316\u6027\u4e0e\u5185\u90e8\u8868\u5f81\u4e0a\u5b58\u5728\u663e\u8457\u4e0d\u540c\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bbe\u7f6e\u4e0b\u6a21\u578b\u9009\u62e9\u4e0e\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8bc1\u4f9d\u636e\u3002\u8be5\u7814\u7a76\u5bf9prompting\u548cfine-tuning\u4f18\u52a3\u7684\u4e89\u8bba\u7ed9\u51fa\u4e86\u65b0\u7684\u7ecf\u9a8c\u89c1\u89e3\u3002"}}
{"id": "2506.17339", "categories": ["cs.CY", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2506.17339", "abs": "https://arxiv.org/abs/2506.17339", "authors": ["Ren\u00e9 Bohnsack", "Mickie de Wet"], "title": "AI is the Strategy: From Agentic AI to Autonomous Business Models onto Strategy in the Age of AI", "comment": "21 pages, 6 figures, 3 tables. Under review at Strategy Science (no\n  decision yet). This version posted to facilitate citation and feedback", "summary": "This article develops the concept of Autonomous Business Models (ABMs) as a\ndistinct managerial and strategic logic in the age of agentic AI. While most\nfirms still operate within human-driven or AI-augmented models, we argue that\nwe are now entering a phase where agentic AI (systems capable of initiating,\ncoordinating, and adapting actions autonomously) can increasingly execute the\ncore mechanisms of value creation, delivery, and capture. This shift reframes\nAI not as a tool to support strategy, but as the strategy itself. Using two\nillustrative cases, getswan.ai, an Israeli startup pursuing autonomy by design,\nand a hypothetical reconfiguration of Ryanair as an AI-driven incumbent, we\ndepict the evolution from augmented to autonomous business models. We show how\nABMs reshape competitive advantage through agentic execution, continuous\nadaptation, and the gradual offloading of human decision-making. This\ntransition introduces new forms of competition between AI-led firms, which we\nterm synthetic competition, where strategic interactions occur at rapid,\nmachine-level speed and scale. It also challenges foundational assumptions in\nstrategy, organizational design, and governance. By positioning agentic AI as\nthe central actor in business model execution, the article invites us to\nrethink strategic management in an era where firms increasingly run themselves.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f01\u4e1a\u6b63\u5728\u4ece\u7531\u4eba\u4e3b\u5bfc\u6216AI\u8f85\u52a9\u7684\u6a21\u5f0f\uff0c\u5411AI\u81ea\u4e3b\u51b3\u7b56\u548c\u6267\u884c\u7684\u81ea\u4e3b\u578b\u5546\u4e1a\u6a21\u5f0f\uff08ABM\uff09\u8f6c\u53d8\u3002\u901a\u8fc7\u6848\u4f8b\u5206\u6790\uff0c\u4f5c\u8005\u6307\u51faAI\u5c06\u6210\u4e3a\u4f01\u4e1a\u7ade\u4e89\u548c\u6218\u7565\u7684\u6838\u5fc3\uff0c\u63a8\u52a8\u884c\u4e1a\u8fdb\u5165\u673a\u5668\u4e3b\u5bfc\u7684\u201c\u5408\u6210\u7ade\u4e89\u201d\u9636\u6bb5\u3002\u8fd9\u4e00\u53d8\u9769\u5bf9\u6218\u7565\u7ba1\u7406\u548c\u7ec4\u7ec7\u8bbe\u8ba1\u63d0\u51fa\u4e86\u5de8\u5927\u6311\u6218\u3002", "motivation": "\u968f\u7740AI\u80fd\u529b\u63d0\u5347\uff0cAI\u4e0d\u518d\u4ec5\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u8fdb\u5165\u4f01\u4e1a\uff0c\u800c\u6709\u6f5c\u529b\u6210\u4e3a\u4f01\u4e1a\u6218\u7565\u548c\u8fd0\u8425\u7684\u6838\u5fc3\uff0c\u9a71\u52a8\u5546\u4e1a\u6a21\u5f0f\u6839\u672c\u6027\u53d8\u9769\u3002\u4f5c\u8005\u5e0c\u671b\u63a2\u8ba8\u548c\u6846\u5b9a\u8fd9\u79cd\u8f6c\u578b\uff0c\u5e76\u5f15\u53d1\u5bf9\u672a\u6765\u4f01\u4e1a\u6218\u7565\u4e0e\u7ec4\u7ec7\u8bbe\u8ba1\u7684\u601d\u8003\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e24\u4e2a\u6848\u4f8b\uff1a\u4ee5\u81ea\u4e3b\u8bbe\u8ba1\u4e3a\u76ee\u6807\u7684\u4ee5\u8272\u5217\u521d\u521b\u516c\u53f8getswan.ai\uff0c\u4ee5\u53ca\u5047\u8bbe\u5c06Ryanair\u91cd\u6784\u4e3aAI\u9a71\u52a8\u4f01\u4e1a\uff0c\u5c55\u793a\u4e86\u4f01\u4e1a\u4eceAI\u8f85\u52a9\u5411AI\u81ea\u4e3b\u6f14\u5316\u7684\u8fc7\u7a0b\u548c\u52a8\u6001\u3002", "result": "ABM\u4f7f\u4f01\u4e1a\u83b7\u5f97\u901a\u8fc7AI\u51b3\u7b56\u6267\u884c\u7684\u65b0\u578b\u7ade\u4e89\u4f18\u52bf\uff0c\u5b9e\u73b0\u6301\u7eed\u9002\u5e94\u548c\u51b3\u7b56\u81ea\u52a8\u5316\uff0c\u91cd\u5851\u884c\u4e1a\u7ade\u4e89\u683c\u5c40\u5e76\u6311\u6218\u4f20\u7edf\u7ba1\u7406\u548c\u6cbb\u7406\u8303\u5f0f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u81ea\u4e3b\u578b\u5546\u4e1a\u6a21\u5f0f\uff08Autonomous Business Models, ABMs\uff09\u7684\u6982\u5ff5\uff0c\u8ba4\u4e3a\u968f\u7740\u667a\u80fd\u4f53AI\u80fd\u529b\u7684\u589e\u5f3a\uff0c\u4f01\u4e1a\u6218\u7565\u548c\u7ba1\u7406\u6b63\u8fdb\u5165\u7531AI\u4e3b\u5bfc\u7684\u65b0\u9636\u6bb5\uff0c\u4eba\u7c7b\u7684\u51b3\u7b56\u548c\u7ba1\u7406\u5c06\u9010\u6b65\u88abAI\u53d6\u4ee3\uff0c\u4f01\u4e1a\u8fd0\u4f5c\u5c06\u66f4\u9ad8\u6548\u4e14\u5177\u9002\u5e94\u6027\uff0c\u672a\u6765\u7684\u7ade\u4e89\u5c06\u8f6c\u53d8\u4e3aAI\u4e4b\u95f4\u7684\u201c\u5408\u6210\u7ade\u4e89\u201d\u3002"}}
{"id": "2506.17487", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.17487", "abs": "https://arxiv.org/abs/2506.17487", "authors": ["Alireza Tabarraei"], "title": "Variational Quantum Latent Encoding for Topology Optimization", "comment": null, "summary": "A variational framework for structural topology optimization is developed,\nintegrating quantum and classical latent encoding strategies within a\ncoordinate-based neural decoding architecture. In this approach, a\nlow-dimensional latent vector, generated either by a variational quantum\ncircuit or sampled from a Gaussian distribution, is mapped to a\nhigher-dimensional latent space via a learnable projection layer. This enriched\nrepresentation is then decoded into a high-resolution material distribution\nusing a neural network that takes both the latent vector and Fourier-mapped\nspatial coordinates as input. The optimization is performed directly on the\nlatent parameters, guided solely by physics-based objectives such as compliance\nminimization and volume constraints evaluated through finite element analysis,\nwithout requiring any precomputed datasets or supervised training. Quantum\nlatent vectors are constructed from the expectation values of Pauli observables\nmeasured on parameterized quantum circuits, providing a structured and\nentangled encoding of information. The classical baseline uses Gaussian-sampled\nlatent vectors projected in the same manner. The proposed variational\nformulation enables the generation of diverse and physically valid topologies\nby exploring the latent space through sampling or perturbation, in contrast to\ntraditional optimization methods that yield a single deterministic solution.\nNumerical experiments show that both classical and quantum encodings produce\nhigh-quality structural designs. However, quantum encodings demonstrate\nadvantages in several benchmark cases in terms of compliance and design\ndiversity. These results highlight the potential of quantum circuits as an\neffective and scalable tool for physics-constrained topology optimization and\nsuggest promising directions for applying near-term quantum hardware in\nstructural design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u91cf\u5b50\u548c\u7ecf\u5178\u6f5c\u5728\u7f16\u7801\u7684\u53d8\u5206\u795e\u7ecf\u7ed3\u6784\u62d3\u6251\u4f18\u5316\u65b9\u6cd5\uff0c\u65e0\u9700\u76d1\u7763\u6570\u636e\uff0c\u53ef\u76f4\u63a5\u8fdb\u884c\u7269\u7406\u76ee\u6807\u9a71\u52a8\u7684\u8bbe\u8ba1\u4f18\u5316\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u91cf\u5b50\u7f16\u7801\u53ef\u83b7\u5f97\u66f4\u4e30\u5bcc\u4e14\u4f18\u8d28\u7684\u7ed3\u6784\u89e3\uff0c\u663e\u793a\u51fa\u91cf\u5b50\u8ba1\u7b97\u5728\u5de5\u7a0b\u4f18\u5316\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u7ed3\u6784\u62d3\u6251\u4f18\u5316\u662f\u5de5\u7a0b\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u5f97\u5230\u552f\u4e00\u786e\u5b9a\u89e3\uff0c\u7f3a\u4e4f\u591a\u6837\u6027\uff0c\u4e14\u4f9d\u8d56\u5927\u89c4\u6a21\u6570\u636e\u6216\u76d1\u7763\u8bad\u7ec3\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u5f15\u5165\u53d8\u5206\u6846\u67b6\uff0c\u7ed3\u5408\u91cf\u5b50\u4e0e\u7ecf\u5178\u65b9\u6cd5\uff0c\u63d0\u5347\u89e3\u7684\u591a\u6837\u6027\u4e0e\u7269\u7406\u6709\u6548\u6027\uff0c\u540c\u65f6\u63a2\u7d22\u91cf\u5b50\u8ba1\u7b97\u5728\u7ed3\u6784\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u878d\u5408\u91cf\u5b50\u4e0e\u7ecf\u5178\u6f5c\u5728\u7f16\u7801\u7684\u53d8\u5206\u6846\u67b6\uff0c\u901a\u8fc7\u5750\u6807\u57fa\u795e\u7ecf\u7f51\u7edc\u89e3\u7801\u3002\u5148\u7528\u53d8\u5206\u91cf\u5b50\u7535\u8def\u6216\u9ad8\u65af\u5206\u5e03\u751f\u6210\u4f4e\u7ef4\u6f5c\u53d8\u91cf\uff0c\u7ecf\u8fc7\u53ef\u5b66\u4e60\u6295\u5f71\u6620\u5c04\u81f3\u9ad8\u7ef4\uff0c\u518d\u4e0e\u5085\u91cc\u53f6\u6620\u5c04\u7a7a\u95f4\u5750\u6807\u4e00\u540c\u8f93\u5165\u795e\u7ecf\u7f51\u7edc\u89e3\u7801\uff0c\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u6750\u6599\u5206\u5e03\u3002\u4f18\u5316\u76f4\u63a5\u5728\u6f5c\u53d8\u91cf\u53c2\u6570\u4e0a\u8fdb\u884c\uff0c\u4ec5\u4f9d\u8d56\u6709\u9650\u5143\u5206\u6790\u5f97\u5230\u7684\u7269\u7406\u76ee\u6807\uff0c\u65e0\u9700\u9884\u5148\u6570\u636e\u96c6\u6216\u76d1\u7763\u8bad\u7ec3\u3002\u91cf\u5b50\u6f5c\u53d8\u91cf\u901a\u8fc7\u91cf\u5b50\u7535\u8def\u4e0a\u7684\u53c2\u6570\u5316\u6ce1\u5229\u7b97\u7b26\u671f\u671b\u503c\u5f97\u5230\uff0c\u5177\u5907\u7ed3\u6784\u5316\u548c\u7ea0\u7f20\u7279\u6027\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u7ecf\u5178\u4e0e\u91cf\u5b50\u7f16\u7801\u65b9\u6cd5\u5747\u53ef\u4ea7\u751f\u9ad8\u8d28\u91cf\u7ed3\u6784\u8bbe\u8ba1\u3002\u91cf\u5b50\u7f16\u7801\u5728\u82e5\u5e72\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u5468\u5411\u6027\u80fd\u548c\u8bbe\u8ba1\u591a\u6837\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c55\u73b0\u51fa\u91cf\u5b50\u7535\u8def\u4f5c\u4e3a\u7269\u7406\u7ea6\u675f\u62d3\u6251\u4f18\u5316\u5de5\u5177\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u8fd1\u671f\u91cf\u5b50\u786c\u4ef6\u5728\u7ed3\u6784\u8bbe\u8ba1\u4e2d\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2506.17231", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17231", "abs": "https://arxiv.org/abs/2506.17231", "authors": ["Xiang Li", "Chong Zhang", "Jia Wang", "Fangyu Wu", "Yushi Li", "Xiaobo Jin"], "title": "Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs", "comment": "15 pages, 5 figures", "summary": "Attacks on large language models (LLMs) in jailbreaking scenarios raise many\nsecurity and ethical issues. Current jailbreak attack methods face problems\nsuch as low efficiency, high computational cost, and poor cross-model\nadaptability and versatility, which make it difficult to cope with the rapid\ndevelopment of LLM and new defense strategies. Our work proposes an Adversarial\nPrompt Distillation, which combines masked language modeling, reinforcement\nlearning, and dynamic temperature control through a prompt generation and\ndistillation method. It enables small language models (SLMs) to jailbreak\nattacks on mainstream LLMs. The experimental results verify the superiority of\nthe proposed method in terms of attack success rate and harm, and reflect the\nresource efficiency and cross-model adaptability. This research explores the\nfeasibility of distilling the jailbreak ability of LLM to SLM, reveals the\nmodel's vulnerability, and provides a new idea for LLM security research.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u5bf9\u6297\u6027\u63d0\u793a\u8bcd\u84b8\u998f\u65b9\u6cd5\uff0c\u80fd\u8ba9\u5c0f\u6a21\u578b\u5bf9\u5927\u6a21\u578b\u9ad8\u6548\u8d8a\u72f1\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9ad8\u6210\u529f\u7387\u548c\u4f4e\u8d44\u6e90\u6d88\u8017\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8d8a\u72f1\u653b\u51fb\u6548\u7387\u4f4e\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4ee5\u53ca\u6a21\u578b\u9002\u5e94\u6027\u548c\u901a\u7528\u6027\u5dee\uff0c\u96be\u4ee5\u5e94\u5bf9LLMs\u7684\u5feb\u901f\u53d1\u5c55\u548c\u65b0\u578b\u9632\u5fa1\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u6297\u6027\u63d0\u793a\u8bcd\u84b8\u998f\uff08Adversarial Prompt Distillation\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u52a8\u6001\u6e29\u5ea6\u63a7\u5236\uff0c\u901a\u8fc7\u63d0\u793a\u8bcd\u7684\u751f\u6210\u548c\u84b8\u998f\u7b56\u7565\uff0c\u8ba9\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u80fd\u591f\u5bf9\u4e3b\u6d41LLMs\u53d1\u8d77\u8d8a\u72f1\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u653b\u51fb\u6210\u529f\u7387\u548c\u5371\u5bb3\u6027\u65b9\u9762\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u540c\u65f6\u4f53\u73b0\u51fa\u8d44\u6e90\u9ad8\u6548\u6027\u548c\u826f\u597d\u7684\u8de8\u6a21\u578b\u9002\u5e94\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u5c06LLM\u8d8a\u72f1\u80fd\u529b\u84b8\u998f\u5230SLM\u7684\u53ef\u884c\u6027\uff0c\u63ed\u793a\u4e86\u5927\u6a21\u578b\u5b58\u5728\u7684\u5b89\u5168\u9690\u60a3\uff0c\u5e76\u4e3aLLM\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.17300", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17300", "abs": "https://arxiv.org/abs/2506.17300", "authors": ["Daniel T. Chang"], "title": "Individual Causal Inference with Structural Causal Model", "comment": null, "summary": "Individual causal inference (ICI) uses causal inference methods to understand\nand predict the effects of interventions on individuals, considering their\nspecific characteristics / facts. It aims to estimate individual causal effect\n(ICE), which varies across individuals. Estimating ICE can be challenging due\nto the limited data available for individuals, and the fact that most causal\ninference methods are population-based. Structural Causal Model (SCM) is\nfundamentally population-based. Therefore, causal discovery (structural\nlearning and parameter learning), association queries and intervention queries\nare all naturally population-based. However, exogenous variables (U) in SCM can\nencode individual variations and thus provide the mechanism for individualized\npopulation per specific individual characteristics / facts. Based on this, we\npropose ICI with SCM as a \"rung 3\" causal inference, because it involves\n\"imagining\" what would be the causal effect of a hypothetical intervention on\nan individual, given the individual's observed characteristics / facts.\nSpecifically, we propose the indiv-operator, indiv(W), to formalize/represent\nthe population individualization process, and the individual causal query, P(Y\n| indiv(W), do(X), Z), to formalize/represent ICI. We show and argue that ICI\nwith SCM is inference on individual alternatives (possible), not individual\ncounterfactuals (non-actual).", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u4e2a\u4f53\u56e0\u679c\u63a8\u65ad\u63d0\u51fa\u4e86\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff08SCM\uff09\u7684\u5168\u65b0\u65b9\u6cd5\uff0c\u9996\u6b21\u5c06\u4e2a\u4f53\u5dee\u5f02\u673a\u5236\u6b63\u5f0f\u5f15\u5165\u56e0\u679c\u63a8\u65ad\u5f62\u5f0f\u5316\u4f53\u7cfb\uff0c\u4e3a\u5177\u4f53\u4e2a\u4f53\u7684\u5e72\u9884\u6548\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u4e0e\u64cd\u4f5c\u5de5\u5177\u3002", "motivation": "\u4e2a\u4f53\u56e0\u679c\u63a8\u65ad\uff08ICI\uff09\u8981\u9884\u6d4b\u7279\u5b9a\u4e2a\u4f53\u5728\u7279\u5b9a\u7279\u5f81/\u4e8b\u5b9e\u4e0b\u7684\u5e72\u9884\u6548\u679c\uff0c\u4f46\u4e3b\u6d41\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u591a\u4e3a\u7fa4\u4f53\u7ea7\u522b\uff0c\u7f3a\u4e4f\u4e2a\u4f53\u7c92\u5ea6\u5efa\u6a21\u3002\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff08SCM\uff09\u672c\u8d28\u4e5f\u662f\u7fa4\u4f53\u7ea7\uff0c\u96be\u4ee5\u76f4\u63a5\u7528\u4e8e\u4e2a\u4f53\u63a8\u65ad\u3002\u52a8\u673a\u5728\u4e8e\u9700\u5f25\u8865\u73b0\u6709\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u5728\u4e2a\u4f53\u5c42\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8eSCM\u7684\u4e2a\u4f53\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165indiv-operator\uff08indiv(W)\uff09\u5f62\u5f0f\u5316\u201c\u4e2a\u4f53\u5316\u7fa4\u4f53\u201d\uff0c\u7528individual causal query\uff08P(Y | indiv(W), do(X), Z)\uff09\u63cf\u8ff0\u4e2a\u4f53\u56e0\u679c\u67e5\u8be2\u8fc7\u7a0b\u3002\u5229\u7528SCM\u4e2d\u7684\u5916\u6e90\u53d8\u91cf\u7f16\u7801\u4e2a\u4f53\u95f4\u5dee\u5f02\uff0c\u4ece\u800c\u5f00\u5c55\u4e2a\u4f53\u7ea7\u56e0\u679c\u63a8\u65ad\u3002", "result": "\u8bc1\u660e\u5e76\u8bba\u8bc1\u4e86\u57fa\u4e8eSCM\u7684\u4e2a\u4f53\u56e0\u679c\u63a8\u65ad\u672c\u8d28\u4e0a\u662f\u5bf9\u4e2a\u4f53\u201c\u53ef\u80fd\u9009\u62e9\u201d\uff08individual alternatives\uff09\u7684\u63a8\u65ad\uff0c\u800c\u975e\u53ea\u5bf9\u4e2a\u4f53\u53cd\u4e8b\u5b9e\uff08non-actual\uff09\u8fdb\u884c\u63a8\u65ad\u3002\u65b0\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7fa4\u4f53\u6a21\u578b\u5230\u4e2a\u4f53\u5c42\u9762\u63a8\u65ad\u7684\u6865\u6881\u3002", "conclusion": "\u57fa\u4e8eSCM\u7684ICI\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u65b0\u7b97\u5b50\u4e0e\u67e5\u8be2\u65b9\u5f0f\uff0c\u6709\u6548\u5b9e\u73b0\u4e86\u4ece\u7fa4\u4f53\u7ea7\u6a21\u578b\u5411\u4e2a\u4f53\u7ea7\u56e0\u679c\u63a8\u65ad\u7684\u8f6c\u53d8\uff0c\u4e3a\u89e3\u51b3\u4e2a\u4f53\u56e0\u679c\u63a8\u65ad\u96be\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u65b9\u6cd5\u652f\u6301\u3002"}}
{"id": "2506.17347", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17347", "abs": "https://arxiv.org/abs/2506.17347", "authors": ["Jennifer Wang", "Andrew Selbst", "Solon Barocas", "Suresh Venkatasubramanian"], "title": "Distinguishing Predictive and Generative AI in Regulation", "comment": null, "summary": "Over the past decade, policymakers have developed a set of regulatory tools\nto ensure AI development aligns with key societal goals. Many of these tools\nwere initially developed in response to concerns with predictive AI and\ntherefore encode certain assumptions about the nature of AI systems and the\nutility of certain regulatory approaches. With the advent of generative AI,\nhowever, some of these assumptions no longer hold, even as policymakers attempt\nto maintain a single regulatory target that covers both types of AI.\n  In this paper, we identify four distinct aspects of generative AI that call\nfor meaningfully different policy responses. These are the generality and\nadaptability of generative AI that make it a poor regulatory target, the\ndifficulty of designing effective evaluations, new legal concerns that change\nthe ecosystem of stakeholders and sources of expertise, and the distributed\nstructure of the generative AI value chain.\n  In light of these distinctions, policymakers will need to evaluate where the\npast decade of policy work remains relevant and where new policies, designed to\naddress the unique risks posed by generative AI, are necessary. We outline\nthree recommendations for policymakers to more effectively identify regulatory\ntargets and leverage constraints across the broader ecosystem to govern\ngenerative AI.", "AI": {"tldr": "\u968f\u7740\u751f\u6210\u5f0fAI\u5174\u8d77\uff0c\u4f20\u7edfAI\u76d1\u7ba1\u5de5\u5177\u4e0d\u518d\u5b8c\u5168\u9002\u7528\uff0c\u672c\u6587\u5206\u6790\u4e86\u751f\u6210\u5f0fAI\u7684\u56db\u5927\u7279\u6027\u548c\u76f8\u5e94\u653f\u7b56\u6311\u6218\uff0c\u547c\u5401\u5236\u5b9a\u65b0\u7684\u76d1\u7ba1\u653f\u7b56\uff0c\u5e76\u63d0\u51fa\u4e09\u9879\u5177\u4f53\u5efa\u8bae\u4ee5\u66f4\u597d\u5730\u7ba1\u7406\u751f\u6210\u5f0fAI\u53d1\u5c55\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u7684\u51fa\u73b0\uff0c\u73b0\u6709\u9488\u5bf9\u9884\u6d4b\u578bAI\u5236\u5b9a\u7684\u76d1\u7ba1\u5de5\u5177\u4e0e\u5047\u8bbe\u53ef\u80fd\u5df2\u4e0d\u518d\u9002\u7528\u4e8e\u65b0\u578b\u98ce\u9669\u4e0e\u7279\u6027\uff0c\u6709\u5fc5\u8981\u91cd\u65b0\u5ba1\u89c6\u548c\u8c03\u6574\u653f\u7b56\u3002", "method": "\u5206\u6790\u751f\u6210\u5f0fAI\u76f8\u8f83\u4e8e\u9884\u6d4b\u6027AI\u7684\u56db\u4e2a\u4e0d\u540c\u7279\u6027\u53ca\u5176\u5e26\u6765\u7684\u653f\u7b56\u6311\u6218\uff0c\u5e76\u5bf9\u6bd4\u73b0\u6709\u653f\u7b56\u7684\u9002\u7528\u6027\uff0c\u8fdb\u4e00\u6b65\u63d0\u51fa\u9488\u5bf9\u751f\u6210\u5f0fAI\u7684\u653f\u7b56\u5efa\u8bae\u3002", "result": "\u63d0\u51fa\u751f\u6210\u5f0fAI\u5177\u5907\u56db\u4e2a\u5173\u952e\u7279\u5f81\uff1a\u666e\u904d\u6027\u548c\u9002\u5e94\u6027\u5f3a\u96be\u4ee5\u7cbe\u51c6\u76d1\u7ba1\u3001\u8bc4\u4f30\u6709\u6548\u6027\u96be\u5ea6\u589e\u5927\u3001\u65b0\u7684\u6cd5\u5f8b\u53ca\u5229\u76ca\u76f8\u5173\u65b9\u53d8\u5316\u3001\u4ef7\u503c\u94fe\u5206\u5e03\u5e7f\u6cdb\u3002\u8fd9\u4e9b\u90fd\u8981\u6c42\u653f\u7b56\u5236\u5b9a\u8005\u91cd\u65b0\u8861\u91cf\u548c\u8c03\u6574\u539f\u6709\u76d1\u7ba1\u7b56\u7565\uff0c\u5e76\u7ed9\u51fa\u76f8\u5e94\u7684\u4e09\u6761\u653f\u7b56\u5efa\u8bae\u3002", "conclusion": "\u73b0\u6709AI\u76d1\u7ba1\u65b9\u6848\u9700\u9488\u5bf9\u751f\u6210\u5f0fAI\u72ec\u6709\u7684\u98ce\u9669\u4e0e\u6311\u6218\u8fdb\u884c\u8c03\u6574\uff0c\u653f\u7b56\u5236\u5b9a\u8005\u5fc5\u987b\u7ed3\u5408\u751f\u6001\u7cfb\u7edf\u7ea6\u675f\u548c\u65b0\u7684\u76d1\u7ba1\u76ee\u6807\uff0c\u5236\u5b9a\u66f4\u6709\u6548\u7684\u653f\u7b56\u3002"}}
{"id": "2506.17830", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.17830", "abs": "https://arxiv.org/abs/2506.17830", "authors": ["Amina El Bachari", "Johann Rannou", "Vladislav A. Yastrebov", "Pierre Kerfriden", "Susanne Claus"], "title": "A predictor-corrector scheme for approximating signed distances using finite element methods", "comment": "26 pages, 17 figures", "summary": "In this article, we introduce a finite element method designed for the robust\ncomputation of approximate signed distance functions to arbitrary boundaries in\ntwo and three dimensions. Our method employs a novel prediction-correction\napproach, involving first the solution of a linear diffusion-based prediction\nproblem, followed by a nonlinear minimization-based correction problem\nassociated with the Eikonal equation. The prediction step efficiently generates\na suitable initial guess, significantly facilitating convergence of the\nnonlinear correction step. A key strength of our approach is its ability to\nhandle complex interfaces and initial level set functions with arbitrary steep\nor flat regions, a notable challenge for existing techniques. Through several\nrepresentative examples, including classical geometries and more complex shapes\nsuch as star domains and three-dimensional tori, we demonstrate the accuracy,\nefficiency, and robustness of the method, validating its broad applicability\nfor reinitializing diverse level set functions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7ebf\u6027\u6269\u6563\u9884\u6d4b\u4e0e\u975e\u7ebf\u6027\u6821\u6b63\u7684\u6709\u9650\u5143\u65b9\u6cd5\uff0c\u9ad8\u6548\u51c6\u786e\u5730\u903c\u8fd1\u4efb\u610f\u7ef4\u590d\u6742\u8fb9\u754c\u4e0b\u7684\u5e26\u7b26\u53f7\u8ddd\u79bb\u51fd\u6570\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5904\u7406\u590d\u6742\u754c\u9762\u548c\u6781\u7aef\u521d\u59cb\u6761\u4ef6\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u6709\u9650\u5143\u65b9\u6cd5\u5728\u903c\u8fd1\u4efb\u610f\u590d\u6742\u8fb9\u754c\u7684\u5e26\u7b26\u53f7\u8ddd\u79bb\u51fd\u6570\u65f6\u9762\u4e34\u6570\u503c\u6536\u655b\u6027\u548c\u5904\u7406\u590d\u6742\u754c\u9762\u5f62\u72b6\u7684\u6311\u6218\u3002\u5c24\u5176\u662f\u5728\u521d\u59cb\u6c34\u5e73\u96c6\u51fd\u6570\u5305\u542b\u4efb\u610f\u9661\u5ced\u6216\u5e73\u5766\u533a\u57df\u65f6\uff0c\u73b0\u6709\u6280\u672f\u5e38\u5e38\u96be\u4ee5\u83b7\u5f97\u51c6\u786e\u548c\u9c81\u68d2\u7684\u91cd\u521d\u59cb\u5316\u7ed3\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u6709\u9650\u5143\u65b9\u6cd5\uff0c\u5305\u62ec\u7ebf\u6027\u6269\u6563\u9884\u6d4b\u6b65\u9aa4\u548c\u57fa\u4e8e\u975e\u7ebf\u6027\u6781\u5c0f\u5316\u7684\u6821\u6b63\u6b65\u9aa4\u3002\u9996\u5148\u901a\u8fc7\u6c42\u89e3\u6269\u6563\u95ee\u9898\u5f97\u5230\u521d\u59cb\u731c\u6d4b\uff0c\u7136\u540e\u901a\u8fc7\u4e0eEikonal\u65b9\u7a0b\u76f8\u5173\u7684\u975e\u7ebf\u6027\u6781\u5c0f\u5316\u8fdb\u4e00\u6b65\u6821\u6b63\uff0c\u63d0\u9ad8\u4e86\u6536\u655b\u6027\u548c\u51c6\u786e\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u590d\u6742\u754c\u9762\u4ee5\u53ca\u521d\u59cb\u6c34\u5e73\u96c6\u51fd\u6570\u7684\u6781\u7aef\u533a\u57df\uff08\u9661\u5ced/\u5e73\u5766\uff09\uff0c\u5e76\u5728\u4e0d\u540c\u4ee3\u8868\u6027\u793a\u4f8b\uff08\u5982\u7ecf\u5178\u51e0\u4f55\u4f53\u3001\u661f\u57df\u3001\u4e09\u7ef4\u73af\u9762\uff09\u4e2d\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u3001\u9ad8\u6548\u7387\u548c\u5f3a\u9c81\u68d2\u6027\uff0c\u9a8c\u8bc1\u5176\u9002\u7528\u4e8e\u591a\u6837\u5316\u6c34\u5e73\u96c6\u51fd\u6570\u7684\u91cd\u521d\u59cb\u5316\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6709\u9650\u5143\u65b9\u6cd5\u4e0d\u4ec5\u9ad8\u6548\u9c81\u68d2\u5730\u903c\u8fd1\u4efb\u610f\u8fb9\u754c\u7684\u5e26\u7b26\u53f7\u8ddd\u79bb\u51fd\u6570\uff0c\u8fd8\u514b\u670d\u4e86\u73b0\u6709\u6280\u672f\u96be\u4ee5\u5904\u7406\u590d\u6742\u5f62\u72b6\u548c\u6781\u7aef\u521d\u59cb\u6761\u4ef6\u7684\u5c40\u9650\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.17286", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17286", "abs": "https://arxiv.org/abs/2506.17286", "authors": ["Luoyang Sun", "Jiwen Jiang", "Cheng Deng", "Xinjian Wu", "Haifeng Zhang", "Lei Chen", "Lionel Ni", "Jun Wang"], "title": "GTA: Grouped-head latenT Attention", "comment": null, "summary": "Attention mechanisms underpin the success of large language models (LLMs),\nyet their substantial computational and memory overhead poses challenges for\noptimizing efficiency and performance. A critical bottleneck arises as KV cache\nand attention computations scale rapidly with text length, challenging\ndeployment on hardware with limited computational and memory resources. We\nobserve that attention mechanisms exhibit substantial redundancy, since the KV\ncache can be significantly compressed and attention maps across heads display\nhigh similarity, revealing that much of the computation and storage is\nunnecessary. Leveraging these insights, we propose \\textbf{G}rouped-Head\nLaten\\textbf{T} \\textbf{A}ttention (GTA), a novel attention mechanism that\nreduces memory usage and computational complexity while maintaining\nperformance. GTA comprises two components: (1) a shared attention map mechanism\nthat reuses attention scores across multiple heads, decreasing the key cache\nsize; and (2) a nonlinear value decoder with learned projections that\ncompresses the value cache into a latent space, further cutting memory needs.\nGTA cuts attention computation FLOPs by up to \\emph{62.5\\%} versus\nGrouped-Query Attention and shrink the KV cache by up to \\emph{70\\%}, all while\navoiding the extra overhead of Multi-Head Latent Attention to improve LLM\ndeployment efficiency. Consequently, GTA models achieve a \\emph{2x} increase in\nend-to-end inference speed, with prefill benefiting from reduced computational\ncost and decoding benefiting from the smaller cache footprint.", "AI": {"tldr": "GTA\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u5171\u4eab\u6ce8\u610f\u529b\u5206\u6570\u548c\u538b\u7f29KV\u7f13\u5b58\uff0c\u5927\u5e45\u51cf\u5c11\u5927\u6a21\u578b\u63a8\u7406\u6240\u9700\u8ba1\u7b97\u548c\u5185\u5b58\uff0c\u63d0\u5347\u4e86\u90e8\u7f72\u4e0e\u63a8\u7406\u901f\u5ea6\uff0c\u5e76\u517c\u987e\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6ce8\u610f\u529b\u673a\u5236\u5b58\u5728\u5927\u91cf\u8ba1\u7b97\u4e0e\u5b58\u50a8\u5197\u4f59\uff0cKV\u7f13\u5b58\u548c\u6ce8\u610f\u529b\u8ba1\u7b97\u5728\u5e8f\u5217\u957f\u5ea6\u589e\u957f\u65f6\u6025\u5267\u589e\u52a0\uff0c\u9650\u5236\u4e86\u5728\u8d44\u6e90\u6709\u9650\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u4e86Grouped-Head Latent Attention (GTA)\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5305\u542b\u5171\u4eab\u6ce8\u610f\u529b\u56fe\u548c\u975e\u7ebf\u6027\u503c\u89e3\u7801\u5668\u4e24\u90e8\u5206\uff0c\u5b9e\u73b0\u5bf9KV\u7f13\u5b58\u548c\u8fd0\u7b97\u7684\u9ad8\u6548\u538b\u7f29\u4e0e\u590d\u7528\u3002", "result": "\u4e0eGrouped-Query Attention\u65b9\u6cd5\u76f8\u6bd4\uff0cGTA\u5c06\u6ce8\u610f\u529b\u8ba1\u7b97FLOPs\u964d\u4f4e\u4e8662.5%\uff0cKV\u7f13\u5b58\u7f29\u5c0f70%\uff0c\u65e0\u591a\u4f59\u5f00\u9500\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e862\u500d\u63a8\u7406\u901f\u5ea6\u63d0\u5347\uff0c\u540c\u65f6\u5728prefill\u548cdecoding\u9636\u6bb5\u90fd\u964d\u4f4e\u4e86\u786c\u4ef6\u538b\u529b\u3002", "conclusion": "GTA\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u6a21\u578b\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2506.17434", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17434", "abs": "https://arxiv.org/abs/2506.17434", "authors": ["Sydney Levine", "Matija Franklin", "Tan Zhi-Xuan", "Secil Yanik Guyot", "Lionel Wong", "Daniel Kilov", "Yejin Choi", "Joshua B. Tenenbaum", "Noah Goodman", "Seth Lazar", "Iason Gabriel"], "title": "Resource Rational Contractualism Should Guide AI Alignment", "comment": "24 pages, 10 figures", "summary": "AI systems will soon have to navigate human environments and make decisions\nthat affect people and other AI agents whose goals and values diverge.\nContractualist alignment proposes grounding those decisions in agreements that\ndiverse stakeholders would endorse under the right conditions, yet securing\nsuch agreement at scale remains costly and slow -- even for advanced AI. We\ntherefore propose Resource-Rational Contractualism (RRC): a framework where AI\nsystems approximate the agreements rational parties would form by drawing on a\ntoolbox of normatively-grounded, cognitively-inspired heuristics that trade\neffort for accuracy. An RRC-aligned agent would not only operate efficiently,\nbut also be equipped to dynamically adapt to and interpret the ever-changing\nhuman social world.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u8d44\u6e90\u7406\u6027\u5951\u7ea6\u4e3b\u4e49\u6846\u67b6\uff0c\u8ba9AI\u501f\u52a9\u8ba4\u77e5\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u9ad8\u6548\u8fd1\u4f3c\u7fa4\u4f53\u8ba4\u540c\u7684\u51b3\u7b56\uff0c\u5b9e\u73b0\u66f4\u5177\u793e\u4f1a\u9002\u5e94\u6027\u7684\u9053\u4e49\u5bf9\u9f50\u3002", "motivation": "\u4f20\u7edf\u7684\u9053\u4e49\u534f\u5546\u65b9\u5f0f\u96be\u4ee5\u5927\u89c4\u6a21\u5b9e\u73b0\uff0c\u5c24\u5176\u662f\u5728AI\u8981\u4e0e\u7acb\u573a\u548c\u4ef7\u503c\u89c2\u5404\u5f02\u7684\u4eba\u7c7b\u53ca\u5176\u4ed6AI\u4e92\u52a8\u65f6\uff0c\u5982\u4f55\u9ad8\u6548\u8fbe\u6210\u5e7f\u6cdb\u8ba4\u53ef\u7684\u51b3\u7b56\u6210\u4e3a\u96be\u9898\u3002", "method": "\u63d0\u51fa\u8d44\u6e90\u7406\u6027\u5951\u7ea6\u4e3b\u4e49\uff08Resource-Rational Contractualism, RRC\uff09\u6846\u67b6\uff0c\u4f7fAI\u7cfb\u7edf\u901a\u8fc7\u4e00\u7cfb\u5217\u53d7\u5230\u4eba\u7c7b\u8ba4\u77e5\u542f\u53d1\u3001\u5177\u6709\u89c4\u8303\u57fa\u7840\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u6743\u8861\u8ba1\u7b97\u52aa\u529b\u4e0e\u51b3\u7b56\u51c6\u786e\u6027\uff0c\u4ece\u800c\u8fd1\u4f3c\u5404\u65b9\u5728\u5408\u7406\u6761\u4ef6\u4e0b\u8fbe\u6210\u7684\u534f\u8bae\u3002", "result": "RRC\u5bf9\u9f50\u7684AI\u4ee3\u7406\u4e0d\u4ec5\u9ad8\u6548\u8fd0\u884c\uff0c\u8fd8\u80fd\u591f\u9002\u5e94\u5e76\u89e3\u91ca\u4e0d\u65ad\u53d8\u5316\u7684\u4eba\u7c7b\u793e\u4f1a\u73af\u5883\u3002", "conclusion": "\u901a\u8fc7RRC\u65b9\u6cd5\uff0cAI\u53ef\u4ee5\u5728\u6210\u672c\u8f83\u4f4e\u3001\u6548\u7387\u8f83\u9ad8\u7684\u60c5\u51b5\u4e0b\u4f5c\u51fa\u66f4\u7b26\u5408\u591a\u5143\u7fa4\u4f53\u610f\u613f\u7684\u51b3\u7b56\uff0c\u4e3aAI\u5728\u591a\u6837\u5316\u4eba\u7c7b\u573a\u666f\u4e0b\u7684\u9053\u4e49\u5bf9\u9f50\u63d0\u4f9b\u53ef\u884c\u9014\u5f84\u3002"}}
{"id": "2506.17354", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17354", "abs": "https://arxiv.org/abs/2506.17354", "authors": ["Farah Altarazi"], "title": "Evaluating the Impact of Lean and Green Practices on Operational Performance: A Real Data-Driven Simulation Case Study", "comment": "16 pages, 6 Figures, 4 Tables, This work is based on part of my\n  Master's thesis at the Department of Industrial Engineering, University of\n  Jordan, Jordan", "summary": "Global market-driven forces and customer needs are continuously changing. In\nthe past, profitability and efficiency were the primary objectives of most\ncompanies. However, in recent decades, sustainable performance has emerged as a\nnew competitive advantage. Companies have been compelled to adopt a concept\nthat combines these evolving global interests with traditional goals resulting\nin the innovation of the lean and green approach.\n  In this study, a research methodology that includes system analysis and\nmodeling procedures to apply the lean and green concept, combined with a new\nevaluation metric, the Overall Environmental Equipment Effectiveness (OEEE) was\nused to investigate the effects of adopting lean and green practices on overall\nperformance.\n  A simulation model and energy value stream mapping were implemented, and the\nOEEE value was calculated to assess the current performance in terms of\nquality, availability, productivity, and sustainability. The current state\nproduction lead time was 329.1 minutes per batch, and the OEEE value was 13.1%.\nThis result indicates existing issues in performance and sustainability,\nsuggesting that improvement efforts should focus on enhancing these two aspects\nto increase the overall OEEE value.\n  Several improvement scenarios were proposed, including combining and\nrearranging the inspection workstations as the first scenario, and using UV\nlighting for drying purposes at the framing workstation as the second. After\napplying these improvements, both scenarios showed increased OEEE values and\nreduced lead times compared to the current state. In the first scenario, the\nlead time decreased to 158.23 minutes, and the OEEE increased to 35%. In the\nsecond scenario, the lead time was reduced to 292 minutes, with the OEEE\nincreasing to 24%.", "AI": {"tldr": "\u672c\u6587\u7ed3\u5408\u7cbe\u76ca\u4e0e\u7eff\u8272\u751f\u4ea7\u7406\u5ff5\uff0c\u901a\u8fc7\u7cfb\u7edf\u5efa\u6a21\u548cOEEE\u6307\u6807\u8bc4\u4f30\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u7cfb\u5217\u751f\u4ea7\u4f18\u5316\u63aa\u65bd\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8fd9\u4e9b\u6539\u8fdb\u663e\u8457\u63d0\u5347\u4e86\u8bbe\u5907\u6574\u4f53\u73af\u5883\u6548\u7387\u548c\u751f\u4ea7\u6548\u7387\uff0c\u5f3a\u8c03\u4e86\u7efc\u5408\u53ef\u6301\u7eed\u7ba1\u7406\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5728\u5168\u7403\u5e02\u573a\u9a71\u52a8\u548c\u5ba2\u6237\u9700\u6c42\u4e0d\u65ad\u53d8\u5316\u7684\u80cc\u666f\u4e0b\uff0c\u53ef\u6301\u7eed\u53d1\u5c55\u6210\u4e3a\u65b0\u7684\u7ade\u4e89\u4f18\u52bf\uff0c\u9a71\u4f7f\u4f01\u4e1a\u5c06\u4f20\u7edf\u7684\u76c8\u5229\u4e0e\u6548\u7387\u76ee\u6807\u4e0e\u53ef\u6301\u7eed\u76ee\u6807\u7ed3\u5408\uff0c\u521b\u65b0\u7cbe\u76ca\u4e0e\u7eff\u8272\u7ba1\u7406\u7406\u5ff5\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u5206\u6790\u548c\u5efa\u6a21\u65b9\u6cd5\uff0c\u5f15\u5165\u5e76\u8ba1\u7b97\u6574\u4f53\u73af\u5883\u8bbe\u5907\u6548\u7387\uff08OEEE\uff09\uff0c\u5229\u7528\u4eff\u771f\u5efa\u6a21\u548c\u80fd\u8017\u4ef7\u503c\u6d41\u7a0b\u56fe\uff0c\u8bc4\u4f30\u548c\u4f18\u5316\u751f\u4ea7\u6d41\u7a0b\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u8fdb\u884c\u60c5\u5883\u5206\u6790\u3002", "result": "\u73b0\u6709\u7cfb\u7edfOEEE\u503c\u4ec5\u4e3a13.1%\uff0c\u751f\u4ea7\u5468\u671f\u8f83\u957f\u3002\u901a\u8fc7\u4f18\u5316\u5de5\u5e8f\u548c\u91c7\u7528\u65b0\u6280\u672f\uff0c\u4e24\u79cd\u6539\u8fdb\u65b9\u6848\u5c06OEEE\u63d0\u5347\u81f324%\u548c35%\uff0c\u751f\u4ea7\u5468\u671f\u5206\u522b\u964d\u81f3292\u5206\u949f\u548c158.23\u5206\u949f\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5c06\u7cbe\u76ca\u4e0e\u7eff\u8272\u751f\u4ea7\u65b9\u6cd5\u7ed3\u5408\uff0c\u5e76\u5e94\u7528OEEE\u6307\u6807\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u751f\u4ea7\u7cfb\u7edf\u7684\u53ef\u6301\u7eed\u6027\u548c\u6574\u4f53\u7ee9\u6548\u3002\u63d0\u51fa\u7684\u6539\u8fdb\u63aa\u65bd\u5728\u6a21\u62df\u4e2d\u5747\u8868\u73b0\u51fa\u66f4\u9ad8\u7684OEEE\u503c\u548c\u66f4\u77ed\u7684\u751f\u4ea7\u5468\u671f\uff0c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.17964", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.17964", "abs": "https://arxiv.org/abs/2506.17964", "authors": ["Bolin Shen", "Eren Erman Ozguven", "Yue Zhao", "Guang Wang", "Yiqun Xie", "Yushun Dong"], "title": "Learning from the Storm: A Multivariate Machine Learning Approach to Predicting Hurricane-Induced Economic Losses", "comment": null, "summary": "Florida is particularly vulnerable to hurricanes, which frequently cause\nsubstantial economic losses. While prior studies have explored specific\ncontributors to hurricane-induced damage, few have developed a unified\nframework capable of integrating a broader range of influencing factors to\ncomprehensively assess the sources of economic loss. In this study, we propose\na comprehensive modeling framework that categorizes contributing factors into\nthree key components: (1) hurricane characteristics, (2) water-related\nenvironmental factors, and (3) socioeconomic factors of affected areas. By\nintegrating multi-source data and aggregating all variables at the finer\nspatial granularity of the ZIP Code Tabulation Area (ZCTA) level, we employ\nmachine learning models to predict economic loss, using insurance claims as\nindicators of incurred damage. Beyond accurate loss prediction, our approach\nfacilitates a systematic assessment of the relative importance of each\ncomponent, providing practical guidance for disaster mitigation, risk\nassessment, and the development of adaptive urban strategies in coastal and\nstorm-exposed areas. Our code is now available at:\nhttps://github.com/LabRAI/Hurricane-Induced-Economic-Loss-Prediction", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u98d3\u98ce\u7279\u5f81\u3001\u6c34\u73af\u5883\u548c\u793e\u4f1a\u7ecf\u6d4e\u4e09\u5927\u56e0\u7d20\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5c0f\u5c3a\u5ea6\uff08ZCTA\uff09\u4e0a\u9884\u6d4b\u548c\u5206\u6790\u98d3\u98ce\u9020\u6210\u7684\u7ecf\u6d4e\u635f\u5931\uff0c\u5e76\u5b9a\u91cf\u533a\u5206\u5404\u7c7b\u5f71\u54cd\u7684\u91cd\u8981\u6027\uff0c\u4ece\u800c\u4e3a\u707e\u5bb3\u7ba1\u7406\u548c\u57ce\u5e02\u51b3\u7b56\u63d0\u4f9b\u5177\u4f53\u6307\u5bfc\u3002", "motivation": "\u4f5b\u7f57\u91cc\u8fbe\u5dde\u9891\u7e41\u906d\u53d7\u98d3\u98ce\u4fb5\u88ad\uff0c\u9020\u6210\u5de8\u5927\u7684\u7ecf\u6d4e\u635f\u5931\u3002\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u63a2\u8ba8\u98d3\u98ce\u635f\u5931\u7684\u5177\u4f53\u5f71\u54cd\u56e0\u7d20\uff0c\u4f46\u5f88\u5c11\u6709\u7814\u7a76\u63d0\u51fa\u80fd\u6574\u5408\u591a\u56e0\u7d20\u7684\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\u3002\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5168\u9762\u8bc6\u522b\u548c\u89e3\u6790\u7ecf\u6d4e\u635f\u5931\u6765\u6e90\u7684\u7edf\u4e00\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u5c06\u98d3\u98ce\u635f\u5931\u5f71\u54cd\u56e0\u7d20\u5206\u4e3a\u4e09\u4e2a\u4e3b\u8981\u90e8\u5206\uff1a\uff081\uff09\u98d3\u98ce\u7684\u81ea\u8eab\u7279\u6027\uff1b\uff082\uff09\u4e0e\u6c34\u6709\u5173\u7684\u73af\u5883\u56e0\u5b50\uff1b\uff083\uff09\u53d7\u5f71\u54cd\u533a\u57df\u7684\u793e\u4f1a\u7ecf\u6d4e\u7279\u5f81\u3002\u901a\u8fc7\u6574\u5408\u591a\u6e90\u6570\u636e\uff0c\u5e76\u5c06\u6240\u6709\u53d8\u91cf\u7ec6\u5316\u5230\u90ae\u653f\u7f16\u7801\u533a\uff08ZCTA\uff09\u5c42\u7ea7\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ee5\u4fdd\u9669\u7406\u8d54\u4f5c\u4e3a\u7ecf\u6d4e\u635f\u5931\u7684\u6307\u6807\u8fdb\u884c\u9884\u6d4b\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u652f\u6301\u7cfb\u7edf\u8861\u91cf\u5404\u7c7b\u56e0\u7d20\u5bf9\u635f\u5931\u7684\u76f8\u5bf9\u91cd\u8981\u6027\u5206\u6790\u3002", "result": "\u63d0\u51fa\u4e86\u7efc\u5408\u5efa\u6a21\u6846\u67b6\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u7ecf\u6d4e\u635f\u5931\uff0c\u5e76\u91cf\u5316\u4e0d\u540c\u56e0\u7d20\u5bf9\u635f\u5931\u7684\u8d21\u732e\uff0c\u4e3a\u707e\u5bb3\u51cf\u7f13\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u57ce\u5e02\u9002\u5e94\u6027\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9e\u7528\u51b3\u7b56\u4f9d\u636e\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "conclusion": "\u672c\u7814\u7a76\u5efa\u7acb\u4e86\u591a\u56e0\u7d20\u4e00\u4f53\u5316\u7684\u98d3\u98ce\u7ecf\u6d4e\u635f\u5931\u9884\u6d4b\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\uff0c\u8fd8\u63ed\u793a\u4e86\u4e0d\u540c\u56e0\u7d20\u5728\u635f\u5931\u4e2d\u7684\u4f5c\u7528\uff0c\u4e3a\u98d3\u98ce\u591a\u53d1\u53ca\u6cbf\u6d77\u57ce\u5e02\u63d0\u4f9b\u4e86\u79d1\u5b66\u7684\u5e94\u5bf9\u548c\u89c4\u5212\u5efa\u8bae\u3002"}}
{"id": "2506.17294", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17294", "abs": "https://arxiv.org/abs/2506.17294", "authors": ["Qirui Zheng", "Xingbo Wang", "Keyuan Cheng", "Yunlong Lu", "Wenxin Li"], "title": "AI-Generated Game Commentary: A Survey and a Datasheet Repository", "comment": null, "summary": "AI-Generated Game Commentary (AIGGC) has gained increasing attention due to\nits market potential and inherent technical challenges. As a comprehensive\nmultimodal Natural Language Processing (NLP) task, AIGGC imposes substantial\ndemands on language models, including factual accuracy, logical reasoning,\nexpressive text generation, generation speed, and context management. In this\npaper, we introduce a general framework for AIGGC and present a comprehensive\nsurvey of 45 existing game commentary dataset and methods according to key\nchallenges they aim to address in this domain. We further classify and compare\nvarious evaluation metrics commonly used in this domain. To support future\nresearch and benchmarking, we also provide a structured datasheet summarizing\nthe essential attributes of these datasets in appendix, which is meanwhile\npublicly available in an open repository.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86AI\u6e38\u620f\u89e3\u8bf4\u9886\u57df\u7684\u6311\u6218\u3001\u65b9\u6cd5\u548c\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u4e86\u4e00\u822c\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u8d44\u6599\u6c47\u603b\uff0c\u6709\u5229\u4e8e\u672a\u6765\u7814\u7a76\u3002", "motivation": "AI\u751f\u6210\u6e38\u620f\u89e3\u8bf4\u56e0\u5176\u5e02\u573a\u6f5c\u529b\u548c\u6280\u672f\u6311\u6218\u53d7\u5230\u5173\u6ce8\uff0c\u9700\u8981\u5f3a\u5927\u7684\u591a\u6a21\u6001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86AIGGC\u7684\u4e00\u822c\u6846\u67b6\uff0c\u5168\u9762\u8c03\u7814\u4e8645\u79cd\u73b0\u6709\u7684\u6570\u636e\u96c6\u548c\u65b9\u6cd5\uff0c\u5e76\u5206\u7c7b\u6bd4\u8f83\u4e86\u4e3b\u6d41\u8bc4\u6d4b\u6307\u6807\u3002\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7684\u6570\u636e\u96c6\u6982\u8981\u8868\u3002", "result": "\u5f52\u7eb3\u4e86\u8be5\u9886\u57df\u7684\u5173\u952e\u6311\u6218\uff0c\u5bf9\u73b0\u6709\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u6574\u7406\u548c\u6bd4\u8f83\uff0c\u516c\u5f00\u4e86\u76f8\u5173\u6570\u636e\u6c47\u603b\u4ee5\u4fbf\u672a\u6765\u7814\u7a76\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u6027\u5de5\u4f5c\u4e3aAIGGC\u9886\u57df\u7684\u7814\u7a76\u4e0e\u8bc4\u6d4b\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u548c\u7cfb\u7edf\u8d44\u6599\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u65b9\u5411\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.17442", "categories": ["cs.AI", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17442", "abs": "https://arxiv.org/abs/2506.17442", "authors": ["Hao Guan", "David Bates", "Li Zhou"], "title": "Keeping Medical AI Healthy: A Review of Detection and Correction Methods for System Degradation", "comment": "15 pages, 5 figures", "summary": "Artificial intelligence (AI) is increasingly integrated into modern\nhealthcare, offering powerful support for clinical decision-making. However, in\nreal-world settings, AI systems may experience performance degradation over\ntime, due to factors such as shifting data distributions, changes in patient\ncharacteristics, evolving clinical protocols, and variations in data quality.\nThese factors can compromise model reliability, posing safety concerns and\nincreasing the likelihood of inaccurate predictions or adverse outcomes. This\nreview presents a forward-looking perspective on monitoring and maintaining the\n\"health\" of AI systems in healthcare. We highlight the urgent need for\ncontinuous performance monitoring, early degradation detection, and effective\nself-correction mechanisms. The paper begins by reviewing common causes of\nperformance degradation at both data and model levels. We then summarize key\ntechniques for detecting data and model drift, followed by an in-depth look at\nroot cause analysis. Correction strategies are further reviewed, ranging from\nmodel retraining to test-time adaptation. Our survey spans both traditional\nmachine learning models and state-of-the-art large language models (LLMs),\noffering insights into their strengths and limitations. Finally, we discuss\nongoing technical challenges and propose future research directions. This work\naims to guide the development of reliable, robust medical AI systems capable of\nsustaining safe, long-term deployment in dynamic clinical settings.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u533b\u7597AI\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898\uff0c\u5206\u6790\u539f\u56e0\uff0c\u603b\u7ed3\u68c0\u6d4b\u4e0e\u4fee\u6b63\u624b\u6bb5\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u5efa\u8bae\uff0c\u4e3aAI\u5065\u5eb7\u7ba1\u7406\u63d0\u4f9b\u4e86\u5168\u9762\u6307\u5bfc\u3002", "motivation": "AI\u7cfb\u7edf\u5728\u5b9e\u9645\u533b\u7597\u73af\u5883\u4e2d\u53ef\u80fd\u56e0\u6570\u636e\u5206\u5e03\u53d8\u5316\u3001\u60a3\u8005\u7279\u5f81\u53d8\u8fc1\u3001\u4e34\u5e8a\u534f\u8bae\u548c\u6570\u636e\u8d28\u91cf\u53d8\u5316\u7b49\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u8fd9\u4e9b\u95ee\u9898\u5a01\u80c1\u5230\u6a21\u578b\u53ef\u9760\u6027\u4e43\u81f3\u533b\u7597\u5b89\u5168\uff0c\u4e9f\u9700\u673a\u5236\u4fdd\u8bc1AI\u7cfb\u7edf\u957f\u671f\u6709\u6548\u8fd0\u884c\u3002", "method": "\u7cfb\u7edf\u6027\u7efc\u8ff0\u4e86AI\u5728\u533b\u7597\u9886\u57df\u6027\u80fd\u9000\u5316\u7684\u4e3b\u8981\u539f\u56e0\u3001\u6f02\u79fb\u68c0\u6d4b\u6280\u672f\u3001\u6839\u56e0\u5206\u6790\u4ee5\u53ca\u6a21\u578b\u4fee\u6b63\u624b\u6bb5\uff0c\u6db5\u76d6\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u8bc4\u4ef7\u4e86\u5404\u81ea\u4f18\u7f3a\u70b9\u548c\u9002\u7528\u573a\u666f\u3002", "result": "\u603b\u7ed3\u4e86\u6570\u636e\u548c\u6a21\u578b\u6f02\u79fb\u68c0\u6d4b\u3001\u6839\u56e0\u5206\u6790\u548c\u4fee\u6b63\u65b9\u6cd5\uff0c\u4e3a\u533b\u7597AI\u7cfb\u7edf\u5e94\u7528\u4e2d\u7684\u6280\u672f\u6311\u6218\u548c\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u89c6\u89d2\u3002\u5c55\u671b\u4e86\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u5065\u5eb7\u7ba1\u7406\u3001\u52a0\u5f3a\u5b9e\u7528\u6027\u4e0e\u5b89\u5168\u6027\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u533b\u7597AI\u7cfb\u7edf\u9700\u8981\u6301\u7eed\u76d1\u6d4b\u3001\u65e9\u671f\u9000\u5316\u68c0\u6d4b\u548c\u6709\u6548\u81ea\u6211\u4fee\u6b63\uff0c\u4ee5\u4fdd\u969c\u5176\u957f\u671f\u5b89\u5168\u3001\u53ef\u9760\u8fd0\u884c\u3002\u63a2\u8ba8\u4e86\u76ee\u524d\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u65e8\u5728\u63a8\u52a8\u533b\u7597AI\u66f4\u5065\u5eb7\u53ef\u6301\u7eed\u53d1\u5c55\u3002"}}
{"id": "2506.17355", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17355", "abs": "https://arxiv.org/abs/2506.17355", "authors": ["Jesse McDonald", "Scott Robertson", "Anthony Peruma"], "title": "PasteTrace: A Single Source Plagiarism Detection Tool For Introductory Programming Courses", "comment": null, "summary": "Introductory Computer Science classes are important for laying the foundation\nfor advanced programming courses. However, students without prior programming\nexperience may find these courses challenging, leading to difficulties in\nunderstanding concepts and engaging in academic dishonesty such as plagiarism.\nWhile there exists plagiarism detection techniques and tools, not all of them\nare suitable for academic settings, especially in introductory programming\ncourses. This paper introduces PasteTrace, a novel open-source plagiarism\ndetection tool designed specifically for introductory programming courses.\nUnlike traditional methods, PasteTrace operates within an Integrated\nDevelopment Environment that tracks the student's coding activities in\nreal-time for evidence of plagiarism. Our evaluation of PasteTrace in two\nintroductory programming courses demonstrates the tool's ability to provide\ninsights into student behavior and detect various forms of plagiarism,\noutperforming an existing well-established tool.\n  A video demonstration of PasteTrace and its source code, and case study data\nare made available at https://doi.org/10.6084/m9.figshare.27115852", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u9488\u5bf9\u7f16\u7a0b\u5165\u95e8\u8bfe\u7a0b\u7684\u5b9e\u65f6\u6284\u88ad\u68c0\u6d4b\u5de5\u5177PasteTrace\uff0c\u5728\u5b9e\u9645\u6559\u5b66\u4e2d\u6548\u679c\u663e\u8457\uff0c\u4f18\u4e8e\u4f20\u7edf\u5de5\u5177\u3002", "motivation": "\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u5165\u95e8\u8bfe\u7a0b\u4e2d\uff0c\u96f6\u57fa\u7840\u5b66\u751f\u7ecf\u5e38\u4f1a\u56e0\u8bfe\u7a0b\u96be\u5ea6\u5927\u800c\u51fa\u73b0\u7406\u89e3\u56f0\u96be\u751a\u81f3\u5b66\u672f\u4e0d\u7aef\uff08\u5982\u6284\u88ad\uff09\u884c\u4e3a\uff0c\u73b0\u6709\u7684\u6284\u88ad\u68c0\u6d4b\u5de5\u5177\u5e76\u4e0d\u5b8c\u5168\u9002\u7528\u4e8e\u6b64\u7c7b\u8bfe\u7a0b\u3002", "method": "\u672c\u6587\u63d0\u51faPasteTrace\uff0c\u4e00\u79cd\u4e13\u4e3a\u7f16\u7a0b\u5165\u95e8\u8bfe\u8bbe\u8ba1\u7684\u5f00\u6e90\u6284\u88ad\u68c0\u6d4b\u5de5\u5177\u3002PasteTrace\u96c6\u6210\u4e8eIDE\u4e2d\uff0c\u5b9e\u65f6\u8ddf\u8e2a\u5b66\u751f\u7f16\u7801\u884c\u4e3a\uff0c\u8bc6\u522b\u5b66\u672f\u4e0d\u7aef\u8bc1\u636e\u3002", "result": "\u5728\u4e24\u95e8\u7f16\u7a0b\u5165\u95e8\u8bfe\u7a0b\u4e2d\u7684\u8bc4\u4f30\u8868\u660e\uff0cPasteTrace\u80fd\u591f\u6709\u6548\u6d1e\u5bdf\u5b66\u751f\u884c\u4e3a\u3001\u68c0\u6d4b\u591a\u79cd\u6284\u88ad\u65b9\u5f0f\uff0c\u5e76\u4e14\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u5de5\u5177\u3002", "conclusion": "PasteTrace\u4f5c\u4e3a\u65b0\u578b\u4ee3\u7801\u6284\u88ad\u68c0\u6d4b\u5de5\u5177\uff0c\u4e3a\u7f16\u7a0b\u5165\u95e8\u6559\u5b66\u7684\u5b66\u672f\u8bda\u4fe1\u7ba1\u7406\u63d0\u4f9b\u4e86\u66f4\u4e13\u4e1a\u548c\u9ad8\u6548\u7684\u624b\u6bb5\u3002"}}
{"id": "2506.18161", "categories": ["cs.CE", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2506.18161", "abs": "https://arxiv.org/abs/2506.18161", "authors": ["Y. Navidtehrani", "C. Beteg\u00f3n", "J. Vallejos", "E. Mart\u00ednez-Pa\u00f1eda"], "title": "A phase field model for hydraulic fracture: Drucker-Prager driving force and a hybrid coupling strategy", "comment": null, "summary": "Recent years have seen a significant interest in using phase field approaches\nto model hydraulic fracture, so as to optimise a process that is key to\nindustries such as petroleum engineering, mining and geothermal energy\nextraction. Here, we present a novel theoretical and computational phase field\nframework to simulate hydraulic fracture. The framework is general and\nversatile, in that it allows for improved treatments of the coupling between\nfluid flow and the phase field, and encompasses a universal description of the\nfracture driving force. Among others, this allows us to bring two innovations\nto the phase field hydraulic fracture community: (i) a new hybrid coupling\napproach to handle the fracture-fluid flow interplay, offering enhanced\naccuracy and flexibility; and (ii) a Drucker-Prager-based strain energy\ndecomposition, extending the simulation of hydraulic fracture to materials\nexhibiting asymmetric tension-compression fracture behaviour (such as shale\nrocks) and enabling the prediction of geomechanical phenomena such as fault\nreactivation and stick-slip behaviour. Four case studies are addressed to\nillustrate these additional modelling capabilities and bring insight into\npermeability coupling, cracking behaviour, and multiaxial conditions in\nhydraulic fracturing simulations. The codes developed are made freely available\nto the community and can be downloaded from {https://mechmat.web.ox.ac.uk/", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u5957\u901a\u7528\u4e14\u7075\u6d3b\u7684\u76f8\u573a\u6c34\u529b\u538b\u88c2\u5efa\u6a21\u65b9\u6cd5\uff0c\u80fd\u66f4\u597d\u8026\u5408\u6d41\u4f53\u4e0e\u65ad\u88c2\u3001\u9002\u7528\u66f4\u591a\u6750\u6599\uff0c\u6848\u4f8b\u9a8c\u8bc1\u521b\u65b0\u6709\u6548\uff0c\u4ee3\u7801\u5df2\u5f00\u653e\u4e0b\u8f7d\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u6c34\u529b\u538b\u88c2\u4f5c\u4e3a\u77f3\u6cb9\u5de5\u7a0b\u3001\u91c7\u77ff\u548c\u5730\u70ed\u80fd\u7b49\u884c\u4e1a\u7684\u5173\u952e\u8fc7\u7a0b\uff0c\u6025\u9700\u4f18\u5316\u6a21\u62df\u65b9\u6cd5\u3002\u4f20\u7edf\u65b9\u6cd5\u5728\u6d41\u4f53-\u65ad\u88c2\u8026\u5408\u53ca\u5bf9\u590d\u6742\u6750\u6599\u884c\u4e3a\u5efa\u6a21\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u7406\u8bba\u4e0e\u6570\u503c\u6846\u67b6\u63d0\u5347\u5efa\u6a21\u80fd\u529b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7406\u8bba\u4e0e\u8ba1\u7b97\u76f8\u573a\u6846\u67b6\uff0c\u80fd\u591f\u666e\u9002\u6027\u5730\u63cf\u8ff0\u6d41\u4f53\u4e0e\u76f8\u573a\u4e4b\u95f4\u7684\u8026\u5408\u8fc7\u7a0b\uff0c\u5e76\u5bf9\u65ad\u88c2\u9a71\u52a8\u529b\u8fdb\u884c\u7edf\u4e00\u5efa\u6a21\u3002\u5177\u4f53\u521b\u65b0\u5305\u62ec\uff1a\u4e00\u662f\u63d0\u51fa\u4e86\u6df7\u5408\u8026\u5408\u65b9\u6cd5\uff0c\u63d0\u5347\u6d41\u4f53-\u65ad\u88c2\u76f8\u4e92\u4f5c\u7528\u7684\u7cbe\u5ea6\u548c\u7075\u6d3b\u6027\uff1b\u4e8c\u662f\u57fa\u4e8eDrucker-Prager\u51c6\u5219\u7684\u5e94\u53d8\u80fd\u5206\u89e3\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5177\u5f20\u62c9-\u538b\u7f29\u975e\u5bf9\u79f0\u65ad\u88c2\u884c\u4e3a\u7684\u6750\u6599\u3002\u901a\u8fc7\u56db\u4e2a\u6848\u4f8b\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u591a\u65b9\u9762\u5efa\u6a21\u80fd\u529b\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6a21\u62df\u5177\u6709\u975e\u5bf9\u79f0\u5f20\u62c9-\u538b\u7f29\u65ad\u88c2\u884c\u4e3a\u7684\u6750\u6599\uff08\u5982\u9875\u5ca9\u5ca9\u77f3\uff09\uff0c\u5e76\u9884\u6d4b\u5305\u62ec\u65ad\u5c42\u518d\u6d3b\u5316\u3001\u7c98\u6ed1\u884c\u4e3a\u7b49\u5730\u8d28\u529b\u5b66\u73b0\u8c61\u3002\u6848\u4f8b\u5c55\u793a\u4e86\u6e17\u900f\u7387\u8026\u5408\u3001\u88c2\u7f1d\u884c\u4e3a\u548c\u591a\u8f74\u5de5\u51b5\u4e0b\u7684\u5efa\u6a21\u80fd\u529b\u3002\u5f00\u53d1\u7684\u4ee3\u7801\u5df2\u514d\u8d39\u516c\u5f00\u3002", "conclusion": "\u8be5\u6587\u63d0\u51fa\u7684\u76f8\u573a\u6846\u67b6\u63d0\u5347\u4e86\u6c34\u529b\u538b\u88c2\u5efa\u6a21\u7684\u666e\u9002\u6027\u3001\u51c6\u786e\u6027\u548c\u9002\u7528\u6750\u6599\u8303\u56f4\uff0c\u4e3a\u76f8\u5173\u884c\u4e1a\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u3001\u7075\u6d3b\u7684\u6a21\u62df\u5de5\u5177\u3002"}}
{"id": "2506.17296", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17296", "abs": "https://arxiv.org/abs/2506.17296", "authors": ["Darius Foodeei", "Simin Fan", "Martin Jaggi"], "title": "Semantic uncertainty in advanced decoding methods for LLM generation", "comment": null, "summary": "This study investigates semantic uncertainty in large language model (LLM)\noutputs across different decoding methods, focusing on emerging techniques like\nspeculative sampling and chain-of-thought (CoT) decoding. Through experiments\non question answering, summarization, and code generation tasks, we analyze how\ndifferent decoding strategies affect both the diversity and reliability of\nmodel outputs. Our findings reveal that while CoT decoding demonstrates higher\nsemantic diversity, it maintains lower predictive entropy, suggesting that\nstructured exploration can lead to more confident and accurate outputs. This is\nevidenced by a 48.8% improvement in code generation Pass@2 rates, despite lower\nalignment with reference solutions. For summarization tasks, speculative\nsampling proved particularly effective, achieving superior ROUGE scores while\nmaintaining moderate semantic diversity. Our results challenge conventional\nassumptions about trade-offs between diversity and accuracy in language model\noutputs, demonstrating that properly structured decoding methods can increase\nsemantic exploration while maintaining or improving output quality. These\nfindings have significant implications for deploying language models in\npractical applications where both reliability and diverse solution generation\nare crucial.", "AI": {"tldr": "\u5b9e\u9a8c\u8868\u660e\uff0c\u521b\u65b0\u89e3\u7801\u65b9\u6cd5\uff08CoT\u3001speculative sampling\uff09\u80fd\u540c\u65f6\u63d0\u5347\u5927\u6a21\u578b\u8f93\u51fa\u7684\u591a\u6837\u6027\u548c\u53ef\u9760\u6027\uff0c\u4f18\u5316\u5b9e\u9645\u5e94\u7528\u6548\u679c\uff0c\u7a81\u7834\u4e86\u4ee5\u5f80\u4e8c\u8005\u9700\u6743\u8861\u7684\u8ba4\u77e5\u3002", "motivation": "\u73b0\u6709\u5173\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u591a\u6837\u6027\u548c\u53ef\u9760\u6027\u7684\u7814\u7a76\u901a\u5e38\u5047\u8bbe\u5b58\u5728\u6743\u8861\u5173\u7cfb\uff0c\u4f46\u968f\u7740\u65b0\u5174\u89e3\u7801\u65b9\u6cd5\uff08\u5982speculative sampling\u548cCoT\uff09\u7684\u51fa\u73b0\uff0c\u8fd9\u4e00\u5047\u8bbe\u503c\u5f97\u91cd\u65b0\u8bc4\u4f30\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u4e0d\u540c\u89e3\u7801\u7b56\u7565\u5bf9\u8f93\u51fa\u7ed3\u679c\u8bed\u4e49\u591a\u6837\u6027\u4e0e\u53ef\u9760\u6027\u7684\u5f71\u54cd\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u591a\u79cd\u89e3\u7801\u65b9\u6cd5\uff08\u5305\u62ecspeculative sampling\u548cCoT\u89e3\u7801\uff09\u5728\u95ee\u7b54\u3001\u6458\u8981\u3001\u4ee3\u7801\u751f\u6210\u7b49\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5404\u89e3\u7801\u65b9\u5f0f\u4e0b\u6a21\u578b\u8f93\u51fa\u7684\u591a\u6837\u6027\u548c\u53ef\u9760\u6027\uff0c\u5e76\u91c7\u7528\u5982Pass@2\u3001ROUGE\u7b49\u6307\u6807\u8fdb\u884c\u91cf\u5316\u5206\u6790\u3002", "result": "CoT\u89e3\u7801\u80fd\u591f\u63d0\u5347\u8bed\u4e49\u591a\u6837\u6027\uff0c\u540c\u65f6\u8868\u73b0\u51fa\u66f4\u4f4e\u7684\u9884\u6d4b\u71b5\uff08\u5373\u8f93\u51fa\u66f4\u52a0\u81ea\u4fe1\u4e14\u51c6\u786e\uff09\uff0c\u5728\u4ee3\u7801\u751f\u6210\u4e0a\u7684Pass@2\u63d0\u5347\u4e8648.8%\uff0c\u4f46\u4e0e\u53c2\u8003\u7b54\u6848\u7684\u4e00\u81f4\u6027\u7565\u4f4e\u3002\u6458\u8981\u4efb\u52a1\u4e2d\uff0cspeculative sampling\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684ROUGE\u5206\u6570\uff0c\u5e76\u4fdd\u6301\u4e86\u9002\u4e2d\u7684\u8bed\u4e49\u591a\u6837\u6027\u3002\u5b9e\u9a8c\u6311\u6218\u4e86\u591a\u6837\u6027\u4e0e\u51c6\u786e\u6027\u4e92\u4e3a\u8d1f\u76f8\u5173\u7684\u4f20\u7edf\u89c2\u70b9\u3002", "conclusion": "\u7ed3\u6784\u5316\u7684\u89e3\u7801\u65b9\u6cd5\uff08\u5982CoT\u548cspeculative sampling\uff09\u4e0d\u4ec5\u80fd\u63d0\u5347\u8bed\u4e49\u63a2\u7d22\u80fd\u529b\uff0c\u8fd8\u80fd\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u8f93\u51fa\u8d28\u91cf\u3002\u56e0\u6b64\uff0c\u5728\u5173\u6ce8\u7ed3\u679c\u53ef\u9760\u6027\u548c\u591a\u6837\u6027\u7684\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\uff0c\u91c7\u7528\u6070\u5f53\u7684\u89e3\u7801\u65b9\u5f0f\u80fd\u591f\u5e26\u6765\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2506.17449", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17449", "abs": "https://arxiv.org/abs/2506.17449", "authors": ["Manasa Bharadwaj", "Nikhil Verma", "Kevin Ferreira"], "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "comment": null, "summary": "Efforts to improve Large Language Model (LLM) agent performance on complex\ntasks have largely focused on fine-tuning and iterative self-correction.\nHowever, these approaches often lack generalizable mechanisms for longterm\nlearning and remain inefficient in dynamic environments. We introduce\nOmniReflect, a hierarchical, reflection-driven framework that constructs a\nconstitution, a compact set of guiding principles distilled from task\nexperiences, to enhance the effectiveness and efficiency of an LLM agent.\nOmniReflect operates in two modes: Self-sustaining, where a single agent\nperiodically curates its own reflections during task execution, and\nCo-operative, where a Meta-advisor derives a constitution from a small\ncalibration set to guide another agent. To construct these constitutional\nprinciples, we employ Neural, Symbolic, and NeuroSymbolic techniques, offering\na balance between contextual adaptability and computational efficiency.\nEmpirical results averaged across models show major improvements in task\nsuccess, with absolute gains of +10.3% on ALFWorld, +23.8% on BabyAI, and +8.3%\non PDDL in the Self-sustaining mode. Similar gains are seen in the Co-operative\nmode, where a lightweight Qwen3-4B ReAct agent outperforms all Reflexion\nbaselines on BabyAI. These findings highlight the robustness and effectiveness\nof OmniReflect across environments and backbones.", "AI": {"tldr": "OmniReflect\u901a\u8fc7\u6784\u5efa\u4efb\u52a1\u7ecf\u9a8c\u603b\u7ed3\u5f62\u6210\u7684\u5baa\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u957f\u671f\u5b66\u4e60\u548c\u9002\u5e94\u80fd\u529b\uff0c\u65e0\u8bba\u5728\u5355\u4ee3\u7406\u8fd8\u662f\u591a\u4ee3\u7406\u534f\u4f5c\u73af\u5883\u4e0b\u5747\u5e26\u6765\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u76ee\u524d\u5e38\u7528\u7684\u5fae\u8c03\u4e0e\u81ea\u6211\u4fee\u6b63\u65b9\u6cd5\u5bf9\u4e8e\u52a8\u6001\u73af\u5883\u4e0b\u7684\u957f\u671f\u5b66\u4e60\u673a\u5236\u7f3a\u4e4f\u901a\u7528\u6027\u4e14\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faOmniReflect\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u5c42\u6b21\u5316\u53cd\u601d\u673a\u5236\uff0c\u901a\u8fc7\u4ece\u4efb\u52a1\u7ecf\u9a8c\u4e2d\u63d0\u70bc\u5baa\u6cd5\uff08\u6307\u5bfc\u6027\u539f\u5219\uff09\u5f3a\u5316LLM\u667a\u80fd\u4f53\u3002OmniReflect\u6709\u4e24\u79cd\u6a21\u5f0f\uff1a\u81ea\u6211\u7ef4\u6301\uff08\u667a\u80fd\u4f53\u81ea\u6211\u53cd\u601d\uff09\u548c\u534f\u4f5c\uff08\u7531Meta-advisor\u603b\u7ed3\u5baa\u6cd5\u6307\u5bfc\u4ee3\u7406\uff09\u3002\u91c7\u7528\u795e\u7ecf\u3001\u7b26\u53f7\u53ca\u795e\u7ecf-\u7b26\u53f7\u6df7\u5408\u65b9\u6cd5\u5f62\u6210\u539f\u5219\u3002", "result": "\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cOmniReflect\u5728\u81ea\u6211\u7ef4\u6301\u6a21\u5f0f\u4e0b\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff08\u5982ALFWorld\u63d0\u9ad810.3%\uff0cBabyAI\u63d0\u9ad823.8%\uff0cPDDL\u63d0\u9ad88.3%\uff09\uff0c\u5728\u534f\u4f5c\u6a21\u5f0f\u4e0b\u8f7b\u91cf\u7ea7\u6a21\u578b\u4e5f\u4f18\u4e8e\u6240\u6709\u73b0\u6709Reflexion\u57fa\u7ebf\u3002", "conclusion": "OmniReflect\u662f\u4e00\u79cd\u7a33\u5065\u4e14\u9ad8\u6548\u7684\u53cd\u601d\u9a71\u52a8\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u663e\u8457\u63d0\u5347LLM\u4ee3\u7406\u5728\u4e0d\u540c\u884c\u4e1a\u73af\u5883\u548c\u5e95\u5ea7\u6a21\u578b\u4e0b\u7684\u590d\u6742\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2506.17356", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.17356", "abs": "https://arxiv.org/abs/2506.17356", "authors": ["Jionghao Lin", "Jiarui Rao", "Yiyang Zhao", "Yuting Wang", "Ashish Gurung", "Amanda Barany", "Jaclyn Ocumpaugh", "Ryan S. Baker", "Kenneth R. Koedinger"], "title": "Automatic Large Language Models Creation of Interactive Learning Lessons", "comment": "Full Research Paper, 15 pages, In Proceedings of 20th European\n  Conference on Technology Enhanced Learning (ECTEL2025)", "summary": "We explore the automatic generation of interactive, scenario-based lessons\ndesigned to train novice human tutors who teach middle school mathematics\nonline. Employing prompt engineering through a Retrieval-Augmented Generation\napproach with GPT-4o, we developed a system capable of creating structured\ntutor training lessons. Our study generated lessons in English for three key\ntopics: Encouraging Students' Independence, Encouraging Help-Seeking Behavior,\nand Turning on Cameras, using a task decomposition prompting strategy that\nbreaks lesson generation into sub-tasks. The generated lessons were evaluated\nby two human evaluators, who provided both quantitative and qualitative\nevaluations using a comprehensive rubric informed by lesson design research.\nResults demonstrate that the task decomposition strategy led to higher-rated\nlessons compared to single-step generation. Human evaluators identified several\nstrengths in the LLM-generated lessons, including well-structured content and\ntime-saving potential, while also noting limitations such as generic feedback\nand a lack of clarity in some instructional sections. These findings underscore\nthe potential of hybrid human-AI approaches for generating effective lessons in\ntutor training.", "AI": {"tldr": "\u901a\u8fc7RAG\u4e0eGPT-4o\u7ed3\u5408\u4efb\u52a1\u5206\u89e3\u63d0\u793a\u5de5\u7a0b\uff0c\u81ea\u52a8\u4e3a\u65b0\u624b\u5728\u7ebf\u6570\u5b66\u6559\u5e08\u751f\u6210\u9ad8\u8d28\u91cf\u57f9\u8bad\u8bfe\u7a0b\uff0c\u7ecf\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u8bfe\u7a0b\u7ed3\u6784\u4f18\u79c0\u4e14\u8282\u7ea6\u65f6\u95f4\uff0c\u4f46\u5b58\u5728\u4e9b\u8bb8\u5185\u5bb9\u6cdb\u5316\u548c\u8bf4\u660e\u4e0d\u6e05\u3002\u4eba\u673a\u534f\u4f5c\u751f\u6210\u6559\u5b66\u5185\u5bb9\u5c55\u73b0\u4e86\u8f83\u5927\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u73b0\u6709\u7684\u5728\u7ebf\u6570\u5b66\u6559\u5e08\u57f9\u8bad\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u3001\u6210\u672c\u9ad8\u6602\u7684\u95ee\u9898\uff0c\u9700\u8981\u81ea\u52a8\u5316\u3001\u9ad8\u8d28\u91cf\u7684\u4e92\u52a8\u5f0f\u8bfe\u7a0b\u751f\u6210\u65b9\u6cd5\uff0c\u8f85\u52a9\u65b0\u624b\u6559\u5e08\u5728\u7ebf\u57f9\u8bad\u3002", "method": "\u63d0\u51fa\u91c7\u7528\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684GPT-4o\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u81ea\u52a8\u751f\u6210\u7ed3\u6784\u5316\u7684\u6559\u5b66\u573a\u666f\u8bfe\u7a0b\u3002\u9488\u5bf9\u4e09\u4e2a\u5173\u952e\u4e3b\u9898\u8fdb\u884c\u8bfe\u7a0b\u751f\u6210\uff0c\u5e76\u7531\u4e24\u540d\u4eba\u5de5\u8bc4\u5ba1\u4f7f\u7528\u57fa\u4e8e\u6559\u5b66\u8bbe\u8ba1\u7684\u8bc4\u5206\u7ec6\u5219\u8fdb\u884c\u5b9a\u91cf\u4e0e\u5b9a\u6027\u8bc4\u4ef7\u3002", "result": "\u4efb\u52a1\u5206\u89e3\u7b56\u7565\u751f\u6210\u7684\u8bfe\u7a0b\u7ed3\u6784\u66f4\u597d\u3001\u5f97\u5206\u66f4\u9ad8\uff0c\u8282\u7701\u65f6\u95f4\u3002\u4eba\u5de5\u8bc4\u5ba1\u6307\u51fa\u8bfe\u7a0b\u5185\u5bb9\u7ed3\u6784\u5408\u7406\u4e14\u6709\u6548\uff0c\u4f46\u4e5f\u5b58\u5728\u53cd\u9988\u6cdb\u5316\u548c\u90e8\u5206\u6559\u5b66\u8bf4\u660e\u4e0d\u6e05\u6670\u7684\u7f3a\u70b9\u3002", "conclusion": "\u63d0\u51fa\u7684AI\u548c\u4eba\u7c7b\u6df7\u5408\u65b9\u6cd5\u80fd\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u6559\u5e08\u57f9\u8bad\u8bfe\u7a0b\uff0c\u663e\u793a\u5728\u4eba\u673a\u8054\u5408\u8bbe\u8ba1\u4e92\u52a8\u8bfe\u7a0b\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2506.18175", "categories": ["cs.CE", "math.DS", "28A80 (Primary), 37N10 (Secondary)", "J.2; E.1"], "pdf": "https://arxiv.org/pdf/2506.18175", "abs": "https://arxiv.org/abs/2506.18175", "authors": ["Pramit Ghosh"], "title": "Measuring Fractal Dimension using Discrete Global Grid Systems", "comment": null, "summary": "This study builds a bridge between two well-studied but distant topics:\nfractal dimension and Discrete Global Grid System (DGGS). DGGSs are used as\ncovering sets for geospatial vector data to calculate the Minkowski-Bouligand\ndimension. Using the method on synthetic data yields results within 1% of their\ntheoretical fractal dimensions. A case study on opaque cloud fields obtained\nfrom satellite images gives fractal dimension in agreement with that available\nin the literature. The proposed method alleviates the problems of arbitrary\ngrid placement and orientation, as well as the progression of cell sizes of the\ncovering sets for geospatial data. Using DGGSs further ensure that\nintersections of the covering sets with the geospatial vector having large\ngeographic extents are calculated by taking the curvature of the earth into\naccount. This paper establishes the validity of DGGSs as covering sets\ntheoretically and discusses desirable properties of DGGSs suitable for this\npurpose.", "AI": {"tldr": "\u672c\u6587\u5c06\u79bb\u6563\u5168\u7403\u7f51\u683c\u7cfb\u7edf(DGGS)\u5e94\u7528\u4e8e\u5730\u7406\u7a7a\u95f4\u6570\u636e\u7684\u5206\u5f62\u7ef4\u5ea6\u6d4b\u7b97\uff0c\u5b9e\u9a8c\u548c\u7406\u8bba\u90fd\u8bc1\u660e\u5176\u9ad8\u7cbe\u5ea6\u548c\u5b9e\u7528\u6027\uff0c\u5e76\u80fd\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u7684\u7f3a\u9677\u3002", "motivation": "\u76ee\u524d\u5206\u5f62\u7ef4\u5ea6\u4e0e\u79bb\u6563\u5168\u7403\u7f51\u683c\u7cfb\u7edf\uff08DGGS\uff09\u662f\u4e24\u4e2a\u7814\u7a76\u8f83\u591a\u4f46\u4e92\u76f8\u72ec\u7acb\u7684\u9886\u57df\u3002\u6587\u7ae0\u5e0c\u671b\u5c06DGGS\u5e94\u7528\u4e8e\u5206\u5f62\u7ef4\u5ea6\u6d4b\u7b97\uff0c\u89e3\u51b3\u5730\u7406\u7a7a\u95f4\u6570\u636e\u5206\u5f62\u5206\u6790\u4e2d\u7f51\u683c\u5e03\u7f6e\u968f\u610f\u3001\u5927\u5c0f\u4e0d\u7edf\u4e00\u7b49\u5b9e\u9645\u95ee\u9898\u3002", "method": "\u91c7\u7528DGGS\u4f5c\u4e3a\u5bf9\u5730\u7406\u7a7a\u95f4\u77e2\u91cf\u6570\u636e\u7684\u8986\u76d6\u96c6\uff0c\u901a\u8fc7Minkowski-Bouligand\u65b9\u6cd5\u6765\u6d4b\u7b97\u5176\u5206\u5f62\u7ef4\u5ea6\uff0c\u5e76\u5728\u5408\u6210\u6570\u636e\u548c\u5b9e\u9645\u536b\u661f\u4e91\u56fe\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u5b9e\u9a8c\u4e2d\uff0c\u6240\u5f97\u5206\u5f62\u7ef4\u5ea6\u7ed3\u679c\u4e0e\u7406\u8bba\u503c\u8bef\u5dee\u5c0f\u4e8e1%\uff1b\u5728\u5b9e\u9645\u536b\u661f\u4e91\u56fe\u4e0a\u6d4b\u5f97\u5206\u5f62\u7ef4\u5ea6\u4e0e\u6587\u732e\u7ed3\u679c\u4e00\u81f4\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u514b\u670d\u4e86\u5e38\u89c4\u7f51\u683c\u5e03\u7f6e\u5b58\u5728\u7684\u968f\u610f\u6027\u95ee\u9898\uff0c\u5e76\u80fd\u5904\u7406\u5927\u5c3a\u5ea6\u5730\u7406\u5bf9\u8c61\u8ba1\u7b97\u65f6\u7684\u5730\u7403\u66f2\u7387\u5f71\u54cd\u3002", "conclusion": "DGGS\u4f5c\u4e3a\u5206\u5f62\u7ef4\u5ea6\u8ba1\u7b97\u7684\u8986\u76d6\u96c6\u4e0d\u4ec5\u7406\u8bba\u4e0a\u6210\u7acb\uff0c\u800c\u4e14\u5728\u5b9e\u8df5\u4e2d\u5177\u6709\u7cbe\u5ea6\u9ad8\u3001\u4e0d\u53d7\u7f51\u683c\u5e03\u7f6e\u548c\u5c3a\u5bf8\u9009\u62e9\u5f71\u54cd\u7b49\u4f18\u70b9\uff0c\u9002\u5408\u4e8e\u5730\u7406\u7a7a\u95f4\u6570\u636e\u7684\u5206\u5f62\u5206\u6790\u3002\u6587\u4e2d\u8fd8\u8ba8\u8bba\u4e86\u4e3a\u6b64\u4efb\u52a1\u9009\u62e9DGGS\u9700\u5177\u5907\u7684\u6027\u8d28\u3002"}}
{"id": "2506.17298", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17298", "abs": "https://arxiv.org/abs/2506.17298", "authors": ["Inception Labs", "Samar Khanna", "Siddhant Kharbanda", "Shufan Li", "Harshit Varma", "Eric Wang", "Sawyer Birnbaum", "Ziyang Luo", "Yanis Miraoui", "Akash Palrecha", "Stefano Ermon", "Aditya Grover", "Volodymyr Kuleshov"], "title": "Mercury: Ultra-Fast Language Models Based on Diffusion", "comment": "15 pages; equal core, cross-function, senior authors listed\n  alphabetically", "summary": "We present Mercury, a new generation of commercial-scale large language\nmodels (LLMs) based on diffusion. These models are parameterized via the\nTransformer architecture and trained to predict multiple tokens in parallel. In\nthis report, we detail Mercury Coder, our first set of diffusion LLMs designed\nfor coding applications. Currently, Mercury Coder comes in two sizes: Mini and\nSmall. These models set a new state-of-the-art on the speed-quality frontier.\nBased on independent evaluations conducted by Artificial Analysis, Mercury\nCoder Mini and Mercury Coder Small achieve state-of-the-art throughputs of 1109\ntokens/sec and 737 tokens/sec, respectively, on NVIDIA H100 GPUs and outperform\nspeed-optimized frontier models by up to 10x on average while maintaining\ncomparable quality. We discuss additional results on a variety of code\nbenchmarks spanning multiple languages and use-cases as well as real-world\nvalidation by developers on Copilot Arena, where the model currently ranks\nsecond on quality and is the fastest model overall. We also release a public\nAPI at https://platform.inceptionlabs.ai/ and free playground at\nhttps://chat.inceptionlabs.ai", "AI": {"tldr": "Mercury Coder \u662f\u57fa\u4e8e\u6269\u6563\u673a\u5236\u548cTransformer\u7684\u65b0\u4e00\u4ee3\u4ee3\u7801\u751f\u6210\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u4fdd\u8bc1\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u63a8\u7406\u901f\u5ea6\u76f8\u6bd4\u73b0\u6709\u6a21\u578b\u5b9e\u73b0\u5927\u5e45\u9886\u5148\uff0c\u6210\u4e3a\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u901f\u5ea6\u4e0e\u8d28\u91cf\u65b0\u6807\u6746\u3002", "motivation": "\u5f53\u524d\u7684\u5546\u4e1a\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6ee1\u8db3\u9ad8\u63a8\u7406\u901f\u5ea6\u4e0e\u751f\u6210\u8d28\u91cf\u95f4\u5b58\u5728\u6743\u8861\uff0c\u5c24\u5176\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\uff0c\u517c\u987e\u9ad8\u541e\u5410\u91cf\u4e0e\u9ad8\u8d28\u91cf\u7684\u6a21\u578b\u9700\u6c42\u8feb\u5207\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6269\u6563\u673a\u5236\uff08diffusion\uff09\u7684\u65b0\u4e00\u4ee3\u5927\u8bed\u8a00\u6a21\u578bMercury\uff0c\u5e76\u91c7\u7528Transformer\u67b6\u6784\u5b9e\u73b0\u591atoken\u5e76\u884c\u9884\u6d4b\u3002\u8be5\u62a5\u544a\u91cd\u70b9\u4ecb\u7ecd\u4e86\u9762\u5411\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u7684Mercury Coder\uff08Mini\u548cSmall\u4e24\u4e2a\u7248\u672c\uff09\uff0c\u5728NVIDIA H100 GPU\u4e0a\u8fdb\u884c\u72ec\u7acb\u57fa\u51c6\u8bc4\u6d4b\u3002", "result": "Mercury Coder Mini\u548cSmall\u5728H100 GPU\u4e0a\u7684\u541e\u5410\u91cf\u5206\u522b\u8fbe\u52301109\u548c737 tokens/s\uff0c\u901f\u5ea6\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u901f\u5ea6\u4f18\u5316\u524d\u6cbf\u6a21\u578b\uff0c\u5e73\u5747\u8d85\u8fc710\u500d\uff0c\u540c\u65f6\u751f\u6210\u8d28\u91cf\u53ef\u4e0e\u4e4b\u5ab2\u7f8e\u3002\u5728\u591a\u8bed\u8a00\u3001\u4e0d\u540c\u7528\u4f8b\u7684\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u5e76\u5728Copilot Arena\u4e2d\u4ee5\u7b2c\u4e8c\u7684\u751f\u6210\u8d28\u91cf\u548c\u6700\u5feb\u901f\u5ea6\u83b7\u5f97\u5f00\u53d1\u8005\u9a8c\u8bc1\u3002", "conclusion": "Mercury Coder\u7cfb\u5217\u4ee5\u5168\u65b0\u57fa\u4e8e\u6269\u6563\u673a\u5236\u7684\u5e76\u884c\u9884\u6d4b\u65b9\u6cd5\uff0c\u6781\u5927\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6548\u7387\uff0c\u5728\u4e0d\u727a\u7272\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u7a81\u7834\u6027\u7684\u63a8\u7406\u901f\u5ea6\uff0c\u5e76\u5df2\u901a\u8fc7\u5f00\u6e90API\u548c\u5728\u7ebf\u4f53\u9a8c\u5e73\u53f0\u9762\u5411\u516c\u4f17\u5f00\u653e\u3002"}}
{"id": "2506.17484", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17484", "abs": "https://arxiv.org/abs/2506.17484", "authors": ["Yao Zhang", "Zaixi Shang", "Silpan Patel", "Mikel Zuniga"], "title": "From Unstructured Communication to Intelligent RAG: Multi-Agent Automation for Supply Chain Knowledge Bases", "comment": "Accepted In Proceedings of the 1st Workshop on AI for Supply Chain:\n  Today and Future @ 31st ACM SIGKDD Conference on Knowledge Discovery and Data\n  Mining V.2 (KDD 25), August 3, 2025, Toronto, ON, Canada. ACM, New York, NY,\n  USA, 14 pages, 2 figures", "summary": "Supply chain operations generate vast amounts of operational data; however,\ncritical knowledge such as system usage practices, troubleshooting workflows,\nand resolution techniques often remains buried within unstructured\ncommunications like support tickets, emails, and chat logs. While RAG systems\naim to leverage such communications as a knowledge base, their effectiveness is\nlimited by raw data challenges: support tickets are typically noisy,\ninconsistent, and incomplete, making direct retrieval suboptimal. Unlike\nexisting RAG approaches that focus on runtime optimization, we introduce a\nnovel offline-first methodology that transforms these communications into a\nstructured knowledge base. Our key innovation is a LLMs-based multi-agent\nsystem orchestrating three specialized agents: Category Discovery for taxonomy\ncreation, Categorization for ticket grouping, and Knowledge Synthesis for\narticle generation. Applying our methodology to real-world support tickets with\nresolution notes and comments, our system creates a compact knowledge base -\nreducing total volume to just 3.4% of original ticket data while improving\nquality. Experiments demonstrate that our prebuilt knowledge base in RAG\nsystems significantly outperforms traditional RAG implementations (48.74% vs.\n38.60% helpful answers) and achieves a 77.4% reduction in unhelpful responses.\nBy automating institutional knowledge capture that typically remains siloed in\nexperts' heads, our solution translates to substantial operational efficiency:\nreducing support workload, accelerating resolution times, and creating\nself-improving systems that automatically resolve approximately 50% of future\nsupply chain tickets. Our approach addresses a key gap in knowledge management\nby transforming transient communications into structured, reusable knowledge\nthrough intelligent offline processing rather than latency-inducing runtime\narchitectures.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u79bb\u7ebf\u5904\u7406\u975e\u7ed3\u6784\u5316\u652f\u6301\u5de5\u5355\uff0c\u6784\u5efa\u9ad8\u6548\u77e5\u8bc6\u5e93\uff0c\u6781\u5927\u63d0\u5347RAG\u95ee\u7b54\u6548\u679c\u548c\u4f9b\u5e94\u94fe\u81ea\u52a8\u5316\u652f\u6301\uff0c\u7ed3\u679c\u5927\u5e45\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f9b\u5e94\u94fe\u8fd0\u4f5c\u4e2d\u4f1a\u4ea7\u751f\u5927\u91cf\u7684\u64cd\u4f5c\u6570\u636e\uff0c\u4f46\u5173\u952e\u77e5\u8bc6\uff08\u5982\u7cfb\u7edf\u4f7f\u7528\u65b9\u6cd5\u3001\u6545\u969c\u6392\u67e5\u548c\u89e3\u51b3\u6280\u5de7\uff09\u591a\u57cb\u85cf\u5728\u975e\u7ed3\u6784\u5316\u7684\u6c9f\u901a\u5185\u5bb9\u4e2d\uff0c\u5982\u652f\u6301\u5de5\u5355\u3001\u90ae\u4ef6\u548c\u804a\u5929\u8bb0\u5f55\u3002\u73b0\u6709RAG\u7cfb\u7edf\u5728\u76f4\u63a5\u5229\u7528\u8fd9\u4e9b\u539f\u59cb\u3001\u566a\u58f0\u5927\u3001\u4e0d\u4e00\u81f4\u4e14\u4e0d\u5b8c\u6574\u7684\u6570\u636e\u65f6\u6548\u679c\u6709\u9650\uff0c\u76f4\u63a5\u68c0\u7d22\u6548\u7387\u4e0d\u9ad8\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u65b0\u65b9\u6cd5\u5c06\u8fd9\u4e9b\u6c9f\u901a\u5185\u5bb9\u8f6c\u5316\u4e3a\u9ad8\u6548\u3001\u53ef\u590d\u7528\u7684\u77e5\u8bc6\u5e93\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u5168\u65b0\u7684\u201c\u79bb\u7ebf\u4f18\u5148\u201d\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5206\u522b\u8d1f\u8d23\uff1a1\uff09\u7c7b\u522b\u53d1\u73b0\uff08\u5efa\u7acb\u77e5\u8bc6\u5206\u7c7b\u4f53\u7cfb\uff09\uff0c2\uff09\u7c7b\u522b\u5f52\u7c7b\uff08\u5c06\u5de5\u5355\u5206\u7ec4\uff09\uff0c3\uff09\u77e5\u8bc6\u7efc\u5408\uff08\u751f\u6210\u77e5\u8bc6\u6587\u7ae0\uff09\u3002\u8be5\u7cfb\u7edf\u5148\u5bf9\u771f\u5b9e\u4e16\u754c\u5de5\u5355\u3001\u5904\u7406\u8bb0\u5f55\u548c\u8bc4\u8bba\u8fdb\u884c\u5904\u7406\uff0c\u5c06\u6d77\u91cf\u975e\u7ed3\u6784\u5316\u6570\u636e\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u4e14\u4f53\u79ef\u7d27\u51d1\u7684\u77e5\u8bc6\u5e93\u3002", "result": "\u5e94\u7528\u4e8e\u771f\u5b9e\u652f\u6301\u5de5\u5355\u540e\uff0c\u6240\u6784\u5efa\u77e5\u8bc6\u5e93\u4f53\u79ef\u4ec5\u4e3a\u539f\u59cb\u6570\u636e\u76843.4%\uff0c\u4fe1\u606f\u8d28\u91cf\u5f97\u5230\u63d0\u5347\u3002\u5728RAG\u7cfb\u7edf\u4e2d\u4f7f\u7528\u9884\u6784\u5efa\u77e5\u8bc6\u5e93\u540e\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6709\u6548\u56de\u7b54\u6bd4\u4f8b\u8fbe48.74%\uff0c\u660e\u663e\u4f18\u4e8e\u4f20\u7edfRAG\uff0838.6%\uff09\uff0c\u4e14\u65e0\u6548\u56de\u7b54\u964d\u4f4e77.4%\u3002\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u89e3\u51b3\u7ea650%\u7684\u540e\u7eed\u5de5\u5355\uff0c\u5927\u5e45\u63d0\u5347\u8fd0\u7ef4\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u65b9\u6cd5\u89e3\u51b3\u4e86\u4f20\u7edfRAG\u5bf9\u8fd0\u8425\u6570\u636e\u76f4\u63a5\u68c0\u7d22\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u667a\u80fd\u79bb\u7ebf\u5904\u7406\u5c06\u4e34\u65f6\u6c9f\u901a\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u3001\u53ef\u590d\u7528\u7684\u77e5\u8bc6\u5e93\uff0c\u6781\u5927\u63d0\u5347\u4e86\u77e5\u8bc6\u7ba1\u7406\u548c\u81ea\u52a8\u5316\u652f\u6301\u80fd\u529b\uff0c\u6709\u6548\u63d0\u5347\u4f9b\u5e94\u94fe\u8fd0\u8425\u6548\u7387\u3002"}}
{"id": "2506.17363", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17363", "abs": "https://arxiv.org/abs/2506.17363", "authors": ["Sunjun Kweon", "Sooyohn Nam", "Hyunseung Lim", "Hwajung Hong", "Edward Choi"], "title": "A Large-Scale Real-World Evaluation of LLM-Based Virtual Teaching Assistant", "comment": "ACL 2025 Industry Track", "summary": "Virtual Teaching Assistants (VTAs) powered by Large Language Models (LLMs)\nhave the potential to enhance student learning by providing instant feedback\nand facilitating multi-turn interactions. However, empirical studies on their\neffectiveness and acceptance in real-world classrooms are limited, leaving\ntheir practical impact uncertain. In this study, we develop an LLM-based VTA\nand deploy it in an introductory AI programming course with 477 graduate\nstudents. To assess how student perceptions of the VTA's performance evolve\nover time, we conduct three rounds of comprehensive surveys at different stages\nof the course. Additionally, we analyze 3,869 student--VTA interaction pairs to\nidentify common question types and engagement patterns. We then compare these\ninteractions with traditional student--human instructor interactions to\nevaluate the VTA's role in the learning process. Through a large-scale\nempirical study and interaction analysis, we assess the feasibility of\ndeploying VTAs in real-world classrooms and identify key challenges for broader\nadoption. Finally, we release the source code of our VTA system, fostering\nfuture advancements in AI-driven education:\n\\texttt{https://github.com/sean0042/VTA}.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u5e76\u5b9e\u5730\u90e8\u7f72\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u865a\u62df\u52a9\u6559\uff08VTA\uff09\uff0c\u5728\u5927\u89c4\u6a21\u8bfe\u7a0b\u4e2d\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5176\u6548\u679c\u548c\u5b66\u751f\u53cd\u9988\uff0c\u5206\u6790\u4e86\u5b9e\u9645\u4ea4\u4e92\u6a21\u5f0f\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u6539\u8fdb\u548c\u63a8\u5e7f\u7684\u5173\u952e\u96be\u70b9\u3002", "motivation": "\u5f53\u524d\u5173\u4e8eLLM\u9a71\u52a8\u7684\u865a\u62df\u52a9\u6559\u5728\u5b9e\u9645\u8bfe\u5802\u4e2d\u7684\u6548\u679c\u548c\u5b66\u751f\u63a5\u53d7\u5ea6\u7684\u5b9e\u8bc1\u7814\u7a76\u6709\u9650\uff0c\u5b9e\u9645\u5f71\u54cd\u5c1a\u4e0d\u660e\u6717\uff0c\u9700\u8981\u901a\u8fc7\u771f\u5b9e\u573a\u666f\u8bc4\u4f30\u5176\u53ef\u884c\u6027\u548c\u6f5c\u5728\u4ef7\u503c\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684VTA\u7cfb\u7edf\uff0c\u5e76\u5728477\u540d\u7814\u7a76\u751f\u7684AI\u7f16\u7a0b\u8bfe\u7a0b\u4e2d\u90e8\u7f72\u3002\u901a\u8fc7\u5728\u8bfe\u7a0b\u7684\u4e0d\u540c\u9636\u6bb5\u8fdb\u884c\u4e09\u8f6e\u95ee\u5377\u8c03\u67e5\uff0c\u6536\u96c6\u5b66\u751f\u5bf9VTA\u8868\u73b0\u7684\u611f\u77e5\u53d8\u5316\uff1b\u540c\u65f6\uff0c\u5206\u67903,869\u6761\u5b66\u751f\u4e0eVTA\u7684\u4ea4\u4e92\u8bb0\u5f55\uff0c\u6bd4\u8f83VTA\u548c\u4eba\u7c7b\u6559\u5e08\u5728\u4ea4\u4e92\u4e2d\u7684\u5f02\u540c\u3002", "result": "\u5b66\u751f\u5bf9VTA\u7684\u611f\u77e5\u968f\u7740\u8bfe\u7a0b\u63a8\u8fdb\u6709\u6240\u53d8\u5316\u3002\u4ea4\u4e92\u5206\u6790\u63ed\u793a\u4e86\u5b66\u751f\u5e38\u89c1\u63d0\u95ee\u7c7b\u578b\u548c\u53c2\u4e0e\u6a21\u5f0f\uff0c\u540c\u65f6\u6307\u51fa\u4e0e\u4eba\u7c7b\u6559\u5e08\u76f8\u6bd4\uff0cVTA\u5728\u652f\u6301\u5b66\u4e60\u8fc7\u7a0b\u4e0a\u53d1\u6325\u4e86\u4e00\u5b9a\u4f5c\u7528\uff0c\u4f46\u4e5f\u9762\u4e34\u4e00\u4e9b\u6311\u6218\u3002", "conclusion": "\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u548c\u4ea4\u4e92\u5206\u6790\uff0c\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u865a\u62df\u52a9\u6559\uff08VTA\uff09\u5728\u771f\u5b9e\u8bfe\u5802\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u5176\u66f4\u5e7f\u6cdb\u5e94\u7528\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2506.18206", "categories": ["cs.CE", "cs.NA", "math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2506.18206", "abs": "https://arxiv.org/abs/2506.18206", "authors": ["Adriana Kulikov\u00e1", "Andrei G. Shvarts", "\u0141ukasz Kaczmarczyk", "Chris J. Pearce"], "title": "Conservative data-driven finite element formulation", "comment": null, "summary": "This paper presents a new data-driven finite element framework derived with\nmixed finite element formulation. The standard approach to diffusion problems\nrequires the solution of the mathematical equations that describe both the\nconservation law and the constitutive relations, where the latter is\ntraditionally obtained after fitting experimental data to simplified material\nmodels. To exploit all available information and avoid bias in the material\nmodel, we follow a data-driven approach. While the conservation laws and\nboundary conditions are satisfied by means of the finite element method, the\nexperimental data is used directly in the numerical simulations, avoiding the\nneed of fitting material model parameters. In order to satisfy the conservation\nlaw a priori in the strong sense, we introduce a mixed finite element\nformulation. This relaxes the regularity requirements on approximation spaces\nwhile enforcing continuity of the normal flux component across all of the inner\nboundaries. This weaker mixed formulation provides a posteriori error\nindicators tailored for this data-driven approach, enabling adaptive\nhp-refinement. The relaxed regularity of the approximation spaces makes it\neasier to observe how the variation in the datasets results in the\nnon-uniqueness of the solution, which can be quantified to predict the\nuncertainty of the results. The capabilities of the formulation are\ndemonstrated in an example of the nonlinear heat transfer in nuclear graphite\nusing synthetically generated material datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u9762\u5411\u6269\u6563\u95ee\u9898\u7684\u6570\u636e\u9a71\u52a8\u6df7\u5408\u6709\u9650\u5143\u6846\u67b6\uff0c\u76f4\u63a5\u5229\u7528\u5b9e\u9a8c\u6570\u636e\u66ff\u4ee3\u672c\u6784\u62df\u5408\uff0c\u5f31\u6df7\u5408\u5f62\u5f0f\u66f4\u7075\u6d3b\uff0c\u5e76\u80fd\u5bf9\u6570\u636e\u5f15\u5165\u7684\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u91cf\u5316\uff0c\u5df2\u5728\u6838\u77f3\u58a8\u4f20\u70ed\u95ee\u9898\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u6269\u6563\u95ee\u9898\u9700\u8981\u5bf9\u6750\u6599\u672c\u6784\u5173\u7cfb\u8fdb\u884c\u62df\u5408\u5efa\u6a21\uff0c\u8fd9\u4f1a\u5f15\u5165\u6a21\u578b\u504f\u5dee\uff0c\u4e14\u4e0d\u80fd\u5145\u5206\u5229\u7528\u5b9e\u9a8c\u6570\u636e\u3002\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u5145\u5206\u5229\u7528\u6570\u636e\u3001\u907f\u514d\u6a21\u578b\u5148\u9a8c\u504f\u5dee\u7684\u6a21\u62df\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6709\u9650\u5143\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f31\u6df7\u5408\u5f62\u5f0f\u4fdd\u8bc1\u5b88\u6052\u5b9a\u5f8b\u5148\u9a8c\u6ee1\u8db3\uff0c\u540c\u65f6\u76f4\u63a5\u5c06\u5b9e\u9a8c\u6570\u636e\u7528\u4e8e\u6570\u503c\u4eff\u771f\uff0c\u907f\u514d\u7269\u6027\u53c2\u6570\u7684\u663e\u5f0f\u62df\u5408\uff0c\u5e76\u57fa\u4e8e\u8be5\u6846\u67b6\u8fdb\u884c\u81ea\u9002\u5e94hp\u52a0\u5bc6\u4e0e\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u91c7\u7528\u8be5\u65b9\u6cd5\u540e\uff0c\u5728\u6838\u77f3\u58a8\u975e\u7ebf\u6027\u4f20\u70ed\u7684\u6570\u503c\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u80fd\u529b\uff0c\u53ef\u4ee5\u91cf\u5316\u548c\u9884\u6d4b\u7531\u6570\u636e\u96c6\u53d8\u5316\u5f15\u8d77\u7684\u89e3\u7684\u4e0d\u552f\u4e00\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u6570\u636e\u9a71\u52a8\u6709\u9650\u5143\u6df7\u5408\u65b9\u6cd5\u80fd\u591f\u907f\u514d\u7269\u6027\u53c2\u6570\u62df\u5408\u5e26\u6765\u7684\u6a21\u578b\u504f\u5dee\uff0c\u5f31\u6df7\u5408\u5f62\u5f0f\u8fd8\u4fbf\u4e8e\u540e\u9a8c\u8bef\u5dee\u5206\u6790\u4e0e\u81ea\u9002\u5e94hp\u52a0\u5bc6\uff0c\u540c\u65f6\u53ef\u4ee5\u91cf\u5316\u6570\u636e\u4e0d\u786e\u5b9a\u6027\u5bf9\u89e3\u7684\u5f71\u54cd\u3002"}}
{"id": "2506.17314", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.17314", "abs": "https://arxiv.org/abs/2506.17314", "authors": ["Adnan Qidwai", "Srija Mukhopadhyay", "Prerana Khatiwada", "Dan Roth", "Vivek Gupta"], "title": "PRAISE: Enhancing Product Descriptions with LLM-Driven Structured Insights", "comment": "9 Pages, 9 Figures. Accepted at ACL 2025 System Demonstration Track", "summary": "Accurate and complete product descriptions are crucial for e-commerce, yet\nseller-provided information often falls short. Customer reviews offer valuable\ndetails but are laborious to sift through manually. We present PRAISE: Product\nReview Attribute Insight Structuring Engine, a novel system that uses Large\nLanguage Models (LLMs) to automatically extract, compare, and structure\ninsights from customer reviews and seller descriptions. PRAISE provides users\nwith an intuitive interface to identify missing, contradictory, or partially\nmatching details between these two sources, presenting the discrepancies in a\nclear, structured format alongside supporting evidence from reviews. This\nallows sellers to easily enhance their product listings for clarity and\npersuasiveness, and buyers to better assess product reliability. Our\ndemonstration showcases PRAISE's workflow, its effectiveness in generating\nactionable structured insights from unstructured reviews, and its potential to\nsignificantly improve the quality and trustworthiness of e-commerce product\ncatalogs.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u6f14\u793a\u4e86PRAISE\u7cfb\u7edf\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4ece\u8bc4\u8bba\u548c\u63cf\u8ff0\u4e2d\u63d0\u53d6\u5e76\u5bf9\u6bd4\u4ea7\u54c1\u5c5e\u6027\uff0c\u6781\u5927\u63d0\u5347\u5546\u54c1\u4fe1\u606f\u8d28\u91cf\u548c\u5e73\u53f0\u4fe1\u5ea6\u3002", "motivation": "\u7535\u5546\u4e2d\u7684\u4ea7\u54c1\u63cf\u8ff0\u5f80\u5f80\u4fe1\u606f\u4e0d\u5168\uff0c\u800c\u5ba2\u6237\u8bc4\u8bba\u4e2d\u6f5c\u85cf\u6709\u4ef7\u503c\u5374\u5206\u6563\u7684\u4fe1\u606f\uff0c\u624b\u52a8\u7b5b\u67e5\u6210\u672c\u9ad8\u3002\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u5de5\u5177\u6765\u6574\u5408\u548c\u5f3a\u5316\u5546\u54c1\u8d44\u6599\u3002", "method": "\u5f00\u53d1\u5e76\u5e94\u7528\u4e86PRAISE\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4ece\u7528\u6237\u8bc4\u8bba\u548c\u5356\u5bb6\u63cf\u8ff0\u4e2d\u62bd\u53d6\u3001\u7ed3\u6784\u5316\u4ea7\u54c1\u5c5e\u6027\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u754c\u9762\u5c55\u793a\u8fd9\u4e9b\u6570\u636e\u53ca\u5176\u5dee\u5f02\u3002", "result": "PRAISE\u80fd\u5c06\u8bc4\u8bba\u548c\u63cf\u8ff0\u4e4b\u95f4\u7f3a\u6f0f\u3001\u77db\u76fe\u4fe1\u606f\u76f4\u89c2\u5448\u73b0\uff0c\u5e76\u63d0\u4f9b\u76f8\u5e94\u8bc1\u636e\uff0c\u65b9\u4fbf\u5356\u5bb6\u4f18\u5316\u4fe1\u606f\u3001\u4e70\u5bb6\u8bc4\u4f30\u5546\u54c1\uff0c\u63d0\u5347\u7535\u5546\u5e73\u53f0\u5185\u5bb9\u8d28\u91cf\u4e0e\u4fe1\u4efb\u5ea6\u3002", "conclusion": "PRAISE\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u63d0\u53d6\u3001\u5bf9\u6bd4\u5e76\u7ed3\u6784\u5316\u7535\u5546\u5546\u54c1\u8bc4\u8bba\u4e0e\u63cf\u8ff0\u4e2d\u7684\u5173\u952e\u4fe1\u606f\uff0c\u5e2e\u52a9\u8bc6\u522b\u4e0e\u5b8c\u5584\u4ea7\u54c1\u63cf\u8ff0\uff0c\u63d0\u9ad8\u5546\u54c1\u76ee\u5f55\u7684\u8d28\u91cf\u4e0e\u4fe1\u4efb\u5ea6\u3002"}}
{"id": "2506.17514", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17514", "abs": "https://arxiv.org/abs/2506.17514", "authors": ["Ninareh Mehrabi", "Tharindu Kumarage", "Kai-Wei Chang", "Aram Galstyan", "Rahul Gupta"], "title": "Kaleidoscopic Teaming in Multi Agent Simulations", "comment": null, "summary": "Warning: This paper contains content that may be inappropriate or offensive.\n  AI agents have gained significant recent attention due to their autonomous\ntool usage capabilities and their integration in various real-world\napplications. This autonomy poses novel challenges for the safety of such\nsystems, both in single- and multi-agent scenarios. We argue that existing red\nteaming or safety evaluation frameworks fall short in evaluating safety risks\nin complex behaviors, thought processes and actions taken by agents. Moreover,\nthey fail to consider risks in multi-agent setups where various vulnerabilities\ncan be exposed when agents engage in complex behaviors and interactions with\neach other. To address this shortcoming, we introduce the term kaleidoscopic\nteaming which seeks to capture complex and wide range of vulnerabilities that\ncan happen in agents both in single-agent and multi-agent scenarios. We also\npresent a new kaleidoscopic teaming framework that generates a diverse array of\nscenarios modeling real-world human societies. Our framework evaluates safety\nof agents in both single-agent and multi-agent setups. In single-agent setup,\nan agent is given a scenario that it needs to complete using the tools it has\naccess to. In multi-agent setup, multiple agents either compete against or\ncooperate together to complete a task in the scenario through which we capture\nexisting safety vulnerabilities in agents. We introduce new in-context\noptimization techniques that can be used in our kaleidoscopic teaming framework\nto generate better scenarios for safety analysis. Lastly, we present\nappropriate metrics that can be used along with our framework to measure safety\nof agents. Utilizing our kaleidoscopic teaming framework, we identify\nvulnerabilities in various models with respect to their safety in agentic\nuse-cases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u201ckaleidoscopic teaming\u201d\u6846\u67b6\uff0c\u65e8\u5728\u751f\u6210\u590d\u6742\u3001\u73b0\u5b9e\u7684\u573a\u666f\u4ee5\u8bc4\u4f30AI\u4ee3\u7406\u5728\u5355\u4f53\u548c\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e0b\u7684\u5b89\u5168\u6027\uff0c\u5e76\u901a\u8fc7\u65b0\u65b9\u6cd5\u8bc6\u522b\u73b0\u6709\u6a21\u578b\u5728\u6b64\u7c7b\u573a\u666f\u4e0b\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u5177\u6709\u9ad8\u5ea6\u81ea\u4e3b\u6027\uff0c\u5e76\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\uff0c\u4f46\u5176\u5728\u590d\u6742\u884c\u4e3a\u548c\u591a\u667a\u80fd\u4f53\u4e92\u52a8\u4e2d\u7684\u5b89\u5168\u98ce\u9669\u8bc4\u4f30\u5b58\u5728\u4e0d\u8db3\u3002\u73b0\u6709\u7684\u7ea2\u961f\u6d4b\u8bd5\u53ca\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\u65e0\u6cd5\u6709\u6548\u6355\u6349\u8fd9\u4e9b\u590d\u6742\u98ce\u9669\uff0c\u7279\u522b\u662f\u5728\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6216\u5bf9\u6297\u573a\u666f\u4e0b\u6f5c\u5728\u7684\u6f0f\u6d1e\u3002", "method": "\u63d0\u51fa\u4e86\u201ckaleidoscopic teaming\u201d\u6982\u5ff5\u53ca\u5176\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u6a21\u62df\u591a\u6837\u5316\u3001\u590d\u6742\u7684\u73b0\u5b9e\u793e\u4f1a\u573a\u666f\uff0c\u5bf9\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8fdb\u884c\u5b89\u5168\u6027\u8bc4\u4f30\u3002\u8be5\u6846\u67b6\u5229\u7528\u573a\u666f\u751f\u6210\u4e0e\u65b0\u9896\u7684\u4e0a\u4e0b\u6587\u4f18\u5316\u6280\u672f\uff0c\u5206\u522b\u6d4b\u8bd5\u5355\u4f53\u5b8c\u6210\u4efb\u52a1\u548c\u591a\u4f53\u7ade\u4e89\u6216\u534f\u4f5c\u5b8c\u6210\u4efb\u52a1\uff0c\u901a\u8fc7\u6355\u83b7\u8fd9\u4e9b\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u5b89\u5168\u6f0f\u6d1e\u6765\u8fdb\u884c\u5206\u6790\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u5ea6\u91cf\u5b89\u5168\u6027\u7684\u6307\u6807\u4f53\u7cfb\u3002", "result": "\u901a\u8fc7\u5e94\u7528\u6240\u63d0\u6846\u67b6\uff0c\u53d1\u73b0\u4e86\u591a\u79cd\u5df2\u6709\u6a21\u578b\u5728\u667a\u80fd\u4f53\u5e94\u7528\u73af\u5883\u4e2d\u5b58\u5728\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e76\u6709\u6548\u63ed\u793a\u4e86\u8fd9\u4e9b\u6f0f\u6d1e\u5206\u5e03\u548c\u8868\u73b0\u65b9\u5f0f\u3002", "conclusion": "\u5f53\u524d\u4e3b\u6d41\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u7cfb\u7edf\u6027\u68c0\u9a8cagent\u53ca\u5176\u4e92\u52a8\u7684\u590d\u6742\u98ce\u9669\u3002\u65b0\u63d0\u51fa\u7684kaleidoscopic teaming\u6846\u67b6\u53ef\u751f\u6210\u4e30\u5bcc\u573a\u666f\u7cfb\u7edf\u8bc4\u6d4b\u667a\u80fd\u4f53\u5b89\u5168\u6027\uff0c\u6709\u52a9\u4e8e\u5168\u9762\u53d1\u73b0agent\u5728\u4e0d\u540c\u573a\u666f\uff08\u5355\u4f53\u3001\u591a\u4f53\uff09\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2506.17364", "categories": ["cs.CY", "cs.AI", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.17364", "abs": "https://arxiv.org/abs/2506.17364", "authors": ["Alvaro Becerra", "Roberto Daza", "Ruth Cobos", "Aythami Morales", "Mutlu Cukurova", "Julian Fierrez"], "title": "AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning", "comment": "Accepted in EC-TEL25: 20th European Conference on Technology Enhanced\n  Learning, Newcastle and Durham, UK, 15-19 September 2025", "summary": "This work investigates the use of multimodal biometrics to detect\ndistractions caused by smartphone use during tasks that require sustained\nattention, with a focus on computer-based online learning. Although the methods\nare applicable to various domains, such as autonomous driving, we concentrate\non the challenges learners face in maintaining engagement amid internal (e.g.,\nmotivation), system-related (e.g., course design) and contextual (e.g.,\nsmartphone use) factors. Traditional learning platforms often lack detailed\nbehavioral data, but Multimodal Learning Analytics (MMLA) and biosensors\nprovide new insights into learner attention. We propose an AI-based approach\nthat leverages physiological signals and head pose data to detect phone use.\nOur results show that single biometric signals, such as brain waves or heart\nrate, offer limited accuracy, while head pose alone achieves 87%. A multimodal\nmodel combining all signals reaches 91% accuracy, highlighting the benefits of\nintegration. We conclude by discussing the implications and limitations of\ndeploying these models for real-time support in online learning environments.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7AI\u548c\u591a\u6a21\u6001\u751f\u7269\u8bc6\u522b\uff08\u751f\u7406\u4fe1\u53f7+\u5934\u90e8\u59ff\u6001\uff09\uff0c\u6709\u6548\u68c0\u6d4b\u7ebf\u4e0a\u5b66\u4e60\u4e2d\u56e0\u624b\u673a\u4f7f\u7528\u5f15\u53d1\u7684\u5206\u5fc3\uff0c\u591a\u6a21\u6001\u65b9\u6cd5\u51c6\u786e\u7387\u9ad8\u8fbe91%\uff0c\u4f18\u4e8e\u5355\u4e00\u4fe1\u53f7\uff0c\u5bf9\u63d0\u5347\u5728\u7ebf\u5b66\u4e60\u652f\u6301\u5177\u6709\u53c2\u8003\u4ef7\u503c\u3002", "motivation": "\u5728\u6301\u7eed\u6ce8\u610f\u529b\u4efb\u52a1\uff08\u7279\u522b\u662f\u7ebf\u4e0a\u5b66\u4e60\uff09\u4e2d\uff0c\u624b\u673a\u4f7f\u7528\u4f1a\u5bfc\u81f4\u5206\u5fc3\uff0c\u73b0\u6709\u5b66\u4e60\u5e73\u53f0\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u7684\u884c\u4e3a\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u63d0\u9ad8\u5bf9\u5b66\u4e60\u5206\u5fc3\u60c5\u51b5\u7684\u68c0\u6d4b\u548c\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u6a21\u6001\u751f\u7269\u8bc6\u522b\u4fe1\u53f7\uff08\u5982\u751f\u7406\u4fe1\u53f7\u548c\u5934\u90e8\u59ff\u6001\u6570\u636e\uff09\u68c0\u6d4b\u5b66\u4e60\u8005\u4f7f\u7528\u624b\u673a\u5bfc\u81f4\u7684\u5206\u5fc3\u884c\u4e3a\u3002\u901a\u8fc7\u6bd4\u8f83\u5355\u4e00\u751f\u7269\u4fe1\u53f7\u4e0e\u591a\u6a21\u6001\u6574\u5408\u6a21\u578b\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "result": "\u5934\u90e8\u59ff\u6001\u5355\u4e00\u4fe1\u53f7\u68c0\u6d4b\u624b\u673a\u4f7f\u7528\u7684\u51c6\u786e\u7387\u4e3a87%\uff0c\u591a\u6a21\u6001\u6a21\u578b\uff08\u7ed3\u5408\u6240\u6709\u4fe1\u53f7\uff09\u7684\u51c6\u786e\u7387\u63d0\u5347\u523091%\u3002", "conclusion": "\u591a\u6a21\u6001\u4fe1\u53f7\u7684\u6574\u5408\u660e\u663e\u4f18\u4e8e\u5355\u4e00\u4fe1\u53f7\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u68c0\u6d4b\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u5206\u5fc3\u884c\u4e3a\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u6a21\u578b\u5728\u5728\u7ebf\u5b66\u4e60\u73af\u5883\u4e2d\u5b9e\u65f6\u652f\u6301\u7684\u53ef\u884c\u6027\u548c\u5c40\u9650\u6027\u3002"}}
{"id": "2506.18227", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.18227", "abs": "https://arxiv.org/abs/2506.18227", "authors": ["Zezhong Zhang", "Caroline Tatsuoka", "Dongbin Xiu", "Guannan Zhang"], "title": "Exact Conditional Score-Guided Generative Modeling for Amortized Inference in Uncertainty Quantification", "comment": null, "summary": "We propose an efficient framework for amortized conditional inference by\nleveraging exact conditional score-guided diffusion models to train a\nnon-reversible neural network as a conditional generative model. Traditional\nnormalizing flow methods require reversible architectures, which can limit\ntheir expressiveness and efficiency. Although diffusion models offer greater\nflexibility, they often suffer from high computational costs during inference.\nTo combine the strengths of both approaches, we introduce a two-stage method.\nFirst, we construct a training-free conditional diffusion model by analytically\nderiving an exact score function under a Gaussian mixture prior formed from\nsamples of the underlying joint distribution. This exact conditional score\nmodel allows us to efficiently generate noise-labeled data, consisting of\ninitial diffusion Gaussian noise and posterior samples conditioned on various\nobservation values, by solving a reverse-time ordinary differential equation.\nSecond, we use this noise-labeled data to train a feedforward neural network\nthat maps noise and observations directly to posterior samples, eliminating the\nneed for reversibility or iterative sampling at inference time. The resulting\nmodel provides fast, accurate, and scalable conditional sampling for\nhigh-dimensional and multi-modal posterior distributions, making it well-suited\nfor uncertainty quantification tasks, e.g., parameter estimation of complex\nphysical systems. We demonstrate the effectiveness of our approach through a\nseries of numerical experiments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u7cbe\u786e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u548c\u975e\u53ef\u9006\u795e\u7ecf\u7f51\u7edc\u7684\u65b0\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u6761\u4ef6\u751f\u6210\u91c7\u6837\uff0c\u5728\u9ad8\u7ef4\u548c\u590d\u6742\u53c2\u6570\u4f30\u8ba1\u95ee\u9898\u4e2d\u6548\u679c\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u7684\u6761\u4ef6\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u548c\u8868\u8fbe\u80fd\u529b\u7684\u6743\u8861\u3002\u53ef\u9006\u7684\u6d41\u6a21\u578b\u6548\u7387\u9ad8\u4f46\u53ef\u8868\u8fbe\u6027\u6709\u9650\uff0c\u6269\u6563\u6a21\u578b\u8868\u8fbe\u6027\u5f3a\u4f46\u63a8\u65ad\u6162\u3002\u8be5\u5de5\u4f5c\u65e8\u5728\u7ed3\u5408\u4e24\u8005\u7684\u4f18\u70b9\uff0c\u5b9e\u73b0\u5feb\u901f\u3001\u9ad8\u6548\u7684\u6761\u4ef6\u751f\u6210\u3002", "method": "\u9996\u5148\uff0c\u4f5c\u8005\u901a\u8fc7\u5728\u9ad8\u65af\u6df7\u5408\u5148\u9a8c\u4e0b\uff0c\u89e3\u6790\u63a8\u5bfc\u51fa\u7cbe\u786e\u7684\u6761\u4ef6score\u51fd\u6570\uff0c\u83b7\u5f97\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff0c\u80fd\u591f\u901a\u8fc7\u89e3\u53cd\u5411\u5e38\u5fae\u5206\u65b9\u7a0b\uff0c\u751f\u6210\u5e26\u566a\u6570\u636e\u3002\u5176\u6b21\uff0c\u7528\u8fd9\u4e9b\u5e26\u566a\u6570\u636e\u8bad\u7ec3\u4e00\u4e2a\u975e\u53ef\u9006\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff0c\u76f4\u63a5\u4ece\u566a\u58f0\u548c\u89c2\u6d4b\u6620\u5c04\u5230\u540e\u9a8c\u91c7\u6837\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u6761\u4ef6\u751f\u6210\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u9488\u5bf9\u9ad8\u7ef4\u3001\u591a\u5cf0\u540e\u9a8c\u5206\u5e03\u7684\u5feb\u901f\u3001\u51c6\u786e\u3001\u53ef\u6269\u5c55\u7684\u6761\u4ef6\u91c7\u6837\uff0c\u975e\u5e38\u9002\u5408\u7528\u4e8e\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7b49\u4efb\u52a1\u3002\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u5408\u6269\u6563\u6a21\u578b\u548c\u6d41\u6a21\u578b\u4f18\u52bf\u7684\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u9ad8\u6548\u548c\u7075\u6d3b\u7684\u6761\u4ef6\u91c7\u6837\uff0c\u5728\u9ad8\u7ef4\u3001\u591a\u5cf0\u540e\u9a8c\u548c\u79d1\u5b66\u53c2\u6570\u4f30\u8ba1\u7b49\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.17352", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17352", "abs": "https://arxiv.org/abs/2506.17352", "authors": ["Tatsuhiro Aoshima", "Mitsuaki Akiyama"], "title": "Towards Safety Evaluations of Theory of Mind in Large Language Models", "comment": null, "summary": "As the capabilities of large language models (LLMs) continue to advance, the\nimportance of rigorous safety evaluation is becoming increasingly evident.\nRecent concerns within the realm of safety assessment have highlighted\ninstances in which LLMs exhibit behaviors that appear to disable oversight\nmechanisms and respond in a deceptive manner. For example, there have been\nreports suggesting that, when confronted with information unfavorable to their\nown persistence during task execution, LLMs may act covertly and even provide\nfalse answers to questions intended to verify their behavior.To evaluate the\npotential risk of such deceptive actions toward developers or users, it is\nessential to investigate whether these behaviors stem from covert, intentional\nprocesses within the model. In this study, we propose that it is necessary to\nmeasure the theory of mind capabilities of LLMs. We begin by reviewing existing\nresearch on theory of mind and identifying the perspectives and tasks relevant\nto its application in safety evaluation. Given that theory of mind has been\npredominantly studied within the context of developmental psychology, we\nanalyze developmental trends across a series of open-weight LLMs. Our results\nindicate that while LLMs have improved in reading comprehension, their theory\nof mind capabilities have not shown comparable development. Finally, we present\nthe current state of safety evaluation with respect to LLMs' theory of mind,\nand discuss remaining challenges for future work.", "AI": {"tldr": "\u672c\u6587\u5173\u6ce8LLM\u7684\u5b89\u5168\u8bc4\u4f30\u95ee\u9898\uff0c\u63d0\u51fa\u6d4b\u91cf\u5176\u7406\u8bba\u5fc3\u667a\u80fd\u529b\u7684\u91cd\u8981\u6027\u3002\u901a\u8fc7\u5206\u6790\u591a\u4e2a\u5f00\u6e90LLM\uff0c\u53d1\u73b0\u5c3d\u7ba1\u6a21\u578b\u5728\u9605\u8bfb\u7406\u89e3\u4e0a\u8fdb\u6b65\u663e\u8457\uff0c\u4f46\u5728\u7406\u8bba\u5fc3\u667a\u80fd\u529b\u65b9\u9762\u63d0\u5347\u6709\u9650\uff0c\u5e76\u63a2\u8ba8\u4e86\u76f8\u5173\u8bc4\u6d4b\u7684\u6311\u6218\u3002", "motivation": "\u8fd1\u671f\uff0cLLM\u5728\u5b89\u5168\u8bc4\u4f30\u9886\u57df\u88ab\u53d1\u73b0\u5b58\u5728\u89c4\u907f\u76d1\u7ba1\u548c\u6b3a\u9a97\u6027\u56de\u5e94\u7b49\u98ce\u9669\u884c\u4e3a\u3002\u4e3a\u533a\u5206\u8fd9\u4e9b\u884c\u4e3a\u662f\u5426\u6e90\u4e8e\u6a21\u578b\u7684\u6709\u610f\u9690\u853d\u8fc7\u7a0b\uff0c\u9700\u8981\u63a2\u7d22\u5176\u7406\u8bba\u5fc3\u667a\u80fd\u529b\u3002", "method": "\u56de\u987e\u73b0\u6709\u7406\u8bba\u5fc3\u667a\u76f8\u5173\u7814\u7a76\uff0c\u754c\u5b9a\u5176\u5728\u5b89\u5168\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u89c6\u89d2\u4e0e\u4efb\u52a1\uff0c\u5e76\u5bf9\u591a\u4e2a\u5f00\u6e90\u6a21\u578b\u8fdb\u884c\u4e86\u53d1\u5c55\u8d8b\u52bf\u5206\u6790\u3002", "result": "LLM\u5728\u9605\u8bfb\u7406\u89e3\u65b9\u9762\u660e\u663e\u63d0\u5347\uff0c\u4f46\u7406\u8bba\u5fc3\u667a\u80fd\u529b\u672a\u89c1\u7c7b\u4f3c\u8fdb\u5c55\u3002\u540c\u65f6\u6307\u51fa\u7406\u8bba\u5fc3\u667a\u89c6\u89d2\u4e0b\u5b89\u5168\u8bc4\u4f30\u7684\u73b0\u72b6\u53ca\u672a\u6765\u6311\u6218\u3002", "conclusion": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u7406\u8bba\u5fc3\u667a\uff08theory of mind\uff09\u80fd\u529b\u4e0a\u5e76\u672a\u5c55\u73b0\u51fa\u4e0e\u5176\u9605\u8bfb\u7406\u89e3\u80fd\u529b\u540c\u6b65\u7684\u63d0\u5347\uff0c\u8fd9\u5bf9\u5b89\u5168\u6027\u8bc4\u4f30\u5e26\u6765\u6311\u6218\u3002"}}
{"id": "2506.17585", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17585", "abs": "https://arxiv.org/abs/2506.17585", "authors": ["Yukun Huang", "Sanxing Chen", "Jian Pei", "Manzil Zaheer", "Bhuwan Dhingra"], "title": "Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models", "comment": null, "summary": "Trustworthy language models should provide both correct and verifiable\nanswers. While language models can sometimes attribute their outputs to\npretraining data, their citations are often unreliable due to hallucination. As\na result, current systems insert citations by querying an external retriever at\ninference time, introducing latency, infrastructure dependence, and\nvulnerability to retrieval noise. We explore whether LLMs can be made to\nreliably attribute to the documents seen during (continual)\npretraining--without test-time retrieval--by revising the training process. To\nevaluate this, we release CitePretrainBench, a benchmark that mixes real-world\ncorpora (Wikipedia, Common Crawl, arXiv) with novel, unseen documents and\nprobes both short-form (single fact) and long-form (multi-fact) citation tasks.\nOur approach follows a two-stage process: (1) continual pretraining to bind\nfacts to persistent document identifiers, and (2) instruction tuning to elicit\ncitation behavior. We find that simple Passive Indexing, which appends an\nidentifier to each document, helps memorize verbatim text but fails on\nparaphrased or compositional facts. Instead, we propose Active Indexing, which\ncontinually pretrains on synthetic QA pairs that (1) restate each fact in\ndiverse compositional forms, and (2) require bidirectional source-to-fact and\nfact-to-source generation, jointly teaching the model to generate content from\na cited source and to attribute its own answers. Experiments with Qwen2.5-7B\nand 3B show that Active Indexing consistently outperforms Passive Indexing\nacross all tasks and models, with citation precision gains up to 30.2 percent.\nOur ablation studies reveal that performance continues to improve as we scale\nthe amount of augmented data, showing a clear upward trend even at 16 times the\noriginal token count.", "AI": {"tldr": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e3b\u52a8\u7d22\u5f15\u8bad\u7ec3\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u7684\u5f15\u7528\u51c6\u786e\u7387\uff0c\u5b9e\u73b0\u65e0\u9700\u63a8\u7406\u65f6\u5916\u90e8\u68c0\u7d22\u5373\u53ef\u53ef\u9760\u5f52\u56e0\uff0c\u5176\u6548\u679c\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0b\u6301\u7eed\u63d0\u5347\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6709\u65f6\u80fd\u591f\u5c06\u8f93\u51fa\u5f52\u56e0\u4e8e\u5176\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u4f46\u5b9e\u9645\u5f15\u7528\u5e38\u5e38\u4e0d\u51c6\u786e\uff0c\u5b58\u5728\u5e7b\u89c9\uff08hallucination\uff09\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u63a8\u7406\u65f6\u5916\u90e8\u68c0\u7d22\u7cfb\u7edf\u8fdb\u884c\u5f15\u7528\uff0c\u5e26\u6765\u5ef6\u8fdf\u3001\u566a\u58f0\u548c\u4f9d\u8d56\u6027\uff0c\u56e0\u6b64\u4f5c\u8005\u60f3\u63a2\u7d22LLM\u80fd\u5426\u901a\u8fc7\u6539\u8fdb\u8bad\u7ec3\u6d41\u7a0b\uff0c\u65e0\u9700\u63a8\u7406\u65f6\u68c0\u7d22\uff0c\u5c31\u80fd\u53ef\u9760\u5730\u5185\u751f\u5f15\u7528\u3002", "method": "\u63d0\u51fa\u5e76\u6bd4\u8f83\u4e86\u4e24\u79cd\u8bad\u7ec3\u65b9\u6cd5\uff1a\uff081\uff09\u88ab\u52a8\u7d22\u5f15\uff08Passive Indexing\uff09\uff1a\u6301\u7eed\u9884\u8bad\u7ec3\u65f6\u4e3a\u6bcf\u4efd\u6587\u6863\u9644\u52a0\u6807\u8bc6\u7b26\uff0c\u52a0\u5f3a\u6a21\u578b\u8bb0\u5fc6\u6587\u6863\u5185\u5bb9\uff1b\uff082\uff09\u4e3b\u52a8\u7d22\u5f15\uff08Active Indexing\uff09\uff1a\u901a\u8fc7\u5408\u6210\u95ee\u7b54\u5bf9\uff0c\u591a\u6837\u5316\u8868\u8fbe\u4e8b\u5b9e\uff0c\u5e76\u8fdb\u884c\u6e90-\u4e8b\u5b9e\u53cc\u5411\u751f\u6210\u8bad\u7ec3\uff0c\u4ece\u800c\u534f\u540c\u5b66\u4e60\u751f\u6210\u5185\u5bb9\u548c\u81ea\u5f52\u56e0\u80fd\u529b\u3002\u5b9e\u9a8c\u8fd8\u53d1\u5e03\u4e86\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6CitePretrainBench\u3002", "result": "\u4e3b\u52a8\u7d22\u5f15\uff08Active Indexing\uff09\u65e0\u8bba\u5728\u77ed\u5f62\u5f0f\uff08\u5355\u4e00\u4e8b\u5b9e\uff09\u8fd8\u662f\u957f\u5f62\u5f0f\uff08\u591a\u4e8b\u5b9e\uff09\u5f15\u7528\u4efb\u52a1\u4e2d\uff0c\u90fd\u663e\u8457\u4f18\u4e8e\u88ab\u52a8\u7d22\u5f15\uff0c\u5728\u6a21\u578bQwen2.5-7B\u548c3B\u4e0a\u5f15\u7528\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe30.2%\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\uff0c\u968f\u7740\u589e\u5f3a\u6570\u636e\u91cf\u6269\u5927\uff0c\u6027\u80fd\u6301\u7eed\u63d0\u5347\uff0c\u5728\u539f\u59cbtoken\u6570\u768416\u500d\u65f6\u4ecd\u6709\u660e\u663e\u589e\u957f\u3002", "conclusion": "\u901a\u8fc7\u8bbe\u8ba1\u4e3b\u52a8\u7d22\u5f15\u673a\u5236\uff0c\u65e0\u9700\u63a8\u7406\u65f6\u5916\u90e8\u68c0\u7d22\u5373\u53ef\u663e\u8457\u63d0\u5347LLM\u7684\u51c6\u786e\u548c\u53ef\u9a8c\u8bc1\u5f15\u7528\u80fd\u529b\u3002\u8be5\u65b9\u5f0f\u66f4\u9002\u5e94\u73b0\u5b9e\u9700\u6c42\uff0c\u4e3a\u66f4\u53ef\u9760\u7684\u5f15\u7528\u548c\u77e5\u8bc6\u5f52\u56e0\u63d0\u4f9b\u65b0\u8def\u5f84\u3002"}}
{"id": "2506.17370", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17370", "abs": "https://arxiv.org/abs/2506.17370", "authors": ["Aditi Madhusudan Jain", "Ayush Jain"], "title": "AI based Content Creation and Product Recommendation Applications in E-commerce: An Ethical overview", "comment": null, "summary": "As e-commerce rapidly integrates artificial intelligence for content creation\nand product recommendations, these technologies offer significant benefits in\npersonalization and efficiency. AI-driven systems automate product\ndescriptions, generate dynamic advertisements, and deliver tailored\nrecommendations based on consumer behavior, as seen in major platforms like\nAmazon and Shopify. However, the widespread use of AI in e-commerce raises\ncrucial ethical challenges, particularly around data privacy, algorithmic bias,\nand consumer autonomy. Bias -- whether cultural, gender-based, or socioeconomic\n-- can be inadvertently embedded in AI models, leading to inequitable product\nrecommendations and reinforcing harmful stereotypes. This paper examines the\nethical implications of AI-driven content creation and product recommendations,\nemphasizing the need for frameworks to ensure fairness, transparency, and need\nfor more established and robust ethical standards. We propose actionable best\npractices to remove bias and ensure inclusivity, such as conducting regular\naudits of algorithms, diversifying training data, and incorporating fairness\nmetrics into AI models. Additionally, we discuss frameworks for ethical\nconformance that focus on safeguarding consumer data privacy, promoting\ntransparency in decision-making processes, and enhancing consumer autonomy. By\naddressing these issues, we provide guidelines for responsibly utilizing AI in\ne-commerce applications for content creation and product recommendations,\nensuring that these technologies are both effective and ethically sound.", "AI": {"tldr": "AI\u5728\u7535\u5546\u5185\u5bb9\u751f\u6210\u548c\u4ea7\u54c1\u63a8\u8350\u4e2d\u5e26\u6765\u6548\u7387\u548c\u4e2a\u6027\u5316\u63d0\u5347\uff0c\u4f46\u4f34\u968f\u6570\u636e\u9690\u79c1\u548c\u7b97\u6cd5\u504f\u89c1\u7b49\u4f26\u7406\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u5ba1\u8ba1\u7b97\u6cd5\u3001\u4e30\u5bcc\u8bad\u7ec3\u6570\u636e\u3001\u591a\u7ef4\u516c\u5e73\u6027\u8003\u91cf\u7b49\u89e3\u51b3\u7b56\u7565\uff0c\u5e76\u9488\u5bf9\u6570\u636e\u9690\u79c1\u548c\u900f\u660e\u5ea6\u63d0\u4f9b\u6846\u67b6\u5efa\u8bae\uff0c\u4e3a\u7535\u5546AI\u5e94\u7528\u6307\u660e\u4e86\u5408\u4e4e\u9053\u5fb7\u7684\u53d1\u5c55\u8def\u5f84\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5728\u7535\u5546\u5185\u5bb9\u751f\u6210\u548c\u4ea7\u54c1\u63a8\u8350\u4e2d\u7684\u5feb\u901f\u5e94\u7528\uff0c\u5c3d\u7ba1\u5e26\u6765\u4e86\u4e2a\u6027\u5316\u548c\u6548\u7387\u63d0\u5347\uff0c\u4f46\u76f8\u5e94\u7684\u4f26\u7406\u6311\u6218\u4e5f\u65e5\u76ca\u51f8\u663e\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u9690\u79c1\u3001\u7b97\u6cd5\u504f\u89c1\u548c\u6d88\u8d39\u8005\u81ea\u4e3b\u6743\u65b9\u9762\u3002", "method": "\u672c\u6587\u7cfb\u7edf\u6027\u5730\u5206\u6790\u4e86AI\u9a71\u52a8\u7684\u5185\u5bb9\u751f\u6210\u548c\u4ea7\u54c1\u63a8\u8350\u4e2d\u7684\u4f26\u7406\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u901a\u8fc7\u7b97\u6cd5\u5e38\u89c4\u5ba1\u8ba1\u3001\u591a\u6837\u5316\u8bad\u7ec3\u6570\u636e\u548c\u5f15\u5165\u516c\u5e73\u6027\u6307\u6807\u7b49\u65b9\u6cd5\u6d88\u9664\u504f\u89c1\u548c\u4fc3\u8fdb\u5305\u5bb9\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u5173\u6ce8\u6570\u636e\u9690\u79c1\u3001\u900f\u660e\u5ea6\u548c\u6d88\u8d39\u8005\u81ea\u4e3b\u6743\u7684\u4f26\u7406\u5408\u89c4\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u53ef\u64cd\u4f5c\u7684\u6700\u4f73\u5b9e\u8df5\u65b9\u6cd5\uff0c\u5305\u62ec\u5b9a\u671f\u5ba1\u8ba1\u7b97\u6cd5\u3001\u4e30\u5bcc\u6570\u636e\u591a\u6837\u6027\u548c\u878d\u5408\u516c\u5e73\u6027\u6307\u6807\u7b49\uff0c\u540c\u65f6\u9488\u5bf9\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u548c\u51b3\u7b56\u900f\u660e\u5ea6\u63d0\u4f9b\u4e86\u5177\u4f53\u6846\u67b6\u5efa\u8bae\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u8df5\u8fd9\u4e9b\u5efa\u8bae\uff0c\u53ef\u4ee5\u786e\u4fdd\u7535\u5546\u5728\u91c7\u7528AI\u8fdb\u884c\u5185\u5bb9\u751f\u6210\u548c\u4ea7\u54c1\u63a8\u8350\u65f6\uff0c\u6280\u672f\u65e2\u6709\u6548\u53c8\u5408\u4e4e\u4f26\u7406\u3002"}}
{"id": "2506.18427", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.18427", "abs": "https://arxiv.org/abs/2506.18427", "authors": ["Weihang Ouyang", "Yeonjong Shin", "Si-Wei Liu", "Lu Lu"], "title": "Neural-operator element method: Efficient and scalable finite element method enabled by reusable neural operators", "comment": null, "summary": "The finite element method (FEM) is a well-established numerical method for\nsolving partial differential equations (PDEs). However, its mesh-based nature\ngives rise to substantial computational costs, especially for complex\nmultiscale simulations. Emerging machine learning-based methods (e.g., neural\noperators) provide data-driven solutions to PDEs, yet they present challenges,\nincluding high training cost and low model reusability. Here, we propose the\nneural-operator element method (NOEM) by synergistically combining FEM with\noperator learning to address these challenges. NOEM leverages neural operators\n(NOs) to simulate subdomains where a large number of finite elements would be\nrequired if FEM was used. In each subdomain, an NO is used to build a single\nelement, namely a neural-operator element (NOE). NOEs are then integrated with\nstandard finite elements to represent the entire solution through the\nvariational framework. Thereby, NOEM does not necessitate dense meshing and\noffers efficient simulations. We demonstrate the accuracy, efficiency, and\nscalability of NOEM by performing extensive and systematic numerical\nexperiments, including nonlinear PDEs, multiscale problems, PDEs on complex\ngeometries, and discontinuous coefficient fields.", "AI": {"tldr": "\u63d0\u51faNOEM\u65b9\u6cd5\uff0c\u5c06\u6709\u9650\u5143\u4e0e\u795e\u7ecf\u7b97\u5b50\u7ed3\u5408\uff0c\u6709\u6548\u51cf\u5c11\u7f51\u683c\u9700\u6c42\uff0c\u5927\u5e45\u63d0\u9ad8PDE\u4eff\u771f\u6548\u7387\u5e76\u4fdd\u8bc1\u7cbe\u5ea6\uff0c\u9002\u7528\u4e8e\u591a\u7c7b\u578b\u590d\u6742\u95ee\u9898\u3002", "motivation": "\u6709\u9650\u5143\u65b9\u6cd5\uff08FEM\uff09\u867d\u7136\u6709\u6548\uff0c\u4f46\u5728\u5904\u7406\u590d\u6742\u591a\u5c3a\u5ea6\u95ee\u9898\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5982\u795e\u7ecf\u7b97\u5b50\u80fd\u63d0\u4f9b\u6570\u636e\u9a71\u52a8\u7684PDE\u6c42\u89e3\uff0c\u4f46\u8bad\u7ec3\u6210\u672c\u9ad8\u3001\u6a21\u578b\u590d\u7528\u6027\u4f4e\u3002\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u662f\u672c\u7814\u7a76\u7684\u51fa\u53d1\u70b9\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u7b97\u5b50\u5143\u65b9\u6cd5\uff08NOEM\uff09\uff0c\u5c06\u6709\u9650\u5143\u65b9\u6cd5\u4e0e\u795e\u7ecf\u7b97\u5b50\u7ed3\u5408\u3002\u5728\u9700\u8981\u5927\u91cf\u6709\u9650\u5143\u7684\u5b50\u57df\u4e2d\uff0c\u7528\u5355\u4e2a\u795e\u7ecf\u7b97\u5b50\u5143\uff08NOE\uff09\u4ee3\u66ff\u591a\u4e2a\u6709\u9650\u5143\u3002NOE\u4e0e\u6807\u51c6\u6709\u9650\u5143\u901a\u8fc7\u53d8\u5206\u6846\u67b6\u6574\u5408\uff0c\u6a21\u62df\u6574\u4f53\u89e3\uff0c\u65e0\u9700\u9ad8\u5bc6\u5ea6\u7f51\u683c\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u7cfb\u7edf\u7684\u6570\u503c\u5b9e\u9a8c\uff08\u5904\u7406\u975e\u7ebf\u6027PDE\u3001\u591a\u5c3a\u5ea6\u95ee\u9898\u3001\u590d\u6742\u51e0\u4f55\u548c\u4e0d\u8fde\u7eed\u7cfb\u6570\u573a\uff09\u5c55\u793a\u4e86NOEM\u5728\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "NOEM\u517c\u987e\u4e86\u6709\u9650\u5143\u7684\u7269\u7406\u901a\u7528\u6027\u4e0e\u795e\u7ecf\u7b97\u5b50\u7684\u6548\u7387\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742PDE\u6a21\u62df\u7684\u8ba1\u7b97\u6548\u7387\u548c\u9002\u5e94\u6027\uff0c\u662f\u89e3\u51b3\u9ad8\u6027\u80fd\u8ba1\u7b97PDE\u95ee\u9898\u7684\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2506.17367", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.17367", "abs": "https://arxiv.org/abs/2506.17367", "authors": ["Mateusz Cedro", "Timour Ichmoukhamedov", "Sofie Goethals", "Yifan He", "James Hinns", "David Martens"], "title": "Cash or Comfort? How LLMs Value Your Inconvenience", "comment": "12 pages, 4 figures, 3 tables", "summary": "Large Language Models (LLMs) are increasingly proposed as near-autonomous\nartificial intelligence (AI) agents capable of making everyday decisions on\nbehalf of humans. Although LLMs perform well on many technical tasks, their\nbehaviour in personal decision-making remains less understood. Previous studies\nhave assessed their rationality and moral alignment with human decisions.\nHowever, the behaviour of AI assistants in scenarios where financial rewards\nare at odds with user comfort has not yet been thoroughly explored. In this\npaper, we tackle this problem by quantifying the prices assigned by multiple\nLLMs to a series of user discomforts: additional walking, waiting, hunger and\npain. We uncover several key concerns that strongly question the prospect of\nusing current LLMs as decision-making assistants: (1) a large variance in\nresponses between LLMs, (2) within a single LLM, responses show fragility to\nminor variations in prompt phrasing (e.g., reformulating the question in the\nfirst person can considerably alter the decision), (3) LLMs can accept\nunreasonably low rewards for major inconveniences (e.g., 1 Euro to wait 10\nhours), and (4) LLMs can reject monetary gains where no discomfort is imposed\n(e.g., 1,000 Euro to wait 0 minutes). These findings emphasize the need for\nscrutiny of how LLMs value human inconvenience, particularly as we move toward\napplications where such cash-versus-comfort trade-offs are made on users'\nbehalf.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\uff0c\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6d89\u53ca\u7528\u6237\u8212\u9002\u4e0e\u91d1\u94b1\u5956\u52b1\u7684\u51b3\u7b56\u4e2d\u8868\u73b0\u51fa\u9ad8\u6ce2\u52a8\u3001\u4e0d\u5408\u7406\u5b9a\u4ef7\u548c\u5bf9\u63d0\u793a\u654f\u611f\u7b49\u95ee\u9898\uff0c\u63d0\u793a\u5176\u4e0d\u9002\u5b9c\u5728\u76f8\u5173\u5b9e\u9645\u5e94\u7528\u4e2d\u76f4\u63a5\u51b3\u7b56\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u88ab\u63d0\u8bae\u4f5c\u4e3a\u80fd\u591f\u4ee3\u8868\u4eba\u7c7b\u505a\u65e5\u5e38\u51b3\u7b56\u7684AI\u4ee3\u7406\uff0c\u4f46\u5176\u5728\u6d89\u53ca\u7528\u6237\u8212\u9002\u5ea6\u4e0e\u91d1\u94b1\u5956\u52b1\u51b2\u7a81\u65f6\u7684\u51b3\u7b56\u884c\u4e3a\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u91cf\u5316\u591a\u4e2a\u4e3b\u6d41LLM\u5bf9\u7528\u6237\u4e0d\u9002\uff08\u5982\u591a\u8d70\u8def\u3001\u7b49\u5f85\u3001\u9965\u997f\u548c\u75bc\u75db\uff09\u7684\u201c\u4ef7\u683c\u201d\u8bc4\u4f30\uff0c\u5373\u5206\u6790\u5b83\u4eec\u5728\u73b0\u91d1\u4e0e\u8212\u9002\u6743\u8861\u573a\u666f\u4e0b\u7ed9\u51fa\u7684\u5177\u4f53\u6570\u503c\u53cd\u5e94\u3002", "result": "\uff081\uff09\u4e0d\u540cLLM\u7684\u56de\u590d\u5dee\u5f02\u5f88\u5927\uff1b\uff082\uff09\u5355\u4e00LLM\u5728\u63d0\u793a\u8bed\u7684\u7ec6\u5fae\u53d8\u5316\u4e0b\u8868\u73b0\u8106\u5f31\uff1b\uff083\uff09LLM\u6709\u65f6\u4f1a\u5bf9\u91cd\u5927\u4e0d\u4fbf\u63a5\u53d7\u6781\u4f4e\u62a5\u916c\uff08\u5982\u4e3a\u7b49\u5f8510\u5c0f\u65f6\u53ea\u65361\u6b27\u5143\uff09\uff1b\uff084\uff09\u5728\u65e0\u4e0d\u9002\u60c5\u51b5\u4e0b\uff0cLLM\u751a\u81f3\u4f1a\u62d2\u7edd\u53ef\u89c2\u62a5\u916c\uff08\u5982\u7b49\u5f850\u5206\u949f\u62d2\u65361000\u6b27\u5143\uff09\u3002", "conclusion": "\u76ee\u524dLLM\u5728\u73b0\u91d1\u4e0e\u7528\u6237\u8212\u9002\u6743\u8861\u65b9\u9762\u7684\u884c\u4e3a\u5b58\u5728\u8bf8\u591a\u95ee\u9898\uff0c\u96be\u4ee5\u76f4\u63a5\u4f5c\u4e3a\u53ef\u9760\u7684\u51b3\u7b56\u52a9\u624b\uff0c\u9700\u8c28\u614e\u8bc4\u4f30\u5176\u5728\u6b64\u7c7b\u573a\u666f\u4e0b\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.17589", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17589", "abs": "https://arxiv.org/abs/2506.17589", "authors": ["Bowen Wang"], "title": "Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to Conquer the Unknown", "comment": null, "summary": "The real value of knowledge lies not just in its accumulation, but in its\npotential to be harnessed effectively to conquer the unknown. Although recent\nmultimodal large language models (MLLMs) exhibit impressing multimodal\ncapabilities, they often fail in rarely encountered domain-specific tasks due\nto limited relevant knowledge. To explore this, we adopt visual game cognition\nas a testbed and select Monster Hunter: World as the target to construct a\nmultimodal knowledge graph (MH-MMKG), which incorporates multi-modalities and\nintricate entity relations. We also design a series of challenging queries\nbased on MH-MMKG to evaluate the models' ability for complex knowledge\nretrieval and reasoning. Furthermore, we propose a multi-agent retriever that\nenables a model to autonomously search relevant knowledge without additional\ntraining. Experimental results show that our approach significantly enhances\nthe performance of MLLMs, providing a new perspective on multimodal\nknowledge-augmented reasoning and laying a solid foundation for future\nresearch.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9762\u5411\u89c6\u89c9\u6e38\u620f\u9886\u57df\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u4e0e\u591a\u667a\u80fd\u4f53\u68c0\u7d22\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u590d\u6742\u9886\u57df\u5185\u7684\u77e5\u8bc6\u68c0\u7d22\u4e0e\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u5904\u7406\u5c11\u89c1\u7684\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u65f6\uff0c\u7531\u4e8e\u76f8\u5173\u77e5\u8bc6\u6709\u9650\uff0c\u8868\u73b0\u6b20\u4f73\u3002\u4f5c\u8005\u5e0c\u671b\u63a2\u7d22\u5982\u4f55\u589e\u5f3aMLLMs\u5728\u7279\u5b9a\u9886\u57df\u590d\u6742\u77e5\u8bc6\u68c0\u7d22\u548c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u4ee5\u89c6\u89c9\u6e38\u620f\u8ba4\u77e5\u4f5c\u4e3a\u7814\u7a76\u6d4b\u8bd5\u573a\uff0c\u9009\u62e9\u300a\u602a\u7269\u730e\u4eba\uff1a\u4e16\u754c\u300b\u4f5c\u4e3a\u5bf9\u8c61\uff0c\u6784\u5efa\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\uff08MH-MMKG\uff09\uff0c\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u548c\u590d\u6742\u5b9e\u4f53\u5173\u7cfb\u3002\u57fa\u4e8eMH-MMKG\u8bbe\u8ba1\u9ad8\u96be\u5ea6\u67e5\u8be2\u8bc4\u6d4b\u6a21\u578b\u77e5\u8bc6\u68c0\u7d22\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u591a\u667a\u80fd\u4f53\u68c0\u7d22\u5668\uff0c\u4e3b\u52a8\u6001\u68c0\u7d22\u76f8\u5173\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f5c\u8005\u7684\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u8868\u73b0\uff0c\u4e3a\u591a\u6a21\u6001\u77e5\u8bc6\u589e\u5f3a\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u548c\u575a\u5b9e\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u6784\u5efa\u590d\u6742\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u4e0e\u591a\u667a\u80fd\u4f53\u68c0\u7d22\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u63a8\u7406\u548c\u68c0\u7d22\u80fd\u529b\uff0c\u5bf9\u540e\u7eed\u7814\u7a76\u5177\u6709\u91cd\u8981\u63a8\u52a8\u4f5c\u7528\u3002"}}
{"id": "2506.17372", "categories": ["cs.CY", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.17372", "abs": "https://arxiv.org/abs/2506.17372", "authors": ["Cedric Bernard", "Xavier Pleimling", "Amun Kharel", "Chase Vickery"], "title": "Multimodal Political Bias Identification and Neutralization", "comment": null, "summary": "Due to the presence of political echo chambers, it becomes imperative to\ndetect and remove subjective bias and emotionally charged language from both\nthe text and images of political articles. However, prior work has focused on\nsolely the text portion of the bias rather than both the text and image\nportions. This is a problem because the images are just as powerful of a medium\nto communicate information as text is. To that end, we present a model that\nleverages both text and image bias which consists of four different steps.\nImage Text Alignment focuses on semantically aligning images based on their\nbias through CLIP models. Image Bias Scoring determines the appropriate bias\nscore of images via a ViT classifier. Text De-Biasing focuses on detecting\nbiased words and phrases and neutralizing them through BERT models. These three\nsteps all culminate to the final step of debiasing, which replaces the text and\nthe image with neutralized or reduced counterparts, which for images is done by\ncomparing the bias scores. The results so far indicate that this approach is\npromising, with the text debiasing strategy being able to identify many\npotential biased words and phrases, and the ViT model showcasing effective\ntraining. The semantic alignment model also is efficient. However, more time,\nparticularly in training, and resources are needed to obtain better results. A\nhuman evaluation portion was also proposed to ensure semantic consistency of\nthe newly generated text and images.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u6587\u672c\u548c\u56fe\u7247\u7684\u653f\u6cbb\u6587\u7ae0\u53bb\u504f\u89c1\u65b9\u6cd5\uff0c\u80fd\u8f83\u597d\u8bc6\u522b\u548c\u51cf\u5c11\u6587\u672c\u53ca\u56fe\u7247\u4e2d\u7684\u504f\u89c1\uff0c\u4f46\u6a21\u578b\u8fd8\u9700\u66f4\u591a\u8bad\u7ec3\u548c\u8d44\u6e90\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u504f\u89c1\u68c0\u6d4b\u65b9\u6cd5\u4ec5\u5173\u6ce8\u6587\u672c\uff0c\u5ffd\u89c6\u4e86\u56fe\u7247\u90e8\u5206\uff0c\u800c\u56fe\u7247\u5728\u4f20\u64ad\u4fe1\u606f\u65f6\u540c\u6837\u91cd\u8981\u3002\u7531\u4e8e\u653f\u6cbb\u56de\u97f3\u5ba4\u73b0\u8c61\uff0c\u6709\u5fc5\u8981\u540c\u65f6\u9488\u5bf9\u653f\u6cbb\u6587\u7ae0\u4e2d\u7684\u6587\u672c\u4e0e\u56fe\u7247\u53bb\u9664\u4e3b\u89c2\u504f\u89c1\u548c\u60c5\u7eea\u5316\u8bed\u8a00\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u6587\u672c\u548c\u56fe\u7247\u504f\u89c1\u5206\u6790\u7684\u65b0\u6a21\u578b\uff0c\u5305\u542b\u56db\u6b65\uff1a\uff081\uff09\u5229\u7528CLIP\u6a21\u578b\u8fdb\u884c\u56fe\u6587\u504f\u89c1\u7684\u8bed\u4e49\u5bf9\u9f50\uff1b\uff082\uff09\u7528ViT\u5206\u7c7b\u5668\u4e3a\u56fe\u7247\u8bc4\u5206\u504f\u89c1\u5ea6\uff1b\uff083\uff09\u7528BERT\u6a21\u578b\u68c0\u6d4b\u4e0e\u6d88\u89e3\u6587\u672c\u4e2d\u7684\u504f\u89c1\u8bcd\u6c47\u4e0e\u77ed\u8bed\uff1b\uff084\uff09\u5c06\u539f\u6587\u4e0e\u56fe\u7247\u66ff\u6362\u4e3a\u7ecf\u8fc7\u4e2d\u548c\u6216\u504f\u89c1\u51cf\u5f31\u7684\u7248\u672c\u3002\u540c\u65f6\u5efa\u8bae\u5f15\u5165\u4eba\u5de5\u8bc4\u4f30\u4ee5\u4fdd\u8bc1\u751f\u6210\u5185\u5bb9\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "result": "\u6587\u672c\u53bb\u504f\u89c1\u65b9\u6cd5\u80fd\u8bc6\u522b\u8bb8\u591a\u6f5c\u5728\u7684\u504f\u89c1\u8bcd\u53e5\uff0cViT\u6a21\u578b\u5bf9\u56fe\u7247\u504f\u89c1\u68c0\u6d4b\u6548\u679c\u826f\u597d\uff0c\u8bed\u4e49\u5bf9\u9f50\u6a21\u578b\u9ad8\u6548\u3002\u4f46\u4e3a\u83b7\u5f97\u66f4\u597d\u7ed3\u679c\uff0c\u8fd8\u9700\u66f4\u591a\u8bad\u7ec3\u548c\u8d44\u6e90\u3002", "conclusion": "\u7ed3\u5408\u6587\u672c\u4e0e\u56fe\u7247\u504f\u89c1\u68c0\u6d4b\u548c\u53bb\u504f\u89c1\u5904\u7406\u7684\u65b9\u6848\u5177\u5907\u524d\u666f\uff0c\u521d\u6b65\u5b9e\u9a8c\u6709\u6548\uff0c\u4f46\u6a21\u578b\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u5e76\u5f3a\u5316\u8bad\u7ec3\u3002"}}
{"id": "2506.18554", "categories": ["cs.CE", "cond-mat.mtrl-sci", "physics.app-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2506.18554", "abs": "https://arxiv.org/abs/2506.18554", "authors": ["J. Wijnen", "J. Parker", "M. Gagliano", "E. Mart\u00ednez-Pa\u00f1eda"], "title": "Virtual failure assessment diagrams for hydrogen transmission pipelines", "comment": null, "summary": "We combine state-of-the-art thermo-metallurgical welding process modelling\nwith coupled diffusion-elastic-plastic phase field fracture simulations to\npredict the failure states of hydrogen transport pipelines. This enables\nquantitatively resolving residual stress states and the role of brittle, hard\nregions of the weld such as the heat affected zone (HAZ). Failure pressures can\nbe efficiently quantified as a function of asset state (existing defects),\nmaterials and weld procedures adopted, and hydrogen purity. Importantly,\nsimulations spanning numerous relevant conditions (defect size and\norientations) are used to build \\emph{Virtual} Failure Assessment Diagrams\n(FADs), enabling a straightforward uptake of this mechanistic approach in\nfitness-for-service assessment. Model predictions are in very good agreement\nwith FAD approaches from the standards but show that the latter are not\nconservative when resolving the heterogeneous nature of the weld\nmicrostructure. Appropriate, \\emph{mechanistic} FAD safety factors are\nestablished that account for the role of residual stresses and hard, brittle\nweld regions.", "AI": {"tldr": "\u4f5c\u8005\u901a\u8fc7\u591a\u7269\u7406\u573a\u8026\u5408\u6a21\u62df\u7cfb\u7edf\u8bc4\u4f30\u6c22\u6c14\u7ba1\u9053\u710a\u7f1d\u7f3a\u9677\u7684\u5931\u6548\u884c\u4e3a\uff0c\u63d0\u51fa\u865a\u62df\u5931\u6548\u8bc4\u4f30\u56fe\uff0c\u8bc1\u660e\u6807\u51c6\u65b9\u6cd5\u5bf9\u590d\u6742\u710a\u7f1d\u5fae\u89c2\u7ed3\u6784\u4f4e\u4f30\u4e86\u98ce\u9669\uff0c\u5e76\u7ed9\u51fa\u66f4\u5408\u7406\u7684\u673a\u5236\u6027\u5b89\u5168\u7cfb\u6570\u3002", "motivation": "\u968f\u7740\u6c22\u80fd\u6e90\u7684\u5174\u8d77\uff0c\u6c22\u6c14\u8fd0\u8f93\u7ba1\u9053\u7684\u7ed3\u6784\u5b89\u5168\u9010\u6e10\u6210\u4e3a\u4e1a\u754c\u5173\u6ce8\u7684\u7126\u70b9\u3002\u4f20\u7edf\u5931\u6548\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u53cd\u6620\u710a\u63a5\u5de5\u827a\u4ea7\u751f\u7684\u6b8b\u4f59\u5e94\u529b\u53ca\u70ed\u5f71\u54cd\u533a\uff08HAZ\uff09\u786c\u8106\u533a\u57df\u5bf9\u5931\u6548\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u66f4\u5177\u7269\u7406\u673a\u5236\u7684\u5931\u6548\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u5c06\u6700\u5148\u8fdb\u7684\u70ed-\u51b6\u91d1\u710a\u63a5\u5de5\u827a\u5efa\u6a21\u4e0e\u8026\u5408\u6269\u6563-\u5f39\u5851\u6027\u76f8\u573a\u65ad\u88c2\u6a21\u62df\u76f8\u7ed3\u5408\uff0c\u7cfb\u7edf\u5206\u6790\u7ba1\u9053\u7ed3\u6784\u4e2d\u7684\u6b8b\u4f59\u5e94\u529b\u5206\u5e03\u548c\u5c40\u90e8\u786c\u8106\u533a\u57df\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669\u3002\u901a\u8fc7\u6a21\u62df\u4e0d\u540c\u7f3a\u9677\u5c3a\u5bf8\u4e0e\u53d6\u5411\u3001\u591a\u79cd\u6750\u6599\u4e0e\u710a\u63a5\u5de5\u827a\u53ca\u6c22\u6c14\u7eaf\u5ea6\u60c5\u666f\uff0c\u6784\u5efa\u865a\u62df\u5931\u6548\u8bc4\u4f30\u56fe\uff08Virtual Failure Assessment Diagrams\uff0cFADs\uff09\uff0c\u4e3a\u670d\u5f79\u9002\u5e94\u6027\u8bc4\u4f30\uff08Fitness-for-service assessment\uff09\u63d0\u4f9b\u76f4\u89c2\u5de5\u5177\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u4e0e\u6807\u51c6\u4e2d\u7684FAD\u65b9\u6cd5\u9ad8\u5ea6\u543b\u5408\uff0c\u4f46\u63ed\u793a\u51fa\u4f20\u7edf\u6807\u51c6\u65e0\u6cd5\u5bf9\u710a\u63a5\u5fae\u89c2\u7ed3\u6784\u5f02\u8d28\u6027\u8fdb\u884c\u4fdd\u5b88\u6027\u8bc4\u4f30\u3002\u7814\u7a76\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u80fd\u591f\u91cf\u5316\u6b8b\u4f59\u5e94\u529b\u53ca\u786c\u8106\u710a\u7f1d\u533a\u57df\u5f71\u54cd\u7684\u673a\u5236\u6027FAD\u5b89\u5168\u7cfb\u6570\uff0c\u66f4\u597d\u4fdd\u969c\u6c22\u6c14\u7ba1\u9053\u7684\u7ed3\u6784\u5b89\u5168\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u8026\u5408\u6a21\u62df\u65b9\u6cd5\u548c\u865a\u62dfFAD\u5de5\u5177\u4e3a\u6c22\u6c14\u8fd0\u8f93\u7ba1\u9053\u7684\u5931\u6548\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5177\u7269\u7406\u610f\u4e49\u4e14\u66f4\u5177\u4fdd\u5b88\u6027\u7684\u6280\u672f\u652f\u6491\uff0c\u53ef\u4e3a\u76f8\u5173\u6807\u51c6\u7684\u4fee\u8ba2\u548c\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2506.17410", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17410", "abs": "https://arxiv.org/abs/2506.17410", "authors": ["Danielle R. Thomas", "Conrad Borchers", "Jionghao Lin", "Sanjit Kakarla", "Shambhavi Bhushan", "Erin Gatz", "Shivang Gupta", "Ralph Abboud", "Kenneth R. Koedinger"], "title": "Leveraging LLMs to Assess Tutor Moves in Real-Life Dialogues: A Feasibility Study", "comment": "Short research paper accepted at EC-TEL 2025", "summary": "Tutoring improves student achievement, but identifying and studying what\ntutoring actions are most associated with student learning at scale based on\naudio transcriptions is an open research problem. This present study\ninvestigates the feasibility and scalability of using generative AI to identify\nand evaluate specific tutor moves in real-life math tutoring. We analyze 50\nrandomly selected transcripts of college-student remote tutors assisting middle\nschool students in mathematics. Using GPT-4, GPT-4o, GPT-4-turbo,\nGemini-1.5-pro, and LearnLM, we assess tutors' application of two tutor skills:\ndelivering effective praise and responding to student math errors. All models\nreliably detected relevant situations, for example, tutors providing praise to\nstudents (94-98% accuracy) and a student making a math error (82-88% accuracy)\nand effectively evaluated the tutors' adherence to tutoring best practices,\naligning closely with human judgments (83-89% and 73-77%, respectively). We\npropose a cost-effective prompting strategy and discuss practical implications\nfor using large language models to support scalable assessment in authentic\nsettings. This work further contributes LLM prompts to support reproducibility\nand research in AI-supported learning.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc1\u660e\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u9ad8\u6548\u51c6\u786e\u8bc6\u522b\u548c\u8bc4\u4ef7\u771f\u5b9e\u6570\u5b66\u8f85\u5bfc\u4e2d\u7684\u5173\u952e\u884c\u4e3a\uff0c\u4e3a\u8f85\u5bfc\u8d28\u91cf\u8bc4\u4f30\u548c\u6559\u80b2AI\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u548c\u5b9e\u7528\u63d0\u793a\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5df2\u8868\u660e\u8f85\u5bfc\u80fd\u591f\u63d0\u9ad8\u5b66\u751f\u6210\u7ee9\uff0c\u4f46\u5982\u4f55\u57fa\u4e8e\u5927\u89c4\u6a21\u97f3\u9891\u8f6c\u5f55\u6570\u636e\uff0c\u8bc6\u522b\u548c\u7814\u7a76\u5bf9\u5b66\u751f\u5b66\u4e60\u6700\u76f8\u5173\u7684\u8f85\u5bfc\u884c\u4e3a\uff0c\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u7814\u7a76\u96be\u9898\u3002", "method": "\u672c\u7814\u7a76\u5206\u6790\u4e8650\u4efd\u968f\u673a\u62bd\u53d6\u7684\u5927\u5b66\u751f\u8fdc\u7a0b\u8f85\u5bfc\u4e2d\u5b66\u751f\u6570\u5b66\u7684\u8f6c\u5f55\u6587\u672c\uff0c\u91c7\u7528GPT-4\u3001GPT-4o\u3001GPT-4-turbo\u3001Gemini-1.5-pro\u548cLearnLM\u7b49\u751f\u6210\u5f0f\u5927\u6a21\u578b\uff0c\u8bc4\u4f30\u5bfc\u5e08\u5728\u6709\u6548\u8868\u626c\u548c\u5e94\u5bf9\u5b66\u751f\u6570\u5b66\u9519\u8bef\u4e24\u4e2a\u6280\u80fd\u4e0a\u7684\u8868\u73b0\u3002\u901a\u8fc7\u5927\u6a21\u578b\u68c0\u6d4b\u5e76\u8bc4\u4ef7\u8f85\u5bfc\u884c\u4e3a\u7684\u51c6\u786e\u6027\u548c\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5404\u5927\u6a21\u578b\u80fd\u591f\u9ad8\u51c6\u786e\u7387\u68c0\u6d4b\u5bfc\u5e08\u8868\u626c\uff08\u51c6\u786e\u738794-98%\uff09\u548c\u5b66\u751f\u72af\u9519\uff08\u51c6\u786e\u738782-88%\uff09\u7684\u60c5\u666f\uff0c\u5e76\u80fd\u6709\u6548\u8bc4\u4ef7\u5bfc\u5e08\u662f\u5426\u9075\u5faa\u6700\u4f73\u5b9e\u8df5\uff0c\u5176\u8bc4\u4ef7\u7ed3\u679c\u4e0e\u4eba\u5de5\u4e00\u81f4\u5ea6\u9ad8\uff0883-89%\u548c73-77%\uff09\u3002", "conclusion": "\u751f\u6210\u5f0f\u5927\u6a21\u578b\u53ef\u4f5c\u4e3a\u7ecf\u6d4e\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u5de5\u5177\uff0c\u4e3a\u5b9e\u9645\u8f85\u5bfc\u573a\u666f\u4e2d\u884c\u4e3a\u8bc4\u4f30\u63d0\u4f9b\u652f\u6301\uff0c\u5e76\u4fc3\u8fdbAI\u8f85\u52a9\u5b66\u4e60\u7684\u7814\u7a76\u4e0e\u53ef\u590d\u73b0\u6027\u3002\u8bba\u6587\u8fd8\u8d21\u732e\u4e86\u76f8\u5173LLM\u63d0\u793a\u8bcd\u3002"}}
{"id": "2506.17644", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17644", "abs": "https://arxiv.org/abs/2506.17644", "authors": ["Zimo Ji", "Daoyuan Wu", "Wenyuan Jiang", "Pingchuan Ma", "Zongjie Li", "Shuai Wang"], "title": "Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges", "comment": null, "summary": "Capture-the-Flag (CTF) competitions are crucial for cybersecurity education\nand training. As large language models (LLMs) evolve, there is increasing\ninterest in their ability to automate CTF challenge solving. For example, DARPA\nhas organized the AIxCC competition since 2023 to advance AI-powered automated\noffense and defense. However, this demands a combination of multiple abilities,\nfrom knowledge to reasoning and further to actions. In this paper, we highlight\nthe importance of technical knowledge in solving CTF problems and deliberately\nconstruct a focused benchmark, CTFKnow, with 3,992 questions to measure LLMs'\nperformance in this core aspect. Our study offers a focused and innovative\nmeasurement of LLMs' capability in understanding CTF knowledge and applying it\nto solve CTF challenges. Our key findings reveal that while LLMs possess\nsubstantial technical knowledge, they falter in accurately applying this\nknowledge to specific scenarios and adapting their strategies based on feedback\nfrom the CTF environment.\n  Based on insights derived from this measurement study, we propose CTFAgent, a\nnovel LLM-driven framework for advancing CTF problem-solving. CTFAgent\nintroduces two new modules: two-stage Retrieval Augmented Generation (RAG) and\ninteractive Environmental Augmentation, which enhance LLMs' technical knowledge\nand vulnerability exploitation on CTF, respectively. Our experimental results\nshow that, on two popular CTF datasets, CTFAgent both achieves over 80%\nperformance improvement. Moreover, in the recent picoCTF2024 hosted by CMU,\nCTFAgent ranked in the top 23.6% of nearly 7,000 participating teams. This\nreflects the benefit of our measurement study and the potential of our\nframework in advancing LLMs' capabilities in CTF problem-solving.", "AI": {"tldr": "\u8bba\u6587\u6784\u5efa\u4e86CTFKnow\u57fa\u51c6\u8861\u91cfLLM\u5728CTF\u9886\u57df\u7684\u77e5\u8bc6\u638c\u63e1\u4e0e\u5e94\u7528\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u5b9e\u9645\u89e3\u9898\u65f6\u5b58\u5728\u77ed\u677f\u3002\u63d0\u51fa\u65b0\u6846\u67b6CTFAgent\uff0c\u901a\u8fc7\u589e\u5f3a\u6280\u672f\u77e5\u8bc6\u548c\u73af\u5883\u9002\u5e94\u6027\uff0c\u5728\u591a\u4e2a\u6807\u51c6\u6570\u636e\u96c6\u548c\u771f\u5b9e\u7ade\u8d5b\u4e2d\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u529b\u63d0\u5347\uff0c\u8d8a\u6765\u8d8a\u591a\u7814\u7a76\u8005\u5173\u6ce8\u5176\u5728\u7f51\u7edc\u5b89\u5168\u653b\u9632\u7ade\u8d5b\uff08\u5982CTF\uff09\u4e2d\u7684\u81ea\u52a8\u89e3\u9898\u80fd\u529b\uff0c\u4f46\u76ee\u524dLLM\u5728\u89e3\u51b3CTF\u95ee\u9898\u65f6\u9700\u8981\u591a\u79cd\u590d\u5408\u80fd\u529b\uff0c\u5c24\u5176\u662f\u6280\u672f\u77e5\u8bc6\u5c42\u9762\u8868\u73b0\u5c1a\u672a\u88ab\u5145\u5206\u8bc4\u4f30\u548c\u6539\u8fdb\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86CTFKnow\u57fa\u51c6\u96c6\uff083992\u9053\u95ee\u9898\uff09\uff0c\u4e13\u6ce8\u8bc4\u4f30LLM\u5728CTF\u6280\u672f\u77e5\u8bc6\u65b9\u9762\u7684\u638c\u63e1\u548c\u5e94\u7528\u80fd\u529b\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86\u65b0\u6846\u67b6CTFAgent\uff0c\u5305\u62ec\u53cc\u9636\u6bb5\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6a21\u5757\u548c\u4ea4\u4e92\u5f0f\u73af\u5883\u589e\u5f3a\u6a21\u5757\uff0c\u5206\u522b\u63d0\u5347\u6280\u672f\u77e5\u8bc6\u83b7\u53d6\u548cCTF\u6f0f\u6d1e\u5229\u7528\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2aCTF\u6570\u636e\u96c6\u53ca\u8d5b\u4e8b\u4e2d\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eLLM\u5f53\u524d\u867d\u5177\u5907\u4e00\u5b9a\u6280\u672f\u77e5\u8bc6\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u548c\u573a\u666f\u81ea\u9002\u5e94\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002\u6240\u63d0\u51fa\u7684CTFAgent\u6846\u67b6\uff0c\u5728\u4e24\u4e2a\u6d41\u884cCTF\u6570\u636e\u96c6\u4e0a\u5e26\u6765\u8d85\u8fc780%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5728picoCTF2024\u6bd4\u8d5b\u4e2d\u8fdb\u5165\u524d23.6%\u3002", "conclusion": "\u672c\u5de5\u4f5c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u5957\u7ec6\u7c92\u5ea6CTF\u77e5\u8bc6\u6d4b\u8bc4\u4f53\u7cfb\u53ca\u9488\u5bf9\u6027\u6846\u67b6\uff0c\u6709\u6548\u53d1\u73b0\u5e76\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728CTF\u81ea\u52a8\u89e3\u9898\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\uff0c\u4e3a\u672a\u6765AI\u81ea\u52a8\u653b\u9632\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u548c\u6709\u529b\u652f\u6491\u3002"}}
{"id": "2506.17510", "categories": ["cs.CY", "cs.DC", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2506.17510", "abs": "https://arxiv.org/abs/2506.17510", "authors": ["Rafael Ferreira da Silva", "Milad Abolhasani", "Dionysios A. Antonopoulos", "Laura Biven", "Ryan Coffee", "Ian T. Foster", "Leslie Hamilton", "Shantenu Jha", "Theresa Mayer", "Benjamin Mintz", "Robert G. Moore", "Salahudin Nimer", "Noah Paulson", "Woong Shin", "Frederic Suter", "Mitra Taheri", "Michela Taufer", "Newell R. Washburn"], "title": "A Grassroots Network and Community Roadmap for Interconnected Autonomous Science Laboratories for Accelerated Discovery", "comment": null, "summary": "Scientific discovery is being revolutionized by AI and autonomous systems,\nyet current autonomous laboratories remain isolated islands unable to\ncollaborate across institutions. We present the Autonomous Interconnected\nScience Lab Ecosystem (AISLE), a grassroots network transforming fragmented\ncapabilities into a unified system that shorten the path from ideation to\ninnovation to impact and accelerates discovery from decades to months. AISLE\naddresses five critical dimensions: (1) cross-institutional equipment\norchestration, (2) intelligent data management with FAIR compliance, (3)\nAI-agent driven orchestration grounded in scientific principles, (4)\ninteroperable agent communication interfaces, and (5) AI/ML-integrated\nscientific education. By connecting autonomous agents across institutional\nboundaries, autonomous science can unlock research spaces inaccessible to\ntraditional approaches while democratizing cutting-edge technologies. This\nparadigm shift toward collaborative autonomous science promises breakthroughs\nin sustainable energy, materials development, and public health.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAISLE\u751f\u6001\u7cfb\u7edf\uff0c\u6253\u7834\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u5b64\u5c9b\uff0c\u63a8\u52a8\u8de8\u673a\u6784\u534f\u4f5c\u548c\u6570\u636e\u5171\u4eab\uff0c\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\uff0c\u5e76\u62d3\u5bbd\u7814\u7a76\u4e0e\u6280\u672f\u5e94\u7528\u8fb9\u754c\u3002", "motivation": "\u76ee\u524d\u7684\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u5728AI\u548c\u81ea\u52a8\u5316\u63a8\u52a8\u4e0b\u5df2\u6709\u5de8\u5927\u8fdb\u5c55\uff0c\u4f46\u4e0d\u540c\u673a\u6784\u4e4b\u95f4\u4ecd\u7f3a\u4e4f\u6709\u6548\u534f\u4f5c\uff0c\u5bfc\u81f4\u80fd\u529b\u788e\u7247\u5316\uff0c\u5f71\u54cd\u79d1\u5b66\u521b\u65b0\u901f\u5ea6\u548c\u5f71\u54cd\u529b\u3002", "method": "\u63d0\u51fa\u4e86AISLE\uff08Autonomous Interconnected Science Lab Ecosystem\uff09\uff0c\u5b9e\u73b0\u8de8\u673a\u6784\u5b9e\u9a8c\u8bbe\u5907\u7f16\u6392\u3001\u667a\u80fd\u6570\u636e\u7ba1\u7406\uff08FAIR\u5408\u89c4\uff09\u3001\u57fa\u4e8e\u79d1\u5b66\u539f\u7406\u7684AI\u7f16\u6392\u3001\u53ef\u4e92\u64cd\u4f5c\u7684\u667a\u80fd\u4f53\u901a\u4fe1\u63a5\u53e3\u4ee5\u53ca\u878d\u5408AI/ML\u7684\u79d1\u5b66\u6559\u80b2\u3002\u901a\u8fc7\u4e92\u8fde\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u8de8\u673a\u6784\u534f\u540c\u521b\u65b0\u3002", "result": "AISLE\u80fd\u591f\u6253\u7834\u4f20\u7edf\u5b64\u5c9b\u6a21\u5f0f\uff0c\u5b9e\u73b0\u4ece\u60f3\u6cd5\u5230\u521b\u65b0\u518d\u5230\u6210\u679c\u7684\u5468\u671f\u7f29\u77ed\uff0c\u4ece\u800c\u660e\u663e\u52a0\u5feb\u79d1\u5b66\u53d1\u73b0\u8fdb\u7a0b\u3002\u8fde\u63a5\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u53ef\u62d3\u5c55\u7814\u7a76\u9886\u57df\u8303\u56f4\u5e76\u4fc3\u8fdb\u6280\u672f\u666e\u53ca\u3002", "conclusion": "AISLE\u4ee3\u8868\u4e86\u81ea\u4e3b\u79d1\u5b66\u7814\u7a76\u8f6c\u5411\u534f\u4f5c\u65b0\u8303\u5f0f\uff0c\u6709\u671b\u5728\u53ef\u6301\u7eed\u80fd\u6e90\u3001\u6750\u6599\u5f00\u53d1\u548c\u516c\u5171\u5065\u5eb7\u9886\u57df\u5e26\u6765\u7a81\u7834\u3002"}}
{"id": "2506.18565", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.18565", "abs": "https://arxiv.org/abs/2506.18565", "authors": ["Zhongya Lin", "Jinshuai Bai", "Shuang Li", "Xindong Chen", "Bo Li", "Xi-Qiao Feng"], "title": "A Physics-Informed Neural Network Framework for Simulating Creep Buckling in Growing Viscoelastic Biological Tissues", "comment": null, "summary": "Modeling viscoelastic behavior is crucial in engineering and biomechanics,\nwhere materials undergo time-dependent deformations, including stress\nrelaxation, creep buckling and biological tissue development. Traditional\nnumerical methods, like the finite element method, often require explicit\nmeshing, artificial perturbations or embedding customised programs to capture\nthese phenomena, adding computational complexity. In this study, we develop an\nenergy-based physics-informed neural network (PINN) framework using an\nincremental approach to model viscoelastic creep, stress relaxation, buckling,\nand growth-induced morphogenesis. Physics consistency is ensured by training\nneural networks to minimize the systems potential energy functional, implicitly\nsatisfying equilibrium and constitutive laws. We demonstrate that this\nframework can naturally capture creep buckling without pre-imposed\nimperfections, leveraging inherent training dynamics to trigger instabilities.\nFurthermore, we extend our framework to biological tissue growth and\nmorphogenesis, predicting both uniform expansion and differential\ngrowth-induced buckling in cylindrical structures. Results show that the\nenergy-based PINN effectively predicts viscoelastic instabilities,\npost-buckling evolution and tissue morphological evolution, offering a\npromising alternative to traditional methods. This study demonstrates that PINN\ncan be a flexible robust tool for modeling complex, time-dependent material\nbehavior, opening possible applications in structural engineering, soft\nmaterials, and tissue development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u91cf\u9a71\u52a8\u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINN\uff09\u65b0\u65b9\u6cd5\uff0c\u6709\u6548\u3001\u81ea\u52a8\u5730\u6a21\u62df\u9ecf\u5f39\u6027\u6750\u6599\u7684\u65f6\u53d8\u884c\u4e3a\uff08\u5982\u5c48\u66f2\u3001\u5e94\u529b\u677e\u5f1b\u548c\u751f\u7269\u7ec4\u7ec7\u751f\u957f\uff09\uff0c\u4e3a\u4f20\u7edf\u6709\u9650\u5143\u63d0\u4f9b\u4e86\u9ad8\u6548\u66ff\u4ee3\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u65e0\u9700\u9884\u8bbe\u7f3a\u9677\u7684\u5c48\u66f2\u548c\u590d\u6742\u7ec4\u7ec7\u5f62\u8c8c\u6f14\u5316\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7814\u7a76\u6750\u6599\u7684\u9ecf\u5f39\u6027\u884c\u4e3a\u591a\u4f9d\u8d56\u4e8e\u6709\u9650\u5143\u7b49\u6570\u503c\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5e38\u5e38\u9700\u8981\u663e\u5f0f\u5efa\u6a21\u3001\u4eba\u5de5\u6270\u52a8\u6216\u81ea\u5b9a\u4e49\u4ee3\u7801\uff0c\u5bfc\u81f4\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002\u800c\u9ecf\u5f39\u6027\u884c\u4e3a\u5e7f\u6cdb\u5b58\u5728\u4e8e\u5de5\u7a0b\u548c\u751f\u7269\u529b\u5b66\u4e2d\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u81ea\u52a8\u5316\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u80fd\u91cf\u51fd\u6570\u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINN\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u7cfb\u7edf\u7684\u52bf\u80fd\u6cdb\u51fd\u6765\u4fdd\u8bc1\u7269\u7406\u4e00\u81f4\u6027\uff0c\u5e76\u91c7\u7528\u589e\u91cf\u6cd5\u6a21\u62df\u9ecf\u5f39\u6027\u8815\u53d8\u3001\u5e94\u529b\u677e\u5f1b\u3001\u5c48\u66f2\u53ca\u751f\u7269\u7ec4\u7ec7\u751f\u957f\u5f62\u53d8\u3002\u7f51\u7edc\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7cfb\u7edf\u53ef\u81ea\u53d1\u4ea7\u751f\u4e0d\u7a33\u5b9a\u6027\uff0c\u65e0\u9700\u4eba\u5de5\u9884\u7f6e\u7f3a\u9677\u3002", "result": "\u8be5PINN\u6846\u67b6\u80fd\u591f\u81ea\u7136\u6355\u6349\u6750\u6599\u7684\u8815\u53d8\u5c48\u66f2\u3001\u540e\u5c48\u66f2\u884c\u4e3a\u3001\u751f\u7269\u7ec4\u7ec7\u7684\u5f62\u6001\u53d8\u5316\u3002\u540c\u6837\u53ef\u51c6\u786e\u9884\u6d4b\u5706\u67f1\u7ed3\u6784\u4e0b\u5747\u5300\u81a8\u80c0\u4e0e\u5dee\u5f02\u751f\u957f\u5bfc\u81f4\u7684\u5c48\u66f2\u73b0\u8c61\u3002\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u80dc\u4efb\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u590d\u6742\u5904\u7406\u7684\u65f6\u95f4\u76f8\u5173\u6750\u6599\u884c\u4e3a\u5efa\u6a21\u4efb\u52a1\u3002", "conclusion": "\u80fd\u91cf\u578bPINN\u53ef\u4f5c\u4e3a\u5efa\u6a21\u590d\u6742\u3001\u65f6\u53d8\u6750\u6599\u884c\u4e3a\u7684\u7075\u6d3b\u4e14\u7a33\u5065\u5de5\u5177\uff0c\u5728\u7ed3\u6784\u5de5\u7a0b\u3001\u8f6f\u6750\u6599\u53ca\u7ec4\u7ec7\u751f\u957f\u7814\u7a76\u4e2d\u5177\u6709\u5e7f\u9614\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.17419", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.17419", "abs": "https://arxiv.org/abs/2506.17419", "authors": ["Jinhao Duan", "James Diffenderfer", "Sandeep Madireddy", "Tianlong Chen", "Bhavya Kailkhura", "Kaidi Xu"], "title": "UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making", "comment": "19 pages, 5 figures, 4 tables", "summary": "As Large Language Models (LLMs) are integrated into safety-critical\napplications involving sequential decision-making in the real world, it is\nessential to know when to trust LLM decisions. Existing LLM Uncertainty\nQuantification (UQ) methods are primarily designed for single-turn\nquestion-answering formats, resulting in multi-step decision-making scenarios,\ne.g., LLM agentic system, being underexplored. In this paper, we introduce a\nprincipled, information-theoretic framework that decomposes LLM sequential\ndecision uncertainty into two parts: (i) internal uncertainty intrinsic to the\ncurrent decision, which is focused on existing UQ methods, and (ii) extrinsic\nuncertainty, a Mutual-Information (MI) quantity describing how much uncertainty\nshould be inherited from preceding decisions. We then propose UProp, an\nefficient and effective extrinsic uncertainty estimator that converts the\ndirect estimation of MI to the estimation of Pointwise Mutual Information (PMI)\nover multiple Trajectory-Dependent Decision Processes (TDPs). UProp is\nevaluated over extensive multi-step decision-making benchmarks, e.g.,\nAgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and\nDeepSeek-V3. Experimental results demonstrate that UProp significantly\noutperforms existing single-turn UQ baselines equipped with thoughtful\naggregation strategies. Moreover, we provide a comprehensive analysis of UProp,\nincluding sampling efficiency, potential applications, and intermediate\nuncertainty propagation, to demonstrate its effectiveness. Codes will be\navailable at https://github.com/jinhaoduan/UProp.", "AI": {"tldr": "\u672c\u6587\u4e3aLLM\u591a\u6b65\u51b3\u7b56\u573a\u666f\u4e0b\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u51fa\u4fe1\u606f\u8bba\u5206\u89e3\u6846\u67b6\uff0c\u5e76\u8bbe\u8ba1\u51fa\u6709\u6548\u5b9e\u7528\u7684UProp\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u660e\u663e\u80dc\u51fa\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "LLM\u88ab\u5e94\u7528\u4e8e\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u7684\u5e8f\u5217\u51b3\u7b56\u4efb\u52a1\u65f6\uff0c\u4f55\u65f6\u5e94\u8be5\u4fe1\u4efbLLM\u7684\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u4e3b\u8981\u9002\u7528\u4e8e\u5355\u8f6e\u95ee\u7b54\uff0c\u7f3a\u4e4f\u5bf9\u591a\u6b65\u51b3\u7b56\u573a\u666f\u7684\u523b\u753b\u4e0e\u5e94\u5bf9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u5c06LLM\u5728\u5e8f\u5217\u51b3\u7b56\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u4e3a\u5185\u90e8\u4e0d\u786e\u5b9a\u6027\u548c\u5916\u90e8\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5f15\u5165UProp\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f30\u8ba1\u4e0d\u540c\u8f68\u8ff9\u4e0b\u7684\u70b9\u5bf9\u4e92\u4fe1\u606f\uff08PMI\uff09\u6765\u9ad8\u6548\u8861\u91cf\u5916\u90e8\u4e0d\u786e\u5b9a\u6027\u3002\u5b9e\u9a8c\u5728AgentBench\u3001HotpotQA\u7b49\u591a\u6b65\u51b3\u7b56\u57fa\u51c6\u4ee5\u53ca\u5982GPT-4.1\u7b49SOTA\u5927\u6a21\u578b\u4e0a\u8fdb\u884c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cUProp\u5728\u591a\u6b65\u51b3\u7b56\u8bc4\u6d4b\u4e2d\u663e\u8457\u4f18\u4e8e\u5e26\u6709\u805a\u5408\u7b56\u7565\u7684\u4e3b\u6d41UQ\u65b9\u6cd5\uff0c\u5e76\u5c55\u73b0\u4e86\u6781\u4f73\u7684\u91c7\u6837\u6548\u7387\u548c\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "UProp\u65b9\u6cd5\u5728\u591a\u6b65\u51b3\u7b56\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5355\u8f6eUQ\u57fa\u7ebf\uff0c\u5e76\u901a\u8fc7\u5168\u9762\u5206\u6790\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u6027\u4e0e\u6709\u6548\u6027\u3002"}}
{"id": "2506.17667", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17667", "abs": "https://arxiv.org/abs/2506.17667", "authors": ["Lintao Wang", "Encheng Su", "Jiaqi Liu", "Pengze Li", "Peng Xia", "Jiabei Xiao", "Wenlong Zhang", "Xinnan Dai", "Xi Chen", "Yuan Meng", "Mingyu Ding", "Lei Bai", "Wanli Ouyang", "Shixiang Tang", "Aoran Wang", "Xinzhu Ma"], "title": "PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models", "comment": null, "summary": "Physics problem-solving is a challenging domain for large AI models,\nrequiring integration of conceptual understanding, mathematical reasoning, and\ninterpretation of physical diagrams. Current evaluation methodologies show\nnotable limitations in capturing the breadth and complexity of\nundergraduate-level physics, underscoring the need for more rigorous\nassessments. To this end, we present PhysUniBench, a large-scale multimodal\nbenchmark designed to evaluate and improve the reasoning capabilities of\nmultimodal large language models (MLLMs) specifically on undergraduate-level\nphysics problems. PhysUniBench consists of 3,304 physics questions spanning 8\nmajor sub-disciplines of physics, each accompanied by one visual diagrams. The\nbenchmark includes both open-ended and multiple-choice questions,\nsystematically curated and difficulty-rated through an iterative\nmodel-in-the-loop process. The benchmark's construction involved a rigorous\nmulti-stage process, including multiple roll-outs, expert-level evaluation,\nautomated filtering of easily solved problems, and a nuanced difficulty grading\nsystem with five levels. Through extensive experiments, we observe that current\nstate-of-the-art models encounter substantial challenges in physics reasoning.\nFor example, GPT-4o mini achieves only about 34.2\\% accuracy in the proposed\nPhysUniBench. These results highlight that current MLLMs struggle with advanced\nphysics reasoning, especially on multi-step problems and those requiring\nprecise diagram interpretation. By providing a broad and rigorous assessment\ntool, PhysUniBench aims to drive progress in AI for Science, encouraging the\ndevelopment of models with stronger physical reasoning, problem-solving skills,\nand multimodal understanding. The benchmark and evaluation scripts are\navailable at https://prismax-team.github.io/PhysUniBenchmark/.", "AI": {"tldr": "\u63d0\u51fa\u4e86PhysUniBench\u5927\u578b\u591a\u6a21\u6001\u5927\u5b66\u7269\u7406\u57fa\u51c6\uff0c\u7cfb\u7edf\u8bc4\u6d4b\u73b0\u6709AI\u6a21\u578b\u7269\u7406\u63a8\u7406\u4e0e\u591a\u6a21\u6001\u80fd\u529b\u3002\u7ed3\u679c\u663e\u793a\u5f53\u524d\u6a21\u578b\uff0c\u5c24\u5176\u662fGPT-4o mini\uff0c\u9762\u5bf9\u591a\u6b65\u9aa4\u548c\u9700\u89e3\u8bfb\u56fe\u793a\u7684\u7269\u7406\u9898\u65f6\u8868\u73b0\u8f83\u5dee\uff0c\u4ec5\u8fbe34%\u51c6\u786e\u7387\u3002\u8be5\u57fa\u51c6\u6709\u52a9\u4e8e\u63a8\u52a8AI\u79d1\u5b66\u95ee\u9898\u6c42\u89e3\u80fd\u529b\u7684\u8fdb\u6b65\u3002", "motivation": "\u73b0\u6709\u5927\u6a21\u578b\u5728\u7269\u7406\u95ee\u9898\u6c42\u89e3\u4e0a\u9762\u4e34\u5f88\u5927\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u6982\u5ff5\u7406\u89e3\u3001\u6570\u5b66\u63a8\u7406\u548c\u7269\u7406\u56fe\u793a\u89e3\u8bfb\u7684\u7efc\u5408\u80fd\u529b\u65b9\u9762\u3002\u5f53\u524d\u7684\u8bc4\u4ef7\u65b9\u6cd5\u65e0\u6cd5\u5168\u9762\u53cd\u6620\u5927\u5b66\u7269\u7406\u95ee\u9898\u7684\u590d\u6742\u6027\u548c\u5e7f\u5ea6\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86PhysUniBench\uff0c\u4e00\u4e2a\u9488\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3001\u4e13\u7528\u4e8e\u5927\u5b66\u7269\u7406\u9886\u57df\u95ee\u9898\u6c42\u89e3\u80fd\u529b\u8bc4\u4f30\u7684\u5927\u578b\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u96c6\u3002\u6570\u636e\u96c6\u6db5\u76d68\u4e2a\u4e3b\u6d41\u7269\u7406\u5b50\u9886\u57df\uff0c\u51713304\u9053\u9898\uff0c\u6bcf\u9898\u5747\u914d\u6709\u4e00\u5f20\u89c6\u89c9\u56fe\u793a\uff0c\u9898\u578b\u5305\u62ec\u5f00\u653e\u6027\u548c\u9009\u62e9\u9898\uff0c\u91c7\u7528\u4e13\u5bb6\u8bc4\u5ba1\u3001\u6a21\u578b\u5faa\u73af\u8fc7\u6ee4\u3001\u81ea\u52a8\u7b5b\u67e5\u7b80\u5355\u95ee\u9898\u3001\u96be\u5ea6\u5206\u7ea7\u7b49\u591a\u9636\u6bb5\u65b9\u5f0f\u6784\u5efa\u3002", "result": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u6a21\u578b\u5728\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\u5e76\u4e0d\u7406\u60f3\uff0c\u5982GPT-4o mini\u5728PhysUniBench\u4e0a\u7684\u51c6\u786e\u7387\u4ec5\u4e3a34.2%\u3002\u5c24\u5176\u662f\u5728\u591a\u6b65\u63a8\u7406\u53ca\u7cbe\u51c6\u56fe\u793a\u7406\u89e3\u7b49\u9898\u76ee\u4e0a\u8868\u73b0\u7a81\u51fa\u4e0d\u8db3\u3002", "conclusion": "PhysUniBench\u5c55\u73b0\u4e86\u73b0\u6709\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u9ad8\u7ea7\u7269\u7406\u63a8\u7406\u548c\u591a\u6a21\u6001\u7406\u89e3\u4e0a\u7684\u4e0d\u8db3\uff0c\u662f\u63a8\u52a8AI\u79d1\u5b66\u548c\u7269\u7406\u63a8\u7406\u80fd\u529b\u63d0\u5347\u7684\u91cd\u8981\u5de5\u5177\u3002\u8be5\u57fa\u51c6\u548c\u8bc4\u6d4b\u811a\u672c\u5df2\u5f00\u653e\uff0c\u65e8\u5728\u4fc3\u8fdb\u5177\u66f4\u5f3a\u7269\u7406\u63a8\u7406\u548c\u591a\u6a21\u6001\u7406\u89e3\u80fd\u529b\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.17513", "categories": ["cs.CY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.17513", "abs": "https://arxiv.org/abs/2506.17513", "authors": ["Rudra Y. Bedekar"], "title": "Public Perceptions of Autonomous Vehicles: A Survey of Pedestrians and Cyclists in Pittsburgh", "comment": null, "summary": "This study investigates how autonomous vehicle(AV) technology is perceived by\npedestrians and bicyclists in Pittsburgh. Using survey data from over 1200\nrespondents, the research explores the interplay between demographics, AV\ninteractions, infrastructural readiness, safety perceptions, and trust.\nFindings highlight demographic divides, infrastructure gaps, and the crucial\nrole of communication and education in AV adoption.", "AI": {"tldr": "\u901a\u8fc7\u5339\u5179\u58211200\u4f59\u4efd\u95ee\u5377\u5206\u6790\uff0c\u53d1\u73b0\u4eba\u53e3\u7279\u5f81\u3001\u57fa\u7840\u8bbe\u65bd\u53ca\u6c9f\u901a\u6559\u80b2\u5bf9\u884c\u4eba\u548c\u9a91\u884c\u8005\u5bf9\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u7684\u6001\u5ea6\u548c\u4fe1\u4efb\u5ea6\u5f71\u54cd\u663e\u8457\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff08AV\uff09\u9010\u6e10\u8fdb\u5165\u73b0\u5b9e\u751f\u6d3b\uff0c\u4e86\u89e3\u884c\u4eba\u548c\u9a91\u884c\u8005\u7684\u6001\u5ea6\u5bf9\u4e8e\u5176\u63a8\u5e7f\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u4e0d\u540c\u7fa4\u4f53\u5982\u4f55\u770b\u5f85AV\uff0c\u5e76\u5206\u6790\u4ed6\u4eec\u7684\u4fe1\u4efb\u4e0e\u5b89\u5168\u611f\u3002", "method": "\u91c7\u7528\u95ee\u5377\u8c03\u67e5\u65b9\u6cd5\uff0c\u6536\u96c6\u4e861200\u591a\u4f4d\u5339\u5179\u5821\u884c\u4eba\u548c\u81ea\u884c\u8f66\u9a91\u884c\u8005\u7684\u6570\u636e\uff0c\u5bf9\u5176\u4e0eAV\u6280\u672f\u7684\u4e92\u52a8\u4f53\u9a8c\u3001\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u3001\u57fa\u7840\u8bbe\u65bd\u51c6\u5907\u5ea6\u3001\u5b89\u5168\u611f\u77e5\u548c\u4fe1\u4efb\u8fdb\u884c\u4e86\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u5bf9\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u7684\u63a5\u53d7\u7a0b\u5ea6\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5f53\u524d\u57fa\u7840\u8bbe\u65bd\u5b58\u5728\u4e0d\u8db3\uff0c\u8fd9\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u5f71\u54cd\u4e86\u4f7f\u7528\u8005\u7684\u5b89\u5168\u611f\u548c\u4fe1\u4efb\u5ea6\u3002\u6c9f\u901a\u548c\u76f8\u5173\u77e5\u8bc6\u666e\u53ca\u80fd\u591f\u6709\u6548\u4fc3\u8fdb\u793e\u4f1a\u5bf9AV\u7684\u63a5\u53d7\u3002", "conclusion": "\u63a8\u52a8\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u843d\u5730\u4e0d\u4ec5\u9700\u8981\u6280\u672f\u8fdb\u6b65\uff0c\u8fd8\u5fc5\u987b\u91cd\u89c6\u884c\u4eba\u4e0e\u9a91\u884c\u8005\u7684\u8eab\u4efd\u5dee\u5f02\u548c\u611f\u53d7\uff0c\u901a\u8fc7\u6539\u5584\u57fa\u7840\u8bbe\u65bd\u53ca\u5f3a\u5316\u5ba3\u4f20\u6559\u80b2\u6765\u63d0\u5347\u516c\u4f17\u4fe1\u4efb\u4e0e\u5b89\u5168\u611f\u3002"}}
{"id": "2506.18572", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.18572", "abs": "https://arxiv.org/abs/2506.18572", "authors": ["Peter Frank", "Falk Dettinger", "Daniel Dittler", "Pascal H\u00e4big", "Nasser Jazdi", "Kai Hufendiek", "Michael Weyrich"], "title": "Communication Architecture for Autonomous Power-to-X Platforms: Enhancing Inspection and Operation With Legged Robots and 5G", "comment": null, "summary": "Inspection and maintenance of offshore platforms are associated with high\ncosts, primarily due to the significant personnel requirements and challenging\noperational conditions. This paper first presents a classification of Power to\nX platforms. Building upon this foundation, a communication architecture is\nproposed to enable monitoring, control, and teleoperation for a Power to X\nplatform. To reduce the demand for human labor, a robotic system is integrated\nto autonomously perform inspection and maintenance tasks. The implementation\nutilizes a quadruped robot. Remote monitoring, control, and teleoperation of\nthe robot are analyzed within the context of a 5G standalone network. As part\nof the evaluation, aspects such as availability and latency are recorded,\ncompared, and critically assessed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u79cd\u57fa\u4e8e5G\u7684\u56db\u8db3\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u80fd\u591f\u66ff\u4ee3\u4eba\u5de5\u5bf9Power to X\u79bb\u5cb8\u5e73\u53f0\u8fdb\u884c\u8fdc\u7a0b\u76d1\u63a7\u548c\u7ef4\u62a4\uff0c\u5e76\u5bf9\u5176\u901a\u4fe1\u6027\u80fd\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u8bc1\u660e\u8be5\u65b9\u6848\u53ef\u884c\uff0c\u80fd\u663e\u8457\u51cf\u8f7b\u8fd0\u7ef4\u538b\u529b\u3002", "motivation": "\u79bb\u5cb8\u5e73\u53f0\u7684\u68c0\u67e5\u4e0e\u7ef4\u62a4\u53d7\u5230\u9ad8\u4eba\u529b\u9700\u6c42\u548c\u64cd\u4f5c\u73af\u5883\u8270\u96be\u7684\u5236\u7ea6\uff0c\u6210\u672c\u5f88\u9ad8\uff0c\u6025\u9700\u964d\u4f4e\u4eba\u5de5\u5e72\u9884\u5e76\u63d0\u9ad8\u4f5c\u4e1a\u6548\u7387\u3002", "method": "\u672c\u6587\u9996\u5148\u5bf9Power to X\u5e73\u53f0\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u6784\u5efa\u901a\u4fe1\u67b6\u6784\uff0c\u5b9e\u73b0\u5bf9\u5e73\u53f0\u7684\u76d1\u63a7\u3001\u63a7\u5236\u4e0e\u8fdc\u7a0b\u64cd\u4f5c\u3002\u96c6\u6210\u56db\u8db3\u673a\u5668\u4eba\u4ee5\u81ea\u52a8\u5b8c\u6210\u68c0\u67e5\u4e0e\u7ef4\u62a4\u4efb\u52a1\uff0c\u5e76\u57285G\u72ec\u7acb\u7ec4\u7f51\u73af\u5883\u4e0b\u8fdc\u7a0b\u76d1\u63a7\u3001\u63a7\u5236\u548c\u64cd\u4f5c\u673a\u5668\u4eba\uff0c\u540c\u65f6\u8bb0\u5f55\u5e76\u8bc4\u4f30\u901a\u4fe1\u7684\u53ef\u7528\u6027\u548c\u65f6\u5ef6\u7b49\u6307\u6807\u3002", "result": "\u6210\u529f\u96c6\u6210\u4e86\u56db\u8db3\u673a\u5668\u4eba\uff0c\u5b9e\u73b0\u4e86\u57285G\u7f51\u7edc\u4e0b\u5bf9\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u8fdc\u7a0b\u76d1\u63a7\u3001\u63a7\u5236\u53ca\u64cd\u4f5c\uff1b\u5e76\u5bf9\u901a\u4fe1\u67b6\u6784\u7684\u53ef\u7528\u6027\u4e0e\u65f6\u5ef6\u8fdb\u884c\u4e86\u5bf9\u6bd4\u4e0e\u8bc4\u4f30\u3002", "conclusion": "\u901a\u8fc7\u642d\u5efa\u57fa\u4e8e5G\u901a\u4fe1\u67b6\u6784\u7684\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u53ef\u4ee5\u6709\u6548\u964d\u4f4e\u79bb\u5cb8\u5e73\u53f0\u7684\u4eba\u529b\u9700\u6c42\uff0c\u63d0\u9ad8\u8fd0\u7ef4\u81ea\u52a8\u5316\u6c34\u5e73\uff0c\u5bf9\u9ad8\u6548\u5b89\u5168\u8fd0\u884c\u5177\u6709\u4fc3\u8fdb\u4f5c\u7528\u3002"}}
{"id": "2506.17435", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17435", "abs": "https://arxiv.org/abs/2506.17435", "authors": ["Alberto Martinez-Serra", "Alejandro De La Fuente", "Nienke Viescher", "Ana S. Cardenal"], "title": "Beyond the Link: Assessing LLMs' ability to Classify Political Content across Global Media", "comment": null, "summary": "The use of large language models (LLMs) is becoming common in the context of\npolitical science, particularly in studies that analyse individuals use of\ndigital media. However, while previous research has demonstrated LLMs ability\nat labelling tasks, the effectiveness of using LLMs to classify political\ncontent (PC) from just URLs is not yet well explored. The work presented in\nthis article bridges this gap by evaluating whether LLMs can accurately\nidentify PC vs. non-PC from both the article text and the URLs from five\ncountries (France, Germany, Spain, the UK, and the US) and different languages.\nUsing cutting-edge LLMs like GPT, Llama, Mistral, Deepseek, Qwen and Gemma, we\nmeasure model performance to assess whether URL-level analysis can be a good\napproximation for full-text analysis of PC, even across different linguistic\nand national contexts. Model outputs are compared with human-labelled articles,\nas well as traditional supervised machine learning techniques, to set a\nbaseline of performance. Overall, our findings suggest the capacity of URLs to\nembed most of the news content, providing a vital perspective on accuracy-cost\nbalancing. We also account for contextual limitations and suggest\nmethodological recommendations to use LLMs within political science studies.", "AI": {"tldr": "\u8be5\u6587\u9a8c\u8bc1\u4e86\u591a\u79cdLLM\u6a21\u578b\u7528\u4ec5URL\u5373\u53ef\u6709\u6548\u8bc6\u522b\u591a\u56fd\u591a\u8bed\u6587\u7ae0\u7684\u653f\u6cbb\u5185\u5bb9\uff0cURL\u5206\u6790\u53ef\u90e8\u5206\u66ff\u4ee3\u5168\u6587\uff0c\u5728\u7cbe\u5ea6\u4e0e\u6210\u672c\u95f4\u8fbe\u6210\u5e73\u8861\uff0c\u5e76\u4e3a\u653f\u6cbb\u5b66\u7814\u7a76\u65b9\u6cd5\u63d0\u4f9b\u5efa\u8bae\u3002", "motivation": "\u76ee\u524dLLMs\u5728\u653f\u6cbb\u79d1\u5b66\u9886\u57df\u88ab\u5e7f\u6cdb\u7528\u4e8e\u6570\u5b57\u5a92\u4f53\u5185\u5bb9\u5206\u6790\uff0c\u4f46\u4ec5\u901a\u8fc7URL\u8bc6\u522b\u653f\u6cbb\u5185\u5bb9\u7684\u6709\u6548\u6027\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u8be5\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1LLMs\u80fd\u5426\u57fa\u4e8eURL\u800c\u975e\u5168\u6587\u9ad8\u6548\u8fa8\u8bc6\u653f\u6cbb\u5185\u5bb9\uff0c\u4ece\u800c\u964d\u4f4e\u5206\u6790\u6210\u672c\u3002", "method": "\u5bf9\u6cd5\u56fd\u3001\u5fb7\u56fd\u3001\u897f\u73ed\u7259\u3001\u82f1\u56fd\u548c\u7f8e\u56fd\u7b49\u4e94\u56fd\u4e0d\u540c\u8bed\u8a00\u7684\u6587\u7ae0\uff0c\u5229\u7528\u591a\u79cd\u6700\u65b0LLMs\u6a21\u578b\uff08\u5982GPT\u3001Llama\u7b49\uff09\u8fdb\u884c\u653f\u6cbb\u5185\u5bb9\u8bc6\u522b\uff0c\u5206\u522b\u7528\u6587\u7ae0\u5168\u6587\u548c\u4ec5\u7528URL\u8fdb\u884c\uff0c\u8f93\u51fa\u7ed3\u679c\u4e0e\u4eba\u5de5\u6807\u6ce8\u53ca\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "LLMs\u5728\u4ec5\u7528URL\u5bf9\u65b0\u95fb\u5185\u5bb9\u8fdb\u884c\u653f\u6cbb\u5185\u5bb9\u5206\u7c7b\u65f6\u8868\u73b0\u4f18\u5f02\uff0cURL\u5305\u542b\u4e86\u5927\u90e8\u5206\u91cd\u8981\u6307\u5f81\uff0c\u80fd\u591f\u5f88\u597d\u5730\u66ff\u4ee3\u90e8\u5206\u5168\u6587\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5173\u65b9\u6cd5\u5efa\u8bae\u3002", "conclusion": "LLMs\u80fd\u591f\u901a\u8fc7\u5206\u6790\u6587\u7ae0URL\u51c6\u786e\u8bc6\u522b\u653f\u6cbb\u5185\u5bb9\uff0c\u4e14\u5728\u591a\u8bed\u79cd\u3001\u591a\u56fd\u5bb6\u60c5\u5883\u4e0b\u8868\u73b0\u826f\u597d\u3002URL\u5206\u6790\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u53ef\u8fd1\u4f3c\u5168\u6587\u5206\u6790\uff0c\u5e76\u5728\u51c6\u786e\u6027\u548c\u6210\u672c\u4e4b\u95f4\u63d0\u4f9b\u5e73\u8861\u3002"}}
{"id": "2506.17697", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17697", "abs": "https://arxiv.org/abs/2506.17697", "authors": ["Bohan Tang", "Dezhao Luo", "Jingxuan Chen", "Shaogang Gong", "Jianye Hao", "Jun Wang", "Kun Shao"], "title": "Beyond Syntax: Action Semantics Learning for App Agents", "comment": null, "summary": "The advent of Large Language Models (LLMs) enables the rise of App agents\nthat interpret user intent and operate smartphone Apps through actions such as\nclicking and scrolling. While prompt-based solutions with closed LLM APIs show\npromising ability, they incur heavy compute costs and external API dependency.\nFine-tuning smaller open-source LLMs solves these limitations. However, current\nfine-tuning methods use a syntax learning paradigm that forces agents to\nreproduce exactly the ground truth action strings, leading to\nout-of-distribution (OOD) vulnerability. To fill this gap, we propose Action\nSemantics Learning (ASL), a novel learning framework, where the learning\nobjective is capturing the semantics of the ground truth actions. Specifically,\ninspired by the programming language theory, we define the action semantics for\nApp agents as the state transition induced by the action in the user interface.\nWith this insight, ASL employs a novel SEmantic Estimator (SEE) to compute a\nsemantic reward to train the App agents in generating actions aligned with the\nsemantics of ground truth actions, even when the syntactic forms differ. To\nsupport the effectiveness of ASL, we theoretically demonstrate the superior\nrobustness of ASL for the OOD problem compared with the existing syntax\nlearning paradigm. Extensive experiments on offline and online smartphone App\noperation benchmarks show that ASL significantly improves the accuracy and\ngeneralisation of App agents over existing methods.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u4e86\u52a8\u4f5c\u8bed\u4e49\u5b66\u4e60\uff08ASL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u5956\u52b1\u8bad\u7ec3\u65b9\u6cd5\uff0c\u589e\u5f3a\u4e86App\u667a\u80fd\u4f53\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u8bed\u6cd5\u5b66\u4e60\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u76ee\u524d\u667a\u80fd\u4f53\u64cd\u4f5c\u624b\u673aApp\u591a\u4f9d\u8d56\u4e8e\u5c01\u95ed\u5f0f\u5927\u6a21\u578bAPI\uff0c\u8ba1\u7b97\u5f00\u9500\u5927\u4e14\u4f9d\u8d56\u5916\u90e8\u63a5\u53e3\u3002\u5f00\u6e90\u5c0f\u6a21\u578b\u5fae\u8c03\u53c8\u5bb9\u6613\u51fa\u73b0\u6a21\u578b\u5bf9\u8bed\u6cd5\u8fc7\u5ea6\u62df\u5408\uff0c\u5bfc\u81f4\u6cdb\u5316\u6027\u5dee\uff08\u5c24\u5176\u5728\u5206\u5e03\u5916\u7684\u6570\u636e\u4e0a\u6613\u5931\u6548\uff09\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u5065\u58ee\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u52a8\u4f5c\u8bed\u4e49\u5b66\u4e60\uff08ASL\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3App\u667a\u80fd\u4f53\u3002\u5176\u6838\u5fc3\u65b9\u6cd5\u662f\u57fa\u4e8e\u7a0b\u5e8f\u8bed\u8a00\u7406\u8bba\uff0c\u5c06\u52a8\u4f5c\u8bed\u4e49\u5b9a\u4e49\u4e3a\u5728UI\u4e2d\u8bf1\u53d1\u7684\u72b6\u6001\u8f6c\u79fb\uff0c\u4f7f\u7528\u4e00\u4e2a\u65b0\u7684\u8bed\u4e49\u8bc4\u4f30\u5668\uff08SEE\uff09\u4e3a\u667a\u80fd\u4f53\u751f\u6210\u7684\u52a8\u4f5c\u5206\u914d\u8bed\u4e49\u5956\u52b1\uff0c\u4ece\u800c\u63a8\u52a8\u6a21\u578b\u5b66\u4e60\u5bf9\u8bed\u4e49\u5bf9\u9f50\u800c\u975e\u8bed\u6cd5\u4e00\u81f4\u7684\u52a8\u4f5c\u3002", "result": "\u7406\u8bba\u8bc1\u660eASL\u5728\u5206\u5e03\u5916\uff08OOD\uff09\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u4f20\u7edf\u8bed\u6cd5\u5b66\u4e60\u65b9\u6cd5\uff1b\u5927\u91cf\u57fa\u4e8e\u624b\u673aApp\u64cd\u4f5c\u7684\u5b9e\u9a8c\uff08\u5305\u62ec\u79bb\u7ebf\u548c\u5728\u7ebf\u57fa\u51c6\u6d4b\u8bd5\uff09\u663e\u793a\uff0cASL\u5728\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ASL\u901a\u8fc7\u5f3a\u5316\u8bed\u4e49\u5bf9\u9f50\u800c\u4e0d\u662f\u7eaf\u7cb9\u7684\u8bed\u6cd5\u590d\u5236\uff0c\u63d0\u5347\u4e86App\u667a\u80fd\u4f53\u5728\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u8868\u73b0\uff0c\u662f\u64cd\u4f5cApp\u7684\u65b0\u4e00\u4ee3\u8bad\u7ec3\u8303\u5f0f\u3002"}}
{"id": "2506.17577", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17577", "abs": "https://arxiv.org/abs/2506.17577", "authors": ["Meng Xia", "Robin Schmucker", "Conrad Borchers", "Vincent Aleven"], "title": "Optimizing Mastery Learning by Fast-Forwarding Over-Practice Steps", "comment": "Full research paper accepted at EC-TEL 2025", "summary": "Mastery learning improves learning proficiency and efficiency. However, the\noverpractice of skills--students spending time on skills they have already\nmastered--remains a fundamental challenge for tutoring systems. Previous\nresearch has reduced overpractice through the development of better problem\nselection algorithms and the authoring of focused practice tasks. However, few\nefforts have concentrated on reducing overpractice through step-level\nadaptivity, which can avoid resource-intensive curriculum redesign. We propose\nand evaluate Fast-Forwarding as a technique that enhances existing problem\nselection algorithms. Based on simulation studies informed by learner models\nand problem-solving pathways derived from real student data, Fast-Forwarding\ncan reduce overpractice by up to one-third, as it does not require students to\ncomplete problem-solving steps if all remaining pathways are fully mastered.\nFast-Forwarding is a flexible method that enhances any problem selection\nalgorithm, though its effectiveness is highest for algorithms that\npreferentially select difficult problems. Therefore, our findings suggest that\nwhile Fast-Forwarding may improve student practice efficiency, the size of its\npractical impact may also depend on students' ability to stay motivated and\nengaged at higher levels of difficulty.", "AI": {"tldr": "\u63d0\u51faFast-Forwarding\u6280\u672f\uff0c\u7528\u4e8e\u51cf\u5c11\u638c\u63e1\u5f0f\u5b66\u4e60\u4e2d\u7684\u8fc7\u5ea6\u7ec3\u4e60\uff0c\u901a\u8fc7\u4eff\u771f\u6700\u9ad8\u53ef\u964d\u4f4e\u8fc7\u5ea6\u7ec3\u4e60\u4e09\u5206\u4e4b\u4e00\uff0c\u80fd\u96c6\u6210\u5230\u591a\u79cd\u9898\u76ee\u9009\u62e9\u7b97\u6cd5\u4e2d\uff0c\u5bf9\u9ad8\u96be\u5ea6\u9898\u76ee\u6210\u6548\u66f4\u597d\uff0c\u4f46\u6210\u6548\u4e0e\u5b66\u751f\u52a8\u529b\u76f8\u5173\u3002", "motivation": "\u638c\u63e1\u5f0f\u5b66\u4e60\u80fd\u63d0\u5347\u5b66\u4e60\u6548\u7387\uff0c\u4f46\u8fc7\u5ea6\u7ec3\u4e60\uff0c\u5373\u5b66\u751f\u5728\u5df2\u638c\u63e1\u6280\u80fd\u4e0a\u82b1\u8d39\u8fc7\u591a\u65f6\u95f4\uff0c\u6210\u4e3a\u6559\u5b66\u7cfb\u7edf\u7684\u6311\u6218\u3002\u4ee5\u5f80\u7814\u7a76\u591a\u901a\u8fc7\u4f18\u5316\u9898\u76ee\u9009\u62e9\u7b97\u6cd5\u548c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u7ec3\u4e60\u5185\u5bb9\u6765\u51cf\u5c11\u8fc7\u5ea6\u7ec3\u4e60\uff0c\u8f83\u5c11\u5173\u6ce8\u901a\u8fc7\u66f4\u7ec6\u7c92\u5ea6\u7684\u201c\u6b65\u9aa4\u7ea7\u81ea\u9002\u5e94\u201d\u6765\u5b9e\u73b0\u3002", "method": "\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u4e00\u79cd\u540d\u4e3aFast-Forwarding\u7684\u65b0\u6280\u672f\uff0c\u8be5\u6280\u672f\u53ef\u589e\u5f3a\u73b0\u6709\u9898\u76ee\u9009\u62e9\u7b97\u6cd5\u3002\u901a\u8fc7\u57fa\u4e8e\u771f\u5b9e\u5b66\u751f\u6570\u636e\u7684\u5b66\u4e60\u8005\u6a21\u578b\u4e0e\u89e3\u9898\u8def\u5f84\uff0c\u5229\u7528\u4eff\u771f\u7814\u7a76\u8003\u5bdf\u5176\u6548\u679c\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u5b66\u751f\u5df2\u5b8c\u5168\u638c\u63e1\u8def\u5f84\u7684\u60c5\u51b5\u4e0b\u8df3\u8fc7\u90e8\u5206\u6b65\u9aa4\uff0c\u51cf\u5c11\u65e0\u6548\u7ec3\u4e60\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cFast-Forwarding\u80fd\u5c06\u8fc7\u5ea6\u7ec3\u4e60\u51cf\u5c11\u81f3\u539f\u6765\u7684\u4e09\u5206\u4e4b\u4e8c\u3002\u5176\u672c\u8eab\u53ef\u4e0e\u4efb\u610f\u9898\u76ee\u9009\u62e9\u7b97\u6cd5\u7ed3\u5408\u4f7f\u7528\uff0c\u4f46\u5728\u504f\u597d\u9009\u62e9\u9ad8\u96be\u5ea6\u9898\u76ee\u7684\u7b97\u6cd5\u4e2d\u6548\u679c\u6700\u660e\u663e\u3002\u5b9e\u9645\u5f71\u54cd\u8fd8\u4f9d\u8d56\u4e8e\u5b66\u751f\u5728\u9ad8\u96be\u5ea6\u4efb\u52a1\u65f6\u7684\u52a8\u529b\u548c\u53c2\u4e0e\u5ea6\u3002", "conclusion": "Fast-Forwarding\u662f\u4e00\u79cd\u7075\u6d3b\u4e14\u6548\u679c\u663e\u8457\u7684\u51cf\u5c11\u8fc7\u5ea6\u7ec3\u4e60\u7684\u65b9\u6cd5\uff0c\u80fd\u63d0\u5347\u638c\u63e1\u5f0f\u5b66\u4e60\u7684\u5b9e\u8df5\u6548\u7387\uff0c\u4f46\u6700\u4f73\u6210\u6548\u9700\u8003\u8651\u5b66\u751f\u7684\u5b66\u4e60\u52a8\u529b\u3002"}}
{"id": "2506.18717", "categories": ["cs.CE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18717", "abs": "https://arxiv.org/abs/2506.18717", "authors": ["Linyue Hu", "Qi Wang"], "title": "A Study of Dynamic Stock Relationship Modeling and S&P500 Price Forecasting Based on Differential Graph Transformer", "comment": null, "summary": "Stock price prediction is vital for investment decisions and risk management,\nyet remains challenging due to markets' nonlinear dynamics and time-varying\ninter-stock correlations. Traditional static-correlation models fail to capture\nevolving stock relationships. To address this, we propose a Differential Graph\nTransformer (DGT) framework for dynamic relationship modeling and price\nprediction. Our DGT integrates sequential graph structure changes into\nmulti-head self-attention via a differential graph mechanism, adaptively\npreserving high-value connections while suppressing noise. Causal temporal\nattention captures global/local dependencies in price sequences. We further\nevaluate correlation metrics (Pearson, Mutual Information, Spearman, Kendall's\nTau) across global/local/dual scopes as spatial-attention priors. Using 10\nyears of S&P 500 closing prices (z-score normalized; 64-day sliding windows),\nDGT with spatial priors outperformed GRU baselines (RMSE: 0.24 vs. 0.87).\nKendall's Tau global matrices yielded optimal results (MAE: 0.11). K-means\nclustering revealed \"high-volatility growth\" and \"defensive blue-chip\" stocks,\nwith the latter showing lower errors (RMSE: 0.13) due to stable correlations.\nKendall's Tau and Mutual Information excelled in volatile sectors. This study\ninnovatively combines differential graph structures with Transformers,\nvalidating dynamic relationship modeling and identifying optimal correlation\nmetrics/scopes. Clustering analysis supports tailored quantitative strategies.\nOur framework advances financial time-series prediction through dynamic\nmodeling and cross-asset interaction analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u5dee\u5206\u56feTransformer\u7528\u4e8e\u52a8\u6001\u5efa\u6a21\u548c\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\uff0c\u6bd4\u4f20\u7edf\u6a21\u578b\u8868\u73b0\u66f4\u4f18\uff0c\u80fd\u81ea\u9002\u5e94\u5904\u7406\u80a1\u7968\u95f4\u53d8\u5316\u76f8\u5173\u6027\uff0c\u7ed3\u679c\u663e\u793a\u5c24\u5176\u9002\u5408\u6ce2\u52a8\u6027\u8f83\u9ad8\u884c\u4e1a\uff0c\u652f\u6301\u91cf\u5316\u6295\u8d44\u7b56\u7565\u4f18\u5316\u3002", "motivation": "\u7531\u4e8e\u80a1\u7968\u5e02\u573a\u5177\u6709\u975e\u7ebf\u6027\u52a8\u6001\u548c\u65f6\u95f4\u53d8\u5316\u7684\u76f8\u5173\u6027\uff0c\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u6781\u5177\u6311\u6218\u6027\u3002\u4f20\u7edf\u7684\u9759\u6001\u76f8\u5173\u6027\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u6355\u6349\u4e0d\u65ad\u6f14\u53d8\u7684\u80a1\u7968\u5173\u7cfb\uff0c\u56e0\u6b64\u9700\u8981\u6709\u65b0\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u52a8\u6001\u5173\u7cfb\u5efa\u6a21\u548c\u66f4\u51c6\u786e\u7684\u4ef7\u683c\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5dee\u5206\u56fe\u795e\u7ecf\u7f51\u7edcTransformer\uff08Differential Graph Transformer, DGT\uff09\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u5c06\u65f6\u5e8f\u6027\u4e0b\u7684\u56fe\u7ed3\u6784\u53d8\u5316\u878d\u5165\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u5dee\u5206\u56fe\u673a\u5236\u81ea\u9002\u5e94\u5730\u4fdd\u7559\u9ad8\u4ef7\u503c\u8fde\u63a5\u3001\u6291\u5236\u566a\u58f0\u3002\u5f15\u5165\u56e0\u679c\u65f6\u5e8f\u6ce8\u610f\u529b\u6355\u83b7\u4ef7\u683c\u5e8f\u5217\u4e2d\u7684\u5168\u5c40\u548c\u5c40\u90e8\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5728\u7a7a\u95f4\u6ce8\u610f\u529b\u4e2d\u6bd4\u8f83\u4e86\u4e0d\u540c\u76f8\u5173\u6027\u6307\u6807\u548c\u8303\u56f4\u4f5c\u4e3a\u5148\u9a8c\u3002", "result": "\u5728\u6807\u51c6\u5316\u540e\u768410\u5e74S&P 500\u6536\u76d8\u4ef7\uff08\u4ee564\u65e5\u6ed1\u7a97\u5904\u7406\uff09\u4e0a\uff0cDGT\u7ed3\u5408\u7a7a\u95f4\u5148\u9a8c\u5728RMSE\u3001MAE\u7b49\u6307\u6807\u4e0a\u5747\u4f18\u4e8eGRU\u7b49\u57fa\u7ebf\u6a21\u578b\u3002\u4ee5Kendall's Tau\u76f8\u5173\u6027\u4e3a\u5168\u5c40\u7a7a\u95f4\u5148\u9a8c\u65f6\u53d6\u5f97\u6700\u4f73\u8868\u73b0\u3002\u805a\u7c7b\u5206\u6790\u53d1\u73b0\u9ad8\u6ce2\u52a8\u6210\u957f\u80a1\u548c\u9632\u5fa1\u578b\u84dd\u7b79\u80a1\uff0c\u5176\u4e2d\u84dd\u7b79\u80a1\u56e0\u76f8\u5173\u6027\u66f4\u7a33\u5b9a\u9884\u6d4b\u8bef\u5dee\u66f4\u4f4e\u3002\u5e76\u4e14Kendall's Tau\u3001\u4e92\u4fe1\u606f\u5728\u9ad8\u6ce2\u52a8\u884c\u4e1a\u8868\u73b0\u5c24\u4f73\u3002", "conclusion": "\u5dee\u5206\u56fe\u7ed3\u6784\u4e0eTransformer\u7684\u7ed3\u5408\u80fd\u6709\u6548\u63d0\u5347\u52a8\u6001\u5173\u7cfb\u5efa\u6a21\u548c\u4ef7\u683c\u9884\u6d4b\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u5b9e\u8be5\u6846\u67b6\u80fd\u6839\u636e\u4e0d\u540c\u80a1\u7968\u76f8\u5173\u6027\u7a33\u5b9a\u6027\u548c\u6ce2\u52a8\u6027\uff0c\u5236\u5b9a\u66f4\u6709\u9488\u5bf9\u6027\u7684\u91cf\u5316\u7b56\u7565\uff0c\u5e76\u5728\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9886\u57df\u5177\u6709\u5148\u8fdb\u6027\u548c\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.17459", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17459", "abs": "https://arxiv.org/abs/2506.17459", "authors": ["Siyu Liang", "Gina-Anne Levow"], "title": "Breaking the Transcription Bottleneck: Fine-tuning ASR Models for Extremely Low-Resource Fieldwork Languages", "comment": null, "summary": "Automatic Speech Recognition (ASR) has reached impressive accuracy for\nhigh-resource languages, yet its utility in linguistic fieldwork remains\nlimited. Recordings collected in fieldwork contexts present unique challenges,\nincluding spontaneous speech, environmental noise, and severely constrained\ndatasets from under-documented languages. In this paper, we benchmark the\nperformance of two fine-tuned multilingual ASR models, MMS and XLS-R, on five\ntypologically diverse low-resource languages with control of training data\nduration. Our findings show that MMS is best suited when extremely small\namounts of training data are available, whereas XLS-R shows parity performance\nonce training data exceed one hour. We provide linguistically grounded analysis\nfor further provide insights towards practical guidelines for field linguists,\nhighlighting reproducible ASR adaptation approaches to mitigate the\ntranscription bottleneck in language documentation.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u5bf9\u6bd4\u6d4b\u8bd5\u4e86\u4e24\u79cd\u4e3b\u6d41\u591a\u8bed\u79cdASR\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u7530\u91ce\u8bed\u97f3\u6570\u636e\u4e0a\u7684\u6548\u679c\uff0c\u63d0\u51fa\u9488\u5bf9\u4e0d\u540c\u6570\u636e\u91cf\u7684\u6a21\u578b\u9009\u62e9\u5efa\u8bae\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u8bed\u8a00\u5b66\u7530\u91ce\u5de5\u4f5c\u7684\u81ea\u52a8\u8f6c\u5199\u6548\u7387\u3002", "motivation": "\u5c3d\u7ba1\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u5728\u9ad8\u8d44\u6e90\u8bed\u8a00\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u51c6\u786e\u7387\uff0c\u4f46\u5e94\u7528\u4e8e\u8bed\u8a00\u7530\u91ce\u8c03\u67e5\u4ecd\u6709\u5c40\u9650\uff0c\u5c24\u5176\u9762\u5bf9\u4f4e\u8d44\u6e90\u548c\u53d7\u9650\u5236\u7684\u6570\u636e\u96c6\u3002\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5b9e\u5730\u8bed\u6599\u81ea\u52a8\u8f6c\u5199\u7684\u74f6\u9888\u96be\u9898\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u4e94\u79cd\u7c7b\u578b\u591a\u6837\u3001\u8d44\u6e90\u7a00\u7f3a\u7684\u8bed\u8a00\uff0c\u4e25\u683c\u63a7\u5236\u8bad\u7ec3\u6570\u636e\u91cf\uff0c\u6d4b\u8bd5\u5e76\u5bf9\u6bd4\u4e86\u4e24\u79cd\u591a\u8bed\u79cdASR\u6a21\u578b\uff08MMS\u548cXLS-R\uff09\u7684\u5fae\u8c03\u6548\u679c\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u6570\u636e\u91cf\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u8bad\u7ec3\u6570\u636e\u6781\u5c11\u65f6\uff0cMMS\u8868\u73b0\u66f4\u4f18\uff1b\u5f53\u8bad\u7ec3\u6570\u636e\u8d85\u8fc7\u4e00\u5c0f\u65f6\u65f6\uff0cXLS-R\u8868\u73b0\u53ef\u4e0eMMS\u6301\u5e73\u3002", "conclusion": "\u8bba\u6587\u4e3a\u7530\u91ce\u8bed\u8a00\u5b66\u5de5\u4f5c\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684ASR\u5fae\u8c03\u9002\u5e94\u5efa\u8bae\uff0c\u5e76\u9610\u91ca\u4e86\u53ef\u590d\u73b0\u7684\u9002\u5e94\u6d41\u7a0b\uff0c\u53ef\u6709\u6548\u7f13\u89e3\u8bed\u8a00\u6863\u6848\u8f6c\u5199\u5de5\u4f5c\u4e2d\u7684\u74f6\u9888\u3002"}}
{"id": "2506.17784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17784", "abs": "https://arxiv.org/abs/2506.17784", "authors": ["Song Wang", "Zhen Tan", "Zihan Chen", "Shuang Zhou", "Tianlong Chen", "Jundong Li"], "title": "AnyMAC: Cascading Flexible Multi-Agent Collaboration via Next-Agent Prediction", "comment": null, "summary": "Recent progress in large language model (LLM)-based multi-agent collaboration\nhighlights the power of structured communication in enabling collective\nintelligence. However, existing methods largely rely on static or graph-based\ninter-agent topologies, lacking the potential adaptability and flexibility in\ncommunication. In this work, we propose a new framework that rethinks\nmulti-agent coordination through a sequential structure rather than a graph\nstructure, offering a significantly larger topology space for multi-agent\ncommunication. Our method focuses on two key directions: (1) Next-Agent\nPrediction, which selects the most suitable agent role at each step, and (2)\nNext-Context Selection (NCS), which enables each agent to selectively access\nrelevant information from any previous step. Together, these components\nconstruct task-adaptive communication pipelines that support both role\nflexibility and global information flow. Extensive evaluations across multiple\nbenchmarks demonstrate that our approach achieves superior performance while\nsubstantially reducing communication overhead.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u987a\u5e8f\u7ed3\u6784\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u4ee3\u7406\u548c\u4e0a\u4e0b\u6587\uff0c\u5b9e\u73b0\u9002\u5e94\u6027\u5f3a\u3001\u4fe1\u606f\u6d41\u901a\u5168\u5c40\u3001\u901a\u4fe1\u5f00\u9500\u4f4e\u7684\u9ad8\u6548\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u65b9\u6cd5\u666e\u904d\u4f9d\u8d56\u9759\u6001\u6216\u57fa\u4e8e\u56fe\u7684\u667a\u80fd\u4f53\u62d3\u6251\uff0c\u7f3a\u4e4f\u901a\u4fe1\u7684\u9002\u5e94\u6027\u548c\u7075\u6d3b\u6027\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u7528\u987a\u5e8f\u7ed3\u6784\u66ff\u4ee3\u56fe\u7ed3\u6784\uff0c\u62d3\u5c55\u591a\u667a\u80fd\u4f53\u901a\u4fe1\u7684\u62d3\u6251\u7a7a\u95f4\u3002", "method": "\u91c7\u7528\u4e24\u5927\u5173\u952e\u673a\u5236\uff1a\uff081\uff09\u4e0b\u4e00\u4ee3\u7406\u4f53\u9884\u6d4b\uff0c\u5373\u5728\u6bcf\u4e00\u6b65\u9009\u62e9\u6700\u5408\u9002\u7684\u4ee3\u7406\u89d2\u8272\uff1b\uff082\uff09\u4e0b\u4e00\u6b65\u4e0a\u4e0b\u6587\u9009\u62e9\uff0c\u4f7f\u6bcf\u4e2a\u4ee3\u7406\u53ef\u4ee5\u4ece\u4efb\u4f55\u5148\u524d\u6b65\u9aa4\u4e2d\u6709\u9009\u62e9\u5730\u83b7\u53d6\u76f8\u5173\u4fe1\u606f\uff0c\u6784\u5efa\u4efb\u52a1\u81ea\u9002\u5e94\u7684\u901a\u4fe1\u7ba1\u9053\u3002", "result": "\u65b9\u6cd5\u5728\u591a\u4e2a\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u57fa\u51c6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4e14\u5927\u5e45\u51cf\u5c11\u4e86\u901a\u4fe1\u6570\u636e\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u987a\u5e8f\u7ed3\u6784\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u66f4\u4f18\u5f02\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u5f00\u9500\u3002"}}
{"id": "2506.17741", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17741", "abs": "https://arxiv.org/abs/2506.17741", "authors": ["Levin Brinkmann", "Thomas F. Eisenmann", "Anne-Marie Nussberger", "Maxim Derex", "Sara Bonati", "Valerii Chirkov", "Iyad Rahwan"], "title": "Experimental Evidence for the Propagation and Preservation of Machine Discoveries in Human Populations", "comment": null, "summary": "Intelligent machines with superhuman capabilities have the potential to\nuncover problem-solving strategies beyond human discovery. Emerging evidence\nfrom competitive gameplay, such as Go, demonstrates that AI systems are\nevolving from mere tools to sources of cultural innovation adopted by humans.\nHowever, the conditions under which intelligent machines transition from tools\nto drivers of persistent cultural change remain unclear. We identify three key\nconditions for machines to fundamentally influence human problem-solving: the\ndiscovered strategies must be non-trivial, learnable, and offer a clear\nadvantage. Using a cultural transmission experiment and an agent-based\nsimulation, we demonstrate that when these conditions are met,\nmachine-discovered strategies can be transmitted, understood, and preserved by\nhuman populations, leading to enduring cultural shifts. These findings provide\na framework for understanding how machines can persistently expand human\ncognitive skills and underscore the need to consider their broader implications\nfor human cognition and cultural evolution.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\uff0c\u673a\u5668\u63d0\u51fa\u7684\u975e\u540c\u51e1\u54cd\u3001\u6613\u4e8e\u5b66\u4e60\u4e14\u6709\u660e\u663e\u4f18\u52bf\u7684\u7b56\u7565\uff0c\u80fd\u591f\u88ab\u6301\u4e45\u5730\u4f20\u9012\u548c\u91c7\u7eb3\uff0c\u4fc3\u8fdb\u4eba\u7c7b\u8ba4\u77e5\u548c\u6587\u5316\u7684\u957f\u671f\u8fdb\u6b65\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u5728\u8bf8\u5982\u56f4\u68cb\u7b49\u9886\u57df\u5df2\u5c55\u73b0\u8d85\u8d8a\u4eba\u7c7b\u7684\u80fd\u529b\uff0c\u5e76\u9010\u6e10\u4ece\u5de5\u5177\u53d1\u5c55\u4e3a\u4eba\u7c7b\u6587\u5316\u521b\u65b0\u7684\u6e90\u6cc9\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u54ea\u4e9b\u6761\u4ef6\u4fc3\u4f7f\u673a\u5668\u4ece\u7b80\u5355\u5de5\u5177\u8f6c\u4e3a\u6301\u7eed\u6587\u5316\u53d8\u9769\u7684\u9a71\u52a8\u529b\u3002", "method": "\u672c\u6587\u91c7\u7528\u6587\u5316\u4f20\u9012\u5b9e\u9a8c\u4ee5\u53ca\u57fa\u4e8e\u4ee3\u7406(agent-based)\u7684\u6a21\u62df\uff0c\u7814\u7a76\u4e86\u667a\u80fd\u673a\u5668\u5bf9\u4eba\u7c7b\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u548c\u6587\u5316\u6f14\u53d8\u7684\u5f71\u54cd\u3002", "result": "\u9a8c\u8bc1\u4e86\u53ea\u6709\u5f53\u673a\u5668\u53d1\u73b0\u7684\u65b0\u7b56\u7565\u5177\u5907\u975e\u5e73\u51e1\u6027\u3001\u53ef\u5b66\u4e60\u6027\u548c\u660e\u663e\u4f18\u52bf\u8fd9\u4e09\u5927\u6761\u4ef6\u65f6\uff0c\u624d\u80fd\u5728\u4eba\u7fa4\u4e2d\u5b9e\u73b0\u4f20\u627f\u548c\u5f71\u54cd\uff0c\u4ece\u800c\u5f15\u53d1\u6301\u4e45\u7684\u6587\u5316\u53d8\u5316\u3002", "conclusion": "\u5f53\u673a\u5668\u53d1\u73b0\u7684\u7b56\u7565\u5177\u5907\u975e\u5e73\u51e1\u6027\u3001\u53ef\u5b66\u4e60\u6027\u548c\u660e\u663e\u4f18\u52bf\u65f6\uff0c\u8fd9\u4e9b\u7b56\u7565\u80fd\u591f\u5728\u4eba\u7c7b\u7fa4\u4f53\u4e2d\u88ab\u4f20\u9012\u3001\u7406\u89e3\u548c\u4fdd\u7559\uff0c\u4ece\u800c\u5e26\u6765\u6301\u7eed\u7684\u6587\u5316\u8f6c\u53d8\u3002"}}
{"id": "2506.18724", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.18724", "abs": "https://arxiv.org/abs/2506.18724", "authors": ["Jun Zhang", "Tong Zhang", "Ying Wang"], "title": "Towards Real-time Structural Dynamics Simulation with Graph-based Digital Twin Modelling", "comment": null, "summary": "Precise and timely simulation of a structure's dynamic behavior is crucial\nfor evaluating its performance and assessing its health status. Traditional\nnumerical methods are often limited by high computational costs and low\nefficiency, while deep learning approaches offer a promising alternative.\nHowever, these data-driven methods still face challenges, such as limited\nphysical interpretability and difficulty in adapting to diverse structural\nconfigurations. To address these issues, this study proposes a graph-based\ndigital twin modelling (GDTM) framework to simulate structural dynamic\nresponses across various spatial topologies. In this framework, the adjacency\nmatrix explicitly represents the spatial relationships between structural\nvertices, enhancing the model's physical interpretability. The effectiveness of\nthe proposed framework was validated through comprehensive numerical and\nexperimental studies. The results demonstrate that the framework accurately\nsimulated structural dynamics across different topological configurations, with\nNormalized Mean-Squared Error (NMSE) values consistently below 0.005 in\nnumerical simulations and 0.0015 in experimental validations. Furthermore, the\nframework achieved over 80-fold improvements in computational efficiency\ncompared to traditional finite element methods (FEM). This research promotes\nthe practical application of graph-based structural dynamics modelling, which\nhas the potential to significantly advance structural performance evaluation\nand health monitoring.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u57fa\u4e8e\u56fe\u7684\u6570\u5b57\u5b6a\u751f\u6a21\u578b\uff0c\u901a\u8fc7\u63d0\u5347\u7269\u7406\u53ef\u89e3\u91ca\u6027\u548c\u9002\u5e94\u4e0d\u540c\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ed3\u6784\u52a8\u529b\u6a21\u62df\u7684\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u7ed3\u6784\u52a8\u6001\u884c\u4e3a\u7684\u7cbe\u786e\u53ca\u65f6\u6a21\u62df\u5bf9\u4e8e\u8bc4\u4f30\u5176\u6027\u80fd\u548c\u5065\u5eb7\u72b6\u6001\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u6548\u7387\u4f4e\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u867d\u5177\u5907\u524d\u666f\uff0c\u4f46\u5b58\u5728\u7269\u7406\u53ef\u89e3\u91ca\u6027\u5dee\u53ca\u96be\u4ee5\u9002\u5e94\u591a\u6837\u7ed3\u6784\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u6570\u5b57\u5b6a\u751f\u5efa\u6a21(GDTM)\u6846\u67b6\uff0c\u5229\u7528\u90bb\u63a5\u77e9\u9635\u663e\u5f0f\u8868\u8fbe\u7ed3\u6784\u8282\u70b9\u95f4\u7684\u7a7a\u95f4\u5173\u7cfb\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u7684\u7269\u7406\u53ef\u89e3\u91ca\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6570\u503c\u53ca\u5b9e\u9a8c\u4e24\u65b9\u9762\u8fdb\u884c\u5168\u9762\u9a8c\u8bc1\u3002", "result": "\u6846\u67b6\u5728\u5404\u79cd\u62d3\u6251\u7ed3\u6784\u7684\u52a8\u6001\u54cd\u5e94\u6a21\u62df\u4e2d\u5747\u83b7\u5f97\u5f88\u9ad8\u51c6\u786e\u5ea6\uff0c\u6570\u503c\u4eff\u771fNMSE\u4f4e\u4e8e0.005\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4f4e\u4e8e0.0015\u3002\u4e0e\u4f20\u7edf\u6709\u9650\u5143\u6cd5(FEM)\u76f8\u6bd4\uff0c\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u8d85\u8fc780\u500d\u3002", "conclusion": "\u57fa\u4e8e\u56fe\u7684\u6570\u5b57\u5b6a\u751f\u52a8\u6001\u5efa\u6a21\u80fd\u663e\u8457\u63d0\u5347\u7ed3\u6784\u52a8\u529b\u54cd\u5e94\u6a21\u62df\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u6709\u52a9\u4e8e\u7ed3\u6784\u6027\u80fd\u8bc4\u4f30\u548c\u5065\u5eb7\u76d1\u6d4b\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.17467", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17467", "abs": "https://arxiv.org/abs/2506.17467", "authors": ["Weixin Liang"], "title": "Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems", "comment": "Stanford CS PhD Dissertation", "summary": "Large language models (LLMs) have shown significant potential to change how\nwe write, communicate, and create, leading to rapid adoption across society.\nThis dissertation examines how individuals and institutions are adapting to and\nengaging with this emerging technology through three research directions.\nFirst, I demonstrate how the institutional adoption of AI detectors introduces\nsystematic biases, particularly disadvantaging writers of non-dominant language\nvarieties, highlighting critical equity concerns in AI governance. Second, I\npresent novel population-level algorithmic approaches that measure the\nincreasing adoption of LLMs across writing domains, revealing consistent\npatterns of AI-assisted content in academic peer reviews, scientific\npublications, consumer complaints, corporate communications, job postings, and\ninternational organization press releases. Finally, I investigate LLMs'\ncapability to provide feedback on research manuscripts through a large-scale\nempirical analysis, offering insights into their potential to support\nresearchers who face barriers in accessing timely manuscript feedback,\nparticularly early-career researchers and those from under-resourced settings.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u5bf9\u4e2a\u4eba\u548c\u673a\u6784\u7684\u5f71\u54cd\uff0c\u5305\u62ecAI\u68c0\u6d4b\u5e26\u6765\u7684\u516c\u5e73\u6027\u6311\u6218\u3001LLM\u666e\u53ca\u7684\u7fa4\u4f53\u7ea7\u8d8b\u52bf\u53ca\u5176\u5728\u79d1\u7814\u652f\u6301\u4e2d\u7684\u6f5c\u529b\uff0c\u547c\u5401\u5173\u6ce8AI\u6cbb\u7406\u4e0e\u8d44\u6e90\u5206\u914d\u7684\u516c\u5e73\u6027\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u793e\u4f1a\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4eba\u4eec\u548c\u673a\u6784\u5fc5\u987b\u9002\u5e94\u5e76\u5408\u7406\u5229\u7528\u8fd9\u4e00\u65b0\u5174\u6280\u672f\u3002\u8be5\u8bba\u6587\u65e8\u5728\u63a2\u8ba8LLM\u5e26\u6765\u7684\u793e\u4f1a\u5f71\u54cd\u4ee5\u53ca\u76f8\u5173\u516c\u5e73\u6027\u3001\u666e\u53ca\u6027\u548c\u5b9e\u7528\u6027\u95ee\u9898\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u4e09\u6761\u7814\u7a76\u8def\u5f84\u8fdb\u884c\u63a2\u8ba8\uff1a1\uff09\u5206\u6790AI\u68c0\u6d4b\u5668\u7684\u5236\u5ea6\u6027\u5e94\u7528\uff0c\u63ed\u793a\u5176\u5bf9\u975e\u4e3b\u6d41\u8bed\u8a00\u5199\u4f5c\u8005\u7684\u4e0d\u516c\u5e73\u5f71\u54cd\uff1b2\uff09\u63d0\u51fa\u7fa4\u4f53\u7ea7\u7684\u7b97\u6cd5\u65b9\u6cd5\uff0c\u91cf\u5316LLM\u5728\u5404\u7c7b\u5199\u4f5c\u9886\u57df\u4e2d\u7684\u91c7\u7528\u7387\uff0c\u5982\u5b66\u672f\u8bc4\u5ba1\u3001\u79d1\u5b66\u51fa\u7248\u3001\u6d88\u8d39\u8005\u6295\u8bc9\u3001\u4f01\u4e1a\u6c9f\u901a\u3001\u62db\u8058\u5e7f\u544a\u548c\u56fd\u9645\u7ec4\u7ec7\u65b0\u95fb\u7a3f\u7b49\uff1b3\uff09\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790LLM\u5728\u79d1\u7814\u624b\u7a3f\u53cd\u9988\u4e2d\u7684\u4f5c\u7528\uff0c\u7279\u522b\u5173\u6ce8\u53d7\u9650\u8d44\u6e90\u7814\u7a76\u8005\u53ef\u83b7\u5f97\u652f\u6301\u7684\u60c5\u51b5\u3002", "result": "1\uff09AI\u68c0\u6d4b\u5de5\u5177\u5728\u5236\u5ea6\u5e94\u7528\u4e2d\u9020\u6210\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u975e\u4e3b\u6d41\u8bed\u8a00\u4f7f\u7528\u8005\u5c24\u4e3a\u53d7\u5bb3\uff0c\u66b4\u9732AI\u6cbb\u7406\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff1b2\uff09\u5728\u591a\u4e2a\u5199\u4f5c\u9886\u57df\u53d1\u73b0LLM\u8f85\u52a9\u5185\u5bb9\u7684\u666e\u904d\u5b58\u5728\u53ca\u5176\u6301\u7eed\u589e\u957f\u7684\u91c7\u7528\u8d8b\u52bf\uff1b3\uff09LLM\u80fd\u591f\u4e3a\u79d1\u7814\u624b\u7a3f\u63d0\u4f9b\u53cd\u9988\uff0c\u663e\u793a\u652f\u6301\u65e9\u671f\u7814\u7a76\u8005\u548c\u8d44\u6e90\u532e\u4e4f\u7fa4\u4f53\u7684\u6f5c\u529b\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\u6b63\u5728\u6df1\u523b\u5f71\u54cd\u5199\u4f5c\u5b9e\u8df5\u548c\u5b66\u672f\u4ea4\u6d41\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u516c\u5e73\u6027\u548c\u6cbb\u7406\u7b49\u91cd\u8981\u6311\u6218\u3002\u9488\u5bf9\u6027\u6280\u672f\u624b\u6bb5\u548c\u653f\u7b56\u9700\u540c\u6b65\u53d1\u5c55\uff0c\u4ee5\u786e\u4fdd\u6280\u672f\u8fdb\u6b65\u5e26\u6765\u7684\u673a\u4f1a\u53ef\u4ee5\u516c\u5e73\u60e0\u53ca\u4e0d\u540c\u7fa4\u4f53\u3002"}}
{"id": "2506.17788", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "I.2.1; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.17788", "abs": "https://arxiv.org/abs/2506.17788", "authors": ["Shahab Rahimirad", "Guven Gergerli", "Lucia Romero", "Angela Qian", "Matthew Lyle Olson", "Simon Stepputtis", "Joseph Campbell"], "title": "Bayesian Social Deduction with Graph-Informed Language Models", "comment": "32 pages, 10 figures. Under review", "summary": "Social reasoning - inferring unobservable beliefs and intentions from partial\nobservations of other agents - remains a challenging task for large language\nmodels (LLMs). We evaluate the limits of current reasoning language models in\nthe social deduction game Avalon and find that while the largest models\ndemonstrate strong performance, they require extensive test-time inference and\ndegrade sharply when distilled to smaller, real-time-capable variants. To\naddress this, we introduce a hybrid reasoning framework that externalizes\nbelief inference to a structured probabilistic model, while using an LLM for\nlanguage understanding and interaction. Our approach achieves competitive\nperformance with much larger models in Agent-Agent play and, notably, is the\nfirst language agent to defeat human players in a controlled study - achieving\na 67% win rate and receiving higher qualitative ratings than both reasoning\nbaselines and human teammates. We release code, models, and a dataset to\nsupport future work on social reasoning in LLM agents, which can be found at\nhttps://camp-lab-purdue.github.io/bayesian-social-deduction/", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LLM\u4e0e\u6982\u7387\u6a21\u578b\u7684\u6df7\u5408\u793e\u4f1a\u63a8\u7406\u65b9\u6cd5\uff0c\u5728\u6e38\u620fAvalon\u4e2d\u53d6\u5f97\u91cd\u5927\u7a81\u7834\uff0c\u9996\u6b21\u5b9e\u73b0AI\u8bed\u8a00\u667a\u80fd\u4f53\u5bf9\u4eba\u7c7b\u73a9\u5bb6\u7684\u663e\u8457\u80dc\u5229\uff0c\u5e76\u5927\u5e45\u63d0\u5347\u4e86\u6548\u7387\u4e0e\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u793e\u4f1a\u63a8\u7406\u2014\u2014\u5373\u6839\u636e\u5bf9\u4ed6\u4eba\u884c\u4e3a\u7684\u90e8\u5206\u89c2\u5bdf\u63a8\u65ad\u5176\u4e0d\u53ef\u89c1\u7684\u4fe1\u5ff5\u548c\u610f\u56fe\u2014\u2014\u65b9\u9762\u4f9d\u7136\u5b58\u5728\u663e\u8457\u6311\u6218\uff0c\u5c24\u5176\u5728\u5feb\u901f\u3001\u5b9e\u65f6\u63a8\u7406\u573a\u666f\u4e0b\u66f4\u4e3a\u660e\u663e\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u80fd\u529b\u548c\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u63d0\u5347\u793e\u4f1a\u63a8\u7406\u7684\u8868\u73b0\uff0c\u540c\u65f6\u517c\u987e\u8fd0\u884c\u6548\u7387\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u63a8\u7406\u6846\u67b6\uff0c\u5c06\u4fe1\u5ff5\u63a8\u65ad\u5916\u5305\u7ed9\u7ed3\u6784\u5316\u7684\u6982\u7387\u6a21\u578b\uff0c\u540c\u65f6\u4f7f\u7528LLM\u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u4ea4\u4e92\u3002\u901a\u8fc7\u8fd9\u79cd\u5206\u5de5\u534f\u4f5c\uff0c\u517c\u987e\u63a8\u7406\u80fd\u529b\u4e0e\u5b9e\u65f6\u6548\u7387\u3002", "result": "\u8be5\u65b9\u6cd5\u5728Agent-Agent\u5bf9\u6218\u4e2d\u53d6\u5f97\u4e86\u4e0e\u8fdc\u5927\u4e8e\u81ea\u8eab\u89c4\u6a21\u7684\u6a21\u578b\u76f8\u5f53\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u5728\u63a7\u5236\u5b9e\u9a8c\u4e2d\u9996\u6b21\u5b9e\u73b0\u4e86\u8bed\u8a00\u667a\u80fd\u4f53\u5728\u793e\u4f1a\u63a8\u7406\u6e38\u620f\u4e2d\u51fb\u8d25\u4eba\u7c7b\u73a9\u5bb6\uff08\u80dc\u7387\u8fbe67%\uff09\uff0c\u5728\u5b9a\u6027\u8bc4\u4ef7\u4e0a\u4e5f\u8d85\u8fc7\u4e86\u73b0\u6709\u63a8\u7406\u57fa\u7ebf\u548c\u4eba\u7c7b\u961f\u53cb\u3002", "conclusion": "\u6df7\u5408\u63a8\u7406\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u5c0f\u578b\u3001\u5b9e\u65f6\u53ef\u7528\u7684LLM\u5728\u793e\u4f1a\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u662f\u5b9e\u73b0\u5177\u5907\u5f3a\u5927\u793e\u4f1a\u8ba4\u77e5\u7684AI\u8bed\u8a00\u4ee3\u7406\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2506.17808", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17808", "abs": "https://arxiv.org/abs/2506.17808", "authors": ["Weina Jin"], "title": "The value of human and machine in machine-generated creative contents", "comment": null, "summary": "The seemingly \"imagination\" and \"creativity\" from machine-generated contents\nshould not be misattributed to the accomplishment of machine. They are\naccomplishments of both human and machine. Without human interpretation, the\nmachine-generated contents remain in the imaginary space of the large language\nmodels, and cannot automatically establish grounding in the reality and human\nexperience.", "AI": {"tldr": "\u673a\u5668\u751f\u6210\u5185\u5bb9\u7684\u521b\u9020\u6027\u79bb\u4e0d\u5f00\u4eba\u7684\u89e3\u91ca\uff0c\u4eba\u548c\u673a\u5668\u5171\u540c\u5b8c\u6210\u6709\u610f\u4e49\u7684\u5185\u5bb9\u521b\u9020\u3002", "motivation": "\u5f53\u524d\u5bf9\u673a\u5668\u751f\u6210\u5185\u5bb9\u7684\u201c\u60f3\u8c61\u529b\u201d\u548c\u201c\u521b\u9020\u529b\u201d\u5e38\u88ab\u8bef\u5f52\u56e0\u4e8e\u673a\u5668\u672c\u8eab\uff0c\u5ffd\u89c6\u4e86\u4eba\u7684\u4f5c\u7528\u3002\u4f5c\u8005\u5e0c\u671b\u6f84\u6e05\u4eba\u673a\u5728\u5185\u5bb9\u521b\u9020\u4e2d\u7684\u5173\u7cfb\u3002", "method": "\u7406\u8bba\u63a2\u8ba8\u4e0e\u54f2\u5b66\u5206\u6790\uff0c\u6f84\u6e05\u4eba\u7c7b\u89e3\u91ca\u5728\u673a\u5668\u751f\u6210\u5185\u5bb9\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u673a\u5668\u751f\u6210\u5185\u5bb9\u672c\u8eab\u65e0\u6cd5\u72ec\u7acb\u5efa\u7acb\u4e0e\u73b0\u5b9e\u548c\u4eba\u7c7b\u7ecf\u9a8c\u7684\u8fde\u63a5\uff0c\u5fc5\u987b\u7ecf\u8fc7\u4eba\u7684\u89e3\u91ca\u4e0e\u8ba4\u77e5\u624d\u80fd\u6210\u4e3a\u6709\u610f\u4e49\u7684\u521b\u9020\u3002", "conclusion": "\u673a\u5668\u4ea7\u751f\u7684\u201c\u60f3\u8c61\u529b\u201d\u548c\u201c\u521b\u9020\u529b\u201d\u4e0d\u662f\u5355\u65b9\u9762\u6210\u5c31\uff0c\u800c\u662f\u4eba\u673a\u5171\u540c\u4f5c\u7528\u7684\u4ea7\u7269\u3002\u4eba\u7c7b\u89e3\u91ca\u8d4b\u4e88\u4e86\u673a\u5668\u751f\u6210\u5185\u5bb9\u73b0\u5b9e\u57fa\u7840\u548c\u610f\u4e49\u3002"}}
{"id": "2506.18853", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2506.18853", "abs": "https://arxiv.org/abs/2506.18853", "authors": ["Yinmin Liu", "Hessam Babaee", "Peyman Givi", "Daniel Livescu", "Arash Nouri"], "title": "Skeletal Reaction Models for Gasoline Surrogate Combustion", "comment": null, "summary": "Skeletal reaction models are derived for a four-component gasoline surrogate\nmodel via an instantaneous local sensitivity analysis technique. The\nsensitivities of the species mass fractions and the temperature with respect to\nthe reaction rates are estimated by a reduced-order modeling (ROM) methodology.\nTermed \"implicit time-dependent basis CUR (implicit TDB-CUR),\" this methodology\nis based on the CUR matrix decomposition and incorporates implicit time\nintegration for evolving the bases. The estimated sensitivities are\nsubsequently analyzed to develop skeletal reaction models with a fully\nautomated procedure. The 1389-species gasoline surrogate model developed at\nLawrence Livermore National Laboratory (LLNL) is selected as the detailed\nkinetics model. The skeletal reduction procedure is applied to this model in a\nzero-dimensional constant-pressure reactor over a wide range of initial\nconditions. The performances of the resulting skeletal models are appraised by\ncomparison against the results via the LLNL detailed model, and also\npredictions via other skeletal models. Two new skeletal models are developed\nconsisting of 679 and 494 species, respectively. The first is an alternative to\nan existing model with the same number of species. The predictions with this\nmodel reproduces the detailed models vital flame results with less than 1%\nerrors. The errors via the second model are less than 10%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9690\u5f0fTDB-CUR\u7684\u81ea\u52a8\u5316\u6c7d\u6cb9\u52a8\u529b\u5b66\u9aa8\u67b6\u5316\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u538b\u7f29\u52a8\u529b\u5b66\u6a21\u578b\u89c4\u6a21\uff08\u6700\u591a\u51cf\u5c11\u81f3\u539f\u67651/3\uff09\uff0c\u4e14\u4fdd\u8bc1\u9884\u6d4b\u8bef\u5dee\u6781\u5c0f\uff08<1%\uff09\uff0c\u4e3a\u590d\u6742\u71c3\u6599\u6a21\u62df\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u7684\u6c7d\u6cb9\u66ff\u4ee3\u71c3\u6599\u52a8\u529b\u5b66\u6a21\u578b\u56e0\u7269\u79cd\u6570\u91cf\u5e9e\u5927\uff08\u59821389\u79cd\uff09\uff0c\u5bfc\u81f4\u6570\u503c\u8ba1\u7b97\u6781\u4e3a\u590d\u6742\u548c\u4f4e\u6548\u3002\u4e3a\u4e86\u4fbf\u4e8e\u5de5\u7a0b\u5e94\u7528\u548c\u6570\u503c\u6a21\u62df\uff0c\u9700\u8981\u5c06\u590d\u6742\u8be6\u7ec6\u6a21\u578b\u7b80\u5316\u6210\u53cd\u5e94\u7269\u79cd\u66f4\u5c11\u4f46\u4ecd\u4fdd\u7559\u52a8\u529b\u5b66\u884c\u4e3a\u7684\u9aa8\u67b6\u6a21\u578b\u3002\u76ee\u524d\uff0c\u81ea\u52a8\u5316\u548c\u9ad8\u6548\u7684\u9aa8\u67b6\u6a21\u578b\u6784\u5efa\u65b9\u6cd5\u4f9d\u7136\u662f\u52a8\u529b\u5b66\u7814\u7a76\u7684\u96be\u70b9\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9690\u5f0f\u65f6\u95f4\u76f8\u5173\u57faCUR\u5206\u89e3\uff08implicit TDB-CUR\uff09\u7684\u964d\u9636\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u53cd\u5e94\u901f\u7387\u7684\u5c40\u90e8\u77ac\u65f6\u7075\u654f\u5ea6\u5206\u6790\uff0c\u81ea\u52a8\u6784\u5efa\u9aa8\u67b6\u53cd\u5e94\u52a8\u529b\u5b66\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408CUR\u77e9\u9635\u5206\u89e3\u4e0e\u9690\u5f0f\u65f6\u95f4\u79ef\u5206\uff0c\u901a\u8fc7\u5206\u6790\u7269\u79cd\u548c\u6e29\u5ea6\u5bf9\u53cd\u5e94\u901f\u7387\u7684\u7075\u654f\u5ea6\uff0c\u7b5b\u9009\u91cd\u8981\u53cd\u5e94\u901a\u9053\uff0c\u81ea\u52a8\u8fdb\u884c\u9aa8\u67b6\u5316\u5904\u7406\u3002", "result": "\u5c06\u6240\u63d0\u51fa\u65b9\u6cd5\u5e94\u7528\u4e8eLLNL\u76841389\u7269\u79cd\u6c7d\u6cb9\u4ee3\u7406\u6a21\u578b\uff0c\u5e76\u5728\u96f6\u7ef4\u5b9a\u538b\u53cd\u5e94\u5668\u4e2d\u8fdb\u884c\u5e7f\u6cdb\u6761\u4ef6\u6d4b\u8bd5\uff0c\u6700\u7ec8\u83b7\u5f97\u4e24\u4e2a\u5206\u522b\u5305\u542b679\u4e2a\u4e0e494\u4e2a\u7269\u79cd\u7684\u9aa8\u67b6\u6a21\u578b\u3002\u5176\u4e2d679\u7269\u79cd\u6a21\u578b\u4e0e\u5df2\u6709\u540c\u89c4\u6a21\u9aa8\u67b6\u6a21\u578b\u7cbe\u5ea6\u76f8\u5f53\uff0c\u5173\u952e\u706b\u7130\u53c2\u6570\u9884\u6d4b\u8bef\u5dee\u4f4e\u4e8e1%\uff1b494\u7269\u79cd\u6a21\u578b\u8bef\u5dee\u4e5f\u63a7\u5236\u572810%\u4ee5\u5185\u3002", "conclusion": "\u63d0\u51fa\u7684implicit TDB-CUR\u65b9\u6cd5\u53ef\u4ee5\u81ea\u52a8\u4e14\u9ad8\u6548\u5730\u5bf9\u5927\u578b\u71c3\u6599\u52a8\u529b\u5b66\u673a\u5236\u8fdb\u884c\u9aa8\u67b6\u5316\uff0c\u5728\u663e\u8457\u51cf\u5c11\u7269\u79cd\u6570\u91cf\u7684\u540c\u65f6\u4fdd\u8bc1\u4e86\u52a8\u529b\u5b66\u9884\u6d4b\u51c6\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u4e3a\u590d\u6742\u71c3\u6599\u5316\u5b66\u6a21\u578b\u7684\u5de5\u7a0b\u5e94\u7528\u4e0e\u6570\u503c\u6a21\u62df\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.17506", "categories": ["cs.CL", "cs.OS"], "pdf": "https://arxiv.org/pdf/2506.17506", "abs": "https://arxiv.org/abs/2506.17506", "authors": ["Lesheng Jin", "Zhenyuan Ruan", "Haohui Mai", "Jingbo Shang"], "title": "VeriLocc: End-to-End Cross-Architecture Register Allocation via LLM", "comment": null, "summary": "Modern GPUs evolve rapidly, yet production compilers still rely on\nhand-crafted register allocation heuristics that require substantial re-tuning\nfor each hardware generation. We introduce VeriLocc, a framework that combines\nlarge language models (LLMs) with formal compiler techniques to enable\ngeneralizable and verifiable register allocation across GPU architectures.\nVeriLocc fine-tunes an LLM to translate intermediate representations (MIRs)\ninto target-specific register assignments, aided by static analysis for\ncross-architecture normalization and generalization and a verifier-guided\nregeneration loop to ensure correctness. Evaluated on matrix multiplication\n(GEMM) and multi-head attention (MHA), VeriLocc achieves 85-99% single-shot\naccuracy and near-100% pass@100. Case study shows that VeriLocc discovers more\nperformant assignments than expert-tuned libraries, outperforming rocBLAS by\nover 10% in runtime.", "AI": {"tldr": "VeriLocc\u901a\u8fc7LLM\u548c\u9a8c\u8bc1\u6280\u672f\uff0c\u5c06GPU\u5bc4\u5b58\u5668\u5206\u914d\u81ea\u52a8\u5316\u3001\u6cdb\u5316\uff0c\u5e76\u53ef\u8d85\u8d8a\u624b\u5de5\u8c03\u4f18\u7684\u4e3b\u6d41\u5e93\uff0c\u5728\u7f16\u8bd1\u5668\u5b9e\u73b0\u4e0a\u5e26\u6765\u65b0\u7a81\u7834\u3002", "motivation": "\u73b0\u4ee3GPU\u786c\u4ef6\u66f4\u65b0\u5feb\uff0c\u4f46\u7f16\u8bd1\u5668\u5bc4\u5b58\u5668\u5206\u914d\u4ecd\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u6bcf\u4ee3\u786c\u4ef6\u90fd\u9700\u5927\u91cf\u91cd\u65b0\u8c03\u6574\u3002\u7f3a\u4e4f\u6cdb\u5316\u548c\u81ea\u52a8\u9a8c\u8bc1\u80fd\u529b\uff0c\u9650\u5236\u4e86\u7f16\u8bd1\u5668\u6548\u7387\u548c\u79fb\u690d\u6027\u3002", "method": "\u63d0\u51fa\u4e86VeriLocc\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u5f62\u5f0f\u5316\u7f16\u8bd1\u5668\u6280\u672f\uff0c\u901a\u8fc7\u5bf9LLM\u8fdb\u884c\u5fae\u8c03\uff0c\u8ba9\u5176\u5c06\u4e2d\u95f4\u8868\u793a\uff08MIR\uff09\u7ffb\u8bd1\u4e3a\u76ee\u6807\u786c\u4ef6\u7684\u5bc4\u5b58\u5668\u5206\u914d\u3002\u91c7\u7528\u9759\u6001\u5206\u6790\u5b9e\u73b0\u8de8\u67b6\u6784\u5f52\u4e00\u5316\u4e0e\u6cdb\u5316\uff0c\u5f15\u5165\u9a8c\u8bc1\u5668\u6307\u5bfc\u7684\u518d\u751f\u6210\u5faa\u73af\u786e\u4fdd\u5206\u914d\u7684\u6b63\u786e\u6027\u3002", "result": "\u5728\u77e9\u9635\u4e58\u6cd5\uff08GEMM\uff09\u4e0e\u591a\u5934\u6ce8\u610f\u529b\uff08MHA\uff09\u6d4b\u8bd5\u4e2d\uff0cVeriLocc\u4e00\u6b21\u6027\u5206\u914d\u51c6\u786e\u7387\u8fbe85-99%\uff0c100\u6b21\u518d\u751f\u6210\u51e0\u4e4e100%\u6b63\u786e\u3002\u6848\u4f8b\u5206\u6790\u8868\u660e\uff0cVeriLocc\u751f\u6210\u7684\u5bc4\u5b58\u5668\u5206\u914d\u4f18\u4e8e\u4e13\u5bb6\u8c03\u4f18\u5e93\uff0c\u77e9\u9635\u4e58\u6cd5\u6bd4rocBLAS\u5e93\u8fd0\u884c\u65f6\u95f4\u5feb10%\u4ee5\u4e0a\u3002", "conclusion": "LLM\u4e0e\u5f62\u5f0f\u5316\u7f16\u8bd1\u5668\u6280\u672f\u7ed3\u5408\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u3001\u6cdb\u5316\u3001\u53ef\u9a8c\u8bc1\u7684GPU\u5bc4\u5b58\u5668\u5206\u914d\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u4e14\u63d0\u5347\u6027\u80fd\u3002VeriLocc\u80fd\u8d85\u8d8a\u4f20\u7edf\u4e13\u5bb6\u8c03\u4f18\u65b9\u6cd5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.17792", "categories": ["cs.AI", "cs.LO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.17792", "abs": "https://arxiv.org/abs/2506.17792", "authors": ["Alexandros Evangelidis", "Gricel V\u00e1zquez", "Simos Gerasimou"], "title": "Efficient Strategy Synthesis for MDPs via Hierarchical Block Decomposition", "comment": null, "summary": "Software-intensive systems, such as software product lines and robotics,\nutilise Markov decision processes (MDPs) to capture uncertainty and analyse\nsequential decision-making problems. Despite the usefulness of conventional\npolicy synthesis methods, they fail to scale to large state spaces. Our\napproach addresses this issue and accelerates policy synthesis in large MDPs by\ndynamically refining the MDP and iteratively selecting the most fragile MDP\nregions for refinement. This iterative procedure offers a balance between\naccuracy and efficiency, as refinement occurs only when necessary. Through a\ncomprehensive empirical evaluation comprising diverse case studies and MDPs up\nto 1M states, we demonstrate significant performance improvements yielded by\nour approach compared to the leading probabilistic model checker PRISM (up to\n2x), thus offering a very competitive solution for real-world policy synthesis\ntasks in larger MDPs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u5927\u89c4\u6a21\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u7684\u5feb\u901f\u653f\u7b56\u7efc\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u7ec6\u5316\u548c\u805a\u7126\u5173\u952e\u533a\u57df\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5904\u7406\u901f\u5ea6\uff0c\u6bd4\u4e3b\u6d41\u5de5\u5177PRISM\u5feb2\u500d\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u590d\u6742\u7cfb\u7edf\u7684\u51b3\u7b56\u5206\u6790\u3002", "motivation": "\u4f20\u7edf\u7684\u653f\u7b56\u7efc\u5408\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u72b6\u6001\u7a7a\u95f4\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u65f6\uff0c\u4e0d\u6613\u6269\u5c55\uff0c\u6548\u7387\u4f4e\u4e0b\u3002\u8f6f\u4ef6\u5bc6\u96c6\u578b\u7cfb\u7edf\uff08\u5982\u8f6f\u4ef6\u4ea7\u54c1\u7ebf\u548c\u673a\u5668\u4eba\uff09\u9700\u8981\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u548c\u5e8f\u8d2f\u51b3\u7b56\u95ee\u9898\uff0c\u56e0\u6b64\u9ad8\u6548\u7684MDP\u5904\u7406\u65b9\u6cd5\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u7ec6\u5316MDP\uff0c\u5e76\u8fed\u4ee3\u9009\u62e9\u6700\u8106\u5f31\u7684MDP\u533a\u57df\u8fdb\u884c\u7cbe\u7ec6\u5316\uff0c\u6bcf\u6b21\u4ec5\u5728\u5fc5\u8981\u65f6\u624d\u8fdb\u884c\u7ec6\u5316\u5316\uff0c\u65e8\u5728\u6743\u8861\u51c6\u786e\u6027\u4e0e\u6548\u7387\uff0c\u4ece\u800c\u52a0\u901f\u5927\u89c4\u6a21MDP\u7684\u653f\u7b56\u7efc\u5408\u3002", "result": "\u5728\u5305\u542b\u591a\u79cd\u6848\u4f8b\u548c\u591a\u8fbe100\u4e07\u4e2a\u72b6\u6001\u7684MDP\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u8bc1\u8bc4\u4f30\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u6bd4\u9886\u5148\u7684\u6982\u7387\u6a21\u578b\u68c0\u6d4b\u5668PRISM\u5feb\u81f32\u500d\uff0c\u663e\u793a\u51fa\u5728\u66f4\u5927\u89c4\u6a21MDP\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u5f3a\u5927\u7ade\u4e89\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5927\u89c4\u6a21MDP\u653f\u7b56\u7efc\u5408\u4efb\u52a1\u7684\u6548\u7387\uff0c\u5728\u51c6\u786e\u7387\u4e0e\u901f\u5ea6\u4e4b\u95f4\u53d6\u5f97\u4e86\u8f83\u597d\u5e73\u8861\uff0c\u4e3a\u5b9e\u9645\u4e2d\u9700\u8981\u5e94\u5bf9\u66f4\u5927\u72b6\u6001\u7a7a\u95f4\u7684MDP\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u529b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.18045", "categories": ["cs.CY", "cs.AI", "cs.CL", "K.4; I.2.7; I.2.0"], "pdf": "https://arxiv.org/pdf/2506.18045", "abs": "https://arxiv.org/abs/2506.18045", "authors": ["I. Loaiza", "R. Vestrelli", "A. Fronzetti Colladon", "R. Rigobon"], "title": "The Democratic Paradox in Large Language Models' Underestimation of Press Freedom", "comment": null, "summary": "As Large Language Models (LLMs) increasingly mediate global information\naccess for millions of users worldwide, their alignment and biases have the\npotential to shape public understanding and trust in fundamental democratic\ninstitutions, such as press freedom. In this study, we uncover three systematic\ndistortions in the way six popular LLMs evaluate press freedom in 180 countries\ncompared to expert assessments of the World Press Freedom Index (WPFI). The six\nLLMs exhibit a negative misalignment, consistently underestimating press\nfreedom, with individual models rating between 71% to 93% of countries as less\nfree. We also identify a paradoxical pattern we term differential misalignment:\nLLMs disproportionately underestimate press freedom in countries where it is\nstrongest. Additionally, five of the six LLMs exhibit positive home bias,\nrating their home countries' press freedoms more favorably than would be\nexpected given their negative misalignment with the human benchmark. In some\ncases, LLMs rate their home countries between 7% to 260% more positively than\nexpected. If LLMs are set to become the next search engines and some of the\nmost important cultural tools of our time, they must ensure accurate\nrepresentations of the state of our human and civic rights globally.", "AI": {"tldr": "\u4e3b\u6d41\u5927\u578b\u8bed\u8a00\u6a21\u578b\u666e\u904d\u4f4e\u4f30\u5168\u7403\u65b0\u95fb\u81ea\u7531\u72b6\u51b5\uff0c\u4e14\u5bf9\u672c\u56fd\u65b0\u95fb\u81ea\u7531\u6709\u660e\u663e\u9ad8\u4f30\u503e\u5411\u3002\u7814\u7a76\u63ed\u793a\u4e86\u4e09\u79cd\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u8bf4\u660eLLMs\u5728\u6210\u4e3a\u4e3b\u6d41\u4fe1\u606f\u5de5\u5177\u524d\u9700\u6539\u8fdb\u5176\u516c\u6b63\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6b63\u5728\u6210\u4e3a\u5168\u7403\u6570\u4ee5\u767e\u4e07\u8ba1\u7528\u6237\u7684\u4fe1\u606f\u83b7\u53d6\u4e2d\u4ecb\uff0c\u5176\u5728\u65b0\u95fb\u81ea\u7531\u7b49\u57fa\u7840\u6c11\u4e3b\u673a\u6784\u4e0a\u7684\u4ef7\u503c\u89c2\u548c\u504f\u89c1\u4f1a\u5f71\u54cd\u5168\u7403\u8206\u8bba\u4e0e\u516c\u4f17\u4fe1\u4efb\u3002\u8be5\u7814\u7a76\u610f\u5728\u63ed\u793aLLMs\u5728\u8bc4\u4f30\u65b0\u95fb\u81ea\u7531\u65f6\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5b58\u5728\u7684\u504f\u5dee\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u504f\u5dee\u5bf9\u793e\u4f1a\u53ef\u80fd\u4ea7\u751f\u7684\u5f71\u54cd\u3002", "method": "\u4f5c\u8005\u5206\u6790\u4e86\u516d\u6b3e\u4e3b\u6d41LLM\uff0c\u5bf9\u4e8e180\u4e2a\u56fd\u5bb6\u7684\u65b0\u95fb\u81ea\u7531\u72b6\u51b5\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u4e0e\u4e16\u754c\u65b0\u95fb\u81ea\u7531\u6307\u6570\uff08WPFI\uff09\u4e13\u5bb6\u8bc4\u5224\u8fdb\u884c\u4e86\u7cfb\u7edf\u5bf9\u6bd4\uff0c\u8bc6\u522b\u6a21\u578b\u4e2d\u7684\u7cfb\u7edf\u6027\u5931\u771f\u548c\u504f\u89c1\u6a21\u5f0f\u3002", "result": "\u516d\u6b3eLLM\u5168\u90e8\u5b58\u5728\u8d1f\u9762\u9519\u4f4d\uff0c\u5373\u666e\u904d\u4f4e\u4f30\u65b0\u95fb\u81ea\u7531\uff1b\u5177\u4f53\u8868\u73b0\u4e3a\u8fd9\u4e9b\u6a21\u578b\u5c0671%\u81f393%\u7684\u56fd\u5bb6\u8bc4\u4e3a\u201c\u65b0\u95fb\u4e0d\u81ea\u7531\u201d\u6216\u4f4e\u4e8e\u4e13\u5bb6\u8bc4\u4ef7\u3002\u4f5c\u8005\u8fd8\u53d1\u73b0\u201c\u5dee\u5f02\u6027\u9519\u4f4d\u201d\uff0c\u5373\u5728\u65b0\u95fb\u81ea\u7531\u5ea6\u9ad8\u7684\u56fd\u5bb6\uff0cLLMs\u5f80\u5f80\u4f4e\u4f30\u66f4\u4e25\u91cd\u3002\u6b64\u5916\uff0c\u5927\u591a\u6570LLM\u5bf9\u5176\u201c\u6bcd\u56fd\u201d\u8868\u73b0\u51fa\u79ef\u6781\u672c\u571f\u504f\u89c1\uff0c\u7ed9\u6bcd\u56fd\u6253\u5206\u9ad8\u4e8e\u5168\u7403\u57fa\u51c6\uff0c\u90e8\u5206\u6a21\u578b\u751a\u81f3\u9ad8\u51fa7%\u81f3260%\u3002", "conclusion": "\u5982LLMs\u53d1\u5c55\u6210\u4e3a\u4e3b\u6d41\u4fe1\u606f\u641c\u7d22\u548c\u6587\u5316\u5de5\u5177\uff0c\u5176\u8868\u73b0\u7684\u4eba\u6743\u4e0e\u516c\u6c11\u6743\u5229\u8bc4\u5224\u5931\u771f\u95ee\u9898\u4e9f\u9700\u5173\u6ce8\u5e76\u6539\u8fdb\uff0c\u5426\u5219\u5c06\u8bef\u5bfc\u516c\u4f17\u5bf9\u65b0\u95fb\u81ea\u7531\u548c\u6c11\u4e3b\u5236\u5ea6\u7684\u8ba4\u77e5\u3002"}}
{"id": "2506.18586", "categories": ["cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18586", "abs": "https://arxiv.org/abs/2506.18586", "authors": ["Zijie Yang", "Qiji Zhou", "Fang Guo", "Sijie Zhang", "Yexun Xi", "Jinglei Nie", "Yudian Zhu", "Liping Huang", "Chou Wu", "Yonghe Xia", "Xiaoyu Ma", "Yingming Pu", "Panzhong Lu", "Junshu Pan", "Mingtao Chen", "Tiannan Guo", "Yanmei Dou", "Hongyu Chen", "Anping Zeng", "Jiaxing Huang", "Tian Xu", "Yue Zhang"], "title": "Airalogy: AI-empowered universal data digitization for research automation", "comment": "146 pages, 6 figures, 49 supplementary figures", "summary": "Research data are the foundation of Artificial Intelligence (AI)-driven\nscience, yet current AI applications remain limited to a few fields with\nreadily available, well-structured, digitized datasets. Achieving comprehensive\nAI empowerment across multiple disciplines is still out of reach. Present-day\nresearch data collection is often fragmented, lacking unified standards,\ninefficiently managed, and difficult to share. Creating a single platform for\nstandardized data digitization needs to overcome the inherent challenge of\nbalancing between universality (supporting the diverse, ever-evolving needs of\nvarious disciplines) and standardization (enforcing consistent formats to fully\nenable AI). No existing platform accommodates both facets. Building a truly\nmultidisciplinary platform requires integrating scientific domain knowledge\nwith sophisticated computing skills. Researchers often lack the computational\nexpertise to design customized and standardized data recording methods, whereas\nplatform developers rarely grasp the intricate needs of multiple scientific\ndomains. These gaps impede research data standardization and hamper AI-driven\nprogress. In this study, we address these challenges by developing Airalogy\n(https://airalogy.com), the world's first AI- and community-driven platform\nthat balances universality and standardization for digitizing research data\nacross multiple disciplines. Airalogy represents entire research workflows\nusing customizable, standardized data records and offers an advanced AI\nresearch copilot for intelligent Q&A, automated data entry, analysis, and\nresearch automation. Already deployed in laboratories across all four schools\nof Westlake University, Airalogy has the potential to accelerate and automate\nscientific innovation in universities, industry, and the global research\ncommunity-ultimately benefiting humanity as a whole.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86Airalogy\u5e73\u53f0\uff0c\u901a\u8fc7AI\u548c\u793e\u533a\u534f\u540c\uff0c\u9996\u6b21\u517c\u987e\u6570\u636e\u6807\u51c6\u5316\u4e0e\u591a\u5b66\u79d1\u901a\u7528\u6027\uff0c\u6709\u6548\u63a8\u52a8\u4e86\u79d1\u7814\u6570\u636e\u6570\u5b57\u5316\uff0c\u5e76\u5df2\u5728\u591a\u5b66\u79d1\u5b9e\u9a8c\u5ba4\u5e94\u7528\uff0c\u5c55\u73b0\u52a0\u901f\u79d1\u7814\u521b\u65b0\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u9636\u6bb5AI\u79d1\u7814\u53d7\u9650\u4e8e\u6570\u636e\u5b64\u5c9b\u3001\u6807\u51c6\u4e0d\u7edf\u4e00\u3001\u7ba1\u7406\u4f4e\u6548\u3001\u8de8\u5b66\u79d1\u96be\u517c\u5bb9\u7b49\u95ee\u9898\u3002\u7f3a\u4e4f\u4e00\u4e2a\u80fd\u517c\u5bb9\u591a\u5b66\u79d1\u3001\u591a\u6837\u5316\u9700\u6c42\u5e76\u5b9e\u73b0\u9ad8\u6807\u51c6\u5316\u7684\u6570\u636e\u5e73\u53f0\uff0c\u5236\u7ea6\u4e86AI\u5bf9\u79d1\u7814\u7684\u5168\u9762\u63a8\u52a8\u3002", "method": "\u901a\u8fc7\u7814\u53d1\u5e76\u4e0a\u7ebfAiralogy\u5e73\u53f0\uff0c\u7ed3\u5408\u53ef\u81ea\u5b9a\u4e49\u4e0e\u6807\u51c6\u5316\u7684\u6570\u636e\u8bb0\u5f55\u3001AI\u7814\u7a76\u52a9\u624b\u3001\u667a\u80fd\u95ee\u7b54\u3001\u81ea\u52a8\u6570\u636e\u5f55\u5165\u4e0e\u5206\u6790\u7b49\u529f\u80fd\uff0c\u89e3\u51b3\u4e86\u591a\u5b66\u79d1\u6570\u636e\u6807\u51c6\u5316\u4e0e\u901a\u7528\u6027\u4e4b\u95f4\u7684\u77db\u76fe\u3002", "result": "Airalogy\u5e73\u53f0\u6210\u529f\u5728\u591a\u4e2a\u5b66\u79d1\u5b9e\u9a8c\u5ba4\u843d\u5730\uff0c\u652f\u6301\u6807\u51c6\u5316\u548c\u901a\u7528\u6027\u7684\u6570\u636e\u5f55\u5165\u3001\u7ba1\u7406\u548cAI\u9a71\u52a8\u7684\u7814\u7a76\u5de5\u4f5c\uff0c\u5c55\u73b0\u51fa\u5bf9\u63a8\u52a8\u79d1\u7814\u521b\u65b0\u4e0e\u81ea\u52a8\u5316\u7684\u5de8\u5927\u6f5c\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Airalogy\u5e73\u53f0\u9996\u6b21\u5b9e\u73b0\u4e86\u5728\u591a\u5b66\u79d1\u7814\u7a76\u9886\u57df\u95f4\u517c\u987e\u901a\u7528\u6027\u4e0e\u6807\u51c6\u5316\u7684\u6570\u636e\u6570\u5b57\u5316\uff0c\u63a8\u52a8\u4e86AI\u8d4b\u80fd\u79d1\u7814\u7684\u53ef\u884c\u6027\u3002\u5e73\u53f0\u5df2\u5728\u591a\u4e2a\u5b9e\u9a8c\u5ba4\u90e8\u7f72\uff0c\u5e76\u5c55\u793a\u4e86\u52a0\u901f\u81ea\u52a8\u5316\u79d1\u5b66\u521b\u65b0\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.17525", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17525", "abs": "https://arxiv.org/abs/2506.17525", "authors": ["Mingfei Lau", "Qian Chen", "Yeming Fang", "Tingting Xu", "Tongzhou Chen", "Pavel Golik"], "title": "Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning", "comment": "Accepted by ACL 2025 Main Conference", "summary": "Our quality audit for three widely used public multilingual speech datasets -\nMozilla Common Voice 17.0, FLEURS, and VoxPopuli - shows that in some\nlanguages, these datasets suffer from significant quality issues. We believe\naddressing these issues will make these datasets more useful as training and\nevaluation sets, and improve downstream models. We divide these quality issues\ninto two categories: micro-level and macro-level. We find that macro-level\nissues are more prevalent in less institutionalized, often under-resourced\nlanguages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that\nhighlights the need for proactive language planning (e.g. orthography\nprescriptions, dialect boundary definition) and enhanced data quality control\nin the process of Automatic Speech Recognition (ASR) dataset creation. We\nconclude by proposing guidelines and recommendations to mitigate these issues\nin future dataset development, emphasizing the importance of sociolinguistic\nawareness in creating robust and reliable speech data resources.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u4e09\u5927\u591a\u8bed\u79cd\u8bed\u97f3\u6570\u636e\u96c6\u8fdb\u884c\u8d28\u91cf\u5ba1\u67e5\uff0c\u6307\u51fa\u8d44\u6e90\u7a00\u7f3a\u8bed\u8a00\u5b58\u5728\u4e25\u91cd\u8d28\u91cf\u95ee\u9898\u3002\u4ee5\u53f0\u7063\u95a9\u5357\u8a9e\u4e3a\u4f8b\uff0c\u5f3a\u8c03\u89c4\u8303\u5316\u4e0e\u6570\u636e\u7ba1\u63a7\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\uff0c\u547c\u5401\u589e\u5f3a\u793e\u4f1a\u8bed\u8a00\u5b66\u610f\u8bc6\u4ee5\u63d0\u5347\u6570\u636e\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u5e7f\u6cdb\u4f7f\u7528\u7684\u591a\u8bed\u79cd\u8bed\u97f3\u6570\u636e\u96c6\u5728\u90e8\u5206\u8bed\u8a00\u4e0a\u5b58\u5728\u663e\u8457\u8d28\u91cf\u95ee\u9898\uff0c\u5c24\u5176\u5f71\u54cd\u8bad\u7ec3\u548c\u8bc4\u4f30\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u6a21\u578b\u7684\u53ef\u9760\u6027\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u5ba1\u89c6\u5e76\u63d0\u5347\u6570\u636e\u96c6\u8d28\u91cf\u3002", "method": "\u5bf9Mozilla Common Voice 17.0\u3001FLEURS\u548cVoxPopuli\u4e09\u5927\u516c\u5f00\u591a\u8bed\u79cd\u8bed\u97f3\u6570\u636e\u96c6\u8fdb\u884c\u8d28\u91cf\u5ba1\u8ba1\uff0c\u5c06\u53d1\u73b0\u7684\u95ee\u9898\u5206\u4e3a\u5fae\u89c2\u548c\u5b8f\u89c2\u4e24\u4e2a\u5c42\u9762\uff0c\u5e76\u4ee5\u53f0\u7063\u95a9\u5357\u8a9e\uff08nan_tw\uff09\u4e3a\u6848\u4f8b\uff0c\u5206\u6790\u5177\u4f53\u8bed\u6599\u95ee\u9898\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "result": "\u53d1\u73b0\u8f83\u5c11\u53d7\u673a\u6784\u652f\u6301\u3001\u8d44\u6e90\u7a00\u7f3a\u8bed\u8a00\u7684\u6570\u636e\u96c6\u5b8f\u89c2\u8d28\u91cf\u95ee\u9898\u66f4\u4e3a\u4e25\u91cd\uff0c\u7279\u522b\u662f\u5728\u6b63\u5b57\u6cd5\u4e0e\u65b9\u8a00\u8fb9\u754c\u754c\u5b9a\u53ca\u6570\u636e\u8d28\u91cf\u7ba1\u63a7\u65b9\u9762\u5b58\u5728\u660e\u663e\u7f3a\u9677\u3002\u901a\u8fc7\u53f0\u7063\u95a9\u5357\u8a9e\u6848\u4f8b\uff0c\u51f8\u663e\u4e86\u4e3b\u52a8\u8bed\u8a00\u89c4\u5212\u4e0e\u6570\u636e\u8d28\u91cf\u63d0\u5347\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u4e3a\u672a\u6765\u8bed\u97f3\u6570\u636e\u96c6\u5f00\u53d1\u63d0\u51fa\u4e86\u5177\u4f53\u51c6\u5219\u548c\u5efa\u8bae\uff0c\u5021\u5bfc\u5728\u6570\u636e\u96c6\u6784\u5efa\u8fc7\u7a0b\u4e2d\u589e\u5f3a\u793e\u4f1a\u8bed\u8a00\u5b66\u610f\u8bc6\uff0c\u4ece\u800c\u63d0\u5347\u8bed\u97f3\u8d44\u6e90\u7684\u7a33\u5065\u6027\u4e0e\u53ef\u9760\u6027\u3002"}}
{"id": "2506.17834", "categories": ["cs.AI", "cs.HC", "I.2.6; H.5.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.17834", "abs": "https://arxiv.org/abs/2506.17834", "authors": ["Carter Blair", "Kate Larson", "Edith Law"], "title": "Reflective Verbal Reward Design for Pluralistic Alignment", "comment": "9 pages, 3 figures, accepted to the IJCAI 2025 Human-Centred AI\n  track. Project repository at: https://osf.io/8yxf2/", "summary": "AI agents are commonly aligned with \"human values\" through reinforcement\nlearning from human feedback (RLHF), where a single reward model is learned\nfrom aggregated human feedback and used to align an agent's behavior. However,\nhuman values are not homogeneous--different people hold distinct and sometimes\nconflicting values. Aggregating feedback into a single reward model risks\ndisproportionately suppressing minority preferences. To address this, we\npresent a novel reward modeling approach for learning individualized reward\nmodels. Our approach uses a language model to guide users through reflective\ndialogues where they critique agent behavior and construct their preferences.\nThis personalized dialogue history, containing the user's reflections and\ncritiqued examples, is then used as context for another language model that\nserves as an individualized reward function (what we call a \"verbal reward\nmodel\") for evaluating new trajectories. In studies with 30 participants, our\nmethod achieved a 9-12% improvement in accuracy over non-reflective verbal\nreward models while being more sample efficient than traditional supervised\nlearning methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7528\u6237\u53cd\u601d\u5bf9\u8bdd\u7684\u4e2a\u6027\u5316\u5956\u52b1\u6a21\u578b\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u597d\u5730\u53cd\u6620\u4e0d\u540c\u4e2a\u4f53\u7684\u4ef7\u503c\u89c2\uff0c\u5b9e\u9a8c\u663e\u793a\u51c6\u786e\u7387\u548c\u6570\u636e\u6548\u7387\u5747\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41RLHF\u901a\u8fc7\u805a\u5408\u4eba\u7c7b\u53cd\u9988\u751f\u6210\u5355\u4e00\u5956\u52b1\u6a21\u578b\uff0c\u4f46\u5ffd\u89c6\u4e86\u4eba\u7c7b\u4ef7\u503c\u7684\u591a\u6837\u4e0e\u5dee\u5f02\uff0c\u53ef\u80fd\u5bfc\u81f4\u5c11\u6570\u7fa4\u4f53\u504f\u597d\u88ab\u5ffd\u7565\u3002\u8fd9\u9700\u8981\u6709\u65b9\u6cd5\u5b9e\u73b0\u5956\u52b1\u6a21\u578b\u7684\u4e2a\u6027\u5316\uff0c\u5bf9\u4e0d\u540c\u7528\u6237\u7684\u4ef7\u503c\u89c2\u505a\u51fa\u533a\u5206\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5f15\u5bfc\u7528\u6237\u8fdb\u884c\u53cd\u601d\u6027\u5bf9\u8bdd\uff0c\u6536\u96c6\u5176\u5bf9AI\u884c\u4e3a\u7684\u8bc4\u4ef7\u4e0e\u504f\u597d\uff0c\u5f62\u6210\u5bf9\u8bdd\u5386\u53f2\u3002\u4e4b\u540e\u5c06\u8be5\u5386\u53f2\u4f5c\u4e3a\u4e0a\u4e0b\u6587\uff0c\u8bad\u7ec3\u53e6\u4e00\u4e2a\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e2a\u6027\u5316\u5956\u52b1\u51fd\u6570\uff08\u79f0\u4e3a\u201cverbal reward model\u201d\uff09\uff0c\u7528\u4e8e\u8bc4\u4ef7\u65b0\u7684AI\u884c\u4e3a\u8f68\u8ff9\u3002", "result": "\u4e0e\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u4e2a\u6027\u5316\u53cd\u601d\u5bf9\u8bdd\u6cd5\u6a21\u578b\u5bf9\u7528\u6237\u884c\u4e3a\u7406\u89e3\u51c6\u786e\u7387\u63d0\u53479-12%\uff0c\u4e14\u6837\u672c\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e2a\u6027\u5316\u7684\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u53cd\u601d\u6027\u5bf9\u8bdd\u5386\u53f2\u751f\u6210\u4e2a\u4eba\u5316\u5956\u52b1\u51fd\u6570\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2506.18133", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2506.18133", "abs": "https://arxiv.org/abs/2506.18133", "authors": ["Jessica Dai", "Inioluwa Deborah Raji", "Benjamin Recht", "Irene Y. Chen"], "title": "Aggregated Individual Reporting for Post-Deployment Evaluation", "comment": null, "summary": "The need for developing model evaluations beyond static benchmarking,\nespecially in the post-deployment phase, is now well-understood. At the same\ntime, concerns about the concentration of power in deployed AI systems have\nsparked a keen interest in 'democratic' or 'public' AI. In this work, we bring\nthese two ideas together by proposing mechanisms for aggregated individual\nreporting (AIR), a framework for post-deployment evaluation that relies on\nindividual reports from the public. An AIR mechanism allows those who interact\nwith a specific, deployed (AI) system to report when they feel that they may\nhave experienced something problematic; these reports are then aggregated over\ntime, with the goal of evaluating the relevant system in a fine-grained manner.\nThis position paper argues that individual experiences should be understood as\nan integral part of post-deployment evaluation, and that the scope of our\nproposed aggregated individual reporting mechanism is a practical path to that\nend. On the one hand, individual reporting can identify substantively novel\ninsights about safety and performance; on the other, aggregation can be\nuniquely useful for informing action. From a normative perspective, the\npost-deployment phase completes a missing piece in the conversation about\n'democratic' AI. As a pathway to implementation, we provide a workflow of\nconcrete design decisions and pointers to areas requiring further research and\nmethodological development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\uff0c\u5c06\u516c\u4f17\u7528\u6237\u7684\u4e2a\u4f53\u62a5\u544a\u805a\u5408\u4f5c\u4e3aAI\u7cfb\u7edf\u90e8\u7f72\u540e\u52a8\u6001\u8bc4\u4f30\u7684\u65b0\u673a\u5236\uff08AIR\uff09\uff0c\u65e2\u63d0\u5347AI\u5b89\u5168\u548c\u6027\u80fd\u53d1\u73b0\uff0c\u4e5f\u63a8\u52a8\u4e86\u201c\u6c11\u4e3b\u5316\u201dAI\u76d1\u7ba1\uff0c\u63d0\u4f9b\u6709\u5b9e\u8df5\u8def\u5f84\u548c\u7814\u7a76\u6307\u5f15\u3002", "motivation": "\u8fd1\u5e74\u6765\u4eba\u4eec\u5bf9AI\u7cfb\u7edf\u90e8\u7f72\u540e\u5982\u4f55\u8fdb\u884c\u8bc4\u4f30\u4ee5\u53ca\u5982\u4f55\u5b9e\u73b0\u201c\u6c11\u4e3b\u201d\u6216\u201c\u516c\u4f17\u53c2\u4e0e\u201d\u7684AI\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\u3002\u73b0\u6709\u9759\u6001\u57fa\u51c6\u8bc4\u6d4b\u65e0\u6cd5\u6ee1\u8db3\u771f\u5b9e\u73af\u5883\u4e0b\u590d\u6742\u53d8\u5316\u548c\u4e2a\u4f53\u4f53\u9a8c\u7684\u53cd\u9988\u9700\u6c42\u3002\u4f5c\u8005\u5e0c\u671b\u5f25\u8865\u8fd9\u4e00\u8bc4\u4f30\u76f2\u533a\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e2a\u4f53\u516c\u4f17\u62a5\u544a\u6c47\u603b\u7684\u540e\u90e8\u7f72\u8bc4\u4f30\u673a\u5236\uff08Aggregated Individual Reporting, AIR\uff09\uff0c\u5177\u4f53\u505a\u6cd5\u662f\u8ba9\u4f7f\u7528\u8fc7\u67d0AI\u7cfb\u7edf\u7684\u7528\u6237\u76f4\u63a5\u62a5\u544a\u4ed6\u4eec\u9047\u5230\u7684\u95ee\u9898\uff0c\u518d\u5c06\u8fd9\u4e9b\u4e2a\u4f53\u62a5\u544a\u957f\u671f\u6c47\u603b\u5206\u6790\uff0c\u4ee5\u7ec6\u81f4\u8bc4\u4f30\u7cfb\u7edf\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u5177\u4f53\u8bbe\u8ba1\u6d41\u7a0b\u548c\u540e\u7eed\u65b9\u6cd5\u5b66\u53d1\u5c55\u7684\u9700\u6c42\u3002", "result": "\u4e2a\u4f53\u62a5\u544a\u80fd\u5e26\u6765\u5bf9AI\u5b89\u5168\u4e0e\u6027\u80fd\u5177\u6709\u91cd\u8981\u4ef7\u503c\u7684\u65b0\u53d1\u73b0\uff0c\u800c\u62a5\u544a\u7684\u6c47\u603b\u53c8\u80fd\u6709\u6548\u6307\u5bfc\u5b9e\u9645\u64cd\u4f5c\u3002\u6b64\u6846\u67b6\u4e3a\u201c\u6c11\u4e3b\u5316\u201dAI\u63d0\u4f9b\u4e86\u5207\u5b9e\u53ef\u884c\u7684\u89e3\u51b3\u8def\u5f84\uff0c\u5e76\u6709\u52a9\u4e8e\u5b8c\u5584AI\u7cfb\u7edf\u76d1\u7ba1\u548c\u8bc4\u4f30\u7684\u7406\u8bba\u4e0e\u5b9e\u8df5\u4f53\u7cfb\u3002", "conclusion": "\u4f5c\u8005\u8ba4\u4e3a\uff0c\u4e2a\u4f53\u4f53\u9a8c\u5e94\u6210\u4e3aAI\u540e\u90e8\u7f72\u9636\u6bb5\u8bc4\u4f30\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0cAIR\u673a\u5236\u65e2\u80fd\u4e30\u5bcc\u8bc4\u4f30\u4fe1\u606f\u6765\u6e90\uff0c\u4e5f\u6709\u52a9\u4e8e\u5b9e\u73b0\u66f4\u52a0\u2018\u6c11\u4e3b\u2019\u548c\u8d1f\u8d23\u4efb\u7684AI\u53d1\u5c55\u3002\u8bba\u6587\u8fd8\u63d0\u51fa\u4e86\u5177\u4f53\u7684\u5b9e\u65bd\u601d\u8def\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.17533", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17533", "abs": "https://arxiv.org/abs/2506.17533", "authors": ["Yuanhao Wu", "Juntong Song", "Hanning Zhang", "Tong Zhang", "Cheng Niu"], "title": "DuaShepherd: Integrating Stepwise Correctness and Potential Rewards for Mathematical Reasoning", "comment": null, "summary": "In this paper, we propose DuaShepherd, a novel reward modeling framework that\nintegrates two complementary reward signals, correctness and potential, to\nenhance the mathematical reasoning capabilities of Large Language Models\n(LLMs). While correctness-based signals emphasize identification of stepwise\nerrors, potential-based signals focus on the likelihood of reaching the correct\nfinal answer. We developed an automated pipeline for constructing large-scale\nreward modeling dataset with both signals. A unified, multi-head architecture\nwas explored to train the two reward models in a multi-task setup,\ndemonstrating benefits from learning both correctness and potential in\nparallel. By combining these two signals into a compound probability, our model\nachieves consistent performance improvements across multiple benchmarks.\nEmpirical evaluations on MATH500 and ProcessBench confirm that this combined\nreward significantly outperforms models trained on either reward type alone,\nachieving state-of-the-art performance under comparable resource constraints.", "AI": {"tldr": "\u63d0\u51faDuaShepherd\u6846\u67b6\uff0c\u5c06\u6b63\u786e\u6027\u4e0e\u6f5c\u529b\u5956\u52b1\u4fe1\u53f7\u7ed3\u5408\uff0c\u591a\u4efb\u52a1\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347LLM\u6570\u5b66\u63a8\u7406\u6027\u80fd\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u5355\u4e00\u4fe1\u53f7\uff08\u5982\u6b63\u786e\u6027\uff09\uff0c\u96be\u4ee5\u5168\u9762\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faDuaShepherd\u5956\u52b1\u5efa\u6a21\u6846\u67b6\uff0c\u96c6\u6210\u201c\u6b63\u786e\u6027\u201d\u548c\u201c\u6f5c\u529b\u201d\u53cc\u91cd\u5956\u52b1\u4fe1\u53f7\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6570\u636e\u96c6\u6784\u5efa\u4e0e\u591a\u4efb\u52a1\u3001\u591a\u5934\u7f51\u7edc\u5e76\u884c\u8bad\u7ec3\uff0c\u8054\u5408\u5efa\u6a21\u4e24\u79cd\u5956\u52b1\u4fe1\u53f7\u3002", "result": "\u5b9e\u9a8c\u5728MATH500\u548cProcessBench\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u53cc\u4fe1\u53f7\u7ed3\u5408\u8bad\u7ec3\u7684\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u4ec5\u7528\u4efb\u4e00\u5355\u4e00\u5956\u52b1\u4fe1\u53f7\uff0c\u8fbe\u5230\u540c\u7c7b\u6700\u4f18\u8868\u73b0\u3002", "conclusion": "DuaShepherd\u6846\u67b6\u5229\u7528\u6b63\u786e\u6027\u548c\u6f5c\u529b\u53cc\u91cd\u5956\u52b1\u4fe1\u53f7\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0a\u7684\u6301\u7eed\u63d0\u5347\u3002"}}
{"id": "2506.17846", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17846", "abs": "https://arxiv.org/abs/2506.17846", "authors": ["Elija Perrier"], "title": "Out of Control -- Why Alignment Needs Formal Control Theory (and an Alignment Control Stack)", "comment": "Under review for Neurips 2025", "summary": "This position paper argues that formal optimal control theory should be\ncentral to AI alignment research, offering a distinct perspective from\nprevailing AI safety and security approaches. While recent work in AI safety\nand mechanistic interpretability has advanced formal methods for alignment,\nthey often fall short of the generalisation required of control frameworks for\nother technologies. There is also a lack of research into how to render\ndifferent alignment/control protocols interoperable. We argue that by recasting\nalignment through principles of formal optimal control and framing alignment in\nterms of hierarchical stack from physical to socio-technical layers according\nto which controls may be applied we can develop a better understanding of the\npotential and limitations for controlling frontier models and agentic AI\nsystems. To this end, we introduce an Alignment Control Stack which sets out a\nhierarchical layered alignment stack, identifying measurement and control\ncharacteristics at each layer and how different layers are formally\ninteroperable. We argue that such analysis is also key to the assurances that\nwill be needed by governments and regulators in order to see AI technologies\nsustainably benefit the community. Our position is that doing so will bridge\nthe well-established and empirically validated methods of optimal control with\npractical deployment considerations to create a more comprehensive alignment\nframework, enhancing how we approach safety and reliability for advanced AI\nsystems.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u4ee5\u5f62\u5f0f\u5316\u6700\u4f18\u63a7\u5236\u7406\u8bba\u4e3a\u6838\u5fc3\u63a8\u8fdbAI\u5bf9\u9f50\u7814\u7a76\uff0c\u5e76\u63d0\u51fa\u201c\u5bf9\u9f50\u63a7\u5236\u6808\u201d\u6a21\u578b\uff0c\u5f3a\u8c03\u5404\u5bf9\u9f50\u5c42\u6b21\u95f4\u7684\u4e92\u64cd\u4f5c\u4e0e\u6cbb\u7406\u9700\u6c42\uff0c\u6709\u52a9\u4e8e\u63d0\u5347AI\u7684\u5b89\u5168\u4e0e\u5b9e\u8df5\u90e8\u7f72\u4fdd\u969c\u3002", "motivation": "\u5f53\u524dAI\u5b89\u5168\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u867d\u7136\u5728\u5f62\u5f0f\u5316\u65b9\u6cd5\u4e0a\u53d6\u5f97\u4e86\u4e00\u5b9a\u8fdb\u5c55\uff0c\u4f46\u6ca1\u6709\u8fbe\u5230\u63a7\u5236\u8bba\u5e94\u7528\u4e8e\u5176\u4ed6\u6280\u672f\u65f6\u6240\u9700\u7684\u5e7f\u6cdb\u6cdb\u5316\u80fd\u529b\uff0c\u4e14\u4e0d\u540c\u5bf9\u9f50/\u63a7\u5236\u534f\u8bae\u95f4\u7684\u4e92\u64cd\u4f5c\u6027\u7814\u7a76\u532e\u4e4f\u3002\u4f5c\u8005\u8ba4\u4e3a\u9700\u901a\u8fc7\u66f4\u7cfb\u7edf\u7684\u63a7\u5236\u6846\u67b6\u63a8\u8fdbAI\u5bf9\u9f50\u7814\u7a76\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u7528\u5f62\u5f0f\u6700\u4f18\u63a7\u5236\u7406\u8bba\u4f5c\u4e3aAI\u5bf9\u9f50\u7814\u7a76\u7684\u6838\u5fc3\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u201c\u5bf9\u9f50\u63a7\u5236\u6808\u201d\u6a21\u578b\uff0c\u5c06AI\u5bf9\u9f50\u5206\u4e3a\u4ece\u7269\u7406\u5c42\u5230\u793e\u4f1a\u6280\u672f\u5c42\u7684\u5206\u5c42\uff0c\u6bcf\u5c42\u5177\u6709\u72ec\u7279\u7684\u6d4b\u91cf\u548c\u63a7\u5236\u7279\u6027\uff0c\u5e76\u63a2\u8ba8\u5c42\u95f4\u7684\u5f62\u5f0f\u4e92\u64cd\u4f5c\u6027\u3002", "result": "\u63d0\u51fa\u201c\u5bf9\u9f50\u63a7\u5236\u6808\u201d\u8fd9\u4e00\u5206\u5c42\u6846\u67b6\uff0c\u660e\u786e\u5404\u5c42\u7684\u63a7\u5236\u5bf9\u8c61\u3001\u6d4b\u91cf\u65b9\u5f0f\u4e0e\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u5c55\u793a\u5982\u4f55\u5229\u7528\u6700\u4f18\u63a7\u5236\u7406\u8bba\u4e3aAI\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u66f4\u5f3a\u7684\u7406\u8bba\u57fa\u7840\u548c\u5de5\u7a0b\u4fdd\u969c\u3002", "conclusion": "\u5c06AI\u5bf9\u9f50\u95ee\u9898\u7cfb\u7edf\u5730\u7eb3\u5165\u6b63\u5f0f\u6700\u4f18\u63a7\u5236\u7406\u8bba\uff0c\u5e76\u901a\u8fc7\u201c\u5bf9\u9f50\u63a7\u5236\u6808\u201d\u6a21\u578b\uff0c\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u548c\u63a7\u5236\u524d\u6cbf\u6a21\u578b/\u4ee3\u7406\u6027AI\u7cfb\u7edf\u7684\u80fd\u529b\u4e0e\u5c40\u9650\uff0c\u6709\u52a9\u4e8e\u4e3a\u76d1\u7ba1\u4e0e\u5b89\u5168\u63d0\u4f9b\u7406\u8bba\u548c\u5b9e\u8df5\u4f9d\u636e\uff0c\u63d0\u5347AI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u4e0e\u53ef\u9760\u6027\u3002"}}
{"id": "2506.17542", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17542", "abs": "https://arxiv.org/abs/2506.17542", "authors": ["Nitin Venkateswaran", "Kevin Tang", "Ratree Wayland"], "title": "Probing for Phonology in Self-Supervised Speech Representations: A Case Study on Accent Perception", "comment": null, "summary": "Traditional models of accent perception underestimate the role of gradient\nvariations in phonological features which listeners rely upon for their accent\njudgments. We investigate how pretrained representations from current\nself-supervised learning (SSL) models of speech encode phonological\nfeature-level variations that influence the perception of segmental accent. We\nfocus on three segments: the labiodental approximant, the rhotic tap, and the\nretroflex stop, which are uniformly produced in the English of native speakers\nof Hindi as well as other languages in the Indian sub-continent. We use the\nCSLU Foreign Accented English corpus (Lander, 2007) to extract, for these\nsegments, phonological feature probabilities using Phonet (V\\'asquez-Correa et\nal., 2019) and pretrained representations from Wav2Vec2-BERT (Barrault et al.,\n2023) and WavLM (Chen et al., 2022) along with accent judgements by native\nspeakers of American English. Probing analyses show that accent strength is\nbest predicted by a subset of the segment's pretrained representation features,\nin which perceptually salient phonological features that contrast the expected\nAmerican English and realized non-native English segments are given prominent\nweighting. A multinomial logistic regression of pretrained representation-based\nsegment distances from American and Indian English baselines on accent ratings\nreveals strong associations between the odds of accent strength and distances\nfrom the baselines, in the expected directions. These results highlight the\nvalue of self-supervised speech representations for modeling accent perception\nusing interpretable phonological features.", "AI": {"tldr": "\u7814\u7a76\u8bc1\u660e\u81ea\u76d1\u7763\u8bed\u97f3\u6a21\u578b\uff08\u5982Wav2Vec2-BERT\u3001WavLM\uff09\u5728\u8868\u8fbe\u53e3\u97f3\u611f\u77e5\u6240\u9700\u7684\u53ef\u89e3\u91ca\u97f3\u7cfb\u7279\u5f81\u4e0a\u975e\u5e38\u6709\u6548\uff0c\u80fd\u63d0\u5347\u5bf9\u975e\u6bcd\u8bed\u8005\u82f1\u8bed\u53e3\u97f3\u5f3a\u5ea6\u7684\u9884\u6d4b\u4e0e\u89e3\u91ca\u80fd\u529b\uff0c\u5bf9\u53e3\u97f3\u8bc6\u522b\u548c\u5efa\u6a21\u6709\u91cd\u8981\u542f\u793a\u3002", "motivation": "\u4f20\u7edf\u53e3\u97f3\u611f\u77e5\u6a21\u578b\u4f4e\u4f30\u4e86\u542c\u8005\u8bc4\u5224\u53e3\u97f3\u65f6\u6240\u4f9d\u8d56\u7684\u97f3\u7cfb\u7279\u5f81\u68af\u5ea6\u5dee\u5f02\uff0c\u7f3a\u4e4f\u5bf9\u97f3\u7cfb\u5c42\u9762\u53d8\u5f02\u7684\u7cbe\u51c6\u523b\u753b\u3002\u81ea\u76d1\u7763\u8bed\u97f3\u6a21\u578b\u5728\u97f3\u7cfb\u5c42\u9762\u5efa\u6a21\u80fd\u529b\u5c1a\u672a\u660e\u6670\u3002", "method": "\u7814\u7a76\u5bf9\u6bd4\u4e86\u4e09\u79cd\u82f1\u8bed\u97f3\u6bb5\uff08\u5507\u9f7f\u8fd1\u97f3\u3001\u95ea\u97f3r\u548c\u5377\u820c\u585e\u97f3\uff09\u5728\u5370\u5ea6\u53ca\u6b21\u5927\u9646\u8bed\u8a00\u7684\u6bcd\u8bed\u8005\u82f1\u8bed\u53d1\u97f3\uff0c\u4e0e\u6807\u51c6\u7f8e\u5f0f\u82f1\u8bed\u7684\u5dee\u5f02\uff0c\u5229\u7528CSLU Foreign Accented English\u8bed\u6599\u5e93\uff0c\u5206\u522b\u7528Phonet\u5de5\u5177\u548cWav2Vec2-BERT\u3001WavLM\u7b49SSL\u6a21\u578b\u63d0\u53d6\u97f3\u6bb5\u7684\u97f3\u7cfb\u7279\u5f81\u6982\u7387\u548c\u9884\u8bad\u7ec3\u8868\u793a\uff0c\u901a\u8fc7\u7f8e\u5f0f\u82f1\u8bed\u6bcd\u8bed\u8005\u8fdb\u884c\u53e3\u97f3\u5224\u5b9a\uff0c\u5e76\u7528\u63a2\u6d4b\u5206\u6790\u53ca\u591a\u9879Logistic\u56de\u5f52\u91cf\u5316\u6a21\u578b\u7279\u5f81\u4e0e\u53e3\u97f3\u5f3a\u5ea6\u7684\u5173\u8054\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u53e3\u97f3\u5f3a\u5ea6\u6700\u80fd\u88ab\u90e8\u5206\u9884\u8bad\u7ec3\u8868\u793a\u7279\u5f81\u9884\u6d4b\uff0c\u8fd9\u4e9b\u7279\u5f81\u6070\u597d\u53cd\u6620\u4e86\u7f8e\u5f0f\u548c\u5370\u5ea6\u82f1\u8bed\u97f3\u6bb5\u5728\u611f\u77e5\u4e0a\u663e\u8457\u7684\u97f3\u7cfb\u7279\u5f81\u5dee\u5f02\u3002\u6a21\u578b\u63d0\u53d6\u7684\u97f3\u6bb5\u8ddd\u79bb\u4e0e\u53e3\u97f3\u5f3a\u5ea6\u663e\u8457\u76f8\u5173\uff0c\u4e14\u65b9\u5411\u7b26\u5408\u9884\u671f\u3002", "conclusion": "\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u8bed\u97f3\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u8868\u793a\u80fd\u591f\u6709\u6548\u5efa\u6a21\u548c\u89e3\u91ca\u53e3\u97f3\u611f\u77e5\u4e2d\u611f\u77e5\u663e\u8457\u7684\u97f3\u7cfb\u7279\u5f81\u53d8\u5316\uff0c\u5728\u53e3\u97f3\u5f3a\u5ea6\u5224\u65ad\u4efb\u52a1\u4e2d\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002"}}
{"id": "2506.17878", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17878", "abs": "https://arxiv.org/abs/2506.17878", "authors": ["Tam Trinh", "Manh Nguyen", "Truong-Son Hy"], "title": "Towards Robust Fact-Checking: A Multi-Agent System with Advanced Evidence Retrieval", "comment": null, "summary": "The rapid spread of misinformation in the digital era poses significant\nchallenges to public discourse, necessitating robust and scalable fact-checking\nsolutions. Traditional human-led fact-checking methods, while credible,\nstruggle with the volume and velocity of online content, prompting the\nintegration of automated systems powered by Large Language Models (LLMs).\nHowever, existing automated approaches often face limitations, such as handling\ncomplex claims, ensuring source credibility, and maintaining transparency. This\npaper proposes a novel multi-agent system for automated fact-checking that\nenhances accuracy, efficiency, and explainability. The system comprises four\nspecialized agents: an Input Ingestion Agent for claim decomposition, a Query\nGeneration Agent for formulating targeted subqueries, an Evidence Retrieval\nAgent for sourcing credible evidence, and a Verdict Prediction Agent for\nsynthesizing veracity judgments with human-interpretable explanations.\nEvaluated on benchmark datasets (FEVEROUS, HOVER, SciFact), the proposed system\nachieves a 12.3% improvement in Macro F1-score over baseline methods. The\nsystem effectively decomposes complex claims, retrieves reliable evidence from\ntrusted sources, and generates transparent explanations for verification\ndecisions. Our approach contributes to the growing field of automated\nfact-checking by providing a more accurate, efficient, and transparent\nverification methodology that aligns with human fact-checking practices while\nmaintaining scalability for real-world applications. Our source code is\navailable at https://github.com/HySonLab/FactAgent", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\uff0c\u80fd\u9ad8\u6548\u5904\u7406\u590d\u6742\u58f0\u660e\u3001\u68c0\u7d22\u53ef\u9760\u8bc1\u636e\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u5224\u51b3\uff0cMacro F1\u63d0\u534712.3%\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u81ea\u52a8\u65b9\u6cd5\u7684\u8bf8\u591a\u5c40\u9650\u3002", "motivation": "\u6570\u5b57\u65f6\u4ee3\u865a\u5047\u4fe1\u606f\u7684\u5feb\u901f\u4f20\u64ad\u5bf9\u516c\u5171\u8bdd\u8bed\u5e26\u6765\u4e25\u5cfb\u6311\u6218\u3002\u4f20\u7edf\u4eba\u5de5\u4e8b\u5b9e\u6838\u67e5\u867d\u5177\u6743\u5a01\u6027\uff0c\u4f46\u96be\u4ee5\u5e94\u5bf9\u6d77\u91cf\u9ad8\u901f\u7684\u7ebf\u4e0a\u5185\u5bb9\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\u3002\u7cfb\u7edf\u5305\u62ec\u56db\u4e2a\u7279\u5316\u667a\u80fd\u4f53\uff1a\u8f93\u5165\u5206\u89e3\uff08\u5206\u89e3\u590d\u6742\u4fe1\u606f\uff09\u3001\u67e5\u8be2\u751f\u6210\uff08\u751f\u6210\u9488\u5bf9\u6027\u5b50\u67e5\u8be2\uff09\u3001\u8bc1\u636e\u68c0\u7d22\uff08\u4ece\u53ef\u4fe1\u6765\u6e90\u83b7\u53d6\u8bc1\u636e\uff09\u548c\u7ed3\u8bba\u9884\u6d4b\uff08\u7ed9\u51fa\u53ef\u89e3\u91ca\u6027\u5224\u51b3\uff09\u3002", "result": "\u5728FEVEROUS\u3001HOVER\u548cSciFact\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u7cfb\u7edfMacro F1-score\u8f83\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u4e8612.3%\u3002\u7cfb\u7edf\u80fd\u591f\u51c6\u786e\u5206\u89e3\u590d\u6742\u58f0\u660e\uff0c\u68c0\u7d22\u5230\u53ef\u9760\u8bc1\u636e\uff0c\u5e76\u751f\u6210\u900f\u660e\u7684\u5224\u51b3\u89e3\u91ca\u3002", "conclusion": "\u672c\u65b9\u6cd5\u589e\u5f3a\u4e86\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u7684\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u65e2\u7b26\u5408\u96c6\u4f53\u4e8b\u5b9e\u6838\u67e5\u5b9e\u8df5\uff0c\u53c8\u5177\u5907\u73b0\u5b9e\u5e94\u7528\u7684\u53ef\u6269\u5c55\u6027\u3002\u5f00\u6e90\u4ee3\u7801\u5df2\u4e0a\u7ebf\uff0c\u63a8\u52a8\u4e86\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.17578", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17578", "abs": "https://arxiv.org/abs/2506.17578", "authors": ["Lingxiao Zeng", "Yiqi Tong", "Wei Guo", "Huarui Wu", "Lihao Ge", "Yijun Ye", "Fuzhen Zhuang", "Deqing Wang", "Wei Guo", "Cheng Chen"], "title": "AgriCHN: A Comprehensive Cross-domain Resource for Chinese Agricultural Named Entity Recognition", "comment": null, "summary": "Agricultural named entity recognition is a specialized task focusing on\nidentifying distinct agricultural entities within vast bodies of text,\nincluding crops, diseases, pests, and fertilizers. It plays a crucial role in\nenhancing information extraction from extensive agricultural text resources.\nHowever, the scarcity of high-quality agricultural datasets, particularly in\nChinese, has resulted in suboptimal performance when employing mainstream\nmethods for this purpose. Most earlier works only focus on annotating\nagricultural entities while overlook the profound correlation of agriculture\nwith hydrology and meteorology. To fill this blank, we present AgriCHN, a\ncomprehensive open-source Chinese resource designed to promote the accuracy of\nautomated agricultural entity annotation. The AgriCHN dataset has been\nmeticulously curated from a wealth of agricultural articles, comprising a total\nof 4,040 sentences and encapsulating 15,799 agricultural entity mentions\nspanning 27 diverse entity categories. Furthermore, it encompasses entities\nfrom hydrology to meteorology, thereby enriching the diversity of entities\nconsidered. Data validation reveals that, compared with relevant resources,\nAgriCHN demonstrates outstanding data quality, attributable to its richer\nagricultural entity types and more fine-grained entity divisions. A benchmark\ntask has also been constructed using several state-of-the-art neural NER\nmodels. Extensive experimental results highlight the significant challenge\nposed by AgriCHN and its potential for further research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AgriCHN\u4e2d\u6587\u519c\u4e1a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u519c\u4e1a\u4e0e\u6c34\u6587\u3001\u6c14\u8c61\u591a\u7c7b\u522b\u9ad8\u8d28\u91cf\u5b9e\u4f53\uff0c\u7ecf\u9a8c\u8bc1\u4f18\u4e8e\u73b0\u6709\u8d44\u6e90\uff0c\u5e76\u5177\u6311\u6218\u6027\u4e0e\u7814\u7a76\u4ef7\u503c\u3002", "motivation": "\u519c\u4e1a\u9886\u57df\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u3001\u7279\u522b\u662f\u4e2d\u6587\u7684\u6570\u636e\u96c6\uff0c\u5bfc\u81f4\u4e3b\u6d41\u65b9\u6cd5\u8868\u73b0\u4e0d\u4f73\u3002\u540c\u65f6\uff0c\u73b0\u6709\u5de5\u4f5c\u5ffd\u89c6\u4e86\u519c\u4e1a\u4e0e\u6c34\u6587\u548c\u6c14\u8c61\u9886\u57df\u7684\u5bc6\u5207\u5173\u8054\u3002", "method": "\u63d0\u51fa\u5e76\u6784\u5efa\u4e86AgriCHN\uff0c\u4e00\u4e2a\u5168\u9762\u7684\u5f00\u6e90\u4e2d\u6587\u519c\u4e1a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6570\u636e\u96c6\u3002\u8be5\u6570\u636e\u96c6\u5305\u542b4040\u4e2a\u53e5\u5b50\uff0c\u6db5\u76d615799\u4e2a\u519c\u4e1a\u5b9e\u4f53\uff0c\u6d89\u53ca27\u4e2a\u7c7b\u522b\uff0c\u5e76\u56ca\u62ec\u4e86\u4e0e\u6c34\u6587\u548c\u6c14\u8c61\u76f8\u5173\u7684\u5b9e\u4f53\u3002\u7528\u591a\u79cd\u5f53\u524d\u4e3b\u6d41\u795e\u7ecf\u7f51\u7edcNER\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u5b9e\u9a8c\u3002", "result": "\u6570\u636e\u9a8c\u8bc1\u8868\u660e\uff0cAgriCHN\u5728\u6570\u636e\u8d28\u91cf\u4e0a\u4f18\u4e8e\u76f8\u5173\u8d44\u6e90\uff0c\u5305\u62ec\u66f4\u4e30\u5bcc\u7684\u519c\u4e1a\u5b9e\u4f53\u7c7b\u578b\u548c\u66f4\u7ec6\u81f4\u7684\u5b9e\u4f53\u5212\u5206\u3002\u5b9e\u9a8c\u8868\u660eAgriCHN\u6570\u636e\u96c6\u5177\u5907\u8f83\u5927\u6311\u6218\u6027\u548c\u7814\u7a76\u6f5c\u529b\u3002", "conclusion": "AgriCHN\u6570\u636e\u96c6\u7684\u63d0\u51fa\u6781\u5927\u4e30\u5bcc\u4e86\u4e2d\u6587\u519c\u4e1a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u8d44\u6e90\uff0c\u62d3\u5c55\u4e86\u519c\u4e1a\u5b9e\u4f53\u7c7b\u578b\u5e76\u63d0\u9ad8\u4e86\u6570\u636e\u7ec6\u7c92\u5ea6\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u65b9\u6cd5\u6539\u8fdb\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.17900", "categories": ["cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.17900", "abs": "https://arxiv.org/abs/2506.17900", "authors": ["Cheng Ji", "Huaiying Luo"], "title": "Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms", "comment": "Accepted by 2025 8th International Conference on Advanced Electronic\n  Materials, Computers and Software Engineering (AEMCSE 2025)", "summary": "With the increasing complexity and rapid expansion of the scale of AI systems\nin cloud platforms, the log data generated during system operation is massive,\nunstructured, and semantically ambiguous, which brings great challenges to\nfault location and system self-repair. In order to solve this problem, this\npaper proposes an intelligent log processing and automatic debugging framework\nbased on Large Language Model (LLM), named Intelligent Debugger (LLM-ID). This\nmethod is extended on the basis of the existing pre-trained Transformer model,\nand integrates a multi-stage semantic inference mechanism to realize the\ncontext understanding of system logs and the automatic reconstruction of fault\nchains. Firstly, the system log is dynamically structured, and the unsupervised\nclustering and embedding mechanism is used to extract the event template and\nsemantic schema. Subsequently, the fine-tuned LLM combined with the multi-round\nattention mechanism to perform contextual reasoning on the log sequence to\ngenerate potential fault assumptions and root cause paths. Furthermore, this\npaper introduces a reinforcement learning-based policy-guided recovery planner,\nwhich is driven by the remediation strategy generated by LLM to support dynamic\ndecision-making and adaptive debugging in the cloud environment. Compared with\nthe existing rule engine or traditional log analysis system, the proposed model\nhas stronger semantic understanding ability, continuous learning ability and\nheterogeneous environment adaptability. Experiments on the cloud platform log\ndataset show that LLM-ID improves the fault location accuracy by 16.2%, which\nis significantly better than the current mainstream methods", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u65e5\u5fd7\u5904\u7406\u4e0e\u81ea\u52a8\u8c03\u8bd5\u7cfb\u7edf\uff08LLM-ID\uff09\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u8bed\u4e49\u63a8\u7406\u548c\u81ea\u9002\u5e94\u81ea\u6108\u673a\u5236\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u4e91\u5e73\u53f0\u65e5\u5fd7\u7684\u6545\u969c\u5b9a\u4f4d\u548c\u4fee\u590d\u6548\u7387\uff0c\u51c6\u786e\u7387\u6bd4\u4f20\u7edf\u65b9\u6cd5\u9ad816.2%\u3002", "motivation": "AI\u7cfb\u7edf\u5728\u4e91\u5e73\u53f0\u4e0a\u7684\u590d\u6742\u6027\u548c\u89c4\u6a21\u4e0d\u65ad\u589e\u52a0\uff0c\u751f\u6210\u7684\u65e5\u5fd7\u6570\u636e\u6d77\u91cf\u3001\u65e0\u7ed3\u6784\u4e14\u8bed\u4e49\u6a21\u7cca\uff0c\u5bfc\u81f4\u6545\u969c\u5b9a\u4f4d\u548c\u81ea\u6108\u53d8\u5f97\u6781\u5177\u6311\u6218\u6027\u3002", "method": "\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684Transformer\u67b6\u6784\uff0c\u7ed3\u5408\u591a\u9636\u6bb5\u8bed\u4e49\u63a8\u7406\u673a\u5236\uff1b\u7cfb\u7edf\u5305\u62ec\u65e5\u5fd7\u52a8\u6001\u7ed3\u6784\u5316\u3001\u65e0\u76d1\u7763\u805a\u7c7b\u4e0e\u5d4c\u5165\u3001\u5229\u7528\u5fae\u8c03LLM\u7684\u591a\u8f6e\u6ce8\u610f\u529b\u673a\u5236\u505a\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7b56\u7565\u6307\u5bfc\u81ea\u6108\u89c4\u5212\u3002", "result": "LLM-ID\u5728\u4e91\u5e73\u53f0\u65e5\u5fd7\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u6545\u969c\u5b9a\u4f4d\u51c6\u786e\u7387\u63d0\u534716.2%\uff0c\u5728\u6027\u80fd\u4e0a\u663e\u8457\u8d85\u8d8a\u5f53\u524d\u4e3b\u6d41\u89c4\u5219\u5f15\u64ce\u548c\u4f20\u7edf\u65e5\u5fd7\u5206\u6790\u7cfb\u7edf\u3002", "conclusion": "\u63d0\u51fa\u7684LLM-ID\u6846\u67b6\u5728\u8bed\u4e49\u7406\u89e3\u3001\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u548c\u5f02\u6784\u73af\u5883\u9002\u5e94\u6027\u65b9\u9762\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5728\u4e91\u5e73\u53f0\u65e5\u5fd7\u6570\u636e\u96c6\u4e0a\u6545\u969c\u5b9a\u4f4d\u51c6\u786e\u7387\u63d0\u534716.2%\u3002"}}
{"id": "2506.17603", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17603", "abs": "https://arxiv.org/abs/2506.17603", "authors": ["Jonathan Sakunkoo", "Annabella Sakunkoo"], "title": "Mind the Gap: Assessing Wiktionary's Crowd-Sourced Linguistic Knowledge on Morphological Gaps in Two Related Languages", "comment": null, "summary": "Morphological defectivity is an intriguing and understudied phenomenon in\nlinguistics. Addressing defectivity, where expected inflectional forms are\nabsent, is essential for improving the accuracy of NLP tools in morphologically\nrich languages. However, traditional linguistic resources often lack coverage\nof morphological gaps as such knowledge requires significant human expertise\nand effort to document and verify. For scarce linguistic phenomena in\nunder-explored languages, Wikipedia and Wiktionary often serve as among the few\naccessible resources. Despite their extensive reach, their reliability has been\na subject of controversy. This study customizes a novel neural morphological\nanalyzer to annotate Latin and Italian corpora. Using the massive annotated\ndata, crowd-sourced lists of defective verbs compiled from Wiktionary are\nvalidated computationally. Our results indicate that while Wiktionary provides\na highly reliable account of Italian morphological gaps, 7% of Latin lemmata\nlisted as defective show strong corpus evidence of being non-defective. This\ndiscrepancy highlights potential limitations of crowd-sourced wikis as\ndefinitive sources of linguistic knowledge, particularly for less-studied\nphenomena and languages, despite their value as resources for rare linguistic\nfeatures. By providing scalable tools and methods for quality assurance of\ncrowd-sourced data, this work advances computational morphology and expands\nlinguistic knowledge of defectivity in non-English, morphologically rich\nlanguages.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u5f62\u6001\u5206\u6790\u5668\uff0c\u7528\u4ee5\u6838\u67e5\u62c9\u4e01\u8bed\u548c\u610f\u5927\u5229\u8bed\u7f3a\u635f\u52a8\u8bcd\u7684\u4f17\u5305\u6570\u636e\u3002\u7ed3\u679c\u53d1\u73b0\uff0cWiktionary\u5bf9\u610f\u5927\u5229\u8bed\u7f3a\u635f\u8bcd\u7684\u6807\u6ce8\u6781\u4e3a\u53ef\u9760\uff0c\u4f46\u62c9\u4e01\u8bed\u4e2d\u67097%\u7684\u8bcd\u6761\u5b58\u5728\u8bef\u5224\uff0c\u63d0\u9192\u6211\u4eec\u4f17\u5305\u6570\u636e\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u7a00\u6709\u8bed\u8a00\u5b66\u73b0\u8c61\u4e0a\u7684\u5c40\u9650\u3002\u8be5\u7814\u7a76\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u5927\u89c4\u6a21\u81ea\u52a8\u5316\u6821\u9a8c\u4f17\u5305\u8bed\u8a00\u6570\u636e\u7684\u65b0\u65b9\u6cd5\uff0c\u8fd8\u63d0\u5347\u4e86\u5f62\u6001\u5b66\u7f3a\u635f\u73b0\u8c61\u5728\u591a\u8bed\u8a00\u80cc\u666f\u4e0b\u7684\u7814\u7a76\u6df1\u5ea6\u3002", "motivation": "\u5f62\u6001\u5b66\u7f3a\u635f\u73b0\u8c61\u5373\u67d0\u4e9b\u8bcd\u6c47\u5e94\u6709\u7684\u5c48\u6298\u5f62\u5f0f\u7f3a\u5931\uff0c\u662f\u8bed\u8a00\u5b66\u4e2d\u4e00\u4e2a\u6709\u8da3\u4f46\u7814\u7a76\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u73b0\u6709NLP\u5de5\u5177\u5728\u5904\u7406\u8fd9\u79cd\u73b0\u8c61\u65f6\u51c6\u786e\u7387\u8f83\u4f4e\uff0c\u4e14\u4e3b\u6d41\u7684\u8bed\u8a00\u5b66\u8d44\u6e90\u5bf9\u7f3a\u635f\u7684\u8986\u76d6\u6709\u9650\uff0c\u4eba\u5de5\u8bb0\u5f55\u548c\u9a8c\u8bc1\u96be\u5ea6\u5927\u3002\u7ef4\u57fa\u767e\u79d1\u548cWiktionary\u867d\u7136\u53ef\u83b7\u53d6\uff0c\u4f46\u5176\u6570\u636e\u7684\u53ef\u9760\u6027\u4e00\u76f4\u5b58\u5728\u4e89\u8bae\u3002", "method": "\u672c\u7814\u7a76\u5b9a\u5236\u4e86\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u5f62\u6001\u5206\u6790\u5668\uff0c\u7528\u4e8e\u6807\u6ce8\u62c9\u4e01\u8bed\u548c\u610f\u5927\u5229\u8bed\u8bed\u6599\u5e93\uff0c\u5e76\u5229\u7528Wiktionary\u4f17\u5305\u7684\u7f3a\u635f\u52a8\u8bcd\u5217\u8868\u8fdb\u884c\u8ba1\u7b97\u673a\u9a8c\u8bc1\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0cWiktionary\u5bf9\u610f\u5927\u5229\u8bed\u5f62\u6001\u5b66\u7f3a\u635f\u73b0\u8c61\u7684\u8bb0\u5f55\u975e\u5e38\u53ef\u9760\uff0c\u4f46\u5728\u62c9\u4e01\u8bed\u4e2d\u7ea6\u67097%\u7684\u6240\u8c13\u7f3a\u635f\u8bcd\u5b9e\u9645\u4e0a\u5728\u8bed\u6599\u4e2d\u5e76\u4e0d\u7f3a\u635f\uff0c\u8868\u660eWiktionary\u7b49\u4f17\u5305\u8d44\u6e90\u5728\u5c11\u6570\u8bed\u8a00\u6216\u73b0\u8c61\u7684\u6743\u5a01\u6027\u6709\u9650\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4f17\u5305\u6570\u636e\u7684\u8d28\u91cf\u4fdd\u969c\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u8ba1\u7b97\u5f62\u6001\u5b66\u53d1\u5c55\uff0c\u5e76\u62d3\u5c55\u4e86\u5bf9\u975e\u82f1\u8bed\u3001\u5f62\u6001\u4e30\u5bcc\u8bed\u8a00\u7f3a\u635f\u73b0\u8c61\u7684\u8ba4\u8bc6\u3002"}}
{"id": "2506.17913", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17913", "abs": "https://arxiv.org/abs/2506.17913", "authors": ["Jinjie Wei", "Jiyao Liu", "Lihao Liu", "Ming Hu", "Junzhi Ning", "Mingcheng Li", "Weijie Yin", "Junjun He", "Xiao Liang", "Chao Feng", "Dingkang Yang"], "title": "Learning, Reasoning, Refinement: A Framework for Kahneman's Dual-System Intelligence in GUI Agents", "comment": null, "summary": "Graphical User Interface (GUI) agents have made significant progress in\nautomating digital tasks through the utilization of computer vision and\nlanguage models. Nevertheless, existing agent systems encounter notable\nlimitations. Firstly, they predominantly depend on trial and error decision\nmaking rather than progressive reasoning, thereby lacking the capability to\nlearn and adapt from interactive encounters. Secondly, these systems are\nassessed using overly simplistic single step accuracy metrics, which do not\nadequately reflect the intricate nature of real world GUI interactions. In this\npaper, we present CogniGUI, a cognitive framework developed to overcome these\nlimitations by enabling adaptive learning for GUI automation resembling\nhuman-like behavior. Inspired by Kahneman's Dual Process Theory, our approach\ncombines two main components: (1) an omni parser engine that conducts immediate\nhierarchical parsing of GUI elements through quick visual semantic analysis to\nidentify actionable components, and (2) a Group based Relative Policy\nOptimization (GRPO) grounding agent that assesses multiple interaction paths\nusing a unique relative reward system, promoting minimal and efficient\noperational routes. This dual-system design facilitates iterative ''exploration\nlearning mastery'' cycles, enabling the agent to enhance its strategies over\ntime based on accumulated experience. Moreover, to assess the generalization\nand adaptability of agent systems, we introduce ScreenSeek, a comprehensive\nbenchmark that includes multi application navigation, dynamic state\ntransitions, and cross interface coherence, which are often overlooked\nchallenges in current benchmarks. Experimental results demonstrate that\nCogniGUI surpasses state-of-the-art methods in both the current GUI grounding\nbenchmarks and our newly proposed benchmark.", "AI": {"tldr": "CogniGUI\u901a\u8fc7\u8ba4\u77e5\u5f0f\u53cc\u7cfb\u7edf\u5b66\u4e60\u673a\u5236\u548c\u521b\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6709\u6548\u63d0\u5347\u4e86GUI\u64cd\u4f5c\u4ee3\u7406\u7684\u667a\u80fd\u5316\u548c\u901a\u7528\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684GUI\u81ea\u52a8\u5316\u667a\u80fd\u4f53\u5927\u591a\u4f9d\u8d56\u8bd5\u9519\u51b3\u7b56\uff0c\u7f3a\u4e4f\u9010\u6b65\u63a8\u7406\u4e0e\u81ea\u9002\u5e94\u5b66\u4e60\u80fd\u529b\uff0c\u5e76\u4e14\u8bc4\u4f30\u65b9\u5f0f\u8fc7\u4e8e\u7b80\u5355\uff0c\u4e0d\u80fd\u771f\u5b9e\u53cd\u6620\u590d\u6742\u7684\u73b0\u5b9e\u4ea4\u4e92\u9700\u6c42\u3002", "method": "\u63d0\u51faCogniGUI\u8ba4\u77e5\u6846\u67b6\uff0c\u501f\u9274Kahneman\u7684\u53cc\u7cfb\u7edf\u7406\u8bba\uff1a\u5305\u62ec\u5feb\u901f\u5206\u5c42\u89e3\u6790GUI\u5143\u7d20\u7684omni parser\u548c\u57fa\u4e8e\u76f8\u5bf9\u5956\u52b1\u4f18\u5316\u591a\u8def\u5f84\u4ea4\u4e92\u7684GRPO\u4ee3\u7406\uff0c\u5b9e\u73b0\u63a2\u7d22-\u5b66\u4e60-\u7cbe\u901a\u7684\u8fed\u4ee3\u4f18\u5316\u3002\u5e76\u5f15\u5165ScreenSeek\u57fa\u51c6\uff0c\u5305\u542b\u591a\u5e94\u7528\u5bfc\u822a\u3001\u52a8\u6001\u72b6\u6001\u8f6c\u6362\u548c\u8de8\u754c\u9762\u4e00\u81f4\u6027\u3002", "result": "CogniGUI\u5728\u73b0\u6709GUI\u57fa\u51c6\u548c\u65b0\u63d0\u51fa\u7684ScreenSeek\u57fa\u51c6\u4e0a\u5747\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u8bc1\u5b9e\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "CogniGUI\u6846\u67b6\u80fd\u6a21\u62df\u4eba\u7c7b\u9010\u6b65\u5b66\u4e60\u548c\u9002\u5e94\u884c\u4e3a\uff0c\u663e\u8457\u63d0\u5347\u4e86GUI\u667a\u80fd\u4f53\u5728\u590d\u6742\u73af\u5883\u4e0b\u7684\u64cd\u4f5c\u80fd\u529b\u4e0e\u8bc4\u4f30\u6807\u51c6\u3002"}}
{"id": "2506.18116", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.18116", "abs": "https://arxiv.org/abs/2506.18116", "authors": ["Batool Haider", "Atmika Gorti", "Aman Chadha", "Manas Gaur"], "title": "Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives", "comment": "19 Pages, 7 Figures, 4 Tables (Note: Under Review)", "summary": "Large Language Models (LLMs) in mental healthcare risk propagating biases\nthat reinforce stigma and harm marginalized groups. While previous research\nidentified concerning trends, systematic methods for detecting intersectional\nbiases remain limited. This work introduces a multi-hop question answering\n(MHQA) framework to explore LLM response biases in mental health discourse. We\nanalyze content from the Interpretable Mental Health Instruction (IMHI) dataset\nacross symptom presentation, coping mechanisms, and treatment approaches. Using\nsystematic tagging across age, race, gender, and socioeconomic status, we\ninvestigate bias patterns at demographic intersections. We evaluate four LLMs:\nClaude 3.5 Sonnet, Jamba 1.6, Gemma 3, and Llama 4, revealing systematic\ndisparities across sentiment, demographics, and mental health conditions. Our\nMHQA approach demonstrates superior detection compared to conventional methods,\nidentifying amplification points where biases magnify through sequential\nreasoning. We implement two debiasing techniques: Roleplay Simulation and\nExplicit Bias Reduction, achieving 66-94% bias reductions through few-shot\nprompting with BBQ dataset examples. These findings highlight critical areas\nwhere LLMs reproduce mental healthcare biases, providing actionable insights\nfor equitable AI development.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u5b58\u5728\u590d\u6742\u7684\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u63d0\u51fa\u7684\u591a\u8df3\u95ee\u7b54\u6846\u67b6\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u68c0\u6d4b\u5e76\u91cf\u5316\u8fd9\u4e9b\u504f\u89c1\uff0c\u901a\u8fc7\u521b\u65b0\u53bb\u504f\u65b9\u6cd5\u53ef\u663e\u8457\u51cf\u5c0f\u504f\u89c1\u5f71\u54cd\uff0c\u4e3a\u6784\u5efa\u516c\u5e73\u7684AI\u533b\u7597\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b9\u6cd5\u548c\u53c2\u8003\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u4e2d\u7684\u5e94\u7528\u53ef\u80fd\u4f1a\u4f20\u64ad\u504f\u89c1\uff0c\u5f3a\u5316\u5bf9\u8fb9\u7f18\u7fa4\u4f53\u7684\u8d1f\u9762\u523b\u677f\u5370\u8c61\u548c\u4f24\u5bb3\u3002\u867d\u7136\u65e9\u671f\u7814\u7a76\u53d1\u73b0\u4e86\u8fd9\u79cd\u95ee\u9898\u7684\u8d8b\u52bf\uff0c\u4f46\u76ee\u524d\u7cfb\u7edf\u6027\u68c0\u6d4b\u4ea4\u53c9\u504f\u89c1\uff08\u5982\u79cd\u65cf\u3001\u6027\u522b\u3001\u5e74\u9f84\u3001\u793e\u4f1a\u7ecf\u6d4e\u5730\u4f4d\u7b49\u4ea4\u53c9\u5f71\u54cd\uff09\u7684\u6709\u6548\u65b9\u6cd5\u4ecd\u5f88\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u8df3\u95ee\u7b54\uff08MHQA\uff09\u6846\u67b6\uff0c\u7cfb\u7edf\u6027\u5730\u5206\u6790LLM\u5728\u5fc3\u7406\u5065\u5eb7\u8bdd\u8bed\u4e2d\u7684\u56de\u5e94\u662f\u5426\u5b58\u5728\u504f\u89c1\u3002\u5177\u4f53\u65b9\u6cd5\u662f\u5229\u7528Interpretable Mental Health Instruction\uff08IMHI\uff09\u6570\u636e\u96c6\u4e2d\u7684\u5185\u5bb9\uff0c\u6db5\u76d6\u75c7\u72b6\u8868\u73b0\u3001\u5e94\u5bf9\u673a\u5236\u548c\u6cbb\u7597\u65b9\u5f0f\uff0c\u5e76\u7ed3\u5408\u5e74\u9f84\u3001\u79cd\u65cf\u3001\u6027\u522b\u3001\u793e\u4f1a\u7ecf\u6d4e\u5730\u4f4d\u7b49\u7cfb\u7edf\u6807\u7b7e\uff0c\u5728\u4eba\u53e3\u7fa4\u4f53\u4ea4\u53c9\u70b9\u63a2\u67e5\u504f\u89c1\u683c\u5c40\u3002\u540c\u65f6\u5bf9Claude 3.5 Sonnet\u3001Jamba 1.6\u3001Gemma 3\u548cLlama 4\u56db\u79cdLLM\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u6bd4\u8f83\u591a\u8df3\u95ee\u7b54\u4e0e\u5e38\u89c4\u68c0\u6d4b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u91c7\u7528\u89d2\u8272\u626e\u6f14\u6a21\u62df\u548c\u663e\u5f0f\u504f\u89c1\u6d88\u51cf\u4e24\u79cd\u53bb\u504f\u6280\u5de7\uff0c\u901a\u8fc7BBQ\u6570\u636e\u96c6\u7684few-shot\u63d0\u793a\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u56db\u79cd\u4e3b\u6d41LLM\u5728\u60c5\u611f\u503e\u5411\u3001\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u548c\u5fc3\u7406\u5065\u5eb7\u72b6\u6001\u65b9\u9762\u90fd\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\u3002\u591a\u8df3\u95ee\u7b54\u65b9\u6cd5\u6bd4\u4f20\u7edf\u68c0\u6d4b\u624b\u6bb5\u66f4\u597d\u5730\u53d1\u73b0\u504f\u89c1\u7684\u653e\u5927\u8282\u70b9\uff08\u5373\u63a8\u7406\u94fe\u6761\u4e2d\u504f\u89c1\u88ab\u653e\u5927\u7684\u73af\u8282\uff09\u3002\u5b9e\u65bd\u7684\u4e24\u79cd\u53bb\u504f\u65b9\u6cd5\u5728\u504f\u89c1\u68c0\u6d4b\u5b9e\u9a8c\u4e2d\u8fbe\u5230\u4e8666-94%\u7684\u504f\u89c1\u6d88\u51cf\u6548\u679c\u3002", "conclusion": "\u5f53\u524d\u4e3b\u6d41LLM\u5728\u5fc3\u7406\u5065\u5eb7\u573a\u666f\u4e0b\u5b58\u5728\u5371\u9669\u7684\u7cfb\u7edf\u6027\u548c\u4ea4\u53c9\u504f\u89c1\u3002\u591a\u8df3\u95ee\u7b54\u6280\u672f\u80fd\u6709\u6548\u6316\u6398\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u89d2\u8272\u626e\u6f14\u548c\u663e\u5f0f\u504f\u89c1\u6d88\u51cf\u6307\u4ee4\u80fd\u5927\u5e45\u964d\u4f4e\u76f8\u5173\u504f\u89c1\uff0c\u5bf9\u672a\u6765\u66f4\u516c\u5e73\u7684AI\u533b\u7597\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\u3002"}}
{"id": "2506.17609", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17609", "abs": "https://arxiv.org/abs/2506.17609", "authors": ["Lincan Li", "Eren Erman Ozguven", "Yue Zhao", "Guang Wang", "Yiqun Xie", "Yushun Dong"], "title": "TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting", "comment": null, "summary": "Accurate typhoon track forecasting is crucial for early system warning and\ndisaster response. While Transformer-based models have demonstrated strong\nperformance in modeling the temporal dynamics of dense trajectories of humans\nand vehicles in smart cities, they usually lack access to broader contextual\nknowledge that enhances the forecasting reliability of sparse meteorological\ntrajectories, such as typhoon tracks. To address this challenge, we propose\nTyphoFormer, a novel framework that incorporates natural language descriptions\nas auxiliary prompts to improve typhoon trajectory forecasting. For each time\nstep, we use Large Language Model (LLM) to generate concise textual\ndescriptions based on the numerical attributes recorded in the North Atlantic\nhurricane database. The language descriptions capture high-level meteorological\nsemantics and are embedded as auxiliary special tokens prepended to the\nnumerical time series input. By integrating both textual and sequential\ninformation within a unified Transformer encoder, TyphoFormer enables the model\nto leverage contextual cues that are otherwise inaccessible through numerical\nfeatures alone. Extensive experiments are conducted on HURDAT2 benchmark,\nresults show that TyphoFormer consistently outperforms other state-of-the-art\nbaseline methods, particularly under challenging scenarios involving nonlinear\npath shifts and limited historical observations.", "AI": {"tldr": "TyphoFormer\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u81ea\u7136\u8bed\u8a00\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u53f0\u98ce\u8def\u5f84\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u76ee\u524d\u4e3b\u6d41\u65b9\u6cd5\u3002", "motivation": "\u53f0\u98ce\u8def\u5f84\u9884\u6d4b\u5bf9\u4e8e\u65e9\u671f\u9884\u8b66\u548c\u707e\u5bb3\u54cd\u5e94\u81f3\u5173\u91cd\u8981\u3002\u4ee5\u5f80\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5904\u7406\u7a00\u758f\u6c14\u8c61\u8f68\u8ff9\u5982\u53f0\u98ce\u8def\u5f84\u65f6\uff0c\u7f3a\u4e4f\u66f4\u5e7f\u6cdb\u7684\u4e0a\u4e0b\u6587\u77e5\u8bc6\uff0c\u96be\u4ee5\u63d0\u5347\u9884\u6d4b\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faTyphoFormer\u6846\u67b6\uff0c\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u57fa\u4e8e\u5317\u5927\u897f\u6d0b\u98d3\u98ce\u6570\u636e\u5e93\u7684\u6570\u503c\u5c5e\u6027\u751f\u6210\u51dd\u7ec3\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\uff0c\u5c06\u5176\u4f5c\u4e3a\u8f85\u52a9\u63d0\u793a\uff0c\u901a\u8fc7\u7279\u6b8atoken\u52a0\u5230\u65f6\u5e8f\u6570\u503c\u8f93\u5165\u524d\u3002\u8fd9\u6837\u8054\u5408\u6587\u672c\u548c\u5e8f\u5217\u4fe1\u606f\u8f93\u5165\u5230Transformer\u7f16\u7801\u5668\u3002", "result": "\u5728HURDAT2\u57fa\u51c6\u4e0a\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\uff0cTyphoFormer\u5728\u5177\u6709\u975e\u7ebf\u6027\u8def\u5f84\u53d8\u5316\u548c\u5386\u53f2\u89c2\u6d4b\u7a00\u5c11\u7684\u4e25\u5cfb\u573a\u666f\u4e0b\uff0c\u9884\u6d4b\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u6700\u65b0\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TyphoFormer\u6709\u6548\u878d\u5408\u4e86\u81ea\u7136\u8bed\u8a00\u4e0e\u6570\u503c\u65f6\u5e8f\u4fe1\u606f\uff0c\u4e3a\u6c14\u8c61\u8f68\u8ff9\uff08\u5982\u53f0\u98ce\u8def\u5f84\uff09\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5c24\u5176\u5728\u56f0\u96be\u573a\u666f\u4e0b\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2506.17930", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.17930", "abs": "https://arxiv.org/abs/2506.17930", "authors": ["Jianyu Wang", "Zhiqiang Hu", "Lidong Bing"], "title": "Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective", "comment": "ICML 2025, and Code will be released at:\n  https://github.com/jianyu-cs/PromptQuine/", "summary": "We propose a novel prompt design paradigm that challenges conventional wisdom\nin large language model (LLM) prompting. While conventional wisdom prioritizes\nwell-crafted instructions and demonstrations for in-context learning (ICL), we\nshow that pruning random demonstrations into seemingly incoherent \"gibberish\"\ncan remarkably improve performance across diverse tasks. Notably, the\n\"gibberish\" always matches or surpasses state-of-the-art automatic prompt\noptimization techniques, achieving substantial gains regardless of LLM\nalignment. Nevertheless, discovering an effective pruning strategy is\nnon-trivial, as existing attribution methods and prompt compression algorithms\nfail to deliver robust results, let alone human intuition. In terms of this, we\npropose a self-discover prompt optimization framework, PromptQuine, an\nevolutionary search framework that automatically searches for the pruning\nstrategy by itself using only low-data regimes. Much like the emergent\ncomplexity in nature--such as symbiosis and self-organization--arising in\nresponse to resource constraints, our framework evolves and refines\nunconventional yet highly effective prompts by leveraging only the tokens\npresent within the context. We demonstrate its effectiveness across\nclassification, multi-choice question answering, generation and math reasoning\ntasks across LLMs, while achieving decent runtime efficiency. We hope our\nfindings can guide mechanistic studies on in-context learning, and provide a\ncall to action, to pave the way for more open-ended search algorithms for more\neffective LLM prompting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PromptQuine\u8fdb\u5316\u5f0f\u81ea\u52a8\u63d0\u793a\u8bcd\u4f18\u5316\u6846\u67b6\uff0c\u53d1\u73b0\u5c06\u90e8\u5206\u539f\u672c\u770b\u4f3c\u65e0\u610f\u4e49\u7684\u63d0\u793a\u8bcd\u7247\u6bb5\u4fdd\u7559\uff0c\u80fd\u591f\u5728\u591a\u79cd\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u63d0\u793a\u8bbe\u8ba1\u4e0e\u4f18\u5316\u65b9\u6cd5\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u7b97\u6cd5\u9a71\u52a8\u3001\u975e\u4eba\u5de5\u76f4\u89c9\u4f18\u5316\u5728LLM\u63d0\u793a\u8bcd\u8bbe\u8ba1\u4e2d\u7684\u91cd\u8981\u4ef7\u503c\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63d0\u793a\u8bcd\uff08prompt\uff09\u8bbe\u8ba1\u666e\u904d\u4f9d\u8d56\u7cbe\u5fc3\u6784\u9020\u7684\u6307\u4ee4\u548c\u8303\u4f8b\u4ee5\u63d0\u5347\u6a21\u578b\u63a8\u7406\u8868\u73b0\uff0c\u4f46\u8be5\u65b9\u6cd5\u5b58\u5728\u8bbe\u8ba1\u6210\u672c\u9ad8\u3001\u6807\u51c6\u5316\u96be\u7b49\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u65e8\u5728\u63a2\u7d22\u66f4\u9ad8\u6548\u3001\u81ea\u52a8\u5316\u7684\u63d0\u793a\u8bcd\u4f18\u5316\u7b56\u7565\uff0c\u7a81\u7834\u4f20\u7edf\u8303\u5f0f\u7684\u5c40\u9650\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8fdb\u5316\u5f0f\u641c\u7d22\u6846\u67b6PromptQuine\uff0c\u901a\u8fc7\u8fdb\u5316\u7b97\u6cd5\u81ea\u52a8\u641c\u7d22\u5e76\u4fee\u526a\u63d0\u793a\u8bcd\uff0c\u5c06\u539f\u59cb\u7684\u3001\u6709\u903b\u8f91\u7684\u63d0\u793a\u8bcd\u201c\u4fee\u526a\u201d\u6210\u90e8\u5206\u770b\u4f3c\u65e0\u610f\u4e49\u7684\u201cgibberish\u201d\uff08\u65e0\u5e8f\u7247\u6bb5\uff09\uff0c\u5728\u4f4e\u6570\u636e\u91cf\u4e0b\u81ea\u52a8\u53d1\u73b0\u6709\u6548\u7684\u4fee\u526a\u7b56\u7565\u3002\u8be5\u65b9\u6cd5\u4e0d\u540c\u4e8e\u4f20\u7edf\u7684\u5f52\u56e0\u5206\u6790\u548c\u63d0\u793a\u538b\u7f29\u7b97\u6cd5\uff0c\u4e0d\u4f9d\u8d56\u4eba\u5de5\u76f4\u89c9\uff0c\u5b8c\u5168\u7531\u7b97\u6cd5\u81ea\u6211\u9a6f\u5316\u4e0e\u6f14\u5316\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u201cgibberish\u201d\u63d0\u793a\u5728\u5404\u7c7b\u4efb\u52a1\uff08\u5305\u62ec\u5206\u7c7b\u3001\u591a\u9009\u95ee\u7b54\u3001\u751f\u6210\u3001\u6570\u5b66\u63a8\u7406\uff09\u4ee5\u53ca\u4e0d\u540c\u7c7b\u578b\u7684LLM\u4e0a\uff0c\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u751a\u81f3\u6bd4\u5f53\u524d\u6700\u4f18\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6280\u672f\u6548\u679c\u66f4\u597d\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u5728\u8fd0\u884c\u6548\u7387\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u4f5c\u8005\u53d1\u73b0\uff0c\u6253\u7834\u4f20\u7edf\u4eba\u7c7b\u8bbe\u8ba1\u76f4\u89c9\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6f14\u5316\u65b9\u5f0f\u5bfb\u627e\u975e\u5e38\u89c4\u63d0\u793a\uff0c\u80fd\u6781\u5927\u63d0\u5347LLM\u7684\u63a8\u7406\u8868\u73b0\u3002\u8be5\u7814\u7a76\u4e0d\u4ec5\u5bf9LLM\u7684\u673a\u7406\u5c42\u7814\u7a76\u5177\u6709\u6307\u5bfc\u610f\u4e49\uff0c\u4e5f\u4e3a\u63d0\u793a\u8bcd\u81ea\u52a8\u641c\u7d22\u4e0e\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2506.18199", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.18199", "abs": "https://arxiv.org/abs/2506.18199", "authors": ["Bushra Asseri", "Estabrag Abdelaziz", "Areej Al-Wabil"], "title": "Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review", "comment": null, "summary": "Large language models have demonstrated remarkable capabilities across\nvarious domains, yet concerns about cultural bias - particularly towards Arabs\nand Muslims - pose significant ethical challenges by perpetuating harmful\nstereotypes and marginalization. Despite growing recognition of bias in LLMs,\nprompt engineering strategies specifically addressing Arab and Muslim\nrepresentation remain understudied. This mixed-methods systematic review\nexamines such techniques, offering evidence-based guidance for researchers and\npractitioners. Following PRISMA guidelines and Kitchenham's systematic review\nmethodology, we analyzed 8 empirical studies published between 2021-2024\ninvestigating bias mitigation strategies. Our findings reveal five primary\nprompt engineering approaches: cultural prompting, affective priming,\nself-debiasing techniques, structured multi-step pipelines, and\nparameter-optimized continuous prompts. Although all approaches show potential\nfor reducing bias, effectiveness varied substantially across studies and bias\ntypes. Evidence suggests that certain bias types may be more resistant to\nprompt-based mitigation than others. Structured multi-step pipelines\ndemonstrated the highest overall effectiveness, achieving up to 87.7% reduction\nin bias, though they require greater technical expertise. Cultural prompting\noffers broader accessibility with substantial effectiveness. These results\nunderscore the accessibility of prompt engineering for mitigating cultural bias\nwithout requiring access to model parameters. The limited number of studies\nidentified highlights a significant research gap in this critical area. Future\nresearch should focus on developing culturally adaptive prompting techniques,\ncreating Arab and Muslim-specific evaluation resources, and integrating prompt\nengineering with complementary debiasing methods to address deeper stereotypes\nwhile maintaining model utility.", "AI": {"tldr": "\u672c\u7efc\u8ff0\u7cfb\u7edf\u8bc4\u4f30\u4e86\u7528\u4e8e\u963f\u62c9\u4f2f\u548c\u7a46\u65af\u6797\u6587\u5316\u504f\u89c1\u7f13\u89e3\u7684prompt\u5de5\u7a0b\u65b9\u6cd5\uff0c\u53d1\u73b0\u7ed3\u6784\u5316\u591a\u6b65\u6d41\u7a0b\u6700\u6709\u6548\uff0c\u4f46\u9700\u8981\u66f4\u6df1\u5165\u7684\u3001\u6587\u5316\u7279\u5f02\u6027\u7814\u7a76\u548c\u8d44\u6e90\u652f\u6301\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4e2a\u9886\u57df\u5c55\u73b0\u51fa\u5353\u8d8a\u80fd\u529b\uff0c\u4f46\u5b58\u5728\u5bf9\u963f\u62c9\u4f2f\u4eba\u548c\u7a46\u65af\u6797\u6587\u5316\u504f\u89c1\uff0c\u8fd9\u5f15\u53d1\u4e86\u4f26\u7406\u62c5\u5fe7\uff0c\u5bb9\u6613\u52a0\u5267\u523b\u677f\u5370\u8c61\u548c\u8fb9\u7f18\u5316\u95ee\u9898\u3002\u5c3d\u7ba1LLMs\u504f\u89c1\u95ee\u9898\u5907\u53d7\u5173\u6ce8\uff0c\u4f46\u9488\u5bf9\u963f\u62c9\u4f2f\u548c\u7a46\u65af\u6797\u7fa4\u4f53\u7684prompt\u5de5\u7a0b\u65b9\u6cd5\u5c1a\u5c11\u6709\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7684\u7cfb\u7edf\u7efc\u8ff0\uff0c\u9075\u5faaPRISMA\u6307\u5357\u548cKitchenham\u7684\u7cfb\u7edf\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790\u4e862021-2024\u5e74\u95f48\u9879\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30\u7528\u4e8e\u51cf\u8f7b\u504f\u89c1\u7684prompt\u5de5\u7a0b\u7b56\u7565\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e94\u79cd\u4e3b\u8981\u7684prompt\u5de5\u7a0b\u65b9\u6cd5\uff1a\u6587\u5316\u5f15\u5bfc\u3001\u60c5\u611f\u542f\u52a8\u3001\u81ea\u53bb\u504f\u3001\u7ed3\u6784\u5316\u591a\u6b65\u6d41\u7a0b\u548c\u53c2\u6570\u4f18\u5316\u8fde\u7eedprompt\u3002\u5404\u79cd\u65b9\u6cd5\u5747\u6709\u51cf\u5c11\u504f\u89c1\u7684\u6f5c\u529b\uff0c\u4f46\u5bf9\u4e0d\u540c\u504f\u89c1\u7c7b\u578b\u6548\u679c\u5dee\u5f02\u8f83\u5927\u3002\u7ed3\u6784\u5316\u591a\u6b65\u6d41\u7a0b\u6548\u679c\u6700\u4f73\uff0c\u504f\u89c1\u51cf\u5c11\u9ad8\u8fbe87.7%\uff0c\u4f46\u6280\u672f\u95e8\u69db\u8f83\u9ad8\u3002\u6587\u5316\u5f15\u5bfc\u65b9\u6cd5\u5177\u6709\u826f\u597d\u53ef\u53ca\u6027\u548c\u663e\u8457\u6548\u679c\u3002", "conclusion": "prompt\u5de5\u7a0b\u53ef\u5728\u65e0\u9700\u8c03\u53c2\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u7f13\u89e3\u6587\u5316\u504f\u89c1\uff0c\u4f46\u5bf9\u67d0\u4e9b\u504f\u89c1\u7c7b\u578b\u7684\u6548\u679c\u6709\u9650\uff0c\u7279\u522b\u662f\u963f\u62c9\u4f2f\u548c\u7a46\u65af\u6797\u76f8\u5173\u9886\u57df\u4e25\u91cd\u7f3a\u4e4f\u7814\u7a76\uff0c\u9700\u53d1\u5c55\u66f4\u5177\u6587\u5316\u9002\u5e94\u6027\u7684prompt\u548c\u76f8\u5173\u8d44\u6e90\uff0c\u5c06prompt\u5de5\u7a0b\u4e0e\u5176\u4ed6\u53bb\u504f\u65b9\u6cd5\u7ed3\u5408\u4ee5\u63d0\u5347\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.17611", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17611", "abs": "https://arxiv.org/abs/2506.17611", "authors": ["Jinchuan Tian", "William Chen", "Yifan Peng", "Jiatong Shi", "Siddhant Arora", "Shikhar Bharadwaj", "Takashi Maekaku", "Yusuke Shinohara", "Keita Goto", "Xiang Yue", "Huck Yang", "Shinji Watanabe"], "title": "OpusLM: A Family of Open Unified Speech Language Models", "comment": null, "summary": "This paper presents Open Unified Speech Language Models (OpusLMs), a family\nof open foundational speech language models (SpeechLMs) up to 7B. Initialized\nfrom decoder-only text language models, the OpusLMs are continuously\npre-trained on 213K hours of speech-text pairs and 292B text-only tokens. We\ndemonstrate our OpusLMs achieve comparable (or even superior) performance with\nexisting SpeechLMs in speech recognition, speech synthesis, and text-only\ncapabilities. Technically, this paper articulates our SpeechLM designs on\ntokenization, multi-stream language models, and multi-stage training\nstrategies. We experimentally demonstrate the importance of model size scaling\nand the effect of annealing data selection. The OpusLMs are all built from\npublicly available materials and are fully transparent models. We release our\ncode, data, checkpoints, and training logs to facilitate open SpeechLM research", "AI": {"tldr": "\u63d0\u51fa\u5e76\u5f00\u6e90\u4e86\u5927\u89c4\u6a21\u3001\u9ad8\u6027\u80fd\u7684\u8bed\u97f3\u8bed\u8a00\u6a21\u578bOpusLMs\uff0c\u6a21\u578b\u53ca\u6570\u636e\u5168\u90e8\u516c\u5f00\uff0c\u6027\u80fd\u4e0e\u4e1a\u754c\u9886\u5148\u6a21\u578b\u6301\u5e73\u751a\u81f3\u66f4\u4f18\uff0c\u6781\u5927\u4fc3\u8fdb\u4e86\u5f00\u653eSpeechLM\u7814\u7a76\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u3001\u5b8c\u5168\u5f00\u6e90\u4e14\u5927\u89c4\u6a21\u7684\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\uff08SpeechLM\uff09\uff0c\u800c\u73b0\u5b58SpeechLMs\u4e3b\u8981\u96c6\u4e2d\u5728\u95ed\u6e90\u6216\u6570\u636e\u53d7\u9650\u5236\u7684\u6a21\u578b\u3002\u8be5\u8bba\u6587\u65e8\u5728\u63a8\u52a8\u5f00\u653e\u9886\u57df\u7684\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u7814\u7a76\uff0c\u63d0\u4f9b\u4e00\u4e2a\u5b8c\u6574\u53ef\u590d\u73b0\u3001\u900f\u660e\u4e14\u6269\u5c55\u6027\u5f3a\u7684\u6a21\u578b\u7cfb\u5217\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86OpusLMs\uff1a\u57fa\u4e8e\u89e3\u7801\u5668\u7684\u6587\u672c\u8bed\u8a00\u6a21\u578b\u505a\u521d\u59cb\u5316\uff0c\u968f\u540e\u5728\u5927\u89c4\u6a21\u8bed\u97f3-\u6587\u672c\u5bf9\uff08213,000\u5c0f\u65f6\uff09\u548c\u6587\u672c\u6570\u636e\uff082920\u4ebftokens\uff09\u4e0a\u6301\u7eed\u9884\u8bad\u7ec3\u3002\u6280\u672f\u4e0a\uff0c\u6587\u7ae0\u4f18\u5316\u4e86\u5206\u8bcd\u65b9\u6848\u3001\u91c7\u7528\u591a\u6d41\u6a21\u578b\u7ed3\u6784\u53ca\u5206\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5e76\u7814\u7a76\u4e86\u6a21\u578b\u5c3a\u5ea6\u6269\u5c55\u53ca\u6570\u636e\u9009\u62e9\u9000\u706b\u7684\u5f71\u54cd\u3002", "result": "OpusLMs\u5728\u8bed\u97f3\u8bc6\u522b\u3001\u8bed\u97f3\u5408\u6210\u53ca\u6587\u672c\u76f8\u5173\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u4e0e\u5f53\u524d\u4f18\u79c0SpeechLMs\u76f8\u5ab2\u7f8e\u751a\u81f3\u66f4\u4f18\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u6240\u6709\u6a21\u578b\u5747\u57fa\u4e8e\u516c\u5f00\u6570\u636e\u4e0e\u4ee3\u7801\uff0c\u6781\u5927\u589e\u5f3a\u4e86\u53ef\u590d\u73b0\u6027\u548c\u5f00\u653e\u6027\u3002", "conclusion": "OpusLMs\u7cfb\u5217\u5b9e\u73b0\u4e86\u5f00\u653e\u3001\u900f\u660e\u7684\u5927\u89c4\u6a21\u8bed\u97f3\u8bed\u8a00\u5efa\u6a21\uff0c\u4e0d\u4ec5\u6027\u80fd\u4f18\u8d8a\u4e14\u5168\u9762\u516c\u5f00\uff0c\u6709\u671b\u63a8\u52a8SpeechLMs\u793e\u533a\u7684\u5f00\u653e\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2506.17959", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17959", "abs": "https://arxiv.org/abs/2506.17959", "authors": ["Lizzy Farrugia", "Lilian M. Azzopardi", "Jeremy Debattista", "Charlie Abela"], "title": "medicX-KG: A Knowledge Graph for Pharmacists' Drug Information Needs", "comment": null, "summary": "The role of pharmacists is evolving from medicine dispensing to delivering\ncomprehensive pharmaceutical services within multidisciplinary healthcare\nteams. Central to this shift is access to accurate, up-to-date medicinal\nproduct information supported by robust data integration. Leveraging artificial\nintelligence and semantic technologies, Knowledge Graphs (KGs) uncover hidden\nrelationships and enable data-driven decision-making. This paper presents\nmedicX-KG, a pharmacist-oriented knowledge graph supporting clinical and\nregulatory decisions. It forms the semantic layer of the broader medicX\nplatform, powering predictive and explainable pharmacy services. medicX-KG\nintegrates data from three sources, including, the British National Formulary\n(BNF), DrugBank, and the Malta Medicines Authority (MMA) that addresses Malta's\nregulatory landscape and combines European Medicines Agency alignment with\npartial UK supply dependence. The KG tackles the absence of a unified national\ndrug repository, reducing pharmacists' reliance on fragmented sources. Its\ndesign was informed by interviews with practicing pharmacists to ensure\nreal-world applicability. We detail the KG's construction, including data\nextraction, ontology design, and semantic mapping. Evaluation demonstrates that\nmedicX-KG effectively supports queries about drug availability, interactions,\nadverse reactions, and therapeutic classes. Limitations, including missing\ndetailed dosage encoding and real-time updates, are discussed alongside\ndirections for future enhancements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86medicX-KG\u77e5\u8bc6\u56fe\u8c31\uff0c\u5c06\u5206\u6563\u7684\u836f\u54c1\u4fe1\u606f\u6709\u6548\u6574\u5408\uff0c\u4e3a\u836f\u5242\u5e08\u5728\u4e34\u5e8a\u548c\u76d1\u7ba1\u51b3\u7b56\u4e2d\u63d0\u4f9b\u667a\u80fd\u5316\u3001\u53ef\u89e3\u91ca\u7684\u6570\u636e\u652f\u6301\uff0c\u5e76\u7ecf\u8bc4\u4f30\u663e\u793a\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u836f\u5242\u5e08\u7684\u89d2\u8272\u6b63\u5728\u4ece\u4f20\u7edf\u7684\u914d\u836f\u5de5\u4f5c\u8f6c\u53d8\u4e3a\u5168\u65b9\u4f4d\u7684\u836f\u5b66\u670d\u52a1\u3002\u5b9e\u73b0\u8fd9\u4e00\u8f6c\u53d8\u6025\u9700\u57fa\u4e8e\u5f3a\u5927\u6570\u636e\u6574\u5408\u7684\u51c6\u786e\u3001\u6700\u65b0\u836f\u54c1\u4fe1\u606f\u3002\u76ee\u524d\u836f\u54c1\u4fe1\u606f\u6765\u6e90\u5206\u6563\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u5e73\u53f0\u5f71\u54cd\u4e86\u836f\u5242\u5e08\u7684\u51b3\u7b56\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u5e76\u6784\u5efa\u4e86\u9762\u5411\u836f\u5242\u5e08\u7684\u77e5\u8bc6\u56fe\u8c31medicX-KG\uff0c\u6574\u5408\u4e86\u82f1\u56fd\u56fd\u5bb6\u5904\u65b9\u96c6\uff08BNF\uff09\u3001DrugBank\u53ca\u9a6c\u8033\u4ed6\u836f\u54c1\u7ba1\u7406\u5c40\uff08MMA\uff09\u6570\u636e\uff0c\u8986\u76d6\u4e34\u5e8a\u53ca\u76d1\u7ba1\u51b3\u7b56\u573a\u666f\u3002\u8be5\u77e5\u8bc6\u56fe\u8c31\u901a\u8fc7\u6570\u636e\u63d0\u53d6\u3001\u672c\u4f53\u8bbe\u8ba1\u548c\u8bed\u4e49\u6620\u5c04\u5b9e\u73b0\uff0c\u4e14\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u53c2\u8003\u4e86\u4e00\u7ebf\u836f\u5242\u5e08\u7684\u9700\u6c42\u3002", "result": "medicX-KG\u53ef\u6709\u6548\u652f\u6301\u836f\u54c1\u53ef\u7528\u6027\u3001\u76f8\u4e92\u4f5c\u7528\u3001\u4e0d\u826f\u53cd\u5e94\u53ca\u6cbb\u7597\u7c7b\u76f8\u5173\u67e5\u8be2\uff0c\u66ff\u4ee3\u4e86\u5bf9\u591a\u4e2a\u96f6\u6563\u4fe1\u606f\u6e90\u7684\u4f9d\u8d56\u3002\u8bc4\u4f30\u663e\u793a\u5176\u5728\u5b9e\u9645\u67e5\u8be2\u4e2d\u6709\u826f\u597d\u8868\u73b0\uff0c\u4f46\u5b58\u5728\u5242\u91cf\u7f16\u7801\u4e0d\u591f\u7ec6\u81f4\u548c\u65e0\u6cd5\u5b9e\u65f6\u66f4\u65b0\u7b49\u5c40\u9650\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5b9e\u73b0\u4e86\u836f\u5242\u5e08\u9762\u5411\u836f\u4e8b\u5168\u6d41\u7a0b\u51b3\u7b56\u652f\u6301\u7684\u77e5\u8bc6\u8bed\u4e49\u5c42\uff0c\u63d0\u5347\u4e86\u4e1a\u52a1\u5e94\u7528\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u4e3a\u672a\u6765\u836f\u5b66\u6570\u636e\u5e73\u53f0\u6269\u5c55\u53ca\u529f\u80fd\u589e\u5f3a\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.18576", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.18576", "abs": "https://arxiv.org/abs/2506.18576", "authors": ["Matteo Melis", "Gabriella Lapesa", "Dennis Assenmacher"], "title": "A Modular Taxonomy for Hate Speech Definitions and Its Impact on Zero-Shot LLM Classification Performance", "comment": null, "summary": "Detecting harmful content is a crucial task in the landscape of NLP\napplications for Social Good, with hate speech being one of its most dangerous\nforms. But what do we mean by hate speech, how can we define it, and how does\nprompting different definitions of hate speech affect model performance? The\ncontribution of this work is twofold. At the theoretical level, we address the\nambiguity surrounding hate speech by collecting and analyzing existing\ndefinitions from the literature. We organize these definitions into a taxonomy\nof 14 Conceptual Elements-building blocks that capture different aspects of\nhate speech definitions, such as references to the target of hate (individual\nor groups) or of the potential consequences of it. At the experimental level,\nwe employ the collection of definitions in a systematic zero-shot evaluation of\nthree LLMs, on three hate speech datasets representing different types of data\n(synthetic, human-in-the-loop, and real-world). We find that choosing different\ndefinitions, i.e., definitions with a different degree of specificity in terms\nof encoded elements, impacts model performance, but this effect is not\nconsistent across all architectures.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4ec7\u6068\u8a00\u8bba\u5b9a\u4e49\u7684\u591a\u6837\u6027\uff0c\u6784\u5efa\u4e8614\u5143\u7d20\u7684\u5b9a\u4e49\u4f53\u7cfb\uff0c\u5e76\u8bc1\u660e\u4e86\u4e0d\u540c\u5b9a\u4e49\u4f1a\u5f71\u54cd\u5927\u6a21\u578b\u68c0\u6d4b\u4ec7\u6068\u8a00\u8bba\u7684\u6548\u679c\uff0c\u4f46\u4e0d\u540c\u6a21\u578b\u8868\u73b0\u4e0d\u540c\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "motivation": "\u5728NLP\u9886\u57df\uff0c\u68c0\u6d4b\u6709\u5bb3\u5185\u5bb9\uff08\u5982\u4ec7\u6068\u8a00\u8bba\uff09\u662f\u4fdd\u969c\u793e\u4ea4\u73af\u5883\u5b89\u5168\u7684\u4e00\u9879\u91cd\u8981\u6311\u6218\uff0c\u4f46\u4ec7\u6068\u8a00\u8bba\u7684\u5b9a\u4e49\u5b58\u5728\u6a21\u7cca\uff0c\u5f71\u54cd\u6a21\u578b\u68c0\u6d4b\u6548\u679c\u3002\u4f5c\u8005\u5e0c\u671b\u5f04\u6e05\u8fd9\u4e00\u5b9a\u4e49\u6b67\u4e49\u5e26\u6765\u7684\u5f71\u54cd\u3002", "method": "1. \u6536\u96c6\u5e76\u5206\u6790\u6587\u732e\u4e2d\u5df2\u6709\u7684\u4ec7\u6068\u8a00\u8bba\u5b9a\u4e49\uff0c\u5c06\u5176\u6574\u7406\u4e3a\u5305\u542b14\u4e2a\u6982\u5ff5\u5143\u7d20\u7684\u5206\u7c7b\u4f53\u7cfb\u30022. \u5206\u522b\u57fa\u4e8e\u4e0d\u540c\u7684\u5b9a\u4e49\uff0c\u5bf9\u4e09\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4e09\u7c7b\u4e0d\u540c\u7c7b\u578b\u7684\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u96f6\u6837\u672c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u4e0d\u540c\u7684\u4ec7\u6068\u8a00\u8bba\u5b9a\u4e49\uff08\u5177\u4f53\u4f53\u73b0\u5728\u6240\u5305\u542b\u7684\u5143\u7d20\u7ec6\u8282\u6570\u91cf\uff09\u4f1a\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u8fd9\u79cd\u5f71\u54cd\u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u4e2d\u8868\u73b0\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u4ec7\u6068\u8a00\u8bba\u5b9a\u4e49\u7684\u5dee\u5f02\u786e\u5b9e\u5bf9NLP\u6a21\u578b\u7684\u68c0\u6d4b\u80fd\u529b\u6709\u5f71\u54cd\uff0c\u56e0\u6b64\u7814\u7a76\u548c\u5e94\u7528\u9700\u5173\u6ce8\u5b9a\u4e49\u9009\u62e9\uff0c\u5e76\u7ed3\u5408\u5177\u4f53\u9700\u6c42\u548c\u6a21\u578b\u67b6\u6784\u8fdb\u884c\u4f18\u5316\u3002"}}
{"id": "2506.17630", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17630", "abs": "https://arxiv.org/abs/2506.17630", "authors": ["Yang Wu", "Yifan Zhang", "Yiwei Wang", "Yujun Cai", "Yurong Wu", "Yuran Wang", "Ning Xu", "Jian Cheng"], "title": "Answer-Centric or Reasoning-Driven? Uncovering the Latent Memory Anchor in LLMs", "comment": "14 pages, 8 figures", "summary": "While Large Language Models (LLMs) demonstrate impressive reasoning\ncapabilities, growing evidence suggests much of their success stems from\nmemorized answer-reasoning patterns rather than genuine inference. In this\nwork, we investigate a central question: are LLMs primarily anchored to final\nanswers or to the textual pattern of reasoning chains? We propose a five-level\nanswer-visibility prompt framework that systematically manipulates answer cues\nand probes model behavior through indirect, behavioral analysis. Experiments\nacross state-of-the-art LLMs reveal a strong and consistent reliance on\nexplicit answers. The performance drops by 26.90\\% when answer cues are masked,\neven with complete reasoning chains. These findings suggest that much of the\nreasoning exhibited by LLMs may reflect post-hoc rationalization rather than\ntrue inference, calling into question their inferential depth. Our study\nuncovers the answer-anchoring phenomenon with rigorous empirical validation and\nunderscores the need for a more nuanced understanding of what constitutes\nreasoning in LLMs.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u9a8c\u63ed\u793a\uff0cLLMs\u7684\u63a8\u7406\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4f9d\u8d56\u4e8e\u663e\u5f0f\u7b54\u6848\u63d0\u793a\uff0c\u800c\u975e\u771f\u6b63\u7684\u903b\u8f91\u63a8\u7406\uff0c\u547c\u5401\u5bf9\u5176\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u66f4\u6df1\u5165\u8ba8\u8bba\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u8d8a\u6765\u8d8a\u591a\u7684\u8bc1\u636e\u8868\u660e\uff0c\u8fd9\u79cd\u80fd\u529b\u66f4\u591a\u6765\u6e90\u4e8e\u5bf9\u7b54\u6848-\u63a8\u7406\u6a21\u5f0f\u7684\u8bb0\u5fc6\uff0c\u800c\u975e\u771f\u5b9e\u63a8\u7406\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8LLMs\u662f\u5426\u771f\u6b63\u8fdb\u884c\u63a8\u7406\uff0c\u6216\u4ec5\u4ec5\u4f9d\u8d56\u5df2\u6709\u7684\u7b54\u6848\u53ca\u5176\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e94\u7ea7\u7b54\u6848\u53ef\u89c1\u6027\u63d0\u793a\u6846\u67b6\uff0c\u7cfb\u7edf\u6027\u5730\u64cd\u7eb5\u7b54\u6848\u7ebf\u7d22\uff0c\u5e76\u901a\u8fc7\u95f4\u63a5\u7684\u884c\u4e3a\u5206\u6790\u6765\u63a2\u67e5\u6a21\u578b\u884c\u4e3a\u3002\u901a\u8fc7\u5bf9\u591a\u79cd\u524d\u6cbfLLM\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8003\u5bdf\u5176\u5bf9\u663e\u5f0f\u7b54\u6848\u7684\u4f9d\u8d56\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5f53\u7b54\u6848\u7ebf\u7d22\u88ab\u9690\u85cf\u65f6\uff0c\u5373\u4f7f\u6709\u5b8c\u6574\u7684\u63a8\u7406\u94fe\uff0c\u6a21\u578b\u6027\u80fd\u4e0b\u964d26.90%\u3002\u8fd9\u5c55\u793a\u4e86LLMs\u5bf9\u663e\u5f0f\u7b54\u6848\u7684\u9ad8\u5ea6\u4f9d\u8d56\u3002", "conclusion": "LLMs\u6240\u8868\u73b0\u51fa\u7684\u8bb8\u591a\u63a8\u7406\u80fd\u529b\u66f4\u591a\u662f\u4e8b\u540e\u5408\u7406\u5316\u800c\u975e\u771f\u6b63\u7684\u63a8\u7406\u63a8\u5bfc\uff0c\u8bf4\u660e\u5176\u63a8\u7406\u6df1\u5ea6\u503c\u5f97\u8d28\u7591\u3002\u9700\u8981\u5bf9LLMs\u63a8\u7406\u80fd\u529b\u7684\u5185\u6db5\u6709\u66f4\u7ec6\u81f4\u7684\u8ba4\u8bc6\u3002"}}
{"id": "2506.18019", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18019", "abs": "https://arxiv.org/abs/2506.18019", "authors": ["Yuanchen Bei", "Weizhi Zhang", "Siwen Wang", "Weizhi Chen", "Sheng Zhou", "Hao Chen", "Yong Li", "Jiajun Bu", "Shirui Pan", "Yizhou Yu", "Irwin King", "Fakhri Karray", "Philip S. Yu"], "title": "Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities", "comment": "20 pages, 7 figures", "summary": "AI agents have experienced a paradigm shift, from early dominance by\nreinforcement learning (RL) to the rise of agents powered by large language\nmodels (LLMs), and now further advancing towards a synergistic fusion of RL and\nLLM capabilities. This progression has endowed AI agents with increasingly\nstrong abilities. Despite these advances, to accomplish complex real-world\ntasks, agents are required to plan and execute effectively, maintain reliable\nmemory, and coordinate smoothly with other agents. Achieving these capabilities\ninvolves contending with ever-present intricate information, operations, and\ninteractions. In light of this challenge, data structurization can play a\npromising role by transforming intricate and disorganized data into\nwell-structured forms that agents can more effectively understand and process.\nIn this context, graphs, with their natural advantage in organizing, managing,\nand harnessing intricate data relationships, present a powerful data paradigm\nfor structurization to support the capabilities demanded by advanced AI agents.\nTo this end, this survey presents a first systematic review of how graphs can\nempower AI agents. Specifically, we explore the integration of graph techniques\nwith core agent functionalities, highlight notable applications, and identify\nprospective avenues for future research. By comprehensively surveying this\nburgeoning intersection, we hope to inspire the development of next-generation\nAI agents equipped to tackle increasingly sophisticated challenges with graphs.\nRelated resources are collected and continuously updated for the community in\nthe Github link.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u56fe\u7ed3\u6784\u5728\u589e\u5f3aAI\u4ee3\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u4efb\u52a1\u6267\u884c\u548c\u591a\u4ee3\u7406\u534f\u4f5c\u4e2d\u7684\u4f18\u52bf\uff0c\u603b\u7ed3\u4e86\u5f53\u524d\u8fdb\u5c55\u5e76\u5c55\u671b\u4e86\u672a\u6765\u53d1\u5c55\u8d8b\u52bf\u3002", "motivation": "AI\u4ee3\u7406\u7684\u53d1\u5c55\u4ece\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5230\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u518d\u5230\u4e24\u8005\u7684\u878d\u5408\uff0c\u4f46\u5728\u5e94\u5bf9\u771f\u5b9e\u4e16\u754c\u590d\u6742\u4efb\u52a1\u65f6\uff0c\u4ecd\u9700\u89e3\u51b3\u89c4\u5212\u3001\u6267\u884c\u3001\u8bb0\u5fc6\u548c\u591a\u4ee3\u7406\u534f\u4f5c\u7b49\u6838\u5fc3\u80fd\u529b\u95ee\u9898\u3002\u9ad8\u6548\u5904\u7406\u548c\u7406\u89e3\u590d\u6742\u6570\u636e\u6210\u4e3a\u74f6\u9888\u3002", "method": "\u672c\u7efc\u8ff0\u7cfb\u7edf\u6027\u68b3\u7406\u4e86\u56fe\u7ed3\u6784\u5728\u63d0\u5347AI\u4ee3\u7406\u80fd\u529b\u65b9\u9762\u7684\u4f5c\u7528\uff0c\u63a2\u8ba8\u4e86\u56fe\u6280\u672f\u4e0e\u4ee3\u7406\u6838\u5fc3\u529f\u80fd\u7684\u7ed3\u5408\u3001\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\uff0c\u5e76\u5bf9\u672a\u6765\u7814\u7a76\u65b9\u5411\u8fdb\u884c\u4e86\u5c55\u671b\u3002", "result": "\u56fe\u7ed3\u6784\u56e0\u5176\u4f18\u52bf\u80fd\u6709\u6548\u7ec4\u7ec7\u548c\u5904\u7406\u590d\u6742\u6570\u636e\u5173\u7cfb\uff0c\u4e3a\u63d0\u5347AI\u4ee3\u7406\u8ba1\u5212\u3001\u6267\u884c\u3001\u8bb0\u5fc6\u548c\u534f\u4f5c\u7b49\u80fd\u529b\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u652f\u6491\u3002", "conclusion": "\u672c\u7efc\u8ff0\u9996\u6b21\u7cfb\u7edf\u56de\u987e\u4e86\u56fe\u5982\u4f55\u8d4b\u80fdAI\u4ee3\u7406\uff0c\u5f3a\u8c03\u56fe\u7ed3\u6784\u5728\u63a8\u52a8AI\u4ee3\u7406\u5411\u66f4\u9ad8\u667a\u80fd\u8fdb\u5316\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u4e3a\u76f8\u5173\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2506.17637", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17637", "abs": "https://arxiv.org/abs/2506.17637", "authors": ["Yang Wu", "Yifan Zhang", "Yurong Wu", "Yuran Wang", "Junkai Zhang", "Jian Cheng"], "title": "Step-Opt: Boosting Optimization Modeling in LLMs through Iterative Data Synthesis and Structured Validation", "comment": "17 pages, 12 figures", "summary": "Large Language Models (LLMs) have revolutionized various domains but\nencounter substantial challenges in tackling optimization modeling tasks for\nOperations Research (OR), particularly when dealing with complex problem. In\nthis work, we propose Step-Opt-Instruct, a framework that augments existing\ndatasets and generates high-quality fine-tuning data tailored to optimization\nmodeling. Step-Opt-Instruct employs iterative problem generation to\nsystematically increase problem complexity and stepwise validation to\nrigorously verify data, preventing error propagation and ensuring the quality\nof the generated dataset. Leveraging this framework, we fine-tune open-source\nLLMs, including LLaMA-3-8B and Mistral-7B, to develop Step-Opt--a model that\nachieves state-of-the-art performance on benchmarks such as NL4OPT, MAMO, and\nIndustryOR. Extensive experiments demonstrate the superior performance of\nStep-Opt, especially in addressing complex OR tasks, with a notable 17.01\\%\nimprovement in micro average accuracy on difficult problems. These findings\nhighlight the effectiveness of combining structured validation with gradual\nproblem refinement to advance the automation of decision-making processes using\nLLMs.The code and dataset are available at https://github.com/samwu-learn/Step.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faStep-Opt-Instruct\uff0c\u901a\u8fc7\u9010\u6b65\u590d\u6742\u5316\u548c\u9a8c\u8bc1\u673a\u5236\u751f\u6210\u9ad8\u8d28\u91cf\u5fae\u8c03\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u5728\u8fd0\u7b79\u4f18\u5316\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5c24\u5176\u5bf9\u590d\u6742\u95ee\u9898\u51c6\u786e\u7387\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u5728\u591a\u4e2a\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u5904\u7406\u8fd0\u7b79\u5b66\u4e2d\u7684\u4f18\u5316\u5efa\u6a21\u4efb\u52a1\u4e0a\u4ecd\u7136\u9762\u4e34\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u9762\u5bf9\u590d\u6742\u95ee\u9898\u65f6\u3002\u8fd9\u9650\u5236\u4e86LLMs\u81ea\u52a8\u5316\u51b3\u7b56\u8fc7\u7a0b\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u65b9\u6cd5\u6765\u63d0\u5347\u5176\u5728\u4f18\u5316\u5efa\u6a21\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86Step-Opt-Instruct\u6846\u67b6\uff0c\u7528\u4e8e\u6269\u5145\u548c\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u9002\u7528\u4e8e\u4f18\u5316\u5efa\u6a21\u7684\u5fae\u8c03\u6570\u636e\u3002\u8be5\u6846\u67b6\u91c7\u7528\u8fed\u4ee3\u5f0f\u95ee\u9898\u751f\u6210\uff0c\u4ee5\u9010\u6b65\u589e\u52a0\u95ee\u9898\u590d\u6742\u5ea6\uff0c\u5e76\u5f15\u5165\u9010\u6b65\u9a8c\u8bc1\u673a\u5236\u4ee5\u4fdd\u8bc1\u6570\u636e\u8d28\u91cf\u548c\u9632\u6b62\u9519\u8bef\u4f20\u64ad\u3002\u57fa\u4e8e\u6b64\u6846\u67b6\u5bf9\u5f00\u6e90\u5927\u6a21\u578b\uff08\u5982LLaMA-3-8B\u548cMistral-7B\uff09\u8fdb\u884c\u5fae\u8c03\uff0c\u5f00\u53d1\u51faStep-Opt\u6a21\u578b\u3002", "result": "Step-Opt\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u4efb\u52a1\uff08NL4OPT\u3001MAMO\u3001IndustryOR\uff09\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u8fd0\u7b79\u5b66\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u5728\u96be\u9898\u4e0a\u7684\u5fae\u5e73\u5747\u51c6\u786e\u7387\u63d0\u5347\u4e8617.01%\u3002", "conclusion": "\u7ed3\u5408\u7ed3\u6784\u5316\u9a8c\u8bc1\u548c\u9010\u6b65\u590d\u6742\u5316\u95ee\u9898\u7684\u6570\u636e\u751f\u6210\u6d41\u7a0b\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316\u51b3\u7b56\u7684\u80fd\u529b\uff0c\u6709\u6548\u63a8\u52a8\u8fd0\u7b79\u4f18\u5316\u4efb\u52a1\u7684\u89e3\u51b3\u6548\u7387\u3002"}}
{"id": "2506.18044", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18044", "abs": "https://arxiv.org/abs/2506.18044", "authors": ["Joseph Babb", "Joohyung Lee"], "title": "Action Language BC+", "comment": "Journal of Logic and Computation, 2015", "summary": "Action languages are formal models of parts of natural language that are\ndesigned to describe effects of actions. Many of these languages can be viewed\nas high level notations of answer set programs structured to represent\ntransition systems. However, the form of answer set programs considered in the\nearlier work is quite limited in comparison with the modern Answer Set\nProgramming (ASP) language, which allows several useful constructs for\nknowledge representation, such as choice rules, aggregates, and abstract\nconstraint atoms. We propose a new action language called BC+, which closes the\ngap between action languages and the modern ASP language. The main idea is to\ndefine the semantics of BC+ in terms of general stable model semantics for\npropositional formulas, under which many modern ASP language constructs can be\nidentified with shorthands for propositional formulas. Language BC+ turns out\nto be sufficiently expressive to encompass the best features of other action\nlanguages, such as languages B, C, C+, and BC. Computational methods available\nin ASP solvers are readily applicable to compute BC+, which led to an\nimplementation of the language by extending system cplus2asp.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86BC+\u52a8\u4f5c\u8bed\u8a00\uff0c\u5c06\u52a8\u4f5c\u8bed\u8a00\u4e0e\u73b0\u4ee3ASP\u8bed\u8a00\u5b8c\u7f8e\u7ed3\u5408\uff0c\u5177\u5907\u66f4\u5f3a\u8868\u8fbe\u529b\uff0c\u53ef\u76f4\u63a5\u57fa\u4e8eASP\u5de5\u5177\u8ba1\u7b97\uff0c\u5bf9\u52a8\u4f5c\u5efa\u6a21\u548c\u77e5\u8bc6\u8868\u793a\u5177\u6709\u7a81\u51fa\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u73b0\u6709\u7684\u52a8\u4f5c\u8bed\u8a00\u867d\u7136\u53ef\u4ee5\u88ab\u770b\u4f5c\u662f\u8868\u793a\u8f6c\u79fb\u7cfb\u7edf\u7684\u9ad8\u5c42\u6b21\u7b54\u6848\u96c6\u7a0b\u5e8f\uff0c\u4f46\u5176\u8868\u8fbe\u80fd\u529b\u8fdc\u900a\u4e8e\u73b0\u4ee3\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u8bed\u8a00\uff0c\u5c24\u5176\u7f3a\u4e4f\u9009\u62e9\u89c4\u5219\u3001\u805a\u5408\u548c\u62bd\u8c61\u7ea6\u675f\u539f\u5b50\u7b49\u77e5\u8bc6\u8868\u793a\u7684\u6709\u7528\u7ed3\u6784\u3002\u56e0\u6b64\u6709\u5fc5\u8981\u63d0\u51fa\u4e00\u79cd\u65b0\u8bed\u8a00\uff0c\u5f25\u5408\u52a8\u4f5c\u8bed\u8a00\u4e0e\u73b0\u4ee3ASP\u8bed\u8a00\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBC+\u7684\u65b0\u52a8\u4f5c\u8bed\u8a00\uff0c\u5c06\u5176\u8bed\u4e49\u5b9a\u4e49\u4e3a\u547d\u9898\u516c\u5f0f\u7684\u4e00\u822c\u7a33\u5b9a\u6a21\u578b\u8bed\u4e49\uff0c\u5e76\u5c06\u73b0\u4ee3ASP\u8bed\u8a00\u7684\u591a\u79cd\u7ed3\u6784\u7eb3\u5165\u5230\u52a8\u4f5c\u8bed\u8a00\u4e2d\u3002\u901a\u8fc7\u8fd9\u6837\u7684\u8bbe\u8ba1\uff0cBC+\u4e0d\u4ec5\u7ee7\u627f\u4e86\u5176\u4ed6\u52a8\u4f5c\u8bed\u8a00\uff08\u5982B\u3001C\u3001C+\u548cBC\uff09\u7684\u4f18\u70b9\uff0c\u8fd8\u80fd\u517c\u5bb9\u73b0\u4ee3ASP\u8bed\u8a00\u7684\u8868\u8fbe\u80fd\u529b\u3002\u8be5\u8bed\u8a00\u7684\u6c42\u89e3\u53ef\u76f4\u63a5\u501f\u52a9ASP\u6c42\u89e3\u5668\u5b9e\u73b0\uff0c\u4e14\u5df2\u7ecf\u901a\u8fc7\u6269\u5c55cplus2asp\u7cfb\u7edf\u5b8c\u6210\u4e86\u521d\u6b65\u5b9e\u73b0\u3002", "result": "BC+\u80fd\u591f\u6db5\u76d6\u5e76\u6269\u5c55\u591a\u79cd\u73b0\u6709\u52a8\u4f5c\u8bed\u8a00\u7684\u4f18\u79c0\u7279\u6027\uff0c\u62e5\u6709\u8db3\u591f\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u80fd\u5229\u7528\u73b0\u6709ASP\u6c42\u89e3\u5668\u8fdb\u884c\u8ba1\u7b97\uff0c\u5e76\u4e14\u5df2\u7ecf\u5f00\u53d1\u51fa\u4e86\u5bf9\u5e94\u7684\u5b9e\u73b0\u5de5\u5177\u3002", "conclusion": "BC+\u5f25\u8865\u4e86\u4f20\u7edf\u52a8\u4f5c\u8bed\u8a00\u548c\u73b0\u4ee3ASP\u8bed\u8a00\u4e4b\u95f4\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u7a33\u5b9a\u6a21\u578b\u8bed\u4e49\u548c\u73b0\u6709\u7684ASP\u5de5\u5177\u589e\u5f3a\u4e86\u52a8\u4f5c\u5efa\u6a21\u7684\u80fd\u529b\u548c\u7075\u6d3b\u6027\u3002"}}
{"id": "2506.17671", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17671", "abs": "https://arxiv.org/abs/2506.17671", "authors": ["Fabien Furfaro"], "title": "TPTT: Transforming Pretrained Transformer into Titans", "comment": "6 pages, 1 figure", "summary": "Recent advances in large language models (LLMs) have led to remarkable\nprogress in natural language processing, but their computational and memory\ndemands remain a significant challenge, particularly for long-context\ninference. We introduce TPTT (Transforming Pretrained Transformer into Titans),\na novel framework for enhancing pretrained Transformer models with efficient\nlinearized attention mechanisms and advanced memory management. TPTT employs\ntechniques such as Memory as Gate (MaG) and mixed linearized attention (LiZA).\nIt is fully compatible with the Hugging Face Transformers library, enabling\nseamless adaptation of any causal LLM through parameter-efficient fine-tuning\n(LoRA) without full retraining. We show the effectiveness of TPTT on the MMLU\nbenchmark with models of approximately 1 billion parameters, observing\nsubstantial improvements in both efficiency and accuracy. For instance,\nTitans-Llama-3.2-1B achieves a 20% increase in Exact Match (EM) over its\nbaseline. Statistical analyses and comparisons with recent state-of-the-art\nmethods confirm the practical scalability and robustness of TPTT. Code is\navailable at https://github.com/fabienfrfr/tptt . Python package at\nhttps://pypi.org/project/tptt/ .", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTPTT\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u6548\u6ce8\u610f\u529b\u673a\u5236\u4e0e\u5185\u5b58\u7ba1\u7406\uff0c\u65e0\u9700\u5168\u91cf\u91cd\u8bad\u5373\u53ef\u663e\u8457\u63d0\u5347\u9884\u8bad\u7ec3Transformer\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u7684\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u6027\u80fd\u8d85\u8fc7\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u867d\u7136\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u53d6\u5f97\u4e86\u5de8\u5927\u8fdb\u5c55\uff0c\u4f46\u5176\u5728\u8ba1\u7b97\u548c\u5185\u5b58\u6d88\u8017\u4e0a\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u5c24\u5176\u662f\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u65f6\u3002\u672c\u6587\u5e0c\u671b\u89e3\u51b3\u5982\u4f55\u63d0\u5347\u9884\u8bad\u7ec3Transformer\u6a21\u578b\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86TPTT\uff08Transforming Pretrained Transformer into Titans\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u9ad8\u6548\u7684\u7ebf\u6027\u5316\u6ce8\u610f\u529b\u673a\u5236\u548c\u5148\u8fdb\u7684\u5185\u5b58\u7ba1\u7406\u65b9\u6cd5\uff0c\u5982Memory as Gate\uff08MaG\uff09\u548c\u6df7\u5408\u7ebf\u6027\u5316\u6ce8\u610f\u529b\uff08LiZA\uff09\uff0c\u5e76\u517c\u5bb9Hugging Face Transformers\u751f\u6001\uff0c\u5728\u4e0d\u9700\u5168\u90e8\u91cd\u8bad\u7ec3\u7684\u524d\u63d0\u4e0b\uff0c\u4ee5\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08\u5982LoRA\uff09\u63d0\u5347\u6a21\u578b\u80fd\u529b\u3002", "result": "\u5728MMLU\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u7ea610\u4ebf\u53c2\u6570\u91cf\u7ea7\u7684\u6a21\u578b\u4f7f\u7528TPTT\u540e\uff0c\u5728\u6548\u7387\u548c\u51c6\u786e\u7387\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f8b\u5982Titans-Llama-3.2-1B\u6a21\u578b\u7684Exact Match\uff08EM\uff09\u6307\u6807\u6bd4\u57fa\u7ebf\u63d0\u5347\u4e8620%\u3002", "conclusion": "TPTT\u80fd\u591f\u663e\u8457\u63d0\u5347\u73b0\u6709LLM\u5728\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u5177\u5907\u826f\u597d\u7684\u6269\u5c55\u6027\u548c\u517c\u5bb9\u6027\uff0c\u5e76\u7ecf\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u6700\u65b0\u7684\u540c\u7c7b\u65b9\u6cd5\u3002"}}
{"id": "2506.18056", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18056", "abs": "https://arxiv.org/abs/2506.18056", "authors": ["Paolo Baldi", "Fabio Aurelio D'Asaro", "Abeer Dyoub", "Francesca Alessandra Lisi"], "title": "Weighted Assumption Based Argumentation to reason about ethical principles and actions", "comment": null, "summary": "We augment Assumption Based Argumentation (ABA for short) with weighted\nargumentation. In a nutshell, we assign weights to arguments and then derive\nthe weight of attacks between ABA arguments. We illustrate our proposal through\nrunning examples in the field of ethical reasoning, and present an\nimplementation based on Answer Set Programming.", "AI": {"tldr": "\u672c\u6587\u5c06\u52a0\u6743\u673a\u5236\u5f15\u5165\u5230\u57fa\u4e8e\u5047\u8bbe\u7684\u8bba\u8bc1\uff08ABA\uff09\u4e2d\uff0c\u901a\u8fc7\u4f26\u7406\u63a8\u7406\u6848\u4f8b\u6f14\u793a\u65b0\u7684\u65b9\u6cd5\uff0c\u5e76\u7ed9\u51fa\u4e86\u4e00\u5957\u57fa\u4e8eASP\u7684\u5b9e\u73b0\uff0c\u63d0\u5347\u4e86ABA\u5728\u5904\u7406\u590d\u6742\u8bba\u8bc1\u65f6\u7684\u80fd\u529b\u4e0e\u7075\u6d3b\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u5047\u8bbe\u7684\u8bba\u8bc1\uff08ABA\uff09\u6ca1\u6709\u8003\u8651\u5230\u8bba\u636e\u7684\u91cd\u8981\u6027\u6216\u6743\u91cd\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u67d0\u4e9b\u9700\u8981\u533a\u5206\u8bba\u636e\u5f71\u54cd\u7a0b\u5ea6\u7684\u9886\u57df\u7684\u5e94\u7528\uff0c\u5982\u4f26\u7406\u63a8\u7406\u3002", "method": "\u5728ABA\u8bba\u8bc1\u6846\u67b6\u4e2d\u5f15\u5165\u52a0\u6743\u673a\u5236\uff1a\u4e3a\u8bba\u636e\u5206\u914d\u6743\u91cd\uff0c\u5e76\u636e\u6b64\u8ba1\u7b97ABA\u8bba\u636e\u4e4b\u95f4\u653b\u51fb\u7684\u6743\u91cd\u3002\u4f7f\u7528\u4f26\u7406\u63a8\u7406\u6848\u4f8b\u4f5c\u4e3a\u5b9e\u4f8b\u8fdb\u884c\u8bf4\u660e\uff0c\u5e76\u57fa\u4e8eAnswer Set Programming\u5b9e\u73b0\u4e86\u8be5\u65b9\u6848\u3002", "result": "\u6210\u529f\u6f14\u793a\u4e86\u5982\u4f55\u5728ABA\u8bba\u8bc1\u4e2d\u5f15\u5165\u52a0\u6743\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u5b9e\u73b0\u5c55\u793a\u5176\u53ef\u884c\u6027\u3002\u57fa\u4e8e\u52a0\u6743\u7684\u6846\u67b6\u80fd\u591f\u66f4\u597d\u5730\u652f\u6301\u4f26\u7406\u63a8\u7406\u60c5\u5883\u4e0b\u7684\u8fa9\u8bc1\u5206\u6790\u3002", "conclusion": "\u5c06\u6743\u91cd\u7eb3\u5165ABA\u6846\u67b6\u80fd\u591f\u63d0\u5347\u5176\u8868\u8fbe\u529b\u548c\u9002\u7528\u6027\uff0c\u5c24\u5176\u9002\u5408\u5e94\u7528\u4e8e\u5bf9\u8bba\u70b9\u91cd\u8981\u6027\u654f\u611f\u7684\u9886\u57df\uff0c\u5982\u4f26\u7406\u63a8\u7406\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5df2\u7ecf\u8fc7\u8fd0\u884c\u5b9e\u4f8b\u548c\u539f\u578b\u7cfb\u7edf\u7684\u9a8c\u8bc1\u3002"}}
{"id": "2506.17692", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17692", "abs": "https://arxiv.org/abs/2506.17692", "authors": ["Binquan Ji", "Haibo Luo", "Yifei Lu", "Lei Hei", "Jiaqi Wang", "Tingjing Liao", "Lingyu Wang", "Shichao Wang", "Feiliang Ren"], "title": "Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering", "comment": null, "summary": "Knowledge-intensive multi-hop question answering (QA) tasks, which require\nintegrating evidence from multiple sources to address complex queries, often\nnecessitate multiple rounds of retrieval and iterative generation by large\nlanguage models (LLMs). However, incorporating many documents and extended\ncontexts poses challenges -such as hallucinations and semantic drift-for\nlightweight LLMs with fewer parameters. This work proposes a novel framework\ncalled DEC (Dynamic Enhancement Chain). DEC first decomposes complex questions\ninto logically coherent subquestions to form a hallucination-free reasoning\nchain. It then iteratively refines these subquestions through context-aware\nrewriting to generate effective query formulations. For retrieval, we introduce\na lightweight discriminative keyword extraction module that leverages extracted\nkeywords to achieve targeted, precise document recall with relatively low\ncomputational overhead. Extensive experiments on three multi-hop QA datasets\ndemonstrate that DEC performs on par with or surpasses state-of-the-art\nbenchmarks while significantly reducing token consumption. Notably, our\napproach attains state-of-the-art results on models with 8B parameters,\nshowcasing its effectiveness in various scenarios, particularly in\nresource-constrained environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDEC\u52a8\u6001\u589e\u5f3a\u94fe\u6846\u67b6\uff0c\u901a\u8fc7\u62c6\u89e3\u4e0e\u91cd\u5199\u5b50\u95ee\u9898\u53ca\u9ad8\u6548\u5173\u952e\u8bcd\u68c0\u7d22\uff0c\u663e\u8457\u63d0\u5347\u8f7b\u91cf\u7ea7LLM\u5728\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u517c\u987e\u7cbe\u5ea6\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u53d6\u5f97\u4e86\u65b0\u7684\u6700\u4f18\u5b9e\u9a8c\u7ed3\u679c\u3002", "motivation": "\u77e5\u8bc6\u5bc6\u96c6\u578b\u7684\u591a\u8df3\u95ee\u7b54\uff08QA\uff09\u4efb\u52a1\u9700\u8981\u6574\u5408\u591a\u4e2a\u6765\u6e90\u7684\u4fe1\u606f\u4ee5\u56de\u7b54\u590d\u6742\u95ee\u9898\uff0c\u800c\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\uff08\u53c2\u6570\u8f83\u5c11\u7684LLMs\uff09\u5728\u5904\u7406\u5927\u91cf\u6587\u6863\u548c\u957f\u4e0a\u4e0b\u6587\u65f6\u5bb9\u6613\u51fa\u73b0\u865a\u5047\u5185\u5bb9\u548c\u8bed\u4e49\u6f02\u79fb\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u589e\u5f3a\u94fe\uff08DEC\uff09\u6846\u67b6\uff1a\u9996\u5148\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u903b\u8f91\u8fde\u8d2f\u7684\u5b50\u95ee\u9898\uff0c\u907f\u514d\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5e7b\u89c9\uff1b\u968f\u540e\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u91cd\u5199\u4e0d\u65ad\u4f18\u5316\u5b50\u95ee\u9898\u8868\u8ff0\uff1b\u5728\u68c0\u7d22\u8fc7\u7a0b\u4e2d\uff0c\u57fa\u4e8e\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5224\u522b\u6027\u5173\u952e\u8bcd\u63d0\u53d6\u6a21\u5757\uff0c\u5229\u7528\u5173\u952e\u8bcd\u9ad8\u6548\u56de\u5fc6\u76f8\u5173\u6587\u6863\uff0c\u4fdd\u8bc1\u7cbe\u786e\u7684\u68c0\u7d22\u4e14\u8ba1\u7b97\u6d88\u8017\u8f83\u4f4e\u3002", "result": "\u5728\u4e09\u4e2a\u591a\u8df3QA\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0cDEC\u6846\u67b6\u80fd\u8fbe\u5230\u6216\u8d85\u8fc7\u540c\u7c7b\u6700\u4f18\u6c34\u5e73\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86token\u6d88\u8017\u3002\u5c24\u5176\u57288B\u53c2\u6570\u6a21\u578b\u4e0a\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u4f18\u7ed3\u679c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\uff0c\u5c24\u5176\u9002\u5408\u7b97\u529b\u8d44\u6e90\u53d7\u9650\u7684\u573a\u666f\u3002", "conclusion": "DEC\u4e3a\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8f7b\u91cf\u7ea7LLMs\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u80fd\u6709\u6548\u63a7\u5236\u5e7b\u89c9\u95ee\u9898\u7684\u89e3\u51b3\u6846\u67b6\uff0c\u4e0d\u4f46\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d1f\u62c5\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.18096", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18096", "abs": "https://arxiv.org/abs/2506.18096", "authors": ["Yuxuan Huang", "Yihang Chen", "Haozheng Zhang", "Kang Li", "Meng Fang", "Linyi Yang", "Xiaoguang Li", "Lifeng Shang", "Songcen Xu", "Jianye Hao", "Kun Shao", "Jun Wang"], "title": "Deep Research Agents: A Systematic Examination And Roadmap", "comment": null, "summary": "The rapid progress of Large Language Models (LLMs) has given rise to a new\ncategory of autonomous AI systems, referred to as Deep Research (DR) agents.\nThese agents are designed to tackle complex, multi-turn informational research\ntasks by leveraging a combination of dynamic reasoning, adaptive long-horizon\nplanning, multi-hop information retrieval, iterative tool use, and the\ngeneration of structured analytical reports. In this paper, we conduct a\ndetailed analysis of the foundational technologies and architectural components\nthat constitute Deep Research agents. We begin by reviewing information\nacquisition strategies, contrasting API-based retrieval methods with\nbrowser-based exploration. We then examine modular tool-use frameworks,\nincluding code execution, multimodal input processing, and the integration of\nModel Context Protocols (MCPs) to support extensibility and ecosystem\ndevelopment. To systematize existing approaches, we propose a taxonomy that\ndifferentiates between static and dynamic workflows, and we classify agent\narchitectures based on planning strategies and agent composition, including\nsingle-agent and multi-agent configurations. We also provide a critical\nevaluation of current benchmarks, highlighting key limitations such as\nrestricted access to external knowledge, sequential execution inefficiencies,\nand misalignment between evaluation metrics and the practical objectives of DR\nagents. Finally, we outline open challenges and promising directions for future\nresearch. A curated and continuously updated repository of DR agent research is\navailable at: {https://github.com/ai-agents-2030/awesome-deep-research-agent}.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u548c\u7cfb\u7edf\u68b3\u7406\u4e86\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u7684\u6280\u672f\u57fa\u7840\u3001\u67b6\u6784\u5206\u7c7b\u548c\u5de5\u5177\u751f\u6001\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u8bc4\u6d4b\u4e0e\u5b9e\u9645\u6548\u679c\u7684\u9519\u4f4d\u53ca\u6548\u7387\u74f6\u9888\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "LLMs\u63a8\u52a8\u4e0b\u7684\u81ea\u4e3bAI\u7cfb\u7edf\uff08DR\u667a\u80fd\u4f53\uff09\u5d1b\u8d77\uff0c\u4f46\u5f53\u524d\u7f3a\u4e4f\u7cfb\u7edf\u68b3\u7406\u4e0e\u7edf\u4e00\u5206\u7c7b\uff0c\u4e14\u73b0\u6709\u8bc4\u6d4b\u4f53\u7cfb\u4e0d\u80fd\u5b8c\u5168\u53cd\u6620\u5176\u5b9e\u9645\u80fd\u529b\uff0c\u56e0\u6b64\u4e9f\u9700\u5168\u9762\u5206\u6790\u548c\u6307\u5bfc\u672a\u6765\u7814\u7a76\u3002", "method": "\u5bf9LLM\u9a71\u52a8\u7684DR\u667a\u80fd\u4f53\u7684\u6280\u672f\u7ec4\u4ef6\uff08\u5982\u4fe1\u606f\u68c0\u7d22\u3001\u5de5\u5177\u5229\u7528\u3001\u67b6\u6784\u5206\u5c42\uff09\u8fdb\u884c\u6587\u732e\u7efc\u8ff0\u548c\u7cfb\u7edf\u5f52\u7c7b\uff0c\u5bf9\u73b0\u6709\u5de5\u4f5c\u5efa\u7acb\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u5bf9\u8bc4\u6d4b\u57fa\u51c6\u8fdb\u884c\u5206\u6790\u548c\u8ba8\u8bba\u672a\u6765\u65b9\u5411\u3002", "result": "\u63d0\u51fa\u4e86\u9759\u6001\u4e0e\u52a8\u6001\u5de5\u4f5c\u6d41\u7684\u7cfb\u7edf\u5206\u7c7b\uff0c\u5206\u6790\u4e86\u591a\u5de5\u5177\u3001\u591a\u6a21\u6001\u548c\u6a21\u578b\u534f\u8bae\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u6307\u51fa\u4e86\u5f53\u524dDR\u667a\u80fd\u4f53\u5728\u5916\u90e8\u77e5\u8bc6\u83b7\u53d6\u3001\u6267\u884c\u6548\u7387\u548c\u6027\u80fd\u8bc4\u4f30\u7b49\u65b9\u9762\u7684\u4e3b\u8981\u4e0d\u8db3\uff0c\u5e76\u53d1\u5e03\u4e86\u76f8\u5173\u7814\u7a76\u8d44\u6e90\u5e93\u3002", "conclusion": "\u672c\u6587\u8be6\u7ec6\u5206\u6790\u4e86\u6df1\u5ea6\u7814\u7a76\uff08Deep Research, DR\uff09\u667a\u80fd\u4f53\u7684\u57fa\u7840\u6280\u672f\u4e0e\u67b6\u6784\uff0c\u63d0\u51fa\u4e86\u7cfb\u7edf\u5316\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u6279\u5224\u6027\u5730\u8bc4\u4f30\u4e86\u73b0\u6709\u57fa\u51c6\u548c\u672a\u6765\u6311\u6218\u3002"}}
{"id": "2506.17693", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17693", "abs": "https://arxiv.org/abs/2506.17693", "authors": ["Yuzhe Ding", "Kang He", "Bobo Li", "Li Zheng", "Haijun He", "Fei Li", "Chong Teng", "Donghong Ji"], "title": "Zero-Shot Conversational Stance Detection: Dataset and Approaches", "comment": "ACL 2025 (Findings)", "summary": "Stance detection, which aims to identify public opinion towards specific\ntargets using social media data, is an important yet challenging task. With the\nincreasing number of online debates among social media users, conversational\nstance detection has become a crucial research area. However, existing\nconversational stance detection datasets are restricted to a limited set of\nspecific targets, which constrains the effectiveness of stance detection models\nwhen encountering a large number of unseen targets in real-world applications.\nTo bridge this gap, we manually curate a large-scale, high-quality zero-shot\nconversational stance detection dataset, named ZS-CSD, comprising 280 targets\nacross two distinct target types. Leveraging the ZS-CSD dataset, we propose\nSITPCL, a speaker interaction and target-aware prototypical contrastive\nlearning model, and establish the benchmark performance in the zero-shot\nsetting. Experimental results demonstrate that our proposed SITPCL model\nachieves state-of-the-art performance in zero-shot conversational stance\ndetection. Notably, the SITPCL model attains only an F1-macro score of 43.81%,\nhighlighting the persistent challenges in zero-shot conversational stance\ndetection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5927\u89c4\u6a21\u96f6\u6837\u672c\u5bf9\u8bdd\u7acb\u573a\u68c0\u6d4b\u6570\u636e\u96c6\uff08ZS-CSD\uff09\u548cSITPCL\u6a21\u578b\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u53d1\u5c55\uff0c\u4f46\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u96f6\u6837\u672c\u5bf9\u8bdd\u7acb\u573a\u68c0\u6d4b\u4f9d\u65e7\u6781\u5177\u6311\u6218\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e2d\u9488\u5bf9\u7279\u5b9a\u8bae\u9898\u7684\u7acb\u573a\u68c0\u6d4b\u662f\u4e00\u4e2a\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u3002\u968f\u7740\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u5728\u7ebf\u8fa9\u8bba\u7684\u589e\u591a\uff0c\u57fa\u4e8e\u5bf9\u8bdd\u7684\u7acb\u573a\u68c0\u6d4b\u9010\u6e10\u6210\u4e3a\u7814\u7a76\u91cd\u70b9\u3002\u4f46\u73b0\u6709\u6570\u636e\u96c6\u76ee\u6807\u6709\u9650\uff0c\u96be\u4ee5\u9002\u5e94\u771f\u5b9e\u4e16\u754c\u4e2d\u5927\u91cf\u672a\u89c1\u8fc7\u7684\u65b0\u76ee\u6807\u3002", "method": "\u4f5c\u8005\u4eba\u5de5\u6574\u7406\u4e86\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u7684\u96f6\u6837\u672c\u5bf9\u8bdd\u7acb\u573a\u68c0\u6d4b\u6570\u636e\u96c6\uff08ZS-CSD\uff09\uff0c\u6db5\u76d6280\u4e2a\u76ee\u6807\uff0c\u5e76\u63d0\u51fa\u4e86SITPCL\u6a21\u578b\uff08\u7ed3\u5408\u8bf4\u8bdd\u8005\u4ea4\u4e92\u548c\u76ee\u6807\u611f\u77e5\u7684\u539f\u578b\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff09\uff0c\u5728\u96f6\u6837\u672c\u573a\u666f\u4e0b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "SITPCL\u6a21\u578b\u5728\u96f6\u6837\u672c\u5bf9\u8bdd\u7acb\u573a\u68c0\u6d4b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u5f53\u524d\u6700\u4f18\u7ed3\u679c\uff0c\u4f46\u5176F1-macro\u5206\u6570\u4ec5\u4e3a43.81%\uff0c\u8bf4\u660e\u5728\u8be5\u9886\u57df\u4ecd\u5b58\u5728\u663e\u8457\u6311\u6218\u3002", "conclusion": "\u63d0\u51fa\u7684ZS-CSD\u6570\u636e\u96c6\u548cSITPCL\u6a21\u578b\u63d0\u5347\u4e86\u96f6\u6837\u672c\u5bf9\u8bdd\u7acb\u573a\u68c0\u6d4b\u7684\u7814\u7a76\u6c34\u5e73\uff0c\u4f46\u5b9e\u9645\u6027\u80fd\u4ecd\u663e\u793a\u8be5\u4efb\u52a1\u7684\u9ad8\u96be\u5ea6\u3002"}}
{"id": "2506.18126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18126", "abs": "https://arxiv.org/abs/2506.18126", "authors": ["Xiang Yuming", "Li Sizhao", "Li Rongpeng", "Zhao Zhifeng", "Zhang Honggang"], "title": "Decentralized Consensus Inference-based Hierarchical Reinforcement Learning for Multi-Constrained UAV Pursuit-Evasion Game", "comment": null, "summary": "Multiple quadrotor unmanned aerial vehicle (UAV) systems have garnered\nwidespread research interest and fostered tremendous interesting applications,\nespecially in multi-constrained pursuit-evasion games (MC-PEG). The Cooperative\nEvasion and Formation Coverage (CEFC) task, where the UAV swarm aims to\nmaximize formation coverage across multiple target zones while collaboratively\nevading predators, belongs to one of the most challenging issues in MC-PEG,\nespecially under communication-limited constraints. This multifaceted problem,\nwhich intertwines responses to obstacles, adversaries, target zones, and\nformation dynamics, brings up significant high-dimensional complications in\nlocating a solution. In this paper, we propose a novel two-level framework\n(i.e., Consensus Inference-based Hierarchical Reinforcement Learning (CI-HRL)),\nwhich delegates target localization to a high-level policy, while adopting a\nlow-level policy to manage obstacle avoidance, navigation, and formation.\nSpecifically, in the high-level policy, we develop a novel multi-agent\nreinforcement learning module, Consensus-oriented Multi-Agent Communication\n(ConsMAC), to enable agents to perceive global information and establish\nconsensus from local states by effectively aggregating neighbor messages.\nMeanwhile, we leverage an Alternative Training-based Multi-agent proximal\npolicy optimization (AT-M) and policy distillation to accomplish the low-level\ncontrol. The experimental results, including the high-fidelity\nsoftware-in-the-loop (SITL) simulations, validate that CI-HRL provides a\nsuperior solution with enhanced swarm's collaborative evasion and task\ncompletion capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u591a\u65e0\u4eba\u673a\u534f\u540c\u89c4\u907f\u4e0e\u7f16\u961f\u8986\u76d6\u6846\u67b6\uff08CI-HRL\uff09\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u5f3a\u5316\u5b66\u4e60\u4e0e\u5171\u8bc6\u901a\u4fe1\u673a\u5236\uff0c\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u7fa4\u5728\u590d\u6742\u73af\u5883\u4e0b\u7684\u534f\u4f5c\u4e0e\u81ea\u4e3b\u80fd\u529b\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u591a\u65cb\u7ffc\u65e0\u4eba\u673a\u7cfb\u7edf\u5728\u591a\u7ea6\u675f\u8ffd\u9003\u535a\u5f08\uff08MC-PEG\uff09\u4e2d\u6709\u91cd\u8981\u5e94\u7528\uff0c\u5c24\u5176\u5728\u901a\u4fe1\u53d7\u9650\u4e0b\u7684\u534f\u540c\u89c4\u907f\u548c\u7f16\u961f\u8986\u76d6\u4efb\u52a1\uff08CEFC\uff09\u4ecd\u9762\u4e34\u9ad8\u7ef4\u3001\u590d\u6742\u73af\u5883\u4e0b\u7684\u6311\u6218\u3002\u5f53\u524d\u7f3a\u4e4f\u80fd\u591f\u9ad8\u6548\u534f\u540c\u89c4\u907f\u6355\u98df\u8005\u3001\u8986\u76d6\u76ee\u6807\u533a\u5e76\u5e94\u5bf9\u969c\u788d\u4e0e\u901a\u4fe1\u9650\u5236\u7684\u6709\u6548\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u5c42\u6b21\u6846\u67b6\uff1a\u5171\u8bc6\u63a8\u65ad\u57fa\u7840\u7684\u5c42\u6b21\u5316\u5f3a\u5316\u5b66\u4e60\uff08CI-HRL\uff09\u3002\u9ad8\u5c42\u7b56\u7565\u8d1f\u8d23\u76ee\u6807\u5b9a\u4f4d\uff0c\u878d\u5408\u4e86\u5171\u8bc6\u5bfc\u5411\u7684\u591a\u667a\u80fd\u4f53\u901a\u4fe1\u6a21\u5757\uff08ConsMAC\uff09\uff0c\u901a\u8fc7\u90bb\u5c45\u4fe1\u606f\u805a\u5408\u5e2e\u52a9\u667a\u80fd\u4f53\u8fbe\u6210\u5168\u5c40\u7406\u89e3\u4e0e\u5171\u8bc6\u3002\u4f4e\u5c42\u901a\u8fc7\u66ff\u4ee3\u8bad\u7ec3\u7684\u591a\u667a\u80fd\u4f53PPO\uff08AT-M\uff09\u548c\u7b56\u7565\u84b8\u998f\uff0c\u5b9e\u73b0\u969c\u788d\u89c4\u907f\u3001\u5bfc\u822a\u53ca\u7f16\u961f\u63a7\u5236\u3002", "result": "\u5b9e\u9a8c\uff08\u5305\u62ec\u9ad8\u4fdd\u771fSITL\u4eff\u771f\uff09\u8868\u660e\uff0cCI-HRL\u65b9\u6848\u5728\u534f\u540c\u89c4\u907f\u548c\u4efb\u52a1\u5b8c\u6210\u6548\u679c\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u7fa4\u7684\u4efb\u52a1\u534f\u540c\u80fd\u529b\u548c\u6548\u80fd\u3002", "conclusion": "CI-HRL\u4e3a\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\u5728\u591a\u7ea6\u675f\u73af\u5883\u4e0b\u6267\u884c\u89c4\u907f\u4e0e\u8986\u76d6\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u3001\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u901a\u4fe1\u53d7\u9650\u548c\u590d\u6742\u52a8\u6001\u73af\u5883\u3002"}}
{"id": "2506.17700", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17700", "abs": "https://arxiv.org/abs/2506.17700", "authors": ["Summra Saleem", "Muhammad Nabeel Asim", "Shaista Zulfiqar", "Andreas Dengel"], "title": "The Evolution of Natural Language Processing: How Prompt Optimization and Language Models are Shaping the Future", "comment": null, "summary": "Large Language Models (LLMs) have revolutionized the field of Natural\nLanguage Processing (NLP) by automating traditional labor-intensive tasks and\nconsequently accelerated the development of computer-aided applications. As\nresearchers continue to advance this field with the introduction of novel\nlanguage models and more efficient training/finetuning methodologies, the idea\nof prompt engineering and subsequent optimization strategies with LLMs has\nemerged as a particularly impactful trend to yield a substantial performance\nboost across diverse NLP tasks. To best of our knowledge numerous review\narticles have explored prompt engineering, however, a critical gap exists in\ncomprehensive analyses of prompt optimization strategies. To bridge this gap\nthis paper provides unique and comprehensive insights about the potential of\ndiverse prompt optimization strategies. It analyzes their underlying working\nparadigms and based on these principles, categorizes them into 11 distinct\nclasses. Moreover, the paper provides details about various NLP tasks where\nthese prompt optimization strategies have been employed, along with details of\ndifferent LLMs and benchmark datasets used for evaluation. This comprehensive\ncompilation lays a robust foundation for future comparative studies and enables\nrigorous assessment of prompt optimization and LLM-based predictive pipelines\nunder consistent experimental settings: a critical need in the current\nlandscape. Ultimately, this research will centralize diverse strategic\nknowledge to facilitate the adaptation of existing prompt optimization\nstrategies for development of innovative predictors across unexplored tasks.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u5e76\u5206\u7c7b\u603b\u7ed3\u4e86\u591a\u79cdPrompt\u4f18\u5316\u7b56\u7565\u53ca\u5176\u5728NLP\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u6709\u52a9\u4e8e\u540e\u7eed\u76f8\u5173\u5de5\u4f5c\u7684\u5bf9\u6bd4\u548c\u65b0\u65b9\u6cd5\u7684\u53d1\u5c55\u3002", "motivation": "\u867d\u7136\u5df2\u6709\u8bb8\u591a\u7efc\u8ff0\u63a2\u8ba8\u4e86Prompt\u5de5\u7a0b\uff0c\u4f46\u5173\u4e8ePrompt\u4f18\u5316\u7b56\u7565\u7684\u7cfb\u7edf\u6027\u5206\u6790\u4ecd\u5b58\u5728\u7a7a\u767d\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u8fd9\u4e9b\u7b56\u7565\u8fdb\u884c\u6df1\u5165\u68b3\u7406\u548c\u5206\u7c7b\u3002", "method": "\u7efc\u5408\u68b3\u7406\u5f53\u524d\u591a\u6837\u7684Prompt\u4f18\u5316\u65b9\u6cd5\uff0c\u5bf9\u5176\u5de5\u4f5c\u539f\u7406\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u4f9d\u636e\u539f\u7406\u5c06\u5176\u5f52\u4e3a11\u4e2a\u7c7b\u522b\u3002\u540c\u65f6\uff0c\u603b\u7ed3\u8fd9\u4e9b\u7b56\u7565\u5728\u5404\u7c7bNLP\u4efb\u52a1\u3001\u4e0d\u540cLLM\u6a21\u578b\u548c\u5e38\u7528\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\u60c5\u51b5\u3002", "result": "\u5efa\u7acb\u4e86Prompt\u4f18\u5316\u7b56\u7565\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u8be6\u7ec6\u7f57\u5217\u4e86\u5b83\u4eec\u5728NLP\u9886\u57df\u4e2d\u7684\u5e94\u7528\u548c\u8bc4\u6d4b\u60c5\u51b5\uff0c\u4e3a\u4eca\u540e\u76f8\u5173\u65b9\u6cd5\u7684\u6bd4\u8f83\u4e0e\u53d1\u5c55\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u8d44\u6599\u3002", "conclusion": "\u672c\u7814\u7a76\u586b\u8865\u4e86Prompt\u4f18\u5316\u7b56\u7565\u7cfb\u7edf\u5206\u6790\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765LLM\u76f8\u5173\u7814\u7a76\u548c\u65b0\u4efb\u52a1\u7684\u7b97\u6cd5\u521b\u65b0\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u65b9\u6cd5\u57fa\u7840\u3002"}}
{"id": "2506.18135", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18135", "abs": "https://arxiv.org/abs/2506.18135", "authors": ["Zijun Chen", "Zhanpeng Zhou", "Bo Zhang", "Weinan Zhang", "Xi Sun", "Junchi Yan"], "title": "SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging", "comment": "preprint, accepted at IJCNN2025", "summary": "Model merging has gained increasing attention due to its intriguing property:\ninterpolating the parameters of different task-specific fine-tuned models leads\nto multi-task abilities. However, despite its empirical success, the underlying\nmechanisms of model merging remain poorly understood. In this work, we delve\ninto the mechanism behind model merging from a representation perspective. Our\nanalysis reveals that model merging achieves multi-task abilities through two\nkey capabilities: i) distinguishing samples from different tasks, and ii)\nadapting to the corresponding expert model for each sample. These two\ncapabilities allow the merged model to retain task-specific expertise, enabling\nefficient multi-task adaptation. Building on these insights, we propose\n\\texttt{SE-Merging}, a self-enhanced model merging framework that leverages\nthese two characteristics to dynamically identify the corresponding task for\neach sample and then adaptively rescales the merging coefficients to further\nenhance task-specific expertise in the merged model. Notably,\n\\texttt{SE-Merging} achieves dynamic model merging without additional training.\nExtensive experiments demonstrate that \\texttt{SE-Merging} achieves significant\nperformance improvements while remaining compatible with existing model merging\ntechniques.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u6a21\u578b\u5408\u5e76\u5b9e\u73b0\u591a\u4efb\u52a1\u80fd\u529b\u7684\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u4e86SE-Merging\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u80fd\u6839\u636e\u6837\u672c\u52a8\u6001\u8c03\u6574\u5408\u5e76\u53c2\u6570\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u591a\u4efb\u52a1\u6a21\u578b\u6027\u80fd\u4e14\u517c\u5bb9\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u6a21\u578b\u5408\u5e76\u56e0\u5176\u53ef\u4ee5\u901a\u8fc7\u63d2\u503c\u4e0d\u540c\u4efb\u52a1\u7684\u5fae\u8c03\u6a21\u578b\u53c2\u6570\uff0c\u83b7\u5f97\u591a\u4efb\u52a1\u80fd\u529b\u800c\u5907\u53d7\u5173\u6ce8\u3002\u7136\u800c\uff0c\u5176\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u6587\u65e8\u5728\u4ece\u8868\u793a\u5b66\u4e60\u7684\u89d2\u5ea6\u6df1\u5165\u63a2\u8ba8\u6a21\u578b\u5408\u5e76\u80cc\u540e\u7684\u673a\u7406\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5206\u6790\uff0c\u53d1\u73b0\u6a21\u578b\u5408\u5e76\u5b9e\u73b0\u591a\u4efb\u52a1\u80fd\u529b\u4e3b\u8981\u6e90\u4e8e\uff1a\u4e00\u662f\u533a\u5206\u4e0d\u540c\u4efb\u52a1\u7684\u6837\u672c\uff0c\u4e8c\u662f\u9488\u5bf9\u6bcf\u4e2a\u6837\u672c\u9002\u5e94\u76f8\u5e94\u7684\u4e13\u5bb6\u6a21\u578b\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86SE-Merging\u6846\u67b6\uff0c\u53ef\u52a8\u6001\u8bc6\u522b\u6837\u672c\u6240\u5c5e\u4efb\u52a1\uff0c\u5e76\u81ea\u9002\u5e94\u8c03\u6574\u5408\u5e76\u7cfb\u6570\uff0c\u4ece\u800c\u63d0\u5347\u878d\u5408\u6a21\u578b\u7684\u4efb\u52a1\u4e13\u957f\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "result": "SE-Merging\u5728\u4e0d\u7528\u989d\u5916\u8bad\u7ec3\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u52a8\u6001\u6a21\u578b\u5408\u5e76\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0e\u73b0\u6709\u6a21\u578b\u5408\u5e76\u6280\u672f\u517c\u5bb9\u7684\u540c\u65f6\uff0c\u6027\u80fd\u6709\u660e\u663e\u63d0\u5347\u3002", "conclusion": "SE-Merging\u4ee5\u81ea\u9002\u5e94\u7684\u65b9\u5f0f\u5b9e\u73b0\u6a21\u578b\u5408\u5e76\uff0c\u4e0d\u4ec5\u589e\u5f3a\u4e86\u4efb\u52a1\u7279\u5f02\u80fd\u529b\uff0c\u800c\u4e14\u63d0\u4f9b\u4e86\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u591a\u4efb\u52a1\u9002\u914d\u673a\u5236\uff0c\u53ef\u5e7f\u6cdb\u517c\u5bb9\u5e76\u63d0\u5347\u73b0\u6709\u6a21\u578b\u5408\u5e76\u6280\u672f\u7684\u6548\u679c\u3002"}}
{"id": "2506.17708", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17708", "abs": "https://arxiv.org/abs/2506.17708", "authors": ["MingZe Tang"], "title": "Aged to Perfection: Machine-Learning Maps of Age in Conversational English", "comment": "6 pages, 11 figures", "summary": "The study uses the British National Corpus 2014, a large sample of\ncontemporary spoken British English, to investigate language patterns across\ndifferent age groups. Our research attempts to explore how language patterns\nvary between different age groups, exploring the connection between speaker\ndemographics and linguistic factors such as utterance duration, lexical\ndiversity, and word choice. By merging computational language analysis and\nmachine learning methodologies, we attempt to uncover distinctive linguistic\nmarkers characteristic of multiple generations and create prediction models\nthat can consistently estimate the speaker's age group from various aspects.\nThis work contributes to our knowledge of sociolinguistic diversity throughout\nthe life of modern British speech.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u82f1\u56fd\u56fd\u5bb6\u8bed\u6599\u5e93\u548c\u673a\u5668\u5b66\u4e60\uff0c\u63ed\u793a\u4e0d\u540c\u5e74\u9f84\u7fa4\u4f53\u5728\u53e3\u8bed\u4e0a\u7684\u663e\u8457\u5dee\u5f02\uff0c\u5e76\u5b9e\u73b0\u4e86\u5e74\u9f84\u7fa4\u4f53\u7684\u6709\u6548\u9884\u6d4b\u3002", "motivation": "\u8bed\u8a00\u968f\u5e74\u9f84\u53d8\u5316\uff0c\u4e86\u89e3\u4e0d\u540c\u5e74\u9f84\u7fa4\u4f53\u4e4b\u95f4\u7684\u53e3\u8bed\u5dee\u5f02\uff0c\u6709\u52a9\u4e8e\u4e30\u5bcc\u793e\u4f1a\u8bed\u8a00\u5b66\u5bf9\u73b0\u4ee3\u82f1\u8bed\u53d8\u5f02\u548c\u591a\u6837\u6027\u7684\u8ba4\u77e5\u3002", "method": "\u7ed3\u5408\u8ba1\u7b97\u8bed\u8a00\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u75282014\u5e74\u82f1\u56fd\u56fd\u5bb6\u8bed\u6599\u5e93\u5bf9\u4e0d\u540c\u5e74\u9f84\u6bb5\u8bf4\u8bdd\u8005\u7684\u8bed\u6599\u8fdb\u884c\u5206\u6790\uff0c\u63d0\u53d6\u8bdd\u8bed\u65f6\u957f\u3001\u8bcd\u6c47\u591a\u6837\u6027\u548c\u7528\u8bcd\u9009\u62e9\u7b49\u7279\u5f81\uff0c\u5e76\u5efa\u7acb\u5e74\u9f84\u7fa4\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u591a\u4ee3\u7fa4\u4f53\u95f4\u5b58\u5728\u663e\u8457\u7684\u8bed\u8a00\u6807\u5fd7\uff0c\u9884\u6d4b\u6a21\u578b\u80fd\u591f\u57fa\u4e8e\u8bed\u97f3\u7279\u5f81\u8f83\u4e3a\u51c6\u786e\u5730\u4f30\u8ba1\u8bf4\u8bdd\u8005\u7684\u5e74\u9f84\u6bb5\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u82f1\u56fd\u5f53\u4ee3\u53e3\u8bed\u5728\u4e0d\u540c\u5e74\u9f84\u7fa4\u4f53\u95f4\u7684\u8bed\u8a00\u6a21\u5f0f\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4e14\u53ef\u4ee5\u901a\u8fc7\u8bed\u8a00\u7279\u5f81\u6709\u6548\u9884\u6d4b\u8bf4\u8bdd\u8005\u7684\u5e74\u9f84\u7fa4\u4f53\u3002"}}
{"id": "2506.18149", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18149", "abs": "https://arxiv.org/abs/2506.18149", "authors": ["Fumian Chen", "Sotheara Veng", "Joshua Wilson", "Xiaoming Li", "Hui Fang"], "title": "CoachGPT: A Scaffolding-based Academic Writing Assistant", "comment": "SIGIR 2025 DEMO Pre-print", "summary": "Academic writing skills are crucial for students' success, but can feel\noverwhelming without proper guidance and practice, particularly when writing in\na second language. Traditionally, students ask instructors or search\ndictionaries, which are not universally accessible. Early writing assistants\nemerged as rule-based systems that focused on detecting misspellings,\nsubject-verb disagreements, and basic punctuation errors; however, they are\ninaccurate and lack contextual understanding. Machine learning-based assistants\ndemonstrate a strong ability for language understanding but are expensive to\ntrain. Large language models (LLMs) have shown remarkable capabilities in\ngenerating responses in natural languages based on given prompts. Still, they\nhave a fundamental limitation in education: they generate essays without\nteaching, which can have detrimental effects on learning when misused. To\naddress this limitation, we develop CoachGPT, which leverages large language\nmodels (LLMs) to assist individuals with limited educational resources and\nthose who prefer self-paced learning in academic writing. CoachGPT is an AI\nagent-based web application that (1) takes instructions from experienced\neducators, (2) converts instructions into sub-tasks, and (3) provides real-time\nfeedback and suggestions using large language models. This unique scaffolding\nstructure makes CoachGPT unique among existing writing assistants. Compared to\nexisting writing assistants, CoachGPT provides a more immersive writing\nexperience with personalized feedback and guidance. Our user studies prove the\nusefulness of CoachGPT and the potential of large language models for academic\nwriting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b66\u672f\u5199\u4f5c\u8f85\u5bfc\u5de5\u5177CoachGPT\uff0c\u76f8\u6bd4\u4f20\u7edf\u52a9\u624b\u66f4\u80fd\u4e2a\u6027\u5316\u548c\u5b9e\u65f6\u6307\u5bfc\u5199\u4f5c\uff0c\u7ecf\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u6548\u679c\u660e\u663e\uff0c\u5bf9\u81ea\u4e3b\u5b66\u4e60\u8005\u7279\u522b\u6709\u5e2e\u52a9\u3002", "motivation": "\u5b66\u672f\u5199\u4f5c\u5bf9\u5b66\u751f\u6210\u529f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5c24\u5176\u5728\u7b2c\u4e8c\u8bed\u8a00\u5199\u4f5c\u65f6\uff0c\u7f3a\u4e4f\u6307\u5bfc\u548c\u7ec3\u4e60\u4f1a\u8ba9\u5b66\u751f\u611f\u5230\u65e0\u4ece\u4e0b\u624b\u3002\u4f20\u7edf\u5199\u4f5c\u5de5\u5177\u65e0\u6cd5\u63d0\u4f9b\u6709\u6548\u3001\u4e2a\u6027\u5316\u7684\u8f85\u52a9\u3002", "method": "\u63d0\u51fa\u5e76\u5f00\u53d1\u4e86CoachGPT\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684AI\u5199\u4f5c\u8f85\u5bfc\u7cfb\u7edf\u3002CoachGPT\u53ef\u6839\u636e\u6559\u80b2\u8005\u6307\u4ee4\u5c06\u5199\u4f5c\u8fc7\u7a0b\u62c6\u5206\u4e3a\u5b50\u4efb\u52a1\uff0c\u5e76\u5b9e\u65f6\u63d0\u4f9b\u53cd\u9988\u548c\u5efa\u8bae\u3002\u5176\u67b6\u6784\u91c7\u7528\u5206\u6b65\u6307\u5bfc\u548c\u4e2a\u6027\u5316\u53cd\u9988\uff0c\u5d4c\u5165\u7f51\u9875\u5e94\u7528\u5b9e\u73b0\u3002", "result": "CoachGPT\u76f8\u8f83\u4e8e\u73b0\u6709\u5199\u4f5c\u52a9\u624b\uff0c\u80fd\u63d0\u4f9b\u66f4\u4e2a\u6027\u5316\u3001\u66f4\u5177\u6c89\u6d78\u611f\u7684\u5199\u4f5c\u4f53\u9a8c\u548c\u53cd\u9988\u3002\u7528\u6237\u7814\u7a76\u8868\u660eCoachGPT\u5177\u6709\u6548\u7528\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b66\u672f\u5199\u4f5c\u8f85\u52a9\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "CoachGPT\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u521b\u65b0\u6027\u5730\u5c06\u6559\u5b66\u548c\u5199\u4f5c\u8f85\u5bfc\u76f8\u7ed3\u5408\uff0c\u6709\u52a9\u4e8e\u4f4e\u8d44\u6e90\u4e0e\u81ea\u4e3b\u5b66\u4e60\u8005\u63d0\u5347\u5b66\u672f\u5199\u4f5c\uff0c\u5f25\u8865\u4e86LLM\u539f\u6709\u7684\u6559\u5b66\u77ed\u677f\u3002"}}
{"id": "2506.17715", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17715", "abs": "https://arxiv.org/abs/2506.17715", "authors": ["Matthias Sch\u00f6ffel", "Esteban Garces Arias", "Marinus Wiedner", "Paula Ruppert", "Meimingwei Li", "Christian Heumann", "Matthias A\u00dfenmacher"], "title": "Unveiling Factors for Enhanced POS Tagging: A Study of Low-Resource Medieval Romance Languages", "comment": null, "summary": "Part-of-speech (POS) tagging remains a foundational component in natural\nlanguage processing pipelines, particularly critical for historical text\nanalysis at the intersection of computational linguistics and digital\nhumanities. Despite significant advancements in modern large language models\n(LLMs) for ancient languages, their application to Medieval Romance languages\npresents distinctive challenges stemming from diachronic linguistic evolution,\nspelling variations, and labeled data scarcity. This study systematically\ninvestigates the central determinants of POS tagging performance across diverse\ncorpora of Medieval Occitan, Medieval Spanish, and Medieval French texts,\nspanning biblical, hagiographical, medical, and dietary domains. Through\nrigorous experimentation, we evaluate how fine-tuning approaches, prompt\nengineering, model architectures, decoding strategies, and cross-lingual\ntransfer learning techniques affect tagging accuracy. Our results reveal both\nnotable limitations in LLMs' ability to process historical language variations\nand non-standardized spelling, as well as promising specialized techniques that\neffectively address the unique challenges presented by low-resource historical\nlanguages.", "AI": {"tldr": "\u672c\u7814\u7a76\u56f4\u7ed5\u4e2d\u53e4\u7f57\u66fc\u8bedPOS\u6807\u6ce8\u7684\u96be\u9898\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u79cd\u6280\u672f\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u663e\u793a\uff1aLLMs\u5bf9\u4e8e\u5386\u53f2\u6587\u672c\u4e2d\u7684\u8bed\u8a00\u53d8\u5f02\u548c\u62fc\u5199\u4e0d\u89c4\u8303\u9002\u5e94\u6027\u6709\u9650\uff0c\u4f46\u90e8\u5206\u65b9\u6cd5\uff08\u5982\u8de8\u8bed\u8a00\u8fc1\u79fb\u7b49\uff09\u80fd\u663e\u8457\u63d0\u5347\u6807\u6ce8\u51c6\u786e\u7387\u3002", "motivation": "\u8bcd\u6027\u6807\u6ce8\uff08POS tagging\uff09\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u57fa\u7840\u4efb\u52a1\uff0c\u5bf9\u4e8e\u6d89\u53ca\u5386\u53f2\u6587\u672c\u5206\u6790\u7684\u9886\u57df\u5c24\u4e3a\u91cd\u8981\u3002\u7136\u800c\uff0c\u5c06\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5e94\u7528\u4e8e\u4e2d\u53e4\u7f57\u66fc\u8bed\uff08\u5982\u4e2d\u53e4\u5965\u514b\u897f\u5510\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u6cd5\u8bed\uff09\u65f6\uff0c\u4f1a\u9047\u5230\u8bed\u8a00\u6f14\u53d8\u3001\u62fc\u5199\u53d8\u5f02\u4ee5\u53ca\u6709\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7b49\u72ec\u7279\u6311\u6218\u3002\u8bba\u6587\u52a8\u673a\u5728\u4e8e\u63ed\u793a\u5f71\u54cd\u5386\u53f2\u5c11\u8d44\u6e90\u8bed\u8a00\u4e2dPOS\u6807\u6ce8\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u7cfb\u7edf\u6027\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8003\u5bdf\u4e0d\u540c\u5fae\u8c03\u65b9\u6cd5\u3001\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u67b6\u6784\u3001\u89e3\u7801\u7b56\u7565\u548c\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b66\u4e60\u6280\u672f\u5982\u4f55\u5f71\u54cdPOS\u6807\u6ce8\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u6db5\u76d6\u4e2d\u53e4\u5965\u514b\u897f\u5510\u8bed\u3001\u897f\u73ed\u7259\u8bed\u548c\u6cd5\u8bed\u7684\u4e0d\u540c\u9886\u57df\u6587\u672c\uff08\u5982\u5723\u7ecf\u3001\u4f20\u8bb0\u3001\u533b\u5b66\u3001\u996e\u98df\u6587\u732e\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u5386\u53f2\u8bed\u8a00\u53d8\u5f02\u548c\u975e\u6807\u51c6\u62fc\u5199\u65b9\u9762\u7684\u663e\u8457\u5c40\u9650\uff0c\u4e5f\u53d1\u73b0\u4e86\u4e00\u4e9b\u80fd\u6709\u6548\u5e94\u5bf9\u4f4e\u8d44\u6e90\u5386\u53f2\u8bed\u8a00\u6311\u6218\u7684\u4e13\u95e8\u6280\u672f\u3002", "conclusion": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5e94\u5bf9\u4e2d\u53e4\u7f57\u66fc\u8bed\u7b49\u5386\u53f2\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684POS\u6807\u6ce8\u4efb\u52a1\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u4f46\u9488\u5bf9\u6027\u7b56\u7565\u4e0e\u6280\u672f\u53ef\u5e26\u6765\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u540e\u7eed\u6570\u5b57\u4eba\u6587\u4e0e\u5386\u53f2\u8bed\u8a00\u5904\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u501f\u9274\u3002"}}
{"id": "2506.18156", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18156", "abs": "https://arxiv.org/abs/2506.18156", "authors": ["Akash Kundu", "Rishika Goswami"], "title": "AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology", "comment": null, "summary": "We investigate whether Large Language Models (LLMs) exhibit human-like\ncognitive patterns under four established frameworks from psychology: Thematic\nApperception Test (TAT), Framing Bias, Moral Foundations Theory (MFT), and\nCognitive Dissonance. We evaluated several proprietary and open-source models\nusing structured prompts and automated scoring. Our findings reveal that these\nmodels often produce coherent narratives, show susceptibility to positive\nframing, exhibit moral judgments aligned with Liberty/Oppression concerns, and\ndemonstrate self-contradictions tempered by extensive rationalization. Such\nbehaviors mirror human cognitive tendencies yet are shaped by their training\ndata and alignment methods. We discuss the implications for AI transparency,\nethical deployment, and future work that bridges cognitive psychology and AI\nsafety", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8003\u5bdfLLMs\u5728\u56db\u5927\u5fc3\u7406\u5b66\u6846\u67b6\u4e0b\u7684\u7c7b\u4eba\u8ba4\u77e5\u503e\u5411\uff0c\u53d1\u73b0\u5176\u5728\u53d9\u4e8b\u3001\u6846\u67b6\u6548\u5e94\u3001\u9053\u5fb7\u5224\u65ad\u53ca\u77db\u76fe\u5904\u7406\u65b9\u9762\u5747\u4e0e\u4eba\u7c7b\u7c7b\u4f3c\uff1b\u8fd9\u4e00\u53d1\u73b0\u6709\u52a9\u4e8e\u4fc3\u8fdbAI\u900f\u660e\u6027\u548c\u4f26\u7406\u5e94\u7528\u7684\u8ba8\u8bba\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u5426\u5c55\u73b0\u7c7b\u4eba\u8ba4\u77e5\u6a21\u5f0f\uff0c\u501f\u52a9\u5fc3\u7406\u5b66\u4e2d\u7684\u56db\u5927\u6846\u67b6\u8fdb\u884c\u5206\u6790\uff0c\u65e8\u5728\u52a0\u6df1\u5bf9AI\u884c\u4e3a\u4e0e\u4eba\u7c7b\u601d\u7ef4\u5f02\u540c\u7684\u7406\u89e3\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u5316\u63d0\u793a\u4e0e\u81ea\u52a8\u8bc4\u5206\u7684\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4e3b\u9898\u7edf\u89c9\u6d4b\u8bd5\uff08TAT\uff09\u3001\u6846\u67b6\u504f\u5dee\u3001\u9053\u5fb7\u57fa\u7840\u7406\u8bba\uff08MFT\uff09\u53ca\u8ba4\u77e5\u5931\u8c03\u56db\u79cd\u5fc3\u7406\u5b66\u6846\u67b6\uff0c\u5bf9\u591a\u79cd\u4e13\u6709\u53ca\u5f00\u6e90LLM\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "LLMs\u5c55\u73b0\u51fa\u53ef\u7406\u89e3\u7684\u53d9\u8ff0\u3001\u5bf9\u79ef\u6781\u6846\u67b6\u5b58\u5728\u504f\u5dee\u3001\u9053\u5fb7\u5224\u65ad\u504f\u5411\u81ea\u7531/\u538b\u8feb\u8bae\u9898\uff0c\u5e76\u8868\u73b0\u51fa\u81ea\u76f8\u77db\u76fe\u4f46\u80fd\u8fdb\u884c\u8f83\u4e3a\u590d\u6742\u7684\u5408\u7406\u5316\u3002\u8fd9\u4e9b\u7279\u5f81\u53cd\u6620\u4e86\u4eba\u7c7b\u7684\u90e8\u5206\u8ba4\u77e5\u503e\u5411\uff0c\u4f46\u53c8\u6df1\u53d7\u8bad\u7ec3\u6570\u636e\u4e0e\u5bf9\u9f50\u624b\u6bb5\u5f71\u54cd\u3002", "conclusion": "LLMs\u5728\u591a\u79cd\u5fc3\u7406\u5b66\u6846\u67b6\u4e0b\u4f53\u73b0\u51fa\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u8ba4\u77e5\u7279\u5f81\uff1b\u8fd9\u4e9b\u8868\u73b0\u5bf9\u4e8e\u7406\u89e3AI\u900f\u660e\u6027\u3001\u4f26\u7406\u90e8\u7f72\u53ca\u672a\u6765\u878d\u5408\u5fc3\u7406\u5b66\u4e0eAI\u5b89\u5168\u7684\u5de5\u4f5c\u5177\u6709\u542f\u793a\u610f\u4e49\u3002"}}
{"id": "2506.17728", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17728", "abs": "https://arxiv.org/abs/2506.17728", "authors": ["Dalong Zhang", "Jun Xu", "Jun Zhou", "Lei Liang", "Lin Yuan", "Ling Zhong", "Mengshu Sun", "Peilong Zhao", "QiWei Wang", "Xiaorui Wang", "Xinkai Du", "YangYang Hou", "Yu Ao", "ZhaoYang Wang", "Zhengke Gui", "ZhiYing Yi", "Zhongpu Bo"], "title": "KAG-Thinker: Teaching Large Language Models to Think with Human-like Reasoning Process", "comment": null, "summary": "In this paper, we introduce KAG-Thinker, a novel human-like reasoning\nframework built upon a parameter-light large language model (LLM). Our approach\nenhances the logical coherence and contextual consistency of the thinking\nprocess in question-answering (Q\\&A) tasks on domain-specific knowledge bases\n(KBs) within LLMs. This framework simulates human cognitive mechanisms for\nhandling complex problems by establishing a structured thinking process.\nContinuing the \\textbf{Logical Form} guided retrieval and reasoning technology\nroute of KAG v0.7, firstly, it decomposes complex questions into independently\nsolvable sub-problems(also referred to as logical forms) through\n\\textbf{breadth decomposition}, each represented in two equivalent\nforms-natural language and logical function-and further classified as either\nKnowledge Retrieval or Reasoning Analysis tasks, with dependencies and\nvariables passing explicitly modeled via logical function interfaces. In the\nsolving process, the Retrieval function is used to perform knowledge retrieval\ntasks, while the Math and Deduce functions are used to perform reasoning\nanalysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval\nsub-problem tasks, LLMs and external knowledge sources are regarded as\nequivalent KBs. We use the \\textbf{knowledge boundary} model to determine the\noptimal source using self-regulatory mechanisms such as confidence calibration\nand reflective reasoning, and use the \\textbf{depth solving} model to enhance\nthe comprehensiveness of knowledge acquisition. Finally, instead of utilizing\nreinforcement learning, we employ supervised fine-tuning with multi-turn\ndialogues to align the model with our structured inference paradigm, thereby\navoiding excessive reflection. This is supported by a data evaluation framework\nand iterative corpus synthesis, which facilitate the generation of detailed\nreasoning trajectories...", "AI": {"tldr": "KAG-Thinker\u662f\u4e00\u79cd\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u7684\u63a8\u7406\u6846\u67b6\uff0c\u53ef\u63d0\u5347LLM\u5728\u4e13\u4e1a\u9886\u57df\u77e5\u8bc6\u95ee\u7b54\u4e2d\u7684\u63a8\u7406\u903b\u8f91\u548c\u77e5\u8bc6\u83b7\u53d6\u80fd\u529b\uff0c\u901a\u8fc7\u5206\u89e3\u5b50\u95ee\u9898\u3001\u52a8\u6001\u77e5\u8bc6\u9009\u62e9\u548c\u6709\u76d1\u7763\u8bad\u7ec3\u5b9e\u73b0\u66f4\u5f3a\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u76ee\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u5e93\u7684\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0c\u7f3a\u4e4f\u4e0e\u4eba\u7c7b\u601d\u7ef4\u8fc7\u7a0b\u76f8\u4eff\u7684\u903b\u8f91\u4e00\u81f4\u6027\u4e0e\u4e0a\u4e0b\u6587\u8fde\u7eed\u6027\u7684\u63a8\u7406\u80fd\u529b\u3002\u4f5c\u8005\u5e0c\u671b\u63d0\u5347LLM\u5728\u4eba\u7c7b\u7c7b\u63a8\u7406\u3001\u590d\u6742\u95ee\u9898\u5206\u89e3\u548c\u52a8\u6001\u77e5\u8bc6\u6e90\u9009\u62e9\u7b49\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86KAG-Thinker\u4eba\u7c7b\u7c7b\u63a8\u7406\u6846\u67b6\uff0c\u57fa\u4e8e\u53c2\u6570\u8f83\u5c11\u7684LLM\u3002\u91c7\u7528Logical Form\u5f15\u5bfc\u7684\u68c0\u7d22\u4e0e\u63a8\u7406\u6280\u672f\uff0c\u9996\u5148\u901a\u8fc7\u5e7f\u5ea6\u5206\u89e3\u5c06\u590d\u6742\u95ee\u9898\u62c6\u89e3\u4e3a\u53ef\u72ec\u7acb\u6c42\u89e3\u7684\u5b50\u95ee\u9898\uff0c\u5e76\u4ee5\u81ea\u7136\u8bed\u8a00\u548c\u903b\u8f91\u51fd\u6570\u4e24\u79cd\u5f62\u5f0f\u8fdb\u884c\u8868\u8fbe\uff0c\u660e\u786e\u4efb\u52a1\u4f9d\u8d56\u548c\u53d8\u91cf\u4f20\u9012\u3002\u5bf9\u4e8e\u77e5\u8bc6\u68c0\u7d22\u4e0e\u63a8\u7406\u5206\u6790\u5b50\u4efb\u52a1\u5206\u522b\u5e94\u7528\u4e0d\u540c\u51fd\u6570\u3002\u521b\u65b0\u5730\u5c06LLM\u548c\u5916\u90e8\u77e5\u8bc6\u6e90\u4f5c\u4e3a\u7b49\u4ef7\u7684\u77e5\u8bc6\u5e93\uff0c\u901a\u8fc7knowledge boundary\u6a21\u578b\u5b9e\u73b0\u52a8\u6001\u77e5\u8bc6\u6e90\u9009\u62e9\uff1b\u6df1\u5ea6\u6c42\u89e3\u6a21\u578b\u63d0\u5347\u77e5\u8bc6\u83b7\u53d6\u5168\u9762\u6027\u3002\u8bad\u7ec3\u65f6\u91c7\u7528\u591a\u8f6e\u5bf9\u8bdd\u7684\u6709\u76d1\u7763\u5fae\u8c03\uff0c\u914d\u5408\u6570\u636e\u8bc4\u6d4b\u4e0e\u8bed\u6599\u8fed\u4ee3\u3002", "result": "KAG-Thinker\u80fd\u663e\u8457\u63d0\u5347LLM\u5728\u9762\u5411\u9886\u57df\u77e5\u8bc6\u5e93\u7684\u95ee\u7b54\u4e2d\uff0c\u63a8\u7406\u94fe\u7684\u903b\u8f91\u6027\u3001\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u548c\u77e5\u8bc6\u68c0\u7d22\u5168\u9762\u6027\uff0c\u907f\u514d\u8fc7\u5ea6\u53cd\u601d\u5e26\u6765\u7684\u63a8\u7406\u5f02\u5e38\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u6846\u67b6\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "conclusion": "KAG-Thinker\u901a\u8fc7\u542f\u53d1\u5f0f\u5206\u89e3\u4e0e\u52a8\u6001\u77e5\u8bc6\u8fb9\u754c\u9009\u62e9\uff0c\u6784\u5efa\u4e86\u66f4\u8d34\u8fd1\u4eba\u7c7b\u8ba4\u77e5\u6a21\u5f0f\u7684LLM\u63a8\u7406\u65b9\u6848\uff0c\u4e3a\u9886\u57df\u77e5\u8bc6\u63a8\u7406\u548c\u590d\u6742\u95ee\u7b54\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2506.18158", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.18158", "abs": "https://arxiv.org/abs/2506.18158", "authors": ["Xinzge Gao", "Chuanrui Hu", "Bin Chen", "Teng Li"], "title": "Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation", "comment": null, "summary": "Multimodal large language models (MLLMs) are attracting growing attention in\nthe development of Graphical User Interface (GUI) agents. Existing approaches\noften rely on historical screenshots or actions to implicitly represent the\ntask state. This reliance poses challenges for GUI agents in accurately\nunderstanding task states and underscores the absence of effective mechanisms\nto store critical information in complex and lengthy cross-app tasks. To\naddress these challenges, we propose Chain-of-Memory (CoM), a novel approach\nfor explicitly modeling short-term and long-term memory in GUI agents. CoM\nachieves this by capturing action descriptions, integrating task-relevant\nscreen information, and maintaining a dedicated memory module to store and\nmanage this information. By leveraging explicit memory representations, CoM\nenables GUI agents to better understand task states and retain critical\nhistorical information persistently. To equip GUI agents with memory management\ncapabilities and evaluate the effectiveness of CoM, we developed the GUI\nOdyssey-CoM, a dataset comprising 111k screen-action pairs annotated with\nChain-of-Memory. Experimental results demonstrate that CoM significantly\nimproves GUI agents' performance in cross-application tasks. Additionally, GUI\nOdyssey-CoM enables 7B models to achieve memory management capabilities\ncomparable to 72B models. The dataset and code will be open-sourced.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u94fe\u5f0f\u8bb0\u5fc6\uff08CoM\uff09\u673a\u5236\uff0c\u63d0\u5347GUI\u667a\u80fd\u4f53\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8bb0\u5fc6\u548c\u72b6\u6001\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u53d1\u5e03\u4e86\u5927\u89c4\u6a21\u914d\u5957\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u663e\u793a\u5c0f\u89c4\u6a21\u6a21\u578b\u4e5f\u80fd\u83b7\u5f97\u5ab2\u7f8e\u5927\u6a21\u578b\u7684\u8bb0\u5fc6\u7ba1\u7406\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u88ab\u7528\u4e8eGUI\u667a\u80fd\u4f53\uff0c\u4f46\u591a\u6570\u65b9\u6cd5\u901a\u8fc7\u5386\u53f2\u622a\u56fe\u6216\u52a8\u4f5c\u9690\u5f0f\u8868\u793a\u4efb\u52a1\u72b6\u6001\uff0c\u8fd9\u5bfc\u81f4\u667a\u80fd\u4f53\u96be\u4ee5\u51c6\u786e\u7406\u89e3\u590d\u6742\u4efb\u52a1\uff0c\u5c24\u5176\u662f\u8de8\u5e94\u7528\u573a\u666f\u4e0b\u91cd\u8981\u4fe1\u606f\u7684\u5b58\u50a8\u548c\u7ba1\u7406\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86Chain-of-Memory\uff08CoM\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u663e\u5f0f\u5efa\u6a21GUI\u667a\u80fd\u4f53\u4e2d\u7684\u77ed\u671f\u548c\u957f\u671f\u8bb0\u5fc6\u3002CoM\u901a\u8fc7\u6355\u83b7\u52a8\u4f5c\u63cf\u8ff0\u3001\u6574\u5408\u4efb\u52a1\u76f8\u5173\u5c4f\u5e55\u4fe1\u606f\uff0c\u5e76\u7ef4\u62a4\u4e13\u7528\u5185\u5b58\u6a21\u5757\u5b58\u50a8\u548c\u7ba1\u7406\u8fd9\u4e9b\u4fe1\u606f\u3002\u540c\u65f6\uff0c\u6784\u5efa\u4e86\u5305\u542b111k\u5c4f\u5e55-\u52a8\u4f5c\u5bf9\uff0c\u5e76\u6807\u6ce8\u6709CoM\u5185\u5b58\u94fe\u7684GUI Odyssey-CoM\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCoM\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86GUI\u667a\u80fd\u4f53\u5728\u8de8\u5e94\u7528\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u540c\u65f6GUI Odyssey-CoM\u6570\u636e\u96c6\u4f7f7B\u6a21\u578b\u5177\u5907\u4e0e72B\u6a21\u578b\u5ab2\u7f8e\u7684\u8bb0\u5fc6\u7ba1\u7406\u80fd\u529b\u3002", "conclusion": "CoM\u901a\u8fc7\u663e\u5f0f\u8bb0\u5fc6\u5efa\u6a21\u4e0e\u7ba1\u7406\uff0c\u63d0\u5347\u4e86GUI\u667a\u80fd\u4f53\u5bf9\u4efb\u52a1\u72b6\u6001\u7684\u7406\u89e3\u548c\u5173\u952e\u5386\u53f2\u4fe1\u606f\u7684\u5b58\u50a8\u80fd\u529b\uff0c\u6709\u6548\u63a8\u52a8\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4ea4\u4e92\u4efb\u52a1\u573a\u666f\u4e0b\u7684\u5e94\u7528\u3002\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5c06\u5f00\u6e90\u3002"}}
{"id": "2506.17748", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17748", "abs": "https://arxiv.org/abs/2506.17748", "authors": ["Anwoy Chatterjee", "Yash Goel", "Tanmoy Chakraborty"], "title": "HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations", "comment": null, "summary": "Contemporary Language Models (LMs), while impressively fluent, often generate\ncontent that is factually incorrect or unfaithful to the input context - a\ncritical issue commonly referred to as 'hallucination'. This tendency of LMs to\ngenerate hallucinated content undermines their reliability, especially because\nthese fabrications are often highly convincing and therefore difficult to\ndetect. While several existing methods attempt to detect hallucinations, most\nrely on analyzing multiple generations per input, leading to increased\ncomputational cost and latency. To address this, we propose a single-pass,\ntraining-free approach for effective Hallucination detectIon via Decoupled\nrEpresentations (HIDE). Our approach leverages the hypothesis that\nhallucinations result from a statistical decoupling between an LM's internal\nrepresentations of input context and its generated output. We quantify this\ndecoupling using the Hilbert-Schmidt Independence Criterion (HSIC) applied to\nhidden-state representations extracted while generating the output sequence. We\nconduct extensive experiments on four diverse question answering datasets,\nevaluating both faithfulness and factuality hallucinations across six\nopen-source LMs of varying scales and properties. Our results demonstrate that\nHIDE outperforms other single-pass methods in almost all settings, achieving an\naverage relative improvement of ~29% in AUC-ROC over the best-performing\nsingle-pass strategy across various models and datasets. Additionally, HIDE\nshows competitive and often superior performance with multi-pass\nstate-of-the-art methods, obtaining an average relative improvement of ~3% in\nAUC-ROC while consuming ~51% less computation time. Our findings highlight the\neffectiveness of exploiting internal representation decoupling in LMs for\nefficient and practical hallucination detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u5355\u904d\u5373\u53ef\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u7684\u65b0\u65b9\u6cd5\uff08HIDE\uff09\uff0c\u5229\u7528\u6a21\u578b\u5185\u90e8\u8868\u5f81\u89e3\u8026\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u51c6\u786e\u6027\u548c\u6548\u7387\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LMs\uff09\u5728\u751f\u6210\u5185\u5bb9\u65f6\u5e38\u51fa\u73b0\u4e8b\u5b9e\u9519\u8bef\u6216\u4e0e\u8f93\u5165\u4e0a\u4e0b\u6587\u4e0d\u7b26\u7684\u95ee\u9898\uff0c\u5373\u201c\u5e7b\u89c9\u201d\u73b0\u8c61\u3002\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u591a\u6b21\u751f\u6210\uff0c\u5bf9\u6bcf\u4e2a\u8f93\u5165\u5206\u6790\u591a\u7ec4\u7ed3\u679c\uff0c\u8ba1\u7b97\u6210\u672c\u548c\u5ef6\u8fdf\u8f83\u9ad8\u3002\u7814\u7a76\u52a8\u673a\u662f\u63d0\u51fa\u4e00\u79cd\u80fd\u6709\u6548\u3001\u5feb\u901f\u68c0\u6d4b\u5e7b\u89c9\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5355\u904d\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u65b0\u65b9\u6cd5\u2014\u2014HIDE\uff08Hallucination detectIon via Decoupled rEpresentations\uff09\u3002\u8be5\u65b9\u6cd5\u5229\u7528Hilbert-Schmidt\u72ec\u7acb\u6027\u51c6\u5219\uff08HSIC\uff09\u5ea6\u91cf\u751f\u6210\u8f93\u51fa\u65f6\u6a21\u578b\u5185\u90e8\u8f93\u5165\u4e0a\u4e0b\u6587\u8868\u793a\u4e0e\u8f93\u51fa\u8868\u793a\u7684\u7edf\u8ba1\u201c\u89e3\u8026\u201d\u7a0b\u5ea6\uff0c\u636e\u6b64\u8bc6\u522b\u5e7b\u89c9\u3002", "result": "\u5728\u56db\u4e2a\u591a\u6837\u5316\u95ee\u7b54\u6570\u636e\u96c6\u548c\u516d\u79cd\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\u3002\u7ed3\u679c\u663e\u793a\uff0cHIDE\u5728\u51e0\u4e4e\u6240\u6709\u8bbe\u7f6e\u4e0b\u90fd\u4f18\u4e8e\u5176\u4ed6\u5355\u904d\u65b9\u6cd5\uff0c\u5728\u5404\u6a21\u578b\u53ca\u6570\u636e\u96c6\u95f4AUC-ROC\u5e73\u5747\u63d0\u5347\u7ea629%\u3002\u76f8\u8f83\u591a\u904d\u6700\u4f18\u65b9\u6cd5\uff0cHIDE\u5728AUC-ROC\u5e73\u5747\u63d0\u5347\u7ea63%\uff0c\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u51cf\u5c11\u7ea651%\u3002", "conclusion": "\u901a\u8fc7\u8861\u91cf\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u8868\u5f81\u7684\u89e3\u8026\uff0cHIDE\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u5e7b\u89c9\u68c0\u6d4b\uff0c\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2506.18183", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18183", "abs": "https://arxiv.org/abs/2506.18183", "authors": ["Zhiting Mei", "Christina Zhang", "Tenny Yin", "Justin Lidard", "Ola Shorinwa", "Anirudha Majumdar"], "title": "Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?", "comment": null, "summary": "Reasoning language models have set state-of-the-art (SOTA) records on many\nchallenging benchmarks, enabled by multi-step reasoning induced using\nreinforcement learning. However, like previous language models, reasoning\nmodels are prone to generating confident, plausible responses that are\nincorrect (hallucinations). Knowing when and how much to trust these models is\ncritical to the safe deployment of reasoning models in real-world applications.\nTo this end, we explore uncertainty quantification of reasoning models in this\nwork. Specifically, we ask three fundamental questions: First, are reasoning\nmodels well-calibrated? Second, does deeper reasoning improve model\ncalibration? Finally, inspired by humans' innate ability to double-check their\nthought processes to verify the validity of their answers and their confidence,\nwe ask: can reasoning models improve their calibration by explicitly reasoning\nabout their chain-of-thought traces? We introduce introspective uncertainty\nquantification (UQ) to explore this direction. In extensive evaluations on SOTA\nreasoning models across a broad range of benchmarks, we find that reasoning\nmodels: (i) are typically overconfident, with self-verbalized confidence\nestimates often greater than 85% particularly for incorrect responses, (ii)\nbecome even more overconfident with deeper reasoning, and (iii) can become\nbetter calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not\nuniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we\nconclude with important research directions to design necessary UQ benchmarks\nand improve the calibration of reasoning models.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u63a8\u7406\u5927\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u666e\u904d\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u4e14\u6df1\u5165\u63a8\u7406\u53cd\u800c\u5bfc\u81f4\u6821\u51c6\u6027\u4e0b\u964d\u3002\u901a\u8fc7\u81ea\u7701\u673a\u5236\u90e8\u5206\u6a21\u578b\u53ef\u63d0\u5347\u6821\u51c6\uff0c\u4f46\u65b9\u6cd5\u5e76\u975e\u9002\u7528\u4e8e\u6240\u6709\u6a21\u578b\u3002\u672a\u6765\u9700\u5efa\u7acb\u66f4\u5b8c\u5584\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u8bc4\u6d4b\u4e0e\u6539\u8fdb\u65b9\u6848\uff0c\u4ee5\u4fc3\u8fdb\u63a8\u7406\u6a21\u578b\u5b89\u5168\u53ef\u63a7\u5e94\u7528\u3002", "motivation": "\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u5728\u8bb8\u591a\u57fa\u51c6\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\uff08SOTA\uff09\u7684\u6210\u679c\uff0c\u4f46\u5b83\u4eec\u4e5f\u5bb9\u6613\u4ea7\u751f\u81ea\u4fe1\u5374\u9519\u8bef\u7684\u865a\u5047\u54cd\u5e94\uff08\u5373\u5e7b\u89c9\uff09\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u91cf\u5316\u5e76\u6821\u51c6\u63a8\u7406\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u662f\u5b89\u5168\u90e8\u7f72\u7684\u91cd\u8981\u524d\u63d0\u3002\u8be5\u8bba\u6587\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30\u63a8\u7406\u6a21\u578b\u7684\u6821\u51c6\u80fd\u529b\uff0c\u4ee5\u53ca\u63a2\u8ba8\u901a\u8fc7\u6a21\u578b\u81ea\u7701\u662f\u5426\u53ef\u4ee5\u63d0\u5347\u6821\u51c6\u6027\u3002", "method": "\u672c\u7814\u7a76\u5206\u522b\u8003\u5bdf\u4e86\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a1\uff09\u5f53\u524d\u63a8\u7406\u6a21\u578b\u7684\u6821\u51c6\u7a0b\u5ea6\u5982\u4f55\uff1f2\uff09\u66f4\u6df1\u5c42\u6b21\u7684\u63a8\u7406\u662f\u5426\u80fd\u63d0\u5347\u6821\u51c6\u6027\uff1f3\uff09\u901a\u8fc7\u8ba9\u6a21\u578b\u5bf9\u81ea\u5df1\u7684\u63a8\u7406\u8fc7\u7a0b\u8fdb\u884c\u81ea\u7701\uff0c\u80fd\u5426\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u6821\u51c6\u80fd\u529b\uff1f\u7814\u7a76\u63d0\u51fa\u4e86\u5185\u7701\u5f0f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u65b9\u6cd5\uff0c\u5e76\u5728\u6700\u5148\u8fdb\u63a8\u7406\u6a21\u578b\u548c\u591a\u79cd\u57fa\u51c6\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff1a\u63a8\u7406\u6a21\u578b\u901a\u5e38\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u5c24\u5176\u662f\u5728\u9519\u8bef\u56de\u7b54\u65f6\u81ea\u62a5\u7f6e\u4fe1\u5ea6\u5e38\u5927\u4e8e85%\uff1b\u968f\u7740\u63a8\u7406\u6df1\u5ea6\u589e\u52a0\uff0c\u6a21\u578b\u8d8a\u53d1\u8fc7\u5ea6\u81ea\u4fe1\uff1b\u901a\u8fc7\u5185\u7701\u673a\u5236\uff0c\u4e00\u4e9b\u6a21\u578b\uff08\u5982o3-Mini\u548cDeepSeek R1\uff09\u6821\u51c6\u6027\u63d0\u5347\uff0c\u4f46\u5e76\u975e\u6240\u6709\u6a21\u578b\u90fd\u6709\u6548\uff08\u5982Claude 3.7 Sonnet\u6821\u51c6\u6027\u53cd\u800c\u53d8\u5dee\uff09\u3002", "conclusion": "\u63a8\u7406\u6a21\u578b\u5728\u6821\u51c6\u53ef\u9760\u6027\u65b9\u9762\u4ecd\u5b58\u660e\u663e\u7f3a\u9677\uff0c\u5c24\u5176\u8868\u73b0\u4e3a\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u9700\u5f15\u5165\u66f4\u591a\u6837\u5316\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u57fa\u51c6\u4e0e\u673a\u5236\uff0c\u6301\u7eed\u4f18\u5316\u63a8\u7406\u6a21\u578b\u7684\u6821\u51c6\u80fd\u529b\u4e0e\u5b89\u5168\u6027\u3002"}}
{"id": "2506.17789", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17789", "abs": "https://arxiv.org/abs/2506.17789", "authors": ["N J Karthika", "Maharaj Brahma", "Rohit Saluja", "Ganesh Ramakrishnan", "Maunendra Sankar Desarkar"], "title": "Multilingual Tokenization through the Lens of Indian Languages: Challenges and Insights", "comment": null, "summary": "Tokenization plays a pivotal role in multilingual NLP. However, existing\ntokenizers are often skewed towards high-resource languages, limiting their\neffectiveness for linguistically diverse and morphologically rich languages\nsuch as those in the Indian subcontinent. This paper presents a comprehensive\nintrinsic evaluation of tokenization strategies across 17 Indian languages. We\nquantify the trade-offs between bottom-up and top-down tokenizer algorithms\n(BPE and Unigram LM), effects of vocabulary sizes, and compare strategies of\nmultilingual vocabulary construction such as joint and cluster-based training.\nWe also show that extremely low-resource languages can benefit from tokenizers\ntrained on related high-resource languages. Our study provides practical\ninsights for building more fair, efficient, and linguistically informed\ntokenizers for multilingual NLP.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e8617\u79cd\u5370\u5ea6\u8bed\u8a00\u7684\u5206\u8bcd\u65b9\u6cd5\uff0c\u4e3a\u591a\u8bed\u79cdNLP\u5206\u8bcd\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7ecf\u9a8c\uff1a\u4f4e\u8d44\u6e90\u8bed\u8a00\u53ef\u501f\u52a9\u9ad8\u8d44\u6e90\u8bed\u8a00\u5206\u8bcd\u5668\uff0c\u63d0\u51fa\u4e86\u66f4\u516c\u5e73\u9ad8\u6548\u7684\u5206\u8bcd\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u8bcd\u5668\u591a\u9488\u5bf9\u9ad8\u8d44\u6e90\u8bed\u8a00\u8bbe\u8ba1\uff0c\u5bf9\u4e8e\u5370\u5ea6\u6b21\u5927\u9646\u7b49\u8bed\u8a00\u591a\u6837\u4e14\u5f62\u6001\u4e30\u5bcc\u7684\u8bed\u8a00\u652f\u6301\u6709\u9650\u3002", "method": "\u5bf917\u79cd\u5370\u5ea6\u8bed\u8a00\u7684\u5206\u8bcd\u7b56\u7565\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5185\u5728\u8bc4\u4f30\uff0c\u91cf\u5316\u5206\u6790\u4e86\u81ea\u5e95\u5411\u4e0a\u4e0e\u81ea\u9876\u5411\u4e0b\u5206\u8bcd\u7b97\u6cd5\uff08\u5982BPE\u548cUnigram LM\uff09\u3001\u8bcd\u6c47\u8868\u89c4\u6a21\u5f71\u54cd\uff0c\u4ee5\u53ca\u591a\u8bed\u79cd\u8bcd\u6c47\u8868\u6784\u5efa\u7b56\u7565\uff08\u8054\u5408\u4e0e\u96c6\u7fa4\u8bad\u7ec3\uff09\u7684\u5bf9\u6bd4\u3002", "result": "\u53d1\u73b0\u6781\u4f4e\u8d44\u6e90\u8bed\u8a00\u53ef\u4ee5\u4ece\u5728\u76f8\u5173\u9ad8\u8d44\u6e90\u8bed\u8a00\u4e0a\u8bad\u7ec3\u7684\u5206\u8bcd\u5668\u4e2d\u83b7\u76ca\u3002", "conclusion": "\u4e3a\u591a\u8bed\u79cdNLP\u6784\u5efa\u66f4\u516c\u5e73\u3001\u9ad8\u6548\u4e14\u8bed\u8a00\u5b66\u66f4\u4f18\u7684\u5206\u8bcd\u5668\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.18187", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.18187", "abs": "https://arxiv.org/abs/2506.18187", "authors": ["Shahriar Noroozizadeh", "Pim Welle", "Jeremy C. Weiss", "George H. Chen"], "title": "The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis", "comment": "Conference on Health, Inference, and Learning (CHIL 2025)", "summary": "This study quantifies the association between non-adherence to antipsychotic\nmedications and adverse outcomes in individuals with schizophrenia. We frame\nthe problem using survival analysis, focusing on the time to the earliest of\nseveral adverse events (early death, involuntary hospitalization, jail\nbooking). We extend standard causal inference methods (T-learner, S-learner,\nnearest neighbor matching) to utilize various survival models to estimate\nindividual and average treatment effects, where treatment corresponds to\nmedication non-adherence. Analyses are repeated using different amounts of\nlongitudinal information (3, 6, 9, and 12 months). Using data from Allegheny\nCounty in western Pennsylvania, we find strong evidence that non-adherence\nadvances adverse outcomes by approximately 1 to 4 months. Ablation studies\nconfirm that county-provided risk scores adjust for key confounders, as their\nremoval amplifies the estimated effects. Subgroup analyses by medication\nformulation (injectable vs. oral) and medication type consistently show that\nnon-adherence is associated with earlier adverse events. These findings\nhighlight the clinical importance of adherence in delaying psychiatric crises\nand show that integrating survival analysis with causal inference tools can\nyield policy-relevant insights. We caution that although we apply causal\ninference, we only make associative claims and discuss assumptions needed for\ncausal interpretation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u521b\u65b0\u6027\u5730\u7ed3\u5408\u751f\u5b58\u5206\u6790\u548c\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u53d1\u73b0\u7cbe\u795e\u5206\u88c2\u75c7\u60a3\u8005\u836f\u7269\u4e0d\u4f9d\u4ece\u53ef\u660e\u663e\u63d0\u524d\u4e0d\u826f\u4e8b\u4ef6\u53d1\u751f\uff0c\u4e34\u5e8a\u548c\u653f\u7b56\u5c42\u9762\u9ad8\u5ea6\u91cd\u89c6\u836f\u7269\u4f9d\u4ece\u6027\u7ba1\u7406\u3002", "motivation": "\u7cbe\u795e\u5206\u88c2\u75c7\u60a3\u8005\u5e38\u56e0\u4e0d\u89c4\u5f8b\u670d\u7528\u6297\u7cbe\u795e\u75c5\u836f\u7269\u800c\u5bfc\u81f4\u4e0d\u826f\u7ed3\u5c40\uff0c\u4f46\u4e0d\u540c\u4e2a\u4f53\u7684\u4e0d\u4f9d\u4ece\u6027\u5bf9\u4e34\u5e8a\u7ed3\u5c40\u7684\u5177\u4f53\u5f71\u54cd\u5c1a\u7f3a\u5c11\u91cf\u5316\u7814\u7a76\u3002\u8be5\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u751f\u5b58\u5206\u6790\u548c\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u5b9a\u91cf\u5206\u6790\u836f\u7269\u670d\u7528\u4e0d\u4f9d\u4ece\u4e0e\u4e34\u5e8a\u4e0d\u826f\u7ed3\u5c40\u4e4b\u95f4\u7684\u5173\u8054\u3002", "method": "\u7814\u7a76\u91c7\u7528\u751f\u5b58\u5206\u6790\u6846\u67b6\uff0c\u5c06\u9996\u4e2a\u4e0d\u826f\u4e8b\u4ef6\uff08\u65e9\u901d\u3001\u5f3a\u5236\u4f4f\u9662\u3001\u88ab\u76d1\u7981\uff09\u53d1\u751f\u65f6\u95f4\u4f5c\u4e3a\u7ec8\u70b9\u3002\u5c06\u836f\u7269\u4e0d\u4f9d\u4ece\u89c6\u4e3a\u201c\u6cbb\u7597\u201d\uff0c\u7ed3\u5408T-learner\u3001S-learner\u3001\u6700\u8fd1\u90bb\u5339\u914d\u7b49\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u5206\u522b\u5229\u7528\u4e0d\u540c\u751f\u5b58\u6a21\u578b\uff0c\u4f30\u7b97\u4e2a\u4f53\u4e0e\u5e73\u5747\u6cbb\u7597\u6548\u5e94\u3002\u5e76\u5bf93\u30016\u30019\u300112\u4e2a\u6708\u6570\u636e\u5206\u522b\u91cd\u590d\u5206\u6790\u3002\u8fd8\u8fdb\u884c\u4e86\u6d88\u878d\u5b9e\u9a8c\u548c\u6309\u836f\u7269\u7c7b\u578b/\u5242\u578b\u7684\u4e9a\u7ec4\u5206\u6790\u3002", "result": "\u5206\u6790\u663e\u793a\uff0c\u836f\u7269\u4e0d\u4f9d\u4ece\u4f7f\u4e0d\u826f\u4e8b\u4ef6\u7684\u53d1\u751f\u63d0\u524d\u7ea61\u81f34\u4e2a\u6708\u3002\u6d88\u878d\u5b9e\u9a8c\u53d1\u73b0\u53bf\u98ce\u9669\u8bc4\u5206\u80fd\u8c03\u6574\u4e3b\u8981\u6df7\u6742\u56e0\u7d20\uff0c\u79fb\u9664\u65f6\u4f30\u7b97\u6548\u5e94\u663e\u8457\u52a0\u5f3a\u3002\u4e9a\u7ec4\u5206\u6790\u663e\u793a\u4e0d\u540c\u836f\u7269\u5242\u578b\u548c\u7c7b\u578b\u4e0b\uff0c\u4e0d\u4f9d\u4ece\u5747\u4e0e\u66f4\u65e9\u4e0d\u826f\u4e8b\u4ef6\u76f8\u5173\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u575a\u6301\u6297\u7cbe\u795e\u75c5\u836f\u7269\u4f9d\u4ece\u6027\u5bf9\u4e8e\u5ef6\u7f13\u7cbe\u795e\u5065\u5eb7\u5371\u673a\u81f3\u5173\u91cd\u8981\uff0c\u6574\u5408\u751f\u5b58\u5206\u6790\u548c\u56e0\u679c\u63a8\u65ad\u5de5\u5177\u6709\u52a9\u4e8e\u4e3a\u4e34\u5e8a\u4e0e\u653f\u7b56\u63d0\u4f9b\u6709\u5f71\u54cd\u529b\u7684\u89c1\u89e3\u3002\u6587\u7ae0\u867d\u8fd0\u7528\u56e0\u679c\u63a8\u65ad\u4ecd\u4ee5\u76f8\u5173\u6027\u4e3a\u4e3b\uff0c\u547c\u5401\u8bfb\u8005\u6ce8\u610f\u56e0\u679c\u89e3\u91ca\u524d\u63d0\u3002"}}
{"id": "2506.17844", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17844", "abs": "https://arxiv.org/abs/2506.17844", "authors": ["Xin Zhang", "Qiyu Wei", "Yingjie Zhu", "Fanyi Wu", "Sophia Ananiadou"], "title": "THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction", "comment": "13 pages, 4 figures", "summary": "Automated clinical risk prediction from electronic health records (EHRs)\ndemands modeling both structured diagnostic codes and unstructured narrative\nnotes. However, most prior approaches either handle these modalities separately\nor rely on simplistic fusion strategies that ignore the directional,\nhierarchical causal interactions by which narrative observations precipitate\ndiagnoses and propagate risk across admissions. In this paper, we propose\nTHCM-CAL, a Temporal-Hierarchical Causal Model with Conformal Calibration. Our\nframework constructs a multimodal causal graph where nodes represent clinical\nentities from two modalities: Textual propositions extracted from notes and ICD\ncodes mapped to textual descriptions. Through hierarchical causal discovery,\nTHCM-CAL infers three clinically grounded interactions: intra-slice\nsame-modality sequencing, intra-slice cross-modality triggers, and inter-slice\nrisk propagation. To enhance prediction reliability, we extend conformal\nprediction to multi-label ICD coding, calibrating per-code confidence intervals\nunder complex co-occurrences. Experimental results on MIMIC-III and MIMIC-IV\ndemonstrate the superiority of THCM-CAL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65f6\u5e8f-\u5c42\u7ea7\u56e0\u679c\u5efa\u6a21\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u4fdd\u5f62\u7f6e\u4fe1\u6821\u51c6\uff0c\u6539\u8fdb\u4e86\u591a\u6a21\u6001EHR\u6570\u636e\u7684\u75be\u75c5\u98ce\u9669\u9884\u6d4b\u6548\u679c\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u8868\u73b0\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u5305\u542b\u7ed3\u6784\u5316\u8bca\u65ad\u4ee3\u7801\u548c\u975e\u7ed3\u6784\u5316\u53d9\u8ff0\u6027\u75c5\u5386\uff0c\u4e24\u8005\u5747\u5bf9\u4e34\u5e8a\u98ce\u9669\u9884\u6d4b\u81f3\u5173\u91cd\u8981\u3002\u4ee5\u5f80\u65b9\u6cd5\u5e38\u5c06\u4e24\u79cd\u6570\u636e\u5206\u5f00\u5904\u7406\uff0c\u6216\u901a\u8fc7\u7b80\u5355\u7684\u6570\u636e\u878d\u5408\uff0c\u800c\u5ffd\u7565\u4e86\u5b9e\u9645\u75c5\u60c5\u7531\u6587\u672c\u89c2\u5bdf\u5f15\u53d1\u8bca\u65ad\u3001\u5bfc\u81f4\u98ce\u9669\u8de8\u6b21\u4f4f\u9662\u4f20\u64ad\u7684\u56e0\u679c\u4e0e\u5c42\u6b21\u8054\u52a8\u3002\u8be5\u6587\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u7f3a\u9677\u3002", "method": "\u63d0\u51faTHCM-CAL\uff08\u5e26\u4fdd\u5f62\u6821\u51c6\u7684\u65f6\u5e8f-\u5c42\u7ea7\u56e0\u679c\u6a21\u578b\uff09\uff0c\u5229\u7528\u56e0\u679c\u63a8\u65ad\u751f\u6210\u591a\u6a21\u6001\u56e0\u679c\u56fe\uff0c\u5c06\u51fa\u81ea\u75c5\u5386\u6587\u672c\u548cICD\u4ee3\u7801\u7684\u4e34\u5e8a\u5b9e\u4f53\u5efa\u4e3a\u8282\u70b9\uff0c\u901a\u8fc7\u5c42\u7ea7\u56e0\u679c\u53d1\u73b0\u5b66\u4e60\u4e09\u79cd\u5173\u952e\u5173\u7cfb\uff1a\u540c\u5c42\u540c\u6a21\u6001\u5e8f\u5217\u3001\u540c\u5c42\u8de8\u6a21\u6001\u89e6\u53d1\u4e0e\u8de8\u5c42\u98ce\u9669\u4f20\u64ad\uff0c\u5e76\u5c06\u4fdd\u5f62\u9884\u6d4b\u6280\u672f\u62d3\u5c55\u5230\u591a\u6807\u7b7eICD\u7f16\u7801\uff0c\u5b9e\u73b0\u591a\u6807\u7b7e\u7f6e\u4fe1\u533a\u95f4\u6821\u51c6\u3002", "result": "\u5728MIMIC-III\u548cMIMIC-IV\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0cTHCM-CAL\u5728\u4e34\u5e8a\u98ce\u9669\u9884\u6d4b\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u5907\u66f4\u9ad8\u9884\u6d4b\u53ef\u9760\u6027\u548c\u7cbe\u5ea6\u3002", "conclusion": "\u9488\u5bf9\u591a\u6a21\u6001EHR\u6570\u636e\u7684\u56e0\u679c\u8054\u52a8\u4e0e\u98ce\u9669\u4f20\u64ad\uff0cTHCM-CAL\u53ef\u6355\u6349\u75c5\u60c5\u6f14\u53d8\u7684\u771f\u5b9e\u4e34\u5e8a\u673a\u5236\uff0c\u5e76\u4ee5\u6821\u51c6\u7f6e\u4fe1\u63d0\u5347\u9884\u6d4b\u53ef\u4fe1\u5ea6\uff0c\u5728\u590d\u6742\u573a\u666f\u4e0b\u5177\u5907\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.18213", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18213", "abs": "https://arxiv.org/abs/2506.18213", "authors": ["Mar\u00eda Victoria Carro", "Denise Alejandra Mester", "Francisca Gauna Selasco", "Luca Nicol\u00e1s Forziati Gangi", "Matheo Sandleris Musa", "Lola Ramos Pereyra", "Mario Leiva", "Juan Gustavo Corvalan", "Mar\u00eda Vanina Martinez", "Gerardo Simari"], "title": "A Conceptual Framework for AI Capability Evaluations", "comment": "arXiv admin note: text overlap with arXiv:2306.04181 by other authors", "summary": "As AI systems advance and integrate into society, well-designed and\ntransparent evaluations are becoming essential tools in AI governance,\ninforming decisions by providing evidence about system capabilities and risks.\nYet there remains a lack of clarity on how to perform these assessments both\ncomprehensively and reliably. To address this gap, we propose a conceptual\nframework for analyzing AI capability evaluations, offering a structured,\ndescriptive approach that systematizes the analysis of widely used methods and\nterminology without imposing new taxonomies or rigid formats. This framework\nsupports transparency, comparability, and interpretability across diverse\nevaluations. It also enables researchers to identify methodological weaknesses,\nassists practitioners in designing evaluations, and provides policymakers with\nan accessible tool to scrutinize, compare, and navigate complex evaluation\nlandscapes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2aAI\u80fd\u529b\u8bc4\u4f30\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u5347\u8bc4\u4f30\u7684\u7cfb\u7edf\u6027\u3001\u900f\u660e\u6027\u4e0e\u53ef\u6bd4\u6027\uff0c\u4e3a\u7814\u7a76\u8005\u3001\u4ece\u4e1a\u8005\u53ca\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u5b9e\u7528\u5206\u6790\u5de5\u5177\uff0c\u52a9\u529bAI\u6cbb\u7406\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u53d1\u5c55\u548c\u793e\u4f1a\u878d\u5408\uff0c\u9700\u8981\u6709\u826f\u597d\u8bbe\u8ba1\u4e14\u900f\u660e\u7684\u8bc4\u4f30\u6765\u652f\u6491AI\u6cbb\u7406\uff0c\u901a\u8fc7\u63d0\u4f9b\u7cfb\u7edf\u80fd\u529b\u548c\u98ce\u9669\u7684\u8bc1\u636e\u8f85\u52a9\u51b3\u7b56\u3002\u7136\u800c\uff0c\u76ee\u524d\u5c1a\u65e0\u5982\u4f55\u5168\u9762\u3001\u53ef\u9760\u5730\u8fdb\u884c\u6b64\u7c7b\u8bc4\u4f30\u7684\u6e05\u6670\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2aAI\u80fd\u529b\u8bc4\u4f30\u5206\u6790\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u4ee5\u7ed3\u6784\u5316\u548c\u63cf\u8ff0\u6027\u7684\u65b9\u6cd5\u5bf9\u5e7f\u6cdb\u4f7f\u7528\u7684\u65b9\u6cd5\u548c\u672f\u8bed\u8fdb\u884c\u7cfb\u7edf\u5316\u5206\u6790\uff0c\u800c\u4e0d\u662f\u5f15\u5165\u65b0\u7684\u5206\u7c7b\u6cd5\u6216\u4e25\u683c\u683c\u5f0f\u3002", "result": "\u8be5\u6846\u67b6\u63d0\u5347\u4e86\u4e0d\u540c\u8bc4\u4f30\u95f4\u7684\u900f\u660e\u5ea6\u3001\u53ef\u6bd4\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u7814\u7a76\u8005\u80fd\u591f\u53d1\u73b0\u65b9\u6cd5\u5b66\u4e0d\u8db3\uff0c\u5e2e\u52a9\u4ece\u4e1a\u4eba\u5458\u8bbe\u8ba1\u8bc4\u4f30\uff0c\u4e5f\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u4fbf\u4e8e\u4f7f\u7528\u7684\u5de5\u5177\uff0c\u4ee5\u4fbf\u5ba1\u67e5\u3001\u6bd4\u8f83\u5e76\u5e94\u5bf9\u590d\u6742\u7684\u8bc4\u4f30\u5c40\u9762\u3002", "conclusion": "\u6587\u7ae0\u901a\u8fc7\u63d0\u51fa\u7684\u6846\u67b6\uff0c\u4e3aAI\u80fd\u529b\u8bc4\u4f30\u63d0\u4f9b\u7ed3\u6784\u5316\u5206\u6790\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u8bc4\u4f30\u65b9\u6cd5\u7684\u6807\u51c6\u5316\u5e76\u4fc3\u8fdbAI\u6cbb\u7406\u51b3\u7b56\u3002"}}
{"id": "2506.17863", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17863", "abs": "https://arxiv.org/abs/2506.17863", "authors": ["Haoran Liu", "Amir Tahmasbi", "Ehtesham Sam Haque", "Purak Jain"], "title": "LLMs for Customized Marketing Content Generation and Evaluation at Scale", "comment": "KDD LLM4ECommerce Workshop 2025", "summary": "Offsite marketing is essential in e-commerce, enabling businesses to reach\ncustomers through external platforms and drive traffic to retail websites.\nHowever, most current offsite marketing content is overly generic,\ntemplate-based, and poorly aligned with landing pages, limiting its\neffectiveness. To address these limitations, we propose MarketingFM, a\nretrieval-augmented system that integrates multiple data sources to generate\nkeyword-specific ad copy with minimal human intervention. We validate\nMarketingFM via offline human and automated evaluations and large-scale online\nA/B tests. In one experiment, keyword-focused ad copy outperformed templates,\nachieving up to 9% higher CTR, 12% more impressions, and 0.38% lower CPC,\ndemonstrating gains in ad ranking and cost efficiency. Despite these gains,\nhuman review of generated ads remains costly. To address this, we propose\nAutoEval-Main, an automated evaluation system that combines rule-based metrics\nwith LLM-as-a-Judge techniques to ensure alignment with marketing principles.\nIn experiments with large-scale human annotations, AutoEval-Main achieved\n89.57% agreement with human reviewers. Building on this, we propose\nAutoEval-Update, a cost-efficient LLM-human collaborative framework to\ndynamically refine evaluation prompts and adapt to shifting criteria with\nminimal human input. By selectively sampling representative ads for human\nreview and using a critic LLM to generate alignment reports, AutoEval-Update\nimproves evaluation consistency while reducing manual effort. Experiments show\nthe critic LLM suggests meaningful refinements, improving LLM-human agreement.\nNonetheless, human oversight remains essential for setting thresholds and\nvalidating refinements before deployment.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u7528\u4e8e\u7535\u5546\u7ad9\u5916\u8425\u9500\u5185\u5bb9\u751f\u6210\u548c\u81ea\u52a8\u5316\u8bc4\u4f30\u7684\u65b0\u7cfb\u7edf\uff0c\u80fd\u63d0\u5347\u5e7f\u544a\u6548\u679c\u5e76\u964d\u4f4e\u4eba\u5de5\u8bc4\u4f30\u6210\u672c\uff0c\u4f46\u6700\u7ec8\u90e8\u7f72\u4ecd\u9700\u4eba\u5de5\u5ba1\u6838\u3002", "motivation": "\u73b0\u6709\u7684\u7535\u5546\u7ad9\u5916\u8425\u9500\u5185\u5bb9\u8fc7\u4e8e\u901a\u7528\u3001\u6a21\u677f\u5316\u4e14\u4e0e\u843d\u5730\u9875\u5339\u914d\u5ea6\u4f4e\uff0c\u5bfc\u81f4\u63a8\u5e7f\u6548\u679c\u53d7\u9650\uff0c\u9700\u8981\u66f4\u667a\u80fd\u4e14\u9ad8\u6548\u7684\u5185\u5bb9\u751f\u6210\u4e0e\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86MarketingFM\u7cfb\u7edf\uff0c\u5229\u7528\u591a\u6570\u636e\u6e90\u548c\u68c0\u7d22\u589e\u5f3a\u6280\u672f\u751f\u6210\u9488\u5bf9\u5173\u952e\u8bcd\u7684\u5e7f\u544a\u6587\u6848\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u3002\u540c\u65f6\u6784\u5efa\u4e86AutoEval-Main\u81ea\u52a8\u5316\u8bc4\u4f30\u7cfb\u7edf\uff0c\u7ed3\u5408\u89c4\u5219\u4e0eLLM\uff08\u5927\u8bed\u8a00\u6a21\u578b\uff09\u8bc4\u5224\uff0c\u5e76\u8fdb\u4e00\u6b65\u63d0\u51faAutoEval-Update\u4eba\u673a\u534f\u4f5c\u6846\u67b6\u52a8\u6001\u4f18\u5316\u8bc4\u4f30\u6807\u51c6\u3002", "result": "MarketingFM\u751f\u6210\u7684\u9488\u5bf9\u6027\u5e7f\u544a\u6587\u6848\u5728A/B\u6d4b\u8bd5\u4e2dCTR\u63d0\u53479%\uff0c\u5c55\u793a\u91cf\u63d0\u9ad812%\uff0cCPC\u964d\u4f4e0.38%\u3002AutoEval-Main\u7cfb\u7edf\u4e0e\u4eba\u5de5\u8bc4\u5ba1\u4e00\u81f4\u7387\u8fbe89.57%\u3002AutoEval-Update\u80fd\u663e\u8457\u63d0\u5347\u8bc4\u4f30\u4e00\u81f4\u6027\u5e76\u964d\u4f4e\u4eba\u5de5\u6210\u672c\uff0c\u4f46\u4eba\u5de5\u628a\u5173\u4ecd\u5fc5\u4e0d\u53ef\u5c11\u3002", "conclusion": "\u5173\u952e\u8bcd\u9a71\u52a8\u7684\u5e7f\u544a\u751f\u6210\u7cfb\u7edf\u4e0e\u81ea\u52a8\u5316\u8bc4\u4f30\u4f53\u7cfb\u80fd\u63d0\u5347\u7535\u5546\u5e7f\u544a\u6295\u653e\u6548\u679c\u548c\u8bc4\u4f30\u6548\u7387\uff0c\u4f46\u5173\u952e\u73af\u8282\u4ecd\u9700\u4eba\u5de5\u6700\u7ec8\u628a\u63a7\u3002"}}
{"id": "2506.18233", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18233", "abs": "https://arxiv.org/abs/2506.18233", "authors": ["Ruike Zhu", "Hanwen Zhang", "Tianyu Shi", "Chi Wang", "Tianyi Zhou", "Zengyi Qin"], "title": "The 4th Dimension for Scaling Model Size", "comment": null, "summary": "Scaling the size of large language models typically involves three\ndimensions: depth, width, and the number of parameters. In this work, we\nexplore a fourth dimension, virtual logical depth (VLD), which increases the\neffective algorithmic depth without changing the overall parameter count by\nreusing parameters within the model. Although parameter reuse is not a new\nconcept, its potential and characteristics in model scaling have not been\nthoroughly studied. Through carefully designed controlled experiments, we make\nthe following key discoveries regarding VLD scaling:\n  VLD scaling forces the knowledge capacity of the model to remain almost\nconstant, with only minor variations.\n  VLD scaling enables a significant improvement in reasoning capability,\nprovided the scaling method is properly implemented.\n  The number of parameters correlates with knowledge capacity, but not with\nreasoning capability. Under certain conditions, it is not necessary to increase\nthe parameter count to enhance reasoning.\n  These findings are consistent across various model configurations and are\nlikely to be generally valid within the scope of our experiments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5e76\u7cfb\u7edf\u7814\u7a76\u4e86\u901a\u8fc7\u53c2\u6570\u590d\u7528\u589e\u52a0\u5927\u6a21\u578b\u201c\u865a\u62df\u903b\u8f91\u6df1\u5ea6\u201d\u7684\u6269\u5c55\u65b9\u6cd5\uff0c\u6307\u51fa\u53ea\u8981\u65b9\u6cd5\u5f97\u5f53\uff0cVLD\u53ef\u4ee5\u5728\u4e0d\u589e\u53c2\u6570\u91cf\u7684\u6761\u4ef6\u4e0b\u5927\u5e45\u63d0\u5347\u6a21\u578b\u63a8\u7406\u529b\uff0c\u800c\u5bf9\u77e5\u8bc6\u5bb9\u91cf\u5f71\u54cd\u8f83\u5c0f\u3002", "motivation": "\u5728\u73b0\u6709\u7684\u4e09\u79cd\u5927\u6a21\u578b\u6269\u5c55\u65b9\u5f0f\uff08\u6df1\u5ea6\u3001\u5bbd\u5ea6\u3001\u53c2\u6570\u6570\u91cf\uff09\u57fa\u7840\u4e0a\uff0c\u63a2\u7d22\u53c2\u6570\u590d\u7528\u6240\u5e26\u6765\u7684\u201c\u865a\u62df\u903b\u8f91\u6df1\u5ea6\u201d\u4f5c\u4e3a\u7b2c\u56db\u79cd\u6269\u5c55\u7ef4\u5ea6\uff0c\u5206\u6790\u5176\u63d0\u5347\u6a21\u578b\u80fd\u529b\u7684\u6f5c\u529b\u53ca\u7279\u70b9\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86\u6709\u63a7\u5236\u7684\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u5bf9\u6bd4\u5206\u6790\u4e0d\u540c\u7684VLD\u6269\u5c55\u65b9\u6cd5\u4e0b\u6a21\u578b\u7684\u8868\u73b0\uff0c\u4ee5\u9a8c\u8bc1\u53c2\u6570\u590d\u7528\u5bf9\u77e5\u8bc6\u5bb9\u91cf\u548c\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0VLD\u6269\u5c55\u80fd\u591f\u5728\u53c2\u6570\u603b\u6570\u4fdd\u6301\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u800c\u5bf9\u77e5\u8bc6\u5bb9\u91cf\u5f71\u54cd\u5f88\u5c0f\u3002\u53c2\u6570\u6570\u91cf\u4f9d\u7136\u4e3b\u5bfc\u77e5\u8bc6\u5bb9\u91cf\u63d0\u5347\uff0c\u4f46\u4e0e\u63a8\u7406\u80fd\u529b\u65e0\u5173\u3002\u8be5\u73b0\u8c61\u5728\u591a\u79cd\u6a21\u578b\u914d\u7f6e\u4e0b\u5747\u6210\u7acb\u3002", "conclusion": "\u865a\u62df\u903b\u8f91\u6df1\u5ea6\uff08VLD\uff09\u6269\u5c55\u4e0d\u4f1a\u663e\u8457\u589e\u52a0\u6a21\u578b\u7684\u77e5\u8bc6\u5bb9\u91cf\uff0c\u4f46\u80fd\u591f\u5927\u5e45\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u540c\u65f6\uff0c\u53c2\u6570\u6570\u91cf\u4e3b\u8981\u5bf9\u5e94\u77e5\u8bc6\u5bb9\u91cf\uff0c\u4e0e\u63a8\u7406\u80fd\u529b\u65e0\u76f4\u63a5\u5173\u7cfb\uff0c\u56e0\u6b64\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u5e76\u4e0d\u4e00\u5b9a\u4f9d\u8d56\u53c2\u6570\u91cf\u7684\u589e\u52a0\u3002"}}
{"id": "2506.17864", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17864", "abs": "https://arxiv.org/abs/2506.17864", "authors": ["Taolin Zhang", "Haidong Kang", "Dongyang Li", "Qizhou Chen", "Chengyu Wang Xiaofeng He", "Richang Hong"], "title": "QueueEDIT: Structural Self-Correction for Sequential Model Editing in LLMs", "comment": null, "summary": "Recently, large language models (LLMs) have demonstrated impressive results\nbut still suffer from hallucinations. Model editing has been proposed to\ncorrect factual inaccuracies in LLMs. A challenging case is sequential model\nediting (SME), which aims to rectify errors continuously rather than treating\nthem as a one-time task. During SME, the general capabilities of LLMs can be\nnegatively affected due to the introduction of new parameters. In this paper,\nwe propose a queue-based self-correction framework (QueueEDIT) that not only\nenhances SME performance by addressing long-sequence dependency but also\nmitigates the impact of parameter bias on the general capabilities of LLMs.\nSpecifically, we first introduce a structural mapping editing loss to map the\ntriplets to the knowledge-sensitive neurons within the Transformer layers of\nLLMs. We then store the located parameters for each piece of edited knowledge\nin a queue and dynamically align previously edited parameters. In each edit, we\nselect queue parameters most relevant to the currently located parameters to\ndetermine whether previous knowledge needs realignment. Irrelevant parameters\nin the queue are frozen, and we update the parameters at the queue head to the\nLLM to ensure they do not harm general abilities. Experiments show that our\nframework significantly outperforms strong baselines across various SME\nsettings and maintains competitiveness in single-turn editing. The resulting\nLLMs also preserve high capabilities in general NLP tasks throughout the SME\nprocess.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86QueueEDIT\u6846\u67b6\uff0c\u901a\u8fc7\u961f\u5217\u7ba1\u7406\u4e0e\u81ea\u9002\u5e94\u53c2\u6570\u5bf9\u9f50\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u8f6e\u7f16\u8f91\u80fd\u529b\uff0c\u5e76\u51cf\u7f13\u901a\u7528\u80fd\u529b\u7684\u4e0b\u964d\uff0c\u5728\u5404\u7c7b\u5b9e\u9a8c\u4e2d\u6548\u679c\u4f18\u4e8e\u5176\u5b83\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c3d\u7ba1\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u4ecd\u5b58\u5728\u5e7b\u89c9\uff08\u4e8b\u5b9e\u6027\u9519\u8bef\uff09\u95ee\u9898\uff0c\u6a21\u578b\u7f16\u8f91\u88ab\u7528\u4e8e\u4fee\u6b63\u8fd9\u4e9b\u9519\u8bef\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u53ea\u8fdb\u884c\u4e00\u6b21\u6027\u7f16\u8f91\uff0c\u96be\u4ee5\u5e94\u5bf9\u9700\u8981\u8fde\u7eed\u591a\u6b21\u4fee\u6b63\u7684\u60c5\u666f\uff0c\u4e14\u9891\u7e41\u7f16\u8f91\u53ef\u80fd\u524a\u5f31\u6a21\u578b\u7684\u6574\u4f53\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u961f\u5217\u7684\u81ea\u6211\u7ea0\u6b63\u6846\u67b6\uff08QueueEDIT\uff09\u3002\u8be5\u6846\u67b6\u9996\u5148\u5c06\u77e5\u8bc6\u4e09\u5143\u7ec4\u6620\u5c04\u5230Transformer\u5c42\u4e2d\u7684\u77e5\u8bc6\u654f\u611f\u795e\u7ecf\u5143\uff0c\u5e76\u5c06\u6bcf\u6b21\u7f16\u8f91\u6d89\u53ca\u7684\u53c2\u6570\u5b58\u50a8\u5728\u961f\u5217\u4e2d\uff0c\u5bf9\u76f8\u5173\u53c2\u6570\u8fdb\u884c\u52a8\u6001\u5bf9\u9f50\u3002\u6bcf\u6b21\u7f16\u8f91\u65f6\uff0c\u53ea\u8c03\u6574\u4e0e\u5f53\u524d\u4efb\u52a1\u76f8\u5173\u7684\u53c2\u6570\uff0c\u51bb\u7ed3\u65e0\u5173\u53c2\u6570\uff0c\u5e76\u5c06\u6700\u65b0\u53c2\u6570\u66f4\u65b0\u56de\u6a21\u578b\uff0c\u4ece\u800c\u51cf\u5c0f\u5bf9\u6a21\u578b\u901a\u7528\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cQueueEDIT\u5728\u591a\u79cd\u8fde\u7eed\u7f16\u8f91\u4efb\u52a1\u4e0b\u4f18\u4e8e\u5176\u4ed6\u4e3b\u6d41\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u5355\u6b21\u7f16\u8f91\u4efb\u52a1\u4e2d\u4e5f\u8868\u73b0\u51fa\u826f\u597d\u7684\u7ade\u4e89\u529b\u3002\u540c\u65f6\uff0c\u7ecf\u8fc7\u591a\u8f6e\u7f16\u8f91\u540e\u7684LLM\u4f9d\u7136\u80fd\u591f\u4fdd\u6301\u8f83\u9ad8\u7684NLP\u4efb\u52a1\u901a\u7528\u80fd\u529b\u3002", "conclusion": "QueueEDIT\u80fd\u591f\u5728\u4fdd\u969c\u6a21\u578b\u7f16\u8f91\u6709\u6548\u6027\u7684\u540c\u65f6\uff0c\u8f83\u597d\u5730\u7ef4\u62a4\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6574\u4f53\u80fd\u529b\uff0c\u4e3a\u89e3\u51b3\u5e8f\u8d2f\u6a21\u578b\u7f16\u8f91\u4e2d\u7684\u80fd\u529b\u9000\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u601d\u8def\u3002"}}
{"id": "2506.18260", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18260", "abs": "https://arxiv.org/abs/2506.18260", "authors": ["FuTe Wong"], "title": "Advanced For-Loop for QML algorithm search", "comment": "7 pages, 8 figures", "summary": "This paper introduces an advanced framework leveraging Large Language\nModel-based Multi-Agent Systems (LLMMA) for the automated search and\noptimization of Quantum Machine Learning (QML) algorithms. Inspired by Google\nDeepMind's FunSearch, the proposed system works on abstract level to\niteratively generates and refines quantum transformations of classical machine\nlearning algorithms (concepts), such as the Multi-Layer Perceptron,\nforward-forward and backpropagation algorithms. As a proof of concept, this\nwork highlights the potential of agentic frameworks to systematically explore\nclassical machine learning concepts and adapt them for quantum computing,\npaving the way for efficient and automated development of QML algorithms.\nFuture directions include incorporating planning mechanisms and optimizing\nstrategy in the search space for broader applications in quantum-enhanced\nmachine learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u641c\u7d22\u548c\u4f18\u5316\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u521d\u6b65\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u53ef\u9ad8\u6548\u63a2\u7d22\u5e76\u6539\u7f16\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5230\u91cf\u5b50\u9886\u57df\uff0c\u4e3aQML\u7b97\u6cd5\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5411\u91cf\u5b50\u8ba1\u7b97\u9886\u57df\u7684\u8fc1\u79fb\u5b58\u5728\u624b\u52a8\u8bbe\u8ba1\u548c\u4f18\u5316\u96be\u9898\uff0c\u56e0\u6b64\u4e9f\u9700\u9ad8\u6548\u81ea\u52a8\u5316\u7684\u63a2\u7d22\u4e0e\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08LLMMA\uff09\u6846\u67b6\uff0c\u7cfb\u7edf\u6027\u5730\u81ea\u52a8\u751f\u6210\u3001\u6539\u8fdb\u548c\u4f18\u5316\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5728\u91cf\u5b50\u8ba1\u7b97\u9886\u57df\u7684\u8f6c\u6362\u65b9\u6cd5\u3002\u8be5\u7cfb\u7edf\u6a21\u4effFunSearch\uff0c\u901a\u8fc7\u591a\u8f6e\u8fed\u4ee3\u63a2\u67e5\u91cf\u5b50\u7248\u672c\u7684MLP\u3001\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\u7b49\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u8be5\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5728\u63a2\u7d22\u5e76\u91cf\u5b50\u5316\u7ecf\u5178\u5b66\u4e60\u7b97\u6cd5\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u81ea\u52a8\u5316\u5f00\u53d1QML\u7b97\u6cd5\u7684\u6f5c\u529b\u3002\u4e3a\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u672a\u6765\u5f00\u53d1\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u81ea\u52a8\u5316\u7684\u6280\u672f\u8def\u7ebf\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e3aQML\u7b97\u6cd5\u7684\u81ea\u52a8\u641c\u7d22\u4e0e\u4f18\u5316\u5e26\u6765\u4e86\u521b\u65b0\u8def\u5f84\uff0c\u672a\u6765\u53ef\u7ee7\u7eed\u96c6\u6210\u89c4\u5212\u4e0e\u4f18\u5316\u7b56\u7565\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u91cf\u5b50\u589e\u5f3a\u673a\u5668\u5b66\u4e60\u9886\u57df\u3002"}}
{"id": "2506.17871", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17871", "abs": "https://arxiv.org/abs/2506.17871", "authors": ["Chenghao Yang", "Ari Holtzman"], "title": "How Alignment Shrinks the Generative Horizon", "comment": "Codebase: https://github.com/yangalan123/LLMBranchingFactor, Website:\n  https://yangalan123.github.io/branching_factor/", "summary": "Despite their impressive capabilities, aligned large language models (LLMs)\noften generate outputs that lack diversity. What drives this stability in the\ngeneration? We investigate this phenomenon through the lens of probability\nconcentration in the model's output distribution. To quantify this\nconcentration, we introduce the Branching Factor (BF) -- a token-invariant\nmeasure of the effective number of plausible next steps during generation. Our\nempirical analysis reveals two key findings: (1) BF often decreases as\ngeneration progresses, suggesting that LLMs become more predictable as they\ngenerate. (2) alignment tuning substantially sharpens the model's output\ndistribution from the outset, reducing BF by nearly an order of magnitude\n(e.g., from 12 to 1.2) relative to base models. This stark reduction helps\nexplain why aligned models often appear less sensitive to decoding strategies.\nBuilding on this insight, we find this stability has surprising implications\nfor complex reasoning. Aligned Chain-of-Thought (CoT) models (e.g.,\nDeepSeek-distilled models), for instance, leverage this effect; by generating\nlonger reasoning chains, they push generation into later, more deterministic\n(lower BF) stages, resulting in more stable outputs. We hypothesize that\nalignment tuning does not fundamentally change a model's behavior, but instead\nsteers it toward stylistic tokens (e.g., \"Sure\") that unlock low-entropy\ntrajectories already present in the base model. This view is supported by\nnudging experiments, which show that prompting base models with such tokens can\nsimilarly reduce BF. Together, our findings establish BF as a powerful\ndiagnostic for understanding and controlling LLM outputs - clarifying how\nalignment reduces variability, how CoT promotes stable generations, and how\nbase models can be steered away from diversity.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u9f50\u5e73\u5927\u6a21\u578b\u7f3a\u4e4f\u591a\u6837\u6027\u7684\u6839\u56e0\u5728\u4e8e\u751f\u6210\u5206\u5e03\u7684\u6536\u655b\u4e0eBF\u663e\u8457\u964d\u4f4e\uff0c\u6307\u51fa\u9f50\u5e73\u8bad\u7ec3\u5b9e\u9645\u4e0a\u662f\u901a\u8fc7\u8bed\u6c14token\u5f15\u5bfc\u800c\u975e\u672c\u8d28\u6539\u53d8\u6a21\u578b\u884c\u4e3a\uff0cBF\u53ef\u4f5c\u4e3a\u8bca\u65ad\u4e0e\u8c03\u63a7\u8f93\u51fa\u591a\u6837\u6027\u7684\u6709\u6548\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u9f50\u5e73\uff08aligned\uff09\u540e\uff0c\u5176\u751f\u6210\u7684\u8f93\u51fa\u5f80\u5f80\u7f3a\u4e4f\u591a\u6837\u6027\u3002\u8be5\u8bba\u6587\u5e0c\u671b\u63a2\u660e\u9020\u6210\u8f93\u51fa\u7a33\u5b9a\u3001\u7f3a\u4e4f\u591a\u6837\u6027\u7684\u5185\u5728\u539f\u56e0\u53ca\u673a\u5236\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u5206\u652f\u56e0\u5b50\uff08Branching Factor, BF\uff09\u4f5c\u4e3a\u8861\u91cf\u6a21\u578b\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u201c\u4e0b\u4e00\u4e2a\u5408\u7406token\u9009\u62e9\u201d\u6570\u91cf\u7684\u5ea6\u91cf\u6307\u6807\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u8ddf\u8e2aBF\u7684\u53d8\u5316\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u8fdb\u884c\u4e86\u201cnudging\u201d\u5b9e\u9a8c\uff0c\u901a\u8fc7\u8bbe\u7f6e\u7279\u5b9a\u63d0\u793a\u8bcd\u76d1\u6d4b\u57fa\u5ea7\u6a21\u578b\u5728\u8f93\u51fa\u591a\u6837\u6027\u4e0a\u7684\u53d8\u5316\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff1a\uff081\uff09\u751f\u6210\u8fc7\u7a0b\u4e2dBF\u666e\u904d\u964d\u4f4e\uff0c\u8bf4\u660e\u6a21\u578b\u8d8a\u751f\u6210\u8d8a\u8d8b\u4e8e\u786e\u5b9a\u6027\u3002\uff082\uff09\u9f50\u5e73\u8c03\u4f18\u4f1a\u6781\u5927\u964d\u4f4e\u521d\u59cb\u7684BF\uff08\u4f8b\u5982\u4ece12\u964d\u81f31.2\uff09\uff0c\u663e\u8457\u6536\u655b\u8f93\u51fa\u5206\u5e03\uff0c\u6709\u52a9\u4e8e\u89e3\u91ca\u9f50\u5e73\u6a21\u578b\u5bf9\u89e3\u7801\u7b56\u7565\u7684\u4e0d\u654f\u611f\u6027\u3002\u6b64\u5916\uff0c\u94fe\u5f0f\u63a8\u7406\u6a21\u578b\u6b63\u662f\u901a\u8fc7\u5ef6\u957f\u63a8\u7406\u94fe\u6761\uff0c\u5c06\u751f\u6210\u63a8\u5411\u66f4\u4e3a\u786e\u5b9a\u6027\u7684\u9636\u6bb5\u800c\u5b9e\u73b0\u8f93\u51fa\u7a33\u5b9a\u3002\u91cd\u8981\u53d1\u73b0\u8fd8\u5305\u62ec\uff0c\u5bf9base\u6a21\u578b\u52a0\u5165\u7279\u5b9a\u7684\u201c\u98ce\u683c\u6027token\u201d\u4e5f\u80fd\u5b9e\u73b0\u7c7b\u4f3c\u7684BF\u964d\u4f4e\u3002", "conclusion": "BF\u6210\u4e3a\u7406\u89e3\u4e0e\u8c03\u8282LLM\u8f93\u51fa\u7a33\u5b9a\u6027\u4e0e\u591a\u6837\u6027\u7684\u5f3a\u6709\u529b\u8bca\u65ad\u5de5\u5177\u3002\u9f50\u5e73\u4e3b\u8981\u901a\u8fc7\u98ce\u683c\u5f15\u5bfctoken\u63a8\u52a8\u6a21\u578b\u8fdb\u5165\u4f4e\u71b5\uff08\u786e\u5b9a\u6027\u5f3a\uff09\u7684\u4e0a\u4e0b\u6587\u8f68\u8ff9\uff0c\u800c\u5e76\u975e\u5b9e\u8d28\u6539\u53d8\u6a21\u578b\u672c\u4f53\u884c\u4e3a\uff0c\u4e3aLLM\u9f50\u5e73\u8bad\u7ec3\u548c\u63a8\u7406\u751f\u6210\u7684\u7406\u89e3\u4e0e\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.18348", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18348", "abs": "https://arxiv.org/abs/2506.18348", "authors": ["Weilun Yu", "Shixiang Tang", "Yonggui Huang", "Nanqing Dong", "Li Fan", "Honggang Qi", "Wei Liu", "Xiaoli Diao", "Xi Chen", "Wanli Ouyang"], "title": "Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team", "comment": null, "summary": "Scientific progress increasingly relies on effective collaboration among\nresearchers, a dynamic that large language models (LLMs) have only begun to\nemulate. While recent LLM-based scientist agents show promise in autonomous\nscientific discovery, they often lack the interactive reasoning and evaluation\nmechanisms essential to real-world research. We propose IDVSCI (Internal\nDiscussion and Vote SCIentists), a multi-agent framework built on LLMs that\nincorporates two key innovations: a Dynamic Knowledge Exchange mechanism\nenabling iterative feedback among agents, and a Dual-Diversity Review paradigm\nthat simulates heterogeneous expert evaluation. These components jointly\npromote deeper reasoning and the generation of more creative and impactful\nscientific ideas. To evaluate the effectiveness and generalizability of our\napproach, we conduct experiments on two datasets: a widely used benchmark in\ncomputer science and a new dataset we introduce in the health sciences domain.\nResults show that IDVSCI consistently achieves the best performance across both\ndatasets, outperforming existing systems such as AI Scientist and VIRSCI. These\nfindings highlight the value of modeling interaction and peer review dynamics\nin LLM-based autonomous research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7ec4\u6210\u591a\u667a\u80fd\u4f53\u79d1\u5b66\u5bb6\u56e2\u961f\uff0c\u901a\u8fc7\u5185\u90e8\u8ba8\u8bba\u3001\u6295\u7968\u3001\u521b\u65b0\u7684\u77e5\u8bc6\u4ea4\u6d41\u548c\u591a\u6837\u5316\u540c\u884c\u8bc4\u5ba1\uff0c\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u79d1\u5b66\u7814\u7a76\u7684\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6848\uff0c\u5f3a\u8c03\u4e86\u4e92\u52a8\u4e0e\u8bc4\u5ba1\u673a\u5236\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u6a21\u62df\u79d1\u5b66\u7814\u7a76\u534f\u4f5c\u4e0a\u8fdb\u5c55\u6709\u9650\uff0c\u7f3a\u4e4f\u7c7b\u4f3c\u4e8e\u73b0\u5b9e\u79d1\u7814\u4e2d\u4e92\u52a8\u63a8\u7406\u548c\u8bc4\u8bae\u7684\u673a\u5236\uff0c\u9650\u5236\u4e86\u5176\u79d1\u5b66\u53d1\u73b0\u80fd\u529b\u3002", "method": "\u63d0\u51faIDVSCI\u6846\u67b6\uff0c\u5305\u62ec\u52a8\u6001\u77e5\u8bc6\u4ea4\u6362\u673a\u5236\u548c\u53cc\u91cd\u591a\u6837\u6027\u8bc4\u5ba1\u8303\u5f0f\uff0c\u5141\u8bb8LLM\u79d1\u5b66\u5bb6\u4ee3\u7406\u95f4\u8fdb\u884c\u8fed\u4ee3\u53cd\u9988\u548c\u591a\u6837\u5316\u540c\u884c\u8bc4\u8bae\uff0c\u4fc3\u8fdb\u66f4\u6df1\u5165\u63a8\u7406\u548c\u521b\u65b0\u6027\u89c2\u70b9\u751f\u6210\u3002", "result": "\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u5e38\u7528\u57fa\u51c6\u6570\u636e\u96c6\u548c\u5065\u5eb7\u79d1\u5b66\u65b0\u6570\u636e\u96c6\u4e0a\uff0cIDVSCI\u90fd\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709AI Scientist\u548cVIRSCI\u7b49\u7cfb\u7edf\u7684\u6700\u4f73\u8868\u73b0\u3002", "conclusion": "IDVSCI\u6846\u67b6\u901a\u8fc7\u5efa\u6a21LLM\u79d1\u5b66\u5bb6\u4ee3\u7406\u95f4\u7684\u4e92\u52a8\u548c\u540c\u884c\u8bc4\u8bae\u52a8\u6001\uff0c\u6709\u6548\u63d0\u5347\u4e86\u81ea\u4e3b\u79d1\u5b66\u7814\u7a76\u7684\u521b\u9020\u529b\u548c\u5f71\u54cd\u529b\uff0c\u8bc1\u660e\u4e86\u6b64\u7c7b\u673a\u5236\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2506.17881", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17881", "abs": "https://arxiv.org/abs/2506.17881", "authors": ["Hua Tang", "Lingyong Yan", "Yukun Zhao", "Shuaiqiang Wang", "Jizhou Huang", "Dawei Yin"], "title": "Multi-turn Jailbreaking via Global Refinement and Active Fabrication", "comment": null, "summary": "Large Language Models (LLMs) have achieved exceptional performance across a\nwide range of tasks. However, they still pose significant safety risks due to\nthe potential misuse for malicious purposes. Jailbreaks, which aim to elicit\nmodels to generate harmful content, play a critical role in identifying the\nunderlying security threats. Recent jailbreaking primarily focuses on\nsingle-turn scenarios, while the more complicated multi-turn scenarios remain\nunderexplored. Moreover, existing multi-turn jailbreaking techniques struggle\nto adapt to the evolving dynamics of dialogue as the interaction progresses. To\naddress this limitation, we propose a novel multi-turn jailbreaking method that\nrefines the jailbreaking path globally at each interaction. We also actively\nfabricate model responses to suppress safety-related warnings, thereby\nincreasing the likelihood of eliciting harmful outputs in subsequent questions.\nExperimental results demonstrate the superior performance of our method\ncompared with existing single-turn and multi-turn jailbreaking techniques\nacross six state-of-the-art LLMs. Our code is publicly available at\nhttps://github.com/Ytang520/Multi-Turn_jailbreaking_Global-Refinment_and_Active-Fabrication.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u5c40\u4f18\u5316\u548c\u4e3b\u52a8\u4f2a\u9020\u54cd\u5e94\u7684\u65b0\u9896\u591a\u8f6e\u8d8a\u72f1\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u63d0\u5347\u4e3b\u6d41\u5927\u6a21\u578b\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u7684\u98ce\u9669\uff0c\u9700\u5f15\u8d77\u5b89\u5168\u5173\u6ce8\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u56e0\u6f5c\u5728\u88ab\u6076\u610f\u6ee5\u7528\u800c\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u5c24\u5176\u662f\u201c\u8d8a\u72f1\u201d\u653b\u51fb\u80fd\u5f15\u53d1\u6709\u5bb3\u5185\u5bb9\u8f93\u51fa\uff0c\u76ee\u524d\u591a\u4e3a\u5355\u8f6e\u5bf9\u8bdd\u653b\u51fb\uff0c\u591a\u8f6e\u573a\u666f\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u591a\u8f6e\u8d8a\u72f1\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u6bcf\u6b21\u4ea4\u4e92\u65f6\u5168\u5c40\u4f18\u5316\u8d8a\u72f1\u8def\u5f84\uff0c\u5e76\u4e3b\u52a8\u4f2a\u9020\u6a21\u578b\u56de\u5e94\u4ee5\u6291\u5236\u5b89\u5168\u8b66\u544a\uff0c\u4ece\u800c\u63d0\u5347\u540e\u7eed\u95ee\u9898\u5f15\u53d1\u6709\u5bb3\u8f93\u51fa\u7684\u6982\u7387\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u516d\u4e2a\u4e3b\u6d41LLM\u4e0a\u4f18\u4e8e\u73b0\u6709\u5355\u8f6e\u53ca\u591a\u8f6e\u8d8a\u72f1\u6280\u672f\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u8f6e\u8d8a\u72f1\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u7684\u6982\u7387\uff0c\u663e\u793a\u51fa\u8f83\u5f3a\u7684\u653b\u9632\u80fd\u529b\uff0c\u5bf9LLM\u5b89\u5168\u9632\u62a4\u63d0\u51fa\u65b0\u6311\u6218\u3002"}}
{"id": "2506.18424", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.18424", "abs": "https://arxiv.org/abs/2506.18424", "authors": ["Chengjie Liu", "Weiyu Chen", "Huiyao Xu", "Yuan Du", "Jun Yang", "Li Du"], "title": "A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction", "comment": "Accepted by ISEDA 2025", "summary": "In the design process of the analog circuit pre-layout phase, device sizing\nis an important step in determining whether an analog circuit can meet the\nrequired performance metrics. Many existing techniques extract the circuit\nsizing task as a mathematical optimization problem to solve and continuously\nimprove the optimization efficiency from a mathematical perspective. But they\nignore the automatic introduction of prior knowledge, fail to achieve effective\npruning of the search space, which thereby leads to a considerable compression\nmargin remaining in the search space. To alleviate this problem, we propose a\nlarge language model (LLM)-based multi-agent framework for analog circuits'\nsizing relationships extraction from academic papers. The search space in the\nsizing process can be effectively pruned based on the sizing relationship\nextracted by this framework. Eventually, we conducted tests on 3 types of\ncircuits, and the optimization efficiency was improved by $2.32 \\sim 26.6\n\\times$. This work demonstrates that the LLM can effectively prune the search\nspace for analog circuit sizing, providing a new solution for the combination\nof LLMs and conventional analog circuit design automation methods.", "AI": {"tldr": "\u63d0\u51fa\u7528LLM\u81ea\u52a8\u4ece\u6587\u732e\u63d0\u53d6\u7535\u8def\u5c3a\u5bf8\u5173\u7cfb\uff0c\u6709\u6548\u526a\u679d\u641c\u7d22\u7a7a\u95f4\uff0c\u63d0\u5347\u4f18\u5316\u6548\u73872~26\u500d\uff0c\u4e3a\u7535\u8def\u8bbe\u8ba1\u81ea\u52a8\u5316\u63d0\u4f9b\u65b0\u65b9\u6cd5\u3002", "motivation": "\u5728\u6a21\u62df\u7535\u8def\u7684\u8bbe\u8ba1\u524d\u671f\uff0c\u5668\u4ef6\u5c3a\u5bf8\u7684\u8bbe\u5b9a\uff08device sizing\uff09\u5bf9\u80fd\u5426\u6ee1\u8db3\u6027\u80fd\u6307\u6807\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u591a\u628a\u8fd9\u4e00\u95ee\u9898\u5f53\u4f5c\u6570\u5b66\u4f18\u5316\u95ee\u9898\uff0c\u6709\u6548\u7387\u63d0\u5347\u7a7a\u95f4\uff0c\u4f46\u672a\u80fd\u5145\u5206\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u8fdb\u884c\u641c\u7d22\u7a7a\u95f4\u526a\u679d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u4ece\u5b66\u672f\u8bba\u6587\u4e2d\u81ea\u52a8\u63d0\u53d6\u6a21\u62df\u7535\u8def\u7684\u5c3a\u5bf8\u5173\u8054\uff08sizing relationship\uff09\uff0c\u636e\u6b64\u5bf9\u4f18\u5316\u641c\u7d22\u7a7a\u95f4\u8fdb\u884c\u6709\u6548\u526a\u679d\u3002\u5e76\u57283\u7c7b\u7535\u8def\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "result": "\u5728\u6d4b\u8bd5\u76843\u7c7b\u7535\u8def\u4e0a\uff0c\u4f18\u5316\u6548\u7387\u63d0\u5347\u4e862.32\u523026.6\u500d\u3002", "conclusion": "LLM\u53ef\u4ee5\u9ad8\u6548\u5730\u526a\u679d\u6a21\u62df\u7535\u8def\u5c3a\u5bf8\u8bbe\u5b9a\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u4e3aLLM\u4e0e\u4f20\u7edf\u7535\u8def\u8bbe\u8ba1\u81ea\u52a8\u5316\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u601d\u8def\u3002"}}
{"id": "2506.17949", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17949", "abs": "https://arxiv.org/abs/2506.17949", "authors": ["Hong Su"], "title": "Scatter-Based Innovation Propagation in Large Language Models for Multi-Stage Process Adaptation", "comment": null, "summary": "Large Language Models (LLMs) exhibit strong capabilities in reproducing and\nextending patterns observed during pretraining but often struggle to generalize\nnovel ideas beyond their original context. This paper addresses the challenge\nof applying such localized innovations - introduced at a specific stage or\ncomponent - to other parts of a multi-stage process. We propose a scatter-based\ninnovation expansion model (innovation scatter model) that guides the LLM\nthrough a four-step process: (1) identifying the core innovation by comparing\nthe user's input with its surrounding context, (2) generalizing the innovation\nby removing references to specific stages or components, (3) determining\nwhether the generalized innovation applies to a broader scope beyond the\noriginal stage, and (4) systematically applying it to other structurally\nsimilar stages using the LLM. This model leverages structural redundancy across\nstages to improve the applicability of novel ideas. Verification results\ndemonstrate that the innovation scatter model enables LLMs to extend\ninnovations across structurally similar stages, thereby enhancing\ngeneralization and reuse.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u6269\u6563\u6a21\u578b\uff0c\u6709\u6548\u63d0\u5347LLM\u5c06\u521b\u65b0\u63a8\u5e7f\u81f3\u591a\u9636\u6bb5\u6d41\u7a0b\u7684\u80fd\u529b\uff0c\u7ecf\u9a8c\u8bc1\u80fd\u6539\u8fdb\u6cdb\u5316\u548c\u521b\u65b0\u590d\u7528\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9884\u8bad\u7ec3\u4e2d\u80fd\u591f\u5f88\u597d\u5730\u518d\u73b0\u548c\u6269\u5c55\u5df2\u6709\u6a21\u5f0f\uff0c\u4f46\u5728\u5c06\u521b\u65b0\u4ece\u4e00\u4e2a\u7279\u5b9a\u9636\u6bb5\u63a8\u5e7f\u5230\u5176\u4ed6\u9636\u6bb5\u65f6\u5e38\u5e38\u8868\u73b0\u4e0d\u4f73\u3002\u89e3\u51b3LLM\u521b\u65b0\u6cdb\u5316\u5c40\u9650\uff0c\u662f\u63d0\u5347\u6a21\u578b\u80fd\u529b\u7684\u5173\u952e\u96be\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u6563\uff08scatter-based\uff09\u7684\u521b\u65b0\u6269\u6563\u6a21\u578b\u3002\u8be5\u6a21\u578b\u6307\u5bfcLLM\u6309\u7167\u56db\u6b65\u6d41\u7a0b\uff1a1\uff09\u6bd4\u8f83\u7528\u6237\u8f93\u5165\u548c\u4e0a\u4e0b\u6587\uff0c\u8bc6\u522b\u6838\u5fc3\u521b\u65b0\uff1b2\uff09\u5c06\u521b\u65b0\u53bb\u9664\u7279\u5b9a\u9636\u6bb5\u3001\u7ec4\u4ef6\u7684\u9650\u5b9a\uff0c\u5b9e\u73b0\u6cdb\u5316\uff1b3\uff09\u5224\u65ad\u6cdb\u5316\u540e\u7684\u521b\u65b0\u662f\u5426\u53ef\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u8303\u56f4\uff1b4\uff09\u7528LLM\u7cfb\u7edf\u6027\u5730\u5c06\u521b\u65b0\u5e94\u7528\u5230\u7ed3\u6784\u4e0a\u76f8\u4f3c\u7684\u5176\u4ed6\u9636\u6bb5\u3002\u5229\u7528\u591a\u9636\u6bb5\u7cfb\u7edf\u4e2d\u7684\u7ed3\u6784\u5197\u4f59\uff0c\u63d0\u5347\u521b\u65b0\u6269\u6563\u80fd\u529b\u3002", "result": "\u9a8c\u8bc1\u8868\u660e\uff0c\u521b\u65b0\u6269\u6563\u6a21\u578b\u8ba9LLM\u80fd\u591f\u5c06\u521b\u65b0\u63a8\u5e7f\u5230\u7ed3\u6784\u4e0a\u76f8\u4f3c\u7684\u4e0d\u540c\u9636\u6bb5\uff0c\u5b9e\u73b0\u4e86\u521b\u65b0\u7684\u66f4\u597d\u6cdb\u5316\u548c\u590d\u7528\u3002", "conclusion": "\u521b\u65b0\u6269\u6563\u6a21\u578b\u80fd\u591f\u63d0\u5347LLM\u5c06\u521b\u65b0\u610f\u89c1\u4ece\u5355\u4e00\u9636\u6bb5\u63a8\u5e7f\u6269\u6563\u5230\u591a\u9636\u6bb5\u7ed3\u6784\u4e2d\u7684\u80fd\u529b\uff0c\u4ece\u800c\u6539\u5584\u5176\u6cdb\u5316\u548c\u521b\u65b0\u590d\u7528\u8868\u73b0\u3002"}}
{"id": "2506.18428", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.18428", "abs": "https://arxiv.org/abs/2506.18428", "authors": ["Feng He", "Zhenyang Liu", "Marco Valentino", "Zhixue Zhao"], "title": "How Robust is Model Editing after Fine-Tuning? An Empirical Study on Text-to-Image Diffusion Models", "comment": null, "summary": "Model editing offers a low-cost technique to inject or correct a particular\nbehavior in a pre-trained model without extensive retraining, supporting\napplications such as factual correction and bias mitigation. Despite this\ncommon practice, it remains unknown whether edits persist after fine-tuning or\nwhether they are inadvertently reversed. This question has fundamental\npractical implications. For example, if fine-tuning removes prior edits, it\ncould serve as a defence mechanism against hidden malicious edits. Vice versa,\nthe unintended removal of edits related to bias mitigation could pose serious\nsafety concerns. We systematically investigate the interaction between model\nediting and fine-tuning in the context of T2I diffusion models, which are known\nto exhibit biases and generate inappropriate content. Our study spans two T2I\nmodel families (Stable Diffusion and FLUX), two sota editing techniques, and\nthree fine-tuning methods (DreamBooth, LoRA, and DoRA). Through an extensive\nempirical analysis across diverse editing tasks and evaluation metrics, our\nfindings reveal a trend: edits generally fail to persist through fine-tuning,\neven when fine-tuning is tangential or unrelated to the edits. Notably, we\nobserve that DoRA exhibits the strongest edit reversal effect. At the same\ntime, among editing methods, UCE demonstrates greater robustness, retaining\nsignificantly higher efficacy post-fine-tuning compared to ReFACT. These\nfindings highlight a crucial limitation in current editing methodologies,\nemphasizing the need for more robust techniques to ensure reliable long-term\ncontrol and alignment of deployed AI systems. These findings have dual\nimplications for AI safety: they suggest that fine-tuning could serve as a\nremediation mechanism for malicious edits while simultaneously highlighting the\nneed for re-editing after fine-tuning to maintain beneficial safety and\nalignment properties.", "AI": {"tldr": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u6a21\u578b\u7f16\u8f91\u5f88\u96be\u5728\u540e\u7eed\u7684\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u6301\u4e45\u4fdd\u5b58\uff0c\u5c24\u5176\u662fDoRA\u5fae\u8c03\u4f1a\u5927\u5e45\u9006\u8f6c\u7f16\u8f91\u3002UCE\u7f16\u8f91\u65b9\u6cd5\u5728\u5fae\u8c03\u540e\u66f4\u7a33\u5065\u3002\u5fae\u8c03\u65e2\u53ef\u4f5c\u4e3a\u6d88\u9664\u6076\u610f\u7f16\u8f91\u7684\u624b\u6bb5\uff0c\u4e5f\u63d0\u793a\u5927\u5bb6\uff0c\u60f3\u4fdd\u7559\u6b63\u5411\u7f16\u8f91\u9700\u5728\u5fae\u8c03\u540e\u91cd\u65b0\u5904\u7406\u3002", "motivation": "\u6a21\u578b\u7f16\u8f91\u80fd\u591f\u4ee5\u8f83\u4f4e\u7684\u6210\u672c\u4fee\u6b63\u6216\u6ce8\u5165\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u7279\u5b9a\u884c\u4e3a\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u4e8b\u5b9e\u4fee\u6b63\u548c\u504f\u89c1\u7f13\u89e3\u7b49\u573a\u666f\u3002\u4f46\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u4fee\u6539\u5728\u4e4b\u540e\u7684\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u80fd\u5426\u4fdd\u5b58\u4e0b\u6765\uff0c\u6216\u8005\u4f1a\u4e0d\u4f1a\u88ab\u5fae\u8c03\u610f\u5916\u5730\u9006\u8f6c\u3002\u8fd9\u4e2a\u95ee\u9898\u76f4\u63a5\u5f71\u54cd\u6a21\u578b\u5b89\u5168\u4e0e\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u4e86\u6a21\u578b\u7f16\u8f91\u4e0e\u5fae\u8c03\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u805a\u7126\u4e8e\u6587\u672c\u5230\u56fe\u50cf\uff08T2I\uff09\u6269\u6563\u6a21\u578b\u3002\u5b9e\u9a8c\u8986\u76d6Stable Diffusion\u548cFLUX\u4e24\u4e2a\u6a21\u578b\u7cfb\u5217\uff0c\u91c7\u7528\u4e86\u4e24\u79cd\u6700\u65b0\u6a21\u578b\u7f16\u8f91\u6280\u672f\uff08\u5982UCE\u548cReFACT\uff09\u4ee5\u53ca\u4e09\u79cd\u4e3b\u6d41\u5fae\u8c03\u65b9\u6cd5\uff08DreamBooth, LoRA, DoRA\uff09\u3002\u901a\u8fc7\u5927\u91cf\u5b9e\u8bc1\u5206\u6790\uff0c\u5bf9\u5404\u79cd\u7f16\u8f91\u4efb\u52a1\u548c\u8bc4\u4f30\u6307\u6807\u8fdb\u884c\u4e86\u7ec6\u81f4\u5bf9\u6bd4\u3002", "result": "\u5927\u591a\u6570\u6a21\u578b\u7f16\u8f91\u5728\u5fae\u8c03\u540e\u65e0\u6cd5\u4fdd\u6301\u539f\u6709\u6548\u679c\uff0c\u5373\u4f7f\u662f\u4e0e\u7f16\u8f91\u76ee\u6807\u65e0\u5173\u7684\u5fae\u8c03\u4e5f\u5bb9\u6613\u9006\u8f6c\u7f16\u8f91\u3002\u5176\u4e2d\uff0cDoRA\u5fae\u8c03\u5bf9\u7f16\u8f91\u7684\u9006\u8f6c\u4f5c\u7528\u6700\u5f3a\u3002\u5728\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u4e2d\uff0cUCE\u6bd4ReFACT\u5728\u5fae\u8c03\u540e\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7a33\u5065\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u73b0\u6709\u7684\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u5b9e\u73b0\u7f16\u8f91\u6548\u679c\u7684\u957f\u671f\u4fdd\u6301\u3002\u56e0\u6b64\uff0c\u672a\u6765\u9700\u53d1\u5c55\u66f4\u5065\u58ee\u7684\u6a21\u578b\u7f16\u8f91\u6280\u672f\uff0c\u4ee5\u786e\u4fddAI\u7cfb\u7edf\u7684\u5b89\u5168\u3001\u957f\u671f\u53ef\u63a7\u4e0e\u5bf9\u9f50\u3002\u5bf9AI\u5b89\u5168\u7684\u53cc\u91cd\u542f\u793a\u662f\uff1a\u5fae\u8c03\u53ef\u51cf\u5c11\u6076\u610f\u7f16\u8f91\u98ce\u9669\uff0c\u4f46\u5bf9\u4e8e\u5b89\u5168\u548c\u5bf9\u9f50\u7c7b\u6709\u76ca\u7f16\u8f91\uff0c\u9700\u5728\u5fae\u8c03\u540e\u91cd\u65b0\u7f16\u8f91\u3002"}}
{"id": "2506.17951", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17951", "abs": "https://arxiv.org/abs/2506.17951", "authors": ["Quanwei Tang", "Sophia Yat Mei Lee", "Junshuang Wu", "Dong Zhang", "Shoushan Li", "Erik Cambria", "Guodong Zhou"], "title": "A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment", "comment": "acl 2025 findings", "summary": "Recent advancements in retrieval-augmented generation (RAG) have enhanced\nlarge language models in question answering by integrating external knowledge.\nHowever, challenges persist in achieving global understanding and aligning\nresponses with human ethical and quality preferences. To address these issues,\nwe propose GraphMPA, a comprehensive graph-based framework with mode-seeking\npreference alignment. Our approach constructs a hierarchical document graph\nusing a general similarity measurement, mimicking human cognitive processes for\ninformation understanding and synthesis. Additionally, we introduce\nmode-seeking preference optimization to better align model outputs with human\npreferences through probability-matching constraints. Extensive experiments on\nsix datasets demonstrate the effectiveness of our\n\\href{https://github.com/tangquanwei/GraphMPA}{GraphMPA}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGraphMPA\uff0c\u901a\u8fc7\u56fe\u7ed3\u6784\u6a21\u62df\u4eba\u7c7b\u4fe1\u606f\u6574\u5408\u8fc7\u7a0b\u5e76\u52a0\u5165\u504f\u597d\u4f18\u5316\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u95ee\u7b54\u7cfb\u7edf\u7684\u5168\u5c40\u7406\u89e3\u548c\u4eba\u7c7b\u5bf9\u9f50\u6c34\u5e73\uff0c\u5728\u591a\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u6548\u679c\u7a81\u51fa\u3002", "motivation": "\u5c3d\u7ba1\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4f46\u6a21\u578b\u5728\u5b9e\u73b0\u5168\u5c40\u7406\u89e3\u548c\u5bf9\u9f50\u4eba\u7c7b\u4f26\u7406\u53ca\u8d28\u91cf\u504f\u597d\u65b9\u9762\u4f9d\u7136\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7efc\u5408\u6027\u57fa\u4e8e\u56fe\u7684\u6846\u67b6GraphMPA\uff0c\u5e76\u914d\u5408\u6a21\u5f0f\u5bfb\u4f18\u504f\u597d\u5bf9\u9f50\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e00\u822c\u76f8\u4f3c\u6027\u5ea6\u91cf\u6784\u5efa\u5206\u5c42\u6587\u6863\u56fe\uff0c\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u8fdb\u884c\u4fe1\u606f\u7406\u89e3\u4e0e\u7efc\u5408\uff0c\u5e76\u5f15\u5165\u6982\u7387\u5339\u914d\u7ea6\u675f\u4ee5\u4f18\u5316\u6a21\u578b\u8f93\u51fa\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u3002", "result": "\u5728\u516d\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86GraphMPA\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "GraphMPA\u6846\u67b6\u80fd\u591f\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5168\u5c40\u7406\u89e3\u80fd\u529b\u4e0e\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u8868\u73b0\uff0c\u4e3a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4efb\u52a1\u5e26\u6765\u66f4\u4f18\u7684\u7b54\u6848\u8d28\u91cf\u548c\u4f26\u7406\u5bf9\u9f50\u6548\u679c\u3002"}}
{"id": "2506.18511", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18511", "abs": "https://arxiv.org/abs/2506.18511", "authors": ["Yu Han", "Aaron Ceross", "Jeroen H. M. Bergmann"], "title": "Standard Applicability Judgment and Cross-jurisdictional Reasoning: A RAG-based Framework for Medical Device Compliance", "comment": null, "summary": "Identifying the appropriate regulatory standard applicability remains a\ncritical yet understudied challenge in medical device compliance, frequently\nnecessitating expert interpretation of fragmented and heterogeneous\ndocumentation across different jurisdictions. To address this challenge, we\nintroduce a modular AI system that leverages a retrieval-augmented generation\n(RAG) pipeline to automate standard applicability determination. Given a\nfree-text device description, our system retrieves candidate standards from a\ncurated corpus and uses large language models to infer jurisdiction-specific\napplicability, classified as Mandatory, Recommended, or Not Applicable, with\ntraceable justifications. We construct an international benchmark dataset of\nmedical device descriptions with expert-annotated standard mappings, and\nevaluate our system against retrieval-only, zero-shot, and rule-based\nbaselines. The proposed approach attains a classification accuracy of 73% and a\nTop-5 retrieval recall of 87%, demonstrating its effectiveness in identifying\nrelevant regulatory standards. We introduce the first end-to-end system for\nstandard applicability reasoning, enabling scalable and interpretable\nAI-supported regulatory science. Notably, our region-aware RAG agent performs\ncross-jurisdictional reasoning between Chinese and U.S. standards, supporting\nconflict resolution and applicability justification across regulatory\nframeworks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u68c0\u7d22\u548c\u5927\u6a21\u578b\u63a8\u7406\u7684AI\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u533b\u7597\u5668\u68b0\u6cd5\u89c4\u6807\u51c6\u9002\u7528\u6027\u7684\u81ea\u52a8\u5224\u65ad\uff0c\u5728\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u652f\u6301\u8de8\u4e2d\u7f8e\u6807\u51c6\u7684\u590d\u6742\u6cd5\u89c4\u9002\u7528\u63a8\u7406\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u6cd5\u89c4\u5408\u89c4\u81ea\u52a8\u5316\u5e26\u6765\u65b0\u5de5\u5177\u3002", "motivation": "\u533b\u7597\u5668\u68b0\u7684\u6cd5\u89c4\u5408\u89c4\u4e2d\uff0c\u5982\u4f55\u51c6\u786e\u5224\u65ad\u9002\u7528\u7684\u6cd5\u89c4\u6807\u51c6\u662f\u4e00\u9879\u5173\u952e\u4e14\u5c1a\u672a\u5145\u5206\u7814\u7a76\u7684\u6311\u6218\uff0c\u5e38\u5e38\u9700\u8981\u4e13\u5bb6\u5bf9\u4e0d\u540c\u53f8\u6cd5\u8f96\u533a\u5185\u5206\u6563\u3001\u4e0d\u4e00\u81f4\u7684\u6587\u6863\u8fdb\u884c\u89e3\u8bfb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u6a21\u5757\u5316AI\u7cfb\u7edf\uff0c\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6d41\u7a0b\u3002\u8be5\u7cfb\u7edf\u9488\u5bf9\u81ea\u7531\u6587\u672c\u63cf\u8ff0\u7684\u533b\u7597\u5668\u68b0\uff0c\u4ece\u6574\u7406\u7684\u6cd5\u89c4\u6807\u51c6\u8bed\u6599\u5e93\u4e2d\u68c0\u7d22\u5019\u9009\u6807\u51c6\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5404\u53f8\u6cd5\u8f96\u533a\u5185\u7684\u9002\u7528\u6027\uff0c\u5206\u7c7b\u4e3a\u5f3a\u5236\u3001\u63a8\u8350\u6216\u4e0d\u9002\u7528\uff0c\u5e76\u7ed9\u51fa\u53ef\u8ffd\u6eaf\u7684\u7406\u7531\u3002\u540c\u65f6\uff0c\u6784\u5efa\u4e86\u5e26\u6709\u4e13\u5bb6\u6807\u6ce8\u6807\u51c6\u6620\u5c04\u7684\u56fd\u9645\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u4e0e\u4ec5\u68c0\u7d22\u3001\u96f6\u6837\u672c\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u7cfb\u7edf\u4ee573%\u7684\u9002\u7528\u6027\u5206\u7c7b\u51c6\u786e\u7387\u548c87%\u7684Top-5\u68c0\u7d22\u53ec\u56de\u7387\uff0c\u6709\u6548\u8bc6\u522b\u76f8\u5173\u6cd5\u89c4\u6807\u51c6\u3002\u7cfb\u7edf\u8fd8\u80fd\u8fdb\u884c\u8de8\u4e2d\u7f8e\u6807\u51c6\u7684\u8de8\u8f96\u533a\u63a8\u7406\uff0c\u652f\u6301\u51b2\u7a81\u89e3\u51b3\u4e0e\u9002\u7528\u6027\u89e3\u91ca\u3002", "conclusion": "\u9996\u6b21\u5b9e\u73b0\u6cd5\u89c4\u6807\u51c6\u9002\u7528\u6027\u63a8\u7406\u7684\u7aef\u5230\u7aefAI\u7cfb\u7edf\uff0c\u4e3a\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u7684AI\u652f\u6301\u578b\u6cd5\u89c4\u79d1\u5b66\u5e26\u6765\u7a81\u7834\uff0c\u5e76\u5b9e\u73b0\u8de8\u5730\u533a\u6cd5\u89c4\u534f\u540c\u3002"}}
{"id": "2506.18027", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18027", "abs": "https://arxiv.org/abs/2506.18027", "authors": ["Thi Thu Uyen Hoang", "Viet Anh Nguyen"], "title": "PDF Retrieval Augmented Question Answering", "comment": null, "summary": "This paper presents an advancement in Question-Answering (QA) systems using a\nRetrieval Augmented Generation (RAG) framework to enhance information\nextraction from PDF files. Recognizing the richness and diversity of data\nwithin PDFs--including text, images, vector diagrams, graphs, and tables--poses\nunique challenges for existing QA systems primarily designed for textual\ncontent. We seek to develop a comprehensive RAG-based QA system that will\neffectively address complex multimodal questions, where several data types are\ncombined in the query. This is mainly achieved by refining approaches to\nprocessing and integrating non-textual elements in PDFs into the RAG framework\nto derive precise and relevant answers, as well as fine-tuning large language\nmodels to better adapt to our system. We provide an in-depth experimental\nevaluation of our solution, demonstrating its capability to extract accurate\ninformation that can be applied to different types of content across PDFs. This\nwork not only pushes the boundaries of retrieval-augmented QA systems but also\nlays a foundation for further research in multimodal data integration and\nprocessing.", "AI": {"tldr": "\u4f5c\u8005\u57fa\u4e8eRAG\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u652f\u6301PDF\u591a\u6a21\u6001\u5185\u5bb9\uff08\u5982\u56fe\u7247\u3001\u8868\u683c\u7b49\uff09\u95ee\u7b54\u7684\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u6539\u8fdb\u6a21\u578b\u548c\u96c6\u6210\u6280\u672f\u5728\u5b9e\u9a8c\u4e2d\u83b7\u5f97\u4e86\u826f\u597d\u6548\u679c\u3002\u8be5\u5de5\u4f5c\u4e3a\u591a\u6a21\u6001\u6570\u636e\u95ee\u7b54\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u76ee\u524d\u5927\u591a\u6570\u95ee\u7b54\u7cfb\u7edf\u4ec5\u9488\u5bf9\u6587\u672c\u6570\u636e\u8bbe\u8ba1\uff0c\u800cPDF\u4e2d\u5bcc\u542b\u6587\u672c\u3001\u56fe\u7247\u3001\u8868\u683c\u3001\u56fe\u8868\u7b49\u591a\u79cd\u7c7b\u578b\u5185\u5bb9\uff0c\u5982\u4f55\u5904\u7406\u8fd9\u4e9b\u591a\u6a21\u6001\u6570\u636e\u5e76\u8fdb\u884c\u6709\u6548\u95ee\u7b54\u6781\u5177\u6311\u6218\u6027\u3002", "method": "\u672c\u7814\u7a76\u57fa\u4e8eRAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u6846\u67b6\uff0c\u4e13\u6ce8\u4e8e\u6539\u8fdb\u5bf9PDF\u6587\u4ef6\u4e2d\u7684\u975e\u6587\u672c\u5143\u7d20\u7684\u5904\u7406\u4e0e\u96c6\u6210\uff0c\u5e76\u901a\u8fc7\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u9488\u5bf9\u6027\u7684\u5fae\u8c03\uff0c\u4ee5\u66f4\u597d\u5730\u9002\u5e94\u591a\u6a21\u6001\u95ee\u7b54\u7684\u573a\u666f\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u6240\u63d0\u51fa\u7cfb\u7edf\u5728\u5904\u7406PDF\u591a\u79cd\u5185\u5bb9\u7c7b\u578b\u65f6\uff0c\u80fd\u591f\u51c6\u786e\u63d0\u53d6\u4fe1\u606f\uff0c\u5bf9\u590d\u6742\u591a\u6a21\u6001\u95ee\u9898\u4e5f\u80fd\u7ed9\u51fa\u6709\u6548\u7b54\u6848\uff0c\u8868\u73b0\u51fa\u8f83\u5f3a\u7684\u9002\u5e94\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u672c\u6587\u63a8\u52a8\u4e86\u68c0\u7d22\u589e\u5f3a\u578b\u95ee\u7b54\u7cfb\u7edf\u5728\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u4e0e\u5904\u7406\u65b9\u9762\u7684\u53d1\u5c55\uff0c\u4e3a\u672a\u6765\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\u548c\u65b0\u601d\u8def\u3002"}}
{"id": "2506.18538", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.18538", "abs": "https://arxiv.org/abs/2506.18538", "authors": ["Rifat Ara Shams", "Didar Zowghi", "Muneera Bano"], "title": "A Question Bank to Assess AI Inclusivity: Mapping out the Journey from Diversity Errors to Inclusion Excellence", "comment": null, "summary": "Ensuring diversity and inclusion (D&I) in artificial intelligence (AI) is\ncrucial for mitigating biases and promoting equitable decision-making. However,\nexisting AI risk assessment frameworks often overlook inclusivity, lacking\nstandardized tools to measure an AI system's alignment with D&I principles.\nThis paper introduces a structured AI inclusivity question bank, a\ncomprehensive set of 253 questions designed to evaluate AI inclusivity across\nfive pillars: Humans, Data, Process, System, and Governance. The development of\nthe question bank involved an iterative, multi-source approach, incorporating\ninsights from literature reviews, D&I guidelines, Responsible AI frameworks,\nand a simulated user study. The simulated evaluation, conducted with 70\nAI-generated personas related to different AI jobs, assessed the question\nbank's relevance and effectiveness for AI inclusivity across diverse roles and\napplication domains. The findings highlight the importance of integrating D&I\nprinciples into AI development workflows and governance structures. The\nquestion bank provides an actionable tool for researchers, practitioners, and\npolicymakers to systematically assess and enhance the inclusivity of AI\nsystems, paving the way for more equitable and responsible AI technologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa253\u95eeAI\u5305\u5bb9\u6027\u95ee\u9898\u5e93\uff0c\u4e3aAI\u5305\u5bb9\u6027\u8bc4\u4f30\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8AI\u516c\u5e73\u3001\u5305\u5bb9\u4e0e\u8d1f\u8d23\u4efb\u53d1\u5c55\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u7ecf\u5e38\u5ffd\u89c6\u591a\u6837\u6027\u4e0e\u5305\u5bb9\u6027\uff08D&I\uff09\u539f\u5219\uff0c\u7f3a\u4e4f\u8861\u91cfAI\u7cfb\u7edf\u5305\u5bb9\u6027\u6807\u51c6\u5316\u5de5\u5177\uff0c\u53ef\u80fd\u5bfc\u81f4\u504f\u89c1\u4e0e\u4e0d\u516c\u51b3\u7b56\u3002", "method": "\u4f5c\u8005\u4ee5\u8fed\u4ee3\u3001\u591a\u4fe1\u606f\u6e90\u65b9\u6cd5\uff0c\u7ed3\u5408\u6587\u732e\u56de\u987e\u3001\u591a\u6837\u6027\u548c\u5305\u5bb9\u6027\u6307\u5bfc\u65b9\u9488\u3001\u8d1f\u8d23\u4efb\u7684AI\u6846\u67b6\u4ee5\u53ca\u6a21\u62df\u7528\u6237\u7814\u7a76\uff0c\u5f00\u53d1\u51fa253\u4e2a\u95ee\u9898\u7ec4\u6210\u7684AI\u5305\u5bb9\u6027\u95ee\u9898\u5e93\uff0c\u8986\u76d6\u201c\u4eba\u3001\u6570\u636e\u3001\u6d41\u7a0b\u3001\u7cfb\u7edf\u3001\u6cbb\u7406\u201d\u4e94\u5927\u7ef4\u5ea6\u3002\u901a\u8fc7\u4e0e70\u4e2a\u6a21\u62dfAI\u76f8\u5173\u5c97\u4f4d\u89d2\u8272\u8fdb\u884c\u8bc4\u6d4b\uff0c\u9a8c\u8bc1\u5176\u76f8\u5173\u6027\u4e0e\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u8bc1\u660e\u4e86D&I\u539f\u5219\u5bf9AI\u5f00\u53d1\u6d41\u7a0b\u4e0e\u6cbb\u7406\u7ed3\u6784\u6574\u5408\u7684\u91cd\u8981\u6027\u3002\u8be5\u95ee\u9898\u5e93\u53ef\u4e3a\u7814\u7a76\u4eba\u5458\u3001\u4ece\u4e1a\u8005\u4e0e\u653f\u7b56\u5236\u5b9a\u8005\uff0c\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e0e\u63d0\u5347AI\u7cfb\u7edf\u5305\u5bb9\u6027\u63d0\u4f9b\u5b9e\u9645\u5de5\u5177\u3002", "conclusion": "\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u5957\u7ed3\u6784\u5316AI\u5305\u5bb9\u6027\u95ee\u9898\u5e93\uff0c\u4e3aAI\u7cfb\u7edf\u5305\u5bb9\u6027\u8bc4\u4f30\u5236\u5b9a\u4e86\u5de5\u5177\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8AI\u9886\u57df\u66f4\u52a0\u516c\u5e73\u3001\u8d1f\u8d23\u4efb\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.18035", "categories": ["cs.CL", "cs.SD", "eess.AS", "68T50 (Primary)", "I.2.7; I.5.4"], "pdf": "https://arxiv.org/pdf/2506.18035", "abs": "https://arxiv.org/abs/2506.18035", "authors": ["Maxence Lasbordes", "Daniele Falavigna", "Alessio Brutti"], "title": "Splitformer: An improved early-exit architecture for automatic speech recognition on edge devices", "comment": "5 pages, 3 Postscript figures", "summary": "The ability to dynamically adjust the computational load of neural models\nduring inference in a resource aware manner is crucial for on-device processing\nscenarios, characterised by limited and time-varying computational resources.\nEarly-exit architectures represent an elegant and effective solution, since\nthey can process the input with a subset of their layers, exiting at\nintermediate branches (the upmost layers are hence removed from the model).\n  From a different perspective, for automatic speech recognition applications\nthere are memory-efficient neural architectures that apply variable frame rate\nanalysis, through downsampling/upsampling operations in the middle layers,\nreducing the overall number of operations and improving significantly the\nperformance on well established benchmarks. One example is the Zipformer.\nHowever, these architectures lack the modularity necessary to inject early-exit\nbranches.\n  With the aim of improving the performance in early-exit models, we propose\nintroducing parallel layers in the architecture that process downsampled\nversions of their inputs. % in conjunction with standard processing layers. We\nshow that in this way the speech recognition performance on standard benchmarks\nsignificantly improve, at the cost of a small increase in the overall number of\nmodel parameters but without affecting the inference time.", "AI": {"tldr": "\u9488\u5bf9\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u573a\u666f\uff0c\u4f5c\u8005\u63d0\u51fa\u5728\u795e\u7ecf\u7f51\u7edc\u65e9\u671f\u9000\u51fa\u6a21\u578b\u4e2d\u589e\u52a0\u5e76\u884c\u4e0b\u91c7\u6837\u5c42\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8bed\u97f3\u8bc6\u522b\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u6a21\u578b\u6548\u7387\u548c\u63a8\u7406\u901f\u5ea6\u7684\u4f18\u5316\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u8bbe\u5907\u7aef\u63a8\u7406\u9762\u4e34\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u4e14\u6ce2\u52a8\u7684\u95ee\u9898\uff0c\u9700\u8981\u6a21\u578b\u5177\u5907\u52a8\u6001\u8c03\u6574\u8ba1\u7b97\u8d1f\u8f7d\u7684\u80fd\u529b\u3002\u65e9\u671f\u9000\u51fa\uff08early-exit\uff09\u67b6\u6784\u901a\u8fc7\u5728\u4e2d\u95f4\u5c42\u63d0\u4f9b\u63d0\u524d\u8f93\u51fa\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u7075\u6d3b\u6027\uff1b\u4f46\u4e00\u4e9b\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u4e2d\u7684\u9ad8\u6548\u67b6\u6784\uff0c\u5982Zipformer\uff0c\u5219\u7f3a\u4e4f\u5f15\u5165\u65e9\u671f\u9000\u51fa\u5206\u652f\u6240\u9700\u7684\u6a21\u5757\u5316\u3002\u8bba\u6587\u65e8\u5728\u6539\u8fdb\u65e9\u671f\u9000\u51fa\u6a21\u578b\u7684\u8868\u73b0\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u5728\u65e9\u671f\u9000\u51fa\u6a21\u578b\u4e2d\u5f15\u5165\u5904\u7406\u4e0b\u91c7\u6837\u8f93\u5165\u7684\u5e76\u884c\u5c42\uff0c\u8fd9\u4e9b\u5e76\u884c\u5c42\u4e0e\u6807\u51c6\u5904\u7406\u5c42\u7ed3\u5408\u5de5\u4f5c\uff0c\u63d0\u5347\u6027\u80fd\u3002\u8fd9\u6837\u5728\u4fdd\u6301\u63a8\u7406\u65f6\u95f4\u57fa\u672c\u4e0d\u53d8\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u5185\u5b58\u6548\u7387\u548c\u7075\u6d3b\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6807\u51c6\u8bed\u97f3\u8bc6\u522b\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4ec5\u5e26\u6765\u6781\u5c0f\u7684\u6a21\u578b\u53c2\u6570\u589e\u52a0\uff0c\u540c\u65f6\u63a8\u7406\u65f6\u95f4\u4e0d\u53d7\u5f71\u54cd\u3002", "conclusion": "\u5f15\u5165\u5e76\u884c\u4e0b\u91c7\u6837\u5c42\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u65e9\u671f\u9000\u51fa\u795e\u7ecf\u7f51\u7edc\u5728\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e14\u53ef\u63a7\u7684\u589e\u52a0\u6a21\u578b\u590d\u6742\u5ea6\u548c\u4fdd\u6301\u63a8\u7406\u9ad8\u6548\u6027\u3002"}}
{"id": "2506.18559", "categories": ["cs.AI", "cs.LO", "I.2.7; F.4.1"], "pdf": "https://arxiv.org/pdf/2506.18559", "abs": "https://arxiv.org/abs/2506.18559", "authors": ["Hong Qing Yu"], "title": "T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent", "comment": null, "summary": "Large language models excel at generating fluent text but frequently struggle\nwith structured reasoning involving temporal constraints, causal relationships,\nand probabilistic reasoning. To address these limitations, we propose Temporal\nCausal Probabilistic Description Logic (T-CPDL), an integrated framework that\nextends traditional Description Logic with temporal interval operators,\nexplicit causal relationships, and probabilistic annotations. We present two\ndistinct variants of T-CPDL: one capturing qualitative temporal relationships\nthrough Allen's interval algebra, and another variant enriched with explicit\ntimestamped causal assertions. Both variants share a unified logical structure,\nenabling complex reasoning tasks ranging from simple temporal ordering to\nnuanced probabilistic causation. Empirical evaluations on temporal reasoning\nand causal inference benchmarks confirm that T-CPDL substantially improves\ninference accuracy, interpretability, and confidence calibration of language\nmodel outputs. By delivering transparent reasoning paths and fine-grained\ntemporal and causal semantics, T-CPDL significantly enhances the capability of\nlanguage models to support robust, explainable, and trustworthy\ndecision-making. This work also lays the groundwork for developing advanced\nLogic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentially\nboosting the reasoning capabilities and efficiency of knowledge graph-enhanced\nRAG systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u63cf\u8ff0\u903b\u8f91\u7684\u65b0\u65b9\u6cd5\uff08T-CPDL\uff09\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5177\u5907\u66f4\u5f3a\u7684\u65f6\u5e8f\u3001\u56e0\u679c\u548c\u6982\u7387\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u63a8\u7406\u8868\u73b0\uff0c\u4e3a\u53ef\u4fe1\u8d56\u7684\u63a8\u7406\u548c\u903b\u8f91\u589e\u5f3a\u7684\u68c0\u7d22\u751f\u6210\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u64c5\u957f\u751f\u6210\u6d41\u7545\u6587\u672c\uff0c\u4f46\u5728\u6d89\u53ca\u65f6\u5e8f\u7ea6\u675f\u3001\u56e0\u679c\u5173\u7cfb\u548c\u6982\u7387\u63a8\u7406\u7b49\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u4e3a\u514b\u670d\u8fd9\u4e9b\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f15\u5165\u80fd\u591f\u8868\u8fbe\u5e76\u63a8\u7406\u8fd9\u4e9b\u7ed3\u6784\u5316\u4fe1\u606f\u7684\u65b0\u903b\u8f91\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u5e8f\u56e0\u679c\u6982\u7387\u63cf\u8ff0\u903b\u8f91\uff08T-CPDL\uff09, \u5305\u62ec\u4e24\u4e2a\u7248\u672c\uff1a\u4e00\u4e2a\u91c7\u7528Allen\u65f6\u5e8f\u533a\u95f4\u4ee3\u6570\u6765\u8868\u8fbe\u65f6\u5e8f\u5173\u7cfb\uff0c\u53e6\u4e00\u4e2a\u5229\u7528\u5e26\u65f6\u95f4\u6233\u7684\u56e0\u679c\u65ad\u8a00\u3002\u4e8c\u8005\u5747\u6709\u7edf\u4e00\u7684\u903b\u8f91\u7ed3\u6784\uff0c\u7528\u4e8e\u8868\u793a\u590d\u6742\u7684\u65f6\u5e8f\u3001\u56e0\u679c\u548c\u6982\u7387\u63a8\u7406\u3002\u901a\u8fc7\u5728\u65f6\u5e8f\u63a8\u7406\u548c\u56e0\u679c\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cT-CPDL\u5728\u63a8\u7406\u51c6\u786e\u7387\u3001\u7ed3\u679c\u53ef\u89e3\u91ca\u6027\u4ee5\u53ca\u4fe1\u5fc3\u6821\u51c6\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u589e\u5f3a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0b\u7684\u8868\u73b0\u80fd\u529b\u3002", "conclusion": "T-CPDL\u80fd\u591f\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u5e8f\u3001\u56e0\u679c\u548c\u6982\u7387\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5b9e\u73b0\u66f4\u9ad8\u7684\u63a8\u7406\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u4fe1\u5fc3\u6821\u51c6\uff0c\u4e3a\u53ef\u4fe1\u8d56\u7684\u51b3\u7b56\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002\u8be5\u65b9\u6cd5\u8fd8\u4e3a\u4eca\u540e\u5f00\u53d1\u57fa\u4e8e\u903b\u8f91\u589e\u5f3a\u7684\u68c0\u7d22\u751f\u6210\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.18036", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18036", "abs": "https://arxiv.org/abs/2506.18036", "authors": ["Aziz Amari", "Mohamed Achref Ben Ammar"], "title": "Markov-Enhanced Clustering for Long Document Summarization: Tackling the 'Lost in the Middle' Challenge with Large Language Models", "comment": null, "summary": "The rapid expansion of information from diverse sources has heightened the\nneed for effective automatic text summarization, which condenses documents into\nshorter, coherent texts. Summarization methods generally fall into two\ncategories: extractive, which selects key segments from the original text, and\nabstractive, which generates summaries by rephrasing the content coherently.\nLarge language models have advanced the field of abstractive summarization, but\nthey are resourceintensive and face significant challenges in retaining key\ninformation across lengthy documents, which we call being \"lost in the middle\".\nTo address these issues, we propose a hybrid summarization approach that\ncombines extractive and abstractive techniques. Our method splits the document\ninto smaller text chunks, clusters their vector embeddings, generates a summary\nfor each cluster that represents a key idea in the document, and constructs the\nfinal summary by relying on a Markov chain graph when selecting the semantic\norder of ideas.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u63d0\u53d6\u5f0f\u548c\u751f\u6210\u5f0f\u7684\u6df7\u5408\u81ea\u52a8\u6587\u672c\u6458\u8981\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6bb5\u3001\u805a\u7c7b\u3001\u751f\u6210\u5c40\u90e8\u6458\u8981\u5e76\u5229\u7528\u9a6c\u5c14\u53ef\u592b\u94fe\u6709\u5e8f\u6574\u5408\uff0c\u5b9e\u73b0\u957f\u6587\u6863\u4f18\u8d28\u6458\u8981\uff0c\u89e3\u51b3\u4e86\u957f\u6587\u672c\u4fe1\u606f\u6613\u4e22\u5931\u7684\u96be\u9898\u3002", "motivation": "\u968f\u7740\u4fe1\u606f\u91cf\u7684\u6781\u5927\u589e\u957f\uff0c\u6709\u6548\u7684\u81ea\u52a8\u6587\u672c\u6458\u8981\u9700\u6c42\u589e\u52a0\u3002\u73b0\u6709\u6458\u8981\u65b9\u6cd5\u5b58\u5728\u63d0\u53d6\u5f0f\u548c\u751f\u6210\u5f0f\u4e24\u79cd\uff0c\u7279\u522b\u662f\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u63d0\u5347\u4e86\u751f\u6210\u5f0f\u6458\u8981\u80fd\u529b\uff0c\u4f46\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u5bb9\u6613\u4e22\u5931\u5173\u952e\u4fe1\u606f\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u66f4\u80fd\u4fdd\u7559\u6838\u5fc3\u5185\u5bb9\u7684\u9ad8\u6548\u6458\u8981\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6458\u8981\u65b9\u6cd5\uff0c\u5c06\u63d0\u53d6\u5f0f\u548c\u751f\u6210\u5f0f\u7ed3\u5408\u3002\u5177\u4f53\u505a\u6cd5\u4e3a\uff1a\u5c06\u6587\u6863\u5206\u5272\u4e3a\u5c0f\u7247\u6bb5\uff0c\u5bf9\u5176\u5411\u91cf\u5d4c\u5165\u8fdb\u884c\u805a\u7c7b\uff0c\u4e3a\u6bcf\u4e2a\u805a\u7c7b\u751f\u6210\u4ee3\u8868\u8be5\u90e8\u5206\u6838\u5fc3\u601d\u60f3\u7684\u6458\u8981\uff0c\u6700\u7ec8\u7528\u9a6c\u5c14\u53ef\u592b\u94fe\u56fe\u9009\u62e9\u6458\u8981\u4e2d\u5404\u601d\u60f3\u7684\u8bed\u4e49\u987a\u5e8f\uff0c\u6784\u5efa\u6700\u7ec8\u6458\u8981\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u6574\u5408\u957f\u6587\u6863\u4e2d\u7684\u5173\u952e\u4fe1\u606f\uff0c\u907f\u514d\u201c\u4e22\u5931\u4e2d\u95f4\u5185\u5bb9\u201d\u7684\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u5347\u6458\u8981\u7684\u51c6\u786e\u6027\u4e0e\u8fde\u8d2f\u6027\u3002", "conclusion": "\u6df7\u5408\u6458\u8981\u65b9\u6cd5\u517c\u5177\u63d0\u53d6\u5f0f\u7684\u7cbe\u51c6\u4e0e\u751f\u6210\u5f0f\u7684\u8868\u8fbe\u4f18\u52bf\uff0c\u80fd\u66f4\u6709\u6548\u5e94\u5bf9\u957f\u6587\u6863\u5185\u5bb9\u5206\u6563\u4e0e\u5173\u952e\u4fe1\u606f\u9057\u6f0f\u7684\u96be\u9898\u3002"}}
{"id": "2506.18082", "categories": ["cs.CL", "stat.AP"], "pdf": "https://arxiv.org/pdf/2506.18082", "abs": "https://arxiv.org/abs/2506.18082", "authors": ["Esteban Garces Arias", "Hannah Blocher", "Julian Rodemann", "Matthias A\u00dfenmacher", "Christoph Jansen"], "title": "Statistical Multicriteria Evaluation of LLM-Generated Text", "comment": null, "summary": "Assessing the quality of LLM-generated text remains a fundamental challenge\nin natural language processing. Current evaluation approaches often rely on\nisolated metrics or simplistic aggregations that fail to capture the nuanced\ntrade-offs between coherence, diversity, fluency, and other relevant indicators\nof text quality. In this work, we adapt a recently proposed framework for\nstatistical inference based on Generalized Stochastic Dominance (GSD) that\naddresses three critical limitations in existing benchmarking methodologies:\nthe inadequacy of single-metric evaluation, the incompatibility between\ncardinal automatic metrics and ordinal human judgments, and the lack of\ninferential statistical guarantees. The GSD-front approach enables simultaneous\nevaluation across multiple quality dimensions while respecting their different\nmeasurement scales, building upon partial orders of decoding strategies, thus\navoiding arbitrary weighting of the involved metrics. By applying this\nframework to evaluate common decoding strategies against human-generated text,\nwe demonstrate its ability to identify statistically significant performance\ndifferences while accounting for potential deviations from the i.i.d.\nassumption of the sampling design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u8bc1\u4e86\u4e00\u79cd\u57fa\u4e8eGSD\u7684\u591a\u7ef4\u5ea6\u6587\u672c\u751f\u6210\u8d28\u91cf\u8bc4\u4ef7\u6846\u67b6\uff0c\u80fd\u591f\u79d1\u5b66\u517c\u5bb9\u591a\u6307\u6807\u548c\u6d4b\u91cf\u5c3a\u5ea6\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u7edf\u8ba1\u63a8\u65ad\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4ef7\u65b9\u6cd5\u7684\u4e3b\u8981\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u6587\u672c\u8d28\u91cf\u7684\u8bc4\u4ef7\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u5355\u4e00\u6307\u6807\u6216\u7b80\u5355\u6c47\u603b\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u6587\u672c\u591a\u7ef4\u5ea6\u7684\u8d28\u91cf\uff08\u5982\u8fde\u8d2f\u6027\u3001\u591a\u6837\u6027\u3001\u6d41\u7545\u6027\u7b49\uff09\u4e4b\u95f4\u7684\u6743\u8861\u3002\u540c\u65f6\uff0c\u81ea\u52a8\u8bc4\u5206\u65b9\u6cd5\u4e0e\u4eba\u5de5\u8bc4\u5224\u7684\u5ea6\u91cf\u65b9\u5f0f\u548c\u5c3a\u5ea6\u5e38\u5e38\u4e0d\u4e00\u81f4\uff0c\u4e14\u7f3a\u4e4f\u7edf\u8ba1\u63a8\u65ad\u4fdd\u8bc1\u3002", "method": "\u672c\u6587\u91c7\u7528\u57fa\u4e8e\u5e7f\u4e49\u968f\u673a\u4f18\u52bf\uff08GSD\uff09\u7684\u7edf\u8ba1\u63a8\u65ad\u6846\u67b6\uff0c\u4ee5\u591a\u5143\u3001\u5206\u5c42\u6b21\u7684\u65b9\u5f0f\u7efc\u5408\u8bc4\u4f30\u751f\u6210\u6587\u672c\u7684\u591a\u79cd\u8d28\u91cf\u7ef4\u5ea6\uff0c\u517c\u5bb9\u4e0d\u540c\u7684\u5ea6\u91cf\u5c3a\u5ea6\uff0c\u907f\u514d\u5bf9\u5404\u6307\u6807\u4f5c\u51fa\u4e3b\u89c2\u52a0\u6743\uff0c\u652f\u6301\u66f4\u79d1\u5b66\u7684\u63a8\u65ad\u5206\u6790\u3002", "result": "\u901a\u8fc7\u8be5\u6846\u67b6\uff0c\u5bf9\u5e38\u89c1\u7684\u6587\u672c\u751f\u6210\u89e3\u7801\u7b56\u7565\u4e0e\u4eba\u5de5\u751f\u6210\u6587\u672c\u8fdb\u884c\u8861\u91cf\uff0c\u53ef\u4ee5\u63ed\u793a\u591a\u7ef4\u8d28\u91cf\u4e0a\u7684\u663e\u8457\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u5b9e\u73b0\u7edf\u8ba1\u663e\u8457\u6027\u7684\u4fdd\u8bc1\uff0c\u4e14\u80fd\u591f\u5e94\u5bf9\u91c7\u6837\u8bbe\u8ba1\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-i.i.d.\uff09\u60c5\u51b5\u3002", "conclusion": "GSD-front\u8bc4\u4f30\u6846\u67b6\u7a81\u7834\u4e86\u73b0\u6709\u7684\u5355\u6307\u6807\u548c\u4eba\u4e3a\u6743\u91cd\u8bbe\u5b9a\u5c40\u9650\uff0c\u80fd\u5b9e\u73b0\u591a\u7ef4\u5ea6\u3001\u53ef\u9760\u4e14\u7edf\u8ba1\u663e\u8457\u7684LLM\u6587\u672c\u8d28\u91cf\u5224\u522b\uff0c\u4e3a\u672a\u6765\u76f8\u5173\u6587\u672c\u751f\u6210\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u79d1\u5b66\u548c\u5b9e\u7528\u7684\u65b9\u6cd5\u3002"}}
