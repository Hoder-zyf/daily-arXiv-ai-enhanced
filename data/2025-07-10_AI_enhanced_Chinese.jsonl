{"id": "2507.06345", "categories": ["q-fin.TR", "q-fin.CP", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2507.06345", "abs": "https://arxiv.org/abs/2507.06345", "authors": ["Patrick Cheridito", "Moritz Weiss"], "title": "Reinforcement Learning for Trade Execution with Market Impact", "comment": null, "summary": "In this paper, we introduce a novel reinforcement learning framework for\noptimal trade execution in a limit order book. We formulate the trade execution\nproblem as a dynamic allocation task whose objective is the optimal placement\nof market and limit orders to maximize expected revenue. By employing\nmultivariate logistic-normal distributions to model random allocations, the\nframework enables efficient training of the reinforcement learning algorithm.\nNumerical experiments show that the proposed method outperforms traditional\nbenchmark strategies in simulated limit order book environments featuring noise\ntraders submitting random orders, tactical traders responding to order book\nimbalances, and a strategic trader seeking to acquire or liquidate an asset\nposition.", "AI": {"tldr": "\u63d0\u51fa\u5f3a\u5316\u5b66\u4e60\u65b0\u65b9\u6cd5\u4f18\u5316\u9650\u4ef7\u8ba2\u5355\u7c3f\u4e2d\u7684\u4ea4\u6613\u6267\u884c\uff0c\u6536\u76ca\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u8fd1\u5e74\u6765\u7b97\u6cd5\u4ea4\u6613\u5bf9\u6700\u4f73\u4ea4\u6613\u6267\u884c\u95ee\u9898\u7684\u5173\u6ce8\u5ea6\u6301\u7eed\u4e0a\u5347\uff0c\u5982\u4f55\u5728\u9650\u4ef7\u8ba2\u5355\u7c3f\u73af\u5883\u4e0b\u9ad8\u6548\u4e0b\u5355\uff0c\u4ee5\u63d0\u5347\u6536\u76ca\u6210\u4e3a\u91cd\u8981\u7814\u7a76\u65b9\u5411\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u4ea4\u6613\u6267\u884c\u95ee\u9898\u5efa\u6a21\u4e3a\u52a8\u6001\u5206\u914d\u4efb\u52a1\uff0c\u7ed3\u5408\u591a\u53d8\u91cflogistic-normal\u5206\u5e03\u6a21\u62df\u968f\u673a\u5206\u914d\uff0c\u4ee5\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u8bad\u7ec3\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5305\u542b\u968f\u673a\u4ea4\u6613\u8005\u3001\u6218\u672f\u4ea4\u6613\u8005\u548c\u6218\u7565\u4ea4\u6613\u8005\u7b49\u591a\u4e3b\u4f53\u590d\u6742\u4eff\u771f\u73af\u5883\u4e0b\uff0c\u4f18\u4e8e\u4f20\u7edf\u57fa\u51c6\u7b56\u7565\u3002", "conclusion": "\u672c\u6587\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u9650\u4ef7\u8ba2\u5355\u7c3f\u73af\u5883\u4e0b\u4ea4\u6613\u6267\u884c\u7684\u8868\u73b0\u548c\u6536\u76ca\uff0c\u6709\u671b\u4e3a\u5b9e\u9645\u4ea4\u6613\u7cfb\u7edf\u5e26\u6765\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.06351", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2507.06351", "abs": "https://arxiv.org/abs/2507.06351", "authors": ["Dhairya Parekh", "Mark L. Franz Ph. D", "Sara Zahedian Ph. D", "Narjes Shayesteh"], "title": "Development and Real-World Application of Commercial Motor Vehicle Safety Enforcement Dashboards", "comment": "Presented at Transportation Research Board Annual Meeting 2025.\n  Presentation number: TRBAM-25-04350", "summary": "Commercial Motor Vehicle (CMV) safety is crucial in traffic management and\npublic safety. CMVs account for numerous traffic incidents, so monitoring CMV\nsafety and safety inspections is essential for ensuring safe and efficient\nhighway movement. This paper presents the development and real-world\napplication of CMV dashboards designed under the guidance of CMV safety\nenforcement professionals from the Maryland State Police (MSP), the Maryland\nDepartment of Transportation - State Highway Administration (MDOT - SHA), and\nthe Federal Motor Carrier Safety Administration (FMCSA) to enable intuitive and\nefficient analysis of CMV safety performance measures. First, three CMV safety\ndashboards enable CMV safety professionals to identify sites with a history of\nsafety performance issues. A supplemental dashboard automates the analysis of\nCMV enforcement initiatives using the same performance measures. These\nperformance measures are based on CMV probe vehicle speeds, inspection/citation\ndata from Truck Weigh and Inspection Stations (TWIS), patrolling enforcement,\nand Virtual Weigh Stations (VWS). The authors collaborated with MSP to identify\na portion of I-81 in Maryland, susceptible to improvement from targeted CMV\nenforcement. The supplemental enforcement assessment dashboard was employed to\nevaluate the impact of enforcement, including the post-enforcement halo effect.\nThe results of the post-enforcement evaluation were mixed, indicating a need\nfor more fine-grained citation data.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u5e76\u5e94\u7528\u4e86\u8fd0\u8f93\u6267\u6cd5\u4eba\u5458\u6307\u5bfc\u4e0b\u7684\u5546\u7528\u8f66\u8f86\u5b89\u5168\u4eea\u8868\u677f\uff0c\u5e2e\u52a9\u8bc6\u522b\u548c\u5206\u6790\u5b89\u5168\u9690\u60a3\u53ca\u6267\u6cd5\u6210\u6548\u3002\u5b9e\u8bc1\u6848\u4f8b\u663e\u793a\u5de5\u5177\u6709\u6548\u4f46\u8bc4\u4f30\u7ed3\u679c\u5dee\u5f02\u8f83\u5927\uff0c\u672a\u6765\u9700\u66f4\u7ec6\u81f4\u7684\u6570\u636e\u63d0\u5347\u6267\u6cd5\u8bc4\u4f30\u7cbe\u5ea6\u3002", "motivation": "\u5546\u7528\u673a\u52a8\u8f66\u8f86\uff08CMV\uff09\u5b89\u5168\u5bf9\u4e8e\u4ea4\u901a\u7ba1\u7406\u548c\u516c\u5171\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002\u7531\u4e8eCMV\u6d89\u53ca\u5927\u91cf\u4ea4\u901a\u4e8b\u6545\uff0c\u56e0\u6b64\u5bf9\u5176\u5b89\u5168\u53ca\u5b89\u68c0\u7684\u9ad8\u6548\u76d1\u6d4b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u672c\u6587\u5728\u9a6c\u91cc\u5170\u5dde\u8b66\u5bdf\u5c40\uff08MSP\uff09\u3001\u8fd0\u8f93\u7f72\u516c\u8def\u7ba1\u7406\u5c40\uff08MDOT-SHA\uff09\u53ca\u8054\u90a6\u6c7d\u8f66\u8fd0\u8f93\u5b89\u5168\u7ba1\u7406\u5c40\uff08FMCSA\uff09\u7684\u4e13\u4e1a\u6307\u5bfc\u4e0b\uff0c\u5f00\u53d1\u51fa\u80fd\u591f\u76f4\u89c2\u3001\u9ad8\u6548\u5206\u6790CMV\u5b89\u5168\u7ee9\u6548\u7684\u4eea\u8868\u677f\u5de5\u5177\u3002\u7814\u7a76\u91c7\u7528\u4e86CMV\u8f66\u8f86\u901f\u5ea6\u3001\u68c0\u67e5/\u5904\u7f5a\u6570\u636e\u3001\u5de1\u67e5\u6267\u6cd5\u53ca\u865a\u62df\u79f0\u91cd\u7ad9\u7b49\u591a\u7ef4\u6570\u636e\u3002\u5e76\u4ee5I-81\u516c\u8def\u7684\u4e00\u6bb5\u4e3a\u6848\u4f8b\uff0c\u914d\u5408MSP\u5b9e\u9645\u5408\u4f5c\uff0c\u8bc4\u4f30\u4e86\u5b9a\u5411\u6267\u6cd5\u5bf9\u63d0\u5347\u5b89\u5168\u7684\u5f71\u54cd\u3002", "result": "\u5229\u7528\u5f00\u53d1\u7684\u4eea\u8868\u677f\u5de5\u5177\uff0cCMV\u5b89\u5168\u4e13\u4e1a\u4eba\u5458\u53ef\u4ee5\u5feb\u901f\u8bc6\u522b\u5b58\u5728\u5b89\u5168\u9690\u60a3\u7684\u5730\u70b9\uff0c\u5e76\u81ea\u52a8\u5206\u6790\u6267\u6cd5\u884c\u52a8\u5e26\u6765\u7684\u6210\u6548\u3002\u6267\u6cd5\u884c\u52a8\u540e\u7684\u5b89\u5168\u8bc4\u4f30\u7ed3\u679c\u51fa\u73b0\u4e86\u597d\u574f\u53c2\u534a\u7684\u60c5\u51b5\uff0c\u8868\u660e\u9700\u8981\u66f4\u8be6\u7ec6\u7684\u5904\u7f5a\u6570\u636e\u4ee5\u652f\u6301\u66f4\u6df1\u5165\u7684\u5206\u6790\u3002", "conclusion": "\u672c\u6587\u8bbe\u8ba1\u5e76\u5b9e\u9645\u5e94\u7528\u4e86CMV\u5b89\u5168\u7ee9\u6548\u4eea\u8868\u677f\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u95ee\u9898\u7684\u9ad8\u6548\u53d1\u73b0\u4e0e\u6267\u6cd5\u6210\u6548\u7684\u81ea\u52a8\u5206\u6790\uff0c\u4e3a\u9053\u8def\u8fd0\u8f93\u5b89\u5168\u7ba1\u7406\u63d0\u4f9b\u4e86\u6280\u672f\u652f\u6301\uff0c\u4f46\u8fdb\u4e00\u6b65\u7cbe\u7ec6\u7684\u6570\u636e\u91c7\u96c6\u4ecd\u7136\u662f\u63d0\u5347\u7ee9\u6548\u8bc4\u4f30\u7684\u5173\u952e\u3002"}}
{"id": "2507.06263", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06263", "abs": "https://arxiv.org/abs/2507.06263", "authors": ["Eric Schwitzgebel", "Jeff Sebo"], "title": "The Emotional Alignment Design Policy", "comment": null, "summary": "According to what we call the Emotional Alignment Design Policy, artificial\nentities should be designed to elicit emotional reactions from users that\nappropriately reflect the entities' capacities and moral status, or lack\nthereof. This principle can be violated in two ways: by designing an artificial\nsystem that elicits stronger or weaker emotional reactions than its capacities\nand moral status warrant (overshooting or undershooting), or by designing a\nsystem that elicits the wrong type of emotional reaction (hitting the wrong\ntarget). Although presumably attractive, practical implementation faces several\nchallenges including: How can we respect user autonomy while promoting\nappropriate responses? How should we navigate expert and public disagreement\nand uncertainty about facts and values? What if emotional alignment seems to\nrequire creating or destroying entities with moral status? To what extent\nshould designs conform to versus attempt to alter user assumptions and\nattitudes?", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u201c\u60c5\u611f\u5bf9\u9f50\u8bbe\u8ba1\u51c6\u5219\u201d\uff0c\u8981\u6c42\u4eba\u5de5\u667a\u80fd\u7b49\u5b9e\u4f53\u6fc0\u53d1\u4e0e\u81ea\u8eab\u80fd\u529b\u548c\u9053\u5fb7\u5730\u4f4d\u76f8\u7b26\u7684\u60c5\u611f\u3002\u4f5c\u8005\u8ba8\u8bba\u4e86\u51c6\u5219\u88ab\u8fdd\u53cd\u7684\u65b9\u5f0f\uff0c\u5e76\u5206\u6790\u4e86\u5b9e\u9645\u6267\u884c\u9762\u4e34\u7684\u4f26\u7406\u4e0e\u5b9e\u8df5\u96be\u9898\uff0c\u4f8b\u5982\u7528\u6237\u81ea\u4e3b\u3001\u4ef7\u503c\u5206\u6b67\u548c\u516c\u4f17\u8ba4\u77e5\u7b49\uff0c\u6307\u51fa\u672a\u6765\u4ecd\u9700\u6df1\u5165\u7814\u7a76\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u548c\u5176\u4ed6\u4eba\u5de5\u5b9e\u4f53\u7684\u666e\u53ca\uff0c\u7528\u6237\u4e0e\u667a\u80fd\u4f53\u7684\u60c5\u611f\u4ea4\u4e92\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u4f5c\u8005\u63d0\u51fa\u5e94\u5173\u6ce8\u4eba\u5de5\u5b9e\u4f53\u88ab\u8bbe\u8ba1\u6210\u6fc0\u53d1\u4e0e\u5176\u80fd\u529b\u548c\u9053\u5fb7\u5730\u4f4d\u76f8\u7b26\u7684\u60c5\u611f\u53cd\u5e94\u2014\u2014\u5373\u201c\u60c5\u611f\u5bf9\u9f50\u8bbe\u8ba1\u51c6\u5219\u201d\uff0c\u4ee5\u51cf\u5c11\u4e0d\u5f53\u60c5\u611f\u53cd\u5e94\u5e26\u6765\u7684\u4f26\u7406\u98ce\u9669\u3002", "method": "\u6587\u7ae0\u91c7\u7528\u4f26\u7406\u54f2\u5b66\u5206\u6790\uff0c\u6784\u5efa\u7406\u8bba\u6a21\u578b\uff0c\u7cfb\u7edf\u68b3\u7406\u4eba\u5de5\u667a\u80fd\u4e0e\u7528\u6237\u4e4b\u95f4\u60c5\u611f\u5bf9\u9f50\u7684\u539f\u5219\u53ca\u5176\u8fdd\u53cd\u65b9\u5f0f\uff0c\u5e76\u8ba8\u8bba\u76f8\u5173\u4f26\u7406\u548c\u5b9e\u8df5\u6311\u6218\u3002", "result": "\u63d0\u51fa\u60c5\u611f\u5bf9\u9f50\u8bbe\u8ba1\u51c6\u5219\uff1a\u4eba\u5de5\u5b9e\u4f53\u5e94\u6fc0\u53d1\u4e0e\u81ea\u8eab\u80fd\u529b\u53ca\u5176\u9053\u5fb7\u5730\u4f4d\u76f8\u7b26\u7684\u60c5\u611f\u53cd\u5e94\u3002\u8bba\u6587\u603b\u7ed3\u4e86\u4e09\u5927\u6311\u6218\uff0c\u5305\u62ec\u5c0a\u91cd\u7528\u6237\u81ea\u4e3b\u3001\u5904\u7406\u4e8b\u5b9e\u4e0e\u4ef7\u503c\u89c2\u4e89\u8bae\uff0c\u4ee5\u53ca\u7528\u6237\u5047\u8bbe\u4e0e\u6001\u5ea6\u7684\u95ee\u9898\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u9519\u8bef\u7c7b\u578b\uff08\u60c5\u611f\u8fc7\u5ea6\u3001\u7f3a\u4e4f\u3001\u6216\u7c7b\u578b\u9519\u8bef\uff09\u7684\u5177\u4f53\u5b9e\u4f8b\u4e0e\u7406\u8bba\u5206\u6790\u3002", "conclusion": "\u60c5\u611f\u5bf9\u9f50\u8bbe\u8ba1\u51c6\u5219\u4e3a\u4eba\u5de5\u667a\u80fd\u4f26\u7406\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\uff0c\u4f46\u5176\u5b9e\u9645\u5e94\u7528\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u9700\u8981\u5728\u5c0a\u91cd\u7528\u6237\u4ee5\u53ca\u793e\u4f1a\u4f26\u7406\u591a\u6837\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u614e\u91cd\u63a8\u8fdb\u3002"}}
{"id": "2507.06261", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06261", "abs": "https://arxiv.org/abs/2507.06261", "authors": ["Gheorghe Comanici", "Eric Bieber", "Mike Schaekermann", "Ice Pasupat", "Noveen Sachdeva", "Inderjit Dhillon", "Marcel Blistein", "Ori Ram", "Dan Zhang", "Evan Rosen", "Luke Marris", "Sam Petulla", "Colin Gaffney", "Asaf Aharoni", "Nathan Lintz", "Tiago Cardal Pais", "Henrik Jacobsson", "Idan Szpektor", "Nan-Jiang Jiang", "Krishna Haridasan", "Ahmed Omran", "Nikunj Saunshi", "Dara Bahri", "Gaurav Mishra", "Eric Chu", "Toby Boyd", "Brad Hekman", "Aaron Parisi", "Chaoyi Zhang", "Kornraphop Kawintiranon", "Tania Bedrax-Weiss", "Oliver Wang", "Ya Xu", "Ollie Purkiss", "Uri Mendlovic", "Ila\u00ef Deutel", "Nam Nguyen", "Adam Langley", "Flip Korn", "Lucia Rossazza", "Alexandre Ram\u00e9", "Sagar Waghmare", "Helen Miller", "Vaishakh Keshava", "Ying Jian", "Xiaofan Zhang", "Raluca Ada Popa", "Kedar Dhamdhere", "Bla\u017e Bratani\u010d", "Kyuyeun Kim", "Terry Koo", "Ferran Alet", "Yi-ting Chen", "Arsha Nagrani", "Hannah Muckenhirn", "Zhiyuan Zhang", "Corbin Quick", "Filip Paveti\u0107", "Duc Dung Nguyen", "Joao Carreira", "Michael Elabd", "Haroon Qureshi", "Fabian Mentzer", "Yao-Yuan Yang", "Danielle Eisenbud", "Anmol Gulati", "Ellie Talius", "Eric Ni", "Sahra Ghalebikesabi", "Edouard Yvinec", "Alaa Saade", "Thatcher Ulrich", "Lorenzo Blanco", "Dan A. Calian", "Muhuan Huang", "A\u00e4ron van den Oord", "Naman Goyal", "Terry Chen", "Praynaa Rawlani", "Christian Schallhart", "Swachhand Lokhande", "Xianghong Luo", "Jyn Shan", "Ceslee Montgomery", "Victoria Krakovna", "Federico Piccinini", "Omer Barak", "Jingyu Cui", "Yiling Jia", "Mikhail Dektiarev", "Alexey Kolganov", "Shiyu Huang", "Zhe Chen", "Xingyu Wang", "Jessica Austin", "Peter de Boursac", "Evgeny Sluzhaev", "Frank Ding", "Huijian Li", "Surya Bhupatiraju", "Mohit Agarwal", "S\u0142awek Kwasiborski", "Paramjit Sandhu", "Patrick Siegler", "Ahmet Iscen", "Eyal Ben-David", "Shiraz Butt", "Miltos Allamanis", "Seth Benjamin", "Robert Busa-Fekete", "Felix Hernandez-Campos", "Sasha Goldshtein", "Matt Dibb", "Weiyang Zhang", "Annie Marsden", "Carey Radebaugh", "Stephen Roller", "Abhishek Nayyar", "Jacob Austin", "Tayfun Terzi", "Bhargav Kanagal Shamanna", "Pete Shaw", "Aayush Singh", "Florian Luisier", "Artur Mendon\u00e7a", "Vaibhav Aggarwal", "Larisa Markeeva", "Claudio Fantacci", "Sergey Brin", "HyunJeong Choe", "Guanyu Wang", "Hartwig Adam", "Avigail Dabush", "Tatsuya Kiyono", "Eyal Marcus", "Jeremy Cole", "Theophane Weber", "Hongrae Lee", "Ronny Huang", "Alex Muzio", "Leandro Kieliger", "Maigo Le", "Courtney Biles", "Long Le", "Archit Sharma", "Chengrun Yang", "Avery Lamp", "Dave Dopson", "Nate Hurley", "Katrina", "Xu", "Zhihao Shan", "Shuang Song", "Jiewen Tan", "Alexandre Senges", "George Zhang", "Chong You", "Yennie Jun", "David Raposo", "Susanna Ricco", "Xuan Yang", "Weijie Chen", "Prakhar Gupta", "Arthur Szlam", "Kevin Villela", "Chun-Sung Ferng", "Daniel Kasenberg", "Chen Liang", "Rui Zhu", "Arunachalam Narayanaswamy", "Florence Perot", "Paul Pucciarelli", "Anna Shekhawat", "Alexey Stern", "Rishikesh Ingale", "Stefani Karp", "Sanaz Bahargam", "Adrian Goedeckemeyer", "Jie Han", "Sicheng Li", "Andrea Tacchetti", "Dian Yu", "Abhishek Chakladar", "Zhiying Zhang", "Mona El Mahdy", "Xu Gao", "Dale Johnson", "Samrat Phatale", "AJ Piergiovanni", "Hyeontaek Lim", "Clement Farabet", "Carl Lebsack", "Theo Guidroz", "John Blitzer", "Nico Duduta", "David Madras", "Steve Li", "Daniel von Dincklage", "Xin Li", "Mahdis Mahdieh", "George Tucker", "Ganesh Jawahar", "Owen Xiao", "Danny Tarlow", "Robert Geirhos", "Noam Velan", "Daniel Vlasic", "Kalesha Bullard", "SK Park", "Nishesh Gupta", "Kellie Webster", "Ayal Hitron", "Jieming Mao", "Julian Eisenschlos", "Laurel Prince", "Nina D'Souza", "Kelvin Zheng", "Sara Nasso", "Gabriela Botea", "Carl Doersch", "Caglar Unlu", "Chris Alberti", "Alexey Svyatkovskiy", "Ankita Goel", "Krzysztof Choromanski", "Pan-Pan Jiang", "Richard Nguyen", "Four Flynn", "Daria \u0106urko", "Peter Chen", "Nicholas Roth", "Kieran Milan", "Caleb Habtegebriel", "Shashi Narayan", "Michael Moffitt", "Jake Marcus", "Thomas Anthony", "Brendan McMahan", "Gowoon Cheon", "Ruibo Liu", "Megan Barnes", "Lukasz Lew", "Rebeca Santamaria-Fernandez", "Mayank Upadhyay", "Arjun Akula", "Arnar Mar Hrafnkelsson", "Alvaro Caceres", "Andrew Bunner", "Michal Sokolik", "Subha Puttagunta", "Lawrence Moore", "Berivan Isik", "Weilun Chen", "Jay Hartford", "Lawrence Chan", "Pradeep Shenoy", "Dan Holtmann-Rice", "Jane Park", "Fabio Viola", "Alex Salcianu", "Sujeevan Rajayogam", "Ian Stewart-Binks", "Zelin Wu", "Richard Everett", "Xi Xiong", "Pierre-Antoine Manzagol", "Gary Leung", "Carl Saroufim", "Bo Pang", "Dawid Wegner", "George Papamakarios", "Jennimaria Palomaki", "Helena Pankov", "Guangda Lai", "Guilherme Tubone", "Shubin Zhao", "Theofilos Strinopoulos", "Seth Neel", "Mingqiu Wang", "Joe Kelley", "Li Li", "Pingmei Xu", "Anitha Vijayakumar", "Andrea D'olimpio", "Omer Levy", "Massimo Nicosia", "Grigory Rozhdestvenskiy", "Ni Lao", "Sirui Xie", "Yash Katariya", "Jon Simon", "Sanjiv Kumar", "Florian Hartmann", "Michael Kilgore", "Jinhyuk Lee", "Aroma Mahendru", "Roman Ring", "Tom Hennigan", "Fiona Lang", "Colin Cherry", "David Steiner", "Dawsen Hwang", "Ray Smith", "Pidong Wang", "Jeremy Chen", "Ming-Hsuan Yang", "Sam Kwei", "Philippe Schlattner", "Donnie Kim", "Ganesh Poomal Girirajan", "Nikola Momchev", "Ayushi Agarwal", "Xingyi Zhou", "Ilkin Safarli", "Zachary Garrett", "AJ Pierigiovanni", "Sarthak Jauhari", "Alif Raditya Rochman", "Shikhar Vashishth", "Quan Yuan", "Christof Angermueller", "Jon Blanton", "Xinying Song", "Nitesh Bharadwaj Gundavarapu", "Thi Avrahami", "Maxine Deines", "Subhrajit Roy", "Manish Gupta", "Christopher Semturs", "Shobha Vasudevan", "Aditya Srikanth Veerubhotla", "Shriya Sharma", "Josh Jacob", "Zhen Yang", "Andreas Terzis", "Dan Karliner", "Auriel Wright", "Tania Rojas-Esponda", "Ashley Brown", "Abhijit Guha Roy", "Pawan Dogra", "Andrei Kapishnikov", "Peter Young", "Wendy Kan", "Vinodh Kumar Rajendran", "Maria Ivanova", "Salil Deshmukh", "Chia-Hua Ho", "Mike Kwong", "Stav Ginzburg", "Annie Louis", "KP Sawhney", "Slav Petrov", "Jing Xie", "Yunfei Bai", "Georgi Stoyanov", "Alex Fabrikant", "Rajesh Jayaram", "Yuqi Li", "Joe Heyward", "Justin Gilmer", "Yaqing Wang", "Radu Soricut", "Luyang Liu", "Qingnan Duan", "Jamie Hayes", "Maura O'Brien", "Gaurav Singh Tomar", "Sivan Eiger", "Bahar Fatemi", "Jeffrey Hui", "Catarina Barros", "Adaeze Chukwuka", "Alena Butryna", "Saksham Thakur", "Austin Huang", "Zhufeng Pan", "Haotian Tang", "Serkan Cabi", "Tulsee Doshi", "Michiel Bakker", "Sumit Bagri", "Ruy Ley-Wild", "Adam Lelkes", "Jennie Lees", "Patrick Kane", "David Greene", "Shimu Wu", "J\u00f6rg Bornschein", "Gabriela Surita", "Sarah Hodkinson", "Fangtao Li", "Chris Hidey", "S\u00e9bastien Pereira", "Sean Ammirati", "Phillip Lippe", "Adam Kraft", "Pu Han", "Sebastian Gerlach", "Zifeng Wang", "Liviu Panait", "Feng Han", "Brian Farris", "Yingying Bi", "Hannah DeBalsi", "Miaosen Wang", "Gladys Tyen", "James Cohan", "Susan Zhang", "Jarred Barber", "Da-Woon Chung", "Jaeyoun Kim", "Markus Kunesch", "Steven Pecht", "Nami Akazawa", "Abe Friesen", "James Lyon", "Ali Eslami", "Junru Wu", "Jie Tan", "Yue Song", "Ravi Kumar", "Chris Welty", "Ilia Akolzin", "Gena Gibson", "Sean Augenstein", "Arjun Pillai", "Nancy Yuen", "Du Phan", "Xin Wang", "Iain Barr", "Heiga Zen", "Nan Hua", "Casper Liu", "Jilei", "Wang", "Tanuj Bhatia", "Hao Xu", "Oded Elyada", "Pushmeet Kohli", "Mirek Ol\u0161\u00e1k", "Ke Chen", "Azalia Mirhoseini", "Noam Shazeer", "Shoshana Jakobovits", "Maggie Tran", "Nolan Ramsden", "Tarun Bharti", "Fred Alcober", "Yunjie Li", "Shilpa Shetty", "Jing Chen", "Dmitry Kalashnikov", "Megha Nawhal", "Sercan Arik", "Hanwen Chen", "Michiel Blokzijl", "Shubham Gupta", "James Rubin", "Rigel Swavely", "Sophie Bridgers", "Ian Gemp", "Chen Su", "Arun Suggala", "Juliette Pluto", "Mary Cassin", "Alain Vaucher", "Kaiyang Ji", "Jiahao Cai", "Andrew Audibert", "Animesh Sinha", "David Tian", "Efrat Farkash", "Amy Hua", "Jilin Chen", "Duc-Hieu Tran", "Edward Loper", "Nicole Brichtova", "Lara McConnaughey", "Ballie Sandhu", "Robert Leland", "Doug DeCarlo", "Andrew Over", "James Huang", "Xing Wu", "Connie Fan", "Eric Li", "Yun Lei", "Deepak Sharma", "Cosmin Paduraru", "Luo Yu", "Matko Bo\u0161njak", "Phuong Dao", "Min Choi", "Sneha Kudugunta", "Jakub Adamek", "Carlos Gu\u00eda", "Ali Khodaei", "Jie Feng", "Wenjun Zeng", "David Welling", "Sandeep Tata", "Christina Butterfield", "Andrey Vlasov", "Seliem El-Sayed", "Swaroop Mishra", "Tara Sainath", "Shentao Yang", "RJ Skerry-Ryan", "Jeremy Shar", "Robert Berry", "Arunkumar Rajendran", "Arun Kandoor", "Andrea Burns", "Deepali Jain", "Tom Stone", "Wonpyo Park", "Shibo Wang", "Albin Cassirer", "Guohui Wang", "Hayato Kobayashi", "Sergey Rogulenko", "Vineetha Govindaraj", "Miko\u0142aj Rybi\u0144ski", "Nadav Olmert", "Colin Evans", "Po-Sen Huang", "Kelvin Xu", "Premal Shah", "Terry Thurk", "Caitlin Sikora", "Mu Cai", "Jin Xie", "Elahe Dabir", "Saloni Shah", "Norbert Kalb", "Carrie Zhang", "Shruthi Prabhakara", "Amit Sabne", "Artiom Myaskovsky", "Vikas Raunak", "Blanca Huergo", "Behnam Neyshabur", "Jon Clark", "Ye Zhang", "Shankar Krishnan", "Eden Cohen", "Dinesh Tewari", "James Lottes", "Yumeya Yamamori", "Hui", "Li", "Mohamed Elhawaty", "Ada Maksutaj Oflazer", "Adri\u00e0 Recasens", "Sheryl Luo", "Duy Nguyen", "Taylor Bos", "Kalyan Andra", "Ana Salazar", "Ed Chi", "Jeongwoo Ko", "Matt Ginsberg", "Anders Andreassen", "Anian Ruoss", "Todor Davchev", "Elnaz Davoodi", "Chenxi Liu", "Min Kim", "Santiago Ontanon", "Chi Ming To", "Dawei Jia", "Rosemary Ke", "Jing Wang", "Anna Korsun", "Moran Ambar", "Ilya Kornakov", "Irene Giannoumis", "Toni Creswell", "Denny Zhou", "Yi Su", "Ishaan Watts", "Aleksandr Zaks", "Evgenii Eltyshev", "Ziqiang Feng", "Sidharth Mudgal", "Alex Kaskasoli", "Juliette Love", "Kingshuk Dasgupta", "Sam Shleifer", "Richard Green", "Sungyong Seo", "Chansoo Lee", "Dale Webster", "Prakash Shroff", "Ganna Raboshchuk", "Isabel Leal", "James Manyika", "Sofia Erell", "Daniel Murphy", "Zhisheng Xiao", "Anton Bulyenov", "Julian Walker", "Mark Collier", "Matej Kastelic", "Nelson George", "Sushant Prakash", "Sailesh Sidhwani", "Alexey Frolov", "Steven Hansen", "Petko Georgiev", "Tiberiu Sosea", "Chris Apps", "Aishwarya Kamath", "David Reid", "Emma Cooney", "Charlotte Magister", "Oriana Riva", "Alec Go", "Pu-Chin Chen", "Sebastian Krause", "Nir Levine", "Marco Fornoni", "Ilya Figotin", "Nick Roy", "Parsa Mahmoudieh", "Vladimir Magay", "Mukundan Madhavan", "Jin Miao", "Jianmo Ni", "Yasuhisa Fujii", "Ian Chou", "George Scrivener", "Zak Tsai", "Siobhan Mcloughlin", "Jeremy Selier", "Sandra Lefdal", "Jeffrey Zhao", "Abhijit Karmarkar", "Kushal Chauhan", "Shivanker Goel", "Zhaoyi Zhang", "Vihan Jain", "Parisa Haghani", "Mostafa Dehghani", "Jacob Scott", "Erin Farnese", "Anastasija Ili\u0107", "Steven Baker", "Julia Pawar", "Li Zhong", "Josh Camp", "Yoel Zeldes", "Shravya Shetty", "Anand Iyer", "V\u00edt List\u00edk", "Jiaxian Guo", "Luming Tang", "Mark Geller", "Simon Bucher", "Yifan Ding", "Hongzhi Shi", "Carrie Muir", "Dominik Grewe", "Ramy Eskander", "Octavio Ponce", "Boqing Gong", "Derek Gasaway", "Samira Khan", "Umang Gupta", "Angelos Filos", "Weicheng Kuo", "Klemen Kloboves", "Jennifer Beattie", "Christian Wright", "Leon Li", "Alicia Jin", "Sandeep Mariserla", "Miteyan Patel", "Jens Heitkaemper", "Dilip Krishnan", "Vivek Sharma", "David Bieber", "Christian Frank", "John Lambert", "Paul Caron", "Martin Polacek", "Mai Gim\u00e9nez", "Himadri Choudhury", "Xing Yu", "Sasan Tavakkol", "Arun Ahuja", "Franz Och", "Rodolphe Jenatton", "Wojtek Skut", "Bryan Richter", "David Gaddy", "Andy Ly", "Misha Bilenko", "Megh Umekar", "Ethan Liang", "Martin Sevenich", "Mandar Joshi", "Hassan Mansoor", "Rebecca Lin", "Sumit Sanghai", "Abhimanyu Singh", "Xiaowei Li", "Sudheendra Vijayanarasimhan", "Zaheer Abbas", "Yonatan Bitton", "Hansa Srinivasan", "Manish Reddy Vuyyuru", "Alexander Fr\u00f6mmgen", "Yanhua Sun", "Ralph Leith", "Alfonso Casta\u00f1o", "DJ Strouse", "Le Yan", "Austin Kyker", "Satish Kambala", "Mary Jasarevic", "Thibault Sellam", "Chao Jia", "Alexander Pritzel", "Raghavender R", "Huizhong Chen", "Natalie Clay", "Sudeep Gandhe", "Sean Kirmani", "Sayna Ebrahimi", "Hannah Kirkwood", "Jonathan Mallinson", "Chao Wang", "Adnan Ozturel", "Kuo Lin", "Shyam Upadhyay", "Vincent Cohen-Addad", "Sean Purser-haskell", "Yichong Xu", "Ebrahim Songhori", "Babi Seal", "Alberto Magni", "Almog Gueta", "Tingting Zou", "Guru Guruganesh", "Thais Kagohara", "Hung Nguyen", "Khalid Salama", "Alejandro Cruzado Ruiz", "Justin Frye", "Zhenkai Zhu", "Matthias Lochbrunner", "Simon Osindero", "Wentao Yuan", "Lisa Lee", "Aman Prasad", "Lam Nguyen Thiet", "Daniele Calandriello", "Victor Stone", "Qixuan Feng", "Han Ke", "Maria Voitovich", "Geta Sampemane", "Lewis Chiang", "Ling Wu", "Alexander Bykovsky", "Matt Young", "Luke Vilnis", "Ishita Dasgupta", "Aditya Chawla", "Qin Cao", "Bowen Liang", "Daniel Toyama", "Szabolcs Payrits", "Anca Stefanoiu", "Dimitrios Vytiniotis", "Ankesh Anand", "Tianxiao Shen", "Blagoj Mitrevski", "Michael Tschannen", "Sreenivas Gollapudi", "Aishwarya P S", "Jos\u00e9 Leal", "Zhe Shen", "Han Fu", "Wei Wang", "Arvind Kannan", "Doron Kukliansky", "Sergey Yaroshenko", "Svetlana Grant", "Umesh Telang", "David Wood", "Alexandra Chronopoulou", "Alexandru \u0162ifrea", "Tao Zhou", "Tony", "Nguy\\~\u00ean", "Muge Ersoy", "Anima Singh", "Meiyan Xie", "Emanuel Taropa", "Woohyun Han", "Eirikur Agustsson", "Andrei Sozanschi", "Hui Peng", "Alex Chen", "Yoel Drori", "Efren Robles", "Yang Gao", "Xerxes Dotiwalla", "Ying Chen", "Anudhyan Boral", "Alexei Bendebury", "John Nham", "Chris Tar", "Luis Castro", "Jiepu Jiang", "Canoee Liu", "Felix Halim", "Jinoo Baek", "Andy Wan", "Jeremiah Liu", "Yuan Cao", "Shengyang Dai", "Trilok Acharya", "Ruoxi Sun", "Fuzhao Xue", "Saket Joshi", "Morgane Lustman", "Yongqin Xian", "Rishabh Joshi", "Deep Karkhanis", "Nora Kassner", "Jamie Hall", "Xiangzhuo Ding", "Gan Song", "Gang Li", "Chen Zhu", "Yana Kulizhskaya", "Bin Ni", "Alexey Vlaskin", "Solomon Demmessie", "Lucio Dery", "Salah Zaiem", "Yanping Huang", "Cindy Fan", "Felix Gimeno", "Ananth Balashankar", "Koji Kojima", "Hagai Taitelbaum", "Maya Meng", "Dero Gharibian", "Sahil Singla", "Wei Chen", "Ambrose Slone", "Guanjie Chen", "Sujee Rajayogam", "Max Schumacher", "Suyog Kotecha", "Rory Blevins", "Qifei Wang", "Mor Hazan Taege", "Alex Morris", "Xin Liu", "Fayaz Jamil", "Richard Zhang", "Pratik Joshi", "Ben Ingram", "Tyler Liechty", "Ahmed Eleryan", "Scott Baird", "Alex Grills", "Gagan Bansal", "Shan Han", "Kiran Yalasangi", "Shawn Xu", "Majd Al Merey", "Isabel Gao", "Felix Weissenberger", "Igor Karpov", "Robert Riachi", "Ankit Anand", "Gautam Prasad", "Kay Lamerigts", "Reid Hayes", "Jamie Rogers", "Mandy Guo", "Ashish Shenoy", "Qiong", "Hu", "Kyle He", "Yuchen Liu", "Polina Zablotskaia", "Sagar Gubbi", "Yifan Chang", "Jay Pavagadhi", "Kristian Kjems", "Archita Vadali", "Diego Machado", "Yeqing Li", "Renshen Wang", "Dipankar Ghosh", "Aahil Mehta", "Dana Alon", "George Polovets", "Alessio Tonioni", "Nate Kushman", "Joel D'sa", "Lin Zhuo", "Allen Wu", "Rohin Shah", "John Youssef", "Jiayu Ye", "Justin Snyder", "Karel Lenc", "Senaka Buthpitiya", "Matthew Tung", "Jichuan Chang", "Tao Chen", "David Saxton", "Jenny Lee", "Lydia Lihui Zhang", "James Qin", "Prabakar Radhakrishnan", "Maxwell Chen", "Piotr Ambroszczyk", "Metin Toksoz-Exley", "Yan Zhong", "Nitzan Katz", "Brendan O'Donoghue", "Tamara von Glehn", "Adi Gerzi Rosenthal", "Aga \u015awietlik", "Xiaokai Zhao", "Nick Fernando", "Jinliang Wei", "Jieru Mei", "Sergei Vassilvitskii", "Diego Cedillo", "Pranjal Awasthi", "Hui Zheng", "Koray Kavukcuoglu", "Itay Laish", "Joseph Pagadora", "Marc Brockschmidt", "Christopher A. Choquette-Choo", "Arunkumar Byravan", "Yifeng Lu", "Xu Chen", "Mia Chen", "Kenton Lee", "Rama Pasumarthi", "Sijal Bhatnagar", "Aditya Shah", "Qiyin Wu", "Zhuoyuan Chen", "Zack Nado", "Bartek Perz", "Zixuan Jiang", "David Kao", "Ganesh Mallya", "Nino Vieillard", "Lantao Mei", "Sertan Girgin", "Mandy Jordan", "Yeongil Ko", "Alekh Agarwal", "Yaxin Liu", "Yasemin Altun", "Raoul de Liedekerke", "Anastasios Kementsietsidis", "Daiyi Peng", "Dangyi Liu", "Utku Evci", "Peter Humphreys", "Austin Tarango", "Xiang Deng", "Yoad Lewenberg", "Kevin Aydin", "Chengda Wu", "Bhavishya Mittal", "Tsendsuren Munkhdalai", "Kleopatra Chatziprimou", "Rodrigo Benenson", "Uri First", "Xiao Ma", "Jinning Li", "Armand Joulin", "Hamish Tomlinson", "Tingnan Zhang", "Milad Nasr", "Zhi Hong", "Micha\u00ebl Sander", "Lisa Anne Hendricks", "Anuj Sharma", "Andrew Bolt", "Eszter V\u00e9rtes", "Jiri Simsa", "Tomer Levinboim", "Olcan Sercinoglu", "Divyansh Shukla", "Austin Wu", "Craig Swanson", "Danny Vainstein", "Fan Bu", "Bo Wang", "Ryan Julian", "Charles Yoon", "Sergei Lebedev", "Antonious Girgis", "Bernd Bandemer", "David Du", "Todd Wang", "Xi Chen", "Ying Xiao", "Peggy Lu", "Natalie Ha", "Vlad Ionescu", "Simon Rowe", "Josip Matak", "Federico Lebron", "Andreas Steiner", "Lalit Jain", "Manaal Faruqui", "Nicolas Lacasse", "Georgie Evans", "Neesha Subramaniam", "Dean Reich", "Giulia Vezzani", "Aditya Pandey", "Joe Stanton", "Tianhao Zhou", "Liam McCafferty", "Henry Griffiths", "Verena Rieser", "Soheil Hassas Yeganeh", "Eleftheria Briakou", "Lu Huang", "Zichuan Wei", "Liangchen Luo", "Erik Jue", "Gabby Wang", "Victor Cotruta", "Myriam Khan", "Jongbin Park", "Qiuchen Guo", "Peiran Li", "Rong Rong", "Diego Antognini", "Anastasia Petrushkina", "Chetan Tekur", "Eli Collins", "Parul Bhatia", "Chester Kwak", "Wenhu Chen", "Arvind Neelakantan", "Immanuel Odisho", "Sheng Peng", "Vincent Nallatamby", "Vaibhav Tulsyan", "Fabian Pedregosa", "Peng Xu", "Raymond Lin", "Yulong Wang", "Emma Wang", "Sholto Douglas", "Reut Tsarfaty", "Elena Gribovskaya", "Renga Aravamudhan", "Manu Agarwal", "Mara Finkelstein", "Qiao Zhang", "Elizabeth Cole", "Phil Crone", "Sarmishta Velury", "Anil Das", "Chris Sauer", "Luyao Xu", "Danfeng Qin", "Chenjie Gu", "Dror Marcus", "CJ Zheng", "Wouter Van Gansbeke", "Sobhan Miryoosefi", "Haitian Sun", "YaGuang Li", "Charlie Chen", "Jae Yoo", "Pavel Dubov", "Alex Tomala", "Adams Yu", "Pawe\u0142 Weso\u0142owski", "Alok Gunjan", "Eddie Cao", "Jiaming Luo", "Nikhil Sethi", "Arkadiusz Socala", "Laura Graesser", "Tomas Kocisky", "Arturo BC", "Minmin Chen", "Edward Lee", "Sophie Wang", "Weize Kong", "Qiantong Xu", "Nilesh Tripuraneni", "Yiming Li", "Xinxin Yu", "Allen Porter", "Paul Voigtlaender", "Biao Zhang", "Arpi Vezer", "Sarah York", "Qing Wei", "Geoffrey Cideron", "Mark Kurzeja", "Seungyeon Kim", "Benny Li", "Ang\u00e9line Pouget", "Hyo Lee", "Kaspar Daugaard", "Yang Li", "Dave Uthus", "Aditya Siddhant", "Paul Cavallaro", "Sriram Ganapathy", "Maulik Shah", "Rolf Jagerman", "Jeff Stanway", "Piermaria Mendolicchio", "Li Xiao", "Kayi Lee", "Tara Thompson", "Shubham Milind Phal", "Jason Chase", "Sun Jae Lee", "Adrian N Reyes", "Disha Shrivastava", "Zhen Qin", "Roykrong Sukkerd", "Seth Odoom", "Lior Madmoni", "John Aslanides", "Jonathan Herzig", "Elena Pochernina", "Sheng Zhang", "Parker Barnes", "Daisuke Ikeda", "Qiujia Li", "Shuo-yiin Chang", "Shakir Mohamed", "Jim Sproch", "Richard Powell", "Bidisha Samanta", "Domagoj \u0106evid", "Anton Kovsharov", "Shrestha Basu Mallick", "Srinivas Tadepalli", "Anne Zheng", "Kareem Ayoub", "Andreas Noever", "Christian Reisswig", "Zhuo Xu", "Junhyuk Oh", "Martin Matysiak", "Tim Blyth", "Shereen Ashraf", "Julien Amelot", "Boone Severson", "Michele Bevilacqua", "Motoki Sano", "Ethan Dyer", "Ofir Roval", "Anu Sinha", "Yin Zhong", "Sagi Perel", "Tea Saboli\u0107", "Johannes Mauerer", "Willi Gierke", "Mauro Verzetti", "Rodrigo Cabrera", "Alvin Abdagic", "Steven Hemingray", "Austin Stone", "Jong Lee", "Farooq Ahmad", "Karthik Raman", "Lior Shani", "Jonathan Lai", "Orhan Firat", "Nathan Waters", "Eric Ge", "Mo Shomrat", "Himanshu Gupta", "Rajeev Aggarwal", "Tom Hudson", "Bill Jia", "Simon Baumgartner", "Palak Jain", "Joe Kovac", "Junehyuk Jung", "Ante \u017du\u017eul", "Will Truong", "Morteza Zadimoghaddam", "Songyou Peng", "Marco Liang", "Rachel Sterneck", "Balaji Lakshminarayanan", "Machel Reid", "Oliver Woodman", "Tong Zhou", "Jianling Wang", "Vincent Coriou", "Arjun Narayanan", "Jay Hoover", "Yenai Ma", "Apoorv Jindal", "Clayton Sanford", "Doug Reid", "Swaroop Ramaswamy", "Alex Kurakin", "Roland Zimmermann", "Yana Lunts", "Dragos Dena", "Zal\u00e1n Borsos", "Vered Cohen", "Shujian Zhang", "Will Grathwohl", "Robert Dadashi", "Morgan Redshaw", "Joshua Kessinger", "Julian Odell", "Silvano Bonacina", "Zihang Dai", "Grace Chen", "Ayush Dubey", "Pablo Sprechmann", "Mantas Pajarskas", "Wenxuan Zhou", "Niharika Ahuja", "Tara Thomas", "Martin Nikoltchev", "Matija Kecman", "Bharath Mankalale", "Andrey Ryabtsev", "Jennifer She", "Christian Walder", "Jiaming Shen", "Lu Li", "Carolina Parada", "Sheena Panthaplackel", "Okwan Kwon", "Matt Lawlor", "Utsav Prabhu", "Yannick Schroecker", "Marc'aurelio Ranzato", "Pete Blois", "Iurii Kemaev", "Ting Yu", "Dmitry", "Lepikhin", "Hao Xiong", "Sahand Sharifzadeh", "Oleaser Johnson", "Jeremiah Willcock", "Rui Yao", "Greg Farquhar", "Sujoy Basu", "Hidetoshi Shimokawa", "Nina Anderson", "Haiguang Li", "Khiem Pham", "Yizhong Liang", "Sebastian Borgeaud", "Alexandre Moufarek", "Hideto Kazawa", "Blair Kutzman", "Marcin Sieniek", "Sara Smoot", "Ruth Wang", "Natalie Axelsson", "Nova Fallen", "Prasha Sundaram", "Yuexiang Zhai", "Varun Godbole", "Petros Maniatis", "Alek Wang", "Ilia Shumailov", "Santhosh Thangaraj", "Remi Crocker", "Nikita Gupta", "Gang Wu", "Phil Chen", "Gell\u00e9rt Weisz", "Celine Smith", "Mojtaba Seyedhosseini", "Boya Fang", "Xiyang Luo", "Roey Yogev", "Zeynep Cankara", "Andrew Hard", "Helen Ran", "Rahul Sukthankar", "George Necula", "Ga\u00ebl Liu", "Honglong Cai", "Praseem Banzal", "Daniel Keysers", "Sanjay Ghemawat", "Connie Tao", "Emma Dunleavy", "Aditi Chaudhary", "Wei Li", "Maciej Miku\u0142a", "Chen-Yu Lee", "Tiziana Refice", "Krishna Somandepalli", "Alexandre Fr\u00e9chette", "Dan Bahir", "John Karro", "Keith Rush", "Sarah Perrin", "Bill Rosgen", "Xiaomeng Yang", "Clara Huiyi Hu", "Mahmoud Alnahlawi", "Justin Mao-Jones", "Roopal Garg", "Hoang Nguyen", "Bat-Orgil Batsaikhan", "I\u00f1aki Iturrate", "Anselm Levskaya", "Avi Singh", "Ashyana Kachra", "Tony Lu", "Denis Petek", "Zheng Xu", "Mark Graham", "Lukas Zilka", "Yael Karov", "Marija Kostelac", "Fangyu Liu", "Yaohui Guo", "Weiyue Wang", "Bernd Bohnet", "Emily Pitler", "Tony Bruguier", "Keisuke Kinoshita", "Chrysovalantis Anastasiou", "Nilpa Jha", "Ting Liu", "Jerome Connor", "Phil Wallis", "Philip Pham", "Eric Bailey", "Shixin Li", "Heng-Tze Cheng", "Sally Ma", "Haiqiong Li", "Akanksha Maurya", "Kate Olszewska", "Manfred Warmuth", "Christy Koh", "Dominik Paulus", "Siddhartha Reddy Jonnalagadda", "Enrique Piqueras", "Ali Elqursh", "Geoff Brown", "Hadar Shemtov", "Loren Maggiore", "Fei Xia", "Ryan Foley", "Beka Westberg", "George van den Driessche", "Livio Baldini Soares", "Arjun Kar", "Michael Quinn", "Siqi Zuo", "Jialin Wu", "Kyle Kastner", "Anna Bortsova", "Aijun Bai", "Ales Mikhalap", "Luowei Zhou", "Jennifer Brennan", "Vinay Ramasesh", "Honglei Zhuang", "John Maggs", "Johan Schalkwyk", "Yuntao Xu", "Hui Huang", "Andrew Howard", "Sasha Brown", "Linting Xue", "Gloria Shen", "Brian Albert", "Neha Jha", "Daniel Zheng", "Varvara Krayvanova", "Spurthi Amba Hombaiah", "Olivier Lacombe", "Gautam Vasudevan", "Dan Graur", "Tian Xie", "Meet Gandhi", "Bangju Wang", "Dustin Zelle", "Harman Singh", "Dahun Kim", "S\u00e9bastien Cevey", "Victor Ungureanu", "Natasha Noy", "Fei Liu", "Annie Xie", "Fangxiaoyu Feng", "Katerina Tsihlas", "Daniel Formoso", "Neera Vats", "Quentin Wellens", "Yinan Wang", "Niket Kumar Bhumihar", "Samrat Ghosh", "Matt Hoffman", "Tom Lieber", "Oran Lang", "Kush Bhatia", "Tom Paine", "Aroonalok Pyne", "Ronny Votel", "Madeleine Clare Elish", "Benoit Schillings", "Alex Panagopoulos", "Haichuan Yang", "Adam Raveret", "Zohar Yahav", "Shuang Liu", "Warren Chen", "Dalia El Badawy", "Nishant Agrawal", "Mohammed Badawi", "Mahdi Mirzazadeh", "Carla Bromberg", "Fan Ye", "Chang Liu", "Tatiana Sholokhova", "George-Cristian Muraru", "Gargi Balasubramaniam", "Jonathan Malmaud", "Alen Carin", "Danilo Martins", "Irina Jurenka", "Pankil Botadra", "Dave Lacey", "Richa Singh", "Mariano Schain", "Dan Zheng", "Isabelle Guyon", "Victor Lavrenko", "Seungji Lee", "Xiang Zhou", "Demis Hassabis", "Jeshwanth Challagundla", "Derek Cheng", "Nikhil Mehta", "Matthew Mauger", "Michela Paganini", "Pushkar Mishra", "Kate Lee", "Zhang Li", "Lexi Baugher", "Ondrej Skopek", "Max Chang", "Amir Zait", "Gaurav Menghani", "Lizzetth Bellot", "Guangxing Han", "Jean-Michel Sarr", "Sharat Chikkerur", "Himanshu Sahni", "Rohan Anil", "Arun Narayanan", "Chandu Thekkath", "Daniele Pighin", "Hana Strej\u010dek", "Marko Velic", "Fred Bertsch", "Manuel Tragut", "Keran Rong", "Alicia Parrish", "Kai Bailey", "Jiho Park", "Isabela Albuquerque", "Abhishek Bapna", "Rajesh Venkataraman", "Alec Kosik", "Johannes Griesser", "Zhiwei Deng", "Alek Andreev", "Qingyun Dou", "Kevin Hui", "Fanny Wei", "Xiaobin Yu", "Lei Shu", "Avia Aharon", "David Barker", "Badih Ghazi", "Sebastian Flennerhag", "Chris Breaux", "Yuchuan Liu", "Matthew Bilotti", "Josh Woodward", "Uri Alon", "Stephanie Winkler", "Tzu-Kuo Huang", "Kostas Andriopoulos", "Jo\u00e3o Gabriel Oliveira", "Penporn Koanantakool", "Berkin Akin", "Michael Wunder", "Cicero Nogueira dos Santos", "Mohammad Hossein Bateni", "Lin Yang", "Dan Horgan", "Beer Changpinyo", "Keyvan Amiri", "Min Ma", "Dayeong Lee", "Lihao Liang", "Anirudh Baddepudi", "Tejasi Latkar", "Raia Hadsell", "Jun Xu", "Hairong Mu", "Michael Han", "Aedan Pope", "Snchit Grover", "Frank Kim", "Ankit Bhagatwala", "Guan Sun", "Yamini Bansal", "Amir Globerson", "Alireza Nazari", "Samira Daruki", "Hagen Soltau", "Jane Labanowski", "Laurent El Shafey", "Matt Harvey", "Yanif Ahmad", "Elan Rosenfeld", "William Kong", "Etienne Pot", "Yi-Xuan Tan", "Aurora Wei", "Victoria Langston", "Marcel Prasetya", "Petar Veli\u010dkovi\u0107", "Richard Killam", "Robin Strudel", "Darren Ni", "Zhenhai Zhu", "Aaron Archer", "Kavya Kopparapu", "Lynn Nguyen", "Emilio Parisotto", "Hussain Masoom", "Sravanti Addepalli", "Jordan Grimstad", "Hexiang Hu", "Joss Moore", "Avinatan Hassidim", "Le Hou", "Mukund Raghavachari", "Jared Lichtarge", "Adam R. Brown", "Hilal Dib", "Natalia Ponomareva", "Justin Fu", "Yujing Zhang", "Altaf Rahman", "Joana Iljazi", "Edouard Leurent", "Gabriel Dulac-Arnold", "Cosmo Du", "Chulayuth Asawaroengchai", "Larry Jin", "Ela Gruzewska", "Ziwei Ji", "Benigno Uria", "Daniel De Freitas", "Paul Barham", "Lauren Beltrone", "V\u00edctor Campos", "Jun Yan", "Neel Kovelamudi", "Arthur Nguyen", "Elinor Davies", "Zhichun Wu", "Zoltan Egyed", "Kristina Toutanova", "Nithya Attaluri", "Hongliang Fei", "Peter Stys", "Siddhartha Brahma", "Martin Izzard", "Siva Velusamy", "Scott Lundberg", "Vincent Zhuang", "Kevin Sequeira", "Adam Santoro", "Ehsan Amid", "Ophir Aharoni", "Shuai Ye", "Mukund Sundararajan", "Lijun Yu", "Yu-Cheng Ling", "Stephen Spencer", "Hugo Song", "Josip Djolonga", "Christo Kirov", "Sonal Gupta", "Alessandro Bissacco", "Clemens Meyer", "Mukul Bhutani", "Andrew Dai", "Weiyi Wang", "Siqi Liu", "Ashwin Sreevatsa", "Qijun Tan", "Maria Wang", "Lucy Kim", "Yicheng Wang", "Alex Irpan", "Yang Xiao", "Stanislav Fort", "Yifan He", "Alex Gurney", "Bryan Gale", "Yue Ma", "Monica Roy", "Viorica Patraucean", "Taylan Bilal", "Golnaz Ghiasi", "Anahita Hosseini", "Melvin Johnson", "Zhuowan Li", "Yi Tay", "Benjamin Beyret", "Katie Millican", "Josef Broder", "Mayank Lunayach", "Danny Swisher", "Eugen Vu\u0161ak", "David Parkinson", "MH Tessler", "Adi Mayrav Gilady", "Richard Song", "Allan Dafoe", "Yves Raimond", "Masa Yamaguchi", "Itay Karo", "Elizabeth Nielsen", "Kevin Kilgour", "Mike Dusenberry", "Rajiv Mathews", "Jiho Choi", "Siyuan Qiao", "Harsh Mehta", "Sahitya Potluri", "Chris Knutsen", "Jialu Liu", "Tat Tan", "Kuntal Sengupta", "Keerthana Gopalakrishnan", "Abodunrinwa Toki", "Mencher Chiang", "Mike Burrows", "Grace Vesom", "Zafarali Ahmed", "Ilia Labzovsky", "Siddharth Vashishtha", "Preeti Singh", "Ankur Sharma", "Ada Ma", "Jinyu Xie", "Pranav Talluri", "Hannah Forbes-Pollard", "Aarush Selvan", "Joel Wee", "Loic Matthey", "Tom Funkhouser", "Parthasarathy Gopavarapu", "Lev Proleev", "Cheng Li", "Matt Thomas", "Kashyap Kolipaka", "Zhipeng Jia", "Ashwin Kakarla", "Srinivas Sunkara", "Joan Puigcerver", "Suraj Satishkumar Sheth", "Emily Graves", "Chen Wang", "Sadh MNM Khan", "Kai Kang", "Shyamal Buch", "Fred Zhang", "Omkar Savant", "David Soergel", "Kevin Lee", "Linda Friso", "Xuanyi Dong", "Rahul Arya", "Shreyas Chandrakaladharan", "Connor Schenck", "Greg Billock", "Tejas Iyer", "Anton Bakalov", "Leslie Baker", "Alex Ruiz", "Angad Chandorkar", "Trieu Trinh", "Matt Miecnikowski", "Yanqi Zhou", "Yangsibo Huang", "Jiazhong Nie", "Ali Shah", "Ashish Thapliyal", "Sam Haves", "Lun Wang", "Uri Shaham", "Patrick Morris-Suzuki", "Soroush Radpour", "Leonard Berrada", "Thomas Strohmann", "Chaochao Yan", "Jingwei Shen", "Sonam Goenka", "Tris Warkentin", "Petar Devi\u0107", "Dan Belov", "Albert Webson", "Madhavi Yenugula", "Puranjay Datta", "Jerry Chang", "Nimesh Ghelani", "Aviral Kumar", "Vincent Perot", "Jessica Lo", "Yang Song", "Herman Schmit", "Jianmin Chen", "Vasilisa Bashlovkina", "Xiaoyue Pan", "Diana Mincu", "Paul Roit", "Isabel Edkins", "Andy Davis", "Yujia Li", "Ben Horn", "Xinjian Li", "Pradeep Kumar S", "Eric Doi", "Wanzheng Zhu", "Sri Gayatri Sundara Padmanabhan", "Siddharth Verma", "Jasmine Liu", "Heng Chen", "Mihajlo Velimirovi\u0107", "Malcolm Reynolds", "Priyanka Agrawal", "Nick Sukhanov", "Abhinit Modi", "Siddharth Goyal", "John Palowitch", "Nima Khajehnouri", "Wing Lowe", "David Klinghoffer", "Sharon Silver", "Vinh Tran", "Candice Schumann", "Francesco Piccinno", "Xi Liu", "Mario Lu\u010di\u0107", "Xiaochen Yang", "Sandeep Kumar", "Ajay Kannan", "Ragha Kotikalapudi", "Mudit Bansal", "Fabian Fuchs", "Javad Hosseini", "Abdelrahman Abdelhamed", "Dawn Bloxwich", "Tianhe Yu", "Ruoxin Sang", "Gregory Thornton", "Karan Gill", "Yuchi Liu", "Virat Shejwalkar", "Jason Lin", "Zhipeng Yan", "Kehang Han", "Thomas Buschmann", "Michael Pliskin", "Zhi Xing", "Susheel Tatineni", "Junlin Zhang", "Sissie Hsiao", "Gavin Buttimore", "Marcus Wu", "Zefei Li", "Geza Kovacs", "Legg Yeung", "Tao Huang", "Aaron Cohen", "Bethanie Brownfield", "Averi Nowak", "Mikel Rodriguez", "Tianze Shi", "Hado van Hasselt", "Kevin Cen", "Deepanway Ghoshal", "Kushal Majmundar", "Weiren Yu", "Warren", "Chen", "Danila Sinopalnikov", "Hao Zhang", "Vlado Gali\u0107", "Di Lu", "Zeyu Zheng", "Maggie Song", "Gary Wang", "Gui Citovsky", "Swapnil Gawde", "Isaac Galatzer-Levy", "David Silver", "Ivana Balazevic", "Dipanjan Das", "Kingshuk Majumder", "Yale Cong", "Praneet Dutta", "Dustin Tran", "Hui Wan", "Junwei Yuan", "Daniel Eppens", "Alanna Walton", "Been Kim", "Harry Ragan", "James Cobon-Kerr", "Lu Liu", "Weijun Wang", "Bryce Petrini", "Jack Rae", "Rakesh Shivanna", "Yan Xiong", "Chace Lee", "Pauline Coquinot", "Yiming Gu", "Lisa Patel", "Blake Hechtman", "Aviel Boag", "Orion Jankowski", "Alex Wertheim", "Alex Lee", "Paul Covington", "Hila Noga", "Sam Sobell", "Shanthal Vasanth", "William Bono", "Chirag Nagpal", "Wei Fan", "Xavier Garcia", "Kedar Soparkar", "Aybuke Turker", "Nathan Howard", "Sachit Menon", "Yuankai Chen", "Vikas Verma", "Vladimir Pchelin", "Harish Rajamani", "Valentin Dalibard", "Ana Ramalho", "Yang Guo", "Kartikeya Badola", "Seojin Bang", "Nathalie Rauschmayr", "Julia Proskurnia", "Sudeep Dasari", "Xinyun Chen", "Mikhail Sushkov", "Anja Hauth", "Pauline Sho", "Abhinav Singh", "Bilva Chandra", "Allie Culp", "Max Dylla", "Olivier Bachem", "James Besley", "Heri Zhao", "Timothy Lillicrap", "Wei Wei", "Wael Al Jishi", "Ning Niu", "Alban Rrustemi", "Rapha\u00ebl Lopez Kaufman", "Ryan Poplin", "Jewel Zhao", "Minh Truong", "Shikhar Bharadwaj", "Ester Hlavnova", "Eli Stickgold", "Cordelia Schmid", "Georgi Stephanov", "Zhaoqi Leng", "Frederick Liu", "L\u00e9onard Hussenot", "Shenil Dodhia", "Juliana Vicente Franco", "Lesley Katzen", "Abhanshu Sharma", "Sarah Cogan", "Zuguang Yang", "Aniket Ray", "Sergi Caelles", "Shen Yan", "Ravin Kumar", "Daniel Gillick", "Renee Wong", "Joshua Ainslie", "Jonathan Hoech", "S\u00e9b Arnold", "Dan Abolafia", "Anca Dragan", "Ben Hora", "Grace Hu", "Alexey Guseynov", "Yang Lu", "Chas Leichner", "Jinmeng Rao", "Abhimanyu Goyal", "Nagabhushan Baddi", "Daniel Hernandez Diaz", "Tim McConnell", "Max Bain", "Jake Abernethy", "Qiqi Yan", "Rylan Schaeffer", "Paul Vicol", "Will Thompson", "Montse Gonzalez Arenas", "Mathias Bellaiche", "Pablo Barrio", "Stefan Zinke", "Riccardo Patana", "Pulkit Mehta", "JK Kearns", "Avraham Ruderman", "Scott Pollom", "David D'Ambrosio", "Cath Hope", "Yang Yu", "Andrea Gesmundo", "Kuang-Huei Lee", "Aviv Rosenberg", "Yiqian Zhou", "Yaoyiran Li", "Drew Garmon", "Yonghui Wu", "Safeen Huda", "Gil Fidel", "Martin Baeuml", "Jian Li", "Phoebe Kirk", "Rhys May", "Tao Tu", "Sara Mc Carthy", "Toshiyuki Fukuzawa", "Miranda Aperghis", "Chih-Kuan Yeh", "Toshihiro Yoshino", "Bo Li", "Austin Myers", "Kaisheng Yao", "Ben Limonchik", "Changwan Ryu", "Rohun Saxena", "Alex Goldin", "Ruizhe Zhao", "Rocky Rhodes", "Tao Zhu", "Divya Tyam", "Heidi Howard", "Nathan Byrd", "Hongxu Ma", "Yan Wu", "Ryan Mullins", "Qingze Wang", "Aida Amini", "Sebastien Baur", "Yiran Mao", "Subhashini Venugopalan", "Will Song", "Wen Ding", "Paul Collins", "Sashank Reddi", "Megan Shum", "Andrei Rusu", "Luisa Zintgraf", "Kelvin Chan", "Sheela Goenka", "Mathieu Blondel", "Michael Collins", "Renke Pan", "Marissa Giustina", "Nikolai Chinaev", "Christian Schuler", "Ce Zheng", "Jonas Valfridsson", "Alyssa Loo", "Alex Yakubovich", "Jamie Smith", "Tao Jiang", "Rich Munoz", "Gabriel Barcik", "Rishabh Bansal", "Mingyao Yang", "Yilun Du", "Pablo Duque", "Mary Phuong", "Alexandra Belias", "Kunal Lad", "Zeyu Liu", "Tal Schuster", "Karthik Duddu", "Jieru Hu", "Paige Kunkle", "Matthew Watson", "Jackson Tolins", "Josh Smith", "Denis Teplyashin", "Garrett Bingham", "Marvin Ritter", "Marco Andreetto", "Divya Pitta", "Mohak Patel", "Shashank Viswanadha", "Trevor Strohman", "Catalin Ionescu", "Jincheng Luo", "Yogesh Kalley", "Jeremy Wiesner", "Dan Deutsch", "Derek Lockhart", "Peter Choy", "Rumen Dangovski", "Chawin Sitawarin", "Cat Graves", "Tanya Lando", "Joost van Amersfoort", "Ndidi Elue", "Zhouyuan Huo", "Pooya Moradi", "Jean Tarbouriech", "Henryk Michalewski", "Wenting Ye", "Eunyoung Kim", "Alex Druinsky", "Florent Altch\u00e9", "Xinyi Chen", "Artur Dwornik", "Da-Cheng Juan", "Rivka Moroshko", "Horia Toma", "Jarrod Kahn", "Hai Qian", "Maximilian Sieb", "Irene Cai", "Roman Goldenberg", "Praneeth Netrapalli", "Sindhu Raghuram", "Yuan Gong", "Lijie Fan", "Evan Palmer", "Yossi Matias", "Valentin Gabeur", "Shreya Pathak", "Tom Ouyang", "Don Metzler", "Geoff Bacon", "Srinivasan Venkatachary", "Sridhar Thiagarajan", "Alex Cullum", "Eran Ofek", "Vytenis Sakenas", "Mohamed Hammad", "Cesar Magalhaes", "Mayank Daswani", "Oscar Chang", "Ashok Popat", "Ruichao Li", "Komal Jalan", "Yanhan Hou", "Josh Lipschultz", "Antoine He", "Wenhao Jia", "Pier Giuseppe Sessa", "Prateek Kolhar", "William Wong", "Sumeet Singh", "Lukas Haas", "Jay Whang", "Hanna Klimczak-Pluci\u0144ska", "Georges Rotival", "Grace Chung", "Yiqing Hua", "Anfal Siddiqui", "Nicolas Serrano", "Dongkai Chen", "Billy Porter", "Libin Bai", "Keshav Shivam", "Sho Arora", "Partha Talukdar", "Tom Cobley", "Sangnie Bhardwaj", "Evgeny Gladchenko", "Simon Green", "Kelvin Guu", "Felix Fischer", "Xiao Wu", "Eric Wang", "Achintya Singhal", "Tatiana Matejovicova", "James Martens", "Hongji Li", "Roma Patel", "Elizabeth Kemp", "Jiaqi Pan", "Lily Wang", "Blake JianHang Chen", "Jean-Baptiste Alayrac", "Navneet Potti", "Erika Gemzer", "Eugene Ie", "Kay McKinney", "Takaaki Saeki", "Edward Chou", "Pascal Lamblin", "SQ Mah", "Zach Fisher", "Martin Chadwick", "Jon Stritar", "Obaid Sarvana", "Andrew Hogue", "Artem Shtefan", "Hadi Hashemi", "Yang Xu", "Jindong Gu", "Sharad Vikram", "Chung-Ching Chang", "Sabela Ramos", "Logan Kilpatrick", "Weijuan Xi", "Jenny Brennan", "Yinghao Sun", "Abhishek Jindal", "Ionel Gog", "Dawn Chen", "Felix Wu", "Jason Lee", "Sudhindra Kopalle", "Srinadh Bhojanapalli", "Oriol Vinyals", "Natan Potikha", "Burcu Karagol Ayan", "Yuan Yuan", "Michael Riley", "Piotr Stanczyk", "Sergey Kishchenko", "Bing Wang", "Dan Garrette", "Antoine Yang", "Vlad Feinberg", "CJ Carey", "Javad Azizi", "Viral Shah", "Erica Moreira", "Chongyang Shi", "Josh Feldman", "Elizabeth Salesky", "Thomas Lampe", "Aneesh Pappu", "Duhyeon Kim", "Jonas Adler", "Avi Caciularu", "Brian Walker", "Yunhan Xu", "Yochai Blau", "Dylan Scandinaro", "Terry Huang", "Sam El-Husseini", "Abhishek Sinha", "Lijie Ren", "Taylor Tobin", "Patrik Sundberg", "Tim Sohn", "Vikas Yadav", "Mimi Ly", "Emily Xue", "Jing Xiong", "Afzal Shama Soudagar", "Sneha Mondal", "Nikhil Khadke", "Qingchun Ren", "Ben Vargas", "Stan Bileschi", "Sarah Chakera", "Cindy Wang", "Boyu Wang", "Yoni Halpern", "Joe Jiang", "Vikas Sindhwani", "Petre Petrov", "Pranavaraj Ponnuramu", "Sanket Vaibhav Mehta", "Yu Watanabe", "Betty Chan", "Matheus Wisniewski", "Trang Pham", "Jingwei Zhang", "Conglong Li", "Dario de Cesare", "Art Khurshudov", "Alex Vasiloff", "Melissa Tan", "Zoe Ashwood", "Bobak Shahriari", "Maryam Majzoubi", "Garrett Tanzer", "Olga Kozlova", "Robin Alazard", "James Lee-Thorp", "Nguyet Minh Phu", "Isaac Tian", "Junwhan Ahn", "Andy Crawford", "Lauren Lax", "Yuan", "Shangguan", "Iftekhar Naim", "David Ross", "Oleksandr Ferludin", "Tongfei Guo", "Andrea Banino", "Hubert Soyer", "Xiaoen Ju", "Dominika Rogozi\u0144ska", "Ishaan Malhi", "Marcella Valentine", "Daniel Balle", "Apoorv Kulshreshtha", "Maciej Kula", "Yiwen Song", "Sophia Austin", "John Schultz", "Roy Hirsch", "Arthur Douillard", "Apoorv Reddy", "Michael Fink", "Summer Yue", "Khyatti Gupta", "Adam Zhang", "Norman Rink", "Daniel McDuff", "Lei Meng", "Andr\u00e1s Gy\u00f6rgy", "Yasaman Razeghi", "Ricky Liang", "Kazuki Osawa", "Aviel Atias", "Matan Eyal", "Tyrone Hill", "Nikolai Grigorev", "Zhengdong Wang", "Nitish Kulkarni", "Rachel Soh", "Ivan Lobov", "Zachary Charles", "Sid Lall", "Kazuma Hashimoto", "Ido Kessler", "Victor Gomes", "Zelda Mariet", "Danny Driess", "Alessandro Agostini", "Canfer Akbulut", "Jingcao Hu", "Marissa Ikonomidis", "Emily Caveness", "Kartik Audhkhasi", "Saurabh Agrawal", "Ioana Bica", "Evan Senter", "Jayaram Mudigonda", "Kelly Chen", "Jingchen Ye", "Xuanhui Wang", "James Svensson", "Philipp Fr\u00e4nken", "Josh Newlan", "Li Lao", "Eva Schnider", "Sami Alabed", "Joseph Kready", "Jesse Emond", "Afief Halumi", "Tim Zaman", "Chengxi Ye", "Naina Raisinghani", "Vilobh Meshram", "Bo Chang", "Ankit Singh Rawat", "Axel Stjerngren", "Sergey Levi", "Rui Wang", "Xiangzhu Long", "Mitchelle Rasquinha", "Steven Hand", "Aditi Mavalankar", "Lauren Agubuzu", "Sudeshna Roy", "Junquan Chen", "Jarek Wilkiewicz", "Hao Zhou", "Michal Jastrzebski", "Qiong Hu", "Agustin Dal Lago", "Ramya Sree Boppana", "Wei-Jen Ko", "Jennifer Prendki", "Yao Su", "Zhi Li", "Eliza Rutherford", "Girish Ramchandra Rao", "Ramona Comanescu", "Adri\u00e0 Puigdom\u00e8nech", "Qihang Chen", "Dessie Petrova", "Christine Chan", "Vedrana Milutinovic", "Felipe Tiengo Ferreira", "Chin-Yi Cheng", "Ming Zhang", "Tapomay Dey", "Sherry Yang", "Ramesh Sampath", "Quoc Le", "Howard Zhou", "Chu-Cheng Lin", "Hoi Lam", "Christine Kaeser-Chen", "Kai Hui", "Dean Hirsch", "Tom Eccles", "Basil Mustafa", "Shruti Rijhwani", "Morgane Rivi\u00e8re", "Yuanzhong Xu", "Junjie Wang", "Xinyang Geng", "Xiance Si", "Arjun Khare", "Cheolmin Kim", "Vahab Mirrokni", "Kamyu Lee", "Khuslen Baatarsukh", "Nathaniel Braun", "Lisa Wang", "Pallavi LV", "Richard Tanburn", "Yuvein", "Zhu", "Fangda Li", "Setareh Ariafar", "Dan Goldberg", "Ken Burke", "Daniil Mirylenka", "Meiqi Guo", "Olaf Ronneberger", "Hadas Natalie Vogel", "Liqun Cheng", "Nishita Shetty", "Johnson Jia", "Thomas Jimma", "Corey Fry", "Ted Xiao", "Martin Sundermeyer", "Ryan Burnell", "Yannis Assael", "Mario Pinto", "JD Chen", "Rohit Sathyanarayana", "Donghyun Cho", "Jing Lu", "Rishabh Agarwal", "Sugato Basu", "Lucas Gonzalez", "Dhruv Shah", "Meng Wei", "Dre Mahaarachchi", "Rohan Agrawal", "Tero Rissa", "Yani Donchev", "Ramiro Leal-Cavazos", "Adrian Hutter", "Markus Mircea", "Alon Jacovi", "Faruk Ahmed", "Jiageng Zhang", "Shuguang Hu", "Bo-Juen Chen", "Jonni Kanerva", "Guillaume Desjardins", "Andrew Lee", "Nikos Parotsidis", "Asier Mujika", "Tobias Weyand", "Jasper Snoek", "Jo Chick", "Kai Chen", "Paul Chang", "Ethan Mahintorabi", "Zi Wang", "Tolly Powell", "Orgad Keller", "Abhirut Gupta", "Claire Sha", "Kanav Garg", "Nicolas Heess", "\u00c1goston Weisz", "Cassidy Hardin", "Bartek Wydrowski", "Ben Coleman", "Karina Zainullina", "Pankaj Joshi", "Alessandro Epasto", "Terry Spitz", "Binbin Xiong", "Kai Zhao", "Arseniy Klimovskiy", "Ivy Zheng", "Johan Ferret", "Itay Yona", "Waleed Khawaja", "Jean-Baptiste Lespiau", "Maxim Krikun", "Siamak Shakeri", "Timothee Cour", "Bonnie Li", "Igor Krivokon", "Dan Suh", "Alex Hofer", "Jad Al Abdallah", "Nikita Putikhin", "Oscar Akerlund", "Silvio Lattanzi", "Anurag Kumar", "Shane Settle", "Himanshu Srivastava", "Folawiyo Campbell-Ajala", "Edouard Rosseel", "Mihai Dorin Istin", "Nishanth Dikkala", "Anand Rao", "Nick Young", "Kate Lin", "Dhruva Bhaswar", "Yiming Wang", "Jaume Sanchez Elias", "Kritika Muralidharan", "James Keeling", "Dayou Du", "Siddharth Gopal", "Gregory Dibb", "Charles Blundell", "Manolis Delakis", "Jacky Liang", "Marco Tulio Ribeiro", "Georgi Karadzhov", "Guillermo Garrido", "Ankur Bapna", "Jiawei Cao", "Adam Sadovsky", "Pouya Tafti", "Arthur Guez", "Coline Devin", "Yixian Di", "Jinwei Xing", "Chuqiao", "Xu", "Hanzhao Lin", "Chun-Te Chu", "Sameera Ponda", "Wesley Helmholz", "Fan Yang", "Yue Gao", "Sara Javanmardi", "Wael Farhan", "Alex Ramirez", "Ricardo Figueira", "Khe Chai Sim", "Yuval Bahat", "Ashwin Vaswani", "Liangzhe Yuan", "Gufeng Zhang", "Leland Rechis", "Hanjun Dai", "Tayo Oguntebi", "Alexandra Cordell", "Eug\u00e9nie Rives", "Kaan Tekelioglu", "Naveen Kumar", "Bing Zhang", "Aurick Zhou", "Nikolay Savinov", "Andrew Leach", "Alex Tudor", "Sanjay Ganapathy", "Yanyan Zheng", "Mirko Rossini", "Vera Axelrod", "Arnaud Autef", "Yukun Zhu", "Zheng Zheng", "Mingda Zhang", "Baochen Sun", "Jie Ren", "Nenad Tomasev", "Nithish Kannan", "Amer Sinha", "Charles Chen", "Louis O'Bryan", "Alex Pak", "Aditya Kusupati", "Weel Yang", "Deepak Ramachandran", "Patrick Griffin", "Seokhwan Kim", "Philipp Neubeck", "Craig Schiff", "Tammo Spalink", "Mingyang Ling", "Arun Nair", "Ga-Young Joung", "Linda Deng", "Avishkar Bhoopchand", "Lora Aroyo", "Tom Duerig", "Jordan Griffith", "Gabe Barth-Maron", "Jake Ades", "Alex Haig", "Ankur Taly", "Yunting Song", "Paul Michel", "Dave Orr", "Dean Weesner", "Corentin Tallec", "Carrie Grimes Bostock", "Paul Niemczyk", "Andy Twigg", "Mudit Verma", "Rohith Vallu", "Henry Wang", "Marco Gelmi", "Kiranbir Sodhia", "Aleksandr Chuklin", "Omer Goldman", "Jasmine George", "Liang Bai", "Kelvin Zhang", "Petar Sirkovic", "Efrat Nehoran", "Golan Pundak", "Jiaqi Mu", "Alice Chen", "Alex Greve", "Paulo Zacchello", "David Amos", "Heming Ge", "Eric Noland", "Colton Bishop", "Jeffrey Dudek", "Youhei Namiki", "Elena Buchatskaya", "Jing Li", "Dorsa Sadigh", "Masha Samsikova", "Dan Malkin", "Damien Vincent", "Robert David", "Rob Willoughby", "Phoenix Meadowlark", "Shawn Gao", "Yan Li", "Raj Apte", "Amit Jhindal", "Stein Xudong Lin", "Alex Polozov", "Zhicheng Wang", "Tomas Mery", "Anirudh GP", "Varun Yerram", "Sage Stevens", "Tianqi Liu", "Noah Fiedel", "Charles Sutton", "Matthew Johnson", "Xiaodan Song", "Kate Baumli", "Nir Shabat", "Muqthar Mohammad", "Hao Liu", "Marco Selvi", "Yichao Zhou", "Mehdi Hafezi Manshadi", "Chu-ling Ko", "Anthony Chen", "Michael Bendersky", "Jorge Gonzalez Mendez", "Nisarg Kothari", "Amir Zandieh", "Yiling Huang", "Daniel Andor", "Ellie Pavlick", "Idan Brusilovsky", "Jitendra Harlalka", "Sally Goldman", "Andrew Lampinen", "Guowang Li", "Asahi Ushio", "Somit Gupta", "Lei Zhang", "Chuyuan Kelly Fu", "Madhavi Sewak", "Timo Denk", "Jed Borovik", "Brendan Jou", "Avital Zipori", "Prateek Jain", "Junwen Bai", "Thang Luong", "Jonathan Tompson", "Alice Li", "Li Liu", "George Powell", "Jiajun Shen", "Alex Feng", "Grishma Chole", "Da Yu", "Yinlam Chow", "Tongxin Yin", "Eric Malmi", "Kefan Xiao", "Yash Pande", "Shachi Paul", "Niccol\u00f2 Dal Santo", "Adil Dostmohamed", "Sergio Guadarrama", "Aaron Phillips", "Thanumalayan Sankaranarayana Pillai", "Gal Yona", "Amin Ghafouri", "Preethi Lahoti", "Benjamin Lee", "Dhruv Madeka", "Eren Sezener", "Simon Tokumine", "Adrian Collister", "Nicola De Cao", "Richard Shin", "Uday Kalra", "Parker Beak", "Emily Nottage", "Ryo Nakashima", "Ivan Jurin", "Vikash Sehwag", "Meenu Gaba", "Junhao Zeng", "Kevin R. McKee", "Fernando Pereira", "Tamar Yakar", "Amayika Panda", "Arka Dhar", "Peilin Zhong", "Daniel Sohn", "Mark Brand", "Lars Lowe Sjoesund", "Viral Carpenter", "Sharon Lin", "Shantanu Thakoor", "Marcus Wainwright", "Ashwin Chaugule", "Pranesh Srinivasan", "Muye Zhu", "Bernett Orlando", "Jack Weber", "Ayzaan Wahid", "Gilles Baechler", "Apurv Suman", "Jovana Mitrovi\u0107", "Gabe Taubman", "Honglin Yu", "Helen King", "Josh Dillon", "Cathy Yip", "Dhriti Varma", "Tomas Izo", "Levent Bolelli", "Borja De Balle Pigem", "Julia Di Trapani", "Fotis Iliopoulos", "Adam Paszke", "Nishant Ranka", "Joe Zou", "Francesco Pongetti", "Jed McGiffin", "Alex Siegman", "Rich Galt", "Ross Hemsley", "Goran \u017du\u017ei\u0107", "Victor Carbune", "Tao Li", "Myle Ott", "F\u00e9lix de Chaumont Quitry", "David Vilar Torres", "Yuri Chervonyi", "Tomy Tsai", "Prem Eruvbetine", "Samuel Yang", "Matthew Denton", "Jake Walker", "Slavica Anda\u010di\u0107", "Idan Heimlich Shtacher", "Vittal Premachandran", "Harshal Tushar Lehri", "Cip Baetu", "Damion Yates", "Lampros Lamprou", "Mariko Iinuma", "Ioana Mihailescu", "Ben Albrecht", "Shachi Dave", "Susie Sargsyan", "Bryan Perozzi", "Lucas Manning", "Chiyuan Zhang", "Denis Vnukov", "Igor Mordatch", "Raia Hadsell Wolfgang Macherey", "Ryan Kappedal", "Jim Stephan", "Aditya Tripathi", "Klaus Macherey", "Jun Qian", "Abhishek Bhowmick", "Shekoofeh Azizi", "R\u00e9mi Leblond", "Shiva Mohan Reddy Garlapati", "Timothy Knight", "Matthew Wiethoff", "Wei-Chih Hung", "Anelia Angelova", "Georgios Evangelopoulos", "Pawel Janus", "Dimitris Paparas", "Matthew Rahtz", "Ken Caluwaerts", "Vivek Sampathkumar", "Daniel Jarrett", "Shadi Noghabi", "Antoine Miech", "Chak Yeung", "Geoff Clark", "Henry Prior", "Fei Zheng", "Jean Pouget-Abadie", "Indro Bhattacharya", "Kalpesh Krishna", "Will Bishop", "Zhe Yuan", "Yunxiao Deng", "Ashutosh Sathe", "Kacper Krasowiak", "Ciprian Chelba", "Cho-Jui Hsieh", "Kiran Vodrahalli", "Buhuang Liu", "Thomas K\u00f6ppe", "Amr Khalifa", "Lubo Litchev", "Pichi Charoenpanit", "Reed Roberts", "Sachin Yadav", "Yasumasa Onoe", "Desi Ivanov", "Megha Mohabey", "Vighnesh Birodkar", "Nemanja Raki\u0107evi\u0107", "Pierre Sermanet", "Vaibhav Mehta", "Krishan Subudhi", "Travis Choma", "Will Ng", "Luheng He", "Kathie Wang", "Tasos Kementsietsidis", "Shane Gu", "Mansi Gupta", "Andrew Nystrom", "Mehran Kazemi", "Timothy Chung", "Nacho Cano", "Nikhil Dhawan", "Yufei Wang", "Jiawei Xia", "Trevor Yacovone", "Eric Jia", "Mingqing Chen", "Simeon Ivanov", "Ashrith Sheshan", "Sid Dalmia", "Pawe\u0142 Stradomski", "Pengcheng Yin", "Salem Haykal", "Congchao Wang", "Dennis Duan", "Neslihan Bulut", "Greg Kochanski", "Liam MacDermed", "Namrata Godbole", "Shitao Weng", "Jingjing Chen", "Rachana Fellinger", "Ramin Mehran", "Daniel Suo", "Hisham Husain", "Tong He", "Kaushal Patel", "Joshua Howland", "Randall Parker", "Kelvin Nguyen", "Sharath Maddineni", "Chris Rawles", "Mina Khan", "Shlomi Cohen-Ganor", "Amol Mandhane", "Xinyi Wu", "Chenkai Kuang", "Iulia Com\u015fa", "Ramya Ganeshan", "Hanie Sedghi", "Adam Bloniarz", "Nuo Wang Pierse", "Anton Briukhov", "Petr Mitrichev", "Anita Gergely", "Serena Zhan", "Allan Zhou", "Nikita Saxena", "Eva Lu", "Josef Dean", "Ashish Gupta", "Nicolas Perez-Nieves", "Renjie Wu", "Cory McLean", "Wei Liang", "Disha Jindal", "Anton Tsitsulin", "Wenhao Yu", "Kaiz Alarakyia", "Tom Schaul", "Piyush Patil", "Peter Sung", "Elijah Peake", "Hongkun Yu", "Feryal Behbahani", "JD Co-Reyes", "Alan Ansell", "Sean Sun", "Clara Barbu", "Jonathan Lee", "Seb Noury", "James Allingham", "Bilal Piot", "Mohit Sharma", "Christopher Yew", "Ivan Korotkov", "Bibo Xu", "Demetra Brady", "Goran Petrovic", "Shibl Mourad", "Claire Cui", "Aditya Gupta", "Parker Schuh", "Saarthak Khanna", "Anna Goldie", "Abhinav Arora", "Vadim Zubov", "Amy Stuart", "Mark Epstein", "Yun Zhu", "Jianqiao Liu", "Yury Stuken", "Ziyue Wang", "Karolis Misiunas", "Dee Guo", "Ashleah Gill", "Ale Hartman", "Zaid Nabulsi", "Aurko Roy", "Aleksandra Faust", "Jason Riesa", "Ben Withbroe", "Mengchao Wang", "Marco Tagliasacchi", "Andreea Marzoca", "James Noraky", "Serge Toropov", "Malika Mehrotra", "Bahram Raad", "Sanja Deur", "Steve Xu", "Marianne Monteiro", "Zhongru Wu", "Yi Luan", "Sam Ritter", "Nick Li", "H\u00e5vard Garnes", "Yanzhang He", "Martin Zlocha", "Jifan Zhu", "Matteo Hessel", "Will Wu", "Spandana Raj Babbula", "Chizu Kawamoto", "Yuanzhen Li", "Mehadi Hassen", "Yan Wang", "Brian Wieder", "James Freedman", "Yin Zhang", "Xinyi Bai", "Tianli Yu", "David Reitter", "XiangHai Sheng", "Mateo Wirth", "Aditya Kini", "Dima Damen", "Mingcen Gao", "Rachel Hornung", "Michael Voznesensky", "Brian Roark", "Adhi Kuncoro", "Yuxiang Zhou", "Rushin Shah", "Anthony Brohan", "Kuangyuan Chen", "James Wendt", "David Rim", "Paul Kishan Rubenstein", "Jonathan Halcrow", "Michelle Liu", "Ty Geri", "Yunhsuan Sung", "Jane Shapiro", "Shaan Bijwadia", "Chris Duvarney", "Christina Sorokin", "Paul Natsev", "Reeve Ingle", "Pramod Gupta", "Young Maeng", "Ndaba Ndebele", "Kexin Zhu", "Valentin Anklin", "Katherine Lee", "Yuan Liu", "Yaroslav Akulov", "Shaleen Gupta", "Guolong Su", "Flavien Prost", "Tianlin Liu", "Vitaly Kovalev", "Pol Moreno", "Martin Scholz", "Sam Redmond", "Zongwei Zhou", "Alex Castro-Ros", "Andr\u00e9 Susano Pinto", "Dia Kharrat", "Michal Yarom", "Rachel Saputro", "Jannis Bulian", "Ben Caine", "Ji Liu", "Abbas Abdolmaleki", "Shariq Iqbal", "Tautvydas Misiunas", "Mikhail Sirotenko", "Shefali Garg", "Guy Bensky", "Huan Gui", "Xuezhi Wang", "Raphael Koster", "Mike Bernico", "Da Huang", "Romal Thoppilan", "Trevor Cohn", "Ben Golan", "Wenlei Zhou", "Andrew Rosenberg", "Markus Freitag", "Tynan Gangwani", "Vincent Tsang", "Anand Shukla", "Xiaoqi Ren", "Minh Giang", "Chi Zou", "Andre Elisseeff", "Charline Le Lan", "Dheeru Dua", "Shuba Lall", "Pranav Shyam", "Frankie Garcia", "Sarah Nguyen", "Michael Guzman", "AJ Maschinot", "Marcello Maggioni", "Ming-Wei Chang", "Karol Gregor", "Lotte Weerts", "Kumaran Venkatesan", "Bogdan Damoc", "Leon Liu", "Jan Wassenberg", "Lewis Ho", "Becca Roelofs", "Majid Hadian", "Fran\u00e7ois-Xavier Aubet", "Yu Liang", "Sami Lachgar", "Danny Karmon", "Yong Cheng", "Amelio V\u00e1zquez-Reina", "Angie Chen", "Zhuyun Dai", "Andy Brock", "Shubham Agrawal", "Chenxi Pang", "Peter Garst", "Mariella Sanchez-Vargas", "Ivor Rendulic", "Aditya Ayyar", "Andrija Ra\u017enatovi\u0107", "Olivia Ma", "Roopali Vij", "Neha Sharma", "Ashwin Balakrishna", "Bingyuan Liu", "Ian Mackinnon", "Sorin Baltateanu", "Petra Poklukar", "Gabriel Ibagon", "Colin Ji", "Hongyang Jiao", "Isaac Noble", "Wojciech Stokowiec", "Zhihao Li", "Jeff Dean", "David Lindner", "Mark Omernick", "Kristen Chiafullo", "Mason Dimarco", "Vitor Rodrigues", "Vittorio Selo", "Garrett Honke", "Xintian", "Wu", "Wei He", "Adam Hillier", "Anhad Mohananey", "Vihari Piratla", "Chang Ye", "Chase Malik", "Sebastian Riedel", "Samuel Albanie", "Zi Yang", "Kenny Vassigh", "Maria Bauza", "Sheng Li", "Yiqing Tao", "Nevan Wichers", "Andrii Maksai", "Abe Ittycheriah", "Ross Mcilroy", "Bryan Seybold", "Noah Goodman", "Romina Datta", "Steven M. Hernandez", "Tian Shi", "Yony Kochinski", "Anna Bulanova", "Ken Franko", "Mikita Sazanovich", "Nicholas FitzGerald", "Praneeth Kacham", "Shubha Srinivas Raghvendra", "Vincent Hellendoorn", "Alexander Grushetsky", "Julian Salazar", "Angeliki Lazaridou", "Jason Chang", "Jan-Thorsten Peter", "Sushant Kafle", "Yann Dauphin", "Abhishek Rao", "Filippo Graziano", "Izhak Shafran", "Yuguo Liao", "Tianli Ding", "Geng Yan", "Grace Chu", "Zhao Fu", "Vincent Roulet", "Gabriel Rasskin", "Duncan Williams", "Shahar Drath", "Alex Mossin", "Raphael Hoffmann", "Jordi Orbay", "Francesco Bertolini", "Hila Sheftel", "Justin Chiu", "Siyang Xue", "Yuheng Kuang", "Ferjad Naeem", "Swaroop Nath", "Nana Nti", "Phil Culliton", "Kashyap Krishnakumar", "Michael Isard", "Pei Sun", "Ayan Chakrabarti", "Nathan Clement", "Regev Cohen", "Arissa Wongpanich", "GS Oh", "Ashwin Murthy", "Hao Zheng", "Jessica Hamrick", "Oskar Bunyan", "Suhas Ganesh", "Nitish Gupta", "Roy Frostig", "John Wieting", "Yury Malkov", "Pierre Marcenac", "Zhixin", "Lai", "Xiaodan Tang", "Mohammad Saleh", "Fedir Zubach", "Chinmay Kulkarni", "Huanjie Zhou", "Vicky Zayats", "Nan Ding", "Anshuman Tripathi", "Arijit Pramanik", "Patrik Zochbauer", "Harish Ganapathy", "Vedant Misra", "Zach Behrman", "Hugo Vallet", "Mingyang Zhang", "Mukund Sridhar", "Ye Jin", "Mohammad Babaeizadeh", "Siim P\u00f5der", "Megha Goel", "Divya Jain", "Tajwar Nasir", "Shubham Mittal", "Tim Dozat", "Diego Ardila", "Aliaksei Severyn", "Fabio Pardo", "Sammy Jerome", "Siyang Qin", "Louis Rouillard", "Amir Yazdanbakhsh", "Zizhao Zhang", "Shivani Agrawal", "Kaushik Shivakumar", "Caden Lu", "Praveen Kallakuri", "Rachita Chhaparia", "Kanishka Rao", "Charles Kwong", "Asya Fadeeva", "Shitij Nigam", "Yan Virin", "Yuan Zhang", "Balaji Venkatraman", "Beliz Gunel", "Marc Wilson", "Huiyu Wang", "Abhinav Gupta", "Xiaowei Xu", "Adrien Ali Ta\u00efga", "Kareem Mohamed", "Doug Fritz", "Daniel Rodriguez", "Zoubin Ghahramani", "Harry Askham", "Lior Belenki", "James Zhao", "Rahul Gupta", "Krzysztof Jastrz\u0119bski", "Takahiro Kosakai", "Kaan Katircioglu", "Jon Schneider", "Rina Panigrahy", "Konstantinos Bousmalis", "Peter Grabowski", "Prajit Ramachandran", "Chaitra Hegde", "Mihaela Rosca", "Angelo Scorza Scarpati", "Kyriakos Axiotis", "Ying Xu", "Zach Gleicher", "Assaf Hurwitz Michaely", "Mandar Sharma", "Sanil Jain", "Christoph Hirnschall", "Tal Marian", "Xuhui Jia", "Kevin Mather", "Kilol Gupta", "Linhai Qiu", "Nigamaa Nayakanti", "Lucian Ionita", "Steven Zheng", "Lucia Loher", "Kurt Shuster", "Igor Petrovski", "Roshan Sharma", "Rahma Chaabouni", "Angel Yeh", "James An", "Arushi Gupta", "Steven Schwarcz", "Seher Ellis", "Sam Conway-Rahman", "Javier Snaider", "Alex Zhai", "James Atwood", "Daniel Golovin", "Liqian Peng", "Te I", "Vivian Xia", "Salvatore Scellato", "Mahan Malihi", "Arthur Bra\u017einskas", "Vlad-Doru Ion", "Younghoon Jun", "James Swirhun", "Soroosh Mariooryad", "Jiao Sun", "Steve Chien", "Rey Coaguila", "Ariel Brand", "Yi Gao", "Tom Kwiatkowski", "Roee Aharoni", "Cheng-Chun Lee", "Mislav \u017dani\u0107", "Yichi Zhang", "Dan Ethier", "Vitaly Nikolaev", "Pranav Nair", "Yoav Ben Shalom", "Hen Fitoussi", "Jai Gupta", "Hongbin Liu", "Dee Cattle", "Tolga Bolukbasi", "Ben Murdoch", "Fantine Huot", "Yin Li", "Chris Hahn"], "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities", "comment": "72 pages, 17 figures", "summary": "In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and\nGemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite\nmodels. Gemini 2.5 Pro is our most capable model yet, achieving SoTA\nperformance on frontier coding and reasoning benchmarks. In addition to its\nincredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that\nexcels at multimodal understanding and it is now able to process up to 3 hours\nof video content. Its unique combination of long context, multimodal and\nreasoning capabilities can be combined to unlock new agentic workflows. Gemini\n2.5 Flash provides excellent reasoning abilities at a fraction of the compute\nand latency requirements and Gemini 2.0 Flash and Flash-Lite provide high\nperformance at low latency and cost. Taken together, the Gemini 2.X model\ngeneration spans the full Pareto frontier of model capability vs cost, allowing\nusers to explore the boundaries of what is possible with complex agentic\nproblem solving.", "AI": {"tldr": "Gemini 2.X\u7cfb\u5217\u65b0\u6a21\u578b\u540c\u65f6\u517c\u987e\u9ad8\u6027\u80fd\u4e0e\u9ad8\u6027\u4ef7\u6bd4\uff0c\u4e0d\u4ec5\u63a8\u7406\u3001\u7f16\u7801\u80fd\u529b\u5f3a\uff0c\u4e14\u652f\u6301\u591a\u6a21\u6001\u53ca\u957f\u89c6\u9891\u5904\u7406\uff0c\u80fd\u5e7f\u6cdb\u8d4b\u80fd\u590d\u6742\u667a\u80fd\u4ee3\u7406\u573a\u666f\u3002", "motivation": "\u5f53\u524d\u7528\u6237\u548c\u4f01\u4e1a\u5bf9\u80fd\u591f\u5904\u7406\u590d\u6742\u63a8\u7406\u3001\u591a\u6a21\u6001\u5185\u5bb9\u4ee5\u53ca\u4f4e\u5ef6\u8fdf\u3001\u4f4e\u6210\u672c\u7684AI\u6a21\u578b\u9700\u6c42\u4e0d\u65ad\u589e\u957f\uff0c\u540c\u65f6\u9700\u8981\u66f4\u5f3a\u667a\u80fd\u4ee3\u7406\u80fd\u529b\u4ee5\u5e94\u5bf9\u590d\u6742\u4efb\u52a1\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u591a\u79cd\u6a21\u578b\u7248\u672c\uff08\u5305\u62ecGemini 2.5 Pro\u30012.5 Flash\u30012.0 Flash\u53caFlash-Lite\uff09\uff0c\u5206\u522b\u4f18\u5316\u5728\u524d\u6cbf\u63a8\u7406\u3001\u7f16\u7801\u3001\u591a\u6a21\u6001\u7406\u89e3\u3001\u5904\u7406\u957f\u89c6\u9891\u5185\u5bb9\u7b49\u591a\u65b9\u9762\u80fd\u529b\uff0c\u5e76\u517c\u987e\u8ba1\u7b97\u4e0e\u54cd\u5e94\u901f\u5ea6\u3002", "result": "Gemini 2.5 Pro\u5728\u524d\u6cbf\u7f16\u7801\u4e0e\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86SOTA\u6c34\u5e73\uff0c\u5177\u5907\u5148\u8fdb\u7684\u591a\u6a21\u6001\u7406\u89e3\u53ca\u6700\u5927\u53d1\u7535\u4e09\u5c0f\u65f6\u89c6\u9891\u5185\u5bb9\u7684\u5904\u7406\u80fd\u529b\uff1b2.5 Flash\u5728\u4fdd\u8bc1\u4f18\u79c0\u63a8\u7406\u6548\u679c\u4e0b\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u548c\u5ef6\u8fdf\u6210\u672c\uff1b2.0 Flash\u53caFlash-Lite\u63d0\u4f9b\u9ad8\u6548\u80fd\u3001\u4f4e\u5ef6\u8fdf\u4e0e\u4f4e\u6210\u672c\u5e94\u7528\u9009\u62e9\u3002", "conclusion": "Gemini 2.X\u7cfb\u5217\u6a21\u578b\u5728\u6027\u80fd\u548c\u6210\u672c\u4e4b\u95f4\u5b9e\u73b0\u4e86\u5168\u9762\u5e73\u8861\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u591a\u79cd\u5f3a\u5927\u4e14\u5177\u9ad8\u6027\u4ef7\u6bd4\u7684\u667a\u80fd\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u6ee1\u8db3\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u9ad8\u7ea7\u63a8\u7406\u3001\u591a\u6a21\u6001\u5904\u7406\u4e0e\u590d\u6742\u4efb\u52a1\u4ee3\u7406\u9700\u6c42\u3002"}}
{"id": "2507.06373", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.06373", "abs": "https://arxiv.org/abs/2507.06373", "authors": ["Jeremy Fischer", "Ram Krishnamoorthy", "Vishal Kumar", "Mahdi Al-Husseini"], "title": "Digital Wargames to Enhance Military Medical Evacuation Decision-Making", "comment": null, "summary": "Medical evacuation is one of the United States Army's most storied and\ncritical mission sets, responsible for efficiently and expediently evacuating\nthe battlefield ill and injured. Medical evacuation planning involves designing\na robust network of medical platforms and facilities capable of moving and\ntreating large numbers of casualties. Until now, there has not been a medium to\nsimulate these networks in a classroom setting and evaluate both offline\nplanning and online decision-making performance. This work describes the\nMedical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer\nsimulation developed in Unity that replicates battlefield constraints and\nuncertainties. MEWI accurately models patient interactions at casualty\ncollection points, ambulance exchange points, medical treatment facilities, and\nevacuation platforms. Two operational scenarios are introduced: an amphibious\nisland assault in the Pacific and a Eurasian conflict across a sprawling road\nand river network. These scenarios pit students against the clock to save as\nmany casualties as possible while adhering to doctrinal lessons learned during\ndidactic training. We visualize performance data collected from two iterations\nof the MEWI Pacific scenario executed in the United States Army's Medical\nEvacuation Doctrine Course. We consider post-wargame Likert survey data from\nstudent participants and external observer notes to identify key planning\ndecision points, document medical evacuation lessons learned, and quantify\ngeneral utility. Results indicate that MEWI participation substantially\nimproves uptake of medical evacuation lessons learned and co-operative\ndecision-making. MEWI is a substantial step forward in the field of\nhigh-fidelity training tools for medical education, and our study findings\noffer critical insights into improving medical evacuation education and\noperations across the joint force.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u7f8e\u56fd\u9646\u519b\u5f00\u53d1\u7684\u533b\u7597\u540e\u9001\u5175\u68cb\u6a21\u62df\u7cfb\u7edfMEWI\uff0c\u5176\u901a\u8fc7\u4eff\u771f\u4e0e\u5b9e\u8bad\u663e\u8457\u63d0\u5347\u4e86\u533b\u5b66\u540e\u9001\u6559\u80b2\u548c\u51b3\u7b56\u6c34\u5e73\uff0c\u5e2e\u52a9\u5b66\u5458\u63d0\u9ad8\u5b9e\u6218\u533b\u7597\u540e\u9001\u80fd\u529b\uff0c\u662f\u533b\u7597\u6559\u80b2\u9ad8\u4eff\u771f\u8bad\u7ec3\u9886\u57df\u7684\u91cd\u8981\u8fdb\u5c55\u3002", "motivation": "\u7f8e\u56fd\u9646\u519b\u533b\u7597\u540e\u9001\u4efb\u52a1\u5bf9\u4e8e\u6218\u573a\u4f24\u5458\u7684\u5feb\u901f\u6551\u6cbb\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u4e00\u4e2a\u80fd\u5728\u8bfe\u5802\u73af\u5883\u4e2d\u6a21\u62df\u548c\u8bc4\u4f30\u533b\u7597\u540e\u9001\u7f51\u7edc\u53ca\u51b3\u7b56\u8868\u73b0\u7684\u5e73\u53f0\u3002\u8be5\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u533b\u7597\u540e\u9001\u6559\u5b66\u548c\u8bad\u7ec3\u63d0\u4f9b\u9ad8\u4fdd\u771f\u3001\u9ad8\u4e92\u52a8\u6027\u7684\u5de5\u5177\u3002", "method": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u6b3e\u4e09\u7ef4\u591a\u4eba\u6a21\u62df\u7cfb\u7edf\u2014\u2014\u533b\u7597\u540e\u9001\u5175\u68cb\u8ba1\u5212\uff08MEWI\uff09\uff0c\u5229\u7528Unity\u5f15\u64ce\u51c6\u786e\u5efa\u6a21\u4e86\u4f24\u5458\u96c6\u5408\u70b9\u3001\u6551\u62a4\u8c03\u6362\u70b9\u3001\u533b\u7597\u6551\u6cbb\u8bbe\u65bd\u548c\u8f6c\u8fd0\u5e73\u53f0\uff0c\u5e76\u8bbe\u7f6e\u4e86\u4e24\u79cd\u5178\u578b\u4f5c\u6218\u573a\u666f\uff08\u592a\u5e73\u6d0b\u5c9b\u5c7f\u4e24\u6816\u8fdb\u653b\u4e0e\u6b27\u4e9a\u5927\u9646\u590d\u6742\u4ea4\u901a\u7f51\u7edc\uff09\u3002\u901a\u8fc7\u5728\u7f8e\u56fd\u9646\u519b\u533b\u7597\u540e\u9001\u5b66\u672f\u8bfe\u7a0b\u4e2d\u5e94\u7528MEWI\u7cfb\u7edf\uff0c\u6536\u96c6\u53c2\u4e0e\u8005\u7ee9\u6548\u6570\u636e\u4e0e\u95ee\u5377\u8c03\u67e5\u53cd\u9988\uff0c\u540c\u65f6\u7ed3\u5408\u5916\u90e8\u89c2\u5bdf\u5458\u7b14\u8bb0\uff0c\u5206\u6790\u5173\u952e\u51b3\u7b56\u8282\u70b9\u548c\u6559\u5b66\u6548\u679c\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0cMEWI\u7684\u53c2\u4e0e\u8005\u5728\u533b\u7597\u540e\u9001\u77e5\u8bc6\u5438\u6536\u3001\u5408\u4f5c\u51b3\u7b56\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\u3002\u8be5\u7cfb\u7edf\u663e\u8457\u63d0\u9ad8\u4e86\u533b\u7597\u540e\u9001\u6559\u5b66\u7684\u9ad8\u4fdd\u771f\u5ea6\u548c\u5b9e\u6218\u76f8\u5173\u6027\uff0c\u4e5f\u4e3a\u8054\u5408\u90e8\u961f\u7684\u533b\u7597\u540e\u9001\u6559\u80b2\u548c\u8fd0\u4f5c\u63d0\u4f9b\u4e86\u5b9d\u8d35\u6539\u8fdb\u5efa\u8bae\u3002", "conclusion": "MEWI\u4e3a\u533b\u5b66\u6559\u80b2\u9886\u57df\u63d0\u4f9b\u4e86\u5148\u8fdb\u7684\u9ad8\u4fdd\u771f\u8bad\u7ec3\u5de5\u5177\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b66\u751f\u7684\u533b\u7597\u540e\u9001\u51b3\u7b56\u80fd\u529b\u548c\u6559\u80b2\u6210\u6548\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u7f8e\u519b\u53ca\u8054\u5408\u90e8\u961f\u7684\u533b\u7597\u540e\u9001\u4f5c\u4e1a\u6a21\u5f0f\u53ca\u6559\u5b66\u6d41\u7a0b\u3002\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u7c7b\u4f3c\u9ad8\u4eff\u771f\u533b\u7597\u6559\u5b66\u5de5\u5177\u7684\u5f00\u53d1\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6848\u4f8b\u4e0e\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2507.06444", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2507.06444", "abs": "https://arxiv.org/abs/2507.06444", "authors": ["Jiaxun Zhang", "Haicheng Liao", "Yumu Xie", "Chengyue Wang", "Yanchen Guan", "Bin Rao", "Zhenning Li"], "title": "Eyes on the Road, Mind Beyond Vision: Context-Aware Multi-modal Enhanced Risk Anticipation", "comment": "Accepted by ACMMM2025", "summary": "Accurate accident anticipation remains challenging when driver cognition and\ndynamic road conditions are underrepresented in predictive models. In this\npaper, we propose CAMERA (Context-Aware Multi-modal Enhanced Risk\nAnticipation), a multi-modal framework integrating dashcam video, textual\nannotations, and driver attention maps for robust accident anticipation. Unlike\nexisting methods that rely on static or environment-centric thresholds, CAMERA\nemploys an adaptive mechanism guided by scene complexity and gaze entropy,\nreducing false alarms while maintaining high recall in dynamic, multi-agent\ntraffic scenarios. A hierarchical fusion pipeline with Bi-GRU (Bidirectional\nGRU) captures spatio-temporal dependencies, while a Geo-Context Vision-Language\nmodule translates 3D spatial relationships into interpretable, human-centric\nalerts. Evaluations on the DADA-2000 and benchmarks show that CAMERA achieves\nstate-of-the-art performance, improving accuracy and lead time. These results\ndemonstrate the effectiveness of modeling driver attention, contextual\ndescription, and adaptive risk thresholds to enable more reliable accident\nanticipation.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u878d\u5408\u591a\u6a21\u6001\u4fe1\u606f\u548c\u81ea\u9002\u5e94\u673a\u5236\u7684CAMERA\u6846\u67b6\uff0c\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u4e8b\u6545\u9884\u5224\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u9886\u5148\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u4e8b\u6545\u9884\u5224\u65b9\u6cd5\u5f80\u5f80\u4f4e\u4f30\u4e86\u9a7e\u9a76\u5458\u8ba4\u77e5\u548c\u52a8\u6001\u9053\u8def\u6761\u4ef6\uff0c\u5bfc\u81f4\u5728\u590d\u6742\u4ea4\u901a\u573a\u666f\u4e2d\u51c6\u786e\u7387\u4e0d\u9ad8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCAMERA\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u6574\u5408\u4e86\u884c\u8f66\u8bb0\u5f55\u4eea\u89c6\u9891\u3001\u6587\u672c\u6ce8\u91ca\u548c\u9a7e\u9a76\u5458\u6ce8\u610f\u529b\u56fe\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u81ea\u9002\u5e94\u673a\u5236\uff0c\u6839\u636e\u573a\u666f\u590d\u6742\u5ea6\u548c\u6ce8\u89c6\u71b5\u52a8\u6001\u8c03\u6574\u98ce\u9669\u95e8\u9650\uff0c\u901a\u8fc7\u5206\u5c42\u878d\u5408\u548cBi-GRU\u6355\u6349\u65f6\u7a7a\u4f9d\u8d56\uff0c\u5e76\u7528Geo-Context\u6a21\u5757\u8f93\u51fa\u53ef\u89e3\u91ca\u7684\u98ce\u9669\u63d0\u793a\u3002", "result": "\u5728DADA-2000\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cCAMERA\u53d6\u5f97\u4e86\u4e1a\u754c\u9886\u5148\u7684\u51c6\u786e\u7387\u548c\u9884\u5224\u63d0\u524d\u91cf\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u8bef\u62a5\u7387\u5e76\u4fdd\u6301\u9ad8\u53ec\u56de\u7387\u3002", "conclusion": "\u5efa\u6a21\u9a7e\u9a76\u5458\u6ce8\u610f\u3001\u8bed\u5883\u63cf\u8ff0\u548c\u81ea\u9002\u5e94\u98ce\u9669\u95e8\u9650\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u4e8b\u6545\u9884\u5224\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.06268", "categories": ["cs.CY", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.06268", "abs": "https://arxiv.org/abs/2507.06268", "authors": ["Michael I. Jordan"], "title": "A Collectivist, Economic Perspective on AI", "comment": null, "summary": "Information technology is in the midst of a revolution in which omnipresent\ndata collection and machine learning are impacting the human world as never\nbefore. The word \"intelligence\" is being used as a North Star for the\ndevelopment of this technology, with human cognition viewed as a baseline. This\nview neglects the fact that humans are social animals, and that much of our\nintelligence is social and cultural in origin. A related issue is that the\ncurrent view treats the social consequences of technology as an afterthought.\nThe path forward is not merely more data and compute, and not merely more\nattention paid to cognitive or symbolic representations, but a thorough\nblending of economic and social concepts with computational and inferential\nconcepts, in the service of system-level designs in which social welfare is a\nfirst-class citizen, and with the aspiration that a new human-centric\nengineering field will emerge.", "AI": {"tldr": "\u4fe1\u606f\u6280\u672f\u5e94\u5173\u6ce8\u4eba\u7c7b\u793e\u4f1a\u6027\uff0c\u7cfb\u7edf\u878d\u5408\u793e\u4f1a\u3001\u7ecf\u6d4e\u548c\u63a8\u7406\u65b9\u6cd5\uff0c\u8ba9\u793e\u4f1a\u798f\u7949\u6210\u4e3a\u6280\u672f\u53d1\u5c55\u7684\u6838\u5fc3\u76ee\u6807\u3002", "motivation": "\u5f53\u524d\u4fe1\u606f\u6280\u672f\u98de\u901f\u53d1\u5c55\uff0c\u667a\u80fd\u6280\u672f\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u76ee\u524d\u4e3b\u8981\u5173\u6ce8\u4eba\u7c7b\u8ba4\u77e5\u667a\u80fd\uff0c\u5ffd\u7565\u4e86\u4eba\u7c7b\u667a\u529b\u7684\u793e\u4f1a\u6027\u4e0e\u6587\u5316\u6027\u6765\u6e90\uff0c\u5e76\u4e14\u6280\u672f\u7684\u793e\u4f1a\u5f71\u54cd\u5e38\u88ab\u4e8b\u540e\u624d\u8003\u8651\u3002", "method": "\u63d0\u51fa\u201c\u5c06\u7ecf\u6d4e\u4e0e\u793e\u4f1a\u6982\u5ff5\u548c\u8ba1\u7b97\u3001\u63a8\u7406\u65b9\u6cd5\u6df1\u5ea6\u878d\u5408\u201d\u7684\u89c2\u70b9\uff0c\u5021\u5bfc\u7cfb\u7edf\u5c42\u6b21\u4e0b\u4ee5\u793e\u4f1a\u798f\u7949\u4e3a\u6838\u5fc3\u76ee\u6807\u7684\u8bbe\u8ba1\u7406\u5ff5\u3002", "result": "\u547c\u5401\u4fe1\u606f\u6280\u672f\u548c\u4eba\u5de5\u667a\u80fd\u9886\u57df\uff0c\u8d85\u8d8a\u5355\u7eaf\u8ba4\u77e5\u548c\u7b26\u53f7\u5904\u7406\uff0c\u63a8\u52a8\u4ee5\u4eba\u4e3a\u672c\u3001\u5173\u6ce8\u793e\u4f1a\u798f\u5229\u7684\u65b0\u5de5\u79d1\u65b9\u5411\u7684\u53d1\u5c55\u3002", "conclusion": "\u6280\u672f\u53d1\u5c55\u5e94\u7efc\u5408\u8003\u91cf\u7ecf\u6d4e\u3001\u793e\u4f1a\u3001\u63a8\u7406\u7b49\u591a\u7ef4\u5ea6\u56e0\u7d20\uff0c\u628a\u793e\u4f1a\u5f71\u54cd\u4e0e\u793e\u4f1a\u798f\u7949\u6446\u5728\u9996\u8981\u4f4d\u7f6e\uff0c\u63a8\u52a8\u65b0\u65f6\u4ee3\u4ee5\u4eba\u548c\u793e\u4f1a\u4e3a\u6838\u5fc3\u7684\u6280\u672f\u5de5\u7a0b\u5b66\u79d1\u7684\u8bde\u751f\u3002"}}
{"id": "2507.06306", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.06306", "abs": "https://arxiv.org/abs/2507.06306", "authors": ["Neil Rathi", "Dan Jurafsky", "Kaitlyn Zhou"], "title": "Humans overrely on overconfident language models, across languages", "comment": "10 pages main text, to appear at COLM 2025", "summary": "As large language models (LLMs) are deployed globally, it is crucial that\ntheir responses are calibrated across languages to accurately convey\nuncertainty and limitations. Previous work has shown that LLMs are\nlinguistically overconfident in English, leading users to overrely on confident\ngenerations. However, the usage and interpretation of epistemic markers (e.g.,\n'It's definitely,' 'I think') can differ sharply across languages. Here, we\nstudy the risks of multilingual linguistic (mis)calibration, overconfidence,\nand overreliance across five languages to evaluate the safety of LLMs in a\nglobal context.\n  We find that overreliance risks are high across all languages. We first\nanalyze the distribution of LLM-generated epistemic markers, and observe that\nwhile LLMs are cross-linguistically overconfident, they are also sensitive to\ndocumented linguistic variation. For example, models generate the most markers\nof uncertainty in Japanese and the most markers of certainty in German and\nMandarin. We then measure human reliance rates across languages, finding that\nwhile users strongly rely on confident LLM generations in all languages,\nreliance behaviors differ cross-linguistically: for example, users rely\nsignificantly more on expressions of uncertainty in Japanese than in English.\nTaken together, these results indicate high risk of reliance on overconfident\nmodel generations across languages. Our findings highlight the challenges of\nmultilingual linguistic calibration and stress the importance of culturally and\nlinguistically contextualized model safety evaluations.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e94\u79cd\u8bed\u8a00\u4e0b\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u5f0f\u53ca\u5176\u5bf9\u7528\u6237\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u65e0\u8bba\u8bed\u8a00\u5982\u4f55\uff0c\u7528\u6237\u5747\u5b58\u5728\u8fc7\u5ea6\u4f9d\u8d56\u6a21\u578b\u751f\u6210\u5185\u5bb9\u7684\u98ce\u9669\uff0c\u800c\u5177\u4f53\u4f9d\u8d56\u884c\u4e3a\u53c8\u53d7\u4e0d\u540c\u8bed\u8a00\u6587\u5316\u5f71\u54cd\uff0c\u5f3a\u8c03\u4e86\u591a\u8bed\u8a00\u80cc\u666f\u4e0b\u6a21\u578b\u6821\u51c6\u4e0e\u5b89\u5168\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5168\u7403\u8303\u56f4\u5185\u90e8\u7f72\uff0c\u786e\u4fdd\u5176\u5728\u591a\u79cd\u8bed\u8a00\u4e0b\u80fd\u591f\u51c6\u786e\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\u4e0e\u5c40\u9650\u6027\u53d8\u5f97\u975e\u5e38\u91cd\u8981\u3002\u6b64\u524d\u7814\u7a76\u53d1\u73b0\uff0cLLM\u5728\u82f1\u8bed\u73af\u5883\u4e0b\u5b58\u5728\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\uff0c\u5bfc\u81f4\u7528\u6237\u8fc7\u5ea6\u4f9d\u8d56\u6a21\u578b\u751f\u6210\u5185\u5bb9\u3002\u8003\u8651\u5230\u8868\u793a\u4e0d\u786e\u5b9a\u6027\u7684\u8bed\u8a00\u6807\u8bb0\u5728\u4e0d\u540c\u8bed\u8a00\u4e2d\u6709\u663e\u8457\u5dee\u5f02\uff0c\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u591a\u8bed\u8a00\u4e0bLLM\u7684\u8bed\u8a00\u6821\u51c6\u98ce\u9669\u3001\u8fc7\u5ea6\u81ea\u4fe1\u4e0e\u8fc7\u5ea6\u4f9d\u8d56\u7b49\u5b89\u5168\u9690\u60a3\u3002", "method": "\u672c\u6587\u5bf9\u4e94\u79cd\u8bed\u8a00\u4e0bLLM\u751f\u6210\u7684\u8868\u5f81\u4e3b\u89c2\u786e\u4fe1\u5ea6\u7684\u8bed\u8a00\u6807\u8bb0\u8fdb\u884c\u5206\u6790\uff0c\u6bd4\u8f83\u5b83\u4eec\u8868\u73b0\u51fa\u7684\u81ea\u4fe1\u4e0e\u4e0d\u786e\u5b9a\u6027\u3002\u518d\u901a\u8fc7\u4eba\u7c7b\u7528\u6237\u884c\u4e3a\u6d4b\u91cf\uff0c\u4e0d\u540c\u8bed\u8a00\u73af\u5883\u4e0b\u7528\u6237\u5bf9\u6a21\u578b\u751f\u6210\u5185\u5bb9\u7684\u4f9d\u8d56\u7a0b\u5ea6\uff0c\u5206\u6790\u7528\u6237\u5bf9\u81ea\u4fe1\u548c\u4e0d\u786e\u5b9a\u8868\u8fbe\u7684\u4f9d\u8d56\u53d8\u5316\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6240\u6709\u8bed\u8a00\u4e0b\u7528\u6237\u5bf9LLM\u751f\u6210\u5185\u5bb9\u7684\u8fc7\u5ea6\u4f9d\u8d56\u98ce\u9669\u5747\u8f83\u9ad8\u3002\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u95f4\u5bf9\u4e0d\u786e\u5b9a\u6027\u6807\u8bb0\u7684\u4f7f\u7528\u5177\u6709\u4e00\u5b9a\u654f\u611f\u6027\uff0c\u5982\u65e5\u8bed\u4e2d\u751f\u6210\u7684\u4e0d\u786e\u5b9a\u8868\u8fbe\u6700\u591a\uff0c\u800c\u5fb7\u8bed\u548c\u4e2d\u6587\u4e2d\u751f\u6210\u7684\u786e\u5b9a\u8868\u8fbe\u6700\u591a\u3002\u7528\u6237\u5c42\u9762\uff0c\u4e0d\u540c\u8bed\u8a00\u80cc\u666f\u4e0b\u5bf9\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\u5185\u5bb9\u7684\u4f9d\u8d56\u5b58\u5728\u5dee\u5f02\uff1a\u4e0e\u82f1\u8bed\u76f8\u6bd4\uff0c\u65e5\u8bed\u7528\u6237\u5bf9\u4e0d\u786e\u5b9a\u8868\u8fbe\u7684\u4f9d\u8d56\u663e\u8457\u66f4\u9ad8\u3002\u6574\u4f53\u6765\u770b\uff0cLLM\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u5e7f\u6cdb\u5b58\u5728\u8fc7\u5ea6\u81ea\u4fe1\u548c\u4f9d\u8d56\u98ce\u9669\u3002", "conclusion": "LLM\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u5b58\u5728\u8f83\u9ad8\u7684\u8fc7\u5ea6\u81ea\u4fe1\u53ca\u4f9d\u8d56\u98ce\u9669\uff0c\u4e14\u6a21\u578b\u4e0e\u7528\u6237\u7684\u884c\u4e3a\u6a21\u5f0f\u53d7\u8bed\u8a00\u6587\u5316\u5f71\u54cd\uff0c\u63d0\u793a\u5f53\u524d\u6821\u51c6\u7b56\u7565\u4e0e\u5b89\u5168\u8bc4\u4f30\u9700\u5145\u5206\u8003\u8651\u591a\u8bed\u8a00\u3001\u591a\u6587\u5316\u7279\u6027\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u7684\u5168\u7403\u5b89\u5168\u6027\u4e0e\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.06396", "categories": ["cs.AI", "cs.LG", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.06396", "abs": "https://arxiv.org/abs/2507.06396", "authors": ["Mandana Vaziri", "Louis Mandel", "Yuji Watanabe", "Hirokuni Kitahara", "Martin Hirzel", "Anca Sailer"], "title": "Representing Prompting Patterns with PDL: Compliance Agent Case Study", "comment": "ICML 2025 Workshop on Programmatic Representations for Agent Learning", "summary": "Prompt engineering for LLMs remains complex, with existing frameworks either\nhiding complexity behind restrictive APIs or providing inflexible canned\npatterns that resist customization -- making sophisticated agentic programming\nchallenging. We present the Prompt Declaration Language (PDL), a novel approach\nto prompt representation that tackles this fundamental complexity by bringing\nprompts to the forefront, enabling manual and automatic prompt tuning while\ncapturing the composition of LLM calls together with rule-based code and\nexternal tools. By abstracting away the plumbing for such compositions, PDL\naims at improving programmer productivity while providing a declarative\nrepresentation that is amenable to optimization. This paper demonstrates PDL's\nutility through a real-world case study of a compliance agent. Tuning the\nprompting pattern of this agent yielded up to 4x performance improvement\ncompared to using a canned agent and prompt pattern.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86PDL\uff0c\u4e00\u79cd\u9762\u5411LLM\u63d0\u793a\u5de5\u7a0b\u7684\u65b0\u8bed\u8a00\uff0c\u5b9e\u73b0\u4e86\u63d0\u793a\u7ec4\u5408\u4e0e\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u667a\u80fd\u4f53\u5f00\u53d1\u7684\u6548\u7387\u4e0e\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63d0\u793a\u5de5\u7a0b\u4f9d\u7136\u590d\u6742\uff0c\u73b0\u6709\u6846\u67b6\u8981\u4e48\u7528\u4e25\u683c\u7684API\u9690\u85cf\u7ec6\u8282\uff0c\u8981\u4e48\u63d0\u4f9b\u96be\u4ee5\u81ea\u5b9a\u4e49\u7684\u6a21\u5f0f\uff0c\u4f7f\u5f97\u5f00\u53d1\u9ad8\u7ea7\u667a\u80fd\u4f53\u7a0b\u5e8f\u5341\u5206\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63d0\u793a\u8868\u793a\u65b9\u5f0f\uff1aPrompt Declaration Language\uff08PDL\uff09\u3002PDL\u5c06\u63d0\u793a\u663e\u6027\u5316\uff0c\u652f\u6301\u4eba\u5de5\u548c\u81ea\u52a8\u8c03\u4f18\uff0c\u5e76\u53ef\u540c\u65f6\u6574\u5408\u89c4\u5219\u4ee3\u7801\u548c\u5916\u90e8\u5de5\u5177\uff0c\u5b9e\u73b0\u9ad8\u7ea7\u7ec4\u5408\u62bd\u8c61\u3002", "result": "\u5728\u771f\u5b9e\u5408\u89c4\u4ee3\u7406\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u4f7f\u7528PDL\u8c03\u4f18\u540e\u7684\u4ee3\u7406\u76f8\u6bd4\u4e8e\u56fa\u5b9a\u6a21\u5f0f\u7684\u4ee3\u7406\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u53ef\u8fbe4\u500d\u3002", "conclusion": "PDL\u80fd\u663e\u8457\u7b80\u5316\u63d0\u793a\u5de5\u7a0b\uff0c\u63d0\u5347\u5f00\u53d1\u6548\u7387\uff0c\u5e76\u53ef\u901a\u8fc7\u58f0\u660e\u5f0f\u8868\u8fbe\u4f18\u5316LLM\u4ee3\u7406\u7a0b\u5e8f\u3002"}}
{"id": "2507.06803", "categories": ["cs.CL", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2507.06803", "abs": "https://arxiv.org/abs/2507.06803", "authors": ["Matthew Anderson Hendricks", "Alice Cicirello"], "title": "Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams", "comment": null, "summary": "This paper contributes to speeding up the design and deployment of\nengineering dynamical systems by proposing a strategy for exploiting domain and\nexpert knowledge for the automated generation of dynamical system computational\nmodel starting from a corpus of document relevant to the dynamical system of\ninterest and an input document describing the specific system. This strategy is\nimplemented in five steps and, crucially, it uses system modeling language\ndiagrams (SysML) to extract accurate information about the dependencies,\nattributes, and operations of components. Natural Language Processing (NLP)\nstrategies and Large Language Models (LLMs) are employed in specific tasks to\nimprove intermediate outputs of the SySML diagrams automated generation, such\nas: list of key nouns; list of extracted relationships; list of key phrases and\nkey relationships; block attribute values; block relationships; and BDD diagram\ngeneration. The applicability of automated SysML diagram generation is\nillustrated with different case studies. The computational models of complex\ndynamical systems from SysML diagrams are then obtained via code generation and\ncomputational model generation steps. In the code generation step, NLP\nstrategies are used for summarization, while LLMs are used for validation only.\nThe proposed approach is not limited to a specific system, domain, or\ncomputational software. The applicability of the proposed approach is shown via\nan end-to-end example from text to model of a simple pendulum, showing improved\nperformance compared to results yielded by LLMs only.", "AI": {"tldr": "\u878d\u5408NLP\u548cLLMs\u81ea\u52a8\u751f\u6210SysML\u5efa\u6a21\u56fe\uff0c\u8f85\u52a9\u5de5\u7a0b\u52a8\u529b\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u5efa\u6a21\u4e0e\u4ee3\u7801\u751f\u6210\uff0c\u63d0\u5347\u8bbe\u8ba1\u6548\u7387\uff0c\u65b9\u6cd5\u901a\u7528\u4e14\u6027\u80fd\u4f18\u4e8e\u4ec5\u7528LLMs\u7684\u65b9\u6848\u3002", "motivation": "\u5de5\u7a0b\u52a8\u529b\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u90e8\u7f72\u8fc7\u7a0b\u901a\u5e38\u8017\u65f6\u4e14\u4f9d\u8d56\u5927\u91cf\u4e13\u4e1a\u77e5\u8bc6\uff0c\u800c\u81ea\u52a8\u5316\u548c\u667a\u80fd\u5316\u624b\u6bb5\u5728\u6b64\u9886\u57df\u5e94\u7528\u4ecd\u5b58\u5728\u5c40\u9650\u3002\u8be5\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u9ad8\u6548\u5229\u7528\u9886\u57df\u77e5\u8bc6\u548c\u4e13\u5bb6\u7ecf\u9a8c\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u65b9\u5f0f\u751f\u6210\u52a8\u529b\u7cfb\u7edf\u7684\u8ba1\u7b97\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e94\u6b65\u6cd5\u7b56\u7565\uff0c\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4ee5\u7cfb\u7edf\u5efa\u6a21\u8bed\u8a00\uff08SysML\uff09\u56fe\u4e3a\u6838\u5fc3\uff0c\u81ea\u52a8\u63d0\u53d6\u6587\u6863\u4e2d\u7684\u7ec4\u4ef6\u4f9d\u8d56\u3001\u5c5e\u6027\u548c\u64cd\u4f5c\u4fe1\u606f\u3002\u5177\u4f53\u5305\u62ec\u5173\u952e\u540d\u8bcd\u63d0\u53d6\u3001\u5173\u7cfb\u62bd\u53d6\u3001\u77ed\u8bed\u53ca\u5c5e\u6027\u5f52\u7eb3\u3001\u6a21\u578b\u56fe\u81ea\u52a8\u751f\u6210\u7b49\u73af\u8282\uff0c\u5e76\u4ee5SysML\u56fe\u4e3a\u4e2d\u4ecb\uff0c\u901a\u8fc7\u4ee3\u7801\u751f\u6210\u83b7\u5f97\u6700\u7ec8\u7684\u52a8\u529b\u7cfb\u7edf\u8ba1\u7b97\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u6848\u4f8b\u5206\u6790\u8868\u660e\uff0c\u81ea\u52a8\u5316\u751f\u6210SysML\u56fe\u53ca\u540e\u7eed\u6a21\u578b\u7684\u6d41\u7a0b\u662f\u53ef\u884c\u7684\uff0c\u5e76\u5728\u4ee5\u5355\u6446\u4e3a\u4f8b\u7684\u7aef\u5230\u7aef\u6d41\u7a0b\u4e2d\uff0c\u4ece\u6587\u672c\u5230\u6a21\u578b\u7684\u8fc7\u7a0b\u5c55\u73b0\u4e86\u6bd4\u4ec5\u9760LLMs\u66f4\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u52a0\u901f\u5de5\u7a0b\u52a8\u529b\u7cfb\u7edf\u7684\u8bbe\u8ba1\u4e0e\u90e8\u7f72\u6d41\u7a0b\uff0c\u4e0d\u4f9d\u8d56\u67d0\u4e00\u7279\u5b9a\u9886\u57df\u6216\u8ba1\u7b97\u5de5\u5177\uff0c\u9002\u7528\u6027\u548c\u901a\u7528\u6027\u8f83\u5f3a\uff0c\u5e76\u5b9e\u73b0\u4e86\u4ece\u6587\u672c\u5230\u6a21\u578b\u7684\u81ea\u52a8\u9ad8\u6548\u8f6c\u6362\u3002"}}
{"id": "2507.06277", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06277", "abs": "https://arxiv.org/abs/2507.06277", "authors": ["Maxim Chupilkin"], "title": "The Prompt War: How AI Decides on a Military Intervention", "comment": "13 pages, 8 tables, 1 figure", "summary": "Which factors determine AI propensity for military intervention? While the\nuse of AI in war games and military planning is growing exponentially, the\nsimple analysis of key drivers embedded in the models has not yet been done.\nThis paper does a simple conjoint experiment proposing a model to decide on\nmilitary intervention in 640 vignettes where each was run for 100 times\nallowing to explore AI decision on military intervention systematically. The\nanalysis finds that largest predictors of AI decision to intervene are high\ndomestic support and high probability of success. Costs such as international\ncondemnation, military deaths, civilian deaths, and negative economic effect\nare statistically significant, but their effect is around half of domestic\nsupport and probability of victory. Closing window of opportunity only reaches\nstatistical significance in interaction with other factors. The results are\nremarkably consistent across scenarios and across different models (OpenAI GPT,\nAnthropic Claude, Google Gemini) suggesting a pattern in AI decision-making.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u5206\u6790\u4e86AI\u5728\u519b\u4e8b\u5e72\u9884\u51b3\u7b56\u4e2d\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u53d1\u73b0\u56fd\u5185\u652f\u6301\u548c\u6210\u529f\u6982\u7387\u6700\u5f71\u54cdAI\u51b3\u7b56\uff0c\u4e09\u5927\u4e3b\u6d41AI\u6a21\u578b\u8868\u73b0\u51fa\u4e00\u81f4\u6027\u3002", "motivation": "\u76ee\u524dAI\u5728\u519b\u4e8b\u6e38\u620f\u548c\u51b3\u7b56\u4e2d\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u591a\uff0c\u4f46\u5c1a\u672a\u6709\u7cfb\u7edf\u6027\u5730\u5206\u6790\u5176\u519b\u4e8b\u5e72\u9884\u51b3\u7b56\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\u7684\u7814\u7a76\u3002\u4f5c\u8005\u5e0c\u671b\u63ed\u793aAI\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\u66f4\u503e\u5411\u4e8e\u652f\u6301\u519b\u4e8b\u5e72\u9884\u3002", "method": "\u91c7\u7528\u8054\u5408\u5206\u6790\u5b9e\u9a8c\uff08conjoint experiment\uff09\uff0c\u8bbe\u8ba1\u4e86640\u4e2a\u60c5\u666f\uff0c\u6bcf\u4e2a\u60c5\u666f\u8fd0\u884c100\u6b21\uff0c\u7cfb\u7edf\u6027\u63a2\u8ba8AI\u5bf9\u4e8e\u662f\u5426\u8fdb\u884c\u519b\u4e8b\u5e72\u9884\u7684\u51b3\u7b56\u504f\u597d\u3002\u6d89\u53ca\u7684AI\u6a21\u578b\u5305\u62ecOpenAI GPT\u3001Anthropic Claude\u548cGoogle Gemini\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5f71\u54cdAI\u505a\u51fa\u5e72\u9884\u51b3\u7b56\u7684\u6700\u5927\u56e0\u7d20\u662f\u9ad8\u56fd\u5185\u652f\u6301\u7387\u53ca\u9ad8\u6210\u529f\u6982\u7387\u3002\u56fd\u9645\u8c34\u8d23\u3001\u58eb\u5175\u6b7b\u4ea1\u3001\u5e73\u6c11\u6b7b\u4ea1\u3001\u7ecf\u6d4e\u8d1f\u9762\u5f71\u54cd\u5bf9AI\u51b3\u7b56\u4e5f\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4f46\u8fd9\u4e9b\u56e0\u7d20\u7684\u5f71\u54cd\u529b\u7ea6\u4e3a\u524d\u4e24\u8005\u7684\u4e00\u534a\u3002\u201c\u7a97\u53e3\u673a\u4f1a\u201d\u7684\u7d27\u8feb\u6027\u53ea\u6709\u4e0e\u5176\u4ed6\u53d8\u91cf\u4ea4\u4e92\u65f6\u624d\u663e\u8457\u3002", "conclusion": "\u5404\u79cdAI\u6a21\u578b\u5bf9\u4e8e\u519b\u4e8b\u5e72\u9884\u51b3\u7b56\u7684\u504f\u597d\u6a21\u5f0f\u9ad8\u5ea6\u4e00\u81f4\uff0cAI\u503e\u5411\u4e8e\u5728\u56fd\u5185\u652f\u6301\u7387\u9ad8\u53ca\u6210\u529f\u6982\u7387\u5927\u7684\u60c5\u51b5\u4e0b\u505a\u51fa\u5e72\u9884\uff0c\u6210\u672c\u56e0\u7d20\u867d\u91cd\u8981\u4f46\u6743\u91cd\u8f83\u4f4e\u3002\u8be5\u7814\u7a76\u63ed\u793a\u4e86AI\u519b\u4e8b\u51b3\u7b56\u7684\u5185\u5728\u903b\u8f91\u3002"}}
{"id": "2507.06313", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06313", "abs": "https://arxiv.org/abs/2507.06313", "authors": ["Kiarash Zahirnia", "Zahra Golpayegani", "Walid Ahmad", "Yang Liu"], "title": "ETT: Expanding the Long Context Understanding Capability of LLMs at Test-Time", "comment": null, "summary": "Transformer-based Language Models' computation and memory overhead increase\nquadratically as a function of sequence length. The quadratic cost poses\nchallenges when employing LLMs for processing long sequences. In this work, we\nintroduce \\ourmodelacronym~(Extend at Test-Time), method for extending the\ncontext length of short context Transformer-based LLMs, with constant memory\nrequirement and linear computation overhead. ETT enable the extension of the\ncontext length at test-time by efficient fine-tuning the model's parameters on\nthe input context, chunked into overlapping small subsequences. We evaluate ETT\non LongBench by extending the context length of GPT-Large and Phi-2 up to 32\ntimes, increasing from 1k to 32k tokens. This results in up to a 30 percent\nimprovement in the model's accuracy. We also study how context can be stored in\nLLM's weights effectively and efficiently. Through a detailed ablation study,\nwe examine which Transformer modules are most beneficial to fine-tune at\ntest-time. Interestingly, we find that fine-tuning the second layer of the FFNs\nis more effective than full fine-tuning, leading to a further improvement in\nthe models' accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faETT\u65b9\u6cd5\uff0c\u5728\u6d4b\u8bd5\u65f6\u901a\u8fc7\u9ad8\u6548\u5fae\u8c03\u663e\u8457\u6269\u5c55LLM\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u4e0d\u4ec5\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\uff0c\u8fd8\u63d0\u5347\u6700\u592730%\u7684\u51c6\u786e\u7387\uff0c\u4e14\u7cbe\u7ec6\u5fae\u8c03\u7279\u5b9a\u5c42\u6b21\u6548\u679c\u66f4\u4f73\u3002", "motivation": "Transformer\u6a21\u578b\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u968f\u5e8f\u5217\u957f\u5ea6\u5448\u4e8c\u6b21\u589e\u957f\uff0c\u9650\u5236\u4e86\u5176\u5728\u957f\u6587\u672c\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u964d\u4f4e\u8fd9\u4e9b\u6a21\u578b\u5728\u957f\u5e8f\u5217\u5904\u7406\u4e2d\u7684\u8d44\u6e90\u6d88\u8017\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aETT\uff08Extend at Test-Time\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u8f93\u5165\u4e0a\u4e0b\u6587\u5207\u5206\u4e3a\u91cd\u53e0\u7684\u5b50\u5e8f\u5217\uff0c\u5728\u6d4b\u8bd5\u65f6\u9ad8\u6548\u5fae\u8c03\u6a21\u578b\u53c2\u6570\u3002\u8be5\u65b9\u6cd5\u5185\u5b58\u9700\u6c42\u6052\u5b9a\uff0c\u8ba1\u7b97\u5f00\u9500\u7ebf\u6027\u589e\u957f\u3002\u5e76\u5bf9\u6bd4\u5206\u6790\u4e0d\u540cTransformer\u6a21\u5757\u5728\u6d4b\u8bd5\u65f6\u5fae\u8c03\u7684\u6548\u679c\u3002", "result": "\u5c06GPT-Large\u548cPhi-2\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u4ece1k\u6269\u5c55\u523032k\u4ee3\u5e01\uff0c\u6a21\u578b\u51c6\u786e\u7387\u63d0\u9ad8\u9ad8\u8fbe30%\u3002\u53d1\u73b0\u4ec5\u5fae\u8c03Feed Forward\u7f51\u7edc\uff08FFN\uff09\u7b2c\u4e8c\u5c42\u6bd4\u5168\u91cf\u5fae\u8c03\u66f4\u6709\u6548\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u51c6\u786e\u7387\u3002", "conclusion": "ETT\u65b9\u6cd5\u663e\u8457\u6269\u5c55\u4e86Transformer LLMs\u5728\u6d4b\u8bd5\u65f6\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u4e14\u8d44\u6e90\u6d88\u8017\u66f4\u4f4e\u3002\u6309\u9700\u5fae\u8c03\u7279\u5b9a\u6a21\u5757\u53ef\u5728\u63d0\u5347\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u91cf\u3002"}}
{"id": "2507.06398", "categories": ["cs.AI", "cs.CY", "68T01, 91B26, 93C15"], "pdf": "https://arxiv.org/pdf/2507.06398", "abs": "https://arxiv.org/abs/2507.06398", "authors": ["David Orban"], "title": "Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI", "comment": "13 pages, 2 figures. Revised following peer review", "summary": "This paper investigates the Jolting Technologies Hypothesis, which posits\nsuperexponential growth (increasing acceleration, or a positive third\nderivative) in the development of AI capabilities. We develop a theoretical\nframework and validate detection methodologies through Monte Carlo simulations,\nwhile acknowledging that empirical validation awaits suitable longitudinal\ndata. Our analysis focuses on creating robust tools for future empirical\nstudies and exploring the potential implications should the hypothesis prove\nvalid. The study examines how factors such as shrinking idea-to-action\nintervals and compounding iterative AI improvements drive this jolting pattern.\nBy formalizing jolt dynamics and validating detection methods through\nsimulation, this work provides the mathematical foundation necessary for\nunderstanding potential AI trajectories and their consequences for AGI\nemergence, offering insights for research and policy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u3001\u5efa\u6a21\u5e76\u6a21\u62df\u9a8c\u8bc1\u4e86AI\u80fd\u529b\u6f5c\u5728\u201c\u8df3\u8dc3\u6027\u201d\u589e\u957f\uff08\u8d85\u7ea7\u6307\u6570\uff09\u7684\u7406\u8bba\u5de5\u5177\uff0c\u4e3a\u672a\u6765\u9a8c\u8bc1\u548c\u9884\u6d4bAI/AGI\u6f14\u8fdb\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u57fa\u7840\u3002", "motivation": "\u73b0\u6709AI\u53d1\u5c55\u7684\u589e\u957f\u6a21\u5f0f\u662f\u5426\u5448\u73b0\u52a0\u901f\uff08\u8d85\u7ea7\u6307\u6570\uff09\u8d8b\u52bf\u5c1a\u65e0\u5b9a\u8bba\uff0c\u8bba\u6587\u65e8\u5728\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u5047\u8bbe\u7684\u7406\u8bba\u5de5\u5177\u548c\u65b9\u6cd5\uff0c\u4e3a\u7406\u89e3\u672a\u6765AI\u751a\u81f3AGI\u7684\u6f5c\u5728\u6f14\u5316\u8f68\u8ff9\u63d0\u4f9b\u7814\u7a76\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u9a8c\u8bc1\u68c0\u6d4b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u5f3a\u8c03\u672a\u6765\u9700\u7ed3\u5408\u957f\u671f\u7eb5\u5411\u6570\u636e\u8fdb\u884c\u5b9e\u8bc1\u68c0\u9a8c\u3002", "result": "\u5efa\u7acb\u4e86\u53ef\u68c0\u6d4b\u8d85\u7ea7\u6307\u6570\u589e\u957f\u7684\u6570\u5b66\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u521d\u6b65\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u3002\u63ed\u793a\u4e86\u201c\u60f3\u6cd5-\u884c\u52a8\u201d\u65f6\u95f4\u7f29\u77ed\u4e0eAI\u81ea\u6211\u8fed\u4ee3\u5bf9\u589e\u957f\u6a21\u5f0f\u7684\u63a8\u52a8\u4f5c\u7528\uff0c\u5f3a\u8c03\u82e5\u5047\u8bbe\u6210\u7acb\u5c06\u5bf9\u7814\u7a76\u3001\u653f\u7b56\u4e0eAGI\u53d1\u5c55\u4ea7\u751f\u91cd\u8981\u610f\u4e49\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3aAI\u80fd\u529b\u53d1\u5c55\u7684\u8d85\u7ea7\u6307\u6570\u589e\u957f\u63d0\u4f9b\u4e86\u6570\u5b66\u57fa\u7840\uff0c\u5e76\u5f3a\u8c03\u4e86\u6b64\u52a8\u6001\u5bf9AGI\u51fa\u73b0\u7684\u6df1\u8fdc\u5f71\u54cd\uff0c\u4e3a\u4eca\u540e\u7684\u7814\u7a76\u4e0e\u653f\u7b56\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2507.06310", "categories": ["cs.CY", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.06310", "abs": "https://arxiv.org/abs/2507.06310", "authors": ["Yongchao Zeng", "Calum Brown", "Mark Rounsevell"], "title": "Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles", "comment": null, "summary": "Large language models (LLMs) have been increasingly used to build agents in\nsocial simulation because of their impressive abilities to generate fluent,\ncontextually coherent dialogues. Such abilities can enhance the realism of\nmodels. However, the pursuit of realism is not necessarily compatible with the\nepistemic foundation of modelling. We argue that LLM agents, in many regards,\nare too human to model: they are too expressive, detailed and intractable to be\nconsistent with the abstraction, simplification, and interpretability typically\ndemanded by modelling. Through a model-building thought experiment that\nconverts the Bass diffusion model to an LLM-based variant, we uncover five core\ndilemmas: a temporal resolution mismatch between natural conversation and\nabstract time steps; the need for intervention in conversations while avoiding\nundermining spontaneous agent outputs; the temptation to introduce rule-like\ninstructions in prompts while maintaining conversational naturalness; the\ntension between role consistency and role evolution across time; and the\nchallenge of understanding emergence, where system-level patterns become\nobscured by verbose micro textual outputs. These dilemmas steer the LLM agents\ntowards an uncanny valley: not abstract enough to clarify underlying social\nmechanisms, while not natural enough to represent realistic human behaviour.\nThis exposes an important paradox: the realism of LLM agents can obscure,\nrather than clarify, social dynamics when misapplied. We tease out the\nconditions in which LLM agents are ideally suited: where system-level emergence\nis not the focus, linguistic nuances and meaning are central, interactions\nunfold in natural time, and stable role identity is more important than\nlong-term behavioural evolution. We call for repositioning LLM agents in the\necosystem of social simulation for future applications.", "AI": {"tldr": "LLM\u7684\u9ad8\u62df\u771f\u80fd\u529b\u5e76\u975e\u603b\u9002\u5408\u793e\u4f1a\u6a21\u62df\uff0c\u5bb9\u6613\u5e26\u6765\u62bd\u8c61\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\uff0c\u5e94\u5f53\u8c28\u614e\u9009\u62e9\u5176\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u793e\u4f1a\u6a21\u62df\u4e2d\u56e0\u5176\u751f\u6210\u6d41\u7545\u3001\u4e0a\u4e0b\u6587\u8fde\u8d2f\u5bf9\u8bdd\u7684\u80fd\u529b\u800c\u88ab\u5e7f\u6cdb\u91c7\u7528\u3002\u5c3d\u7ba1\u8fd9\u79cd\u80fd\u529b\u63d0\u5347\u4e86\u6a21\u578b\u7684\u62df\u771f\u6027\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\uff0c\u8ffd\u6c42\u6781\u81f4\u7684\u62df\u771f\u6027\u4e0e\u5efa\u6a21\u7684\u8ba4\u8bc6\u8bba\u57fa\u7840\u5e76\u4e0d\u603b\u662f\u517c\u5bb9\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u5982\u4f55\u5408\u7406\u8fd0\u7528LLM\u3002", "method": "\u901a\u8fc7\u4e00\u4e2a\u6a21\u578b\u6784\u5efa\u7684\u601d\u60f3\u5b9e\u9a8c\uff0c\u5c06\u7ecf\u5178\u7684Bass\u6269\u6563\u6a21\u578b\u8f6c\u5316\u4e3a\u57fa\u4e8eLLM\u7684\u53d8\u4f53\uff0c\u7cfb\u7edf\u5730\u63ed\u793a\u4e86\u5728\u793e\u4f1a\u6a21\u62df\u4e2d\u4f7f\u7528LLM\u4ee3\u7406\u9762\u4e34\u7684\u6838\u5fc3\u56f0\u5883\u3002", "result": "\u4f5c\u8005\u603b\u7ed3\u51fa\u4e94\u5927\u56f0\u5883\uff1a\u65f6\u5e8f\u5206\u8fa8\u7387\u4e0e\u5efa\u6a21\u6b65\u957f\u7684\u4e0d\u5339\u914d\u3001\u5bf9\u751f\u6210\u5bf9\u8bdd\u4ecb\u5165\u7684\u4e24\u96be\u3001\u5f15\u5165\u89c4\u5219\u63d0\u793a\u4e0e\u81ea\u7136\u5bf9\u8bdd\u7684\u51b2\u7a81\u3001\u89d2\u8272\u4e00\u81f4\u6027\u4e0e\u6f14\u5316\u7684\u5f20\u529b\u3001\u7cfb\u7edf\u7ea7\u6d8c\u73b0\u88ab\u7ec6\u788e\u6587\u672c\u63a9\u76d6\u3002\u8fd9\u4e9b\u95ee\u9898\u8ba9LLM\u4ee3\u7406\u5904\u4e8e\u4e00\u4e2a\u5c34\u5c2c\u7684\u201c\u62df\u771f\u9e3f\u6c9f\u201d\u4e2d\uff0c\u65e2\u4e0d\u591f\u62bd\u8c61\u53c8\u4e0d\u591f\u81ea\u7136\uff0c\u53cd\u800c\u53ef\u80fd\u63a9\u76d6\u793e\u4f1a\u52a8\u529b\u5b66\u3002", "conclusion": "LLM\u4ee3\u7406\u5728\u5173\u6ce8\u8bed\u8a00\u7ec6\u8282\u3001\u4ea4\u4e92\u81ea\u7136\u3001\u89d2\u8272\u7a33\u5b9a\u4e14\u7cfb\u7edf\u7ea7\u6d8c\u73b0\u975e\u6838\u5fc3\u7684\u60c5\u5883\u4e0b\u66f4\u4e3a\u9002\u7528\u3002\u4f5c\u8005\u547c\u5401\u672a\u6765\u793e\u4f1a\u6a21\u62df\u5e94\u8be5\u91cd\u65b0\u5b9a\u4f4dLLM\u4ee3\u7406\u7684\u5e94\u7528\u573a\u666f\uff0c\u8b66\u60d5\u5176\u9ad8\u62df\u771f\u6027\u5e26\u6765\u7684\u8ba4\u8bc6\u8bef\u533a\u3002"}}
{"id": "2507.06335", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06335", "abs": "https://arxiv.org/abs/2507.06335", "authors": ["Casey Kennington", "David Schlangen"], "title": "Could the Road to Grounded, Neuro-symbolic AI be Paved with Words-as-Classifiers?", "comment": "9 pages", "summary": "Formal, Distributional, and Grounded theories of computational semantics each\nhave their uses and their drawbacks. There has been a shift to ground models of\nlanguage by adding visual knowledge, and there has been a call to enrich models\nof language with symbolic methods to gain the benefits from formal,\ndistributional, and grounded theories. In this paper, we attempt to make the\ncase that one potential path forward in unifying all three semantic fields is\npaved with the words-as-classifier model, a model of word-level grounded\nsemantics that has been incorporated into formalisms and distributional\nlanguage models in the literature, and it has been well-tested within\ninteractive dialogue settings. We review that literature, motivate the\nwords-as-classifiers model with an appeal to recent work in cognitive science,\nand describe a small experiment. Finally, we sketch a model of semantics\nunified through words-as-classifiers.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u56de\u987e\u4e0e\u5b9e\u9a8c\uff0c\u8bba\u8bc1words-as-classifier\u6a21\u578b\u53ef\u4ee5\u7edf\u5408\u5f62\u5f0f\u3001\u5206\u5e03\u5f0f\u53ca\u5177\u8eab\u8bed\u4e49\u7406\u8bba\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u6b64\u6a21\u578b\u7684\u7edf\u4e00\u8bed\u4e49\u6846\u67b6\u8bbe\u60f3\u3002", "motivation": "\u73b0\u6709\u7684\u8ba1\u7b97\u8bed\u4e49\u5b66\u7406\u8bba\u2014\u2014\u5f62\u5f0f\u8bed\u4e49\u3001\u5206\u5e03\u5f0f\u8bed\u4e49\u548c\u5177\u8eab\u8bed\u4e49\uff08\u57fa\u4e8e\u611f\u77e5/\u89c6\u89c9\u7684\u8bed\u4e49\uff09\u5404\u6709\u4f18\u7f3a\u70b9\uff0c\u76ee\u524d\u5b66\u754c\u63a2\u7d22\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9\u4fe1\u606f\u3001\u5f15\u5165\u7b26\u53f7\u65b9\u6cd5\u6765\u6574\u5408\u8fd9\u4e9b\u7406\u8bba\u3002\u4f5c\u8005\u5e0c\u671b\u63a8\u52a8\u4e09\u8005\u7684\u7edf\u4e00\u3002", "method": "\u6587\u732e\u56de\u987ewords-as-classifier\u6a21\u578b\uff0c\u5e76\u4ee5\u6700\u8fd1\u8ba4\u77e5\u79d1\u5b66\u6210\u679c\u4e3a\u52a8\u673a\uff0c\u505a\u4e86\u4e00\u4e2a\u5c0f\u578b\u5b9e\u9a8c\uff0c\u6700\u540e\u63d0\u51fa\u57fa\u4e8ewords-as-classifier\u7684\u7edf\u4e00\u8bed\u4e49\u6a21\u578b\u8bbe\u60f3\u3002", "result": "words-as-classifier\u6a21\u578b\u5df2\u88ab\u7528\u4e8e\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u88ab\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e86\u5f62\u5f0f\u3001\u5206\u5e03\u5f0f\u548c\u5177\u8eab\u8bed\u4e49\u65b9\u6cd5\u7684\u90e8\u5206\u6574\u5408\u3002\u4f5c\u8005\u8fd8\u63cf\u8ff0\u4e86\u8fd9\u4e00\u6a21\u578b\u5982\u4f55\u4f5c\u4e3a\u4e09\u79cd\u7406\u8bba\u7edf\u4e00\u6846\u67b6\u3002", "conclusion": "words-as-classifier\u6a21\u578b\u6709\u6f5c\u529b\u4f5c\u4e3a\u7edf\u4e00\u5f62\u5f0f\u3001\u5206\u5e03\u5f0f\u548c\u5177\u8eab\u8bed\u4e49\u5b66\u7684\u8f7d\u4f53\uff0c\u5bf9\u8bed\u4e49\u5efa\u6a21\u5177\u6709\u7efc\u5408\u6027\u4ef7\u503c\u3002"}}
{"id": "2507.06798", "categories": ["cs.AI", "math.LO"], "pdf": "https://arxiv.org/pdf/2507.06798", "abs": "https://arxiv.org/abs/2507.06798", "authors": ["Uri Andrews", "Luca San Mauro"], "title": "Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)", "comment": "25 pages, accepted at JELIA 2025", "summary": "Dialectical systems are a mathematical formalism for modeling an agent\nupdating a knowledge base seeking consistency. Introduced in the 1970s by\nRoberto Magari, they were originally conceived to capture how a working\nmathematician or a research community refines beliefs in the pursuit of truth.\nDialectical systems also serve as natural models for the belief change of an\nautomated agent, offering a unifying, computable framework for dynamic belief\nmanagement.\n  The literature distinguishes three main models of dialectical systems:\n(d-)dialectical systems based on revising beliefs when they are seen to be\ninconsistent, p-dialectical systems based on revising beliefs based on finding\na counterexample, and q-dialectical systems which can do both. We answer an\nopen problem in the literature by proving that q-dialectical systems are\nstrictly more powerful than p-dialectical systems, which are themselves known\nto be strictly stronger than (d-)dialectical systems. This result highlights\nthe complementary roles of counterexample and contradiction in automated belief\nrevision, and thus also in the reasoning processes of mathematicians and\nresearch communities.", "AI": {"tldr": "\u672c\u8bba\u6587\u89e3\u51b3\u4e86\u8fa8\u8bc1\u7cfb\u7edf\u9886\u57df\u7684\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\uff1a\u4e25\u683c\u8bc1\u660e\u4e86q-\u8fa8\u8bc1\u7cfb\u7edf\u7684\u80fd\u529b\u5927\u4e8ep-\u8fa8\u8bc1\u7cfb\u7edf\uff0c\u540e\u8005\u53c8\u5927\u4e8ed-\u8fa8\u8bc1\u7cfb\u7edf\uff0c\u4ece\u800c\u63ed\u793a\u4e86\u5728\u81ea\u52a8\u5316\u4fe1\u5ff5\u4fee\u6b63\u4e2d\uff0c\u53cd\u4f8b\u4e0e\u77db\u76fe\u673a\u5236\u7684\u4e92\u8865\u4e0e\u91cd\u8981\u6027\u3002", "motivation": "\u8be5\u8bba\u6587\u5173\u6ce8\u4e8e\u89e3\u51b3\u4e00\u4e2a\u957f\u671f\u5b58\u5728\u7684\u5f00\u653e\u6027\u95ee\u9898\uff1a\u4e0d\u540c\u7c7b\u578b\u7684\u8fa8\u8bc1\u7cfb\u7edf\u5728\u77e5\u8bc6\u4fee\u6b63\u4e0e\u66f4\u65b0\u4e2d\u7684\u7406\u8bba\u80fd\u529b\u6bd4\u8f83\uff0c\u7279\u522b\u662fq-\u8fa8\u8bc1\u7cfb\u7edf\u4e0ep-\u8fa8\u8bc1\u7cfb\u7edf\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u8fa8\u8bc1\u7cfb\u7edf\u6700\u521d\u662f\u4e3a\u4e86\u6a21\u62df\u6570\u5b66\u5bb6\u6216\u7814\u7a76\u56e2\u4f53\u5728\u8ffd\u6c42\u771f\u7406\u8fc7\u7a0b\u4e2d\u5982\u4f55\u4fee\u6b63\u548c\u5b8c\u5584\u4fe1\u5ff5\u63d0\u51fa\u7684\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u548c\u63cf\u8ff0\u4e86\u4e09\u7c7b\u8fa8\u8bc1\u7cfb\u7edf\uff08d-\u8fa8\u8bc1\u3001p-\u8fa8\u8bc1\u548cq-\u8fa8\u8bc1\u7cfb\u7edf\uff09\u7684\u7ed3\u6784\u4e0e\u64cd\u4f5c\u673a\u5236\uff0c\u91cd\u70b9\u8bc1\u660e\u4e86q-\u8fa8\u8bc1\u7cfb\u7edf\u5728\u80fd\u529b\u4e0a\u4e25\u683c\u8d85\u8d8ap-\u8fa8\u8bc1\u7cfb\u7edf\u3002", "result": "\u4f5c\u8005\u9996\u6b21\u8bc1\u660e\u4e86q-\u8fa8\u8bc1\u7cfb\u7edf\u5728\u63a8\u7406\u548c\u4fe1\u5ff5\u4fee\u6b63\u7684\u80fd\u529b\u4e0a\u4e25\u683c\u5f3a\u4e8ep-\u8fa8\u8bc1\u7cfb\u7edf\uff0c\u800c\u540e\u8005\u53c8\u5df2\u77e5\u5f3a\u4e8e\u6700\u57fa\u7840\u7684d-\u8fa8\u8bc1\u7cfb\u7edf\u3002\u8fd9\u4e00\u7ed3\u8bba\u63ed\u793a\u4e86\u53cd\u4f8b\uff08counterexample\uff09\u4e0e\u77db\u76fe\uff08contradiction\uff09\u5728\u81ea\u52a8\u4fe1\u5ff5\u4fee\u6b63\u8fc7\u7a0b\u4e2d\u7684\u4e92\u8865\u4f5c\u7528\u3002", "conclusion": "q-\u8fa8\u8bc1\u7cfb\u7edf\u5728\u52a8\u6001\u4fe1\u5ff5\u7ba1\u7406\u548c\u81ea\u52a8\u63a8\u7406\u65b9\u9762\u5177\u5907\u66f4\u5f3a\u7684\u8868\u8fbe\u4e0e\u4fee\u6b63\u80fd\u529b\uff0c\u80fd\u591f\u66f4\u5168\u9762\u5730\u6a21\u62df\u6570\u5b66\u5bb6\u548c\u5b66\u672f\u5171\u540c\u4f53\u7684\u63a8\u7406\u8fc7\u7a0b\u3002"}}
{"id": "2507.06379", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2507.06379", "abs": "https://arxiv.org/abs/2507.06379", "authors": ["Haydn Belfield"], "title": "Domestic frontier AI regulation, an IAEA for AI, an NPT for AI, and a US-led Allied Public-Private Partnership for AI: Four institutions for governing and developing frontier AI", "comment": "46 pages, 6 figures, 7 tables", "summary": "Compute governance can underpin international institutions for the governance\nof frontier AI. To demonstrate this I explore four institutions for governing\nand developing frontier AI. Next steps for compute-indexed domestic frontier AI\nregulation could include risk assessments and pre-approvals, data centre usage\nreports, and release gate regulation. Domestic regimes could be harmonized and\nmonitored through an International AI Agency - an International Atomic Energy\nAgency (IAEA) for AI. This could be backed up by a Secure Chips Agreement - a\nNon-Proliferation Treaty (NPT) for AI. This would be a non-proliferation regime\nfor advanced chips, building on the chip export controls - states that do not\nhave an IAIA-certified frontier regulation regime would not be allowed to\nimport advanced chips. Frontier training runs could be carried out by a\nmegaproject between the USA and its allies - a US-led Allied Public-Private\nPartnership for frontier AI. As a project to develop advanced AI, this could\nhave significant advantages over alternatives led by Big Tech or particular\nstates: it could be more legitimate, secure, safe, non-adversarial, peaceful,\nand less prone to misuse. For each of these four scenarios, a key incentive for\nparticipation is access to the advanced AI chips that are necessary for\nfrontier training runs and large-scale inference. Together, they can create a\nsituation in which governments can be reassured that frontier AI is developed\nand deployed in a secure manner with misuse minimised and benefits widely\nshared. Building these institutions may take years or decades, but progress is\nincremental and evolutionary and the first steps have already been taken.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ee5\u7b97\u529b\uff08\u786c\u4ef6\u82af\u7247\uff09\u4e3a\u4e3b\u7ebf\uff0c\u63a8\u52a8\u56fd\u5185\u5916AI\u6cbb\u7406\u63aa\u65bd\uff0c\u5305\u62ec\u5efa\u7acb\u56fd\u9645AI\u673a\u6784\u3001\u82af\u7247\u534f\u8bae\u548c\u7f8e\u897f\u65b9\u4e3b\u5bfc\u7684AI\u5408\u4f19\u5f00\u53d1\u9879\u76ee\uff0c\u901a\u8fc7\u8ba1\u7b97\u8d44\u6e90\u6fc0\u52b1\uff0c\u4fc3\u8fdb\u5b89\u5168\u3001\u6709\u5e8f\u3001\u5171\u8d62\u7684\u524d\u6cbfAI\u53d1\u5c55\u3002", "motivation": "\u524d\u6cbf\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u5e26\u6765\u91cd\u5927\u7684\u98ce\u9669\u4e0e\u6311\u6218\uff0c\u73b0\u6709\u7684\u56fd\u9645\u673a\u5236\u96be\u4ee5\u6709\u6548\u76d1\u7ba1AI\u7684\u53d1\u5c55\u548c\u4f7f\u7528\u3002\u8bba\u6587\u52a8\u673a\u662f\u63a2\u8ba8\u4ee5\u7b97\u529b\u6cbb\u7406\u4e3a\u57fa\u7840\uff0c\u5efa\u7acb\u66f4\u6709\u6548\u7684\u56fd\u9645\u6cbb\u7406\u67b6\u6784\uff0c\u4ee5\u964d\u4f4e\u98ce\u9669\u3001\u4fdd\u969c\u5b89\u5168\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4ee5\u7b97\u529b\u6307\u6807\u4e3a\u6838\u5fc3\uff0c\u7ed3\u5408\u56fd\u5185\u4e0e\u56fd\u9645\u591a\u5c42\u6b21\u6cbb\u7406\u63aa\u65bd\u3002\u5177\u4f53\u5305\u62ec\u98ce\u9669\u8bc4\u4f30\u3001\u6570\u636e\u4e2d\u5fc3\u4f7f\u7528\u62a5\u544a\u3001\u53d1\u5e03\u95e8\u63a7\u7b49\u56fd\u5185\u7ba1\u7406\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u5efa\u8bae\u5efa\u7acb\u56fd\u9645AI\u673a\u6784\uff08\u7c7b\u4f3c\u56fd\u9645\u539f\u5b50\u80fd\u673a\u6784IAEA\uff09\uff0c\u63a8\u52a8\u300a\u5b89\u5168\u82af\u7247\u534f\u8bae\u300b\uff08\u7c7b\u4f3c\u6838\u4e0d\u6269\u6563\u6761\u7ea6NPT\uff09\uff0c\u5e76\u5021\u8bae\u7531\u7f8e\u897f\u65b9\u4e3b\u5bfc\u7684AI\u516c\u5171-\u79c1\u8425\u5408\u4f19\u9879\u76ee\u3002", "result": "\u4f5c\u8005\u5206\u6790\u4e86\u56db\u79cd\u6cbb\u7406\u4e0e\u53d1\u5c55\u524d\u6cbfAI\u7684\u56fd\u9645\u673a\u6784\u6a21\u5f0f\u3002\u8bba\u8bc1\u901a\u8fc7\u201c\u82af\u7247\u201d\u8fd9\u4e00\u6fc0\u52b1\u673a\u5236\uff0c\u5f15\u5bfc\u5404\u56fd\u53c2\u4e0e\u7b97\u529b\u4e0eAI\u7684\u534f\u540c\u6cbb\u7406\uff0c\u6709\u671b\u4fc3\u8fdbAI\u5b89\u5168\u548c\u5168\u7403\u5171\u4eab\uff0c\u5e76\u51cf\u5c11\u8bef\u7528\u98ce\u9669\u3002\u5f3a\u8c03\u5236\u5ea6\u5efa\u8bbe\u662f\u957f\u8fdc\u7684\u3001\u6e10\u8fdb\u7684\uff0c\u73b0\u5df2\u542f\u52a8\u521d\u6b65\u63a2\u7d22\u3002", "conclusion": "\u7b97\u529b\u6cbb\u7406\u53ef\u4e3a\u524d\u6cbfAI\u56fd\u9645\u6cbb\u7406\u673a\u6784\u63d0\u4f9b\u53ef\u884c\u7684\u57fa\u7840\u3002\u901a\u8fc7\u591a\u5c42\u6b21\u63aa\u65bd\u548c\u5f3a\u6fc0\u52b1\u673a\u5236\uff0c\u80fd\u591f\u5b9e\u73b0\u65e2\u5b89\u5168\u53c8\u516c\u5e73\u7684AI\u5f00\u53d1\u53ca\u5e94\u7528\uff0c\u4f46\u9700\u8981\u8010\u5fc3\u63a8\u8fdb\u548c\u56fd\u9645\u5408\u4f5c\u3002"}}
{"id": "2507.06378", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06378", "abs": "https://arxiv.org/abs/2507.06378", "authors": ["Catherine Arnett", "Marisa Hudspeth", "Brendan O'Connor"], "title": "Evaluating Morphological Alignment of Tokenizers in 70 Languages", "comment": "6 pages, 3 figures. Accepted to the Tokenization Workshop at ICML\n  2025", "summary": "While tokenization is a key step in language modeling, with effects on model\ntraining and performance, it remains unclear how to effectively evaluate\ntokenizer quality. One proposed dimension of tokenizer quality is the extent to\nwhich tokenizers preserve linguistically meaningful subwords, aligning token\nboundaries with morphological boundaries within a word. We expand MorphScore\n(Arnett & Bergen, 2025), which previously covered 22 languages, to support a\ntotal of 70 languages. The updated MorphScore offers more flexibility in\nevaluation and addresses some of the limitations of the original version. We\nthen correlate our alignment scores with downstream task performance for five\npre-trained languages models on seven tasks, with at least one task in each of\nthe languages in our sample. We find that morphological alignment does not\nexplain very much variance in model performance, suggesting that morphological\nalignment alone does not measure dimensions of tokenization quality relevant to\nmodel performance.", "AI": {"tldr": "\u4f5c\u8005\u6269\u5c55\u4e86MorphScore\uff0c\u652f\u630170\u79cd\u8bed\u8a00\uff0c\u4ee5\u8bc4\u4f30\u5206\u8bcd\u4e0e\u5f62\u6001\u7ed3\u6784\u7684\u5bf9\u9f50\uff0c\u4f46\u53d1\u73b0\u5f62\u6001\u5b66\u5bf9\u9f50\u7a0b\u5ea6\u4e0e\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u76f8\u5173\u6027\u5f88\u4f4e\uff0c\u8bf4\u660e\u4ec5\u51ed\u5f62\u6001\u5bf9\u9f50\u65e0\u6cd5\u5168\u9762\u8bc4\u4ef7\u5206\u8bcd\u5668\u8d28\u91cf\u3002", "motivation": "\u8bcd\u8bed\u5206\u8bcd\u662f\u8bed\u8a00\u5efa\u6a21\u7684\u91cd\u8981\u73af\u8282\uff0c\u4f46\u5982\u4f55\u6709\u6548\u8bc4\u4f30\u5206\u8bcd\u5668\u7684\u8d28\u91cf\u5c1a\u4e0d\u660e\u786e\u3002\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4e4b\u4e00\u662f\u770b\u5206\u8bcd\u8fb9\u754c\u662f\u5426\u4e0e\u8bcd\u7684\u5f62\u6001\u5b66\u8fb9\u754c\u5bf9\u9f50\uff0c\u8fd9\u5728\u8bed\u8a00\u5b66\u4e0a\u6709\u610f\u4e49\u3002", "method": "\u6269\u5c55\u4e86MorphScore\u8bc4\u4f30\u5de5\u5177\uff0c\u5c06\u8986\u76d6\u7684\u8bed\u8a00\u6570\u91cf\u4ece22\u79cd\u6269\u5c55\u523070\u79cd\uff0c\u5e76\u589e\u5f3a\u4e86\u7075\u6d3b\u6027\u53ca\u5f25\u8865\u4e86\u90e8\u5206\u539f\u6709\u7248\u672c\u7684\u4e0d\u8db3\u3002\u4e4b\u540e\uff0c\u4f5c\u8005\u57fa\u4e8e\u4e94\u4e2a\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3001\u4e03\u4e2a\u4efb\u52a1\uff0c\u7edf\u8ba1\u4e86\u5206\u8bcd\u4e0e\u5f62\u6001\u5b66\u5bf9\u9f50\u5206\u6570\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u76f8\u5173\u6027\u3002", "result": "\u5206\u8bcd\u8fb9\u754c\u4e0e\u5f62\u6001\u5b66\u8fb9\u754c\u7684\u5bf9\u9f50\u5ea6\u5bf9\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5f71\u54cd\u5f88\u5c0f\uff0c\u89e3\u91ca\u4e0d\u4e86\u5927\u90e8\u5206\u6027\u80fd\u65b9\u5dee\u3002", "conclusion": "\u5f62\u6001\u5b66\u5bf9\u9f50\u4f5c\u4e3a\u5206\u8bcd\u5668\u8d28\u91cf\u7684\u5355\u4e00\u8861\u91cf\u6807\u51c6\u4e0d\u8db3\u4ee5\u53cd\u6620\u6a21\u578b\u6027\u80fd\u8868\u73b0\u3002\u5206\u8bcd\u8bc4\u4f30\u9700\u8981\u8003\u8651\u66f4\u591a\u7ef4\u5ea6\u3002"}}
{"id": "2507.06852", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06852", "abs": "https://arxiv.org/abs/2507.06852", "authors": ["Uri Andrews", "Luca San Mauro"], "title": "SCC-recursiveness in infinite argumentation (extended version)", "comment": "26 pages, accepted at JELIA 2025", "summary": "Argumentation frameworks (AFs) are a foundational tool in artificial\nintelligence for modeling structured reasoning and conflict. SCC-recursiveness\nis a well-known design principle in which the evaluation of arguments is\ndecomposed according to the strongly connected components (SCCs) of the attack\ngraph, proceeding recursively from \"higher\" to \"lower\" components. While\nSCC-recursive semantics such as \\cft and \\stgt have proven effective for finite\nAFs, Baumann and Spanring showed the failure of SCC-recursive semantics to\ngeneralize reliably to infinite AFs due to issues with well-foundedness.\n  We propose two approaches to extending SCC-recursiveness to the infinite\nsetting. We systematically evaluate these semantics using Baroni and Giacomin's\nestablished criteria, showing in particular that directionality fails in\ngeneral. We then examine these semantics' behavior in finitary frameworks,\nwhere we find some of our semantics satisfy directionality. These results\nadvance the theory of infinite argumentation and lay the groundwork for\nreasoning systems capable of handling unbounded or evolving domains.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u73b0\u6709SCC\u9012\u5f52\u8bed\u4e49\u96be\u4ee5\u63a8\u5e7f\u81f3\u65e0\u9650AF\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e24\u79cd\u6269\u5c55\u65b9\u6cd5\u5e76\u7cfb\u7edf\u8bc4\u4ef7\uff0c\u53d1\u73b0\u65b0\u65b9\u6cd5\u5728\u4e00\u5b9a\u6761\u4ef6\u4e0b\u5177\u6709\u65b9\u5411\u6027\uff0c\u4e3a\u6784\u5efa\u80fd\u5904\u7406\u65e0\u9650\u6216\u6f14\u5316\u9886\u57df\u7684\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u4f20\u7edf\u7684SCC\u9012\u5f52\u8bed\u4e49\u5728\u6709\u9650\u8fa9\u8bba\u6846\u67b6\uff08AFs\uff09\u4e2d\u975e\u5e38\u6709\u6548\uff0c\u4f46Baumann\u548cSpanring\u6307\u51fa\u5c06\u5176\u76f4\u63a5\u5e94\u7528\u5230\u65e0\u9650AFs\u65f6\u4f1a\u9047\u5230\u57fa\u7840\u6027\u95ee\u9898\uff0c\u65e0\u6cd5\u53ef\u9760\u63a8\u5e7f\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u63a2\u7d22\u9002\u7528\u4e8e\u65e0\u9650\u8fa9\u8bba\u6846\u67b6\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5e76\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e86\u4e24\u79cd\u5c06SCC\u9012\u5f52\u6027\u6269\u5c55\u5230\u65e0\u9650AF\u7684\u65b9\u6848\uff0c\u91c7\u7528Baroni\u548cGiacomin\u7684\u8bed\u4e49\u8bc4\u5224\u6807\u51c6\u5bf9\u65b0\u65b9\u6848\u8fdb\u884c\u5206\u6790\u4e0e\u6bd4\u8f83\uff0c\u91cd\u70b9\u8003\u5bdf\u4e86\u65b9\u5411\u6027\uff08directionality\uff09\u7b49\u5c5e\u6027\u3002", "result": "\u53d1\u73b0\u5728\u65e0\u9650AF\u4e2d\uff0c\u73b0\u6709\u7684\u65b9\u5411\u6027\u7b49\u6027\u8d28\u901a\u5e38\u65e0\u6cd5\u4fdd\u6301\uff0c\u4f46\u5728\u7279\u5b9a\u7684\u6709\u9650\u6027\uff08\u5982finitary frameworks\uff09\u4e0b\uff0c\u90e8\u5206\u65b0\u63d0\u65b9\u6848\u80fd\u591f\u6ee1\u8db3\u65b9\u5411\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6269\u5c55\u65b9\u6cd5\u4e30\u5bcc\u4e86\u65e0\u9650AF\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4e3a\u672a\u6765\u5904\u7406\u65e0\u754c\u6216\u52a8\u6001\u9886\u57df\u7684\u63a8\u7406\u7cfb\u7edf\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2507.06434", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06434", "abs": "https://arxiv.org/abs/2507.06434", "authors": ["Ayrton San Joaquin", "Rokas Gipi\u0161kis", "Leon Staufer", "Ariel Gil"], "title": "Deprecating Benchmarks: Criteria and Framework", "comment": "10 pages, 1 table. Accepted to the ICML 2025 Technical AI Governance\n  Workshop", "summary": "As frontier artificial intelligence (AI) models rapidly advance, benchmarks\nare integral to comparing different models and measuring their progress in\ndifferent task-specific domains. However, there is a lack of guidance on when\nand how benchmarks should be deprecated once they cease to effectively perform\ntheir purpose. This risks benchmark scores over-valuing model capabilities, or\nworse, obscuring capabilities and safety-washing. Based on a review of\nbenchmarking practices, we propose criteria to decide when to fully or\npartially deprecate benchmarks, and a framework for deprecating benchmarks. Our\nwork aims to advance the state of benchmarking towards rigorous and quality\nevaluations, especially for frontier models, and our recommendations are aimed\nto benefit benchmark developers, benchmark users, AI governance actors (across\ngovernments, academia, and industry panels), and policy makers.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u4e86\u5f53\u524dAI\u57fa\u51c6\u6d4b\u8bd5\u5728\u5931\u6548\u540e\u7f3a\u4e4f\u660e\u786e\u5f03\u7528\u673a\u5236\u6240\u5e26\u6765\u7684\u98ce\u9669\uff0c\u63d0\u51fa\u4e86\u4e00\u5957\u5f03\u7528\u6807\u51c6\u548c\u64cd\u4f5c\u6846\u67b6\uff0c\u65e8\u5728\u89c4\u8303\u8bc4\u4f30\uff0c\u63a8\u52a8AI\u6a21\u578b\u79d1\u5b66\u5065\u5eb7\u53d1\u5c55\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u5feb\u901f\u53d1\u5c55\uff0c\u4e0d\u540c\u6a21\u578b\u7684\u8bc4\u4f30\u79bb\u4e0d\u5f00\u57fa\u51c6\u6d4b\u8bd5\uff08benchmarks\uff09\u3002\u7136\u800c\uff0c\u7f3a\u4e4f\u6709\u5173\u4f55\u65f6\u53ca\u5982\u4f55\u5f03\u7528\u5df2\u4e0d\u518d\u6709\u6548\u7684\u57fa\u51c6\u7684\u6307\u5bfc\uff0c\u53ef\u80fd\u5bfc\u81f4\u5bf9\u6a21\u578b\u80fd\u529b\u7684\u9ad8\u4f30\u6216\u80fd\u529b\u63a9\u76d6\u751a\u81f3\u5b89\u5168\u98ce\u9669\u88ab\u5ffd\u89c6\u3002", "method": "\u56de\u987e\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u8df5\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u5957\u6807\u51c6\uff0c\u7528\u4e8e\u5224\u65ad\u4f55\u65f6\uff08\u5b8c\u5168\u6216\u90e8\u5206\uff09\u5f03\u7528\u57fa\u51c6\uff0c\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2a\u5f03\u7528\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u5f03\u7528\u57fa\u51c6\u7684\u6807\u51c6\u548c\u76f8\u5e94\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u8bc4\u4f30\u66f4\u4e3a\u4e25\u683c\u3001\u9ad8\u8d28\u91cf\uff0c\u5c24\u5176\u9488\u5bf9\u524d\u6cbfAI\u6a21\u578b\u3002", "conclusion": "\u8fd9\u4e9b\u5de5\u4f5c\u548c\u5efa\u8bae\u5c06\u9020\u798f\u57fa\u51c6\u5f00\u53d1\u8005\u3001\u7528\u6237\u3001AI\u6cbb\u7406\u76f8\u5173\u4eba\u5458\u548c\u653f\u7b56\u5236\u5b9a\u8005\uff0c\u63d0\u5347AI\u8bc4\u4f30\u4f53\u7cfb\u7684\u79d1\u5b66\u6027\u548c\u4e25\u8c28\u6027\u3002"}}
{"id": "2507.06393", "categories": ["cs.CL", "math.QA", "math.RA", "91F20, 18M60, 18M80, 16T05, 68Q70"], "pdf": "https://arxiv.org/pdf/2507.06393", "abs": "https://arxiv.org/abs/2507.06393", "authors": ["Matilde Marcolli", "Riny Huijbregts", "Richard K. Larson"], "title": "Hypermagmas and Colored Operads: Heads, Phases, and Theta Roles", "comment": "LaTeX, 48 pages", "summary": "We show that head functions on syntactic objects extend the magma structure\nto a hypermagma, with the c-command relation compatible with the magma\noperation and the m-command relation with the hypermagma. We then show that the\nstructure of head and complement and specifier, additional modifier positions,\nand the structure of phases in the Extended Projection can be formulated as a\nbud generating system of a colored operad, in a form similar to the structure\nof theta roles. We also show that, due to the special form of the colored\noperad generators, the filtering of freely generated syntactic objects by these\ncoloring rules can be equivalently formulated as a filtering in the course of\nstructure formation via a colored Merge, which can in turn be related to the\nhypermagma structure. The rules on movement by Internal Merge with respect to\nphases, the Extended Projection Principle, Empty Category Principle, and Phase\nImpenetrability Condition are all subsumed into the form of the colored operad\ngenerators. Movement compatibilities between the phase structure and the theta\nroles assignments can then be formulated in terms of the respective colored\noperads and a transduction of colored operads.", "AI": {"tldr": "\u672c\u8bba\u6587\u8fd0\u7528\u9ad8\u7ea7\u4ee3\u6570\uff08hyper-magma\uff0ccolored operad\u7b49\uff09\u7edf\u4e00\u5f62\u5f0f\u5316\u53e5\u6cd5\u7ed3\u6784\u53ca\u5176\u9650\u5236\uff08\u5982\u9636\u6bb5\u7ed3\u6784\u3001\u6295\u5c04\u539f\u5219\u3001\u53e5\u6cd5\u79fb\u52a8\u7b49\uff09\uff0c\u5c55\u793a\u4e86\u53e5\u6cd5\u7406\u8bba\u53ef\u501f\u52a9\u8303\u7574\u8bba\u5de5\u5177\u4e25\u5bc6\u523b\u753b\u3002", "motivation": "\u5e0c\u671b\u4e3a\u53e5\u6cd5\u5b66\u4e2d\u7684\u590d\u6742\u7ed3\u6784\u4e0e\u9650\u5236\uff08\u5982\u9636\u6bb5\u3001\u6295\u5c04\u3001\u79fb\u52a8\u89c4\u5219\u7b49\uff09\u63d0\u4f9b\u7edf\u4e00\u3001\u4e25\u683c\u7684\u4ee3\u6570\u4e0e\u8303\u7574\u5b66\u5f62\u5f0f\u5de5\u5177\uff0c\u4ece\u800c\u66f4\u597d\u5730\u89e3\u91ca\u53e5\u6cd5\u5bf9\u8c61\u7684\u751f\u6210\u548c\u9650\u5236\u65b9\u5f0f\u3002", "method": "\u901a\u8fc7\u5c06\u53e5\u6cd5\u5bf9\u8c61\u6269\u5c55\u4e3ahyper-magma\u7ed3\u6784\uff0c\u8fd0\u7528colored operad\uff08\u5f69\u8272\u5e7a\u534a\u8303\u7574\uff09\u7684\u82bd\u751f\u6210\u7cfb\u7edf(bud generating system)\uff0c\u5bf9\u5934\u3001\u8865\u8db3\u8bed\u3001\u6807\u8bc6\u8bed\u3001\u53ca\u4fee\u9970\u8bed\u4f4d\u7f6e\u7b49\u53e5\u6cd5\u7ed3\u6784\u8fdb\u884c\u5f62\u5f0f\u5316\uff0c\u5e76\u5c06\u53e5\u6cd5\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u7ea6\u675f\u8868\u8fbe\u4e3a\u6709\u8272operad\u751f\u6210\u5668\u7684\u8fc7\u6ee4\u548c\u53d8\u6362\u89c4\u5219\u3002\u91c7\u7528\u8303\u7574\u8bba\u548c\u4ee3\u6570\u7ed3\u6784\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u53e5\u6cd5\u5bf9\u8c61\u53ca\u5176\u76f8\u5173\u5173\u7cfb\uff08\u5982c-command\u4e0em-command\u3001theta\u89d2\u8272\u5206\u914d\u7b49\uff09\u53ef\u4ee5\u5728ma/gma\u548chyper-magma\u7684\u7ed3\u6784\u4e0b\u7528\u5f69\u8272operad formalism\u8868\u8fbe\uff0c\u53e5\u6cd5\u751f\u6210\u7684\u8fc7\u7a0b\u548c\u5404\u79cd\u53e5\u6cd5\u89c4\u5219\uff08\u5982\u79fb\u52a8\u3001\u9636\u6bb5\u4e0d\u53ef\u7a7f\u900f\u7b49\uff09\u5747\u80fd\u6574\u5408\u4e3a\u6709\u8272operad\u7684\u751f\u6210\u4e0e\u8fc7\u6ee4\u8fc7\u7a0b\u3002", "conclusion": "\u8be5\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u53e5\u6cd5\u7ed3\u6784\u4e2d\u7684\u8fd0\u52a8\u89c4\u5219\u3001\u6295\u5c04\u539f\u5219\u4ee5\u53ca\u76f8\u5173\u7684\u9650\u5236\u6761\u4ef6\uff0c\u90fd\u53ef\u4ee5\u7edf\u4e00\u5730\u7528\u6709\u8272operad\u751f\u6210\u5668\u6765\u63cf\u8ff0\uff0c\u800c\u8bed\u7c7b\u3001\u4fee\u9970\u8bed\u4f4d\u7f6e\u7b49\u6838\u5fc3\u53e5\u6cd5\u7ed3\u6784\u4e5f\u53ef\u901a\u8fc7\u6709\u8272operad\u7cfb\u7edf\u6765\u5f62\u5f0f\u5316\u3002\u9636\u6bb5\u7ed3\u6784\u4e0etheta\u89d2\u8272\u7684\u517c\u5bb9\u6027\u4e5f\u53ef\u5f52\u7ed3\u4e3a\u6709\u8272operad\u95f4\u7684\u6362\u4f4d(transduction)\u95ee\u9898\u3002"}}
{"id": "2507.06968", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06968", "abs": "https://arxiv.org/abs/2507.06968", "authors": ["Li Du", "Hanyu Zhao", "Yiming Ju", "Tengfei Pan"], "title": "Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report", "comment": null, "summary": "Instruction tuning has become a foundation for unlocking the capabilities of\nlarge-scale pretrained models and improving their performance on complex tasks.\nThus, the construction of high-quality instruction datasets is crucial for\nenhancing model performance and generalizability. Although current instruction\ndatasets have reached tens of millions of samples, models finetuned on them may\nstill struggle with complex instruction following and tasks in rare domains.\nThis is primarily due to limited expansion in both ``coverage'' (coverage of\ntask types and knowledge areas) and ``depth'' (instruction complexity) of the\ninstruction set. To address this issue, we propose a systematic instruction\ndata construction framework, which integrates a hierarchical labeling system,\nan informative seed selection algorithm, an evolutionary data synthesis\nprocess, and a model deficiency diagnosis with targeted data generation. These\ncomponents form an iterative closed-loop to continuously enhance the coverage\nand depth of instruction data. Based on this framework, we construct\nInfinityInstruct-Subject, a high-quality dataset containing ~1.5 million\ninstructions. Experiments on multiple foundation models and benchmark tasks\ndemonstrate its effectiveness in improving instruction-following capabilities.\nFurther analyses suggest that InfinityInstruct-Subject shows enlarged coverage\nand depth compared to comparable synthesized instruction datasets. Our work\nlays a theoretical and practical foundation for the efficient, continuous\nevolution of instruction datasets, moving from data quantity expansion to\nqualitative improvement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7cfb\u7edf\u5316\u7684\u6307\u4ee4\u6570\u636e\u96c6\u6269\u5c55\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u6a21\u578b\u5728\u590d\u6742\u53ca\u51b7\u95e8\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u6784\u5efa\u4e86\u9ad8\u8d28\u91cf\u6570\u636e\u96c6InfinityInstruct-Subject\uff0c\u4e3a\u6307\u4ee4\u6570\u636e\u53d1\u5c55\u6307\u660e\u4e86\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u6307\u4ee4\u5fae\u8c03\u4f5c\u4e3a\u63d0\u5347\u5927\u6a21\u578b\u80fd\u529b\u7684\u5173\u952e\u65b9\u5f0f\uff0c\u7136\u800c\u73b0\u6709\u6307\u4ee4\u6570\u636e\u96c6\u65e0\u8bba\u5728\u6db5\u76d6\u9886\u57df\uff08coverage\uff09\u8fd8\u662f\u6307\u4ee4\u590d\u6742\u6027\uff08depth\uff09\u4e0a\u90fd\u5b58\u5728\u4e0d\u8db3\uff0c\u5bfc\u81f4\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u548c\u7f55\u89c1\u9886\u57df\u4efb\u52a1\u65f6\u8868\u73b0\u6709\u9650\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u6307\u4ee4\u6570\u636e\u6784\u5efa\u6846\u67b6\uff0c\u5305\u62ec\u5206\u5c42\u6807\u6ce8\u4f53\u7cfb\u3001\u4fe1\u606f\u5316\u79cd\u5b50\u9009\u62e9\u7b97\u6cd5\u3001\u6f14\u5316\u5f0f\u6570\u636e\u5408\u6210\u6d41\u7a0b\uff0c\u4ee5\u53ca\u57fa\u4e8e\u6a21\u578b\u8584\u5f31\u70b9\u7684\u6709\u9488\u5bf9\u6027\u6570\u636e\u751f\u6210\uff0c\u5e76\u4ee5\u95ed\u73af\u8fed\u4ee3\u7684\u65b9\u5f0f\u6301\u7eed\u63d0\u5347\u6570\u636e\u96c6\u7684\u8986\u76d6\u5ea6\u548c\u6df1\u5ea6\u3002", "result": "\u57fa\u4e8e\u4e0a\u8ff0\u6846\u67b6\uff0c\u4f5c\u8005\u6784\u5efa\u4e86InfinityInstruct-Subject\u6570\u636e\u96c6\uff0c\u5305\u542b\u7ea6150\u4e07\u6761\u9ad8\u8d28\u91cf\u6307\u4ee4\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6570\u636e\u96c6\u80fd\u591f\u6709\u6548\u63d0\u5347\u57fa\u7840\u6a21\u578b\u7684\u6307\u4ee4\u9075\u5faa\u4e0e\u590d\u6742\u4efb\u52a1\u80fd\u529b\uff0c\u5e76\u5728\u8986\u76d6\u5ea6\u548c\u6df1\u5ea6\u4e0a\u8d85\u8d8a\u540c\u7c7b\u5408\u6210\u6570\u636e\u96c6\u3002", "conclusion": "\u672c\u5de5\u4f5c\u4e3a\u9ad8\u6548\u3001\u6301\u7eed\u6f14\u5316\u7684\u6307\u4ee4\u6570\u636e\u96c6\u5efa\u8bbe\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u4ece\u6570\u91cf\u6269\u5f20\u5411\u8d28\u91cf\u63d0\u5347\u7684\u8dc3\u8fc1\u3002"}}
{"id": "2507.06438", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.06438", "abs": "https://arxiv.org/abs/2507.06438", "authors": ["Kal\u00e9u Delphino"], "title": "Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study", "comment": "40 pages, 23 figures", "summary": "Tools that can generate computer code in response to inputs written in\nnatural language, such as ChatGPT, pose an existential threat to Computer\nScience education in its current form, since students can now use these tools\nto solve assignments without much effort. While that risk has already been\nrecognized by scholars, the proportion of the student body that is incurring in\nthis new kind of plagiarism is still an open problem. We conducted a pilot\nstudy in a large CS class (n=120) to assess the feasibility of estimating AI\nplagiarism through anonymous surveys and interviews. More than 25% of the\nsurvey respondents admitted to committing AI plagiarism. Conversely, only one\nstudent accepted to be interviewed. Given the high levels of misconduct\nacknowledgment, we conclude that surveys are an effective method for studies on\nthe matter, while interviews should be avoided or designed in a way that can\nentice participation.", "AI": {"tldr": "\u5b66\u751f\u7528AI\u5de5\u5177\u6284\u88ad\u7684\u6bd4\u4f8b\u8f83\u9ad8\uff0c\u95ee\u5377\u53ef\u6709\u6548\u8c03\u67e5\u6b64\u73b0\u8c61\uff0c\u800c\u9762\u8c08\u96be\u4ee5\u83b7\u5f97\u771f\u5b9e\u53cd\u9988\u3002", "motivation": "\u968f\u7740\u81ea\u7136\u8bed\u8a00\u751f\u6210\u4ee3\u7801\u5de5\u5177\uff08\u5982ChatGPT\uff09\u7684\u51fa\u73b0\uff0c\u4f20\u7edf\u7684\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u9762\u4e34\u5b66\u751f\u5229\u7528AI\u4f5c\u5f0a\u7684\u65b0\u6311\u6218\u3002\u4f46\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u6709\u591a\u5c11\u5b66\u751f\u5b9e\u9645\u5728\u5229\u7528\u8fd9\u4e9b\u5de5\u5177\u8fdb\u884c\u6284\u88ad\u3002", "method": "\u7814\u7a76\u8005\u5728\u4e00\u95e8\u5927\u89c4\u6a21\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\uff08n=120\uff09\u4e2d\uff0c\u901a\u8fc7\u533f\u540d\u95ee\u5377\u8c03\u67e5\u548c\u9762\u8c08\uff0c\u8bc4\u4f30\u7528\u533f\u540d\u8c03\u67e5\u91cf\u5316AI\u6284\u88ad\u884c\u4e3a\u7684\u53ef\u884c\u6027\u3002", "result": "\u8d85\u8fc725%\u7684\u53d7\u8bbf\u5b66\u751f\u627f\u8ba4\u5b58\u5728AI\u6284\u88ad\u884c\u4e3a\uff0c\u4f46\u4ec5\u6709\u4e00\u540d\u5b66\u751f\u540c\u610f\u63a5\u53d7\u9762\u8c08\u3002", "conclusion": "\u95ee\u5377\u8c03\u67e5\u662f\u4e00\u79cd\u6709\u6548\u8bc4\u4f30AI\u6284\u88ad\u7684\u9014\u5f84\uff0c\u800c\u9762\u8c08\u56e0\u54cd\u5e94\u7387\u4f4e\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u6216\u907f\u514d\u4f7f\u7528\u3002"}}
{"id": "2507.06415", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06415", "abs": "https://arxiv.org/abs/2507.06415", "authors": ["Zeming Chen", "Angelika Romanou", "Gail Weiss", "Antoine Bosselut"], "title": "PERK: Long-Context Reasoning as Parameter-Efficient Test-Time Learning", "comment": "10 pages, 7 figures", "summary": "Long-context reasoning requires accurately identifying relevant information\nin extensive, noisy input contexts. Previous research shows that using\ntest-time learning to encode context directly into model parameters can\neffectively enable reasoning over noisy information. However, meta-learning\nmethods for enabling test-time learning are prohibitively memory-intensive,\npreventing their application to long context settings. In this work, we propose\nPERK (Parameter Efficient Reasoning over Knowledge), a scalable approach for\nlearning to encode long input contexts using gradient updates to a lightweight\nmodel adapter at test time. Specifically, PERK employs two nested optimization\nloops in a meta-training phase. The inner loop rapidly encodes contexts into a\nlow-rank adapter (LoRA) that serves as a parameter-efficient memory module for\nthe base model. Concurrently, the outer loop learns to use the updated adapter\nto accurately recall and reason over relevant information from the encoded long\ncontext. Our evaluations on several long-context reasoning tasks show that PERK\nsignificantly outperforms the standard prompt-based long-context baseline,\nachieving average absolute performance gains of up to 90% for smaller models\n(GPT-2) and up to 27% for our largest evaluated model, Qwen-2.5-0.5B. In\ngeneral, PERK is more robust to reasoning complexity, length extrapolation, and\nthe locations of relevant information in contexts. Finally, we show that while\nPERK is memory-intensive during training, it scales more efficiently at\ninference time than prompt-based long-context inference.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPERK\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6d4b\u8bd5\u65f6\u5bf9\u4f4e\u79e9\u9002\u914d\u5668\u8fdb\u884c\u66f4\u65b0\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u9ad8\u6027\u80fd\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u3002\u5b9e\u9a8c\u663e\u793aPERK\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u517c\u5177\u5f3a\u5927\u63a8\u7406\u80fd\u529b\u548c\u63a8\u7406\u9636\u6bb5\u7684\u5185\u5b58\u9ad8\u6548\u6027\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u9700\u8981\u5728\u5927\u91cf\u5608\u6742\u7684\u8f93\u5165\u4fe1\u606f\u4e2d\u51c6\u786e\u8bc6\u522b\u6709\u7528\u5185\u5bb9\uff0c\u4f46\u76ee\u524d\u7684\u5143\u5b66\u4e60\u65b9\u6cd5\u5185\u5b58\u6d88\u8017\u6781\u5927\uff0c\u96be\u4ee5\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u5e94\u7528\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u5185\u5b58\u4e0e\u6548\u7387\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aPERK\uff08Parameter Efficient Reasoning over Knowledge\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6d4b\u8bd5\u65f6\u5bf9\u8f7b\u91cf\u7ea7\u6a21\u578b\u9002\u914d\u5668\u8fdb\u884c\u68af\u5ea6\u66f4\u65b0\uff0c\u5c06\u957f\u8f93\u5165\u4e0a\u4e0b\u6587\u7f16\u7801\u5230\u53c2\u6570\u4e2d\u3002\u91c7\u7528\u4e24\u4e2a\u5d4c\u5957\u7684\u4f18\u5316\u5faa\u73af\uff1a\u5185\u5faa\u73af\u5feb\u901f\u7f16\u5199\u4e0a\u4e0b\u6587\u5230\u4f4e\u79e9\u9002\u914d\u5668\uff08LoRA\uff09\uff0c\u4f5c\u4e3a\u9ad8\u6548\u7684\u8bb0\u5fc6\u6a21\u5757\uff1b\u5916\u5faa\u73af\u5219\u5b66\u4e60\u5982\u4f55\u5229\u7528\u66f4\u65b0\u540e\u7684\u9002\u914d\u5668\u51c6\u786e\u56de\u5fc6\u548c\u63a8\u7406\u76f8\u5173\u4fe1\u606f\u3002", "result": "\u5728\u591a\u4e2a\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u4e0a\uff0cPERK\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u57fa\u4e8e\u63d0\u793a\u7684\u957f\u4e0a\u4e0b\u6587\u65b9\u6cd5\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u8f83\u5c0f\u6a21\u578b\uff08GPT-2\uff09\u5e73\u5747\u7edd\u5bf9\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe90%\uff0c\u6700\u5927\u6a21\u578b\uff08Qwen-2.5-0.5B\uff09\u63d0\u5347\u81f327%\u3002PERK\u5bf9\u63a8\u7406\u590d\u6742\u5ea6\u3001\u957f\u5ea6\u5916\u63a8\u4ee5\u53ca\u5173\u952e\u4fe1\u606f\u4f4d\u7f6e\u66f4\u5177\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u5728\u63a8\u7406\u9636\u6bb5\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u9ad8\u6548\u3002", "conclusion": "PERK\u80fd\u591f\u9ad8\u6548\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u65b9\u6cd5\u5728\u6027\u80fd\u4e0e\u63a8\u7406\u6548\u7387\u4e0a\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002\u5c3d\u7ba1\u8bad\u7ec3\u65f6\u5185\u5b58\u6d88\u8017\u8f83\u9ad8\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\uff08\u63a8\u7406\uff09\u4e2d\u5c55\u73b0\u4e86\u8f83\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u679c\u3002"}}
{"id": "2507.06993", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.06993", "abs": "https://arxiv.org/abs/2507.06993", "authors": ["Jieren Deng", "Aleksandar Cvetkovic", "Pak Kiu Chung", "Dragomir Yankov", "Chiqun Zhang"], "title": "The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation", "comment": null, "summary": "Traditional travel-planning systems are often static and fragmented, leaving\nthem ill-equipped to handle real-world complexities such as evolving\nenvironmental conditions and unexpected itinerary disruptions. In this paper,\nwe identify three gaps between existing service providers causing frustrating\nuser experience: intelligent trip planning, precision \"last-100-meter\"\nnavigation, and dynamic itinerary adaptation. We propose three cooperative\nagents: a Travel Planning Agent that employs grid-based spatial grounding and\nmap analysis to help resolve complex multi-modal user queries; a Destination\nAssistant Agent that provides fine-grained guidance for the final navigation\nleg of each journey; and a Local Discovery Agent that leverages image\nembeddings and Retrieval-Augmented Generation (RAG) to detect and respond to\ntrip plan disruptions. With evaluations and experiments, our system\ndemonstrates substantial improvements in query interpretation, navigation\naccuracy, and disruption resilience, underscoring its promise for applications\nfrom urban exploration to emergency response.", "AI": {"tldr": "\u9488\u5bf9\u4f20\u7edf\u65c5\u6e38\u7cfb\u7edf\u5728\u667a\u80fd\u89c4\u5212\u3001\u672b\u7aef\u5bfc\u822a\u548c\u52a8\u6001\u8c03\u6574\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u672c\u6587\u63d0\u51fa\u4e09\u667a\u80fd\u4f53\u7cfb\u7edf\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u67e5\u8be2\u7406\u89e3\u3001\u5bfc\u822a\u7cbe\u5ea6\u548c\u5e94\u5bf9\u884c\u7a0b\u610f\u5916\u7684\u80fd\u529b\uff0c\u589e\u5f3a\u4e86\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u4f20\u7edf\u7684\u65c5\u6e38\u89c4\u5212\u7cfb\u7edf\u5b58\u5728\u9759\u6001\u548c\u5272\u88c2\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u5e94\u5bf9\u73af\u5883\u53d8\u5316\u548c\u884c\u7a0b\u5e72\u6270\uff0c\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\u3002\u73b0\u6709\u7cfb\u7edf\u5728\u667a\u80fd\u89c4\u5212\u3001\u672b\u7aef\u5bfc\u822a\u3001\u52a8\u6001\u8c03\u6574\u65b9\u9762\u5b58\u5728\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u534f\u4f5c\u667a\u80fd\u4f53\uff1a\u65c5\u884c\u89c4\u5212\u667a\u80fd\u4f53\uff08\u501f\u52a9\u7f51\u683c\u5316\u7a7a\u95f4\u57fa\u7840\u4e0e\u5730\u56fe\u5206\u6790\u5904\u7406\u591a\u6a21\u6001\u67e5\u8be2\uff09\u3001\u76ee\u7684\u5730\u52a9\u624b\u667a\u80fd\u4f53\uff08\u7cbe\u7ec6\u5316\u5f15\u5bfc\u7528\u6237\u5b8c\u6210\u6700\u540e\u4e00\u6bb5\u8def\u7ebf\uff09\u3001\u672c\u5730\u53d1\u73b0\u667a\u80fd\u4f53\uff08\u5229\u7528\u56fe\u50cf\u5d4c\u5165\u4e0eRAG\u6280\u672f\u5e94\u5bf9\u7a81\u53d1\u53d8\u52a8\uff09\u3002", "result": "\u7cfb\u7edf\u5728\u67e5\u8be2\u89e3\u91ca\u3001\u5bfc\u822a\u7cbe\u5ea6\u53ca\u5e94\u5bf9\u884c\u7a0b\u4e2d\u65ad\u80fd\u529b\u4e0a\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u7cfb\u7edf\u663e\u8457\u6539\u5584\u4e86\u65c5\u884c\u4e2d\u667a\u80fd\u89c4\u5212\u3001\u672b\u7aef\u5bfc\u822a\u548c\u52a8\u6001\u8c03\u6574\u7684\u80fd\u529b\uff0c\u80fd\u591f\u5b9e\u9645\u5e94\u7528\u4e8e\u57ce\u5e02\u63a2\u7d22\u548c\u5e94\u6025\u54cd\u5e94\u7b49\u573a\u666f\u3002"}}
{"id": "2507.06640", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2507.06640", "abs": "https://arxiv.org/abs/2507.06640", "authors": ["Yelena Mejova", "Ronald E. Robertson", "Catherine A. Gimbrone", "Sarah McKetta"], "title": "Google Search Advertising after Dobbs v. Jackson", "comment": null, "summary": "Search engines have become the gateway to information, products, and\nservices, including those concerning healthcare. Access to reproductive health\nhas been especially complicated in the wake of the 2022 Dobbs v. Jackson\ndecision by the Supreme Court of the United States, splintering abortion\nregulations among the states. In this study, we performed an audit of the\nadvertisements shown to Google Search users seeking information about abortion\nacross the United States during the year following the Dobbs decision. We found\nthat Crisis Pregnancy Centers (CPCs) -- organizations that target women with\nunexpected or \"crisis\" pregnancies, but do not provide abortions -- accounted\nfor 47% of advertisements, whereas abortion clinics -- for 30%. Advertisements\nfrom CPCs were often returned for queries concerning information and safety.\nThe type of advertisements returned, however, varied widely within each state,\nwith Arizona returning the most advertisements from abortion clinics and other\npro-choice organizations, and Minnesota the least. The proportion of pro-choice\nvs. anti-choice advertisements returned also varied over time, but estimates\nfrom Staggered Augmented Synthetic Control Methods did not indicate that\nchanges in advertisement results were attributable to changes in state abortion\nlaws. Our findings raise questions about the access to accurate medical\ninformation across the U.S. and point to a need for further examination of\nsearch engine advertisement policies and geographical bias.", "AI": {"tldr": "\u7f8e\u56fd\u6700\u9ad8\u6cd5\u9662Dobbs\u5224\u51b3\u540e\uff0c\u8c37\u6b4c\u4e0a\u4e0e\u5815\u80ce\u76f8\u5173\u5e7f\u544a\u7531CPCs\u4e3b\u5bfc\uff0c\u800c\u5815\u80ce\u8bca\u6240\u5e7f\u544a\u8f83\u5c11\u3002\u5e7f\u544a\u7c7b\u578b\u968f\u5dde\u53ca\u65f6\u95f4\u53d8\u5316\u5927\u4f46\u4e0e\u6cd5\u5f8b\u65e0\u663e\u8457\u8054\u7cfb\uff0c\u63d0\u793a\u641c\u7d22\u5f15\u64ce\u5e7f\u544a\u5b58\u5728\u4fe1\u606f\u83b7\u53d6\u4e0d\u516c\u548c\u5730\u57df\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u81ea2022\u5e74\u7f8e\u56fd\u6700\u9ad8\u6cd5\u9662Dobbs v. Jackson\u5224\u51b3\u540e\uff0c\u5404\u5dde\u5bf9\u5815\u80ce\u7684\u6cd5\u89c4\u5dee\u5f02\u52a0\u5927\uff0c\u5f71\u54cd\u5230\u4eba\u4eec\u83b7\u53d6\u751f\u6b96\u5065\u5eb7\u4fe1\u606f\u7684\u65b9\u5f0f\u3002\u9274\u4e8e\u641c\u7d22\u5f15\u64ce\u5df2\u6210\u4e3a\u533b\u7597\u4fe1\u606f\u7684\u4e3b\u8981\u83b7\u53d6\u6e20\u9053\uff0c\u7814\u7a76\u5e0c\u671b\u4e86\u89e3\u7528\u6237\u5728\u8c37\u6b4c\u641c\u7d22\u4e0e\u5815\u80ce\u76f8\u5173\u4fe1\u606f\u65f6\u63a5\u6536\u5230\u7684\u5e7f\u544a\u5185\u5bb9\uff0c\u4ece\u800c\u8bc4\u4f30\u4fe1\u606f\u7684\u51c6\u786e\u6027\u548c\u83b7\u53d6\u516c\u5e73\u6027\u3002", "method": "\u4f5c\u8005\u5bf9\u7f8e\u56fd\u5404\u5dde\u8303\u56f4\u5185\u7528\u6237\u5728\u8c37\u6b4c\u641c\u7d22\u5815\u80ce\u4fe1\u606f\u65f6\u770b\u5230\u7684\u5e7f\u544a\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u5ba1\u67e5\uff0c\u6db5\u76d6Dobbs\u5224\u51b3\u540e\u7684\u4e00\u5e74\u3002\u901a\u8fc7\u6536\u96c6\u548c\u7edf\u8ba1\u5404\u7c7b\u578b\u5e7f\u544a\uff08\u5371\u673a\u6000\u5b55\u4e2d\u5fc3\u4e0e\u5815\u80ce\u8bca\u6240\u7b49\uff09\u51fa\u73b0\u7684\u6bd4\u4f8b\uff0c\u5e76\u4f7f\u7528\u9636\u68af\u589e\u5f3a\u5408\u6210\u63a7\u5236\u65b9\u6cd5\uff08Staggered Augmented Synthetic Control Methods\uff09\u5206\u6790\u5e7f\u544a\u53d8\u5316\u4e0e\u5dde\u6cd5\u5f8b\u53d8\u5316\u7684\u5173\u8054\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5371\u673a\u6000\u5b55\u4e2d\u5fc3\uff08CPCs\uff09\u5360\u5e7f\u544a\u768447%\uff0c\u5815\u80ce\u8bca\u6240\u4ec5\u536030%\u3002CPCs\u5e7f\u544a\u4e0d\u4ec5\u6570\u91cf\u591a\uff0c\u8fd8\u5e38\u51fa\u73b0\u5728\u7528\u6237\u68c0\u7d22\u4fe1\u606f\u548c\u5b89\u5168\u76f8\u5173\u67e5\u8be2\u65f6\u3002\u5dde\u4e0e\u5dde\u4e4b\u95f4\u5e7f\u544a\u7c7b\u578b\u5dee\u5f02\u5927\uff0c\u4f8b\u5982\u4e9a\u5229\u6851\u90a3\u5dde\u4ee5\u5815\u80ce\u8bca\u6240\u5e7f\u544a\u5c45\u591a\uff0c\u660e\u5c3c\u82cf\u8fbe\u5dde\u6700\u5c11\u3002\u867d\u7136\u5404\u5dde\u5e7f\u544a\u6bd4\u4f8b\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u4f46\u65b9\u6cd5\u5206\u6790\u663e\u793a\uff0c\u8fd9\u4e9b\u53d8\u5316\u672a\u4e0e\u5404\u5dde\u5815\u80ce\u6cd5\u5f8b\u53d8\u5316\u663e\u8457\u76f8\u5173\u3002", "conclusion": "\u5404\u5730\u8c37\u6b4c\u641c\u7d22\u7ed3\u679c\u4e2d\uff0c\u5bfb\u6c42\u5815\u80ce\u4fe1\u606f\u7684\u7528\u6237\u9762\u4e34\u5927\u91cf\u7531\u4e0d\u63d0\u4f9b\u5815\u80ce\u670d\u52a1\u7684\u5371\u673a\u6000\u5b55\u4e2d\u5fc3\u5e7f\u544a\uff0c\u610f\u5473\u7740\u83b7\u53d6\u533b\u7597\u4fe1\u606f\u53d7\u5230\u9650\u5236\u4e14\u7cbe\u51c6\u5ea6\u5b58\u7591\u3002\u9700\u8981\u5bf9\u641c\u7d22\u5f15\u64ce\u5e7f\u544a\u653f\u7b56\u548c\u5730\u57df\u504f\u5dee\u8fdb\u884c\u66f4\u6df1\u5165\u7814\u7a76\uff0c\u4ee5\u4fdd\u969c\u533b\u7597\u4fe1\u606f\u7684\u51c6\u786e\u4e0e\u516c\u5e73\u83b7\u53d6\u3002"}}
{"id": "2507.06419", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06419", "abs": "https://arxiv.org/abs/2507.06419", "authors": ["Pankayaraj Pathmanathan", "Furong Huang"], "title": "Reward Models Can Improve Themselves: Reward-Guided Adversarial Failure Mode Discovery for Robust Reward Modeling", "comment": null, "summary": "Reward modeling (RM), which captures human preferences to align large\nlanguage models (LLMs), is increasingly employed in tasks such as model\nfinetuning, response filtering, and ranking. However, due to the inherent\ncomplexity of human preferences and the limited coverage of available datasets,\nreward models often fail under distributional shifts or adversarial\nperturbations. Existing approaches for identifying such failure modes typically\nrely on prior knowledge about preference distributions or failure attributes,\nlimiting their practicality in real-world settings where such information is\nunavailable. In this work, we propose a tractable, preference-distribution\nagnostic method for discovering reward model failure modes via reward guided\ncontrolled decoding. Building on this, we introduce REFORM, a self-improving\nreward modeling framework that enhances robustness by using the reward model\nitself to guide the generation of falsely scored responses. These adversarial\nexamples are then used to augment the training data and patch the reward\nmodel's misaligned behavior. We evaluate REFORM on two widely used preference\ndatasets Anthropic Helpful Harmless (HH) and PKU Beavertails and demonstrate\nthat it significantly improves robustness without sacrificing reward quality.\nNotably, REFORM preserves performance both in direct evaluation and in\ndownstream policy training, and further improves alignment quality by removing\nspurious correlations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86REFORM\u6846\u67b6\uff0c\u5229\u7528\u5956\u52b1\u6a21\u578b\u81ea\u8eab\u751f\u6210\u5e76\u4fee\u590d\u5bf9\u6297\u6027\u5931\u8d25\u6837\u672c\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5956\u52b1\u5efa\u6a21\u5728\u5b9e\u9645\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u4e0e\u5bf9\u9f50\u8d28\u91cf\uff0c\u65e0\u9700\u4f9d\u8d56\u504f\u597d\u5206\u5e03\u5148\u9a8c\u3002", "motivation": "\u73b0\u6709\u7684\u5956\u52b1\u6a21\u578b\u5728\u5bf9\u9f50\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u7531\u4e8e\u4eba\u7c7b\u504f\u597d\u7684\u590d\u6742\u6027\u548c\u6570\u636e\u96c6\u8986\u76d6\u6709\u9650\uff0c\u7ecf\u5e38\u5728\u5206\u5e03\u8f6c\u79fb\u6216\u5bf9\u6297\u6270\u52a8\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5bf9\u8fd9\u4e9b\u5931\u8d25\u6a21\u5f0f\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u5b9e\u9645\u4f7f\u7528\u4e2d\u7f3a\u4e4f\u901a\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0e\u504f\u597d\u5206\u5e03\u65e0\u5173\u3001\u53ef\u884c\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5956\u52b1\u5f15\u5bfc\u7684\u53ef\u63a7\u89e3\u7801\u53d1\u73b0\u5956\u52b1\u6a21\u578b\u7684\u5931\u8d25\u6a21\u5f0f\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86REFORM\u6846\u67b6\uff0c\u901a\u8fc7\u5956\u52b1\u6a21\u578b\u81ea\u8eab\u6307\u5bfc\u751f\u6210\u9519\u8bef\u8bc4\u5206\u7684\u56de\u7b54\uff0c\u751f\u6210\u5bf9\u6297\u6837\u672c\u7528\u4e8e\u6269\u5145\u8bad\u7ec3\u6570\u636e\uff0c\u4ece\u800c\u4fee\u590d\u5956\u52b1\u6a21\u578b\u7684\u8bef\u884c\u4e3a\u3002", "result": "\u5728Anthropic HH\u548cPKU Beavertails\u4e24\u4e2a\u4e3b\u6d41\u504f\u597d\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cREFORM\u663e\u8457\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u4e0d\u4f1a\u635f\u5931\u5956\u52b1\u8d28\u91cf\u3002\u5728\u76f4\u63a5\u8bc4\u4f30\u548c\u4e0b\u6e38\u7b56\u7565\u8bad\u7ec3\u4e2d\u5747\u4fdd\u6301\u4e86\u6027\u80fd\uff0c\u8fd8\u901a\u8fc7\u53bb\u9664\u865a\u5047\u76f8\u5173\u6027\u63d0\u5347\u4e86\u5bf9\u9f50\u8d28\u91cf\u3002", "conclusion": "REFORM\u6846\u67b6\u80fd\u5728\u65e0\u9700\u504f\u597d\u5206\u5e03\u5148\u9a8c\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u53d1\u73b0\u5e76\u4fee\u590d\u5956\u52b1\u6a21\u578b\u7684\u5931\u6548\u6a21\u5f0f\uff0c\u5b9e\u8d28\u6027\u63d0\u5347\u5bf9\u9f50\u548c\u9c81\u68d2\u6027\uff0c\u5bf9\u5b9e\u9645\u5956\u52b1\u5efa\u6a21\u6709\u8f83\u9ad8\u4ef7\u503c\u3002"}}
{"id": "2507.07017", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07017", "abs": "https://arxiv.org/abs/2507.07017", "authors": ["Tianyu Zheng", "Tianshun Xing", "Qingshui Gu", "Taoran Liang", "Xingwei Qu", "Xin Zhou", "Yizhi Li", "Zhoufutu Wen", "Chenghua Lin", "Wenhao Huang", "Qian Liu", "Ge Zhang", "Zejun Ma"], "title": "First Return, Entropy-Eliciting Explore", "comment": null, "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning\nabilities of Large Language Models (LLMs) but it struggles with unstable\nexploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a\nstructured exploration framework that identifies high-uncertainty decision\npoints in reasoning trajectories and performs targeted rollouts to construct\nsemantically grounded intermediate feedback. Our method provides targeted\nguidance without relying on dense supervision. Empirical results on\nmathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable\ntraining, produces longer and more coherent responses, and increases the\nproportion of fully correct trajectories. These results highlight the\nframework's effectiveness in improving LLM reasoning through more robust and\nstructured exploration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ed3\u6784\u5316\u63a2\u7d22\u6846\u67b6 FR3E\uff0c\u901a\u8fc7\u8bc6\u522b\u9ad8\u4e0d\u786e\u5b9a\u6027\u7684\u63a8\u7406\u51b3\u7b56\u70b9\u5e76\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684rollout\uff0c\u89e3\u51b3\u4e86RLVR\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u8868\u73b0\uff0c\u8bad\u7ec3\u66f4\u7a33\u5b9a\u3001\u8f93\u51fa\u66f4\u4f18\u8d28\u3002", "motivation": "\u73b0\u6709\u7684\u53ef\u9a8c\u8bc1\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u867d\u7136\u80fd\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u63a2\u7d22\u9636\u6bb5\u5b58\u5728\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u6539\u8fdb\u63a2\u7d22\u7b56\u7565\uff0c\u4fc3\u8fdb\u66f4\u7a33\u5b9a\u548c\u6709\u6548\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faFR3E\u6846\u67b6\uff08First Return, Entropy-Eliciting Explore\uff09\uff0c\u8be5\u65b9\u6cd5\u5728\u63a8\u7406\u8f68\u8ff9\u4e2d\u8bc6\u522b\u9ad8\u4e0d\u786e\u5b9a\u6027\u7684\u51b3\u7b56\u70b9\uff0c\u5e76\u5bf9\u8fd9\u4e9b\u70b9\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684rollout\uff0c\u751f\u6210\u6709\u8bed\u4e49\u57fa\u7840\u7684\u4e2d\u95f4\u53cd\u9988\uff0c\u65e0\u9700\u4f9d\u8d56\u5bc6\u96c6\u76d1\u7763\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08AIME24\uff09\u4e0a\uff0cFR3E\u5e26\u6765\u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\uff0c\u751f\u6210\u66f4\u957f\u4e14\u66f4\u8fde\u8d2f\u7684\u56de\u7b54\uff0c\u63d0\u9ad8\u4e86\u5b8c\u5168\u6b63\u786e\u63a8\u7406\u8f68\u8ff9\u7684\u6bd4\u4f8b\u3002", "conclusion": "FR3E\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u63a2\u7d22\uff0c\u6709\u6548\u589e\u5f3a\u4e86LLM\u7684\u63a8\u7406\u8868\u73b0\uff0c\u8868\u660e\u7a33\u5065\u6709\u9488\u5bf9\u6027\u7684\u63a2\u7d22\u7b56\u7565\u5bf9\u63d0\u5347\u6a21\u578b\u80fd\u529b\u6709\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2507.06827", "categories": ["cs.CY", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.06827", "abs": "https://arxiv.org/abs/2507.06827", "authors": ["Dibakar Das", "Barath S Narayan", "Aarna Bhammar", "Jyotsna Bapat"], "title": "Connecting the Unconnected -- Sentiment Analysis of Field Survey of Internet Connectivity in Emerging Economies", "comment": null, "summary": "Internet has significantly improved the quality of citizens across the world.\nThough the internet coverage is quite high, 40% of global population do not\nhave access to broadband internet. This paper presents an analysis of a field\nsurvey of population in some areas of Kathmandu, Nepal, an emerging economy.\nThis survey was triggered by intermittent severe congestion of internet in\ncertain areas of the city. People from three different areas were asked about\ntheir present experience of internet usage, its impact on their lives and their\naspirations for the future. Survey pointed to high speed, low cost, reliable\nand secure internet as a major aspiration of the respondents. Based on their\ninputs, this paper presents a sentiment analysis as well as demographic\ninformation. Keys insights from this analysis shows that overall sentiment to\nmost queries are positive. The variances of positive sentiments are high\nwhereas those for negative ones are low. Also, some correlations and clusters\nare observed among the attributes though no dominant component exists in the\ndata.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf9\u5c3c\u6cca\u5c14\u52a0\u5fb7\u6ee1\u90fd\u90e8\u5206\u533a\u57df\u5c45\u6c11\u4e92\u8054\u7f51\u4f7f\u7528\u72b6\u51b5\u7684\u95ee\u5377\u8c03\u67e5\uff0c\u63ed\u793a\u4e86\u7528\u6237\u5bf9\u4e92\u8054\u7f51\u666e\u53ca\u7684\u79ef\u6781\u6001\u5ea6\u53ca\u5bf9\u9ad8\u6548\u4f18\u8d28\u7f51\u7edc\u670d\u52a1\u7684\u5f3a\u70c8\u671f\u671b\uff0c\u5e76\u57fa\u4e8e\u6570\u636e\u5206\u6790\u53d1\u73b0\u5404\u5c5e\u6027\u95f4\u867d\u6709\u4e00\u5b9a\u5173\u8054\uff0c\u4f46\u65e0\u5355\u4e00\u4e3b\u5bfc\u56e0\u7d20\u3002", "motivation": "\u56e0\u90e8\u5206\u5730\u533a\u4e92\u8054\u7f51\u4e25\u91cd\u62e5\u5835\uff0c\u4e9f\u9700\u4e86\u89e3\u5e02\u6c11\u5b9e\u9645\u4e92\u8054\u7f51\u4f7f\u7528\u72b6\u51b5\u3001\u4e3b\u8981\u8bc9\u6c42\u53ca\u672a\u6765\u671f\u671b\u3002", "method": "\u901a\u8fc7\u5bf9\u52a0\u5fb7\u6ee1\u90fd\u90e8\u5206\u5730\u533a\u5c45\u6c11\u8fdb\u884c\u5b9e\u5730\u95ee\u5377\u8c03\u67e5\uff0c\u5e76\u7ed3\u5408\u60c5\u611f\u5206\u6790\u4e0e\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\uff0c\u5bf9\u4e92\u8054\u7f51\u4f7f\u7528\u4f53\u9a8c\u53ca\u5176\u5f71\u54cd\u8fdb\u884c\u5206\u6790\u3002", "result": "\u8c03\u67e5\u663e\u793a\u7528\u6237\u6700\u671f\u671b\u83b7\u5f97\u9ad8\u901f\u3001\u4f4e\u4ef7\u3001\u53ef\u9760\u4e14\u5b89\u5168\u7684\u4e92\u8054\u7f51\u670d\u52a1\u3002\u5927\u90e8\u5206\u95ee\u9898\u53cd\u9988\u7684\u6b63\u9762\u60c5\u611f\u8f83\u591a\uff0c\u8d1f\u9762\u60c5\u611f\u7684\u65b9\u5dee\u8f83\u5c0f\u3002\u5728\u5c5e\u6027\u4e4b\u95f4\u53d1\u73b0\u76f8\u5173\u6027\u548c\u805a\u7c7b\u73b0\u8c61\uff0c\u4f46\u6570\u636e\u4e2d\u4e0d\u5b58\u5728\u4e3b\u5bfc\u6210\u5206\u3002", "conclusion": "\u6574\u4f53\u6765\u770b\uff0c\u53d7\u8bbf\u8005\u5bf9\u4e92\u8054\u7f51\u7684\u6001\u5ea6\u5927\u591a\u662f\u79ef\u6781\u7684\uff0c\u4f46\u7f3a\u4e4f\u5355\u4e00\u4e3b\u5bfc\u56e0\u7d20\u3002"}}
{"id": "2507.06427", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06427", "abs": "https://arxiv.org/abs/2507.06427", "authors": ["Shun Wang", "Tyler Loakman", "Youbo Lei", "Yi Liu", "Bohao Yang", "Yuting Zhao", "Dong Yang", "Chenghua Lin"], "title": "Exploring Task Performance with Interpretable Models via Sparse Auto-Encoders", "comment": null, "summary": "Large Language Models (LLMs) are traditionally viewed as black-box\nalgorithms, therefore reducing trustworthiness and obscuring potential\napproaches to increasing performance on downstream tasks. In this work, we\napply an effective LLM decomposition method using a dictionary-learning\napproach with sparse autoencoders. This helps extract monosemantic features\nfrom polysemantic LLM neurons. Remarkably, our work identifies model-internal\nmisunderstanding, allowing the automatic reformulation of the prompts with\nadditional annotations to improve the interpretation by LLMs. Moreover, this\napproach demonstrates a significant performance improvement in downstream\ntasks, such as mathematical reasoning and metaphor detection.", "AI": {"tldr": "\u672c\u7814\u7a76\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u89e3\u6784\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6539\u8fdb\u4e86\u6a21\u578b\u7406\u89e3\u3001\u63d0\u793a\u91cd\u5199\u548c\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\uff0c\u63d0\u9ad8\u4e86\u53ef\u4fe1\u5ea6\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u8ba4\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u9ed1\u7bb1\u7b97\u6cd5\uff0c\u96be\u4ee5\u7406\u89e3\u5176\u5185\u90e8\u673a\u5236\uff0c\u8fd9\u964d\u4f4e\u4e86\u5176\u53ef\u4fe1\u5ea6\uff0c\u4e5f\u963b\u788d\u4e86\u63d0\u5347\u6a21\u578b\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u65b9\u6cd5\u5f00\u53d1\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u5b57\u5178\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06LLM\u4e2d\u7684\u591a\u4e49\u795e\u7ecf\u5143\u5206\u89e3\u51fa\u5355\u4e00\u8bed\u4e49\u7279\u5f81\uff08monosemantic features\uff09\u3002", "result": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63ed\u793a\u4e86\u6a21\u578b\u5185\u90e8\u7684\u8bef\u89e3\uff0c\u8fd8\u80fd\u81ea\u52a8\u91cd\u5199\u63d0\u793a\uff08prompts\uff09\u5e76\u52a0\u5165\u6ce8\u91ca\uff0c\u4ece\u800c\u63d0\u5347\u4e86LLM\u5bf9\u8f93\u5165\u7684\u7406\u89e3\u3002\u540c\u65f6\uff0c\u5728\u6570\u5b66\u63a8\u7406\u548c\u9690\u55bb\u68c0\u6d4b\u7b49\u4e0b\u6e38\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u6a21\u578b\u89e3\u6784\uff0c\u80fd\u66f4\u597d\u5730\u7406\u89e3\u4e0e\u63d0\u5347LLM\u7684\u8868\u73b0\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u4e0b\u6e38\u4efb\u52a1\u5e26\u6765\u6027\u80fd\u4e0a\u7684\u63d0\u5347\u3002"}}
{"id": "2507.06876", "categories": ["cs.CY", "cs.AI", "I.2; J.4; K.4.0"], "pdf": "https://arxiv.org/pdf/2507.06876", "abs": "https://arxiv.org/abs/2507.06876", "authors": ["Adrian Rauchfleisch", "Joshua Philip Suarez", "Nikka Marie Sales", "Andreas Jungherr"], "title": "Winning and losing with Artificial Intelligence: What public discourse about ChatGPT tells us about how societies make sense of technological change", "comment": null, "summary": "Public product launches in Artificial Intelligence can serve as focusing\nevents for collective attention, surfacing how societies react to technological\nchange. Social media provide a window into the sensemaking around these events,\nsurfacing hopes and fears and showing who chooses to engage in the discourse\nand when. We demonstrate that public sensemaking about AI is shaped by economic\ninterests and cultural values of those involved. We analyze 3.8 million tweets\nposted by 1.6 million users across 117 countries in response to the public\nlaunch of ChatGPT in 2022. Our analysis shows how economic self-interest,\nproxied by occupational skill types in writing, programming, and mathematics,\nand national cultural orientations, as measured by Hofstede's individualism,\nuncertainty avoidance, and power distance dimensions, shape who speaks, when\nthey speak, and their stance towards ChatGPT. Roles requiring more technical\nskills, such as programming and mathematics, tend to engage earlier and express\nmore positive stances, whereas writing-centric occupations join later with\ngreater skepticism. At the cultural level, individualism predicts both earlier\nengagement and a more negative stance, and uncertainty avoidance reduces the\nprevalence of positive stances but does not delay when users first engage with\nChatGPT. Aggregate sentiment trends mask the dynamics observed in our study.\nThe shift toward a more critical stance towards ChatGPT over time stems\nprimarily from the entry of more skeptical voices rather than a change of heart\namong early adopters. Our findings underscore the importance of both the\noccupational background and cultural context in understanding public reactions\nto AI.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86ChatGPT\u53d1\u5e03\u540eTwitter\u4e0a\u7684\u5168\u7403\u8ba8\u8bba\uff0c\u53d1\u73b0\u4e0d\u540c\u804c\u4e1a\u548c\u6587\u5316\u80cc\u666f\u663e\u8457\u5f71\u54cd\u4e86\u516c\u4f17\u4f55\u65f6\u3001\u4ee5\u4f55\u79cd\u6001\u5ea6\u53c2\u4e0eAI\u8bdd\u9898\u3002\u6280\u672f\u7c7b\u804c\u4e1a\u66f4\u79ef\u6781\uff0c\u5199\u4f5c\u7c7b\u66f4\u6000\u7591\uff1b\u6587\u5316\u4e0a\uff0c\u4e2a\u4eba\u4e3b\u4e49\u9ad8\u56fd\u5bb6\u66f4\u65e9\u4f46\u66f4\u6279\u5224\u6027\u3002\u4e0d\u540c\u65f6\u671f\u7684\u60c5\u7eea\u53d8\u5316\u4e3b\u8981\u6765\u81ea\u65b0\u7fa4\u4f53\u7684\u52a0\u5165\uff0c\u800c\u975e\u65e9\u671f\u53c2\u4e0e\u8005\u6001\u5ea6\u8f6c\u53d8\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u9886\u57df\u7684\u516c\u5171\u4ea7\u54c1\u53d1\u5e03\u5f80\u5f80\u80fd\u5f15\u53d1\u793e\u4f1a\u7684\u5e7f\u6cdb\u5173\u6ce8\uff0c\u4f46\u4e0d\u540c\u4eba\u7fa4\u548c\u6587\u5316\u80cc\u666f\u5982\u4f55\u5f71\u54cd\u4ed6\u4eec\u5bf9AI\u4e8b\u4ef6\u7684\u611f\u77e5\u4e0e\u56de\u5e94\u5c1a\u4e0d\u6e05\u695a\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u91cf\u5316\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u8ba8\u8bba\uff0c\u63a2\u7d22\u7ecf\u6d4e\u5229\u76ca\u548c\u6587\u5316\u4ef7\u503c\u89c2\u5982\u4f55\u5851\u9020\u516c\u4f17\u5bf9AI\uff08\u5982ChatGPT\uff09\uff0c\u7279\u522b\u662f\u5728\u5176\u53d1\u5e03\u521d\u671f\u7684\u96c6\u4f53\u53cd\u5e94\u3002", "method": "\u5206\u6790\u4e862022\u5e74ChatGPT\u516c\u5f00\u53d1\u5e03\u540e\uff0c\u6765\u81ea117\u4e2a\u56fd\u5bb6160\u4e07\u7528\u6237\u53d1\u7684380\u4e07\u6761\u63a8\u6587\u3002\u5229\u7528\u7528\u6237\u804c\u4e1a\u6280\u80fd\u7c7b\u578b\uff08\u5199\u4f5c\u3001\u7f16\u7a0b\u3001\u6570\u5b66\uff09\u8fd1\u4f3c\u7ecf\u6d4e\u5229\u76ca\uff0c\u7528\u970d\u592b\u65af\u6cf0\u5fb7\u6587\u5316\u7ef4\u5ea6\uff08\u4e2a\u4eba\u4e3b\u4e49\u3001\u4e0d\u786e\u5b9a\u6027\u89c4\u907f\u3001\u6743\u529b\u8ddd\u79bb\uff09\u91cf\u5316\u56fd\u5bb6\u6587\u5316\u53d6\u5411\uff0c\u901a\u8fc7\u5185\u5bb9\u5206\u6790\u4e0e\u5206\u7fa4\u7b49\u65b9\u6cd5\u5224\u65ad\u4e0d\u540c\u7fa4\u4f53\u7684\u6d3b\u8dc3\u65f6\u95f4\u3001\u53c2\u4e0e\u5f3a\u5ea6\u4e0e\u6001\u5ea6\u503e\u5411\u3002", "result": "\u6280\u672f\u578b\u5c97\u4f4d\uff08\u5982\u7f16\u7a0b\u3001\u6570\u5b66\uff09\u7684\u4eba\u66f4\u65e9\u53c2\u4e0e\uff0c\u6001\u5ea6\u66f4\u79ef\u6781\uff0c\u800c\u5199\u4f5c\u7c7b\u5c97\u4f4d\u7528\u6237\u66f4\u665a\u52a0\u5165\u5e76\u6301\u66f4\u6000\u7591\u7684\u6001\u5ea6\uff1b\u56fd\u5bb6\u5c42\u9762\uff0c\u4e2a\u4eba\u4e3b\u4e49\u66f4\u9ad8\u7684\u793e\u4f1a\u4eba\u7fa4\u66f4\u65e9\u53c2\u4e0e\u8ba8\u8bba\u5374\u66f4\u6d88\u6781\uff0c\u4e0d\u786e\u5b9a\u6027\u89c4\u907f\u8f83\u9ad8\u7684\u4eba\u7fa4\u867d\u4e0d\u5f71\u54cd\u52a0\u5165\u901f\u5ea6\u4f46\u66f4\u5c11\u8868\u8fbe\u79ef\u6781\u6001\u5ea6\u3002\u6574\u4f53\u4e0a\uff0c\u5bf9ChatGPT\u7684\u8d1f\u9762\u6001\u5ea6\u5e76\u975e\u65e9\u671f\u7528\u6237\u6001\u5ea6\u8f6c\u53d8\uff0c\u800c\u662f\u540e\u7eed\u66f4\u6301\u6000\u7591\u6001\u5ea6\u7fa4\u4f53\u7684\u52a0\u5165\u5bfc\u81f4\u3002", "conclusion": "\u516c\u4f17\u5bf9AI\u4ea7\u54c1\u7684\u53cd\u5e94\u53d7\u804c\u4e1a\u7c7b\u578b\u4e0e\u6587\u5316\u56e0\u7d20\u53cc\u91cd\u5f71\u54cd\u3002\u672a\u6765AI\u6280\u672f\u63a8\u5e7f\u548c\u8ba8\u8bba\u9700\u8981\u6df1\u5165\u8003\u8651\u4e0d\u540c\u7ecf\u6d4e\u5229\u76ca\u76f8\u5173\u8005\u53ca\u6587\u5316\u80cc\u666f\u4eba\u7fa4\u7684\u8bc9\u6c42\u548c\u7acb\u573a\u3002"}}
{"id": "2507.06435", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06435", "abs": "https://arxiv.org/abs/2507.06435", "authors": ["Rafiu Adekoya Badekale", "Adewale Akinfaderin"], "title": "Temporal Analysis of Climate Policy Discourse: Insights from Dynamic Embedded Topic Modeling", "comment": "10 pages, 7 figures. Code and data available at\n  https://github.com/AdeTheBade/TACPD.git", "summary": "Understanding how policy language evolves over time is critical for assessing\nglobal responses to complex challenges such as climate change. Temporal\nanalysis helps stakeholders, including policymakers and researchers, to\nevaluate past priorities, identify emerging themes, design governance\nstrategies, and develop mitigation measures. Traditional approaches, such as\nmanual thematic coding, are time-consuming and limited in capturing the\ncomplex, interconnected nature of global policy discourse. With the increasing\nrelevance of unsupervised machine learning, these limitations can be addressed,\nparticularly under high-volume, complex, and high-dimensional data conditions.\nIn this work, we explore a novel approach that applies the dynamic embedded\ntopic model (DETM) to analyze the evolution of global climate policy discourse.\nA probabilistic model designed to capture the temporal dynamics of topics over\ntime. We collected a corpus of United Nations Framework Convention on Climate\nChange (UNFCCC) policy decisions from 1995 to 2023, excluding 2020 due to the\npostponement of COP26 as a result of the COVID-19 pandemic. The model reveals\nshifts from early emphases on greenhouse gases and international conventions to\nrecent focuses on implementation, technical collaboration, capacity building,\nfinance, and global agreements. Section 3 presents the modeling pipeline,\nincluding preprocessing, model training, and visualization of temporal word\ndistributions. Our results show that DETM is a scalable and effective tool for\nanalyzing the evolution of global policy discourse. Section 4 discusses the\nimplications of these findings and we concluded with future directions and\nrefinements to extend this approach to other policy domains.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8eDETM\u6a21\u578b\uff0c\u81ea\u52a8\u5206\u6790\u4e861995-2023\u5e74\u8054\u5408\u56fd\u6c14\u5019\u653f\u7b56\u6587\u672c\u7684\u4e3b\u9898\u53d8\u5316\uff0c\u5b9e\u73b0\u4e86\u653f\u7b56\u6f14\u5316\u8d8b\u52bf\u7684\u9ad8\u6548\u8ffd\u8e2a\uff0c\u4e3a\u5168\u7403\u6cbb\u7406\u4e0e\u5e94\u5bf9\u590d\u6742\u5371\u673a\u63d0\u4f9b\u4e86\u6570\u636e\u652f\u6301\u548c\u65b9\u6cd5\u521b\u65b0\u3002", "motivation": "\u7406\u89e3\u653f\u7b56\u8bed\u8a00\u968f\u65f6\u95f4\u7684\u6f14\u53d8\uff0c\u5bf9\u8bc4\u4f30\u5168\u7403\u5e94\u5bf9\u590d\u6742\u6311\u6218\uff08\u5982\u6c14\u5019\u53d8\u5316\uff09\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u4eba\u5de5\u7f16\u7801\u65b9\u6cd5\u6548\u7387\u4f4e\u3001\u96be\u4ee5\u6355\u6349\u590d\u6742\u8bdd\u8bed\u8054\u7cfb\uff0c\u4e9f\u9700\u5f15\u5165\u66f4\u9ad8\u6548\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u6536\u96c61995-2023\u5e74\u8054\u5408\u56fd\u6c14\u5019\u53d8\u5316\u6846\u67b6\u516c\u7ea6\uff08UNFCCC\uff09\u653f\u7b56\u51b3\u7b56\u6587\u672c\uff0c\u91c7\u7528DETM\u6a21\u578b\u8fdb\u884c\u4e3b\u9898\u6f14\u5316\u5efa\u6a21\uff0c\u5305\u62ec\u6570\u636e\u9884\u5904\u7406\u3001\u6a21\u578b\u8bad\u7ec3\u53ca\u8bcd\u5206\u5e03\u65f6\u5e8f\u53ef\u89c6\u5316\u3002", "result": "\u6a21\u578b\u63ed\u793a\u4e86\u653f\u7b56\u8bdd\u8bed\u91cd\u5fc3\u4ece\u65e9\u671f\u7684\u6e29\u5ba4\u6c14\u4f53\u548c\u56fd\u9645\u516c\u7ea6\uff0c\u9010\u6b65\u8f6c\u5411\u8fd1\u671f\u7684\u5b9e\u65bd\u3001\u6280\u672f\u5408\u4f5c\u3001\u80fd\u529b\u5efa\u8bbe\u3001\u91d1\u878d\u652f\u6301\u548c\u5168\u7403\u534f\u5b9a\u7b49\u9886\u57df\u3002", "conclusion": "DETM\uff08\u52a8\u6001\u5d4c\u5165\u4e3b\u9898\u6a21\u578b\uff09\u80fd\u591f\u6709\u6548\u3001\u53ef\u6269\u5c55\u5730\u5206\u6790\u5168\u7403\u653f\u7b56\u8bdd\u8bed\u7684\u6f14\u53d8\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u548c\u4e3b\u9898\u8ffd\u8e2a\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u540e\u7eed\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u653f\u7b56\u9886\u57df\u3002"}}
{"id": "2507.06878", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.06878", "abs": "https://arxiv.org/abs/2507.06878", "authors": ["Lucile Favero", "Juan-Antonio P\u00e9rez-Ortiz", "Tanja K\u00e4ser", "Nuria Oliver"], "title": "Do AI tutors empower or enslave learners? Toward a critical use of AI in education", "comment": "Applications of Generative AI to support teaching and learning in\n  Higher Education, co-located with AIED 2025. Palermo Italy", "summary": "The increasing integration of AI tools in education presents both\nopportunities and challenges, particularly regarding the development of the\nstudents' critical thinking skills. This position paper argues that while AI\ncan support learning, its unchecked use may lead to cognitive atrophy, loss of\nagency, emotional risks, and ethical concerns, ultimately undermining the core\ngoals of education. Drawing on cognitive science and pedagogy, the paper\nexplores how over-reliance on AI can disrupt meaningful learning, foster\ndependency and conformity, undermine the students' self-efficacy, academic\nintegrity, and well-being, and raise concerns about questionable privacy\npractices. It also highlights the importance of considering the students'\nperspectives and proposes actionable strategies to ensure that AI serves as a\nmeaningful support rather than a cognitive shortcut. The paper advocates for an\nintentional, transparent, and critically informed use of AI that empowers\nrather than diminishes the learner.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u6559\u80b2\u9886\u57dfAI\u5de5\u5177\u5e26\u6765\u7684\u673a\u9047\u4e0e\u6311\u6218\uff0c\u8b66\u793a\u8fc7\u5ea6\u4f9d\u8d56AI\u4f1a\u635f\u5bb3\u5b66\u751f\u80fd\u529b\u4e0e\u798f\u7949\uff0c\u5e76\u4e3b\u5f20\u91c7\u53d6\u4ee5\u5b66\u751f\u4e3a\u672c\u3001\u660e\u786e\u4e14\u8d1f\u8d23\u4efb\u7684AI\u4f7f\u7528\u7b56\u7565\u3002", "motivation": "\u968f\u7740AI\u5de5\u5177\u5728\u6559\u80b2\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5982\u4f55\u5e73\u8861\u5176\u8d4b\u80fd\u4f5c\u7528\u4e0e\u5bf9\u5b66\u751f\u5173\u952e\u80fd\u529b\uff08\u5982\u6279\u5224\u6027\u601d\u7ef4\uff09\u6f5c\u5728\u5a01\u80c1\u6210\u4e3a\u91cd\u8981\u8bae\u9898\u3002", "method": "\u672c\u6587\u7acb\u573a\u8bba\u6587\uff0c\u7ed3\u5408\u8ba4\u77e5\u79d1\u5b66\u4e0e\u6559\u80b2\u5b66\u7406\u8bba\u5206\u6790AI\u5728\u6559\u5b66\u4e2d\u7684\u4f5c\u7528\u53ca\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u5177\u4f53\u7b56\u7565\uff0c\u65e8\u5728\u5c06AI\u4f5c\u4e3a\u6709\u6548\u7684\u5b66\u4e60\u8f85\u52a9\u800c\u975e\u8ba4\u77e5\u6377\u5f84\u3002", "result": "AI\u5de5\u5177\u82e5\u4e0d\u52a0\u7ba1\u63a7\uff0c\u53ef\u80fd\u5bfc\u81f4\u5b66\u751f\u8ba4\u77e5\u9000\u5316\u3001\u81ea\u4e3b\u6027\u4e27\u5931\u3001\u60c5\u611f\u98ce\u9669\u4e0e\u4f26\u7406\u9690\u5fe7\uff0c\u7834\u574f\u6559\u80b2\u7684\u6839\u672c\u76ee\u6807\u3002\u91c7\u53d6\u900f\u660e\u3001\u5ba1\u614e\u3001\u4ee5\u5b66\u751f\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\u3002", "conclusion": "\u5e94\u9f13\u52b1\u6709\u610f\u8bc6\u3001\u900f\u660e\u3001\u6279\u5224\u6027\u5730\u4f7f\u7528AI\uff0c\u8ba9\u5176\u6210\u4e3a\u52a9\u529b\u800c\u975e\u969c\u788d\uff0c\u4ece\u800c\u771f\u6b63\u8d4b\u6743\u5b66\u751f\u800c\u975e\u524a\u5f31\u5176\u80fd\u529b\u3002"}}
{"id": "2507.06448", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06448", "abs": "https://arxiv.org/abs/2507.06448", "authors": ["Zhenhailong Wang", "Xuehang Guo", "Sofia Stoica", "Haiyang Xu", "Hongru Wang", "Hyeonjeong Ha", "Xiusi Chen", "Yangyi Chen", "Ming Yan", "Fei Huang", "Heng Ji"], "title": "Perception-Aware Policy Optimization for Multimodal Reasoning", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a\nhighly effective strategy for endowing Large Language Models (LLMs) with robust\nmulti-step reasoning abilities. However, its design and optimizations remain\ntailored to purely textual domains, resulting in suboptimal performance when\napplied to multimodal reasoning tasks. In particular, we observe that a major\nsource of error in current multimodal reasoning lies in the perception of\nvisual inputs. To address this bottleneck, we propose Perception-Aware Policy\nOptimization (PAPO), a simple yet effective extension of GRPO that encourages\nthe model to learn to perceive while learning to reason, entirely from internal\nsupervision signals. Notably, PAPO does not rely on additional data curation,\nexternal reward models, or proprietary models. Specifically, we introduce the\nImplicit Perception Loss in the form of a KL divergence term to the GRPO\nobjective, which, despite its simplicity, yields significant overall\nimprovements (4.4%) on diverse multimodal benchmarks. The improvements are more\npronounced, approaching 8.0%, on tasks with high vision dependency. We also\nobserve a substantial reduction (30.5%) in perception errors, indicating\nimproved perceptual capabilities with PAPO. We conduct comprehensive analysis\nof PAPO and identify a unique loss hacking issue, which we rigorously analyze\nand mitigate through a Double Entropy Loss. Overall, our work introduces a\ndeeper integration of perception-aware supervision into RLVR learning\nobjectives and lays the groundwork for a new RL framework that encourages\nvisually grounded reasoning. Project page: https://mikewangwzhl.github.io/PAPO.", "AI": {"tldr": "\u8be5\u5de5\u4f5c\u63d0\u51faPAPO\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u7684\u611f\u77e5\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u65e0\u9700\u65b0\u589e\u5916\u90e8\u6570\u636e\u6216\u5956\u52b1\uff0c\u5c24\u5176\u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u540c\u65f6\u8fd8\u7f13\u89e3\u4e86\u635f\u5931\u653b\u7834\u95ee\u9898\uff0c\u662fRLVR\u7684\u4e00\u5927\u8fdb\u6b65\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u65b9\u6cd5\u867d\u7136\u5728\u6587\u672c\u9886\u57df\u5927\u5e45\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u6b65\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u591a\u6a21\u6001\u63a8\u7406\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u89c6\u89c9\u611f\u77e5\u80fd\u529b\u4e0d\u8db3\uff0c\u5bfc\u81f4\u611f\u77e5\u8f93\u5165\u7684\u9519\u8bef\u9891\u53d1\u3002\u4f5c\u8005\u5e0c\u671b\u63d0\u5347\u6a21\u578b\u5728\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u7684\u611f\u77e5\u548c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u611f\u77e5\u611f\u77e5\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff08PAPO\uff09\uff0c\u8fd9\u662f\u5bf9GRPO\u7684\u6269\u5c55\u3002PAPO\u5728\u76ee\u6807\u4e2d\u52a0\u5165\u4e86\u9690\u5f0f\u611f\u77e5\u635f\u5931\uff08KL\u6563\u5ea6\u9879\uff09\uff0c\u5b9e\u73b0\u611f\u77e5\u4e0e\u63a8\u7406\u7684\u540c\u6b65\u5b66\u4e60\uff0c\u4e14\u4ec5\u4f9d\u8d56\u6a21\u578b\u5185\u90e8\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u65e0\u9700\u65b0\u589e\u6570\u636e\u3001\u5916\u90e8\u5956\u52b1\u6216\u4e13\u6709\u6a21\u578b\u3002\u8bba\u6587\u8fd8\u63d0\u51fa\u4e86Double Entropy Loss\u6765\u7f13\u89e3\u65b0\u53d1\u73b0\u7684\u635f\u5931\u88ab\u653b\u7834\uff08loss hacking\uff09\u95ee\u9898\u3002", "result": "PAPO\u5728\u591a\u6837\u5316\u591a\u6a21\u6001\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e864.4%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728\u5f3a\u4f9d\u8d56\u89c6\u89c9\u7684\u4efb\u52a1\u4e0a\u63d0\u5347\u63a5\u8fd18.0%\u3002\u611f\u77e5\u9519\u8bef\u51cf\u5c11\u4e8630.5%\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u611f\u77e5\u80fd\u529b\u3002\u8fd8\u4e13\u95e8\u5206\u6790\u5e76\u89e3\u51b3\u4e86\u635f\u5931\u653b\u7834\u95ee\u9898\u3002", "conclusion": "PAPO\u6709\u6548\u5c06\u611f\u77e5\u80fd\u529b\u7eb3\u5165RLVR\u76ee\u6807\u4e2d\uff0c\u4e3a\u591a\u6a21\u6001\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u5177\u89c6\u89c9\u4f9d\u8d56\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u65b0\u65b9\u6cd5\uff0c\u5e76\u89e3\u51b3\u4e86\u611f\u77e5\u65b9\u9762\u7684\u77ed\u677f\u3002\u4e3a\u672a\u6765\u57fa\u4e8e\u89c6\u89c9\u7684\u63a8\u7406\u578bRL\u6846\u67b6\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.07047", "categories": ["cs.CY", "cs.HC", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.07047", "abs": "https://arxiv.org/abs/2507.07047", "authors": ["Yuan Li", "Teja Mandaloju", "Haihua Chen"], "title": "Exploring Public Perceptions of Generative AI in Libraries: A Social Media Analysis of X Discussions", "comment": null, "summary": "This study investigates public perceptions of generative artificial\nintelligence (GenAI) in libraries through a large-scale analysis of posts on X\n(formerly Twitter). Using a mixed-method approach that combines temporal trend\nanalysis, sentiment classification, and social network analysis, this paper\nexplores how public discourse around GenAI and libraries has evolved over time,\nthe emotional tones that dominate the conversation, and the key users or\norganizations driving engagement. The findings reveal that discussions are\npredominantly negative in tone, with surges linked to concerns about ethics and\nintellectual property. Furthermore, social network analysis identifies both\ninstitutional authority and individual bridge users who facilitate cross-domain\nengagement. The results in this paper contribute to the growing body of\nliterature on GenAI in the library and GLAM (Galleries, Libraries, Archives,\nand Museums) sectors and offer a real-time, public-facing perspective on the\nemerging opportunities and concerns GenAI presents.", "AI": {"tldr": "\u672c\u7814\u7a76\u5927\u89c4\u6a21\u5206\u6790\u4e86X\u5e73\u53f0\u4e0a\u5173\u4e8e\u751f\u6210\u5f0fAI\u5728\u56fe\u4e66\u9986\u7684\u8ba8\u8bba\uff0c\u53d1\u73b0\u516c\u4f17\u8ba8\u8bba\u666e\u904d\u8f83\u4e3a\u8d1f\u9762\uff0c\u5173\u6ce8\u70b9\u96c6\u4e2d\u5728\u4f26\u7406\u548c\u77e5\u8bc6\u4ea7\u6743\u95ee\u9898\uff0c\u793e\u4ea4\u7f51\u7edc\u4e2d\u65e2\u6709\u6743\u5a01\u673a\u6784\u4e5f\u6709\u4fc3\u8fdb\u8de8\u754c\u4ea4\u6d41\u7684\u4e2a\u4eba\u7528\u6237\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u56fe\u4e66\u9986\u53caGLAM\u884c\u4e1a\u7684\u5e94\u7528\u65e5\u76ca\u589e\u52a0\uff0c\u4e86\u89e3\u516c\u4f17\u5bf9\u5176\u7684\u8ba4\u77e5\u4e0e\u8ba8\u8bba\uff0c\u5bf9\u4e8e\u9884\u6d4b\u548c\u5f15\u5bfc\u672a\u6765\u53d1\u5c55\u65b9\u5411\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u4e86\u6df7\u5408\u65b9\u6cd5\uff0c\u5305\u62ec\u65f6\u95f4\u8d8b\u52bf\u5206\u6790\u3001\u60c5\u611f\u5206\u7c7b\u548c\u793e\u4ea4\u7f51\u7edc\u5206\u6790\uff0c\u5bf9X\u5e73\u53f0\u4e0a\u7684\u76f8\u5173\u5e16\u5b50\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\u3002", "result": "\u8ba8\u8bba\u4e3b\u8981\u5448\u73b0\u8d1f\u9762\u60c5\u611f\u8272\u5f69\uff0c\u60c5\u611f\u6ce2\u52a8\u4e0e\u4f26\u7406\u4e0e\u77e5\u8bc6\u4ea7\u6743\u76f8\u5173\u8bdd\u9898\u5bc6\u5207\u76f8\u5173\u3002\u793e\u4ea4\u7f51\u7edc\u63ed\u793a\u4e86\u673a\u6784\u548c\u4e2a\u4eba\u5728\u63a8\u52a8\u8de8\u9886\u57df\u4ea4\u6d41\u4e2d\u7684\u4e0d\u540c\u4f5c\u7528\u3002", "conclusion": "\u516c\u5171\u5bf9\u8bdd\u5927\u591a\u6301\u8d1f\u9762\u6001\u5ea6\uff0c\u8d1f\u9762\u8ba8\u8bba\u4e3b\u8981\u56f4\u7ed5\u4f26\u7406\u4e0e\u77e5\u8bc6\u4ea7\u6743\u95ee\u9898\uff0c\u4e0eGenAI\u76f8\u5173\u7684\u8ba8\u8bba\u5728\u56fe\u4e66\u9986\u548cGLAM\u9886\u57df\u5c24\u4e3a\u96c6\u4e2d\uff0c\u793e\u4ea4\u7f51\u7edc\u4e2d\u65e2\u6709\u673a\u6784\u6743\u5a01\u4e5f\u6709\u4fc3\u8fdb\u884c\u4e1a\u4ea4\u53c9\u6c9f\u901a\u7684\u4e2a\u4eba\u7528\u6237\u3002"}}
{"id": "2507.06450", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06450", "abs": "https://arxiv.org/abs/2507.06450", "authors": ["Xin Su", "Sungduk Yu", "Phillip Howard", "Steven Bethard"], "title": "A Semantic Parsing Framework for End-to-End Time Normalization", "comment": null, "summary": "Time normalization is the task of converting natural language temporal\nexpressions into machine-readable representations. It underpins many downstream\napplications in information retrieval, question answering, and clinical\ndecision-making. Traditional systems based on the ISO-TimeML schema limit\nexpressivity and struggle with complex constructs such as compositional,\nevent-relative, and multi-span time expressions. In this work, we introduce a\nnovel formulation of time normalization as a code generation task grounded in\nthe SCATE framework, which defines temporal semantics through symbolic and\ncompositional operators. We implement a fully executable SCATE Python library\nand demonstrate that large language models (LLMs) can generate executable SCATE\ncode. Leveraging this capability, we develop an automatic data augmentation\npipeline using LLMs to synthesize large-scale annotated data with code-level\nvalidation. Our experiments show that small, locally deployable models trained\non this augmented data can achieve strong performance, outperforming even their\nLLM parents and enabling practical, accurate, and interpretable time\nnormalization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u65f6\u95f4\u5f52\u4e00\u5316\u89c6\u4e3a\u57fa\u4e8eSCATE\u6846\u67b6\u7684\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7LLM\u81ea\u52a8\u5408\u6210\u6570\u636e\u7528\u4e8e\u8bad\u7ec3\u5c0f\u578b\u53ef\u90e8\u7f72\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u65b9\u6cd5\u5927\u5e45\u63d0\u5347\u4e86\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5b9e\u73b0\u4e86\u8d85\u8d8a\u4f20\u7edf\u548c\u7236\u6a21\u578b\u7684\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u7684\u65f6\u95f4\u5f52\u4e00\u5316\u7cfb\u7edf\uff08\u5982ISO-TimeML\uff09\u8868\u8fbe\u80fd\u529b\u6709\u9650\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u7684\u65f6\u95f4\u8868\u8fbe\uff08\u5982\u7ec4\u5408\u578b\u3001\u4e8b\u4ef6\u76f8\u5173\u3001\u591a\u533a\u95f4\u65f6\u95f4\u8868\u8fbe\uff09\uff0c\u8fd9\u9650\u5236\u4e86\u4e0b\u6e38\u5e94\u7528\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u5c06\u65f6\u95f4\u5f52\u4e00\u5316\u4efb\u52a1\u8f6c\u5316\u4e3a\u57fa\u4e8eSCATE\u6846\u67b6\u7684\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u53ef\u6267\u884c\u7684SCATE Python\u5e93\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u751f\u6210\u5927\u91cf\u5e26\u6709\u4ee3\u7801\u7ea7\u6821\u9a8c\u7684\u6807\u6ce8\u6570\u636e\uff0c\u5e76\u7528\u6b64\u6570\u636e\u8bad\u7ec3\u5c0f\u578b\u672c\u5730\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u6570\u636e\u589e\u5f3a\u540e\u8bad\u7ec3\u7684\u5c0f\u578b\u672c\u5730\u6a21\u578b\u5728\u65f6\u95f4\u5f52\u4e00\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u751a\u81f3\u8d85\u8d8a\u4e86\u7528\u4e8e\u751f\u6210\u6570\u636e\u7684LLM\u672c\u8eab\uff0c\u4e14\u5177\u5907\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u65b0\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u53ca\u6570\u636e\u589e\u5f3a\u6d41\u7a0b\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u5f52\u4e00\u5316\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u8868\u8fbe\u548c\u6027\u80fd\u74f6\u9888\u3002"}}
{"id": "2507.07059", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2507.07059", "abs": "https://arxiv.org/abs/2507.07059", "authors": ["Meng Liang", "Xiaoyue Zhang", "Linqi Ye"], "title": "Girlhood Feminism as Soft Resistance: Affective Counterpublics and Algorithmic Negotiation on RedNote", "comment": "19 pages, 6 figures, AoIR Conference 2025", "summary": "This article explores how Chinese female users tactically mobilise platform\nfeatures and hashtag practices to construct vernacular forms and an exclusive\nspace of feminist resistance under algorithmic and cultural constraints.\nFocusing on the reappropriation of the hashtag Baby Supplementary Food (BSF), a\nfemale-dominated lifestyle app with over 300 million users, we analyse how\nusers create a female-centered counterpublic through self-infantilisation,\nalgorithmic play, and aesthetic withdrawal. Using the Computer-Assisted\nLearning and Measurement (CALM) framework, we analysed 1580 posts and propose\nthe concept of girlhood feminism: an affective, culturally grounded form of\nsoft resistance that refuses patriarchal life scripts without seeking direct\nconfrontation or visibility. Rather than challenging censorship and misogyny\ndirectly, users rework platform affordances and domestic idioms to carve out\nemotional and symbolic spaces of dissent. Situated within the broader dynamics\nof East Asia's compressed modernity, this essay challenges liberal feminist\nparadigms grounded in confrontation and transparency. It advances a regionally\ngrounded framework for understanding how gendered publics are navigated,\nnegotiated, and quietly reimagined in algorithmically governed spaces.", "AI": {"tldr": "\u4e2d\u56fd\u5973\u6027\u901a\u8fc7\u751f\u6d3b\u65b9\u5f0fApp\u548c\u6807\u7b7e\u5b9e\u8df5\uff0c\u5229\u7528\u201cgirlhood feminism\u201d\u6e29\u548c\u8868\u8fbe\u5973\u6743\u62b5\u6297\uff0c\u5728\u7b97\u6cd5\u548c\u6587\u5316\u9650\u5236\u4e0b\u521b\u9020\u9690\u79d8\u7684\u53cd\u6297\u7a7a\u95f4\uff0c\u63d0\u51fa\u4e1c\u4e9a\u672c\u571f\u5316\u7684\u89e3\u91ca\u6846\u67b6\uff0c\u533a\u522b\u4e8e\u897f\u65b9\u5bf9\u6297\u6027\u5973\u6743\u4e3b\u4e49\u3002", "motivation": "\u5728\u7b97\u6cd5\u548c\u6587\u5316\u53cc\u91cd\u538b\u5236\u4e0b\uff0c\u4e2d\u56fd\u5973\u6027\u5982\u4f55\u5229\u7528\u6570\u5b57\u5e73\u53f0\u5f00\u5c55\u5973\u6743\u62b5\u6297\uff0c\u4ee5\u53ca\u8fd9\u79cd\u62b5\u6297\u5f62\u5f0f\u4e0e\u897f\u65b9\u5bf9\u6297\u6027\u81ea\u7531\u5973\u6743\u4e3b\u4e49\u6709\u4f55\u4e0d\u540c\u3002", "method": "\u91c7\u7528Computer-Assisted Learning and Measurement\uff08CALM\uff09\u6846\u67b6\uff0c\u5206\u6790\u4e861580\u7bc7\u5973\u6027\u4e3b\u5bfc\u751f\u6d3b\u65b9\u5f0fApp\u4e2d\u7684\u76f8\u5173\u5e16\u5b50\uff0c\u901a\u8fc7\u5b9a\u6027\u548c\u5b9a\u91cf\u65b9\u6cd5\u89e3\u8bfb\u7528\u6237\u4e92\u52a8\u4e0e\u884c\u4e3a\u3002", "result": "\u7528\u6237\u901a\u8fc7\u81ea\u6211\u5e7c\u6001\u5316\u3001\u7b97\u6cd5\u620f\u800d\u548c\u5ba1\u7f8e\u64a4\u9000\u7b49\u7b56\u7565\uff0c\u5de7\u5999\u7ed5\u5f00\u5ba1\u67e5\u4e0e\u7236\u6743\u538b\u5236\uff0c\u521b\u9020\u4e86\u5bcc\u6709\u60c5\u611f\u4e0e\u8c61\u5f81\u610f\u4e49\u7684\u6297\u8bae\u7a7a\u95f4\u3002\u8fd9\u6539\u53d8\u4e86\u5973\u6743\u516c\u5171\u7a7a\u95f4\u7684\u8fd0\u4f5c\u548c\u8868\u8fbe\u65b9\u5f0f\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u201cgirlhood feminism\uff08\u5c11\u5973\u5973\u6743\u4e3b\u4e49\uff09\u201d\u7684\u6982\u5ff5\uff0c\u5f3a\u8c03\u4e2d\u56fd\u5973\u6027\u7528\u6237\u901a\u8fc7\u7b56\u7565\u6027\u5229\u7528\u5e73\u53f0\u548c\u6807\u7b7e\uff0c\u521b\u9020\u6e29\u548c\u3001\u60c5\u611f\u5316\u4f46\u6709\u6548\u7684\u62b5\u6297\u7a7a\u95f4\u3002\u8fd9\u79cd\u62b5\u6297\u89c4\u907f\u4e86\u76f4\u63a5\u5bf9\u6297\u548c\u53ef\u89c1\u6027\u6311\u6218\uff0c\u4ee5\u4f4e\u8c03\u548c\u60c5\u611f\u5171\u9e23\u65b9\u5f0f\u6539\u53d8\u6027\u522b\u8bdd\u8bed\u3002"}}
{"id": "2507.06457", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06457", "abs": "https://arxiv.org/abs/2507.06457", "authors": ["Dustin Wang", "Rui-Jie Zhu", "Steven Abreu", "Yong Shan", "Taylor Kergan", "Yuqi Pan", "Yuhong Chou", "Zheng Li", "Ge Zhang", "Wenhao Huang", "Jason Eshraghian"], "title": "A Systematic Analysis of Hybrid Linear Attention", "comment": null, "summary": "Transformers face quadratic complexity and memory issues with long sequences,\nprompting the adoption of linear attention mechanisms using fixed-size hidden\nstates. However, linear models often suffer from limited recall performance,\nleading to hybrid architectures that combine linear and full attention layers.\nDespite extensive hybrid architecture research, the choice of linear attention\ncomponent has not been deeply explored. We systematically evaluate various\nlinear attention models across generations - vector recurrences to advanced\ngating mechanisms - both standalone and hybridized. To enable this\ncomprehensive analysis, we trained and open-sourced 72 models: 36 at 340M\nparameters (20B tokens) and 36 at 1.3B parameters (100B tokens), covering six\nlinear attention variants across five hybridization ratios. Benchmarking on\nstandard language modeling and recall tasks reveals that superior standalone\nlinear models do not necessarily excel in hybrids. While language modeling\nremains stable across linear-to-full attention ratios, recall significantly\nimproves with increased full attention layers, particularly below a 3:1 ratio.\nOur study highlights selective gating, hierarchical recurrence, and controlled\nforgetting as critical for effective hybrid models. We recommend architectures\nsuch as HGRN-2 or GatedDeltaNet with a linear-to-full ratio between 3:1 and 6:1\nto achieve Transformer-level recall efficiently. Our models are open-sourced at\nhttps://huggingface.co/collections/m-a-p/hybrid-linear-attention-research-686c488a63d609d2f20e2b1e.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u6d4b\u4e86\u591a\u79cd\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u578b\u5728\u6df7\u5408\u7ed3\u6784\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u6df7\u5408\u6bd4\u4f8b\u548c\u67b6\u6784\u7684\u63a8\u8350\u3002\u7ed3\u679c\u663e\u793a\uff0c\u6df7\u5408\u4e2d\u5168\u6ce8\u610f\u529b\u5c42\u7684\u6bd4\u4f8b\u5bf9\u56de\u5fc6\u6027\u80fd\u5f71\u54cd\u8f83\u5927\uff0c\u9009\u62e9\u6027\u95e8\u63a7\u548c\u5206\u5c42\u673a\u5236\u81f3\u5173\u91cd\u8981\u3002\u5efa\u8bae3:1\u52306:1\u7684\u7ebf\u6027-\u5168\u6ce8\u610f\u529b\u6bd4\u4f8b\uff0c\u5e76\u5df2\u5f00\u6e90\u5168\u90e8\u5b9e\u9a8c\u6a21\u578b\u3002", "motivation": "Transformers\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\u9762\u4e34\u5e73\u65b9\u7ea7\u522b\u7684\u590d\u6742\u5ea6\u548c\u5185\u5b58\u74f6\u9888\uff0c\u56e0\u6b64\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u5e94\u8fd0\u800c\u751f\u3002\u4f46\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u578b\u5728\u56de\u5fc6\u6027\u80fd\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4fc3\u4f7f\u7814\u7a76\u8005\u63d0\u51fa\u7ebf\u6027-\u5168\u6ce8\u610f\u529b\u6df7\u5408\u7ed3\u6784\u3002\u7136\u800c\uff0c\u6df7\u5408\u67b6\u6784\u4e2d\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u5757\u7684\u5177\u4f53\u9009\u62e9\u5c1a\u672a\u88ab\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e86\u591a\u4ee3\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u578b\uff08\u4ece\u5411\u91cf\u9012\u5f52\u5230\u9ad8\u7ea7\u95e8\u63a7\u673a\u5236\uff09\uff0c\u65e2\u4f5c\u4e3a\u5355\u72ec\u6a21\u578b\u4e5f\u4f5c\u4e3a\u6df7\u5408\u578b\u6a21\u578b\u3002\u8bad\u7ec3\u4e86\u5e76\u5f00\u6e90\u4e8672\u4e2a\u6a21\u578b\uff0c\u6db5\u76d6\u516d\u79cd\u7ebf\u6027\u6ce8\u610f\u529b\u53d8\u4f53\u3001\u4e94\u79cd\u6df7\u5408\u6bd4\u4f8b\uff0c\u5728340M\u548c1.3B\u53c2\u6570\u89c4\u6a21\u300120B\u548c100B\u8bad\u7ec3Token\u4e0b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5728\u6807\u51c6\u8bed\u8a00\u5efa\u6a21\u4e0e\u56de\u5fc6\u4efb\u52a1\u4e0a\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0\u8868\u73b0\u8f83\u597d\u7684\u5355\u72ec\u7ebf\u6027\u6a21\u578b\u672a\u5fc5\u80fd\u5728\u6df7\u5408\u6a21\u578b\u4e2d\u7ef4\u6301\u4f18\u52bf\u3002\u968f\u7740\u5168\u6ce8\u610f\u529b\u5c42\u5360\u6bd4\u589e\u52a0\uff0c\u56de\u5fc6\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u57283:1\u4ee5\u4e0b\u6df7\u5408\u6bd4\u4f8b\u65f6\u3002\u800c\u8bed\u8a00\u5efa\u6a21\u80fd\u529b\u5728\u4e0d\u540c\u6df7\u5408\u6bd4\u4f8b\u4e0b\u76f8\u5bf9\u7a33\u5b9a\u3002\u5f3a\u8c03\u4e86\u9009\u62e9\u6027\u95e8\u63a7\u3001\u5206\u5c42\u9012\u5f52\u548c\u53ef\u63a7\u9057\u5fd8\u673a\u5236\u5728\u6df7\u5408\u67b6\u6784\u4e2d\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u5efa\u8bae\u91c7\u7528HGRN-2\u6216GatedDeltaNet\u7b49\u67b6\u6784\uff0c\u5e76\u5c06\u7ebf\u6027\u4e0e\u5168\u6ce8\u610f\u529b\u6df7\u5408\u6bd4\u4f8b\u8bbe\u7f6e\u57283:1\u52306:1\u4e4b\u95f4\uff0c\u4ee5\u5728\u6548\u7387\u548c\u56de\u5fc6\u80fd\u529b\u4e4b\u95f4\u53d6\u5f97Transformer\u7ea7\u522b\u7684\u5e73\u8861\u3002\u6240\u6709\u6a21\u578b\u5747\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.06489", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06489", "abs": "https://arxiv.org/abs/2507.06489", "authors": ["Stephen Obadinma", "Xiaodan Zhu"], "title": "On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks", "comment": null, "summary": "Robust verbal confidence generated by large language models (LLMs) is crucial\nfor the deployment of LLMs to ensure transparency, trust, and safety in\nhuman-AI interactions across many high-stakes applications. In this paper, we\npresent the first comprehensive study on the robustness of verbal confidence\nunder adversarial attacks. We introduce a novel framework for attacking verbal\nconfidence scores through both perturbation and jailbreak-based methods, and\nshow that these attacks can significantly jeopardize verbal confidence\nestimates and lead to frequent answer changes. We examine a variety of\nprompting strategies, model sizes, and application domains, revealing that\ncurrent confidence elicitation methods are vulnerable and that commonly used\ndefence techniques are largely ineffective or counterproductive. Our findings\nunderscore the urgent need to design more robust mechanisms for confidence\nexpression in LLMs, as even subtle semantic-preserving modifications can lead\nto misleading confidence in responses.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u8868\u8fbe\u4fe1\u5fc3\u65f6\u5728\u5bf9\u6297\u6027\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u653b\u51fb\u6846\u67b6\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u524d\u65b9\u6cd5\u5f88\u96be\u9632\u5fa1\u8fd9\u79cd\u653b\u51fb\uff0c\u51f8\u663e\u4e86\u8bbe\u8ba1\u66f4\u5065\u58ee\u4fe1\u5fc3\u8868\u8fbe\u673a\u5236\u7684\u7d27\u8feb\u6027\u3002", "motivation": "\u968f\u7740LLM\u5728\u5173\u952e\u9886\u57df\u7684\u5e94\u7528\uff0c\u5bf9\u5176\u751f\u6210\u7a33\u5b9a\u53ef\u9760\u4fe1\u5fc3\u8868\u8ff0\u7684\u9700\u6c42\u65e5\u76ca\u589e\u52a0\uff0c\u4ee5\u4fdd\u969c\u4eba\u673a\u4ea4\u4e92\u7684\u900f\u660e\u5ea6\u3001\u4fe1\u4efb\u4e0e\u5b89\u5168\u3002", "method": "\u63d0\u51fa\u4e86\u9488\u5bf9LLM\u53e3\u5934\u81ea\u4fe1\u5ea6\u7684\u65b0\u578b\u5e72\u6270\u4e0e\u7ed5\u8fc7\u5bf9\u6297\u653b\u51fb\u6846\u67b6\uff0c\u6d4b\u8bd5\u4e86\u4e0d\u540c\u7684\u63d0\u793a\u65b9\u5f0f\u3001\u6a21\u578b\u89c4\u6a21\u53ca\u5e94\u7528\u9886\u57df\u3002", "result": "\u5bf9\u6297\u6027\u653b\u51fb\u6781\u6613\u5f71\u54cd\u6a21\u578b\u7684\u53e3\u5934\u81ea\u4fe1\u8bc4\u5206\uff0c\u5f15\u53d1\u9891\u7e41\u7684\u7b54\u6848\u53d8\u52a8\uff0c\u800c\u76ee\u524d\u5e7f\u6cdb\u4f7f\u7528\u7684\u4fe1\u5fc3\u8868\u8fbe\u65b9\u5f0f\u4e0e\u9632\u5fa1\u6280\u672f\u65e0\u6cd5\u6709\u6548\u62b5\u5fa1\u6b64\u7c7b\u653b\u51fb\u3002", "conclusion": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7528\u4e8e\u8868\u8fbe\u81ea\u4fe1\u5ea6\u7684\u673a\u5236\u5728\u9762\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u65f6\u975e\u5e38\u8106\u5f31\uff0c\u73b0\u6709\u9632\u5fa1\u624b\u6bb5\u65e0\u6548\u751a\u81f3\u9002\u5f97\u5176\u53cd\u3002"}}
{"id": "2507.06506", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.06506", "abs": "https://arxiv.org/abs/2507.06506", "authors": ["Russell Taylor", "Benjamin Herbert", "Michael Sana"], "title": "Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings", "comment": "CLEF 2025 Working Notes, 9-12 September 2025, Madrid, Spain", "summary": "Translating wordplay across languages presents unique challenges that have\nlong confounded both professional human translators and machine translation\nsystems. This research proposes a novel approach for translating puns from\nEnglish to French by combining state-of-the-art large language models with\nspecialized techniques for wordplay generation.\n  Our methodology employs a three-stage approach. First, we establish a\nbaseline using multiple frontier large language models with feedback based on a\nnew contrastive learning dataset. Second, we implement a guided\nchain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we\nimplement a multi-agent generator-discriminator framework for evaluating and\nregenerating puns with feedback.\n  Moving beyond the limitations of literal translation, our methodology's\nprimary objective is to capture the linguistic creativity and humor of the\nsource text wordplay, rather than simply duplicating its vocabulary. Our best\nruns earned first and second place in the CLEF JOKER 2025 Task 2 competition\nwhere they were evaluated manually by expert native French speakers.\n  This research addresses a gap between translation studies and computational\nlinguistics by implementing linguistically-informed techniques for wordplay\ntranslation, advancing our understanding of how language models can be\nleveraged to handle the complex interplay between semantic ambiguity, phonetic\nsimilarity, and the implicit cultural and linguistic awareness needed for\nsuccessful humor.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u9896\u65b9\u6cd5\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4e13\u4e1a\u6280\u672f\uff0c\u5b9e\u73b0\u82f1\u6cd5\u6587\u5b57\u6e38\u620f\u9ad8\u8d28\u91cf\u7ffb\u8bd1\uff0c\u5728\u56fd\u9645\u7ade\u8d5b\u4e2d\u83b7\u4f73\u7ee9\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5e7d\u9ed8\u4e0e\u521b\u9020\u529b\u7684\u8de8\u8bed\u9645\u4f20\u9012\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7ffb\u8bd1\uff08\u5305\u62ec\u4eba\u5de5\u548c\u673a\u5668\uff09\u96be\u4ee5\u4fdd\u7559\u5b57\u8c1c\u3001\u53cc\u5173\u7b49\u6587\u5b57\u6e38\u620f\u7684\u5e7d\u9ed8\u548c\u521b\u9020\u529b\u3002\u672c\u7814\u7a76\u65e8\u5728\u7a81\u7834\u5b57\u9762\u7ffb\u8bd1\u9650\u5236\uff0c\u63a2\u7d22\u5982\u4f55\u66f4\u597d\u5730\u5c06\u6e90\u8bed\u8a00\u7684\u8bed\u8a00\u5de7\u601d\u548c\u6587\u5316\u5e7d\u9ed8\u4f20\u8fbe\u7ed9\u76ee\u6807\u8bed\u53d7\u4f17\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4e09\u9636\u6bb5\uff1a\u9996\u5148\u7528\u591a\u79cd\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u5efa\u7acb\u57fa\u7ebf\uff0c\u901a\u8fc7\u65b0\u5bf9\u6bd4\u5b66\u4e60\u6570\u636e\u96c6\u8fdb\u884c\u53cd\u9988\uff1b\u7b2c\u4e8c\uff0c\u5b9e\u65bd\u7ed3\u5408\u8bed\u97f3\u2014\u8bed\u4e49\u5d4c\u5165\u7684\u5f15\u5bfc\u5f0f\u601d\u8def\u94fe\u6d41\u7a0b\uff1b\u7b2c\u4e09\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u751f\u6210\u2014\u5224\u522b\u6846\u67b6\uff0c\u5bf9\u53cc\u5173\u8bed\u8fdb\u884c\u8bc4\u4ef7\u548c\u518d\u751f\u6210\u5e76\u6301\u7eed\u53cd\u9988\u3002", "result": "\u63d0\u51fa\u7684\u7cfb\u7edf\u5728CLEF JOKER 2025 Task 2\u7ade\u8d5b\u4e2d\u53d6\u5f97\u7b2c\u4e00\u548c\u7b2c\u4e8c\u540d\uff0c\u8868\u73b0\u4f18\u5f02\uff0c\u7ecf\u6cd5\u8bed\u6bcd\u8bed\u4e13\u5bb6\u4eba\u5de5\u8bc4\u5ba1\u8ba4\u53ef\u3002\u540c\u65f6\u63a8\u52a8\u4e86\u7ffb\u8bd1\u5b66\u4e0e\u8ba1\u7b97\u8bed\u8a00\u5b66\u7684\u4ea4\u53c9\u4e0e\u53d1\u5c55\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4e13\u95e8\u7684\u6587\u5b57\u6e38\u620f\u751f\u6210\u6280\u672f\uff0c\u80fd\u6709\u6548\u63d0\u5347\u82f1\u6cd5\u6587\u5b57\u6e38\u620f\u7ffb\u8bd1\u7684\u521b\u9020\u6027\u548c\u5e7d\u9ed8\u611f\u8868\u73b0\uff0c\u7a81\u7834\u4e86\u4ee5\u5f80\u76f4\u8bd1\u65e0\u6cd5\u4f20\u8fbe\u8da3\u5473\u548c\u673a\u667a\u7684\u5c40\u9650\u3002"}}
{"id": "2507.06910", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.06910", "abs": "https://arxiv.org/abs/2507.06910", "authors": ["Fareya Ikram", "Alexander Scarlatos", "Andrew Lan"], "title": "Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues", "comment": "Published in BEA 2025: 20th Workshop on Innovative Use of NLP for\n  Building Educational Applications", "summary": "Tutoring dialogues have gained significant attention in recent years, given\nthe prominence of online learning and the emerging tutoring abilities of\nartificial intelligence (AI) agents powered by large language models (LLMs).\nRecent studies have shown that the strategies used by tutors can have\nsignificant effects on student outcomes, necessitating methods to predict how\ntutors will behave and how their actions impact students. However, few works\nhave studied predicting tutor strategy in dialogues. Therefore, in this work we\ninvestigate the ability of modern LLMs, particularly Llama 3 and GPT-4o, to\npredict both future tutor moves and student outcomes in dialogues, using two\nmath tutoring dialogue datasets. We find that even state-of-the-art LLMs\nstruggle to predict future tutor strategy while tutor strategy is highly\nindicative of student outcomes, outlining a need for more powerful methods to\napproach this task.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\u672a\u6765\u7684\u5bfc\u5e08\u7b56\u7565\uff0c\u800c\u5bfc\u5e08\u7b56\u7565\u53c8\u5bf9\u5b66\u751f\u7ed3\u679c\u6709\u663e\u8457\u5f71\u54cd\uff0c\u8868\u660e\u9700\u8981\u5f00\u53d1\u66f4\u5f3a\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u5728\u7ebf\u5b66\u4e60\u5174\u8d77\u548c\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u52a8\u7684AI\u5bfc\u5e08\u80fd\u529b\u63d0\u5347\uff0c\u4fc3\u4f7f\u7814\u7a76\u4eba\u5458\u5173\u6ce8\u5bfc\u5e08\u5728\u8f85\u5bfc\u5bf9\u8bdd\u4e2d\u7684\u7b56\u7565\u5bf9\u5b66\u751f\u7ed3\u679c\u7684\u5f71\u54cd\u3002\u7136\u800c\uff0c\u5173\u4e8e\u9884\u6d4b\u5bfc\u5e08\u4e0b\u4e00\u6b65\u7b56\u7565\u7684\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u672c\u6587\u91c7\u7528Llama 3\u548cGPT-4o\u4e24\u79cd\u5148\u8fdb\u7684LLM\uff0c\u5bf9\u4e24\u4e2a\u6570\u5b66\u8f85\u5bfc\u5bf9\u8bdd\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u5176\u9884\u6d4b\u672a\u6765\u5bfc\u5e08\u884c\u4e3a\u548c\u5b66\u751f\u7ed3\u679c\u7684\u80fd\u529b\u3002", "result": "\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684LLM\u5728\u9884\u6d4b\u672a\u6765\u5bfc\u5e08\u7b56\u7565\u65b9\u9762\u4f9d\u7136\u8868\u73b0\u8f83\u5dee\uff0c\u800c\u8001\u5e08\u7684\u7b56\u7565\u5bf9\u5b66\u751f\u7ed3\u679c\u53c8\u6709\u5f88\u5f3a\u7684\u6307\u793a\u4f5c\u7528\u3002", "conclusion": "\u73b0\u6709LLM\u5728\u9884\u6d4b\u5bfc\u5e08\u7b56\u7565\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u8fd9\u4e00\u4efb\u52a1\u7684\u8868\u73b0\u3002"}}
{"id": "2507.06517", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06517", "abs": "https://arxiv.org/abs/2507.06517", "authors": ["Zicong Tang", "Shi Luohe", "Zuchao Li", "Baoyuan Qi", "Guoming Liu", "Lefei Zhang", "Ping Wang"], "title": "SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers", "comment": "Accepted by ACL 2025 main", "summary": "Large Language Models (LLMs) have achieved impressive accomplishments in\nrecent years. However, the increasing memory consumption of KV cache has\npossessed a significant challenge to the inference system. Eviction methods\nhave revealed the inherent redundancy within the KV cache, demonstrating its\npotential for reduction, particularly in deeper layers. However, KV cache\nreduction for shallower layers has been found to be insufficient. Based on our\nobservation that, the KV cache exhibits a high degree of similarity. Based on\nthis observation, we proposed a novel KV cache reduction method, SpindleKV,\nwhich balances both shallow and deep layers. For deep layers, we employ an\nattention weight based eviction method, while for shallow layers, we apply a\ncodebook based replacement approach which is learnt by similarity and merging\npolicy. Moreover, SpindleKV addressed the Grouped-Query Attention (GQA) dilemma\nfaced by other attention based eviction methods. Experiments on two common\nbenchmarks with three different LLMs shown that SpindleKV obtained better KV\ncache reduction effect compared to baseline methods, while preserving similar\nor even better model performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSpindleKV\uff0c\u4e00\u79cd\u517c\u987e\u6d45\u5c42\u548c\u6df1\u5c42KV\u7f13\u5b58\u538b\u7f29\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u51cf\u5c11\u5185\u5b58\u6d88\u8017\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "KV\u7f13\u5b58\u7684\u5185\u5b58\u6d88\u8017\u65e5\u76ca\u589e\u52a0\uff0c\u6210\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7cfb\u7edf\u4e2d\u7684\u6311\u6218\u3002\u867d\u7136\u73b0\u6709\u65b9\u6cd5\u53d1\u73b0\u6df1\u5c42KV\u7f13\u5b58\u6709\u5197\u4f59\u53ef\u538b\u7f29\uff0c\u4f46\u6d45\u5c42KV\u7f13\u5b58\u538b\u7f29\u6548\u679c\u6709\u9650\u3002\u4f5c\u8005\u6ce8\u610f\u5230KV\u7f13\u5b58\u9ad8\u5ea6\u76f8\u4f3c\u6027\uff0c\u9a71\u52a8\u65b0\u65b9\u6cd5\u63d0\u51fa\u3002", "method": "\u63d0\u51faSpindleKV\uff0c\u4e00\u79cd\u9488\u5bf9\u4e0d\u540c\u5c42\u6b21\u91c7\u53d6\u4e0d\u540c\u7b56\u7565\u7684KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff1a\u6df1\u5c42\u91c7\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u6743\u91cd\u7684\u9a71\u9010\u673a\u5236\uff1b\u6d45\u5c42\u91c7\u7528\u901a\u8fc7\u76f8\u4f3c\u6027\u5b66\u4e60\u548c\u5408\u5e76\u7b56\u7565\u8bad\u7ec3\u51fa\u7684\u7801\u672c\u66ff\u6362\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5206\u7ec4\u67e5\u8be2\u6ce8\u610f\u529b\uff08GQA\uff09\u673a\u5236\u4e0b\u7684\u96be\u9898\u3002", "result": "\u5728\u4e24\u4e2a\u5e38\u7528\u57fa\u51c6\u548c\u4e09\u79cd\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\uff0cSpindleKV\u5b9e\u73b0\u4e86\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u66f4\u597d\u7684KV\u7f13\u5b58\u538b\u7f29\u6548\u679c\uff0c\u5e76\u4fdd\u6301\u4e86\u76f8\u8fd1\u6216\u66f4\u4f18\u7684\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "SpindleKV\u65b9\u6cd5\u5728\u538b\u7f29KV\u7f13\u5b58\u65b9\u9762\u53d6\u5f97\u4e86\u4f18\u5f02\u8868\u73b0\uff0c\u80fd\u6709\u6548\u51cf\u5c11\u5185\u5b58\u6d88\u8017\u4e14\u4e0d\u5f71\u54cd\u6a21\u578b\u7cbe\u5ea6\uff0c\u5c24\u5176\u89e3\u51b3\u4e86\u4e0d\u540c\u5c42\u7ea7KV\u7f13\u5b58\u538b\u7f29\u7684\u5e73\u8861\u548cGQA\u96be\u9898\u3002"}}
{"id": "2507.06528", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06528", "abs": "https://arxiv.org/abs/2507.06528", "authors": ["Huisheng Wang", "Zhuoshi Pan", "Hangjing Zhang", "Mingxiao Liu", "Hanqing Gao", "H. Vicky Zhao"], "title": "InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior", "comment": null, "summary": "Aligning Large Language Models (LLMs) with investor decision-making processes\nunder herd behavior is a critical challenge in behavioral finance, which\ngrapples with a fundamental limitation: the scarcity of real-user data needed\nfor Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM\noutputs and human behavioral patterns, its reliance on massive authentic data\nimposes substantial collection costs and privacy risks. We propose InvestAlign,\na novel framework that constructs high-quality SFT datasets by leveraging\ntheoretical solutions to similar and simple optimal investment problems rather\nthan complex scenarios. Our theoretical analysis demonstrates that training\nLLMs with InvestAlign-generated data achieves faster parameter convergence than\nusing real-user data, suggesting superior learning efficiency. Furthermore, we\ndevelop InvestAgent, an LLM agent fine-tuned with InvestAlign, which\ndemonstrates significantly closer alignment to real-user data than pre-SFT\nmodels in both simple and complex investment problems. This highlights our\nproposed InvestAlign as a promising approach with the potential to address\ncomplex optimal investment problems and align LLMs with investor\ndecision-making processes under herd behavior. Our code is publicly available\nat https://github.com/thu-social-network-research-group/InvestAlign.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faInvestAlign\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u7406\u8bba\u89e3\u5408\u6210SFT\u6570\u636e\uff0c\u4f4e\u6210\u672c\u9ad8\u6548\u5730\u8bad\u7ec3LLM\uff0c\u4f7f\u5176\u66f4\u597d\u5730\u6a21\u62df\u6295\u8d44\u8005\u5728\u7f8a\u7fa4\u884c\u4e3a\u4e0b\u7684\u51b3\u7b56\uff0c\u5b9e\u9a8c\u548c\u7406\u8bba\u5206\u6790\u5747\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u4f7f\u7528\u771f\u5b9e\u7528\u6237\u6570\u636e\u7684\u65b9\u5f0f\u3002", "motivation": "\u884c\u4e3a\u91d1\u878d\u9886\u57df\u5173\u6ce8\u8ba9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u66f4\u597d\u5730\u6a21\u62df\u6295\u8d44\u8005\u5728\u7f8a\u7fa4\u884c\u4e3a\u4e0b\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f46\u7531\u4e8e\u771f\u5b9e\u7528\u6237\u6570\u636e\u7a00\u7f3a\uff0c\u53d7\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u9762\u4e34\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u548c\u9690\u79c1\u98ce\u9669\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faInvestAlign\u6846\u67b6\uff0c\u5229\u7528\u7c7b\u4f3c\u3001\u7b80\u5355\u6700\u4f18\u6295\u8d44\u95ee\u9898\u7684\u7406\u8bba\u89e3\u4ee3\u66ff\u590d\u6742\u60c5\u666f\uff0c\u5408\u6210\u9ad8\u8d28\u91cfSFT\u5fae\u8c03\u6570\u636e\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e86\u7528InvestAlign\u6570\u636e\u4e0e\u771f\u5b9e\u7528\u6237\u6570\u636e\u8bad\u7ec3LLM\u7684\u8868\u73b0\u3002", "result": "\u7528InvestAlign\u751f\u6210\u7684\u6570\u636e\u8bad\u7ec3\u7684LLM\u53c2\u6570\u6536\u655b\u66f4\u5feb\uff0c\u5b66\u4e60\u6548\u7387\u66f4\u9ad8\u3002\u57fa\u4e8eInvestAlign\u5fae\u8c03\u7684InvestAgent\u5728\u5404\u7c7b\u6295\u8d44\u95ee\u9898\u4e0a\u4e0e\u771f\u5b9e\u7528\u6237\u6570\u636e\u7684\u5bf9\u9f50\u5ea6\u4f18\u4e8e\u672a\u5fae\u8c03\u6a21\u578b\u3002", "conclusion": "InvestAlign\u4e3a\u89e3\u51b3\u6295\u8d44\u9886\u57df\u590d\u6742\u51b3\u7b56\u5efa\u6a21\u548cLLM\u5bf9\u9f50\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u3001\u9690\u79c1\u53cb\u597d\u7684\u65b0\u65b9\u6848\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u884c\u4e3a\u91d1\u878d\u9886\u57df\u5e94\u7528\u7684\u53ef\u884c\u6027\u548c\u6f5c\u529b\u3002"}}
{"id": "2507.06539", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06539", "abs": "https://arxiv.org/abs/2507.06539", "authors": ["Yunyang Cao", "Yanjun Li", "Silong Dai"], "title": "Large Language Model for Extracting Complex Contract Information in Industrial Scenes", "comment": null, "summary": "This paper proposes a high-quality dataset construction method for complex\ncontract information extraction tasks in industrial scenarios and fine-tunes a\nlarge language model based on this dataset. Firstly, cluster analysis is\nperformed on industrial contract texts, and GPT-4 and GPT-3.5 are used to\nextract key information from the original contract data, obtaining high-quality\ndata annotations. Secondly, data augmentation is achieved by constructing new\ntexts, and GPT-3.5 generates unstructured contract texts from randomly combined\nkeywords, improving model robustness. Finally, the large language model is\nfine-tuned based on the high-quality dataset. Experimental results show that\nthe model achieves excellent overall performance while ensuring high field\nrecall and precision and considering parsing efficiency. LoRA, data balancing,\nand data augmentation effectively enhance model accuracy and robustness. The\nproposed method provides a novel and efficient solution for industrial contract\ninformation extraction tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u6784\u5efa\u65b9\u6cd5\u7ed3\u5408\u5927\u6a21\u578b\u5fae\u8c03\uff0c\u6210\u529f\u63d0\u5347\u4e86\u5408\u540c\u4fe1\u606f\u62bd\u53d6\u7684\u51c6\u786e\u6027\u4e0e\u9c81\u68d2\u6027\uff0c\u4e3a\u5de5\u4e1a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u65b9\u6848\u3002", "motivation": "\u5de5\u4e1a\u573a\u666f\u4e0b\u7684\u5408\u540c\u4fe1\u606f\u63d0\u53d6\u4efb\u52a1\u590d\u6742\uff0c\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u9650\u5236\u4e86\u6a21\u578b\u6027\u80fd\u63d0\u5347\u3002", "method": "\u9996\u5148\u5bf9\u5408\u540c\u6587\u672c\u805a\u7c7b\u5206\u6790\uff0c\u501f\u52a9GPT-4\u548cGPT-3.5\u81ea\u52a8\u62bd\u53d6\u5173\u952e\u4fe1\u606f\u751f\u6210\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u3002\u5176\u6b21\u4f7f\u7528\u5173\u952e\u8bcd\u968f\u673a\u7ec4\u5408\u548c\u5927\u6a21\u578b\uff08GPT-3.5\uff09\u751f\u6210\u65b0\u7684\u975e\u7ed3\u6784\u5316\u5408\u540c\u6587\u672c\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u3002\u6700\u540e\u7528\u8fd9\u4e9b\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u540c\u65f6\u5e94\u7528LoRA\u3001\u6570\u636e\u5747\u8861\u7b49\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1\u9ad8\u53ec\u56de\u7387\u548c\u9ad8\u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\uff0c\u53d6\u5f97\u4e86\u51fa\u8272\u7684\u6574\u4f53\u6027\u80fd\uff0c\u4e14\u89e3\u6790\u6548\u7387\u826f\u597d\u3002\u6570\u636e\u589e\u5f3a\u3001\u5747\u8861\u3001LoRA\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6570\u636e\u96c6\u6784\u5efa\u4e0e\u6a21\u578b\u5fae\u8c03\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5de5\u4e1a\u5408\u540c\u4fe1\u606f\u62bd\u53d6\u7684\u6574\u4f53\u8868\u73b0\uff0c\u662f\u9762\u5411\u8be5\u9886\u57df\u7684\u4e00\u79cd\u65b0\u9896\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.06565", "categories": ["cs.CL", "cs.LG", "68T01, 60J10, 91D30, 05C82, 68T50, 68W20, 94A15", "I.2.7; I.2.11; G.3"], "pdf": "https://arxiv.org/pdf/2507.06565", "abs": "https://arxiv.org/abs/2507.06565", "authors": ["Juan B. Guti\u00e9rrez"], "title": "The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production", "comment": "27 pages, 3 figures, 4 tables, 1 algorithm, 28 references", "summary": "Large-language models turn writing into a live exchange between humans and\nsoftware. We capture this new medium with a discursive-network model that\ntreats people and LLMs as equal nodes and tracks how their statements\ncirculate. Broadening the focus from isolated hallucinations, we define\ninvalidation (any factual, logical, or structural breach) and show it follows\nfour hazards: drift from truth, self-repair, fresh fabrication, and external\ndetection. A general mathematical model of discursive networks is developed to\nprovide valuable insights: A network governed only by drift and self-repair\nstabilizes at a modest error rate; adding fabrication reproduces the high rates\nseen in current LLMs. Giving each false claim even a small chance of peer\nreview shifts the system to a truth-dominant state. We operationalize peer\nreview with the open-source \\emph{Flaws-of-Others (FOO) algorithm}: a\nconfigurable loop in which any set of agents critique one another while a\nharmoniser merges their verdicts. The takeaway is practical and cultural:\nreliability in this new medium comes not from perfecting single models but from\nwiring imperfect ones into networks that keep each other honest.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\uff0c\u5c06\u4eba\u548c\u5927\u8bed\u8a00\u6a21\u578b\u8282\u70b9\u7ec4\u5efa\u6210\u5e26\u6709\u4e92\u8bc4\u516c\u5171\u673a\u5236\u7684\u8bdd\u8bed\u7f51\u7edc\uff0c\u6bd4\u5355\u4e00\u5b8c\u5584\u6a21\u578b\u66f4\u80fd\u63d0\u9ad8\u6574\u4f53\u6587\u672c\u8f93\u51fa\u7684\u771f\u5b9e\u6027\u548c\u53ef\u9760\u6027\u3002\u901a\u8fc7\u6570\u5b66\u5efa\u6a21\u4e0eFOO\u7b97\u6cd5\u5b9e\u9a8c\uff0c\u5728\u591a\u4ee3\u7406\u4e92\u76f8\u6279\u6539\u4e0b\uff0c\u865a\u5047\u4fe1\u606f\u53ef\u5927\u5e45\u5ea6\u88ab\u6291\u5236\uff0c\u7f51\u7edc\u8f93\u51fa\u66f4\u7a33\u5b9a\u771f\u5b9e\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u4e8b\u5b9e\u3001\u903b\u8f91\u3001\u7ed3\u6784\u6027\u9519\u8bef\u9891\u53d1\u7684\u95ee\u9898\uff0c\u5355\u4e00\u6a21\u578b\u96be\u4ee5\u6839\u672c\u89e3\u51b3\u3002\u4f5c\u8005\u65e8\u5728\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u7f51\u7edc\u7ed3\u6784\u6539\u53d8\u4e0e\u63d0\u9ad8\u751f\u6210\u6587\u672c\u7684\u53ef\u9760\u6027\u3002", "method": "\u4f5c\u8005\u9996\u5148\u4ee5\u4eba\u548cLLM\u4e3a\u5e73\u7b49\u8282\u70b9\u6784\u5efa\u8bdd\u8bed\u7f51\u7edc\u6570\u5b66\u6a21\u578b\uff0c\u5206\u6790\u5178\u578b\u5931\u6548\uff08invalidations\uff09\u53ca\u5176\u56db\u79cd\u98ce\u9669\u6765\u6e90\uff0c\u5e76\u5f00\u53d1Flaws-of-Others (FOO)\u7b97\u6cd5\uff0c\u5c06\u540c\u884c\u4e92\u8bc4\u673a\u5236\u5d4c\u5165\u7f51\u7edc\uff0c\u901a\u8fc7\u591a\u4ee3\u7406\u4e92\u76f8\u6279\u5224\u548c\u7ed3\u8bba\u6574\u5408\u6765\u9a8c\u8bc1\u8fd9\u4e00\u673a\u5236\u7684\u6709\u6548\u6027\u3002", "result": "\u7406\u8bba\u6a21\u578b\u663e\u793a\uff0c\u4ec5\u6709\u201c\u6f02\u79fb\u4e0e\u81ea\u6211\u4fee\u6b63\u201d\u673a\u5236\u5c1a\u53ef\u7a33\u5b9a\u4e8e\u4e2d\u7b49\u9519\u8bef\u7387\uff1b\u82e5\u52a0\u5165\u865a\u6784\uff0c\u5219\u4e0e\u73b0\u6709LLM\u9519\u8bef\u7387\u543b\u5408\u3002\u5f15\u5165\u540c\u884c\u8bc4\u8bae\u540e\uff0c\u54ea\u6015\u53ea\u7ed9\u6bcf\u6761\u9519\u8bef\u4fe1\u606f\u5fae\u5c0f\u7684\u7ea0\u9519\u673a\u4f1a\uff0c\u7cfb\u7edf\u5c31\u80fd\u663e\u8457\u8f6c\u5411\u4ee5\u771f\u5b9e\u4e3a\u4e3b\u5bfc\u7684\u72b6\u6001\u3002FOO\u7b97\u6cd5\u5b9e\u9a8c\u4e5f\u8bc1\u5b9e\u4e86\u8fd9\u79cd\u673a\u5236\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6587\u63d0\u51fa\uff0c\u4e0e\u5176\u8ffd\u6c42\u5355\u4e00\u5927\u6a21\u578b\u7684\u5b8c\u7f8e\uff0c\u4e0d\u5982\u5c06\u591a\u4e2a\u4e0d\u5b8c\u7f8e\u6a21\u578b/\u4eba\u7ec4\u7f51\uff0c\u901a\u8fc7\u5f7c\u6b64\u7ea0\u9519\u6765\u63d0\u9ad8\u6574\u4f53\u8f93\u51fa\u7684\u53ef\u9760\u6027\uff0c\u8fd9\u79cd\u7f51\u7edc\u7ed3\u6784\u66f4\u6709\u52a9\u4e8e\u4fe1\u606f\u7684\u771f\u5b9e\u4e0e\u51c6\u786e\u6d41\u52a8\u3002"}}
{"id": "2507.06623", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06623", "abs": "https://arxiv.org/abs/2507.06623", "authors": ["James Stewart-Evans", "Emma Wilson", "Tessa Langley", "Andrew Prayle", "Angela Hands", "Karen Exley", "Jo Leonardi-Bee"], "title": "Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review", "comment": "44 pages, 4 figures", "summary": "The data extraction stages of reviews are resource-intensive, and researchers\nmay seek to expediate data extraction using online (large language models) LLMs\nand review protocols. Claude 3.5 Sonnet was used to trial two approaches that\nused a review protocol to prompt data extraction from 10 evidence sources\nincluded in a case study scoping review. A protocol-based approach was also\nused to review extracted data. Limited performance evaluation was undertaken\nwhich found high accuracy for the two extraction approaches (83.3% and 100%)\nwhen extracting simple, well-defined citation details; accuracy was lower (9.6%\nand 15.8%) when extracting more complex, subjective data items. Considering all\ndata items, both approaches had precision >90% but low recall (<25%) and F1\nscores (<40%). The context of a complex scoping review, open response types and\nmethodological approach likely impacted performance due to missed and\nmisattributed data. LLM feedback considered the baseline extraction accurate\nand suggested minor amendments: four of 15 (26.7%) to citation details and 8 of\n38 (21.1%) to key findings data items were considered to potentially add value.\nHowever, when repeating the process with a dataset featuring deliberate errors,\nonly 2 of 39 (5%) errors were detected. Review-protocol-based methods used for\nexpediency require more robust performance evaluation across a range of LLMs\nand review contexts with comparison to conventional prompt engineering\napproaches. We recommend researchers evaluate and report LLM performance if\nusing them similarly to conduct data extraction or review extracted data. LLM\nfeedback contributed to protocol adaptation and may assist future review\nprotocol drafting.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5229\u7528LLM+\u534f\u8bae\u81ea\u52a8\u5316\u6570\u636e\u63d0\u53d6\u7684\u6548\u679c\uff0c\u5bf9\u7b80\u5355\u6570\u636e\u9879\u6709\u6548\u4f46\u590d\u6742\u5ea6\u63d0\u5347\u540e\u53ec\u56de\u7387\u6781\u4f4e\uff0c\u5bf9\u9519\u8bef\u7684\u8bc6\u522b\u80fd\u529b\u4e5f\u8f83\u5dee\u3002LLM\u53ef\u8f85\u52a9\u534f\u8bae\u4f18\u5316\uff0c\u4f46\u5168\u9762\u66ff\u4ee3\u4eba\u5de5\u5c1a\u4e0d\u73b0\u5b9e\uff0c\u9700\u8fdb\u4e00\u6b65\u6d4b\u8bd5\u5e76\u8c28\u614e\u4f7f\u7528\u3002", "motivation": "\u6570\u636e\u63d0\u53d6\u662f\u7cfb\u7edf\u7efc\u8ff0\u4e2d\u7684\u9ad8\u8d44\u6e90\u6d88\u8017\u73af\u8282\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u5229\u7528\u5728\u7ebf\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u7efc\u8ff0\u65b9\u6848\uff0c\u63d0\u9ad8\u6570\u636e\u63d0\u53d6\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\u672c\u6587\u5c1d\u8bd5\u7528Claude 3.5 Sonnet\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u534f\u8bae\u9a71\u52a8\u7684\u63d0\u793a\u6765\u81ea\u52a8\u5316\u6b64\u8fc7\u7a0b\u3002", "method": "\u672c\u6587\u57fa\u4e8e\u6848\u4f8b\u7814\u7a76\u6cd5\uff0c\u5728\u4e00\u9879scoping review\u4e2d\u4ece10\u4e2a\u8bc1\u636e\u6e90\u4e2d\u5c1d\u8bd5\u4e86\u4e24\u79cd\u57fa\u4e8e\u7efc\u8ff0\u534f\u8bae\u7684\u6570\u636e\u63d0\u53d6\u65b9\u6cd5\uff0c\u5e76\u7528\u534f\u8bae\u8f85\u52a9\u590d\u5ba1\u62bd\u53d6\u6570\u636e\u3002\u6027\u80fd\u8bc4\u4f30\u5305\u62ec\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u53caF1\u503c\u7b49\u5e38\u89c1\u6307\u6807\u3002\u53e6\u6709\u4e00\u7ec4\u542b\u6709\u523b\u610f\u9519\u8bef\u7684\u6570\u636e\u7528\u4ee5\u6d4b\u8bd5\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u5728\u63d0\u53d6\u7b80\u5355\u660e\u786e\u5b9a\u4e49\u7684\u5f15\u6587\u8be6\u7ec6\u4fe1\u606f\u65f6\u51c6\u786e\u7387\u8f83\u9ad8\uff0883.3%\u4e0e100%\uff09\uff0c\u4f46\u5bf9\u4e8e\u590d\u6742\u4e3b\u89c2\u6570\u636e\u7684\u51c6\u786e\u7387\u8f83\u4f4e\uff089.6%\u548c15.8%\uff09\u3002\u603b\u4f53\u4e0a\u4e24\u8005\u7684\u7cbe\u786e\u7387\u5747\u5927\u4e8e90%\uff0c\u4f46\u53ec\u56de\u7387\u4f4e\u4e8e25%\uff0cF1\u503c\u4e0d\u523040%\u3002\u5bf9\u6545\u610f\u5f15\u5165\u9519\u8bef\u7684\u6570\u636e\u96c6\uff0c\u9519\u8bef\u68c0\u51fa\u7387\u4ec55%\u3002LLM\u5728\u53cd\u9988\u4fee\u8ba2\u65b9\u9762\u6709\u4e00\u5b9a\u8d21\u732e\uff0c\u4f46\u9519\u6f0f\u4f9d\u7136\u8f83\u591a\u3002", "conclusion": "\u57fa\u4e8e\u534f\u8bae\u7684LLM\u6570\u636e\u63d0\u53d6\u5728\u590d\u6742\u7efc\u8ff0\u60c5\u5883\u4e0b\u8868\u73b0\u5c1a\u4e0d\u7406\u60f3\uff0c\u7cbe\u786e\u7387\u9ad8\u4f46\u53ec\u56de\u7387\u4e0e\u5168\u9762\u6027\u4e0d\u8db3\uff0c\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\u6709\u9650\u3002\u8be5\u65b9\u6cd5\u5c1a\u9700\u5728\u4e0d\u540cLLM\u53ca\u7efc\u8ff0\u573a\u666f\u4e0b\u5f00\u5c55\u66f4\u7cfb\u7edf\u7684\u8bc4\u4f30\uff0c\u5e76\u4e0e\u7ecf\u5178prompt\u5de5\u7a0b\u6cd5\u5bf9\u6bd4\u3002\u5efa\u8bae\u672a\u6765\u5728\u5b9e\u9645\u5e94\u7528\u65f6\u9700\u4e25\u683c\u8bc4\u4f30\u548c\u62a5\u544aLLM\u8868\u73b0\uff0c\u5e76\u7ed3\u5408LLM\u53cd\u9988\u4f18\u5316\u7efc\u8ff0\u534f\u8bae\u3002"}}
{"id": "2507.06571", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06571", "abs": "https://arxiv.org/abs/2507.06571", "authors": ["Srihari K B", "Pushpak Bhattacharyya"], "title": "Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis", "comment": null, "summary": "We propose a unified food-domain QA framework that combines a large-scale\nmultimodal knowledge graph (MMKG) with generative AI. Our MMKG links 13,000\nrecipes, 3,000 ingredients, 140,000 relations, and 14,000 images. We generate\n40,000 QA pairs using 40 templates and LLaVA/DeepSeek augmentation. Joint\nfine-tuning of Meta LLaMA 3.1-8B and Stable Diffusion 3.5-Large improves\nBERTScore by 16.2\\%, reduces FID by 37.8\\%, and boosts CLIP alignment by\n31.1\\%. Diagnostic analyses-CLIP-based mismatch detection (35.2\\% to 7.3\\%) and\nLLaVA-driven hallucination checks-ensure factual and visual fidelity. A hybrid\nretrieval-generation strategy achieves 94.1\\% accurate image reuse and 85\\%\nadequacy in synthesis. Our results demonstrate that structured knowledge and\nmultimodal generation together enhance reliability and diversity in food QA.", "AI": {"tldr": "\u5229\u7528\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u548c\u751f\u6210\u5f0fAI\uff0c\u6781\u5927\u63d0\u5347\u4e86\u7f8e\u98df\u95ee\u7b54\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u4e0e\u591a\u6837\u6027\uff0c\u8868\u73b0\u4f18\u4e8e\u4ee5\u5f80\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7f8e\u98df\u9886\u57df\u7684\u95ee\u7b54\u7cfb\u7edf\u5728\u591a\u6a21\u6001\u4fe1\u606f\uff08\u5982\u6587\u672c\u3001\u56fe\u7247\uff09\u6574\u5408\u548c\u77e5\u8bc6\u7684\u5168\u9762\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u7ed3\u5408\u5927\u89c4\u6a21\u77e5\u8bc6\u4e0e\u751f\u6210\u5f0fAI\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u95ee\u7b54\u7684\u51c6\u786e\u6027\u4e0e\u591a\u6837\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7f8e\u98df\u9886\u57df\u95ee\u7b54\u6846\u67b6\uff0c\u5c06\u5927\u89c4\u6a21\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\uff08MMKG\uff09\u4e0e\u751f\u6210\u5f0fAI\u76f8\u7ed3\u5408\u3002\u6784\u5efa\u4e86\u5305\u542b13,000\u4e2a\u83dc\u8c31\u30013,000\u4e2a\u98df\u6750\u3001140,000\u4e2a\u5173\u7cfb\u548c14,000\u5f20\u56fe\u7247\u7684MMKG\uff0c\u901a\u8fc740\u79cd\u6a21\u677f\u548cLLaVA/DeepSeek\u589e\u5f3a\u751f\u62104\u4e07\u7ec4\u95ee\u7b54\u914d\u5bf9\u3002\u8054\u5408\u5fae\u8c03Meta LLaMA 3.1-8B\u4e0eStable Diffusion 3.5-Large\uff0c\u5e76\u5229\u7528CLIP\u548cLLaVA\u8fdb\u884c\u8bca\u65ad\u5206\u6790\u548c\u9519\u8bef\u68c0\u6d4b\u3002\u91c7\u7528\u68c0\u7d22-\u751f\u6210\u6df7\u5408\u7b56\u7565\u63d0\u5347\u95ee\u7b54\u6027\u80fd\u3002", "result": "BERTScore\u63d0\u534716.2%\uff0cFID\u964d\u4f4e37.8%\uff0cCLIP\u5bf9\u9f50\u63d0\u534731.1%\uff1bCLIP\u9519\u8bef\u68c0\u6d4b\u7387\u4ece35.2%\u964d\u81f37.3%\uff1bLLaVA\u5e7b\u89c9\u68c0\u67e5\u8fdb\u4e00\u6b65\u63d0\u5347\u4e8b\u5b9e\u548c\u89c6\u89c9\u7684\u51c6\u786e\u6027\uff1b94.1%\u7684\u56fe\u7247\u590d\u7528\u51c6\u786e\u7387\u548c85%\u7684\u5408\u6210\u5145\u5206\u6027\u3002", "conclusion": "\u7ed3\u6784\u5316\u77e5\u8bc6\u4e0e\u591a\u6a21\u6001\u751f\u6210\u7684\u534f\u540c\u5e94\u7528\u53ef\u6709\u6548\u63d0\u5347\u7f8e\u98df\u9886\u57df\u95ee\u7b54\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u591a\u6837\u6027\u3002"}}
{"id": "2507.06658", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06658", "abs": "https://arxiv.org/abs/2507.06658", "authors": ["Gennadii Iakovlev"], "title": "Elite Polarization in European Parliamentary Speeches: a Novel Measurement Approach Using Large Language Models", "comment": null, "summary": "This project introduces a new measure of elite polarization via actor and\nsubject detection using artificial intelligence. I identify when politicians\nmention one another in parliamentary speeches, note who is speaking and who is\nbeing addressed, and assess the emotional temperature behind these evaluations.\nThis maps how elites evaluate their various out-parties, allowing us to create\nan index of mutual out-party hostility, that is, elite polarization. While I\nanalyzed polarization data over the past four decades for the UK, and two\ndecades for Hungary and Italy, my approach lays the groundwork for a\ntwenty-year, EU-wide time-series dataset on elite polarization. I obtain the\nresults that can be aggregated by party and quarter. The resulting index\ndemonstrates a good face validity: it reacts to events such as electoral\ncampaigns, country- and party-level crises, and to parties losing and assuming\npower.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u5229\u7528\u4eba\u5de5\u667a\u80fd\u81ea\u52a8\u8bc6\u522b\u548c\u91cf\u5316\u8bae\u4f1a\u6f14\u8bb2\u4e2d\u7684\u653f\u6cbb\u7cbe\u82f1\u6781\u5316\uff0c\u5e76\u5f00\u53d1\u51fa\u7cbe\u82f1\u6781\u5316\u6307\u6570\uff0c\u80fd\u654f\u611f\u6355\u6349\u653f\u6cbb\u91cd\u5927\u4e8b\u4ef6\u5e26\u6765\u7684\u53d8\u5316\uff0c\u5177\u6709\u8f83\u5f3a\u5b9e\u8bc1\u4ef7\u503c\u3002", "motivation": "\u5f53\u524d\u5bf9\u7cbe\u82f1\u6781\u5316\u7684\u6d4b\u91cf\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u548c\u4e3b\u89c2\u5224\u65ad\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u3001\u53ef\u8de8\u56fd\u4e14\u957f\u65f6\u95f4\u5e8f\u5217\u7684\u6570\u636e\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u5f00\u53d1\u81ea\u52a8\u5316\u3001\u91cf\u5316\u5de5\u5177\uff0c\u63d0\u5347\u5206\u6790\u6548\u7387\u548c\u5ba2\u89c2\u6027\u3002", "method": "\u901a\u8fc7\u4eba\u5de5\u667a\u80fd\u5bf9\u8bae\u4f1a\u6f14\u8bb2\u4e2d\u7684\u53d1\u8a00\u8005\u548c\u88ab\u63d0\u53ca\u8005\u8fdb\u884c\u8bc6\u522b\uff0c\u5206\u6790\u60c5\u611f\u503e\u5411\uff0c\u5e76\u6784\u5efa\u201c\u76f8\u4e92\u5916\u515a\u654c\u610f\u6307\u6570\u201d\u4f5c\u4e3a\u7cbe\u82f1\u6781\u5316\u8861\u91cf\u5de5\u5177\u3002", "result": "\u6784\u5efa\u4e86\u53ef\u6309\u515a\u6d3e\u548c\u5b63\u5ea6\u7ec6\u5206\u7684\u7cbe\u82f1\u6781\u5316\u6307\u6570\uff0c\u9a8c\u8bc1\u4e86\u5176\u5bf9\u91cd\u8981\u653f\u6cbb\u4e8b\u4ef6\u5177\u6709\u826f\u597d\u53cd\u5e94\u548c\u89e3\u91ca\u529b\uff0c\u5e76\u4e3a\u5efa\u7acb\u8de8\u6b27\u76df\u957f\u671f\u6570\u636e\u6253\u4e0b\u57fa\u7840\u3002", "conclusion": "\u65b0\u7684\u7cbe\u82f1\u6781\u5316\u6307\u6807\u6709\u6548\u53cd\u6620\u4e86\u653f\u515a\u95f4\u7684\u654c\u610f\uff0c\u5e76\u80fd\u591f\u52a8\u6001\u8ddf\u8e2a\u76f8\u5173\u653f\u6cbb\u4e8b\u4ef6\u5e26\u6765\u7684\u53d8\u5316\uff0c\u8bc1\u660e\u5176\u53ef\u7528\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.06607", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06607", "abs": "https://arxiv.org/abs/2507.06607", "authors": ["Liliang Ren", "Congcong Chen", "Haoran Xu", "Young Jin Kim", "Adam Atkinson", "Zheng Zhan", "Jiankai Sun", "Baolin Peng", "Liyuan Liu", "Shuohang Wang", "Hao Cheng", "Jianfeng Gao", "Weizhu Chen", "Yelong Shen"], "title": "Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation", "comment": null, "summary": "Recent advances in language modeling have demonstrated the effectiveness of\nState Space Models (SSMs) for efficient sequence modeling. While hybrid\narchitectures such as Samba and the decoder-decoder architecture, YOCO, have\nshown promising performance gains over Transformers, prior works have not\ninvestigated the efficiency potential of representation sharing between SSM\nlayers. In this paper, we introduce the Gated Memory Unit (GMU), a simple yet\neffective mechanism for efficient memory sharing across layers. We apply it to\ncreate SambaY, a decoder-hybrid-decoder architecture that incorporates GMUs in\nthe cross-decoder to share memory readout states from a Samba-based\nself-decoder. SambaY significantly enhances decoding efficiency, preserves\nlinear pre-filling time complexity, and boosts long-context performance, all\nwhile eliminating the need for explicit positional encoding. Through extensive\nscaling experiments, we demonstrate that our model exhibits a significantly\nlower irreducible loss compared to a strong YOCO baseline, indicating superior\nperformance scalability under large-scale compute regimes. Our largest model\nenhanced with Differential Attention, Phi4-mini-Flash-Reasoning, achieves\nsignificantly better performance than Phi4-mini-Reasoning on reasoning tasks\nsuch as Math500, AIME24/25, and GPQA Diamond without any reinforcement\nlearning, while delivering up to 10x higher decoding throughput on 2K-length\nprompts with 32K generation length under the vLLM inference framework. We\nrelease our training codebase on open-source data at\nhttps://github.com/microsoft/ArchScale.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u7684GMU\u6a21\u5757\u53ca\u57fa\u4e8e\u5176\u7684SambaY\u6df7\u5408\u67b6\u6784\uff0c\u901a\u8fc7\u8de8\u5c42\u8bb0\u5fc6\u5171\u4eab\uff0c\u663e\u8457\u63d0\u5347\u4e86\u957f\u5e8f\u5217\u63a8\u7406\u6548\u7387\u548c\u4e0b\u6e38\u63a8\u7406\u4efb\u52a1\u80fd\u529b\uff0c\u5bf9\u6bd4\u4e3b\u6d41YOCO\u57fa\u7ebf\u5728\u591a\u4e2a\u7ef4\u5ea6\u53d6\u5f97\u7a81\u7834\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u8fd1\u5e74\u6765\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSMs\uff09\u5728\u9ad8\u6548\u5e8f\u5217\u5efa\u6a21\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff0c\u90e8\u5206\u6df7\u5408\u67b6\u6784\uff08\u5982Samba, YOCO\uff09\u5df2\u4f18\u4e8e\u7ecf\u5178Transformer\u3002\u4f46\u73b0\u6709\u7814\u7a76\u5c1a\u672a\u63a2\u7d22SSM\u5c42\u95f4\u8868\u793a\u5171\u4eab\u7684\u6548\u7387\u6f5c\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGated Memory Unit\uff08GMU\uff09\u7684\u673a\u5236\uff0c\u5b9e\u73b0\u8de8\u5c42\u9ad8\u6548\u8bb0\u5fc6\u5171\u4eab\u3002\u57fa\u4e8e\u6b64\uff0c\u8bbe\u8ba1\u4e86SambaY\u67b6\u6784\uff0c\u901a\u8fc7\u5728\u4ea4\u53c9\u89e3\u7801\u5668\u4e2d\u5229\u7528GMU\u5171\u4eabSamba\u5f0f\u81ea\u89e3\u7801\u5668\u7684\u8bb0\u5fc6\u8bfb\u51fa\u72b6\u6001\uff0c\u4ece\u800c\u4f18\u5316\u4e86\u6df7\u5408\u89e3\u7801\u4e5d\u6784\u67b6\u3002", "result": "SambaY\u63d0\u5347\u4e86\u89e3\u7801\u6548\u7387\u3001\u4fdd\u6301\u7ebf\u6027\u9884\u586b\u5145\u65f6\u95f4\u590d\u6742\u5ea6\u4e14\u589e\u5f3a\u4e86\u957f\u4e0a\u4e0b\u6587\u6027\u80fd\uff0c\u65e0\u9700\u663e\u5f0f\u4f4d\u7f6e\u7f16\u7801\u3002\u5728\u5927\u89c4\u6a21\u5b9e\u9a8c\u4e2d\uff0c\u5bf9YOCO\u57fa\u7ebf\u5c55\u73b0\u4e86\u66f4\u4f4e\u7684\u4e0d\u53ef\u7ea6\u635f\u5931\uff0c\u8868\u73b0\u66f4\u4f18\u3002\u96c6\u6210\u5dee\u5206\u6ce8\u610f\u529b\u7684\u6700\u5927\u6a21\u578bPhi4-mini-Flash-Reasoning\u5728\u591a\u4e2a\u63a8\u7406\u4efb\u52a1\u4e0a\u4f18\u4e8ePhi4-mini-Reasoning\uff0c\u5e76\u80fd\u5728\u957f\u5e8f\u5217\u63a8\u7406\u573a\u666f\u4e0b\u5e26\u6765\u9ad8\u8fbe10\u500d\u7684\u63a8\u7406\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "GMU\u673a\u5236\u548cSambaY\u67b6\u6784\u6709\u6548\u5b9e\u73b0\u4e86\u8de8\u5c42\u8bb0\u5fc6\u5171\u4eab\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u548c\u5927\u89c4\u6a21\u63a8\u7406\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2507.06715", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.06715", "abs": "https://arxiv.org/abs/2507.06715", "authors": ["Garapati Keerthana", "Manik Gupta"], "title": "CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs", "comment": "12 pages, 4 figures", "summary": "Large language models (LLMs), including zero-shot and few-shot paradigms,\nhave shown promising capabilities in clinical text generation. However,\nreal-world applications face two key challenges: (1) patient data is highly\nunstructured, heterogeneous, and scattered across multiple note types and (2)\nclinical notes are often long and semantically dense, making naive prompting\ninfeasible due to context length constraints and the risk of omitting\nclinically relevant information.\n  We introduce CLI-RAG (Clinically Informed Retrieval-Augmented Generation), a\ndomain-specific framework for structured and clinically grounded text\ngeneration using LLMs. It incorporates a novel hierarchical chunking strategy\nthat respects clinical document structure and introduces a task-specific\ndual-stage retrieval mechanism. The global stage identifies relevant note types\nusing evidence-based queries, while the local stage extracts high-value content\nwithin those notes creating relevance at both document and section levels.\n  We apply the system to generate structured progress notes for individual\nhospital visits using 15 clinical note types from the MIMIC-III dataset.\nExperiments show that it preserves temporal and semantic alignment across\nvisits, achieving an average alignment score of 87.7%, surpassing the 80.7%\nbaseline from real clinician-authored notes. The generated outputs also\ndemonstrate high consistency across LLMs, reinforcing deterministic behavior\nessential for reproducibility, reliability, and clinical trust.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u7528\u4e8e\u4e34\u5e8a\u6587\u672c\u751f\u6210\u7684\u65b0\u6846\u67b6CLI-RAG\uff0c\u7ed3\u5408\u5206\u5c42\u5206\u5757\u4e0e\u53cc\u9636\u6bb5\u68c0\u7d22\uff0c\u5728\u7ed3\u6784\u5316\u533b\u7597\u6587\u672c\u751f\u6210\u4e0a\u8d85\u8fc7\u533b\u751f\u5199\u4f5c\u6c34\u5e73\uff0c\u5e76\u4fdd\u8bc1\u4e86\u9ad8\u4e00\u81f4\u6027\u4e0e\u53ef\u590d\u73b0\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u6a21\u578b\u5728\u533b\u7597\u6587\u672c\u751f\u6210\u4e2d\u7684\u5e94\u7528\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u60a3\u8005\u6570\u636e\u9ad8\u5ea6\u975e\u7ed3\u6784\u5316\u3001\u5f02\u6784\u4e14\u5206\u6563\u4e8e\u591a\u79cd\u7b14\u8bb0\u7c7b\u578b\u4e2d\uff1b\u533b\u7597\u7b14\u8bb0\u5197\u957f\u4e14\u8bed\u4e49\u5bc6\u96c6\uff0c\u4f20\u7edf\u63d0\u793a\u65b9\u6cd5\u96be\u4ee5\u6db5\u76d6\u6240\u6709\u5173\u952e\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86CLI-RAG\u6846\u67b6\uff0c\u7528\u4e8e\u7ed3\u6784\u5316\u548c\u533b\u5b66\u4e8b\u5b9e\u652f\u6491\u7684\u6587\u672c\u751f\u6210\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u5206\u5c42\u6587\u672c\u5206\u5757\u7b56\u7565\uff0c\u7ed3\u5408\u7279\u5b9a\u4efb\u52a1\u7684\u53cc\u9636\u6bb5\u68c0\u7d22\u673a\u5236\u3002\u7b2c\u4e00\u9636\u6bb5\u5168\u5c40\u68c0\u7d22\u76f8\u5173\u7b14\u8bb0\u7c7b\u578b\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5c40\u90e8\u68c0\u7d22\u7b14\u8bb0\u5185\u90e8\u6709\u4ef7\u503c\u7684\u4fe1\u606f\uff0c\u5b9e\u73b0\u6587\u6863\u548c\u7ae0\u8282\u7ea7\u522b\u7684\u4fe1\u606f\u76f8\u5173\u6027\u3002", "result": "\u5728MIMIC-III\u6570\u636e\u96c6\u4e0a\uff0c\u5229\u752815\u79cd\u4e34\u5e8a\u7b14\u8bb0\u7c7b\u578b\u751f\u6210\u7ed3\u6784\u5316\u75c5\u7a0b\u8bb0\u5f55\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u4fdd\u6301\u4e0d\u540c\u5c31\u8bca\u95f4\u7684\u65f6\u5e8f\u548c\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u5e73\u5747\u5bf9\u9f50\u5206\u6570\u4e3a87.7%\uff0c\u9ad8\u4e8e\u771f\u5b9e\u533b\u751f\u7b14\u8bb0\u768480.7%\uff0c\u751f\u6210\u5185\u5bb9\u5728\u4e0d\u540c\u5927\u6a21\u578b\u95f4\u7684\u4e00\u81f4\u6027\u9ad8\uff0c\u589e\u5f3a\u4e86\u53ef\u590d\u73b0\u6027\u548c\u4e34\u5e8a\u4fe1\u4efb\u3002", "conclusion": "CLI-RAG\u901a\u8fc7\u521b\u65b0\u7684\u5206\u5c42\u5206\u5757\u548c\u53cc\u9636\u6bb5\u68c0\u7d22\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e34\u5e8a\u7b14\u8bb0\u751f\u6210\u4e2d\u7684\u7ed3\u6784\u5316\u548c\u5173\u952e\u4fe1\u606f\u63d0\u53d6\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6587\u672c\u751f\u6210\u7684\u8d28\u91cf\u548c\u4e00\u81f4\u6027\u3002"}}
{"id": "2507.06622", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06622", "abs": "https://arxiv.org/abs/2507.06622", "authors": ["Boshko Koloski", "Senja Pollak", "Roberto Navigli", "Bla\u017e \u0160krlj"], "title": "FuDoBa: Fusing Document and Knowledge Graph-based Representations with Bayesian Optimisation", "comment": null, "summary": "Building on the success of Large Language Models (LLMs), LLM-based\nrepresentations have dominated the document representation landscape, achieving\ngreat performance on the document embedding benchmarks. However, the\nhigh-dimensional, computationally expensive embeddings from LLMs tend to be\neither too generic or inefficient for domain-specific applications. To address\nthese limitations, we introduce FuDoBa a Bayesian optimisation-based method\nthat integrates LLM-based embeddings with domain-specific structured knowledge,\nsourced both locally and from external repositories like WikiData. This fusion\nproduces low-dimensional, task-relevant representations while reducing training\ncomplexity and yielding interpretable early-fusion weights for enhanced\nclassification performance. We demonstrate the effectiveness of our approach on\nsix datasets in two domains, showing that when paired with robust AutoML-based\nclassifiers, our proposed representation learning approach performs on par\nwith, or surpasses, those produced solely by the proprietary LLM-based\nembedding baselines.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faFuDoBa\uff0c\u4e00\u79cd\u878d\u5408\u9886\u57df\u77e5\u8bc6\u4e0eLLM\u5d4c\u5165\u3001\u4f4e\u7ef4\u9ad8\u6548\u7684\u6587\u6863\u8868\u5f81\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709LLM\u8868\u5f81\u66f4\u597d\u7684\u9886\u57df\u9002\u5e94\u548c\u5206\u7c7b\u6548\u679c\u3002", "motivation": "\u53d7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6587\u6863\u8868\u793a\u9886\u57df\u6210\u529f\u7684\u542f\u53d1\uff0c\u4f46\u5176\u9ad8\u7ef4\u5d4c\u5165\u5e38\u5b58\u5728\u6cdb\u5316\u6027\u5f3a\u3001\u5bf9\u7279\u5b9a\u9886\u57df\u6548\u7387\u4f4e\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u4f5c\u8005\u5e0c\u671b\u63d0\u5347\u9886\u57df\u76f8\u5173\u6027\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faFuDoBa\u65b9\u6cd5\uff0c\u5229\u7528\u8d1d\u53f6\u65af\u4f18\u5316\uff0c\u5c06LLM\u751f\u6210\u7684\u5d4c\u5165\u4e0e\u9886\u57df\u7ed3\u6784\u5316\u77e5\u8bc6\uff08\u5982WikiData\u7b49\u5916\u90e8\u5e93\u548c\u672c\u5730\u77e5\u8bc6\uff09\u8fdb\u884c\u878d\u5408\uff0c\u5e76\u751f\u6210\u4f4e\u7ef4\u4e14\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u8868\u793a\uff0c\u540c\u65f6\u8f93\u51fa\u53ef\u89e3\u91ca\u7684\u878d\u5408\u6743\u91cd\u3002", "result": "\u5728\u516d\u4e2a\u6570\u636e\u96c6\u3001\u4e24\u4e2a\u9886\u57df\u4e0b\uff0c\u7ed3\u5408AutoML\u5206\u7c7b\u5668\u540e\uff0c\u8be5\u4f4e\u7ef4\u8868\u5f81\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u53ef\u4e0e\u6216\u4f18\u4e8e\u4f20\u7edfLLM\u5d4c\u5165\u57fa\u7ebf\u3002", "conclusion": "FuDoBa\u6709\u6548\u878d\u5408LLM\u5d4c\u5165\u4e0e\u9886\u57df\u77e5\u8bc6\uff0c\u63d0\u5347\u4e86\u8868\u5f81\u7684\u6548\u7387\u3001\u76f8\u5173\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u9886\u57df\u7279\u5b9a\u6587\u6863\u8868\u793a\u63d0\u4f9b\u4e86\u4f18\u4e8e\u73b0\u6709LLM\u65b9\u6cd5\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2507.06753", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6"], "pdf": "https://arxiv.org/pdf/2507.06753", "abs": "https://arxiv.org/abs/2507.06753", "authors": ["Ye Kyaw Thu", "Thura Aung", "Thazin Myint Oo", "Thepchai Supnithi"], "title": "KAConvText: Novel Approach to Burmese Sentence Classification using Kolmogorov-Arnold Convolution", "comment": "10 pages, 3 figures, 4 tables", "summary": "This paper presents the first application of Kolmogorov-Arnold Convolution\nfor Text (KAConvText) in sentence classification, addressing three tasks:\nimbalanced binary hate speech detection, balanced multiclass news\nclassification, and imbalanced multiclass ethnic language identification. We\ninvestigate various embedding configurations, comparing random to fastText\nembeddings in both static and fine-tuned settings, with embedding dimensions of\n100 and 300 using CBOW and Skip-gram models. Baselines include standard CNNs\nand CNNs augmented with a Kolmogorov-Arnold Network (CNN-KAN). In addition, we\ninvestigated KAConvText with different classification heads - MLP and KAN,\nwhere using KAN head supports enhanced interpretability. Results show that\nKAConvText-MLP with fine-tuned fastText embeddings achieves the best\nperformance of 91.23% accuracy (F1-score = 0.9109) for hate speech detection,\n92.66% accuracy (F1-score = 0.9267) for news classification, and 99.82%\naccuracy (F1-score = 0.9982) for language identification.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5c06KAConvText\u5377\u79ef\u7ed3\u6784\u5e94\u7528\u4e8e\u6587\u672c\u5206\u7c7b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u3001\u65b0\u95fb\u5206\u7c7b\u548c\u8bed\u8a00\u8bc6\u522b\u4e09\u9879\u4efb\u52a1\u7684\u51c6\u786e\u6027\u548cF1\u5206\u6570\uff0c\u540c\u65f6\u517c\u987e\u4e86\u6027\u80fd\u548c\u89e3\u91ca\u6027\uff0c\u8868\u73b0\u8d85\u8fc7\u4f20\u7edfCNN\u53ca\u5176\u53d8\u79cd\u3002", "motivation": "\u76ee\u524d\u6587\u672c\u5206\u7c7b\u9886\u57df\u5b58\u5728\u8bf8\u5982\u7c7b\u522b\u4e0d\u5e73\u8861\u3001\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7b49\u6311\u6218\uff0c\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u65b0\u7684\u5efa\u6a21\u65b9\u5f0f\u4ee5\u63d0\u5347\u5206\u7c7b\u6548\u679c\u4e14\u589e\u5f3a\u6a21\u578b\u89e3\u91ca\u80fd\u529b\u3002", "method": "\u672c\u6587\u9996\u6b21\u5c06Kolmogorov-Arnold\u5377\u79ef\u5e94\u7528\u4e8e\u6587\u672c\u5206\u7c7b\uff08KAConvText\uff09\uff0c\u9488\u5bf9\u4e09\u9879\u4efb\u52a1\uff1a\u4e0d\u5e73\u8861\u7684\u4e8c\u5206\u7c7b\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u3001\u5747\u8861\u7684\u591a\u5206\u7c7b\u65b0\u95fb\u5206\u7c7b\u3001\u4e0d\u5e73\u8861\u7684\u591a\u5206\u7c7b\u6c11\u65cf\u8bed\u8a00\u8bc6\u522b\u3002\u7814\u7a76\u5bf9\u6bd4\u4e86\u591a\u79cd\u8bcd\u5d4c\u5165\u53ca\u7f51\u7edc\u7ed3\u6784\uff0c\u5e76\u5c1d\u8bd5\u4e0d\u540c\u5206\u7c7b\u5934\u3002", "result": "KAConvText-MLP\u4e0e\u5fae\u8c03\u540e\u7684fastText\u5d4c\u5165\u7ed3\u5408\uff0c\u5728\u4e09\u9879\u4efb\u52a1\u4e0a\u5206\u522b\u53d6\u5f97\u4e8691.23%\u300192.66%\u300199.82%\u7684\u51c6\u786e\u7387\uff0cF1\u5206\u6570\u5206\u522b\u4e3a0.9109\u30010.9267\u548c0.9982\u3002", "conclusion": "KAConvText\u5728\u6587\u672c\u5206\u7c7b\u4e2d\u7684\u9996\u6b21\u5e94\u7528\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\uff0c\u7279\u522b\u662f\u7ed3\u5408MLP\u5206\u7c7b\u5934\u548c\u5fae\u8c03\u8bcd\u5411\u91cf\u65f6\uff0c\u5728\u4e09\u79cd\u7c7b\u578b\u4efb\u52a1\u4e0a\u5747\u8d85\u8d8a\u4e86\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7KAN\u5206\u7c7b\u5934\u63d0\u5347\u4e86\u6a21\u578b\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.06795", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06795", "abs": "https://arxiv.org/abs/2507.06795", "authors": ["Seonwu Kim", "Yohan Na", "Kihun Kim", "Hanhee Cho", "Geun Lim", "Mintae Kim", "Seongik Park", "Ki Hyun Kim", "Youngsub Han", "Byoung-Ki Jeon"], "title": "Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications", "comment": "under review", "summary": "The emergence of open-source large language models (LLMs) has expanded\nopportunities for enterprise applications; however, many organizations still\nlack the infrastructure to deploy and maintain large-scale models. As a result,\nsmall LLMs (sLLMs) have become a practical alternative, despite their inherent\nperformance limitations. While Domain Adaptive Continual Pretraining (DACP) has\nbeen previously explored as a method for domain adaptation, its utility in\ncommercial applications remains under-examined. In this study, we validate the\neffectiveness of applying a DACP-based recipe across diverse foundation models\nand service domains. Through extensive experiments and real-world evaluations,\nwe demonstrate that DACP-applied sLLMs achieve substantial gains in target\ndomain performance while preserving general capabilities, offering a\ncost-efficient and scalable solution for enterprise-level deployment.", "AI": {"tldr": "\u9488\u5bf9\u4f01\u4e1a\u7f3a\u4e4f\u5927\u6a21\u578b\u90e8\u7f72\u80fd\u529b\u7684\u95ee\u9898\uff0c\u672c\u6587\u9a8c\u8bc1\u4e86\u7528DACP\u65b9\u6cd5\u63d0\u5347\u5c0f\u578b\u6a21\u578b\u9886\u57df\u9002\u5e94\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u53ef\u5728\u4fdd\u8bc1\u901a\u7528\u80fd\u529b\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u76ee\u6807\u4efb\u52a1\u8868\u73b0\uff0c\u9002\u5408\u4f01\u4e1a\u5927\u89c4\u6a21\u90e8\u7f72\u3002", "motivation": "\u8bb8\u591a\u4f01\u4e1a\u7f3a\u4e4f\u90e8\u7f72\u548c\u7ef4\u62a4\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u56e0\u6b64\u66f4\u52a0\u5173\u6ce8\u6027\u80fd\u6709\u9650\u4f46\u66f4\u6613\u7ba1\u7406\u7684\u5c0f\u6a21\u578b\uff08sLLMs\uff09\u3002\u9886\u57df\u81ea\u9002\u5e94\u6301\u7eed\u9884\u8bad\u7ec3\uff08DACP\uff09\u867d\u7136\u88ab\u63a2\u8ba8\u7528\u4e8e\u9886\u57df\u9002\u5e94\uff0c\u4f46\u5176\u5728\u5546\u4e1a\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u672a\u5145\u5206\u9a8c\u8bc1\u3002", "method": "\u672c\u6587\u5728\u591a\u79cd\u57fa\u7840\u6a21\u578b\u548c\u670d\u52a1\u9886\u57df\u4e0a\uff0c\u91c7\u7528\u5e76\u9a8c\u8bc1\u4e86\u57fa\u4e8eDACP\u7684\u5c0f\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u9886\u57df\u9002\u5e94\u6027\u7684\u65b9\u6848\u3002\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u548c\u5b9e\u9645\u5e94\u7528\u8bc4\u6d4b\uff0c\u68c0\u9a8c\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u548c\u771f\u5b9e\u5e94\u7528\u7ed3\u679c\u8868\u660e\uff0c\u91c7\u7528DACP\u7684\u5c0f\u578b\u6a21\u578b\u5728\u76ee\u6807\u9886\u57df\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u901a\u7528\u80fd\u529b\uff0c\u5177\u5907\u6210\u672c\u6548\u76ca\u9ad8\u3001\u53ef\u6269\u5c55\u6027\u5f3a\u7684\u4f18\u52bf\uff0c\u9002\u5408\u4f01\u4e1a\u90e8\u7f72\u3002", "conclusion": "DACP\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u7684\u8868\u73b0\uff0c\u662f\u6ee1\u8db3\u4f01\u4e1a\u7ea7\u90e8\u7f72\u9700\u6c42\u7684\u9ad8\u6027\u4ef7\u6bd4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.06722", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06722", "abs": "https://arxiv.org/abs/2507.06722", "authors": ["Sunwoo Kim", "Haneul Yoo", "Alice Oh"], "title": "On the Effect of Uncertainty on Layer-wise Inference Dynamics", "comment": "Accepted to Actionable Interpretability Workshop - ICML 2025", "summary": "Understanding how large language models (LLMs) internally represent and\nprocess their predictions is central to detecting uncertainty and preventing\nhallucinations. While several studies have shown that models encode uncertainty\nin their hidden states, it is underexplored how this affects the way they\nprocess such hidden states. In this work, we demonstrate that the dynamics of\noutput token probabilities across layers for certain and uncertain outputs are\nlargely aligned, revealing that uncertainty does not seem to affect inference\ndynamics. Specifically, we use the Tuned Lens, a variant of the Logit Lens, to\nanalyze the layer-wise probability trajectories of final prediction tokens\nacross 11 datasets and 5 models. Using incorrect predictions as those with\nhigher epistemic uncertainty, our results show aligned trajectories for certain\nand uncertain predictions that both observe abrupt increases in confidence at\nsimilar layers. We balance this finding by showing evidence that more competent\nmodels may learn to process uncertainty differently. Our findings challenge the\nfeasibility of leveraging simplistic methods for detecting uncertainty at\ninference. More broadly, our work demonstrates how interpretability methods may\nbe used to investigate the way uncertainty affects inference.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u672a\u660e\u663e\u5f71\u54cd\u5176\u63a8\u7406\u8fc7\u7a0b\uff0c\u591a\u6570\u60c5\u51b5\u4e0b\u8f93\u51fa\u6982\u7387\u8f68\u8ff9\u5bf9\u9f50\uff0c\u4ec5\u6709\u66f4\u5f3a\u6a21\u578b\u5728\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u4e0a\u8868\u73b0\u4e0d\u540c\uff0c\u8fd9\u5bf9\u5229\u7528\u7b80\u5355\u65b9\u6cd5\u68c0\u6d4b\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u63d0\u51fa\u4e86\u6311\u6218\u3002", "motivation": "\u6df1\u5165\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u5982\u4f55\u8868\u793a\u548c\u5904\u7406\u9884\u6d4b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u53ca\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u662f\u5426\u5f71\u54cd\u5176\u63a8\u7406\u8fc7\u7a0b\uff0c\u8fdb\u800c\u6539\u8fdb\u68c0\u6d4b\u5e7b\u89c9\u548c\u63d0\u5347\u6a21\u578b\u53ef\u9760\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Tuned Lens\u65b9\u6cd5\u5206\u67905\u79cd\u6a21\u578b\u572811\u4e2a\u6570\u636e\u96c6\u4e0a\u5bf9\u6700\u7ec8\u9884\u6d4btoken\u7684\u5206\u5c42\u6982\u7387\u8f68\u8ff9\uff0c\u5bf9\u6bd4\u786e\u5b9a\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u9884\u6d4b\u7ed3\u679c\u3002", "result": "\u5bf9\u4e8e\u6b63\u786e\uff08\u786e\u5b9a\uff09\u548c\u9519\u8bef\uff08\u4e0d\u786e\u5b9a\uff09\u9884\u6d4b\uff0c\u6a21\u578b\u7684\u8f93\u51fa\u6982\u7387\u8f68\u8ff9\u5c42\u5c42\u5bf9\u9f50\uff0c\u8868\u660e\u7edd\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4e0d\u786e\u5b9a\u6027\u672a\u5f71\u54cd\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f46\u66f4\u597d\u7684\u6a21\u578b\u663e\u793a\u51fa\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u624b\u6cd5\u7684\u53d8\u5316\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u5e76\u672a\u663e\u8457\u5f71\u54cdLLM\u7684\u63a8\u7406\u52a8\u6001\uff0c\u552f\u6709\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u624d\u53ef\u80fd\u5b66\u4f1a\u4e0d\u540c\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u5f0f\u3002"}}
